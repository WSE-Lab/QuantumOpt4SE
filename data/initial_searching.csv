Author,Title,Year,DOI,Link,Type,Venue,Abstract,Source
"Lubrano, Francesco and Vercellino, Chiara and Vitali, Giacomo and Viviani, Paolo and Scionti, Alberto and Terzo, Olivier",Advanced Resource Allocation in the Context of Heterogeneous Workflows Management,2024,10.1145/3642978.3652835,https://doi.org/10.1145/3642978.3652835,Conference paper,WiDE '24: Proceedings of the 2nd Workshop on Workflows in Distributed Environments,"In High-Performance Computing (HPC), workflows are utilized to define and manage a set of interdependent computations which allow the users to extract insights from (scientific) numerical simulations or data analytics. HPC platforms can perform extreme-scale simulations, combining Artificial Intelligence (AI) training and inference and data analytics (we refer to heterogeneous workflows), by providing tools and computing resources which serve a variety of use-cases spanning very diverse application domains (e.g., weather forecasting, quantum mechanics, etc.). Executing such workflows at scale requires to handle dependencies, job submission automation, I/O mechanisms. Despite State-of-the-Art batch schedulers can be configured and integrated with tools accomplishing this automation, a number of cases where resource allocation can lead to inefficiencies still exist. In this paper, to overcome these limitations, we present the WARP (Workflow-aware Advanced Resource Planner), a tool that integrates with workflow management tools and batch schedulers, to reserve in advance resources for an optimal execution of jobs, based on their duration, dependencies and machine load. WARP has been designed to minimize the overall workflow execution, without violating the priority policies for cluster users imposed by the system administrators.",ACM
"Granucci, Nicole and Jaiswal, Chetan",Beyond the Pixels: An Interdisciplinary Approach to Image Analysis in Astronomy --- Poster Abstract,2024,10.5555/3665609.3665640,https://dl.acm.org/doi/10.5555/3665609.3665640,Journal,J. Comput. Sci. Coll.,"Interdisciplinary collaboration between computer science and astronomy is critical for new discoveries as it brings together the expertise of two distinct yet complementary fields. The vast and complex datasets generated by astronomical observations require sophisticated computational methods for analysis and interpretation. Computer scientists contribute their skills in algorithm development, data processing, and artificial intelligence whereas astronomers provide unique challenges and insights that push the boundaries of computer science applications. This collaboration offers a multifaceted learning experience for students beyond disciplinary boundaries. This approach encourages a diverse skill set development, promotes creativity, critical thinking, and adaptability. It provides students with real-world applications for their theoretical knowledge, preparing them for careers that demand cross-disciplinary collaboration. It also instills a collaborative mindset that is increasingly essential in today's interconnected scientific landscape. Our intent is to develop a baseline model and then involve students during the summer research experience program. We also foresee developing a Computer Science-Physics cross listed undergraduate course for enriching student experience who are interested in these two disciplines. In this study, we will present our work in progress towards developing open-source software for astronomy image study and analysis. The flexibility of open-source development combined with a culture of innovation, leads to rapid improvements and the introduction of cutting-edge features. This software would provide a transparent mode for non-programmer users to not only view, stack, and overlay the raw image capture(s) but also do basic photometry and image statistics. The work in progress also involves the study of unsupervised learning to perform clustering analysis of the raw image capture(s). This analysis would group pixels or regions with similar characteristics, uncovering structures such as globular clusters, galaxies, or binary star systems. This process helps discern spatial relationships, identify outliers, and distinguish different celestial objects based on their inherent properties, such as brightness and shape. We are testing our open-source software with image data from a college telescope from Southern Connecticut State University. The telescope is a Spica Eyes Dobsonian reflecting telescope with an aperture size of 0.6m and focal ratio f/3.3. Transfer optics were added to increased our spatial resolution from 1.4 arcsec per pixel to 0.8 arcsec per pixel measurement. The transfer optics used a filter ¦Ë0 = 537nm that optimized quantum efficiency in the V-band. These images were taken July 2018 at Southern Connecticut State University (SCSU) in New Haven, CT where there is high artificial brightness and Bortle scale of 8. These images were taken in poor seeing conditions since the humidity was high due to the typical nature of costal Connecticut in the summer. Furthermore, tracking was not stable leading to target drift across the image plane. Figure 1(a) shows images from this observation session which include 8 frames of 0.05s exposure time with a readout speed of 2MHz of Jupiter. This shows how tracking and poor alignment can lead to images that are not resolved to show the details of Jupiter as seen in Figure 1(b). Stacking is necessary to improve the signal to noise ratio of the images as well as smooth out details. Without sufficient stacking, it will be difficult to distinguish details of the images.",ACM
"Muqeet, Asmar and Ali, Shaukat and Arcaini, Paolo",Quantum Program Testing Through Commuting Pauli Strings on IBM's Quantum Computers,2024,10.1145/3691620.3695275,https://doi.org/10.1145/3691620.3695275,Conference paper,ASE '24: Proceedings of the 39th IEEE/ACM International Conference on Automated Software Engineering,"The most promising applications of quantum computing are centered around solving search and optimization tasks, particularly in fields such as physics simulations, quantum chemistry, and finance. However, the current quantum software testing methods face practical limitations when applied in industrial contexts: (i) they do not apply to quantum programs most relevant to the industry, (ii) they require a full program specification, which is usually not available for these programs, and (iii) they are incompatible with error mitigation methods currently adopted by main industry actors like IBM. To address these challenges, we present QOPS, a novel quantum software testing approach. QOPS introduces a new definition of test cases based on Pauli strings to improve compatibility with different quantum programs. QOPS also introduces a new test oracle that can be directly integrated with industrial APIs such as IBM's Estimator API and can utilize error mitigation methods for testing on real noisy quantum computers. We also leverage the commuting property of Pauli strings to relax the requirement of having complete program specifications, making QOPS practical for testing complex quantum programs in industrial settings. We empirically evaluate QOPS on 194,982 real quantum programs, demonstrating effective performance in test assessment compared to the state-of-the-art with a perfect F1-score, precision, and recall. Furthermore, we validate the industrial applicability of QOPS by assessing its performance on IBM's three real quantum computers, incorporating both industrial and open-source error mitigation methods.",ACM
"Vallero, Marzio and Casagranda, Gioele and Vella, Flavio and Rech, Paolo",On the Efficacy of Surface Codes in Compensating for Radiation Events in Superconducting Devices,2024,10.1109/SC41406.2024.00075,https://doi.org/10.1109/SC41406.2024.00075,Conference paper,"SC '24: Proceedings of the International Conference for High Performance Computing, Networking, Storage, and Analysis","Reliability is fundamental for developing large-scale quantum computers. Since the benefit of technological advancements to the qubit's stability is saturating, algorithmic solutions, such as quantum error correction (QEC) codes, are needed to bridge the gap to reliable computation. Unfortunately, the deployment of the first quantum computers has identified faults induced by natural radiation as an additional threat to qubits reliability. The high sensitivity of qubits to radiation hinders the large-scale adoption of quantum computers, since the persistence and area-of-effect of the fault can potentially undermine the efficacy of the most advanced QEC.In this paper, we investigate the resilience of various implementations of state-of-the-art QEC codes to radiation-induced faults. We report data from over 400 million fault injections and correlate hardware faults with the logical error observed after decoding the code output, extrapolating physical-to-logical error rates. We compare the code's radiation-induced logical error rate over the code distance, the number and role in the QEC of physical qubits, the underlying quantum computer topology, and particle energy spread in the chip. We show that, by simply selecting and tuning properly the surface code, thus without introducing any overhead, the probability of correcting a radiation-induced fault is increased by up to 10%. Finally, we provide indications and guidelines for the design of future QEC codes to further increase their effectiveness against radiation-induced events.",ACM
"Jiang, Hanru",Qubit Recycling Revisited,2024,10.1145/3656428,https://doi.org/10.1145/3656428,Journal,Proc. ACM Program. Lang.,"Reducing the width of quantum circuits is crucial due to limited number of qubits in quantum devices. This paper revisit an optimization strategy known as qubit recycling (alternatively wire-recycling or measurement-and-reset), which leverages gate commutativity to reuse discarded qubits, thereby reducing circuit width. We introduce qubit dependency graphs (QDGs) as a key abstraction for this optimization. With QDG, we isolate the computationally demanding components, and observe that qubit recycling is essentially a matrix triangularization problem. Based on QDG and this observation, we study qubit recycling with a focus on complexity, algorithmic, and verification aspects. Firstly, we establish qubit recycling¡¯s NP-hardness through reduction from Wilf¡¯s question, another matrix triangularization problem. Secondly, we propose a QDG-guided solver featuring multiple heuristic options for effective qubit recycling. Benchmark tests conducted on RevLib illustrate our solver¡¯s superior or comparable performance to existing alternatives. Notably, it achieves optimal solutions for the majority of circuits. Finally, we develop a certified qubit recycler that integrates verification and validation techniques, with its correctness proof mechanized in Coq.",ACM
"Tan, Siwei and Xiang, Debin and Lu, Liqiang and Lu, Junlin and Jiang, Qiuping and Chen, Mingshuai and Yin, Jianwei",MorphQPV: Exploiting Isomorphism in Quantum Programs to Facilitate Confident Verification,2024,10.1145/3620666.3651360,https://doi.org/10.1145/3620666.3651360,Conference paper,"ASPLOS '24: Proceedings of the 29th ACM International Conference on Architectural Support for Programming Languages and Operating Systems, Volume 3","Unlike classical computing, quantum program verification (QPV) is much more challenging due to the non-duplicability of quantum states that collapse after measurement. Prior approaches rely on deductive verification that shows poor scalability. Or they require exhaustive assertions that cannot ensure the program is correct for all inputs. In this paper, we propose MorphQPV, a confident assertion-based verification methodology. Our key insight is to leverage the isomorphism in quantum programs, which implies a structure-preserve relation between the program runtime states. In the assertion statement, we define a tracepoint pragma to label the verified quantum state and an assume-guarantee primitive to specify the expected relation between states. Then, we characterize the ground-truth relation between states using an isomorphism-based approximation, which can effectively obtain the program states under various inputs while avoiding repeated executions. Finally, the verification is formulated as a constraint optimization problem with a confidence estimation model to enable rigorous analysis. Experiments suggest that MorphQPV reduces the number of program executions by 107.9\texttimes{} when verifying the 27-qubit quantum lock algorithm and improves the probability of success by 3.3\texttimes{}-9.9\texttimes{} when debugging five benchmarks.",ACM
"Gemeinhardt, Felix and Garmendia, Antonio and Wimmer, Manuel and Wille, Robert",A Model-Driven Framework for Composition-Based Quantum Circuit Design,2024,10.1145/3688856,https://doi.org/10.1145/3688856,Journal,ACM Transactions on Quantum Computing,"Quantum programming languages support the design of quantum applications. However, to create such programs, one needs to understand the fundamental characteristics of quantum computing and quantum information theory. Furthermore, quantum algorithms frequently make use of abstract operations with a hidden low-level realization (e.g., Quantum Fourier Transform). Thus, turning from elementary quantum operations to a higher-level view of quantum circuit design not only reduces the development effort but also lowers the entry barriers for non-quantum computing experts.To this end, this article proposes a modeling language and design framework for quantum circuits. This allows the definition of composite operators to advocate a higher-level quantum algorithm design, together with automated code generation for the circuit execution. To demonstrate the benefits of the proposed approach, coined Composition-based Quantum Circuit Designer, we applied it for realizing the Quantum Counting algorithm and the Quantum Approximate Optimization Algorithm. Our evaluation results show that, compared to an existing state-of-the-art editor, the proposed approach allows for the realization of both quantum algorithms on a high level with a substantially reduced development effort. In particular, the proposed approach shows constant scaling when increasing the size of the investigated quantum circuits and a lower change criticality when evolving existing quantum circuits.",ACM
"Hao, Tianyi and Liu, Kun and Tannu, Swamit",Enabling High Performance Debugging for Variational Quantum Algorithms using Compressed Sensing,2023,10.1145/3579371.3589044,https://doi.org/10.1145/3579371.3589044,Conference paper,ISCA '23: Proceedings of the 50th Annual International Symposium on Computer Architecture,"Variational quantum algorithms (VQAs) can potentially solve practical problems using contemporary Noisy Intermediate Scale Quantum (NISQ) computers. VQAs find near-optimal solutions in the presence of qubit errors by classically optimizing a loss function computed by parameterized quantum circuits. However, developing and testing VQAs is challenging due to the limited availability of quantum hardware, their high error rates, and the significant overhead of classical simulations. Furthermore, VQA researchers must pick the right initialization for circuit parameters, utilize suitable classical optimizer configurations, and deploy appropriate error mitigation methods. Unfortunately, these tasks are done in an ad-hoc manner today, as there are no software tools to configure and tune the VQA hyperparameters.In this paper, we present OSCAR (cOmpressed Sensing based Cost lAndscape Reconstruction) to help configure: 1) correct initialization, 2) noise mitigation techniques, and 3) classical optimizers to maximize the quality of the solution on NISQ hardware. OSCAR enables efficient debugging and performance tuning by providing users with the loss function landscape without running thousands of quantum circuits as required by the grid search. Using OSCAR, we can accurately reconstruct the complete cost landscape with up to 100X speedup. Furthermore, OSCAR can compute an optimizer function query in an instant by interpolating a computed landscape, thus enabling the trial run of a VQA configuration with considerably reduced overhead.",ACM
"Guan, Ji and Fang, Wang and Huang, Mingyu and Ying, Mingsheng",Detecting Violations of Differential Privacy for Quantum Algorithms,2023,10.1145/3576915.3623108,https://doi.org/10.1145/3576915.3623108,Conference paper,CCS '23: Proceedings of the 2023 ACM SIGSAC Conference on Computer and Communications Security,"Quantum algorithms for solving a wide range of practical problems have been proposed in the last ten years, such as data search and analysis, product recommendation, and credit scoring. The concern about privacy and other ethical issues in quantum computing naturally rises up. In this paper, we define a formal framework for detecting violations of differential privacy for quantum algorithms. A detection algorithm is developed to verify whether a (noisy) quantum algorithm is differentially private and automatically generates bugging information when the violation of differential privacy is reported. The information consists of a pair of quantum states that violate the privacy, to illustrate the cause of the violation. Our algorithm is equipped with Tensor Networks, a highly efficient data structure, and executed both on TensorFlow Quantum and TorchQuantum which are the quantum extensions of famous machine learning platforms - TensorFlow and PyTorch, respectively. The effectiveness and efficiency of our algorithm are confirmed by the experimental results of almost all types of quantum algorithms already implemented on realistic quantum computers, including quantum supremacy algorithms (beyond the capability of classical algorithms), quantum machine learning models, quantum approximate optimization algorithms, and variational quantum eigensolvers with up to 21 quantum bits.",ACM
"Higgott, Oscar",PyMatching: A Python Package for Decoding Quantum Codes with Minimum-Weight Perfect Matching,2022,10.1145/3505637,https://doi.org/10.1145/3505637,Journal,ACM Transactions on Quantum Computing,"This article introduces PyMatching, a fast open-source Python package for decoding quantum error-correcting codes with the minimum-weight perfect matching (MWPM) algorithm. PyMatching includes the standard MWPM decoder as well as a variant, which we call local matching, that restricts each syndrome defect to be matched to another defect within a local neighborhood. The decoding performance of local matching is almost identical to that of the standard MWPM decoder in practice, while reducing the computational complexity. We benchmark the performance of PyMatching, showing that local matching is several orders of magnitude faster than implementations of the full MWPM algorithm using NetworkX or Blossom V for problem sizes typically considered in error correction simulations. PyMatching and its dependencies are open-source, and it can be used to decode any quantum code for which syndrome defects come in pairs using a simple Python interface. PyMatching supports the use of weighted edges, hook errors, boundaries and measurement errors, enabling fast decoding, and simulation of fault-tolerant quantum computing.",ACM
"Xia, Peng and Lu, Gang and Yuan, Bo and Zhao, Qiuli and Liang, Facun",Quantum Genetic Optimization Algorithm for Carbon Reduction Demand Response in Parks Targeting Carbon Quotas,2024,10.1145/3690407.3690537,https://doi.org/10.1145/3690407.3690537,Conference paper,"CAIBDA '24: Proceedings of the 2024 4th International Conference on Artificial Intelligence, Big Data and Algorithms","The allocation of carbon quotas affects the carbon reduction behavior of park enterprises. Enterprises can reduce carbon emissions under the carbon quota system to meet the requirements of carbon quotas and achieve carbon reduction demand response. In order to motivate enterprises to find more cost-effective ways to reduce carbon emissions and promote the diversification of carbon reduction demand response methods, a quantum genetic optimization algorithm for carbon quota oriented park carbon reduction demand response is proposed. From the perspective of load side autonomous response, establish a demand side response thermal and electrical load model for the park, use the benchmark method to allocate carbon quotas for carbon reduction in the park, and set up a carbon reduction trading mechanism. On this basis, with the objective function of minimizing comprehensive cost and coal consumption, constraints are set to construct a carbon reduction model for the park. Quantum genetic optimization algorithm is used to solve the park's carbon reduction model, achieving carbon quota oriented park carbon reduction. The experimental results show that the method proposed in this paper can effectively achieve carbon reduction in industrial parks and has a good effect on carbon reduction in industrial parks.",ACM
"Yuan, Charles and Carbin, Michael",The T-Complexity Costs of Error Correction for Control Flow in Quantum Computation,2024,10.1145/3656397,https://doi.org/10.1145/3656397,Journal,Proc. ACM Program. Lang.,"Numerous quantum algorithms require the use of quantum error correction to overcome the intrinsic unreliability of physical qubits. However, quantum error correction imposes a unique performance bottleneck, known as T-complexity, that can make an implementation of an algorithm as a quantum program run more slowly than on idealized hardware. In this work, we identify that programming abstractions for control flow, such as the quantum if-statement, can introduce polynomial increases in the T-complexity of a program. If not mitigated, this slowdown can diminish the computational advantage of a quantum algorithm. To enable reasoning about the costs of control flow, we present a cost model that a developer can use to accurately analyze the T-complexity of a program under quantum error correction and pinpoint the sources of slowdown. To enable the mitigation of these costs, we present a set of program-level optimizations that a developer can use to rewrite a program to reduce its T-complexity, predict the T-complexity of the optimized program using the cost model, and then compile it to an efficient circuit via a straightforward strategy. We implement the program-level optimizations in Spire, an extension of the Tower quantum compiler. Using a set of 11 benchmark programs that use control flow, we empirically show that the cost model is accurate, and that Spire¡¯s optimizations recover programs that are asymptotically efficient, meaning their runtime T-complexity under error correction is equal to their time complexity on idealized hardware. Our results show that optimizing a program before it is compiled to a circuit can yield better results than compiling the program to an inefficient circuit and then invoking a quantum circuit optimizer found in prior work. For our benchmarks, only 2 of 8 tested quantum circuit optimizers recover circuits with asymptotically efficient T-complexity. Compared to these 2 optimizers, Spire uses 54\texttimes{}¨C2400\texttimes{} less compile time.",ACM
"d'Aloisio, Giordano and Fortz, Sophie and Hanna, Carol and Fortunato, Daniel and Bensoussan, Avner and Mendiluze Usandizaga, E\~{n}aut and Sarro, Federica",Exploring LLM-Driven Explanations for Quantum Algorithms,2024,10.1145/3674805.3690753,https://doi.org/10.1145/3674805.3690753,Conference paper,ESEM '24: Proceedings of the 18th ACM/IEEE International Symposium on Empirical Software Engineering and Measurement,"Background: Quantum computing is a rapidly growing new programming paradigm that brings significant changes to the design and implementation of algorithms. Understanding quantum algorithms requires knowledge of physics and mathematics, which can be challenging for software developers. Aims: In this work, we provide a first analysis of how LLMs can support developers¡¯ understanding of quantum code. Method: We empirically analyse and compare the quality of explanations provided by three widely adopted LLMs (Gpt3.5, Llama2, and Tinyllama) using two different human-written prompt styles for seven state-of-the-art quantum algorithms. We also analyse how consistent LLM explanations are over multiple rounds and how LLMs can improve existing descriptions of quantum algorithms. Results: Llama2 provides the highest quality explanations from scratch, while Gpt3.5 emerged as the LLM best suited to improve existing explanations. In addition, we show that adding a small amount of context to the prompt significantly improves the quality of explanations. Finally, we observe how explanations are qualitatively and syntactically consistent over multiple rounds. Conclusions: This work highlights promising results, and opens challenges for future research in the field of LLMs for quantum code explanation. Future work includes refining the methods through prompt optimisation and parsing of quantum code explanations, as well as carrying out a systematic assessment of the quality of explanations.",ACM
"Jang, Enhyeok and Ha, Dongho and Choi, Seungwoo and Kim, Youngmin and Kwon, Jaewon and Lee, Yongju and Ahn, Sungwoo and Kim, Hyungseok and Ro, Won Woo",Recompiling QAOA Circuits on Various Rotational Directions,2024,10.1145/3656019.3676899,https://doi.org/10.1145/3656019.3676899,Conference paper,PACT '24: Proceedings of the 2024 International Conference on Parallel Architectures and Compilation Techniques,"The quantum approximate optimization algorithm (QAOA) is introduced to efficiently solve combinatorial optimization problems. Despite the promise of QAOA, the cost of executing QAOA circuits at scale for quantum advantage may still be excessive for the near-future quantum device. We observe the increasing overhead of QAOA circuit execution in the native gate translation. To execute QAOA circuits on a real quantum computing device, Hamiltonians composed of predefined specific rotations (e.g., ZZ and X) should be decomposed into finite native gates. By adopting rotational combinations that utilize native gates more directly than the standard QAOA circuit model, the execution cost on real quantum devices can be reduced. In this study, we propose Racoon (Rotational Space Virtualization for QAOA Ansatz), an algorithm-hardware co-design approach that revisits the synthesis conditions of QAOA circuits and selects alternative candidates with different rotational combinations. Our analysis of six commercial quantum processors demonstrates that applying Racoon to QAOA circuits for the 4-node Sherrington-Kirkpatrick model reduces the number of native gates by an average of 23% and up to 79%. Consequently, using Racoon results in 43% fewer training epochs, 41% lower training energy consumption, and a 6% improvement in inference on average compared to standard QAOA. Racoon consistently reduces circuit depth as the number of qubits and layers increases, achieving 123 \texttimes{} more circuit depth reduction compared to the recently proposed Depth First Search (DFS)-based method. Furthermore, we confirm that Racoon¡¯s method can be extended to State-of-The-Art QAOAs with modified ans\""{a}tze and to the variational quantum eigensolver (VQE).",ACM
"Jhaveri, Samyak and Krone-Martins, Alberto and Lopes, Cristina V.",Cloning and Beyond: A Quantum Solution to Duplicate Code,2023,10.1145/3622758.3622889,https://doi.org/10.1145/3622758.3622889,Conference paper,"Onward! 2023: Proceedings of the 2023 ACM SIGPLAN International Symposium on New Ideas, New Paradigms, and Reflections on Programming and Software","Quantum computers are becoming a reality. The advantage of quantum computing is that it has the potential to solve computationally complex problems in a fixed amount time, independent of the size of the problem. However, the kinds of problems for which these computers are a good fit, and the ways to express those problems, are substantially different from the kinds of problems and expressions used in classical computing. Quantum annealers, in particular, are currently the most promising and available quantum computing devices in the short term. However, they are also the most foreign compared to classical programs, as they require a different kind of computational thinking. In order to ease the transition into this new world of quantum computing, we present a novel quantum approach to a well-known software problem: code clone detection. We express code clone detection as a subgraph isomorphism problem that is mapped into a quadratic optimization problem, and solve it using a DWave quantum annealing computer. We developed a quantum annealing algorithm that compares Abstract Syntax Trees (AST) and reports an energy value that indicates how similar they are. The motivation behind this research goes well beyond code duplicate detection: our approach paves the way into how to express software engineering problems as optimization problems that can be solved by quantum annealers.",ACM
"Volpe, Deborah and Cirillo, Giovanni and Zamboni, Maurizio and Graziano, Mariagrazia and Turvani, Giovanna",Improving the exploitability of Simulated Adiabatic Bifurcation through a flexible and open-source digital architecture,2024,10.1145/3665281,https://doi.org/10.1145/3665281,Journal,ACM Transactions on Quantum Computing,"Combinatorial Optimization (CO) problems exhibit exponential complexity, constraining classical computers from providing fast and satisfactory outcomes. Quantum Computers (QCs) can effectively find optimal or near-optimal solutions by exploring the solutions space of a problem encoded in a qubits system, exploiting principles of quantum mechanics. However, non-idealities and high costs limit their availability. These can be overcome by emulating QCs on cheaper and more accessible classical computing platforms, like Field-Programmable Gate Arrays (FPGAs). This article presents a digital architecture, implementing the Ising-compatible Simulated Adiabatic Bifurcation algorithm. It mimics the quantum adiabatic evolution of a network of non-linear Kerr oscillators. The architecture, described in VHDL and targeting FPGAs, consists of processing elements for computing the Kerr oscillators¡¯ evolution, a set of units considering their Ising-related interactions and an evolution variables update unit. The proposed approach includes a speedup-targeting approximation of the algorithm, a method for handling single-variable constraints, and a software model that allows architecture customization for specific problems. Tests were conducted using an Altera Cyclone V SoC with FPGA logic and the Nios II processor for interface purposes. The results demonstrate the functionality of the architecture and its scalability with the problem size, making it suitable for real-world applications.",ACM
"Ammermann, Joshua and Brenneisen, Fabian Jakob and Bittner, Tim and Schaefer, Ina",Quantum Solution for Configuration Selection and Prioritization,2024,10.1145/3643667.3648221,https://doi.org/10.1145/3643667.3648221,Conference paper,Q-SE 2024: Proceedings of the 5th ACM/IEEE International Workshop on Quantum Software Engineering,"The analyses of highly configurable systems, as applied in software or automotive domains, yield hard problems due to the exponentially increasing number of possible product configurations. Current research identified that such combinatorial optimization problems, e.g. configuration selection and prioritization, are ideal targets for expected exponential quantum speedups. However, empirical evidence about the applicability of quantum computing to these problems is still missing. In this paper, we investigate how the constraint satisfaction and optimization problems of configuration selection and prioritization can be addressed using quantum computing. We propose a method to transform the configuration selection and prioritization problems encoded in attributed feature models into a quantum mechanical formulation suitable for optimization problems. We provide a Python library to automatically perform this transformation and apply the Quantum Approximate Optimization Algorithm (QAOA), such that configuration selection and prioritization are solved with quantum computers. Our approach is evaluated regarding feasibility, solution quality, and scalability. We show that QAOA obtains good results regarding configuration selection, but for configuration prioritization, the approach needs further improvement.","ACM, IEEE"
"Hua, Fei and Chen, Yanhao and Jin, Yuwei and Zhang, Chi and Hayes, Ari and Zhang, Youtao and Zhang, Eddy Z.",AutoBraid: A Framework for Enabling Efficient Surface Code Communication in Quantum Computing,2021,10.1145/3466752.3480072,https://doi.org/10.1145/3466752.3480072,Conference paper,MICRO '21: Proceedings of the 54th Annual IEEE/ACM International Symposium on Microarchitecture,"Quantum computers can solve problems that are intractable using the most powerful classical computer. However, qubits are fickle and error prone. It is necessary to actively correct errors in the execution of a quantum circuit. Quantum error correction (QEC) codes are developed to enable fault-tolerant quantum computing. With QEC, one logical circuit is converted into an encoded circuit. Most studies on quantum circuit compilation focus on NISQ devices which have 10-100 qubits and are not fault-tolerant. In this paper, we focus on the compilation for fault-tolerant quantum hardware. In particular, we focus on optimizing communication parallelism for the surface code based QEC. The execution of surface code circuits involves non-trivial geometric manipulation of a large lattice of entangled physical qubits. A two-qubit gate in surface code is implemented as a virtual ¡°pipe¡± in space-time called a braiding path. The braiding paths should be carefully routed to avoid congestion. Communication between qubits is considered the major bottleneck as it involves scheduling and searching for simultaneous paths between qubits. We provide a framework for efficiently scheduling braiding paths. We discover that for quantum programs with a local parallelism pattern, our framework guarantees an optimal solution, while the previous greedy-heuristic-based solution cannot. Moreover, we propose an extension to the local parallelism analysis framework to address the communication bottleneck. Our framework achieves orders of magnitude improvement after addressing the communication bottleneck.",ACM
"Borrelli, Thomas J. and Polak, Monika and Radziszowski, Stanis\l{}aw",Designing and Delivering a Post-Quantum Cryptography Course,2024,10.1145/3626252.3630823,https://doi.org/10.1145/3626252.3630823,Conference paper,SIGCSE 2024: Proceedings of the 55th ACM Technical Symposium on Computer Science Education V. 1,"The security of many commonly used cryptographic protocols, especially public-key cryptosystems, would be compromised if general-purpose, large-scale, fault-tolerant quantum computers become a reality. In this paper we present our experience developing and launching a course in Post-Quantum Cryptography (PQC). PQC refers to cryptographic systems that are secure against both quantum and classical computers. Such systems may be achieved through classical (i.e. non-quantum) means.Because of progress in the design of quantum computers and the ongoing National Institute of Standards and Technology (NIST) process to develop post-quantum cryptographic systems, we realized that there is a need to design a course that covers the consequences of developments in quantum computing (QC),the threats of QC to currently used cryptographic schemes, and how to mitigate those threats by developing quantum-resistant schemes. We designed a new course that is attracting students interested in the future of cryptography and computing security/cybersecurity. We first offered it as an MS-level graduate course, also open to upper-level undergraduates, in Spring 2022, and followed with the second offering in Spring 2023. The course covers the PQC algorithm design process, the consequences of QC, some computationally hard problems and then discusses selected proposals for post-quantum cryptosystems designed to be resistant to known classical and quantum attacks. Three main types of such designs include lattice-based, code-based, and hash-based schemes. These three types are used both for key encapsulation methods (KEM) and digital signatures (DS), and more generally for encryption and authentication.",ACM
"Wang, Xinyi and Arcaini, Paolo and Yue, Tao and Ali, Shaukat",QuSBT: search-based testing of quantum programs,2022,10.1145/3510454.3516839,https://doi.org/10.1145/3510454.3516839,Conference paper,ICSE '22: Proceedings of the ACM/IEEE 44th International Conference on Software Engineering: Companion Proceedings,"Generating a test suite for a quantum program such that it has the maximum number of failing tests is an optimization problem. For such optimization, search-based testing has shown promising results in the context of classical programs. To this end, we present a test generation tool for quantum programs based on a genetic algorithm, called QuSBT (Search-based Testing of Quantum Programs). QuSBT automates the testing of quantum programs, with the aim of finding a test suite having the maximum number of failing test cases. QuSBT utilizes IBM's Qiskit as the simulation framework for quantum programs. We present the tool architecture in addition to the implemented methodology (i.e., the encoding of the search individual, the definition of the fitness function expressing the search problem, and the test assessment w.r.t. two types of failures). Finally, we report results of the experiments in which we tested a set of faulty quantum programs with QuSBT to assess its effectiveness. Repository (code and experimental results): https://github.com/Simula-COMPLEX/qusbt-toolVideo: https://youtu.be/3apRCtluAn4","ACM, IEEE"
"Anand, Christopher Kumar and Gonder, Steven and Dutton, Lucas and O¡¯Farrell, William",Accelerating and Visualizing Modulo Arithmetic using Multiple Radices,2023,10.5555/3615924.3615937,https://dl.acm.org/doi/10.5555/3615924.3615937,Conference paper,CASCON '23: Proceedings of the 33rd Annual International Conference on Computer Science and Software Engineering,"Efficiently implementing modulo arithmetic is a key challenge in ap-plied cryptography. As secure ecommerce, messaging and signing continue to expand, and the footprint of these algorithms grows, the importance of their efficiency also grows. On the other hand, radical new attacks via quantum computing or more incremental weaken-ing through the steady increase in computational resources moti-vate researchers and standardization committees to develop new algorithms. At the heart of most algorithms is arithmetic modulo a prime too big to fit in a machine register. Although multi-limb, in-cluding mixed-radix, algorithms are well known, other researchers continue to discover innovative ways of using new and existing Single-Instruction-Multiple-Data (SIMD) instructions to implement them. In this paper, we will demonstrate a 2.26X improvement over parallel modulo reduction with three limbs as demonstrated by Gadriwala et al. in Bernstein¡¯s Poly1305 hashing algorithm. The improvement comes from a different choice of radices, and a mid-algorithm change of radices to reduce from three limbs to two. Since this one algorithm can be optimized in multiple contexts (e.g., for intermediate or final rounding), it is useful to have tools to help develop such optimizations. The second contribution of this paper is a prototype visualization tool: a visual debugging tool for integer (especially multi-limb) computations. This tool adds place value as type information to every bit in the computation, and uses that information to detect errors and to display the place values through alignment. We have found the tool useful for exploring possible implementations, and with additional inference rules, it could also be used for verification.",ACM
"Kydros, Asimakis and Prousalis, Konstantinos and Konofaos, Nikos",QuaCiDe: A General Purpose Quantum Circuit Design and Simulation Interface,2024,10.1145/3665870.3665874,https://doi.org/10.1145/3665870.3665874,Conference paper,ReAQCT '24: Proceedings of Recent Advances in Quantum Computing and Technology,"A circuit design interface for simulation of quantum circuits is presented. This simple but powerful tool aims to enable and improve experimentation in the field of quantum computing, either for professional or amateur usage. It provides an intuitive, automated, easy-to-use environment for building algorithms using the circuit model of quantum computation, while freeing the experimenter from technical procedures, such as coding or program installations. It provides a wide range of tools to the user, from a universal gate-set, to custom gate definitions, post-selected measurements, complex compositions of sub-circuits in a recursive way, good modularity and nice output results. Moreover, it is combined with popular backend simulators due to its circuit-parsing capabilities.",ACM
"Dias, Adhitha and Anderson, Logan and Sundararajah, Kirshanthan and Pelenitsyn, Artem and Kulkarni, Milind",SparseAuto: An Auto-scheduler for Sparse Tensor Computations using Recursive Loop Nest Restructuring,2024,10.1145/3689730,https://doi.org/10.1145/3689730,Journal,Proc. ACM Program. Lang.,"Automated code generation and performance enhancements for sparse tensor algebra have become essential in many real-world applications, such as quantum computing, physical simulations, computational chemistry, and machine learning. General sparse tensor algebra compilers are not always versatile enough to generate asymptotically optimal code for sparse tensor contractions. This paper shows how to generate asymptotically better schedules for complex sparse tensor expressions using kernel fission and fusion. We present generalized loop restructuring transformations to reduce asymptotic time complexity and memory footprint.Furthermore, we present an auto-scheduler that uses a partially ordered set (poset)-based cost model that uses both time and auxiliary memory complexities to prune the search space of schedules. In addition, we highlight the use of Satisfiability Module Theory (SMT) solvers in sparse auto-schedulers to approximate the Pareto frontier of better schedules to the smallest number of possible schedules, with user-defined constraints available at compile-time. Finally, we show that our auto-scheduler can select better-performing schedules and generate code for them. Our results show that the auto-scheduler provided schedules achieve orders-of-magnitude speedup compared to the code generated by the Tensor Algebra Compiler (TACO) for several computations on different real-world tensors.",ACM
"Sharma, Ritvik and Achour, Sara",Compilation of Qubit Circuits to Optimized Qutrit Circuits,2024,10.1145/3656388,https://doi.org/10.1145/3656388,Journal,Proc. ACM Program. Lang.,"Quantum computers are a revolutionary class of computational platforms that are capable of solving computationally hard problems. However, today¡¯s quantum hardware is subject to noise and decoherence issues that together limit the scale and complexity of the quantum circuits that can be implemented. Recently, practitioners have developed qutrit-based quantum hardware platforms that compute over 0, 1, and 2 states, and have presented circuit depth reduction techniques using qutrits¡¯ higher energy 2 states to temporarily store information. However, thus far, such quantum circuits that use higher order states for temporary storage need to be manually crafted by hardware designers. We present , an optimizing compiler for qutrit circuits that implement qubit computations.  deploys a qutrit circuit decomposition algorithm and a rewrite engine to construct and optimize qutrit circuits. We evaluate  against hand-optimized qutrit circuits and qubit circuits, and find  delivers up to 65% depth improvement over manual qutrit implementations, and 43-75% depth improvement over qubit circuits. We also perform a fidelity analysis and find -optimized qutrit circuits deliver up to 8.9\texttimes{} higher fidelity circuits than their manually implemented counterparts.",ACM
"Goodrich, Timothy D. and Horton, Eric and Sullivan, Blair D.",An Updated Experimental Evaluation of Graph Bipartization Methods,2021,10.1145/3467968,https://doi.org/10.1145/3467968,Journal,ACM J. Exp. Algorithmics,"We experimentally evaluate the practical state-of-the-art in graph bipartization (Odd Cycle Transversal (OCT)), motivated by the need for good algorithms for embedding problems into near-term quantum computing hardware. We assemble a preprocessing suite of fast input reduction routines from the OCT and Vertex Cover (VC) literature and compare algorithm implementations using Quadratic Unconstrained Binary Optimization problems from the quantum literature. We also generate a corpus of frustrated cluster loop graphs, which have previously been used to benchmark quantum annealing hardware. The diversity of these graphs leads to harder OCT instances than in existing benchmarks.In addition to combinatorial branching algorithms for solving OCT directly, we study various reformulations into other NP-hard problems such as VC and Integer Linear Programming (ILP), enabling the use of solvers such as CPLEX. We find that for heuristic solutions with time constraints under a second, iterative compression routines jump-started with a heuristic solution perform best, after which point using a highly tuned solver like CPLEX is worthwhile. Results on exact solvers are split between using ILP formulations on CPLEX and solving VC formulations with a branch-and-reduce solver. We extend our results with a large corpus of synthetic graphs, establishing robustness and potential to generalize to other domain data. In total, over 8,000 graph instances are evaluated, compared to the previous canonical corpus of 100 graphs.Finally, we provide all code and data in an open source suite, including a Python API for accessing reduction routines and branching algorithms, along with scripts for fully replicating our results.",ACM
"Jati, Arpan and Gupta, Naina and Chattopadhyay, Anupam and Sanadhya, Somitra Kumar",A Configurable CRYSTALS-Kyber Hardware Implementation with Side-Channel Protection,2024,10.1145/3587037,https://doi.org/10.1145/3587037,Journal,ACM Trans. Embed. Comput. Syst.,"In this work, we present a configurable and side channel resistant implementation of the post-quantum key-exchange algorithm CRYSTALS-Kyber. The implemented design can be configured for different performance and area requirements leading to different trade-offs for different applications. A low area implementation can be achieved in 5,269 LUTs and 2,422 FFs, whereas a high performance implementation required 7,151 LUTs and 3,730 FFs. Due to a deeply pipelined architecture, a high operating speed of more than 250 MHz could be achieved on 28nm Xilinx FPGAs. The side channel resistance is implemented using a carefully chosen set of novel and known techniques such as Fault Detection Hashes, Instruction Randomization, FSM Protection and so on. resulting in a low overhead of less than 5% while being highly configurable. To the best of our knowledge, this work presents the first side-channel and fault attack protected configurable accelerator for CRYSTALS-Kyber. Using TVLA (test vector leakage assessment), we validate the implemented protection techniques and demonstrate that the design does not leak information even after 200 K traces. Furthermore, one of the configuration choices results in the smallest hardware implementation of CRYSTALS-Kyber known in the literature.",ACM
"Fan, Hongxiang and Guo, Ce and Luk, Wayne",Optimizing quantum circuit placement via machine learning,2022,10.1145/3489517.3530403,https://doi.org/10.1145/3489517.3530403,Conference paper,DAC '22: Proceedings of the 59th ACM/IEEE Design Automation Conference,"Quantum circuit placement (QCP) is the process of mapping the synthesized logical quantum programs on physical quantum machines, which introduces additional SWAP gates and affects the performance of quantum circuits. Nevertheless, determining the minimal number of SWAP gates has been demonstrated to be an NP-complete problem. Various heuristic approaches have been proposed to address QCP, but they suffer from suboptimality due to the lack of exploration. Although exact approaches can achieve higher optimality, they are not scalable for large quantum circuits due to the massive design space and expensive runtime. By formulating QCP as a bilevel optimization problem, this paper proposes a novel machine learning (ML)-based framework to tackle this challenge. To address the lower-level combinatorial optimization problem, we adopt a policy-based deep reinforcement learning (DRL) algorithm with knowledge transfer to enable the generalization ability of our framework. An evolutionary algorithm is then deployed to solve the upper-level discrete search problem, which optimizes the initial mapping with a lower SWAP cost. The proposed ML-based approach provides a new paradigm to overcome the drawbacks in both traditional heuristic and exact approaches while enabling the exploration of optimality-runtime trade-off. Compared with the leading heuristic approaches, our ML-based method significantly reduces the SWAP cost by up to 100%. In comparison with the leading exact search, our proposed algorithm achieves the same level of optimality while reducing the runtime cost by up to 40 times.",ACM
"Abdulla, Parosh Aziz and Chen, Yo-Ga and Chen, Yu-Fang and Hol\'{\i}k, Luk\'{a}\v{s} and Leng\'{a}l, Ond\v{r}ej and Lin, Jyun-Ao and Lo, Fang-Yi and Tsai, Wei-Lun",Verifying Quantum Circuits with Level-Synchronized Tree Automata,2025,10.1145/3704868,https://doi.org/10.1145/3704868,Journal,Proc. ACM Program. Lang.,"We present a new method for the verification of quantum circuits based on a novel symbolic representation of sets of quantum states using level-synchronized tree automata (LSTAs). LSTAs extend classical tree automata by labeling each transition with a set of choices, which are then used to synchronize subtrees of an accepted tree. Compared to the traditional tree automata, LSTAs have an incomparable expressive power while maintaining important properties, such as closure under union and intersection, and decidable language emptiness and inclusion. We have developed an efficient and fully automated symbolic verification algorithm for quantum circuits based on LSTAs. The complexity of supported gate operations is at most quadratic, dramatically improving the exponential worst-case complexity of an earlier tree automata-based approach. Furthermore, we show that LSTAs are a promising model for parameterized verification, i.e., verifying the correctness of families of circuits with the same structure for any number of qubits involved, which principally lies beyond the capabilities of previous automated approaches. We implemented this method as a C++ tool and compared it with three symbolic quantum circuit verifiers and two simulators on several benchmark examples. The results show that our approach can solve problems with sizes orders of magnitude larger than the state of the art.",ACM
"Wang, Meng and Fang, Bo and Li, Ang and Nair, Prashant J.",Red-QAOA: Efficient Variational Optimization through Circuit Reduction,2024,10.1145/3620665.3640363,https://doi.org/10.1145/3620665.3640363,Conference paper,"ASPLOS '24: Proceedings of the 29th ACM International Conference on Architectural Support for Programming Languages and Operating Systems, Volume 2","The Quantum Approximate Optimization Algorithm (QAOA) addresses combinatorial optimization challenges by converting inputs to graphs. However, the optimal parameter searching process of QAOA is greatly affected by noise. Larger problems yield bigger graphs, requiring more qubits and making their outcomes highly noise-sensitive. This paper introduces Red-QAOA, leveraging energy landscape concentration via a simulated annealing-based graph reduction.Red-QAOA creates a smaller (distilled) graph with nearly identical parameters to the original graph. The distilled graph produces a smaller quantum circuit and thus reduces noise impact. At the end of the optimization, Red-QAOA employs the parameters from the distilled graph on the original graph and continues the parameter search on the original graph. Red-QAOA outperforms state-of-the-art Graph Neural Network (GNN)-based pooling techniques on 3200 real-world problems. Red-QAOA reduced node and edge counts by 28% and 37%, respectively, with a mean square error of only 2%.",ACM
"Stein, Samuel and Sussman, Sara and Tomesh, Teague and Guinn, Charles and Tureci, Esin and Lin, Sophia Fuhui and Tang, Wei and Ang, James and Chakram, Srivatsan and Li, Ang and Martonosi, Margaret and Chong, Fred and Houck, Andrew A. and Chuang, Isaac L. and Demarco, Michael",HetArch: Heterogeneous Microarchitectures for Superconducting Quantum Systems,2023,10.1145/3613424.3614300,https://doi.org/10.1145/3613424.3614300,Conference paper,MICRO '23: Proceedings of the 56th Annual IEEE/ACM International Symposium on Microarchitecture,"Noisy Intermediate-Scale Quantum Computing (NISQ) has dominated headlines in recent years, with the longer-term vision of Fault-Tolerant Quantum Computation (FTQC) offering significant potential albeit at currently intractable resource costs and quantum error correction (QEC) overheads. For problems of interest, FTQC will require millions of physical qubits with long coherence times, high-fidelity gates, and compact sizes to surpass classical systems. Just as heterogeneous specialization has offered scaling benefits in classical computing, it is likewise gaining interest in FTQC. However, systematic use of heterogeneity in either hardware or software elements of FTQC systems remains a serious challenge due to the vast design space and variable physical constraints. This paper meets the challenge of making heterogeneous FTQC design practical by introducing HetArch, a toolbox for designing heterogeneous quantum systems, and using it to explore heterogeneous design scenarios. Using a hierarchical approach, we successively break quantum algorithms into smaller operations (akin to classical application kernels), thus greatly simplifying the design space and resulting tradeoffs. Specializing to superconducting systems, we then design optimized heterogeneous hardware composed of varied superconducting devices, abstracting physical constraints into design rules that enable devices to be assembled into standard cells optimized for specific operations. Finally, we provide a heterogeneous design space exploration framework which reduces the simulation burden by a factor of 104 or more and allows us to characterize optimal design points. We use these techniques to design superconducting quantum modules for entanglement distillation, error correction, and code teleportation, reducing error rates by 2.6 \texttimes{",ACM
"Kundu, Suparna and Norga, Quinten and Karmakar, Angshuman and Gangopadhyay, Shreya and Bermudo Mera, Jose Maria and Verbauwhede, Ingrid",Scabbard: An Exploratory Study on Hardware Aware Design Choices of Learning with Rounding-based Key Encapsulation Mechanisms,2024,10.1145/3696208,https://doi.org/10.1145/3696208,Journal,ACM Trans. Embed. Comput. Syst.,"Recently, the construction of cryptographic schemes based on hard lattice problems has gained immense popularity. Apart from being quantum resistant, lattice-based cryptography allows a wide range of variations in the underlying hard problem. As cryptographic schemes can work in different environments under different operational constraints such as memory footprint, silicon area, efficiency, power requirement, and so on, such variations in the underlying hard problem are very useful for designers to construct different cryptographic schemes. In this work, we explore various design choices of lattice-based cryptography and their impact on performance in the real world. In particular, we propose a suite of key-encapsulation mechanisms based on the learning with rounding problem with a focus on improving different performance aspects of lattice-based cryptography. Our suite consists of three schemes. Our first scheme is Florete, which is designed for efficiency. The second scheme is Espada, which is aimed at improving parallelization, flexibility, and memory footprint. The last scheme is Sable, which can be considered an improved version in terms of key sizes and parameters of the Saber key-encapsulation mechanism, one of the finalists in the National Institute of Standards and Technology¡¯s post-quantum standardization procedure. In this work, we have described our design rationale behind each scheme.Furthermore, to demonstrate the justification of our design decisions, we have provided software and hardware implementations. Our results show Florete is faster than most state-of-the-art KEMs on software platforms. For example, the key-generation algorithm of high-security version Florete outperforms the National Institute of Standards and Technology¡¯s standard Kyber by 47%, the Federal Office for Information Security¡¯s standard Frodo by 99%, and Saber by 57% on the ARM Cortex-M4 platform. Similarly, in hardware, Florete outperforms Frodo and NTRU Prime for all KEM operations. The scheme Espada requires less memory and area than the implementation of most state-of-the-art schemes. For example, the encapsulation algorithm of high-security version Espada uses 30% less stack memory than Kyber, 57% less stack memory than Frodo, and 67% less stack memory than Saber on the ARM Cortex-M4 platform. The implementations of Sable maintain a tradeoff between Florete and Espada regarding software performance and memory requirements. Sable outperforms Saber at least by 6% and Frodo by 99%. Through an efficient polynomial multiplier design, which exploits the small secret size, Sable outperforms most state-of-the-art KEMs, including Saber, Frodo, and NTRU Prime. The implementations of Sable that use number theoretic transform-based polynomial multiplication (SableNTT) surpass all the state-of-the-art schemes in performance, which are optimized for speed on the Cortext M4 platform. The performance benefit of SableNTT against Kyber lies in between 7-29%, 2-13% for Saber, and around 99% for Frodo.",ACM
"Wei, Xinliang and Fan, Lei and Guo, Yuanxiong and Han, Zhu and Wang, Yu",Entanglement From Sky: Optimizing Satellite-Based Entanglement Distribution for Quantum Networks,2024,10.1109/TNET.2024.3456789,https://doi.org/10.1109/TNET.2024.3456789,Journal,IEEE/ACM Trans. Netw.,"The advancement of satellite-based quantum networks shows promise in transforming global communication infrastructure by establishing a secure and reliable quantum Internet. These networks use optical signals from satellites to ground stations to distribute high-fidelity quantum entanglements over long distances, overcoming the limitations of traditional terrestrial systems. However, the complexity of satellite-based entanglement distribution and terrestrial quantum swapping in the integrated network requires joint optimization with satellite assignment, resource allocation, and path selection. To address this challenge, we introduce a hybrid quantum-classical algorithm to solve the optimization problem by leveraging the strengths of both quantum and classical computing. The original problem is decomposed into a master problem and several subproblems using Dantzig-Wolfe decomposition and linearization techniques. Through experiments, this study demonstrates the effectiveness and reliability of the proposed methods in optimizing large-scale networks and managing qubit usage compared to the classical optimization techniques. The findings provide valuable insights for designing and implementing satellite-based entanglement distribution in quantum networks, paving the way for a secure global quantum communication infrastructure.",ACM
"Karl, Patrick and Schupp, Jonas and Fritzmann, Tim and Sigl, Georg",Post-Quantum Signatures on RISC-V with Hardware Acceleration,2024,10.1145/3579092,https://doi.org/10.1145/3579092,Journal,ACM Trans. Embed. Comput. Syst.,"CRYSTALS-Dilithium and Falcon are digital signature algorithms based on cryptographic lattices, which are considered secure even if large-scale quantum computers will be able to break conventional public-key cryptography. Both schemes have been selected for standardization in the NIST Post-Quantum competition. In this work, we present a RISC-V HW/SW codesign that aims to combine the advantages of software and hardware implementations, i.e., flexibility and performance. It shows the use of flexible hardware accelerators, which have been previously used for Public-Key Encryption (PKE) and Key-Encapsulation Mechanism (KEM), for Post-Quantum signatures. It is optimized for Dilithium as a generic signature scheme but also accelerates applications that require fast verification of Falcon¡¯s compact signatures. We provide a comparison with previous works showing that for Dilithium and Falcon, cycle counts are significantly reduced, such that our design is faster than previous software implementations or other HW/SW codesigns. In addition to that, we present a compact Globalfoundries 22nm ASIC design that runs at 800 MHz. By using hardware acceleration, energy consumption for Dilithium is reduced by up to 92.2%, and up to 67.5% for Falcon¡¯s signature verification.","ACM, Web of Science"
"Xu, Amanda and Molavi, Abtin and Pick, Lauren and Tannu, Swamit and Albarghouthi, Aws",Synthesizing Quantum-Circuit Optimizers,2023,10.1145/3591254,https://doi.org/10.1145/3591254,Journal,Proc. ACM Program. Lang.,"Near-term quantum computers are expected to work in an environment where each operation is noisy, with no error correction. Therefore, quantum-circuit optimizers are applied to minimize the number of noisy operations. Today, physicists are constantly experimenting with novel devices and architectures. For every new physical substrate and for every modification of a quantum computer, we need to modify or rewrite major pieces of the optimizer to run successful experiments. In this paper, we present QUESO, an efficient approach for automatically synthesizing a quantum-circuit optimizer for a given quantum device. For instance, in 1.2 minutes, QUESO can synthesize an optimizer with high-probability correctness guarantees for IBM computers that significantly outperforms leading compilers, such as IBM's Qiskit and TKET, on the majority (85%) of the circuits in a diverse benchmark suite.A number of theoretical and algorithmic insights underlie QUESO: (1) An algebraic approach for representing rewrite rules and their semantics. This facilitates reasoning about complex symbolic rewrite rules that are beyond the scope of existing techniques. (2) A fast approach for probabilistically verifying equivalence of quantum circuits by reducing the problem to a special form of polynomial identity testing. (3) A novel probabilistic data structure, called a polynomial identity filter (PIF), for efficiently synthesizing rewrite rules. (4) A beam-search-based algorithm that efficiently applies the synthesized symbolic rewrite rules to optimize quantum circuits.",ACM
"Huang, Keli and Palsberg, Jens",Compiling Conditional Quantum Gates without Using Helper Qubits,2024,10.1145/3656436,https://doi.org/10.1145/3656436,Journal,Proc. ACM Program. Lang.,"We present a compilation scheme for conditional quantum gates. Our scheme compiles a multi-qubit conditional to a linear number of two-qubit conditionals. This can be done straightforwardly with helper qubits, but we show how to do it without using helper qubits and with much fewer gates than in previous work. Specifically, our scheme requires 1/3 as many gates as the previous best scheme without using helper qubits, which is essential for practical use. Our experiments show that several quantum-circuit optimizers have little impact on the compiled code from the previous best scheme, confirming the need for our new scheme. Our experiments with Grover's algorithm and quantum walk also show that our scheme has a major impact on the reliability of the compiled code.",ACM
"Smith, Ethan and Davis, Marc Grau and Larson, Jeffrey and Younis, Ed and Oftelie, Lindsay Bassman and Lavrijsen, Wim and Iancu, Costin",LEAP: Scaling Numerical Optimization Based Synthesis Using an Incremental Approach,2023,10.1145/3548693,https://doi.org/10.1145/3548693,Journal,ACM Transactions on Quantum Computing,"While showing great promise, circuit synthesis techniques that combine numerical optimization with search over circuit structures face scalability challenges due to a large number of parameters, exponential search spaces, and complex objective functions. The LEAP algorithm improves scaling across these dimensions using iterative circuit synthesis, incremental reoptimization, dimensionality reduction, and improved numerical optimization. LEAP draws on the design of the optimal synthesis algorithm QSearch by extending it with an incremental approach to determine constant prefix solutions for a circuit. By narrowing the search space, LEAP improves scalability from four to six qubit circuits. LEAP was evaluated with known quantum circuits such as QFT and physical simulation circuits like the VQE, TFIM, and QITE. LEAP can compile four qubit unitaries up to 59\texttimes{} faster than QSearch and five and six qubit unitaries with up to 1.2\texttimes{} fewer CNOTs compared to the QFAST package. LEAP can reduce the CNOT count by up to 36\texttimes{",ACM
"Li, Ang and Stein, Samuel and Krishnamoorthy, Sriram and Ang, James",QASMBench: A Low-Level Quantum Benchmark Suite for NISQ Evaluation and Simulation,2023,10.1145/3550488,https://doi.org/10.1145/3550488,Journal,ACM Transactions on Quantum Computing,"The rapid development of quantum computing (QC) in the NISQ era urgently demands a low-level benchmark suite and insightful evaluation metrics for characterizing the properties of prototype NISQ devices, the efficiency of QC programming compilers, schedulers and assemblers, and the capability of quantum system simulators in a classical computer. In this work, we fill this gap by proposing a low-level, easy-to-use benchmark suite called QASMBench based on the OpenQASM assembly representation. It consolidates commonly used quantum routines and kernels from a variety of domains including chemistry, simulation, linear algebra, searching, optimization, arithmetic, machine learning, fault tolerance, cryptography, and so on, trading-off between generality and usability. To analyze these kernels in terms of NISQ device execution, in addition to circuit width and depth, we propose four circuit metrics including gate density, retention lifespan, measurement density, and entanglement variance, to extract more insights about the execution efficiency, the susceptibility to NISQ error, and the potential gain from machine-specific optimizations. Applications in QASMBench can be launched and verified on several NISQ platforms, including IBM-Q, Rigetti, IonQ and Quantinuum. For evaluation, we measure the execution fidelity of a subset of QASMBench applications on 12 IBM-Q machines through density matrix state tomography, comprising 25K circuit evaluations. We also compare the fidelity of executions among the IBM-Q machines, the IonQ QPU and the Rigetti Aspen M-1 system. QASMBench is released at: .",ACM
"Xu, Yingte and Barthe, Gilles and Zhou, Li",Automating Equational Proofs in Dirac Notation,2025,10.1145/3704878,https://doi.org/10.1145/3704878,Journal,Proc. ACM Program. Lang.,"Dirac notation is widely used in quantum physics and quantum programming languages to define, compute and reason about quantum states. This paper considers Dirac notation from the perspective of automated reasoning. We prove two main results: first, the first-order theory of Dirac notation is decidable, by a reduction to the theory of real closed fields and Tarski's theorem. Then, we prove that validity of equations can be decided efficiently, using term-rewriting techniques. We implement our equivalence checking algorithm in Mathematica, and showcase its efficiency across more than 100 examples from the literature.",ACM
"Li, Fang and Liu, Xin and Liu, Yong and Zhao, Pengpeng and Yang, Yuling and Shang, Honghui and Sun, Weizhe and Wang, Zhen and Dong, Enming and Chen, Dexun",SW_Qsim: a minimize-memory quantum simulator with high-performance on a new Sunway supercomputer,2021,10.1145/3458817.3476161,https://doi.org/10.1145/3458817.3476161,Conference paper,"SC '21: Proceedings of the International Conference for High Performance Computing, Networking, Storage and Analysis","Classical simulation of quantum computation plays a critical role in numerical studies of quantum algorithms and the validation of quantum devices. Here, we introduce SW_Qsim, a tensor-network-based quantum simulator, which is designed with a two-level parallel structure for efficient implementation on the many-core New Sunway Supercomputer. We propose a minimize-memory contraction path algorithm for rectangular quantum grids to reduce the memory overhead, and provide the memory-limited simulation capacity of SW26010pro. Moreover, tensor operations are carefully optimized on the SW processor to achieve high performance. We design a fault tolerance mechanism to improve the extreme-scale parallel stability. We benchmark SW_Qsim's simulation of RQCs up to 400-qubits, achieving near-linear strong and weak scaling with up to 28.75 million cores, far beyond the previous state of the art. Our work sheds light on the development of efficient quantum algorithms for use in the physical, chemical, and engineering science fields.","ACM, IEEE"
"Christiansen, L\ae{}rke Vinther and Bharosa, Nitesh and Janssen, Marijn",Policy guidelines to facilitate collective action towards quantum-safety: Recommended policy guidelines to aid and facilitate collective action in migration towards quantum-safe public key infrastructure systems,2023,10.1145/3598469.3598480,https://doi.org/10.1145/3598469.3598480,Conference paper,dg.o '23: Proceedings of the 24th Annual International Conference on Digital Government Research,"As the development of quantum computers advances, actors relying on public key infrastructures (PKI) for secure information exchange are becoming aware of the disruptive implications. Currently, governments and businesses employ PKI for many core processes that may become insecure or unavailable when quantum computers break the cryptographic algorithms foundational to PKI. While standardization institutes are currently testing quantum safe cryptographic algorithms, there are no globally agreed-upon cryptographic solutions available. Actors looking to prepare for the implementation of quantum safe cryptographic algorithms lack methods that allow for collective planning and action across organizations, sectors, and nations. The goal of this policy paper is to elicit requirements for a serious game on QS PKI, and derive policy guidelines that actors can use to prepare and formulate governance arrangements. We followed a two-step approach, drawing on technology threat avoidance theory and collective action theory, followed by empirical grounding through a focus group. The results from the literature confirm that a serious game could be a suitable governance mechanism for QS PKI. The focus group results discussed 12 requirements and the requirement's relation to the theoretical background. From this, the findings section arrived at four policy guidelines derived from the requirements that can function as focus areas for further requirement development and as input for policy makers. The policy guidelines concluded are (1) prioritize increasing collective awareness through emphasizing social networks, (2) acknowledge the interdependencies in migrating towards QS PKI, (3) create an understanding of the technical standards in the field and their issuers, and (4) being highly realistic with both negative and positive scenarios to center the players¡¯ understanding of real-world impact.",ACM
"Gan, Weimin and Li, Jianhui",Research on Genetic Quantum Particle Swarm Optimization Fusion Algorithm in Virtual Machine Scheduling,2024,10.1145/3691720.3691744,https://doi.org/10.1145/3691720.3691744,Conference paper,EKI '24: Proceedings of the 2nd International Conference on Educational Knowledge and Informatization,"With the rapid development of cloud computing technology, virtual machine scheduling has become an important means to ensure the performance, efficiency, and reliability of cloud services. In response to the shortcomings of traditional virtual machine scheduling algorithms in optimization efficiency and global search ability, this paper proposes a virtual machine scheduling method based on genetic quantum particle swarm fusion algorithm. This algorithm improves the convergence speed and solution quality of the algorithm by introducing mechanisms such as quantum particle swarm optimization and genetic algorithm. The experimental results show that the algorithm achieves precise and efficient virtual machine scheduling, optimizing resource mapping from virtual machines to physical hosts.",ACM
"Gogeissl, Martin and Safi, Hila and Mauerer, Wolfgang",Quantum Data Encoding Patterns and their Consequences,2024,10.1145/3665225.3665446,https://doi.org/10.1145/3665225.3665446,Conference paper,Q-Data '24: Proceedings of the 1st Workshop on Quantum Computing and Quantum-Inspired Technology for Data-Intensive Systems and Applications,"The use of quantum processing units (QPUs) promises speed-ups for solving computational problems, in particular for discrete optimisation. While a few groundbreaking algorithmic approaches are known that can provably outperform classical computers, we observe a scarcity of programming abstractions for constructing efficient quantum algorithms. A good fraction of the literature that addresses solving concrete problems related to database management concentrates on casting them as quadratic unconstrained binary optimisation problems (QUBOs), which can then, among others, be processed on gate-based machines (using the quantum approximate optimisation algorithm), or quantum annealers. A critical aspect that affects efficiency and scalability of either of these approaches is how classical data are loaded into qubits, respectively how problems are encoded into QUBO representation. The effectiveness of encodings is known to be of crucial importance for quantum computers, especially since the amount of available qubits is strongly limited in the era of noisy, intermediate-size quantum computers. In this paper, we present three encoding patterns, discuss their impact on scalability, and their ease of use. We consider the recreational (yet computationally challenging) Sudoku problem and its reduction to graph colouring as an illustrative example to discuss their individual benefits and disadvantages. Our aim is enable database researchers to choose an appropriate encoding scheme for their purpose without having to acquire in-depth knowledge on quantum peculiarities, thus easing the path towards applying quantum acceleration on data management systems.",ACM
"Khammassi, N. and Ashraf, I. and Someren, J. V. and Nane, R. and Krol, A. M. and Rol, M. A. and Lao, L. and Bertels, K. and Almudever, C. G.",OpenQL: A Portable Quantum Programming Framework for Quantum Accelerators,2021,10.1145/3474222,https://doi.org/10.1145/3474222,Journal,J. Emerg. Technol. Comput. Syst.,"With the potential of quantum algorithms to solve intractable classical problems, quantum computing is rapidly evolving, and more algorithms are being developed and optimized. Expressing these quantum algorithms using a high-level language and making them executable on a quantum processor while abstracting away hardware details is a challenging task. First, a quantum programming language should provide an intuitive programming interface to describe those algorithms. Then a compiler has to transform the program into a quantum circuit, optimize it, and map it to the target quantum processor respecting the hardware constraints such as the supported quantum operations, the qubit connectivity, and the control electronics limitations. In this article, we propose a quantum programming framework named OpenQL, which includes a high-level quantum programming language and its associated quantum compiler. We present the programming interface of OpenQL, we describe the different layers of the compiler and how we can provide portability over different qubit technologies. Our experiments show that OpenQL allows the execution of the same high-level algorithm on two different qubit technologies, namely superconducting qubits and Si-Spin qubits. Besides the executable code, OpenQL also produces an intermediate quantum assembly code, which is technology independent and can be simulated using the QX simulator.",ACM
"Xu, Ming and Fu, Jianling and Jiang, Hui and Deng, Yuxin and Li, Zhi-Bin",Termination and Universal Termination Problems for Nondeterministic Quantum Programs,2024,10.1145/3691632,https://doi.org/10.1145/3691632,Journal,ACM Trans. Softw. Eng. Methodol.,"Verifying quantum programs has attracted a lot of interest in recent years. In this article, we consider the following two categories of termination problems of quantum programs with nondeterminism, namely:(1)(termination) Is an input of a program terminating with probability one under all schedulers? If not, how can a scheduler be synthesized to evidence the nontermination?(2)(universal termination) Are all inputs terminating with probability one under their respective schedulers? If yes, a further question asks whether there is a scheduler that forces all inputs to be terminating with probability one together with how to synthesize it; otherwise, how can an input be provided to refute the universal termination?For the effective verification of the first category, we over-approximate the reachable set of quantum program states by the reachable subspace, whose algebraic structure is a linear space. On the other hand, we study the set of divergent states from which the program terminates with probability zero under some scheduler. The divergent set also has an explicit algebraic structure. Exploiting these explicit algebraic structures, we address the decision problem by a necessary and sufficient condition, i.e., the disjointness of the reachable subspace and the divergent set. Furthermore, the scheduler synthesis is completed in exponential time, whose bottleneck lies in computing the divergent set reported for the first time.For the second category, we reduce the decision problem to the existence of an invariant subspace, from which the program terminates with probability zero under all schedulers. The invariant subspace is characterized by linear equations and thus can be efficiently computed. The states on that invariant subspace are evidence of the nontermination. Furthermore, the scheduler synthesis is completed by seeking a pattern of finite schedulers that forces all inputs to be terminating with positive probability. The repetition of that pattern yields the desired universal scheduler that forces all inputs to be terminating with probability one. All the problems in the second category are shown, also for the first time, to be solved in polynomial time. Finally, we demonstrate the aforementioned methods via a running example¡ªthe quantum Bernoulli factory protocol.",ACM
"Casanova-Marqu\'{e}s, Ra\'{u}l and Dzurenda, Petr and Hajny, Jan",Implementation of Revocable Keyed-Verification Anonymous Credentials on Java Card,2022,10.1145/3538969.3543798,https://doi.org/10.1145/3538969.3543798,Conference paper,"ARES '22: Proceedings of the 17th International Conference on Availability, Reliability and Security","Java Card stands out as a good choice for the development of smart card applications due to the high interoperability between different manufacturers, its security, and wide support of cryptographic algorithms. Despite extensive cryptographic support, current Java Cards do not support non-standard cryptographic algorithms such as post-quantum, secure-multiparty computations, and privacy-enhancing cryptographic schemes. Moreover, Java Card is restricted by the Application Programming Interface (API) in algebraic operations, which are the foundation of modern cryptographic schemes. This paper addresses the issue of developing these modern schemes by exploiting the limited cryptographic API provided by these types of cards. We show how to (ab)use the Java Card¡¯s API to perform modular arithmetic operations, as well as basic operations on elliptic curves. Furthermore, we implement an attribute-based privacy-enhancing scheme on an off-the-shelf Java Card. To do so, we use our cryptographic API and several optimization techniques to make the scheme as efficient as possible. To demonstrate the practicality of our solution, we present the implementation results and benchmark tests.",ACM
"Ren, Jiawei and Sui, Yulei and Cheng, Xiao and Feng, Yuan and Zhao, Jianjun",Dynamic Transitive Closure-based Static Analysis through the Lens of Quantum Search,2024,10.1145/3644389,https://doi.org/10.1145/3644389,Journal,ACM Trans. Softw. Eng. Methodol.,"Many existing static analysis algorithms suffer from cubic bottlenecks because of the need to compute a dynamic transitive closure (DTC). For the first time, this article studies the quantum speedups on searching subtasks in DTC-based static analysis algorithms using quantum search (e.g., Grover¡¯s algorithm). We first introduce our oracle implementation in Grover¡¯s algorithm for DTC-based static analysis and illustrate our quantum search subroutine. Then, we take two typical DTC-based analysis algorithms: context-free-language reachability and set constraint-based analysis, and show that our quantum approach can reduce the time complexity of these two algorithms to truly subcubic ( (O(N^2sqrt {N}{it polylog}(N))) ), yielding better results than the upper bound (O(N3/log N)) of existing classical algorithms. Finally, we conducted a classical simulation of Grover¡¯s search to validate our theoretical approach, due to the current quantum hardware limitation of lacking a practical, large-scale, noise-free quantum machine. We evaluated the correctness and efficiency of our approach using IBM Qiskit on nine open-source projects and randomly generated edge-labeled graphs/constraints. The results demonstrate the effectiveness of our approach and shed light on the promising direction of applying quantum algorithms to address the general challenges in static analysis.",ACM
"Feng, Yuan and Xu, Yingte",Verification of Nondeterministic Quantum Programs,2023,10.1145/3582016.3582039,https://doi.org/10.1145/3582016.3582039,Conference paper,"ASPLOS 2023: Proceedings of the 28th ACM International Conference on Architectural Support for Programming Languages and Operating Systems, Volume 3","Nondeterministic choice is a useful program construct that provides a way to describe the behaviour of a program without specifying the details of possible implementations. It supports the stepwise refinement of programs, a method that has proven useful in software development. Nondeterminism has also been introduced in quantum programming, and termination of nondeterministic quantum programs has been extensively analysed. In this paper, we go beyond termination analysis to investigate the verification of nondeterministic quantum programs where properties are given by sets of hermitian operators on the associated Hilbert space. Hoare-type logic systems for partial and total correctness are proposed which turn out to be both sound and relatively complete with respect to their corresponding semantic correctness. To show the utility of these proof systems, we analyse some quantum algorithms such as quantum error correction scheme, Deutsch algorithm, and a nondeterministic quantum walk. Finally, a proof assistant prototype is implemented to aid in the automated reasoning of nondeterministic quantum programs.",ACM
"Park, Sunghye and Kim, Dohun and Sim, Jae-Yoon and Kang, Seokhyeong",MCQA: Multi-Constraint Qubit Allocation for Near-FTQC Device,2022,10.1145/3508352.3549462,https://doi.org/10.1145/3508352.3549462,Conference paper,ICCAD '22: Proceedings of the 41st IEEE/ACM International Conference on Computer-Aided Design,"In response to the rapid development of quantum processors, quantum software must be advanced by considering the actual hardware limitations. Among the various design automation problems in quantum computing, qubit allocation modifies the input circuit to match the hardware topology constraints. In this work, we present an effective heuristic approach for qubit allocation that considers not only the hardware topology but also other constraints for near-fault-tolerant quantum computing (near-FTQC). We propose a practical methodology to find an effective initial mapping to reduce both the number of gates and circuit latency. We then perform dynamic scheduling to maximize the number of gates executed in parallel in the main mapping phase. Our experimental results with a Surface-17 processor confirmed a substantial reduction in the number of gates, latency, and runtime by 58%, 28%, and 99%, respectively, compared with the previous method [18]. Moreover, our mapping method is scalable and has a linear time complexity with respect to the number of gates.","ACM, IEEE"
"Anagolum, Sashwat and Alavisamani, Narges and Das, Poulami and Qureshi, Moinuddin and Shi, Yunong",Elivagar: Efficient Quantum Circuit Search for Classification,2024,10.1145/3620665.3640354,https://doi.org/10.1145/3620665.3640354,Conference paper,"ASPLOS '24: Proceedings of the 29th ACM International Conference on Architectural Support for Programming Languages and Operating Systems, Volume 2","Designing performant and noise-robust circuits for Quantum Machine Learning (QML) is challenging --- the design space scales exponentially with circuit size, and there are few well-supported guiding principles for QML circuit design. Although recent Quantum Circuit Search (QCS) methods attempt to search for such circuits, they directly adopt designs from classical Neural Architecture Search (NAS) that are misaligned with the unique constraints of quantum hardware, resulting in high search overheads and severe performance bottlenecks.We present \'{E}liv\'{a}gar, a novel resource-efficient, noise-guided QCS framework. \'{E}liv\'{a}gar innovates in all three major aspects of QCS --- search space, search algorithm and candidate evaluation strategy --- to address the design flaws in current classically-inspired QCS methods. \'{E}liv\'{a}gar achieves hardware-efficiency and avoids an expensive circuit-mapping co-search via noise- and device topology-aware candidate generation. By introducing two cheap-to-compute predictors, Clifford noise resilience and representational capacity, \'{E}liv\'{a}gar decouples the evaluation of noise robustness and performance, enabling early rejection of low-fidelity circuits and reducing circuit evaluation costs. Due to its resource-efficiency, \'{E}liv\'{a}gar can further search for data embeddings, significantly improving performance.Based on a comprehensive evaluation of \'{E}liv\'{a}gar on 12 real quantum devices and 9 QML applications, \'{E}liv\'{a}gar achieves 5.3% higher accuracy and a 271\texttimes{} speedup compared to state-of-the-art QCS methods.",ACM
"Kazemian, Fazeleh S. and Galvez Vallejo, Jorge L. and Barca, Giuseppe M. J.","High-Performance, Accurate Large-Scale Quantum Chemistry Calculations on GPU Supercomputers using Coulomb-Perturbed Fragmentation",2024,10.1145/3673038.3673087,https://doi.org/10.1145/3673038.3673087,Conference paper,ICPP '24: Proceedings of the 53rd International Conference on Parallel Processing,"Predicting the chemico-physical properties of large molecular systems is a formidable challenge in chemistry and materials science. Traditional quantum mechanical methods, while accurate, have impractical scaling for large molecules with thousands of atoms, which are crucial in the development of novel therapeutics, catalysts, and nanomaterials. To address this, molecular fragmentation algorithms have been proposed to improve scalability and enable extensive parallelism. In this article, we introduce a significant enhancement to the Fragment Molecular Orbital (FMO) method, termed the Coulomb-Perturbed Fragmentation (CPF) method. CPF incorporates algorithmic improvements and implementation enhancements to optimize performance on heterogeneous computing systems equipped with a large number of GPUs. Key developments include a significant simplification of iteratitve self-consistent field (SCF) algorithm, advanced data management through a one-sided communication model, topology-aware optimizations, and a hybrid communication strategy for intra-group exchanges. Moreover, CPF integrates a distributed dynamic multi-layer load balancing scheme to optimise fragment distribution and workload management across nodes and GPUs. Performance evaluations on a 420-atom benzene molecule system comprising 35 fragments reveal that CPF outperforms existing GPU/CPU-based FMO algorithms in both efficiency and accuracy. When deployed on the Gadi supercomputer, CPF achieves over 97% parallel efficiency on 20 nodes, with scalability maintaining above 98% and 90% efficiency in weak-scaling tests for smaller and larger systems, respectively. Notably, CPF matches or exceeds the computational accuracy of conventional FMO methods, marking a substantial progress in the field of computational chemistry for fragmentation-based large-scale molecular modelling.",ACM
"Coletti, Mark and Sedova, Ada and Chahal, Rajni and Gibson, Luke and Roy, Santanu and Bryantsev, Vyacheslav",Multiobjective Hyperparameter Optimization for Deep Learning Interatomic Potential Training Using NSGA-II,2023,10.1145/3605731.3608931,https://doi.org/10.1145/3605731.3608931,Conference paper,ICPP Workshops '23: Proceedings of the 52nd International Conference on Parallel Processing Workshops,"Deep neural network (DNN) potentials are an emerging tool for simulation of dynamical atomistic systems, with the promise of quantum mechanical accuracy at speedups of 10000 \texttimes{}. As with other DNN methods, hyperparameters used during training can make a substantial difference in model accuracy, and optimal settings vary with dataset. To enable rapid tuning of hyperparameters for DNN potential training, we developed a scalable multiobjective optimization evolutionary algorithm for supercomputers and tested it on the Summit system at the Oak Ridge Leadership Computing Facility (OLCF). The multiobjective approach is required due to the coupling of two learned values defining the potential: the energy and force. Using a large-scale implementation of the NSGA-II algorithm adapted for training DNN potentials, we discovered several optimal multiobjective combinations, including best choices of activation functions, learning rate scaling scheme, and pairing of the two radial cutoffs used in the three dimensional descriptor function.",ACM
"Ludmir, Jason Zev and Huo, Yuqian and DiBrita, Nicholas S. and Patel, Tirthak",Modeling and Simulating Rydberg Atom Quantum Computers for Hardware-Software Co-design with PachinQo,2024,10.1145/3700421,https://doi.org/10.1145/3700421,Journal,Proc. ACM Meas. Anal. Comput. Syst.,"Quantum computing has the potential to accelerate various domains: scientific computation, machine learning, and optimization. Recently, Rydberg atom quantum computing has emerged as a promising quantum computing technology, especially with the demonstration of the zonal addressing architecture. However, this demonstration is only compatible with one type of quantum algorithm, and extending it to compile and execute general quantum algorithms is a challenge. To address it, we propose PachinQo, a framework to co-design the architecture and compilation for zonal addressing systems for any given quantum algorithm. PachinQo's evaluation demonstrates its ability to improve a quantum algorithm's estimated probability of success by 45% on average in error-prone quantum environments.",ACM
"Sheng, Guangzu and Cao, Tongtong and Huang, Xing and Wen, Tian and Li, Yixiang and Peng, Xiaoxiang",Research on the Shield Tunneling Parameter Prediction Model Based on Incremental Learning and QPSO-BiLSTM Algorithm,2024,10.1145/3672758.3672821,https://doi.org/10.1145/3672758.3672821,Conference paper,"CAICE '24: Proceedings of the 3rd International Conference on Computer, Artificial Intelligence and Control Engineering","Relying on the Wuhan Ping'an Avenue South Extension Tunnel Project, this study explores the operational patterns of shield tunneling control parameters. It establishes a tunneling parameter prediction model for shield tunneling based on incremental learning and Quantum Particle Swarm Optimization (QPSO) bidirectional Long Short-Term Memory (BiLSTM) algorithm. Firstly, shield ring data is collected to obtain tunneling parameters, and geological parameters are obtained through a combination of construction geological reports and on-site surveys. By calculating the Vandermonde coefficient, the correlation between input parameters is analyzed, and the optimal input parameters for predicting tunneling speed are determined. Secondly, a shield tunneling parameter prediction model based on the BiLSTM algorithm is established. Four activation functions in the BiLSTM hidden layers are compared through calculation and theoretical analysis, and the Rectified Linear Unit (Relu) function is ultimately determined as the optimal activation function for the BiLSTM hidden layers. During the model operation, the QPSO optimization algorithm is employed to find the optimal hyperparameters, and the model's accuracy is validated through calculation evaluation metrics. Finally, based on the prediction model, an incremental learning approach is used to simulate learning the next moment's tunneling parameters. The model is continuously updated through iterative training, and comparative verification of model accuracy is conducted. The research results indicate that the shield tunneling speed prediction model based on incremental learning and QPSO-BiLSTM has an average absolute error of only 7.63%, demonstrating good prediction performance and providing a feasible approach for on-site estimation of shield machine tunneling speed.",ACM
"Markidis, Stefano",Enabling Quantum Computer Simulations on AMD GPUs: a HIP Backend for Google's qsim,2023,10.1145/3624062.3624223,https://doi.org/10.1145/3624062.3624223,Conference paper,"SC-W '23: Proceedings of the SC '23 Workshops of The International Conference on High Performance Computing, Network, Storage, and Analysis","Quantum computer simulators play a critical role in supporting the development and validation of quantum algorithms and hardware. This study focuses on porting Google¡¯s qsim, a quantum computer simulator, to AMD Graphics Processing Units&nbsp;(GPUs). We leverage the existing qsim CUDA backend and harness the HIPIFY tool to provide a qsim HIP backend tailored for AMD GPUs. Our performance analysis centers on evaluating the HIP backend¡¯s capabilities, executed on a computing node equipped with the AMD MI250X GPU and the AMD EPYC Trento CPU. We use the Random Quantum Circuit (RQC) sampling benchmark, employing a circuit featuring 30 qubits. The qsim HIP backend on AMD GPU outperforms the CPU version by a remarkable margin, achieving seven to nine times faster speeds. Our investigation also compares qsim¡¯s performance on the Nvidia A100 and AMD MI250X GPUs. The Nvidia A100 consistently outperforms the AMD MI250x counterpart, and this performance gap further widens with optimal gate fusion configurations. For instance, a two-gate fusion configuration exhibits a 5% difference, whereas a four-gate fusion setup reveals a large 44% performance gap. Our work highlights the substantial performance advantage of GPU-based quantum simulation over traditional CPU approaches. Despite a performance lag compared to the qsim CUDA backend, the AMD HIP qsim backend emerges as a competitive alternative poised for further optimization.",ACM
"Shi, Jinjing and Xiao, Zimeng and Shi, Heyuan and Jiang, Yu and Li, Xuelong",QuanTest: Entanglement-Guided Testing of Quantum Neural Network Systems,2024,10.1145/3688840,https://doi.org/10.1145/3688840,Journal,ACM Trans. Softw. Eng. Methodol.,"Quantum Neural Network (QNN) combines the Deep Learning (DL) principle with the fundamental theory of quantum mechanics to achieve machine learning tasks with quantum acceleration. Recently, QNN systems have been found to manifest robustness issues similar to classical DL systems. There is an urgent need for ways to test their correctness and security. However, QNN systems differ significantly from traditional quantum software and classical DL systems, posing critical challenges for QNN testing. These challenges include the inapplicability of traditional quantum software testing methods to QNN systems due to differences in programming paradigms and decision logic representations, the dependence of quantum test sample generation on perturbation operators, and the absence of effective information in quantum neurons. In this paper, we propose QuanTest, a quantum entanglement-guided adversarial testing framework to uncover potential erroneous behaviors in QNN systems. We design a quantum entanglement adequacy criterion to quantify the entanglement acquired by the input quantum states from the QNN system, along with two similarity metrics to measure the proximity of generated quantum adversarial examples to the original inputs. Subsequently, QuanTest formulates the problem of generating test inputs that maximize the quantum entanglement adequacy and capture incorrect behaviors of the QNN system as a joint optimization problem and solves it in a gradient-based manner to generate quantum adversarial examples. Experimental results demonstrate that QuanTest possesses the capability to capture erroneous behaviors in QNN systems (generating 67.48%-96.05% more high-quality test samples than the random noise under the same perturbation size constraints). The entanglement-guided approach proves effective in adversarial testing, generating more adversarial examples (maximum increase reached 21.32%).",ACM
"Li, Zhengang and Shen, Xuan and Yuan, Geng and Zabihi, Masoud and Yamauchi, Tomoharu and Wang, Yanzhi and Chen, Olivia",Late Breaking Result: AQFP-aware Binary Neural Network Architecture Search,2024,10.1145/3649329.3663503,https://doi.org/10.1145/3649329.3663503,Conference paper,DAC '24: Proceedings of the 61st ACM/IEEE Design Automation Conference,"Adiabatic Quantum-Flux-Parametron (AQFP) is a superconducting logic with extremely high energy efficiency. Recent research has made initial strides toward developing AQFP accelerator. However several critical challenges from both the hardware and software side remain, preventing the design from being a comprehensive solution. This paper proposes an AQFP-aware binary neural network architecture search framework that leverages software-hardware co-optimization to eventually search the AQFP-adapted neural network and the corresponding hardware configuration, providing a feasible AQFP-based solution for binary neural network (BNN) acceleration. Experimental results show that our framework consistently outperforms the representative AQFP-based framework.",ACM
"Rasch, Ari",(De/Re)-Composition of Data-Parallel Computations via Multi-Dimensional Homomorphisms,2024,10.1145/3665643,https://doi.org/10.1145/3665643,Journal,ACM Trans. Program. Lang. Syst.,"Data-parallel computations, such as linear algebra routines and stencil computations, constitute one of the most relevant classes in parallel computing, e.g., due to their importance for deep learning. Efficiently de-composing such computations for the memory and core hierarchies of modern architectures and re-composing the computed intermediate results back to the final result¡ªwe say (de/re)-composition for short¡ªis key to achieve high performance for these computations on, e.g., GPU and CPU. Current high-level approaches to generating data-parallel code are often restricted to a particular subclass of data-parallel computations and architectures (e.g., only linear algebra routines on only GPU or only stencil computations), and/or the approaches rely on a user-guided optimization process for a well-performing (de/re)-composition of computations, which is complex and error prone for the user.We formally introduce a systematic (de/re)-composition approach, based on the algebraic formalism of Multi-Dimensional Homomorphisms (MDHs). Our approach is designed as general enough to be applicable to a wide range of data-parallel computations and for various kinds of target parallel architectures. To efficiently target the deep and complex memory and core hierarchies of contemporary architectures, we exploit our introduced (de/re)-composition approach for a correct-by-construction, parametrized cache blocking, and parallelization strategy. We show that our approach is powerful enough to express, in the same formalism, the (de/re)-composition strategies of different classes of state-of-the-art approaches (scheduling-based, polyhedral, etc.), and we demonstrate that the parameters of our strategies enable systematically generating code that can be fully automatically optimized (auto-tuned) for the particular target architecture and characteristics of the input and output data (e.g., their sizes and memory layouts). Particularly, our experiments confirm that via auto-tuning, we achieve higher performance than state-of-the-art approaches, including hand-optimized solutions provided by vendors (such as NVIDIA cuBLAS/cuDNN and Intel oneMKL/oneDNN), on real-world datasets and for a variety of data-parallel computations, including linear algebra routines, stencil and quantum chemistry computations, data mining algorithms, and computations that recently gained high attention due to their relevance for deep learning.",ACM
"Suau, Adrien and Staffelbach, Gabriel and Todri-Sanial, Aida",qprof: A gprof-Inspired Quantum Profiler,2022,10.1145/3529398,https://doi.org/10.1145/3529398,Journal,ACM Transactions on Quantum Computing,"We introduce qprof, a new and extensible quantum program profiler able to generate profiling reports of quantum circuits written using various quantum computing frameworks. We describe the internal structure and working of qprof and provide practical examples on quantum circuits with increasing complexity along with benchmarks of the tool execution time on large circuits. This tool will allow researchers to visualise their quantum algorithm implementation in a different and complementary way and reliably localise the bottlenecks for efficient code optimisation.",ACM
"Xie, Xiaojie and Yang, Gang and An, Lei and Ren, Yun and Wu, Xiao and Tong, Xin and He, Yanhua and Chen, Xiaojie",Research on Substation Quantum Secure Communication System Based on 5G Private Network Technology,2023,10.1145/3617184.3617779,https://doi.org/10.1145/3617184.3617779,Conference paper,ICCSIE '23: Proceedings of the 8th International Conference on Cyber Security and Information Engineering,"Quantum cryptography is an epoch-making technology with irreplaceable security, which has been widely used in the field of secure communication. This paper first explores the application prospects of quantum communication technology in power systems. Secondly, this paper innovatively proposes a power secure communication method based on quantum keys. At the same time, this paper constructs the quantum key secure communication network architecture and analyzes the application principle and security mechanism of quantum key. Taking the quantum key management system as the core, the author designs and implements the quantum key security storage and business security process application model. Thirdly, this paper uses the local search algorithm to optimize the parameters of the MDI-QKD protocol under symmetric and asymmetric conditions, and gives its optimized key rate. Finally, this paper uses the actual quantum key distribution equipment, quantum VPN and network tester to build an experimental environment. The system uses a comprehensive network tester to simulate the power grid application business information to test and statistically analyze the core performance characteristics of quantum VPN, such as throughput, delay, and encryption algorithm. The experimental results can provide a reference for the popularization and application of the quantum secure communication system in the power grid production control and management information business.",ACM
"Jiang, Shui and Fu, Rongliang and Burgholzer, Lukas and Wille, Robert and Ho, Tsung-Yi and Huang, Tsung-Wei",FlatDD: A High-Performance Quantum Circuit Simulator using Decision Diagram and Flat Array,2024,10.1145/3673038.3673073,https://doi.org/10.1145/3673038.3673073,Conference paper,ICPP '24: Proceedings of the 53rd International Conference on Parallel Processing,"Quantum circuit simulator (QCS) is essential for designing quantum algorithms because it assists researchers in understanding how quantum operations work without access to expensive quantum computers. Traditional array-based QCSs suffer from exponential time and memory complexities. To address this problem, Decision Diagram (DD) was introduced to compress simulation data by exploring the circuit regularity. However, for irregular circuit structures, DD-based simulation incurs significant runtime and memory overhead. To overcome this challenge, we present FlatDD, a high-performance QCS that capitalizes on the strength of both DD- and array-based approaches. FlatDD parallelizes the simulation workload at multiple levels and leverages an efficient caching technique to reuse historical results. To further enhance the simulation performance for deep circuits, FlatDD introduces a gate-fusion algorithm to reduce the computational cost. Compared to state-of-the-art QCSs on commonly used quantum circuits, FlatDD achieves 34.81\texttimes{} speed-up and 1.93\texttimes{} memory reduction.",ACM
"Kanakagiri, Raghavendra and Solomonik, Edgar",Minimum Cost Loop Nests for Contraction of a Sparse Tensor with a Tensor Network,2024,10.1145/3626183.3659985,https://doi.org/10.1145/3626183.3659985,Conference paper,SPAA '24: Proceedings of the 36th ACM Symposium on Parallelism in Algorithms and Architectures,"Sparse tensor decomposition and completion are common in numerous applications, ranging from machine learning to computational quantum chemistry. Typically, the main bottleneck in optimization of these models are contractions of a single large sparse tensor with a network of several dense matrices or tensors (SpTTN). Prior works on high-performance tensor decomposition and completion have focused on performance and scalability optimizations for specific SpTTN kernels. We present algorithms and a runtime system for identifying and executing the most efficient loop nest for any SpTTN kernel. We consider both enumeration of such loop nests for autotuning and efficient algorithms for finding the lowest cost loop nest for simpler metrics, such as buffer size or cache miss models. Our runtime system identifies the best choice of loop nest without user guidance, and also provides a distributed-memory parallelization of SpTTN kernels. We evaluate our framework using both real-world and synthetic tensors. Our results demonstrate that our approach outperforms available generalized state-of-the-art libraries and matches the performance of specialized codes.",ACM
"Lykov, Danylo and Shaydulin, Ruslan and Sun, Yue and Alexeev, Yuri and Pistoia, Marco",Fast Simulation of High-Depth QAOA Circuits,2023,10.1145/3624062.3624216,https://doi.org/10.1145/3624062.3624216,Conference paper,"SC-W '23: Proceedings of the SC '23 Workshops of The International Conference on High Performance Computing, Network, Storage, and Analysis","Until high-fidelity quantum computers with a large number of qubits become widely available, classical simulation remains a vital tool for algorithm design, tuning, and validation. We present a simulator for the Quantum Approximate Optimization Algorithm (QAOA). Our simulator is designed with the goal of reducing the computational cost of QAOA parameter optimization and supports both CPU and GPU execution. Our central observation is that the computational cost of both simulating the QAOA state and computing the QAOA objective to be optimized can be reduced by precomputing the diagonal Hamiltonian encoding the problem. We reduce the time for a typical QAOA parameter optimization by eleven times for n = 26 qubits compared to a state-of-the-art GPU quantum circuit simulator based on cuQuantum. Our simulator is available on GitHub: https://github.com/jpmorganchase/QOKit",ACM
"Sch\""{o}nberger, Manuel and Trummer, Immanuel and Mauerer, Wolfgang",Quantum-Inspired Digital Annealing for Join Ordering,2023,10.14778/3632093.3632112,https://doi.org/10.14778/3632093.3632112,Journal,Proc. VLDB Endow.,"Finding the optimal join order (JO) is one of the most important problems in query optimisation, and has been extensively considered in research and practise. As it involves huge search spaces, approximation approaches and heuristics are commonly used, which explore a reduced solution space at the cost of solution quality. To explore even large JO search spaces, we may consider special-purpose software, such as mixed-integer linear programming (MILP) solvers, which have successfully solved JO problems. However, even mature solvers cannot overcome the limitations of conventional hardware prompted by the end of Moore's law.We consider quantum-inspired digital annealing hardware, which takes inspiration from quantum processing units (QPUs). Unlike QPUs, which likely remain limited in size and reliability in the near and mid-term future, the digital annealer (DA) can solve large instances of mathematically encoded optimisation problems today. We derive a novel, native encoding for the JO problem tailored to this class of machines that substantially improves over known MILP and quantum-based encodings, and reduces encoding size over the state-of-the-art. By augmenting the computation with a novel readout method, we derive valid join orders for each solution obtained by the (probabilistically operating) DA. Most importantly and despite an extremely large solution space, our approach scales to practically relevant dimensions of around 50 relations and improves result quality over conventionally employed approaches, adding a novel alternative to solving the long-standing JO problem.","ACM, Web of Science"
"Xu, Mingkuan and Cao, Shiyi and Miao, Xupeng and Acar, Umut A. and Jia, Zhihao",Atlas: Hierarchical Partitioning for Quantum Circuit Simulation on GPUs,2024,10.1109/SC41406.2024.00087,https://doi.org/10.1109/SC41406.2024.00087,Conference paper,"SC '24: Proceedings of the International Conference for High Performance Computing, Networking, Storage, and Analysis","This paper presents techniques for theoretically and practically efficient and scalable Schr\""{o}dinger-style quantum circuit simulation. Our approach partitions a quantum circuit into a hierarchy of subcircuits and simulates the subcircuits on multinode GPUs, exploiting available data parallelism while minimizing communication costs. To minimize communication costs, we formulate an Integer Linear Program that rewards simulation of ""nearby"" gates on ""nearby"" GPUs. To maximize throughput, we use a dynamic programming algorithm to compute the subcircuit simulated by each kernel at a GPU. We realize these techniques in Atlas, a distributed, multi-GPU quantum circuit simulator. Our evaluation on a variety of quantum circuits shows that Atlas outperforms state-of-the-art GPU-based simulators by more than 2\texttimes{} on average and is able to run larger circuits via offloading to DRAM, outperforming other large-circuit simulators by two orders of magnitude.",ACM
"Paltenghi, Matteo",Cross-platform testing of quantum computing platforms,2022,10.1145/3510454.3517061,https://doi.org/10.1145/3510454.3517061,Conference paper,ICSE '22: Proceedings of the ACM/IEEE 44th International Conference on Software Engineering: Companion Proceedings,"Quantum computing has been attracting the attention of both applied research and companies. Continuous progress on fundamental hardware technology promises to bring us more reliable and large-scale quantum computers on which to run the next generation of quantum algorithms. These programs are compiled and executed on dedicated platforms, and similarly to classical programs, a large effort is required to test these platforms and create a robust software toolchain.Unlike previous studies which focused on cross-optimization and cross-backend testing, this dissertation aims to create the first approach for cross-platform testing which compares execution on diverse quantum computing platforms. To inform the design of the method, we will first perform an empirical study of bugs in quantum computing platforms and a review of the characteristics of realistic quantum programs.The final approach for cross-platform testing will include three components: a learning-based method to generate realistic quantum programs, an approach to map and run them on multiple platforms, and finally a quantum-specific statistical test to compare two multivariate binary distributions returned as the output of quantum programs.","ACM, IEEE"
"Barletta, Vita Santa and Caivano, Danilo and Catalano, Christian and De Vincentiis, Mirko",Quantum-based Automotive Threat Intelligence and Countermeasures,2024,10.1145/3661167.3661278,https://doi.org/10.1145/3661167.3661278,Conference paper,EASE '24: Proceedings of the 28th International Conference on Evaluation and Assessment in Software Engineering,"Due to the increasing amount of software and hardware in connected and autonomous cars, the attack surface is growing, which increases the risk of security attacks. Researchers proposed machine learning or deep learning techniques to identify threats in in-vehicle networks. However, using these techniques is not enough to support the automotive industry since new processes or techniques must be conceptualized to make automotive systems more secure. Therefore, this research work presents a methodology, Quantum-based Automotive Threat Intelligence and Countermeasures (QUANTICAR), that integrates quantum optimization for CAN bus Intrusion Detection and the National Vulnerability Database (NVD) to understand the automotive attacks. In the first phase, QUANTICAR identifies the different types of attacks and then, based on the specific attack class, extracts new knowledge using the NVD. This contributes not only to improving attack detection but also to developing an Automotive Knowledge Base that can support developers and security experts in the secure development of automotive components in compliance with ISO/SAE 21434.","ACM, Scopus"
"Wang, Jiyuan and Zhang, Qian and Xu, Guoqing Harry and Kim, Miryung",QDiff: differential testing of quantum software stacks,2022,10.1109/ASE51524.2021.9678792,https://doi.org/10.1109/ASE51524.2021.9678792,Conference paper,ASE '21: Proceedings of the 36th IEEE/ACM International Conference on Automated Software Engineering,"Over the past few years, several quantum software stacks (QSS) have been developed in response to rapid hardware advances in quantum computing. A QSS includes a quantum programming language, an optimizing compiler that translates a quantum algorithm written in a high-level language into quantum gate instructions, a quantum simulator that emulates these instructions on a classical device, and a software controller that sends analog signals to a very expensive quantum hardware based on quantum circuits. In comparison to traditional compilers and architecture simulators, QSSes are difficult to tests due to the probabilistic nature of results, the lack of clear hardware specifications, and quantum programming complexity.This work devises a novel differential testing approach for QSSes, named QDIFF with three major innovations: (1) We generate input programs to be tested via semantics-preserving, source to source transformation to explore program variants. (2) We speed up differential testing by filtering out quantum circuits that are not worthwhile to execute on quantum hardware by analyzing static characteristics such as a circuit depth, 2-gate operations, gate error rates, and T1 relaxation time. (3) We design an extensible equivalence checking mechanism via distribution comparison functions such as Kolmogorov-Smirnov test and cross entropy.We evaluate QDiff with three widely-used open source QSSes: Qiskit from IBM, Cirq from Google, and Pyquil from Rigetti. By running QDiff on both real hardware and quantum simulators, we found several critical bugs revealing potential instabilities in these platforms. QDiff's source transformation is effective in producing semantically equivalent yet not-identical circuits (i.e., 34% of trials), and its filtering mechanism can speed up differential testing by 66%.","ACM, IEEE"
"Whitley, Darrell and Chicano, Francisco and Aguirre, Hernan","Quadratization of gray coded representations, long path problems and needle functions",2021,10.1145/3449639.3459325,https://doi.org/10.1145/3449639.3459325,Conference paper,GECCO '21: Proceedings of the Genetic and Evolutionary Computation Conference,"In Evolutionary Computation, it is informative to ask what happens when well known benchmarks and bit representations are transformed into quadratic pseudo-Boolean optimization problems. Such transforms are commonly used in quantum computing in order to reduce nonlinearity to k-bounded interactions. First we show that Gray code representations are transformed into linear encodings with quadratic constraints. Next we look at Long Path problems which are constructed so that bit flip local search requires exponential time to converge to a global or local optimum. We show that Long Path problems are similar to reflected Gray codes in both construction and complexity. Finally, a basic form of the ""Needle in a haystack"" problem is transformed into a problem that can be optimally solved in linear time.",ACM
"Zhou, Li and Barthe, Gilles and Strub, Pierre-Yves and Liu, Junyi and Ying, Mingsheng",CoqQ: Foundational Verification of Quantum Programs,2023,10.1145/3571222,https://doi.org/10.1145/3571222,Journal,Proc. ACM Program. Lang.,"CoqQ is a framework for reasoning about quantum programs in the Coq proof assistant. Its main components are: a deeply embedded quantum programming language, in which classic quantum algorithms are easily expressed, and an expressive program logic for proving properties of programs. CoqQ is foundational: the program logic is formally proved sound with respect to a denotational semantics based on state-of-art mathematical libraries (MathComp and MathComp Analysis). CoqQ is also practical: assertions can use Dirac expressions, which eases concise specifications, and proofs can exploit local and parallel reasoning, which minimizes verification effort. We illustrate the applicability of CoqQ with many examples from the literature.","ACM, Web of Science"
"Zhang, Mengyu and Xie, Lei and Zhang, Zhenxing and Yu, Qiaonian and Xi, Guanglei and Zhang, Hualiang and Liu, Fuming and Zheng, Yarui and Zheng, Yicong and Zhang, Shengyu",Exploiting Different Levels of Parallelism in the Quantum Control Microarchitecture for Superconducting Qubits,2021,10.1145/3466752.3480116,https://doi.org/10.1145/3466752.3480116,Conference paper,MICRO '21: Proceedings of the 54th Annual IEEE/ACM International Symposium on Microarchitecture,"As current Noisy Intermediate Scale Quantum (NISQ) devices suffer from decoherence errors, any delay in the instruction execution of quantum control microarchitecture can lead to the loss of quantum information and incorrect computation results. Hence, it is crucial for the control microarchitecture to issue quantum operations to the Quantum Processing Unit (QPU) in time. As in classical microarchitecture, parallelism in quantum programs needs to be exploited for speedup. However, three challenges emerge in the quantum scenario: 1) the quantum feedback control can introduce significant pipeline stall latency; 2) timing control is required for all quantum operations; 3) QPU requires a deterministic operation supply to prevent the accumulation of quantum errors. In this paper, we propose a novel control microarchitecture design to exploit Circuit Level Parallelism (CLP) and Quantum Operation Level Parallelism (QOLP). Firstly, we develop a Multiprocessor architecture to exploit CLP, which supports dynamic scheduling of different sub-circuits. This architecture can handle parallel feedback control and minimize the potential overhead that disrupts the timing control. Secondly, we propose a Quantum Superscalar approach that exploits QOLP by efficiently executing massive quantum instructions in parallel. Both methods issue quantum operations to QPU deterministically. In the benchmark test of a Shor syndrome measurement, a six-core implementation of our proposal achieves up to 2.59 \texttimes{} speedup compared with a single core. For various canonical quantum computing algorithms, our superscalar approach achieves an average of 4.04 \texttimes{} improvement over a baseline design. Finally, We perform a simultaneous randomized benchmarking (simRB) experiment on a real QPU using the proposed microarchitecture for validation.",ACM
"Lubinski, Thomas and Coffrin, Carleton and McGeoch, Catherine and Sathe, Pratik and Apanavicius, Joshua and Bernal Neira, David and Quantum Economic Development Consortium(QED-C) Collaboration",Optimization Applications as Quantum Performance Benchmarks,2024,10.1145/3678184,https://doi.org/10.1145/3678184,Journal,ACM Transactions on Quantum Computing,"Combinatorial optimization is anticipated to be one of the primary use cases for quantum computation in the coming years. The Quantum Approximate Optimization Algorithm&nbsp;and Quantum Annealing can potentially demonstrate significant run-time performance benefits over current state-of-the-art solutions. Inspired by existing methods to characterize classical optimization algorithms, we analyze the solution quality obtained by solving Max-cut problems using gate-model quantum devices and a quantum annealing device. This is used to guide the development of an advanced benchmarking framework for quantum computers designed to evaluate the trade-off between run-time execution performance and the solution quality for iterative hybrid quantum-classical applications. The framework generates performance profiles through compelling visualizations that show performance progression as a function of time for various problem sizes and illustrates algorithm limitations uncovered by the benchmarking approach. As an illustration, we explore the factors that influence quantum computing system throughput, using results obtained through execution on various quantum simulators and quantum hardware systems.",ACM
"Carril, Xavier and Kardaris, Charalampos and Ribes-Gonz\'{a}Lez, Jordi and Farr\`{a}s, Oriol and Hernandez, Carles and Kostalabros, Vatistas and Gonz\'{a}lez-Jim\'{e}nez, Joel Ulises and Moret\'{o",Hardware Acceleration for High-Volume Operations of CRYSTALS-Kyber and CRYSTALS-Dilithium,2024,10.1145/3675172,https://doi.org/10.1145/3675172,Journal,ACM Trans. Reconfigurable Technol. Syst.,"Many high-demand digital services need to perform several cryptographic operations, such as key exchange or security credentialing, in a concise amount of time. In turn, the security of some of these cryptographic schemes is threatened by advances in quantum computing, as quantum computer could break their security in the near future. Post-quantum cryptography (PQC) is an emerging field that studies cryptographic algorithms that resist such attacks. The National Institute of Standards and Technology (NIST) has selected the CRYSTALS-Kyber Key Encapsulation Mechanism and the CRYSTALS-Dilithium Digital Signature algorithm as primary PQC standards. In this article, we present field-programmable gate array (FPGA)-based hardware accelerators for high-volume operations of both schemes. We apply high-level synthesis (HLS) for hardware optimization, leveraging a batch processing approach to maximize the memory throughput and applying custom HLS logic to specific algorithmic components. Using reconfigurable FPGAs, we show that our hardware accelerators achieve speedups between 3 (times)  and 9 (times)  over software baseline implementations, even over ones leveraging CPU vector architectures. Furthermore, the methods used in this study can also be extended to the new CRYSTALS-based NIST FIPS drafts, ML-KEM and ML-DSA, with similar acceleration results.",ACM
"Li, Zikun and Peng, Jinjun and Mei, Yixuan and Lin, Sina and Wu, Yi and Padon, Oded and Jia, Zhihao",Quarl: A Learning-Based Quantum Circuit Optimizer,2024,10.1145/3649831,https://doi.org/10.1145/3649831,Journal,Proc. ACM Program. Lang.,"Optimizing quantum circuits is challenging due to the very large search space of functionally equivalent circuits and the necessity of applying transformations that temporarily decrease performance to achieve a final performance improvement. This paper presents Quarl, a learning-based quantum circuit optimizer. Applying reinforcement learning (RL) to quantum circuit optimization raises two main challenges: the large and varying action space and the non-uniform state representation. Quarl addresses these issues with a novel neural architecture and RL-training procedure. Our neural architecture decomposes the action space into two parts and leverages graph neural networks in its state representation, both of which are guided by the intuition that optimization decisions can be mostly guided by local reasoning while allowing global circuit-wide reasoning. Our evaluation shows that Quarl significantly outperforms existing circuit optimizers on almost all benchmark circuits. Surprisingly, Quarl can learn to perform rotation merging¡ªa complex, non-local circuit optimization implemented as a separate pass in existing optimizers.",ACM
"Chitty, Darren M. and Charles, James and Moraglio, Alberto and Keedwell, Ed",Applying a Quantum Annealer to the Traffic Assignment Problem,2024,10.1145/3638529.3654131,https://doi.org/10.1145/3638529.3654131,Conference paper,GECCO '24: Proceedings of the Genetic and Evolutionary Computation Conference,"The Traffic Assignment Problem (TAP) is a complex transportation optimisation problem typically solved using meta-heuristics on classical computers. Quantum computers, despite being a nascent technology, have the potential to significantly speed up computation by exploiting quantum parallelism. A quantum annealer (QA) is a quantum computer tailored to solve combinatorial optimisation problems formulated as a Quadratic Unconstrained Binary Optimisation (QUBO). Formulating complex optimisation problems as QUBO is an open challenge. This paper derives a new QUBO formulation for TAP by employing a streamlined methodology of general applicability. It also attempts a direct comparison at solving TAP encompassing a QA (D-WAVE), a hybrid quantum-classical algorithm, and classical methods including Simulated Annealing and Genetic Algorithms. This comparison is difficult and seldom done due to the inherent differences between quantum and classic hardware. As expected from the current quantum technology, our results show that a pure QA suffers from significant noise in qubits and requires significant additional computational time, although we show that the time required solely by the QPU does not increase with problem size. We also show that the hybrid QA mitigates these noise issues and is on a par with traditional methods.",ACM
"Ding, Yongshan and Wu, Xin-Chuan and Holmes, Adam and Wiseth, Ash and Franklin, Diana and Martonosi, Margaret and Chong, Frederic T.",SQUARE: strategic quantum ancilla reuse for modular quantum programs via cost-effective uncomputation,2020,10.1109/ISCA45697.2020.00054,https://doi.org/10.1109/ISCA45697.2020.00054,Conference paper,ISCA '20: Proceedings of the ACM/IEEE 47th Annual International Symposium on Computer Architecture,"Compiling high-level quantum programs to machines that are size constrained (i.e. limited number of quantum bits) and time constrained (i.e. limited number of quantum operations) is challenging. In this paper, we present SQUARE (Strategic QUantum Ancilla REuse), a compilation infrastructure that tackles allocation and reclamation of scratch qubits (called ancilla) in modular quantum programs. At its core, SQUARE strategically performs uncomputation to create opportunities for qubit reuse.Current Noisy Intermediate-Scale Quantum (NISQ) computers and forward-looking Fault-Tolerant (FT) quantum computers have fundamentally different constraints such as data locality, instruction parallelism, and communication overhead. Our heuristic-based ancilla-reuse algorithm balances these considerations and fits computations into resource-constrained NISQ or FT quantum machines, throttling parallelism when necessary. To precisely capture the workload of a program, we propose an improved metric, the ""active quantum volume,"" and use this metric to evaluate the effectiveness of our algorithm. Our results show that SQUARE improves the average success rate of NISQ applicationsby 1.47X. Surprisingly, the additional gates for uncomputation create ancilla with better locality, and result in substantially fewer swap gates and less gate noise overall. SQUARE also achieves an average reduction of 1.5X (and up to 9.6X) in active quantum volume for FT machines.","ACM, IEEE"
"Pang, Yuchen and Hao, Tianyi and Dugad, Annika and Zhou, Yiqing and Solomonik, Edgar",Efficient 2D tensor network simulation of quantum systems,2020,10.5555/3433701.3433719,https://dl.acm.org/doi/10.5555/3433701.3433719,Conference paper,"SC '20: Proceedings of the International Conference for High Performance Computing, Networking, Storage and Analysis","Simulation of quantum systems is challenging due to the exponential size of the state space. Tensor networks provide a systematically improvable approximation for quantum states. 2D tensor networks such as Projected Entangled Pair States (PEPS) are well-suited for key classes of physical systems and quantum circuits. However, direct contraction of PEPS networks has exponential cost, while approximate algorithms require computations with large tensors. We propose new scalable algorithms and software abstractions for PEPS-based methods, accelerating the bottleneck operation of contraction and refactorization of a tensor subnetwork. We employ randomized SVD with an implicit matrix to reduce cost and memory footprint asymptotically. Further, we develop a distributed-memory PEPS library and study accuracy and efficiency of alternative algorithms for PEPS contraction and evolution on the Stampede2 supercomputer. We also simulate a popular near-term quantum algorithm, the Variational Quantum Eigensolver (VQE), and benchmark Imaginary Time Evolution (ITE), which compute ground states of Hamiltonians.",ACM
"Farhani, Yousra and Saiem, Malak and Arbaoui, Taha and Hnaien, Faicel",Enhanced QUBO Formulations for The Flow Shop Scheduling Problem,2024,10.1145/3638530.3664150,https://doi.org/10.1145/3638530.3664150,Conference paper,GECCO '24 Companion: Proceedings of the Genetic and Evolutionary Computation Conference Companion,"In recent years, the Flow shop Scheduling Problem (FSP) has gained significant attention, prompting researchers to develop various methods, from conventional to hybrid optimization algorithms. Driven by the rapid growth of quantum computing capabilities, quantum approaches applied to optimization problems have attracted an increasing research effort. This work attempts to solve the permutation flow shop scheduling problem using quantum annealing by formulating the problem as a Quadratic Unconstrained Binary Optimization model (QUBO). Two QUBO formulations tailored to address the FSP are used. The first formulation is based on the position-based modelling while the second is based on five approximations of FSP as a Traveling Salesman Problem (TSP). The QUBO formulations are tested, using D-Wave's quantum annealers, on the well-known Taillard FSP benchmark and compared against each other. Results show that the proposed position-based QUBO reaches better solutions than the TSP-based QUBOs. This work is an attempt to highlight the increasing effectiveness of quantum annealers in addressing complex optimization problems and their limitations compared to conventional classical methods.",ACM
"Ding, Yongshan and Holmes, Adam and Javadi-Abhari, Ali and Franklin, Diana and Martonosi, Margaret and Chong, Frederic T.",Magic-state functional units: mapping and scheduling multi-level distillation circuits for fault-tolerant quantum architectures,2018,10.1109/MICRO.2018.00072,https://doi.org/10.1109/MICRO.2018.00072,Conference paper,MICRO-51: Proceedings of the 51st Annual IEEE/ACM International Symposium on Microarchitecture,"Quantum computers have recently made great strides and are on a long-term path towards useful fault-tolerant computation. A dominant overhead in fault-tolerant quantum computation is the production of high-fidelity encoded qubits, called magic states, which enable reliable error-corrected computation. We present the first detailed designs of hardware functional units that implement space-time optimized magic-state factories for surface code error-corrected machines.Interactions among distant qubits require surface code braids (physical pathways on chip) which must be routed. Magic-state factories are circuits comprised of a complex set of braids that is more difficult to route than quantum circuits considered in previous work [1]. This paper explores the impact of scheduling techniques, such as gate reordering and qubit renaming, and we propose two novel mapping techniques: braid repulsion and dipole moment braid rotation. We combine these techniques with graph partitioning and community detection algorithms, and further introduce a stitching algorithm for mapping subgraphs onto a physical machine. Our results show a factor of 5.64 reduction in space-time volume compared to the best-known previous designs for magic-state factories.","ACM, IEEE"
"Holmes, Adam and Jokar, Mohammad Reza and Pasandi, Ghasem and Ding, Yongshan and Pedram, Massoud and Chong, Frederic T.",NISQ+: boosting quantum computing power by approximating quantum error correction,2020,10.1109/ISCA45697.2020.00053,https://doi.org/10.1109/ISCA45697.2020.00053,Conference paper,ISCA '20: Proceedings of the ACM/IEEE 47th Annual International Symposium on Computer Architecture,"Quantum computers are growing in size, and design decisions are being made now that attempt to squeeze more computation out of these machines. In this spirit, we design a method to boost the computational power of near-term quantum computers by adapting protocols used in quantum error correction to implement ""Approximate Quantum Error Correction (AQEC)."" By approximating fully-fledged error correction mechanisms, we can increase the compute volume (qubits x gates, or ""Simple Quantum Volume (SQV)"") of near-term machines. The crux of our design is a fast hardware decoder that can approximately decode detected error syndromes rapidly. Specifically, we demonstrate a proof-of-concept that approximate error decoding can be accomplished online in near-term quantum systems by designing and implementing a novel algorithm in superconducting Single Flux Quantum (SFQ) logic technology. This avoids a critical decoding backlog, hidden in all offline decoding schemes, that leads to idle time exponential in the number of T gates in a program [58].Our design utilizes one SFQ processing module per physical quantum bit. Employing state-of-the-art SFQ synthesis tools, we show that the circuit area, power, and latency are within the constraints of typical, contemporary quantum system designs. Under a pure dephasing error model, the proposed accelerator and AQEC solution is able to expand SQV by factors between 3,402 and 11,163 on expected near-term machines. The decoder achieves a 5% accuracy threshold as well as pseudo-thresholds of approximately 5%, 4.75%, 4.5%, and 3.5% physical error rates for code distances 3, 5, 7, and 9, respectively. Decoding solutions are achieved in a maximum of ~ 20 nanoseconds on the largest code distances studied. By avoiding the exponential idle time in offline decoders, we achieve a 10x reduction in required code distances to achieve the same logical performance as alternative designs.","ACM, IEEE"
"Li, Zhengang and Yuan, Geng and Yamauchi, Tomoharu and Masoud, Zabihi and Xie, Yanyue and Dong, Peiyan and Tang, Xulong and Yoshikawa, Nobuyuki and Tiwari, Devesh and Wang, Yanzhi and Chen, Olivia",SupeRBNN: Randomized Binary Neural Network Using Adiabatic Superconductor Josephson Devices,2023,10.1145/3613424.3623771,https://doi.org/10.1145/3613424.3623771,Conference paper,MICRO '23: Proceedings of the 56th Annual IEEE/ACM International Symposium on Microarchitecture,"Adiabatic Quantum-Flux-Parametron (AQFP) is a superconducting logic with extremely high energy efficiency. By employing the distinct polarity of current to denote logic ¡®0¡¯ and ¡®1¡¯, AQFP devices serve as excellent carriers for binary neural network (BNN) computations. Although recent research has made initial strides toward developing an AQFP-based BNN accelerator, several critical challenges remain, preventing the design from being a comprehensive solution. In this paper, we propose SupeRBNN, an AQFP-based randomized BNN acceleration framework that leverages software-hardware co-optimization to eventually make the AQFP devices a feasible solution for BNN acceleration. Specifically, we investigate the randomized behavior of the AQFP devices and analyze the impact of crossbar size on current attenuation, subsequently formulating the current amplitude into the values suitable for use in BNN computation. To tackle the accumulation problem and improve overall hardware performance, we propose a stochastic computing-based accumulation module and a clocking scheme adjustment-based circuit optimization method. To effectively train the BNN models that are compatible with the distinctive characteristics of AQFP devices, we further propose a novel randomized BNN training solution that utilizes algorithm-hardware co-optimization, enabling simultaneous optimization of hardware configurations. In addition, we propose implementing batch normalization matching and the weight rectified clamp method to further improve the overall performance. We validate our SupeRBNN framework across various datasets and network architectures, comparing it with implementations based on different technologies, including CMOS, ReRAM, and superconducting RSFQ/ERSFQ. Experimental results demonstrate that our design achieves an energy efficiency of approximately 7.8 \texttimes{} 104 times higher than that of the ReRAM-based BNN framework while maintaining a similar level of model accuracy. Furthermore, when compared with superconductor-based counterparts, our framework demonstrates at least two orders of magnitude higher energy efficiency.","ACM, IEEE"
"Park, Daeyoung and Kim, Heehoon and Kim, Jinpyo and Kim, Taehyun and Lee, Jaejin",SnuQS: scaling quantum circuit simulation using storage devices,2022,10.1145/3524059.3532375,https://doi.org/10.1145/3524059.3532375,Conference paper,ICS '22: Proceedings of the 36th ACM International Conference on Supercomputing,"Since the state-of-the-art quantum computers are still noisy and error-prone, classical simulation of quantum circuits is essential in verifying/calibrating quantum computers and prototyping/debugging complex quantum algorithms. Classical simulation of large quantum systems is challenging due to its exponential increase in space and computation requirements. In this paper, we propose a full-state simulation framework, SnuQS. It exploits storage devices, such as HDDs and NVMe SSDs, to enlarge the available main memory capacity at a small cost. To achieve maximum I/O bandwidth, we propose an overlay-based memory management technique and optimization techniques. We also propose an I/O subsystem architecture that guarantees the maximum bandwidth of each storage device. We evaluate SnuQS on a 64-core CPU and 4-GPU system with 80 2TB HDDs and 10 4TB NVMe SSDs using quantum supremacy and quantum Fourier transform circuits. The experimental result indicates that SnuQS and the proposed I/O subsystem together is an effective and practical solution to scale the full-state simulation of large quantum circuits at about 300X lower cost than the DDR4 DRAM main-memory-only system.",ACM
"H\""{a}ner, Thomas and Steiger, Damian S. and Hoefler, Torsten and Troyer, Matthias",Distributed quantum computing with QMPI,2021,10.1145/3458817.3476172,https://doi.org/10.1145/3458817.3476172,Conference paper,"SC '21: Proceedings of the International Conference for High Performance Computing, Networking, Storage and Analysis","Practical applications of quantum computers require millions of physical qubits and it will be challenging for individual quantum processors to reach such qubit numbers. It is therefore timely to investigate the resource requirements of quantum algorithms in a distributed setting, where multiple quantum processors are interconnected by a coherent network. We introduce an extension of the Message Passing Interface (MPI) to enable high-performance implementations of distributed quantum algorithms. In turn, these implementations can be used for testing, debugging, and resource estimation. In addition to a prototype implementation of quantum MPI, we present a performance model for distributed quantum computing, SENDQ. The model is inspired by the classical LogP model, making it useful to inform algorithmic decisions when programming distributed quantum computers. Specifically, we consider several optimizations of two quantum algorithms for problems in physics and chemistry, and we detail their effects on performance in the SENDQ model.","ACM, IEEE"
"Schneider, Sarah and Burgholzer, Lukas and Wille, Robert",A SAT Encoding for Optimal Clifford Circuit Synthesis,2023,10.1145/3566097.3567929,https://doi.org/10.1145/3566097.3567929,Conference paper,ASPDAC '23: Proceedings of the 28th Asia and South Pacific Design Automation Conference,"Executing quantum algorithms on a quantum computer requires compilation to representations that conform to all restrictions imposed by the device. Due to devices' limited coherence times and gate fidelities, the compilation process has to be optimized as much as possible. To this end, an algorithm's description first has to be synthesized using the device's gate library. In this paper, we consider the optimal synthesis of Clifford circuits---an important subclass of quantum circuits, with various applications. Such techniques are essential to establish lower bounds for (heuristic) synthesis methods and gauging their performance. Due to the huge search space, existing optimal techniques are limited to a maximum of six qubits. The contribution of this work is twofold: First, we propose an optimal synthesis method for Clifford circuits based on encoding the task as a satisfiability (SAT) problem and solving it using a SAT solver in conjunction with a binary search scheme. The resulting tool is demonstrated to synthesize optimal circuits for up to 26 qubits---more than four times as many as the current state of the art. Second, we experimentally show that the overhead introduced by state-of-the-art heuristics exceeds the lower bound by 27 % on average. The resulting tool is publicly available at https://github.com/cda-tum/qmap.",ACM
"Chen, Mingyu and Zhang, Yu and Li, Yongshang and Wang, Zhen and Li, Jun and Li, Xiangyang",QCIR: Pattern Matching Based Universal Quantum Circuit Rewriting Framework,2022,10.1145/3508352.3549405,https://doi.org/10.1145/3508352.3549405,Conference paper,ICCAD '22: Proceedings of the 41st IEEE/ACM International Conference on Computer-Aided Design,"Due to multiple limitations of quantum computers in the NISQ era, quantum compilation efforts are required to efficiently execute quantum algorithms on NISQ devices Program rewriting based on pattern matching can improve the generalization ability of compiler optimization. However, it has rarely been explored for quantum circuit optimization, further considering physical features of target devices.In this paper, we propose a pattern-matching based quantum circuit optimization framework QCIR with a novel pattern description format, enabling the user-configured cost model and two categories of patterns, i.e., generic patterns and folding patterns. To get better compilation latency, we propose a DAG representation of quantum circuit called QCir-DAG, and QVF algorithm for subcircuit matching. We implement continuous single-qubit optimization pass constructed by QCIR, achieving 10% and 20% optimization rate for benchmarks from Qiskit and ScaffCC, respectively. The practicality of QCIR is demonstrated by execution time and experimental results on the quantum simulator and quantum devices.","ACM, IEEE"
"Bertuzzi, Amedeo and Ferrari, Davide and Manzalini, Antonio and Amoretti, Michele",Evaluation of Quantum and Hybrid Solvers for Combinatorial Optimization,2024,10.1145/3649153.3649205,https://doi.org/10.1145/3649153.3649205,Conference paper,CF '24: Proceedings of the 21st ACM International Conference on Computing Frontiers,"Academic and industrial sectors have been engaged in a fierce competition to develop quantum technologies, fueled by the explosive advancements in quantum hardware. While universal quantum computers have been shown to support up to hundreds of qubits, the scale of quantum annealers has reached three orders of magnitude (i.e., thousands of qubits). Therefore, quantum algorithms are becoming increasingly popular in a variety of fields, with optimization being one of the most prominent. This work aims to explore the topic of quantum optimization by comprehensively evaluating the technologies provided by D-Wave Systems. To do so, a model for the energy optimization of data centers is proposed as a benchmark. D-Wave quantum and hybrid solvers are compared, in order to identify the most suitable one for the considered application. To highlight its advantageous performance capabilities and associated solving potential, the selected D-Wave hybrid solver is then contrasted with CPLEX, a highly efficient classical solver.",ACM
"Smith, Kaitlin N. and Perlin, Michael A. and Gokhale, Pranav and Frederick, Paige and Owusu-Antwi, David and Rines, Richard and Omole, Victory and Chong, Frederic",Clifford-based Circuit Cutting for Quantum Simulation,2023,10.1145/3579371.3589352,https://doi.org/10.1145/3579371.3589352,Conference paper,ISCA '23: Proceedings of the 50th Annual International Symposium on Computer Architecture,"Quantum computing has potential to provide exponential speedups over classical computing for many important applications. However, today's quantum computers are in their early stages, and hardware quality issues hinder the scale of program execution. Benchmarking and simulation of quantum circuits on classical computers is therefore essential to advance the understanding of how quantum computers and programs operate, enabling both algorithm discovery that leads to high-impact quantum computation and engineering improvements that deliver to more powerful quantum systems. Unfortunately, the nature of quantum information causes simulation complexity to scale exponentially with problem size.In this paper, we debut Super.tech's SuperSim framework, a new approach for high fidelity and scalable quantum circuit simulation. SuperSim employs two key techniques for accelerated quantum circuit simulation: Clifford-based simulation and circuit cutting. Through the isolation of Clifford subcircuit fragments within a larger non-Clifford circuit, resource-efficient Clifford simulation can be invoked, leading to significant reductions in runtime. After fragments are independently executed, circuit cutting and recombination procedures allow the final output of the original circuit to be reconstructed from fragment execution results. Through the combination of these two state-of-art techniques, SuperSim is a product for quantum practitioners that allows quantum circuit evaluation to scale beyond the frontiers of current simulators. Our results show that Clifford-based circuit cutting accelerates the simulation of near-Clifford circuits, allowing 100s of qubits to be evaluated with modest runtimes.",ACM
"Groppe, Sven and Groppe, Jinghua",Optimizing Transaction Schedules on Universal Quantum Computers via Code Generation for Grover¡¯s Search Algorithm,2021,10.1145/3472163.3472164,https://doi.org/10.1145/3472163.3472164,Conference paper,IDEAS '21: Proceedings of the 25th International Database Engineering &amp; Applications Symposium,"Quantum computers are known to be efficient for solving combinatorial problems like finding optimal schedules for processing transactions in parallel without blocking. We show how Grover¡¯s search algorithm for quantum computers can be applied for finding an optimal transaction schedule via generating code from the problem instance. We compare our approach with existing approaches for traditional computers and quantum annealers in terms of preprocessing, runtime, space and code length complexity. Furthermore, we show by experiments the expected number of optimal solutions of this problem as well as suboptimal ones. With the help of an estimator of the number of solutions, we further speed up our optimizer for optimal and suboptimal transaction schedules.",ACM
"Li, Lu and Tian, Qi and Qin, Guofeng and Chen, Shuaiyu and Wang, Weijia",Compact Instruction Set Extensions for Dilithium,2024,10.1145/3643826,https://doi.org/10.1145/3643826,Journal,ACM Trans. Embed. Comput. Syst.,"Post-quantum cryptography is considered to provide security against both traditional and quantum computer attacks. Dilithium is a digital signature algorithm that derives its security from the challenge of finding short vectors in lattices. It has been selected as one of the standardizations in the NIST post-quantum cryptography project. Hardware-software co-design is a commonly adopted implementation strategy to address various implementation challenges, including limited resources, high performance, and flexibility requirements. In this study, we investigate using compact instruction set extensions (ISEs) for Dilithium, aiming to improve software efficiency with low hardware overheads. To begin with, we propose tightly coupled accelerators that are deeply integrated into the RISC-V processor. These accelerators target the most computationally demanding components in resource-constrained processors, such as polynomial generation, Number Theoretic Transform (NTT), and modular arithmetic. Next, we design a set of custom instructions that seamlessly integrate with the RISC-V base instruction formats, completing the accelerators in a compact manner. Subsequently, we implement our ISEs in a chip design for the Hummingbird E203 core and conduct performance benchmarks for Dilithium utilizing these ISEs. Additionally, we evaluate the resource consumption of the ISEs on FPGA and ASIC technologies. Compared to the reference software implementation on the RISC-V core, our co-design demonstrates a remarkable speedup factor ranging from 6.95 to 9.96. This significant improvement in performance is achieved by incorporating additional hardware resources, specifically, a 35% increase in LUTs, a 14% increase in FFs, 7 additional DSPs, and no additional RAM. Furthermore, compared to the state-of-the-art approach, our work achieves faster speed performance with a reduced circuit cost. Specifically, the usage of additional LUTs, FFs, and RAMs is reduced by 47.53%, 50.43%, and 100%, respectively. On ASIC technology, our approach demonstrates 12, 412 cell counts. Our co-design provides a better tradeoff implementation on speed performance and circuit overheads.",ACM
"Nannicini, Giacomo and Bishop, Lev S. and G\""{u}nl\""{u}k, Oktay and Jurcevic, Petar",Optimal Qubit Assignment and Routing via Integer Programming,2022,10.1145/3544563,https://doi.org/10.1145/3544563,Journal,ACM Transactions on Quantum Computing,"We consider the problem of mapping a logical quantum circuit onto a given hardware with limited 2-qubit connectivity. We model this problem as an integer linear program, using a network flow formulation with binary variables that includes the initial allocation of qubits and their routing. We consider several cost functions: an approximation of the fidelity of the circuit, its total depth, and a measure of cross-talk, all of which can be incorporated in the model. Numerical experiments on synthetic data and different hardware topologies indicate that the error rate and depth can be optimized simultaneously without significant loss. We test our algorithm on a large number of quantum volume circuits, optimizing for error rate and depth; our algorithm significantly reduces the number of CNOTs compared to Qiskit¡¯s default transpiler SABRE&nbsp;[19] and produces circuits that, when executed on hardware, exhibit higher fidelity.",ACM
"Jiang, Hui and Fu, Jianling and Xu, Ming and Deng, Yuxin and Li, Zhi-Bin",A Sample-Driven Solving Procedure for the Repeated Reachability of Quantum Continuous-time Markov Chains,2024,10.1145/3641513.3650126,https://doi.org/10.1145/3641513.3650126,Conference paper,HSCC '24: Proceedings of the 27th ACM International Conference on Hybrid Systems: Computation and Control,"Reachability analysis plays a central role in system design and verification. The reachability problem, denoted ?j¦µ, asks whether the system will meet the property ¦µ after some time in a given time interval j. Recently, it has been considered on a novel kind of real-time systems ¡ª quantum continuous-time Markov chains (QCTMCs), and embedded into the model-checking algorithm. In this paper, we further study the repeated reachability problem in QCTMCs, denoted ¡õ¦©?j¦µ, which concerns whether the system starting from each absolute time in ¦© meet the property ¦µ after some coming relative time in j. First of all, we reduce it to the real root isolation of a class of real-valued functions (exponential polynomials), whose solvability is conditional to Schanuel¡¯s conjecture being true. To speed up the procedure, we employ the strategy of sampling. The original problem is shown to be equivalent to the existence of a finite collection of satisfying samples. We then present a sample-driven procedure, which can effectively refine the sample space after each time of sampling, no matter whether the sample itself is satisfying or conflicting. The improvement on efficiency is validated by randomly generated instances. Hence the proposed method would be promising to attack the repeated reachability problems together with checking other ¦Ø -regular properties in a wide scope of real-time systems.",ACM
"Barthe, Gilles and Bela\""{\i}d, Sonia and Espitau, Thomas and Fouque, Pierre-Alain and Rossi, M\'{e}lissa and Tibouchi, Mehdi","GALACTICS: Gaussian Sampling for Lattice-Based Constant- Time Implementation of Cryptographic Signatures, Revisited",2019,10.1145/3319535.3363223,https://doi.org/10.1145/3319535.3363223,Conference paper,CCS '19: Proceedings of the 2019 ACM SIGSAC Conference on Computer and Communications Security,"In this paper, we propose a constant-time implementation of the BLISS lattice-based signature scheme. BLISS is possibly the most efficient lattice-based signature scheme proposed so far, with a level of performance on par with widely used pre-quantum primitives like ECDSA. It is only one of the few postquantum signatures to have seen real-world deployment, as part of the strongSwan VPN software suite. The outstanding performance of the BLISS signature scheme stems in large part from its reliance on discrete Gaussian distributions, which allow for better parameters and security reductions. However, that advantage has also proved to be its Achilles' heel, as discrete Gaussians pose serious challenges in terms of secure implementations. Implementations of BLISS so far have included secret-dependent branches and memory accesses, both as part of the discrete Gaussian sampling and of the essential rejection sampling step in signature generation. These defects have led to multiple devastating timing attacks, and were a key reason why BLISS was not submitted to the NIST postquantum standardization effort. In fact, almost all of the actual candidates chose to stay away from Gaussians despite their efficiency advantage, due to the serious concerns surrounding implementation security. Moreover, naive countermeasures will often not cut it: we show that a reasonable-looking countermeasure suggested in previous work to protect the BLISS rejection sampling can again be defeated using novel timing attacks, in which the timing information is fed to phase retrieval machine learning algorithm in order to achieve a full key recovery. Fortunately, we also present careful implementation techniques that allow us to describe an implementation of BLISS with complete timing attack protection, achieving the same level of efficiency as the original unprotected code, without resorting on floating point arithmetic or platform-specific optimizations like AVX intrinsics. These techniques, including a new approach to the polynomial approximation of transcendental function, can also be applied to the masking of the BLISS signature scheme, and will hopefully make more efficient and secure implementations of lattice-based cryptography possible going forward.",ACM
"Tan, Bochen and Cong, Jason",Optimal layout synthesis for quantum computing,2020,10.1145/3400302.3415620,https://doi.org/10.1145/3400302.3415620,Conference paper,ICCAD '20: Proceedings of the 39th International Conference on Computer-Aided Design,"Recent years have witnessed the fast development of quantum computing. Researchers around the world are eager to run larger and larger quantum algorithms that promise speedups impossible to any classical algorithm. However, the available quantum computers are still volatile and error-prone. Thus, layout synthesis, which transforms quantum programs to meet these hardware limitations, is a crucial step in the realization of quantum computing. In this paper, we present two synthesizers, one optimal and one approximate but nearly optimal. Although a few optimal approaches to this problem have been published, our optimal synthesizer explores a larger solution space, thus is optimal in a stronger sense. In addition, it reduces time and space complexity exponentially compared to some leading optimal approaches. The key to this success is a more efficient spacetime-based variable encoding of the layout synthesis problem as a mathematical programming problem. By slightly changing our formulation, we arrive at an approximate synthesizer that is even more efficient and outperforms some leading heuristic approaches, in terms of additional gate cost, by up to 100%, and also fidelity by up to 10x on a comprehensive set of benchmark programs and architectures. For a specific family of quantum programs named QAOA, which is deemed to be a promising application for near-term quantum computers, we further adjust the approximate synthesizer by taking commutation into consideration, achieving up to 75% reduction in depth and up to 65% reduction in additional cost compared to the tool used in a leading QAOA study.","ACM, IEEE"
"Wu, Xin-Chuan and Di, Sheng and Dasgupta, Emma Maitreyee and Cappello, Franck and Finkel, Hal and Alexeev, Yuri and Chong, Frederic T.",Full-state quantum circuit simulation by using data compression,2019,10.1145/3295500.3356155,https://doi.org/10.1145/3295500.3356155,Conference paper,"SC '19: Proceedings of the International Conference for High Performance Computing, Networking, Storage and Analysis","Quantum circuit simulations are critical for evaluating quantum algorithms and machines. However, the number of state amplitudes required for full simulation increases exponentially with the number of qubits. In this study, we leverage data compression to reduce memory requirements, trading computation time and fidelity for memory space. Specifically, we develop a hybrid solution by combining the lossless compression and our tailored lossy compression method with adaptive error bounds at each timestep of the simulation. Our approach optimizes for compression speed and makes sure that errors due to lossy compression are uncorrelated, an important property for comparing simulation output with physical machines. Experiments show that our approach reduces the memory requirement of simulating the 61-qubit Grover's search algorithm from 32 exabytes to 768 terabytes of memory on Argonne's Theta supercomputer using 4,096 nodes. The results suggest that our techniques can increase the simulation size by 2~16 qubits for general quantum circuits.",ACM
"Liu, Ji and Bello, Luciano and Zhou, Huiyang",Relaxed peephole optimization: a novel compiler optimization for quantum circuits,2021,10.1109/CGO51591.2021.9370310,https://doi.org/10.1109/CGO51591.2021.9370310,Conference paper,CGO '21: Proceedings of the 2021 IEEE/ACM International Symposium on Code Generation and Optimization,"As in classical computing, compilers play an important role in quantum computing. Quantum processors typically support a limited set of primitive operations or quantum gates and have certain hardware-related limitations. A quantum compiler is responsible for adapting a quantum program to these constraint environments and decomposing quantum gates into a sequence of the primitive ones. During the compilation process, it is also critical for the compiler to optimize the quantum circuits in order to reduce the noise in the computation results. Since the noise is introduced by operations and decoherence, reducing the gate count is the key for improving performance.In this paper, we propose a novel quantum compiler optimization, named relaxed peephole optimization (RPO) for quantum computers. RPO leverages the single-qubit state information that can be determined statically by the compiler. We define that a qubit is in a basis state when, at a given point in time, its state is either in the X-, Y-, or Z-basis (|+¡µ / |-¡µ, |L¡µ / |R¡µ and |0¡µ / |1¡µ). When basis qubits are used as inputs to quantum gates, there exist opportunities for strength reduction, which replaces quantum operations with equivalent but less expensive ones. Compared to the existing peephole optimization for quantum programs, the difference is that our proposed optimization does not require an identical unitary matrix, thereby named 'relaxed' peephole optimization. We also extend our approach to optimize the quantum gates when some input qubits are in known pure states. Both optimizations, namely the Quantum Basis-state Optimization (QBO) and the Quantum Pure-state Optimization (QPO), are implemented in the IBM's Qiskit transpiler. Our experimental results show that our proposed optimization pass is fast and effective. The circuits optimized with our compiler optimizations obtain up to 18.0% (11.7% on average) fewer CNOT gates and up to 8.2% (7.1% on average) lower transpilation time than that of the most aggressive optimization level in the Qiskit compiler. When running on real quantum computers, the success rates of 3-qubit quantum phase estimation algorithm improve by 2.30X due to the reduced gate counts.","ACM, IEEE"
"Westerhout, Tom and Chamberlain, Bradford L.",Implementing scalable matrix-vector products for the exact diagonalization methods in quantum many-body physics,2023,10.1145/3624062.3624597,https://doi.org/10.1145/3624062.3624597,Conference paper,"SC-W '23: Proceedings of the SC '23 Workshops of The International Conference on High Performance Computing, Network, Storage, and Analysis","Exact diagonalization is a well-established method for simulating small quantum systems. Its applicability is limited by the exponential growth of the Hamiltonian matrix that needs to be diagonalized. Physical symmetries are usually utilized to reduce the matrix dimension, and distributed-memory parallelism is employed to explore larger systems. This paper focuses on an implementation of the core distributed algorithms, with a special emphasis on the matrix-vector product. Instead of the conventional MPI+X paradigm, Chapel is chosen as the language in this work. We provide a comprehensive description of the algorithms and present performance and scalability tests. Our implementation outperforms the state-of-the-art MPI-based solution by a factor of 7¨C8 on 32 compute nodes or 4096 cores and scales well through 256 nodes or 32?768 cores. The implementation has 3 times fewer software lines of code than the current state of the art, but is still able to handle generic Hamiltonians.",ACM
"Stein, Samuel and Wiebe, Nathan and Ding, Yufei and Ang, James and Li, Ang",Q-BEEP: Quantum Bayesian Error Mitigation Employing Poisson Modeling over the Hamming Spectrum,2023,10.1145/3579371.3589043,https://doi.org/10.1145/3579371.3589043,Conference paper,ISCA '23: Proceedings of the 50th Annual International Symposium on Computer Architecture,"Quantum computing technology has grown rapidly in recent years, with new technologies being explored, error rates being reduced, and quantum processors' qubit capacity growing. However, near-term quantum algorithms are still unable to be induced without compounding consequential levels of noise, leading to non-trivial erroneous results. Quantum Error Correction (in-situ error mitigation) and Quantum Error Mitigation (post-induction error mitigation) are promising fields of research within the quantum algorithm scene, aiming to alleviate quantum errors. IBM recently published an article stating that Quantum Error Mitigation is the path to quantum computing usefulness. A recent work, namely HAMMER, demonstrated the existence of a latent structure regarding post-circuit induction errors when mapping to the Hamming spectrum. However, they assumed that errors occur solely in local clusters, whereas we observe that at higher average Hamming distances this structure falls away. In this work, we show that such a correlated structure is not only local but extends certain non-local clustering patterns which can be precisely described by a Poisson distribution model taking the input circuit, the device run time status (i.e., calibration statistics) and qubit topology into consideration. Using this quantum error characterizing model, we developed an iterative algorithm over the generated Bayesian network state-graph for post-induction error mitigation. Thanks to more precise modeling of the error distribution latent structure and the proposed iterative method, our Q-Beep approach provides state of the art performance and can boost circuit execution fidelity by up to 234.6% on Bernstein-Vazirani circuits and on average 71.0% on QAOA solution quality, using 16 practical IBMQ quantum processors. For other benchmarks such as those in QASMBench, a fidelity improvement of up to 17.8% is attained. Q-Beep is a light-weight post-processing technique that can be performed offline and remotely, making it a useful tool for quantum vendors to adopt and provide more reliable circuit induction results. Q-Beep is maintained at github.com/pnnl/qbeep",ACM
"Ang, James and Carini, Gabriella and Chen, Yanzhu and Chuang, Isaac and Demarco, Michael and Economou, Sophia and Eickbusch, Alec and Faraon, Andrei and Fu, Kai-Mei and Girvin, Steven and Hatridge, Michael and Houck, Andrew and Hilaire, Paul and Krsulich, Kevin and Li, Ang and Liu, Chenxu and Liu, Yuan and Martonosi, Margaret and McKay, David and Misewich, Jim and Ritter, Mark and Schoelkopf, Robert and Stein, Samuel and Sussman, Sara and Tang, Hong and Tang, Wei and Tomesh, Teague and Tubman, Norm and Wang, Chen and Wiebe, Nathan and Yao, Yongxin and Yost, Dillon and Zhou, Yiyu",ARQUIN: Architectures for Multinode Superconducting Quantum Computers,2024,10.1145/3674151,https://doi.org/10.1145/3674151,Journal,ACM Transactions on Quantum Computing,"Many proposals to scale quantum technology rely on modular or distributed designs wherein individual quantum processors, called nodes, are linked together to form one large multinode quantum computer (MNQC). One scalable method to construct an MNQC is using superconducting quantum systems with optical interconnects. However, internode gates in these systems may be two to three orders of magnitude noisier and slower than local operations. Surmounting the limitations of internode gates will require improvements in entanglement generation, use of entanglement distillation, and optimized software and compilers. Still, it remains unclear what performance is possible with current hardware and what performance algorithms require. In this article, we employ a systems analysis approach to quantify overall MNQC performance in terms of hardware models of internode links, entanglement distillation, and local architecture. We show how to navigate tradeoffs in entanglement generation and distillation in the context of algorithm performance, lay out how compilers and software should balance between local and internode gates, and discuss when noisy quantum internode links have an advantage over purely classical links. We find that a factor of 10¨C100\texttimes{} better link performance is required and introduce a research roadmap for the co-design of hardware and software towards the realization of early MNQCs. While we focus on superconducting devices with optical interconnects, our approach is general across MNQC implementations.",ACM
"Chen, Yaojian and Liu, Yong and Shi, Xinmin and Song, Jiawei and Liu, Xin and Gan, Lin and Guo, Chu and Fu, Haohuan and Gao, Jie and Chen, Dexun and Yang, Guangwen",Lifetime-Based Optimization for Simulating Quantum Circuits on a New Sunway Supercomputer,2023,10.1145/3572848.3577529,https://doi.org/10.1145/3572848.3577529,Conference paper,PPoPP '23: Proceedings of the 28th ACM SIGPLAN Annual Symposium on Principles and Practice of Parallel Programming,"High-performance classical simulator for quantum circuits, in particular the tensor network contraction algorithm, has become an important tool for the validation of noisy quantum computing. In order to address the memory limitations, the slicing technique is used to reduce the tensor dimensions, but it could also lead to additional computation overhead that greatly slows down the overall performance. This paper proposes novel lifetime-based methods to reduce the slicing overhead and improve the computing efficiency, including, an interpretation method to deal with slicing overhead, an inplace slicing strategy to find the smallest slicing set and an adaptive tensor network contraction path refiner customized for Sunway architecture. Experiments show that in most cases the slicing overhead with our inplace slicing strategy would be less than the Cotengra, which is the most used graph path optimization software at present. Finally, the resulting simulation time is reduced to 96.1s for the Sycamore quantum processor RQC, with a sustainable single-precision performance of 308.6Pflops using over 41M cores to generate 1M correlated samples, which is more than 5 times performance improvement compared to 60.4 Pflops in 2021 Gordon Bell Prize work.",ACM
"Whitaker, Tim",Quantum neuron selection: finding high performing subnetworks with quantum algorithms,2022,10.1145/3520304.3533961,https://doi.org/10.1145/3520304.3533961,Conference paper,GECCO '22: Proceedings of the Genetic and Evolutionary Computation Conference Companion,"Gradient descent methods have long been the de facto standard for training deep neural networks. Millions of training samples are fed into models with billions of parameters, which are slowly updated over hundreds of epochs. Recently, it's been shown that large, randomly initialized neural networks contain subnetworks that perform as well as fully trained models. This insight offers a promising avenue for training future neural networks by simply pruning weights from large, random models. However, this problem is combinatorically hard and classical algorithms are not efficient at finding the best subnetwork. In this paper, we explore how quantum algorithms could be formulated and applied to this neuron selection problem. We introduce several methods for local quantum neuron selection that reduce the entanglement complexity that large scale neuron selection would require, making this problem more tractable for current quantum hardware.",ACM
"Nejatollahi, Hamid and Valencia, Felipe and Banik, Subhadeep and Regazzoni, Francesco and Cammarota, Rosario and Dutt, Nikil",Synthesis of Flexible Accelerators for Early Adoption of Ring-LWE Post-quantum Cryptography,2020,10.1145/3378164,https://doi.org/10.1145/3378164,Journal,ACM Trans. Embed. Comput. Syst.,"The advent of the quantum computer makes current public-key infrastructure insecure. Cryptography community is addressing this problem by designing, efficiently implementing, and evaluating novel public-key algorithms capable of withstanding quantum computational power. Governmental agencies, such as NIST, are promoting standardization of quantum-resistant algorithms that is expected to run for 7 years. Several modern applications must maintain permanent data secrecy; therefore, they ultimately require the use of quantum-resistant algorithms. Because algorithms are still under scrutiny for eventual standardization, the deployment of the hardware implementation of quantum-resistant algorithms is still in early stages.In this article, we propose a methodology to design programmable hardware accelerators for lattice-based algorithms, and we use the proposed methodology to implement flexible and energy efficient post-quantum cache-based accelerators for NewHope, Kyber, Dilithium, Key Consensus from Lattice (KCL), and R.EMBLEM submissions to the NIST standardization contest.To the best of our knowledge, we propose the first efficient domain-specific, programmable cache-based accelerators for lattice-based algorithms. We design a single accelerator for a common kernel among various schemes with different kernel sizes, i.e., loop count, and data types. This is in contrast to the traditional approach of designing one special purpose accelerators for each scheme.We validate our methodology by integrating our accelerators into an HLS-based SoC infrastructure based on the X86 processor and evaluate overall performance. Our experiments demonstrate the suitability of the approach and allow us to collect insightful information about the performance bottlenecks and the energy efficiency of the explored algorithms. Our results provide guidelines for hardware designers, highlighting the optimization points to address for achieving the highest energy minimization and performance increase. At the same time, our proposed design allows us to specify and execute new variants of lattice-based schemes with superior energy efficiency compared to the main application processor without changing the hardware acceleration platform. For example, we manage to reduce the energy consumption up to 2.1\texttimes{} and energy-delay product (EDP) up to 5.2\texttimes{} and improve the speedup up to 2.5\texttimes{}.",ACM
"Li, Liyi and Voichick, Finn and Hietala, Kesha and Peng, Yuxiang and Wu, Xiaodi and Hicks, Michael",Verified compilation of Quantum oracles,2022,10.1145/3563309,https://doi.org/10.1145/3563309,Journal,Proc. ACM Program. Lang.,"Quantum algorithms often apply classical operations, such as arithmetic or predicate checks, over a quantum superposition of classical data; these so-called oracles are often the largest components of a quantum program. To ease the construction of efficient, correct oracle functions, this paper presents VQO, a high-assurance framework implemented with the Coq proof assistant. The core of VQO is OQASM, the oracle quantum assembly language. OQASM operations move qubits between two different bases via the quantum Fourier transform, thus admitting important optimizations, but without inducing entanglement and the exponential blowup that comes with it. OQASM¡¯s design enabled us to prove correct VQO¡¯s compilers¡ªfrom a simple imperative language called OQIMP to OQASM, and from OQASM to SQIR, a general-purpose quantum assembly language¡ªand allowed us to efficiently test properties of OQASM programs using the QuickChick property-based testing framework. We have used VQO to implement a variety of arithmetic and geometric operators that are building blocks for important oracles, including those used in Shor¡¯s and Grover¡¯s algorithms. We found that VQO¡¯s QFT-based arithmetic oracles require fewer qubits, sometimes substantially fewer, than those constructed using ¡°classical¡± gates; VQO¡¯s versions of the latter were nevertheless on par with or better than (in terms of both qubit and gate counts) oracles produced by Quipper, a state-of-the-art but unverified quantum programming platform.",ACM
"Lin, Sophia Fuhui and Sussman, Sara and Duckering, Casey and Mundada, Pranav S. and Baker, Jonathan M. and Kumar, Rohan S. and Houck, Andrew A. and Chong, Frederic T.",Let Each Quantum Bit Choose Its Basis Gates,2023,10.1109/MICRO56248.2022.00075,https://doi.org/10.1109/MICRO56248.2022.00075,Conference paper,MICRO '22: Proceedings of the 55th Annual IEEE/ACM International Symposium on Microarchitecture,"Near-term quantum computers are primarily limited by errors in quantum operations (or gates) between two quantum bits (or qubits). A physical machine typically provides a set of basis gates that include primitive 2-qubit (2Q) and 1-qubit (1Q) gates that can be implemented in a given technology. 2Q entangling gates, coupled with some 1Q gates, allow for universal quantum computation. In superconducting technologies, the current state of the art is to implement the same 2Q gate between every pair of qubits (typically an XX-or XY-type gate). This strict hardware uniformity requirement for 2Q gates in a large quantum computer has made scaling up a time and resource-intensive endeavor in the lab.We propose a radical idea - allow the 2Q basis gate(s) to differ between every pair of qubits, selecting the best entangling gates that can be calibrated between given pairs of qubits. This work aims to give quantum scientists the ability to run meaningful algorithms with qubit systems that are not perfectly uniform. Scientists will also be able to use a much broader variety of novel 2Q gates for quantum computing. We develop a theoretical framework for identifying good 2Q basis gates on ""nonstandard"" Cartan trajectories that deviate from ""standard"" trajectories like XX. We then introduce practical methods for calibration and compilation with nonstandard 2Q gates, and discuss possible ways to improve the compilation. To demonstrate our methods in a case study, we simulated both standard XY-type trajectories and faster, nonstandard trajectories using an entangling gate architecture with far-detuned transmon qubits. We identify efficient 2Q basis gates on these nonstandard trajectories and use them to compile a number of standard benchmark circuits such as QFT and QAOA. Our results demonstrate an 8x improvement over the baseline 2Q gates with respect to speed and coherence-limited gate fidelity.",ACM
"Yang, Hang and Wu, Bi and Xuan, Yongbo and Li, Qiting and Wang, Xiaofei",Progress and Prospects of Quantum Algorithms,2022,10.1145/3568364.3568379,https://doi.org/10.1145/3568364.3568379,Conference paper,WSSE '22: Proceedings of the 4th World Symposium on Software Engineering,"Quantum computers are designed to outperform standard computers by running quantum algorithms. Fields in which quantum algorithms can be applied include cryptography, search and optimization, simulation of quantum systems and solving large systems of linear equations. Here we briefly survey some known quantum algorithms, with an emphasis on a broad overview of their applications rather than their technical details. We focus to introduce the development of entire field, and provide a comprehensive and accurate understanding concerning this field, which may be helpful for interested researchers in this area.",ACM
"Ayanzadeh, Ramin and Alavisamani, Narges and Das, Poulami and Qureshi, Moinuddin",FrozenQubits: Boosting Fidelity of QAOA by Skipping Hotspot Nodes,2023,10.1145/3575693.3575741,https://doi.org/10.1145/3575693.3575741,Conference paper,"ASPLOS 2023: Proceedings of the 28th ACM International Conference on Architectural Support for Programming Languages and Operating Systems, Volume 2","Quantum Approximate Optimization Algorithm (QAOA) is one of the leading candidates for demonstrating the quantum advantage using near-term quantum computers. Unfortunately, high device error rates limit us from reliably running QAOA circuits for problems with more than a few qubits. In QAOA, the problem graph is translated into a quantum circuit such that every edge corresponds to two 2-qubit CNOT operations in each layer of the circuit. As CNOTs are extremely error-prone, the fidelity of QAOA circuits is dictated by the number of edges in the problem graph. We observe that the majority of graphs corresponding to real-world applications follow a ¡°power-law¡± distribution, where some hotspot nodes have significantly higher number of connections. We leverage this insight and propose ¡°FrozenQubits¡± that freezes the hotspot nodes or qubits and intelligently partitions the state-space of the given problem into several smaller sub-spaces, which are then solved independently. The corresponding QAOA sub-circuits are significantly less vulnerable to gate and decoherence errors due to the reduced number of CNOT operations in each sub-circuit. Unlike prior circuit-cutting approaches, FrozenQubits does not require any exponentially complex postprocessing step. Our evaluations with 5,300 QAOA circuits on eight different quantum computers from IBM show that FrozenQubits can improve the quality of solutions by 8.73x on average (and by up to 57x), albeit while utilizing 2x more quantum resources.",ACM
"Upadhyay, Suryansh and Ghosh, Swaroop",Robust and Secure Hybrid Quantum-Classical Computation on Untrusted Cloud-Based Quantum Hardware,2023,10.1145/3569562.3569569,https://doi.org/10.1145/3569562.3569569,Conference paper,HASP '22: Proceedings of the 11th International Workshop on Hardware and Architectural Support for Security and Privacy,"Quantum computers are currently accessible through a cloud-based platform that allows users to run their programs on a suite of quantum hardware. As the quantum computing ecosystem grows in popularity and utility, it is reasonable to expect more companies, including untrustworthy/untrustworthy/unreliable vendors, to begin offering quantum computers as hardware-as-a-service at various price/performance points. Since computing time on quantum hardware is expensive and the access queue may be long, users will be enticed to use less expensive but less reliable/trustworthy hardware. Less-trusted vendors may tamper with the results and/or parameters of quantum circuits, providing the user with a sub-optimal solution or incurring a cost of higher iterations. In this paper, we model and simulate adversarial tampering of input parameters and measurement outcomes on an exemplary hybrid quantum classical algorithm namely, Quantum Approximate Optimization Algorithm (QAOA). We observe a maximum performance degradation of . To achieve comparable performance with minimal parameter tampering, the user incurs a minimum cost of 20X higher iteration. We propose distributing the computation (iterations) equally among the various hardware options to ensure trustworthy computing for a mix of trusted and untrusted hardware. In the chosen performance metrics, we observe a maximum improvement of ¡Ö 30%. In addition, we propose re-initialization of the parameters after a few initial iterations to fully recover the original program performance and an intelligent run adaptive split heuristic, which allows users to identify tampered/untrustworthy hardware at runtime and allocate more iterations to the reliable hardware, resulting in a maximum improvement of ¡Ö .",ACM
"Li, Hai-Sheng and Quan, Jinhui and Song, Shuxiang and Wei, Yuxing and Qing, Li",Quantum Bilinear Interpolation Algorithms Based on Geometric Centers,2023,10.1145/3591364,https://doi.org/10.1145/3591364,Journal,ACM Transactions on Quantum Computing,"Bilinear interpolation is widely used in classical signal and image processing. Quantum algorithms have been designed for efficiently realizing bilinear interpolation. However, these quantum algorithms have limitations in circuit width and garbage outputs, which block the quantum algorithms applied to noisy intermediate-scale quantum devices. In addition, the existing quantum bilinear interpolation algorithms cannot keep the consistency between the geometric centers of the original and target images. To save the above questions, we propose quantum bilinear interpolation algorithms based on geometric centers using fault-tolerant implementations of quantum arithmetic operators. Proposed algorithms include the scaling-up and scaling-down for signals (grayscale images) and signals with three channels (color images). Simulation results demonstrate that the proposed bilinear interpolation algorithms obtain the same results as their classical counterparts with an exponential speedup. Performance analysis reveals that the proposed bilinear interpolation algorithms keep the consistency of geometric centers and significantly reduce circuit width and garbage outputs compared to the existing works.",ACM
"Paler, Alexandru",Controlling distilleries in fault-tolerant quantum circuits: problem statement and analysis towards a solution,2018,10.1145/3232195.3232224,https://doi.org/10.1145/3232195.3232224,Conference paper,NANOARCH '18: Proceedings of the 14th IEEE/ACM International Symposium on Nanoscale Architectures,"The failure susceptibility of the quantum hardware will force quantum computers to execute fault-tolerant quantum circuits. These circuits are based on quantum error correcting codes, and there is increasing evidence that one of the most practical choices is the surface code. Design methodologies of surface code based quantum circuits were focused on the layout of such circuits without emphasizing the reduced availability of hardware and its effect on the execution time. Circuit layout has not been investigated for practical scenarios, and the problem presented herein was neglected until now. For achieving fault-tolerance and implementing surface code based computations, a significant amount of computing resources (hardware and time) are necessary for preparing special quantum states in a procedure called distillation. This work introduces the problem of how distilleries (circuit portions responsible for state distillation) influence the layout of surface code protected quantum circuits, and analyses the tradeoffs for reducing the resources necessary for executing the circuits. A first algorithmic solution is presented, implemented and evaluated for addition quantum circuits.",ACM
"Li, Ang and Subasi, Omer and Yang, Xiu and Krishnamoorthy, Sriram",Density matrix quantum circuit simulation via the BSP machine on modern GPU clusters,2020,10.5555/3433701.3433718,https://dl.acm.org/doi/10.5555/3433701.3433718,Conference paper,"SC '20: Proceedings of the International Conference for High Performance Computing, Networking, Storage and Analysis","As quantum computers evolve, simulations of quantum programs on classical computers will be essential in validating quantum algorithms, understanding the effect of system noise, and designing applications for future quantum computers. In this paper, we first propose a new multi-GPU programming methodology called MG-BSP which constructs a virtual BSP machine on top of modern multi-GPU platforms, and apply this methodology to build a multi-GPU density matrix quantum simulator called DM-Sim. We propose a new formulation that can significantly reduce communication overhead, and show that this formula transformation can conserve the semantics despite noise being introduced. We build the tool-chain for the simulator to run open standard quantum assembly code, execute synthesized quantum circuits, and perform ultra-deep and large-scale simulations. We evaluated DM-Sim on several state-of-the-art multi-GPU platforms including NVIDIA's Pascal/Volta DGX-1, DGX-2, and ORNL's Summit supercomputer. In particular, we have demonstrated the simulation of one million general gates in 94 minutes on DGX-2, far deeper circuits than has been demonstrated in prior works. Our simulator is more than 10x faster with respect to the corresponding state-vector quantum simulators on GPUs and other platforms. The DM-Sim simulator is released at: http://github.com/pnnl/DM-Sim.",ACM
"McGeoch, Catherine C. and Farr\'{e",Milestones on the Quantum Utility Highway: Quantum Annealing Case Study,2023,10.1145/3625307,https://doi.org/10.1145/3625307,Journal,ACM Transactions on Quantum Computing,"We introduce quantum utility, a new approach to evaluating quantum performance that aims to capture the user experience by considering the overhead costs associated with a quantum computation. A demonstration of quantum utility by the quantum processing unit (QPU) shows that the QPU can outperform classical solvers at some tasks of interest to practitioners, when considering the costs of computational overheads. A milestone is a test of quantum utility that is restricted to a specific subset of overhead costs and input types.We illustrate this approach with a benchmark study of a D-Wave annealing-based QPU versus seven classical solvers for a variety of problems in heuristic optimization. We consider overhead costs that arise in standalone use of the D-Wave QPU (as opposed to a hybrid computation). We define three early milestones on the path to broad-scale quantum utility. Milestone 0 is the purely quantum computation with no overhead costs and is demonstrated implicitly by positive results on other milestones. We evaluate the performance of a D-Wave Advantage QPU with respect to milestones 1 and 2: For milestone 1, the QPU outperformed all classical solvers in 99% of our tests. For milestone 2, the QPU outperformed all classical solvers in 19% of our tests, and the scenarios in which the QPU found success correspond to cases where classical solvers most frequently failed.This approach of isolating subsets of overheads for separate analysis reveals distinct mechanisms in quantum versus classical performance, which explain the observed differences in patterns of success and failure. We present evidence-based arguments that these distinctions bode well for annealing quantum processors to support demonstrations of quantum utility on ever-expanding classes of inputs and with more challenging milestones in the very near future.",ACM
"Wille, Robert and Burgholzer, Lukas",MQT QMAP: Efficient Quantum Circuit Mapping,2023,10.1145/3569052.3578928,https://doi.org/10.1145/3569052.3578928,Conference paper,ISPD '23: Proceedings of the 2023 International Symposium on Physical Design,"Quantum computing is an emerging technology that has the potential to revolutionize fields such as cryptography, machine learning, optimization, and quantum simulation. However, a major challenge in the realization of quantum algorithms on actual machines is ensuring that the gates in a quantum circuit (i.e., corresponding operations) match the topology of a targeted architecture so that the circuit can be executed while, at the same time, the resulting costs (e.g., in terms of the number of additionally introduced gates, fidelity, etc.) are kept low. This is known as the quantum circuit mapping problem. This summary paper provides an overview of QMAP-an open-source tool that is part of the Munich Quantum Toolkit (MQT) and offers efficient, automated, and accessible methods for tackling this problem. To this end, the paper first briefly reviews the problem. Afterwards, it shows how QMAP can be used to efficiently map quantum circuits to quantum computing architectures from both a user's and a developer's perspective. QMAP is publicly available as open-source at https://github.com/cda-tum/qmap.",ACM
"Patel, Tirthak and Silver, Daniel and Tiwari, Devesh",Geyser: a compilation framework for quantum computing with neutral atoms,2022,10.1145/3470496.3527428,https://doi.org/10.1145/3470496.3527428,Conference paper,ISCA '22: Proceedings of the 49th Annual International Symposium on Computer Architecture,"Compared to widely-used superconducting qubits, neutral-atom quantum computing technology promises potentially better scalability and flexible arrangement of qubits to allow higher operation parallelism and more relaxed cooling requirements. The high performance computing (HPC) and architecture community is beginning to design new solutions to take advantage of neutral-atom quantum architectures and overcome its unique challenges.We propose Geyser, the first work to take advantage of the multi-qubit gates natively supported by neutral-atom quantum computers by appropriately mapping quantum circuits to three-qubit-friendly physical arrangement of qubits. Then, Geyser creates multiple logical blocks in the quantum circuit to exploit quantum parallelism and reduce the number of pulses needed to realize physical gates. These circuit blocks elegantly enable Geyser to compose equivalent circuits with three-qubit gates, even when the original program does not have any multi-qubit gates. Our evaluation results show Geyser reduces the number of operation pulses by 25%-90% and improves the algorithm's output fidelity by 25%-60% points across different algorithms.",ACM
"Zhou, Zhen and He, Debiao and Liu, Zhe and Luo, Min and Choo, Kim-Kwang Raymond",A Software/Hardware Co-Design of Crystals-Dilithium Signature Scheme,2021,10.1145/3447812,https://doi.org/10.1145/3447812,Journal,ACM Trans. Reconfigurable Technol. Syst.,"As quantum computers become more affordable and commonplace, existing security systems that are based on classical cryptographic primitives, such as RSA and Elliptic Curve Cryptography (ECC), will no longer be secure. Hence, there has been interest in designing post-quantum cryptographic (PQC) schemes, such as those based on lattice-based cryptography (LBC). The potential of LBC schemes is evidenced by the number of such schemes passing the selection of NIST PQC Standardization Process Round-3. One such scheme is the Crystals-Dilithium signature scheme, which is based on the hard module-lattice problem. However, there is no efficient implementation of the Crystals-Dilithium signature scheme. Hence, in this article, we present a compact hardware architecture containing elaborate modular multiplication units using the Karatsuba algorithm along with smart generators of address sequence and twiddle factors for NTT, which can complete polynomial addition/multiplication with the parameter setting of Dilithium in a short clock period. Also, we propose a fast software/hardware co-design implementation on Field Programmable Gate Array (FPGA) for the Dilithium scheme with a tradeoff between speed and resource utilization. Our co-design implementation outperforms a pure C implementation on a Nios-II processor of the platform Altera DE2-115, in the sense that our implementation is 11.2 and 7.4 times faster for signature and verification, respectively. In addition, we also achieve approximately 51% and 31% speed improvement for signature and verification, in comparison to the pure C implementation on processor ARM Cortex-A9 of ZYNQ-7020 platform.","ACM, Web of Science"
"Hua, Fei and Wang, Meng and Li, Gushu and Peng, Bo and Liu, Chenxu and Zheng, Muqing and Stein, Samuel and Ding, Yufei and Zhang, Eddy Z. and Humble, Travis and Li, Ang",QASMTrans: A QASM Quantum Transpiler Framework for NISQ Devices,2023,10.1145/3624062.3624222,https://doi.org/10.1145/3624062.3624222,Conference paper,"SC-W '23: Proceedings of the SC '23 Workshops of The International Conference on High Performance Computing, Network, Storage, and Analysis","The success of a quantum algorithm hinges on the ability to orchestrate a successful application induction. Detrimental overheads in mapping general quantum circuits to physically implementable routines can be the deciding factor between a successful and erroneous circuit induction. In QASMTrans, we focus on the problem of rapid circuit transpilation. Transpilation plays a crucial role in converting high-level, machine-agnostic circuits into machine-specific circuits constrained by physical topology and supported gate sets. The efficiency of transpilation continues to be a substantial bottleneck, especially when dealing with larger circuits requiring high degrees of inter-qubit interaction. QASMTrans is a high-performance C++ quantum transpiler framework that demonstrates 3-1111 \texttimes{} speedups compared to the commonly used Qiskit transpiler. We observe speedups on large dense circuits such as ¡®uccsd_n24¡¯ which require gates. QASMTrans successfully transpiles the aforementioned circuits in 7.9s, whilst Qiskit needs 502 seconds with optimization 1 and exceeds an hour of transpilation time with optimization 3. With QASMTrans providing transpiled circuits in a fraction of the time of prior transpilers, potential design space exploration, and heuristic-based transpiler design becomes substantially more tractable. QASMTrans is released at http://github.com/pnnl/qasmtrans.",ACM
"Tokuda, Ryo and Kameyama, Yukiyoshi",Generating Programs for Polynomial Multiplication with Correctness Assurance,2023,10.1145/3571786.3573017,https://doi.org/10.1145/3571786.3573017,Conference paper,PEPM 2023: Proceedings of the 2023 ACM SIGPLAN International Workshop on Partial Evaluation and Program Manipulation,"Program-generation techniques prevail in domains that need high performance, such as linear algebra, image processing, and database. Yet, it is hard to generate high-performance programs with correctness assurance, and cryptography needs both. Masuda and Kameyama proposed a DSL-based framework for implementing a program generator, an analyzer, and a formula generator, and obtained an efficient and correct implementation of Number-Theoretic Transform (NTT) that is necessary for many cryptographic algorithms. This paper advances their study in two ways. First, we develop a generation-and-analysis framework so that program generation is driven by program analysis. As a concrete result, we have found an optimization missed in previous studies. Second, we investigate whether the framework can be applied to other algorithms, including inverse NTT. By combining generated programs, we have obtained an efficient and correct implementation of polynomial multiplication, the key for several post-quantum cryptographic algorithms.",ACM
"Lao, Lingling and Browne, Dan E.",2QAN: a quantum compiler for 2-local qubit hamiltonian simulation algorithms,2022,10.1145/3470496.3527394,https://doi.org/10.1145/3470496.3527394,Conference paper,ISCA '22: Proceedings of the 49th Annual International Symposium on Computer Architecture,"Simulating quantum systems is one of the most important potential applications of quantum computers. The high-level circuit defining the simulation needs to be compiled into one that complies with hardware limitations such as qubit architecture (connectivity) and instruction (gate) set. General-purpose quantum compilers work at the gate level and have little knowledge of the mathematical properties of quantum applications, missing further optimization opportunities. Existing application-specific compilers only apply advanced optimizations in the scheduling procedure and are restricted to the CNOT or CZ gate set. In this work, we develop a compiler, named 2QAN, to optimize quantum circuits for 2-local qubit Hamiltonian simulation problems, a framework which includes the important quantum approximate optimization algorithm (QAOA). In particular, we exploit the flexibility of permuting different operators in the Hamiltonian (no matter whether they commute) and propose permutation-aware techniques for qubit routing, gate optimization and scheduling to minimize compilation overhead. 2QAN can target different architectures and different instruction sets. Compilation results on four applications (up to 50 qubits) and three quantum computers (namely, Google Sycamore, IBMQ Montreal and Rigetti Aspen) show that 2QAN outperforms state-of-the-art general-purpose compilers and application-specific compilers. Specifically, 2QAN can reduce the number of inserted SWAP gates by 11.5X, reduce overhead in hardware gate count by 68.5X, and reduce overhead in circuit depth by 21X. Experimental results on the Montreal device demonstrate that benchmarks compiled by 2QAN achieve the highest fidelity.",ACM
"Lin, Yu-Cheng and Wang, Chuan-Chi and Tu, Chia-Heng and Hung, Shih-Hao",Towards Optimizations of Quantum Circuit Simulation for Solving Max-Cut Problems with QAOA,2024,10.1145/3605098.3635897,https://doi.org/10.1145/3605098.3635897,Conference paper,SAC '24: Proceedings of the 39th ACM/SIGAPP Symposium on Applied Computing,"Quantum approximate optimization algorithm (QAOA) is one of the popular quantum algorithms that are used to solve combinatorial optimization problems via approximations. QAOA is able to be evaluated on both physical and virtual quantum computers simulated by classical computers, with virtual ones being favored for their noise-free feature and availability. Nevertheless, performing QAOA on virtual quantum computers suffers from a slow simulation speed for solving combinatorial optimization problems which require large-scale quantum circuit simulation (QCS). In this paper, we propose techniques to accelerate QCS for QAOA using mathematical optimizations to compress quantum operations, incorporating efficient bitwise operations to further lower the computational complexity, and leveraging different levels of parallelisms from modern multi-core processors, with a study case to show the effectiveness on solving max-cut problems. The experimental results reveal substantial performance improvements, surpassing a state-of-the-art simulator, QuEST, by a factor of 17 on a virtual quantum computer running on a 16-core, 32-thread AMD Ryzen 9 5950X processor. We believe that this work opens up new possibilities for accelerating various QAOA applications.",ACM
"Schoenberger, Daniel and Hillmich, Stefan and Brandl, Matthias and Wille, Robert",Using Boolean Satisfiability for Exact Shuttling in Trapped-Ion Quantum Computers,2024,10.1109/ASP-DAC58780.2024.10473902,https://doi.org/10.1109/ASP-DAC58780.2024.10473902,Conference paper,ASPDAC '24: Proceedings of the 29th Asia and South Pacific Design Automation Conference,"Trapped ions are a promising technology for building scalable quantum computers. Not only can they provide a high qubit quality, but they also enable modular architectures, referred to as Quantum Charge Coupled Device (QCCD) architecture. Within these devices, ions can be shuttled (moved) throughout the trap and through different dedicated zones, e.g., a memory zone for storage and a processing zone for the actual computation. However, this movement incurs a cost in terms of required time steps, which increases the probability of decoherence, and, thus, should be minimized. In this paper, we propose a formalization of the possible movements in ion traps via Boolean satisfiability. This formalization allows for determining the minimal number of time steps needed for a given quantum algorithm and device architecture, hence reducing the decoherence probability. An empirical evaluation confirms that---using the proposed approach---minimal results (i.e., the lower bound) can be determined for the first time. An open-source implementation of the proposed approach is publicly available at https://github.com/cda-tum/mqt-ion-shuttler.",ACM
"Kittelmann, Florian and Sulimov, Pavel and Stockinger, Kurt",QardEst: Using Quantum Machine Learning for Cardinality Estimation of Join Queries,2024,10.1145/3665225.3665444,https://doi.org/10.1145/3665225.3665444,Conference paper,Q-Data '24: Proceedings of the 1st Workshop on Quantum Computing and Quantum-Inspired Technology for Data-Intensive Systems and Applications,"Classical and learned query optimizers (LQOs) use cardinality estimations as one of the critical inputs for query planning. Thus, accurately predicting the cardinality of arbitrary queries plays a vital role in query optimization. A recent boom in novel deep learning methods stimulated not only the rise of LQOs but also contributed to the appearance of learned cardinality estimators (LCEs). However, the majority of them are based on classical neural networks, ignoring that multivariate correlations between attributes across different tables could be naturally represented via entanglements in quantum circuits. In this paper, we introduce QardEst - Quantum Cardinality Estimator - a novel quantum neural network approach to estimate the cardinality of join queries. Our experiments conducted with a similar number of trainable parameters suggest that quantum neural networks executed on a quantum simulator outperform classical neural networks in terms of mean squared error as well as the q-error.",ACM
"Meuli, Giulia and Soeken, Mathias and Roetteler, Martin and H\""{a}ner, Thomas",Enabling accuracy-aware Quantum compilers using symbolic resource estimation,2020,10.1145/3428198,https://doi.org/10.1145/3428198,Journal,Proc. ACM Program. Lang.,"Approximation errors must be taken into account when compiling quantum programs into a low-level gate set. We present a methodology that tracks such errors automatically and then optimizes accuracy parameters to guarantee a specified overall accuracy while aiming to minimize the implementation cost in terms of quantum gates. The core idea of our approach is to extract functions that specify the optimization problem directly from the high-level description of the quantum program. Then, custom compiler passes optimize these functions, turning them into (near-)symbolic expressions for (1) the total error and (2) the implementation cost (e.g., total quantum gate count). All unspecified parameters of the quantum program will show up as variables in these expressions, including accuracy parameters. After solving the corresponding optimization problem, a circuit can be instantiated from the found solution. We develop two prototype implementations, one in C++ based on Clang/LLVM, and another using the Q# compiler infrastructure. We benchmark our prototypes on typical quantum computing programs, including the quantum Fourier transform, quantum phase estimation, and Shor's algorithm.",ACM
"Park, Sunghye and Kim, Daeyeon and Kweon, Minhyuk and Sim, Jae-Yoon and Kang, Seokhyeong",A fast and scalable qubit-mapping method for noisy intermediate-scale quantum computers,2022,10.1145/3489517.3530402,https://doi.org/10.1145/3489517.3530402,Conference paper,DAC '22: Proceedings of the 59th ACM/IEEE Design Automation Conference,"This paper presents an efficient qubit-mapping method that redesigns a quantum circuit to overcome the limitations of qubit connectivity. We propose a recursive graph-isomorphism search to generate the scalable initial mapping. In the main mapping, we use an adaptive look-ahead window search to resolve the connectivity constraint within a short runtime. Compared with the state-of-the-art method [15], our proposed method reduced the number of additional gates by 23% on average and the runtime by 68% for the three largest benchmark circuits. Furthermore, our method improved circuit stability by reducing the circuit depth and thus can be a step forward towards fault tolerance.",ACM
"Lopez-Valdivieso, Jonathan and Cumplido, Rene",Design and Implementation of Hardware-Software Architecture Based on Hashes for SPHINCS+,2024,10.1145/3653459,https://doi.org/10.1145/3653459,Journal,ACM Trans. Reconfigurable Technol. Syst.,"Advances in quantum computing have posed a future threat to today¡¯s cryptography. With the advent of these quantum computers, security could be compromised. Therefore, the National Institute of Standards and Technology (NIST) has issued a request for proposals to standardize algorithms for post-quantum cryptography (PQC), which is considered difficult to solve for both classical and quantum computers. Among the proposed technologies, the most popular choices are lattice-based (shortest vector problem) and hash-based approaches. Other important categories are public key cryptography (PKE) and digital signatures. Within the realm of digital signatures lies SPHINCS+. However, there are few implementations of this scheme in hardware architectures. In this article, we present a hardware-software architecture for the SPHINCS+ scheme. We utilized a free RISC-V (Reduced Instruction Set Computer) processor synthesized on a Field Programmable Gate Array (FPGA), primarily integrating two accelerator modules for Keccak-1600 and the Haraka hash function. Additionally, modifications were made to the processor to accommodate the execution of these added modules. Our implementation yielded a 15-fold increase in performance with the SHAKE-256 function and nearly 90-fold improvement when using Haraka, compared to the reference software. Moreover, it is more compact compared to related works. This implementation was realized on a Xilinx FPGA Arty S7: Spartan-7.",ACM
"Cuomo, Daniele and Caleffi, Marcello and Krsulich, Kevin and Tramonto, Filippo and Agliardi, Gabriele and Prati, Enrico and Cacciapuoti, Angela Sara",Optimized Compiler for Distributed Quantum Computing,2023,10.1145/3579367,https://doi.org/10.1145/3579367,Journal,ACM Transactions on Quantum Computing,"Practical distributed quantum computing requires the development of efficient compilers, able to make quantum circuits compatible with some given hardware constraints. This problem is known to be tough, even for local computing. Here, we address it on distributed architectures. As generally assumed in this scenario, telegates represent the fundamental remote (inter-processor) operations. Each telegate consists of several tasks: (i) entanglement generation and distribution, (ii) local operations, and (iii) classical communications. Entanglement generations and distribution is an expensive resource, as it is time-consuming. To mitigate its impact, we model an optimization problem that combines running-time minimization with the usage of distributed entangled states. Specifically, we formulated the distributed compilation problem as a dynamic network flow. To enhance the solution space, we extend the formulation, by introducing a predicate that manipulates the circuit given in input and parallelizes telegate tasks.To evaluate our framework, we split the problem into three sub-problems, and solve it by means of an approximation routine. Experiments demonstrate that the run-time is resistant to the problem size scaling. Moreover, we apply the proposed algorithm to compile circuits under different topologies, showing that topologies with a higher ratio between edges and nodes give rise to shallower circuits.",ACM
"Rajakumar, Joel and Golden, John and B\""{a}rtschi, Andreas and Eidenbenz, Stephan",Trainability Barriers in Low-Depth QAOA Landscapes,2024,10.1145/3649153.3649204,https://doi.org/10.1145/3649153.3649204,Conference paper,CF '24: Proceedings of the 21st ACM International Conference on Computing Frontiers,"The Quantum Alternating Operator Ansatz (QAOA) is a prominent variational quantum algorithm for solving combinatorial optimization problems. Its effectiveness depends on identifying input parameters that yield high-quality solutions. However, understanding the complexity of training QAOA remains an under-explored area. Previous results have given analytical performance guarantees for a small, fixed number of parameters. At the opposite end of the spectrum, barren plateaus are likely to emerge at ¦¸ (n) parameters for n qubits. In this work, we study the difficulty of training in the intermediate regime, which is the focus of most current numerical studies and near-term hardware implementations. Through extensive numerical analysis of the quality and quantity of local minima, we argue that QAOA landscapes can exhibit a superpolynomial growth in the number of low-quality local minima even when the number of parameters scales logarithmically with n. This means that the common technique of gradient descent from randomly initialized parameters is doomed to fail beyond small n, and emphasizes the need for good initial guesses of the optimal parameters.",ACM
"Zou, Xiaofeng and Peng, Yuanxi and Zhang, Qing",Design and Implementation of a Compiler Supporting RISC-V Custom Cryptographic and Vector Instructions,2023,10.1145/3627915.3628090,https://doi.org/10.1145/3627915.3628090,Conference paper,CSAE '23: Proceedings of the 7th International Conference on Computer Science and Application Engineering,"Post-quantum cryptographic algorithms capable of resisting quantum computing attacks have received increasing attention in recent years, especially lattice-based cryptographic algorithms have become mainstream. Since their specialization and complex computation, the cryptographic computation is inefficient on general-purpose processors. In order to improve the performance of the processor in post-quantum cryptography computing, we have extended a set of cryptographic and vector instruction sets for the CRYSTALS-Kyber algorithm, and implemented support for custom cryptographic and vector instructions based on the open-source toolchain. These efforts can realize the compilation and disassembly of the CRYSTALS-Kyber encryption/decryption algorithm programs, and optimized the performance of the compilation. This paper mainly introduces how to design an extended instruction set based on the target algorithm and enable the compiler to support these instructions. Compared to the situation before extending custom instructions, the total number of instructions for key generation, encryption, and decryption assembly programs has decreased by 3651 times, and the total number of execution cycles has decreased by 2195 times.",ACM
"Gokhale, Pranav and Ding, Yongshan and Propson, Thomas and Winkler, Christopher and Leung, Nelson and Shi, Yunong and Schuster, David I. and Hoffmann, Henry and Chong, Frederic T.",Partial Compilation of Variational Algorithms for Noisy Intermediate-Scale Quantum Machines,2019,10.1145/3352460.3358313,https://doi.org/10.1145/3352460.3358313,Conference paper,MICRO '52: Proceedings of the 52nd Annual IEEE/ACM International Symposium on Microarchitecture,"Quantum computing is on the cusp of reality with Noisy Intermediate-Scale Quantum (NISQ) machines currently under development and testing. Some of the most promising algorithms for these machines are variational algorithms that employ classical optimization coupled with quantum hardware to evaluate the quality of each candidate solution. Recent work used GRadient Descent Pulse Engineering (GRAPE) to translate quantum programs into highly optimized machine control pulses, resulting in a significant reduction in the execution time of programs. This is critical, as quantum machines can barely support the execution of short programs before failing.However, GRAPE suffers from high compilation latency, which is untenable in variational algorithms since compilation is interleaved with computation. We propose two strategies for partial compilation, exploiting the structure of variational circuits to pre-compile optimal pulses for specific blocks of gates. Our results indicate significant pulse speedups ranging from 1.5x-3x in typical benchmarks, with only a small fraction of the compilation latency of GRAPE.",ACM
"Xu, Mingkuan and Li, Zikun and Padon, Oded and Lin, Sina and Pointing, Jessica and Hirth, Auguste and Ma, Henry and Palsberg, Jens and Aiken, Alex and Acar, Umut A. and Jia, Zhihao",Quartz: superoptimization of Quantum circuits,2022,10.1145/3519939.3523433,https://doi.org/10.1145/3519939.3523433,Conference paper,PLDI 2022: Proceedings of the 43rd ACM SIGPLAN International Conference on Programming Language Design and Implementation,"Existing quantum compilers optimize quantum circuits by applying circuit transformations designed by experts. This approach requires significant manual effort to design and implement circuit transformations for different quantum devices, which use different gate sets, and can miss optimizations that are hard to find manually. We propose Quartz, a quantum circuit superoptimizer that automatically generates and verifies circuit transformations for arbitrary quantum gate sets. For a given gate set, Quartz generates candidate circuit transformations by systematically exploring small circuits and verifies the discovered transformations using an automated theorem prover. To optimize a quantum circuit, Quartz uses a cost-based backtracking search that applies the verified transformations to the circuit. Our evaluation on three popular gate sets shows that Quartz can effectively generate and verify transformations for different gate sets. The generated transformations cover manually designed transformations used by existing optimizers and also include new transformations. Quartz is therefore able to optimize a broad range of circuits for diverse gate sets, outperforming or matching the performance of hand-tuned circuit optimizers.",ACM
"Codognet, Philippe",A Constraint Programming Approach for QUBO Solving and Quantum Annealing,2024,10.1145/3660829.3660850,https://doi.org/10.1145/3660829.3660850,Conference paper,"Programming '24: Companion Proceedings of the 8th International Conference on the Art, Science, and Engineering of Programming","Quantum Annealing is an alternative type of computation in which problems are encoded in quantum Hamiltonians (energy functions) and quantum dynamics is used to find solutions (ground states of minimal energy). Quantum computers such as the D-Wave systems are indeed implementing those ideas in hardware, as well as ""quantum-inspired"" devices based on classical electronics such as Fujitsu¡¯s Digital Annealing Unit. All those systems use the same modeling language: Quadratic Unconstrained Binary Optimization (QUBO). However, QUBO is a low-level language and for modeling combinatorial problems such as constraint satisfaction and constrained optimization problems, we need to introduce higher-level abstractions in order to define complex constraints. We present in this paper an experience report on the use of a constraint-based methodology coming from the Constraint Programming paradigm for solving combinatorial problems by quantum computing, in particular for systems based on quantum annealing. We give a general overview of our recent works on Quantum Annealing and QUBO modeling [17, 19, 20, 21, 23, 44] and try to formulate the lessons learned from these experiments and possible research directions.",ACM
"Angara, Prashanti Priya and Stege, Ulrike and M\""{u}ller, Hausi A. and Bozzo-Rey, Mehdi",Hybrid quantum-classical problem solving in the NISQ era,2020,10.5555/3432601.3432634,https://dl.acm.org/doi/10.5555/3432601.3432634,Conference paper,CASCON '20: Proceedings of the 30th Annual International Conference on Computer Science and Software Engineering,"Quantum computing has evolved from a field of scientific research to a quantum technology industry. Much progress is still needed to solve real-world problems with quantum technology and achieve quantum advantage. Industries, governments, and universities are experimenting with advanced quantum computing technologies to become quantum ready. One way forward is to combine quantum and classical approaches to form hybrid models, algorithms, and architectures to overcome the limitations of NISQ systems for near-term quantum computations. Many algorithm design, data management, and software engineering challenges have to be addressed for practical hybrid development including problem decomposition, variational circuit design, tool integration, and debugging. This paper presents algorithmic patterns and software infrastructures appearing in the literature for practical hybrid quantum problem solving and software development for selected application domains. Hybrid approaches provide significant opportunities for HPC centers and application developers to tackle hard problems that have been considered intractable using merely classical approaches. The most promising hybrid algorithms and architectures provide an excellent avenue for developers to scale quantum applications gradually and for educators to train the workforce incrementally.",ACM
"Hillmich, Stefan and Zulehner, Alwin and Kueng, Richard and Markov, Igor L. and Wille, Robert",Approximating Decision Diagrams for Quantum Circuit Simulation,2022,10.1145/3530776,https://doi.org/10.1145/3530776,Journal,ACM Transactions on Quantum Computing,"Quantum computers promise to solve important problems faster than conventional computers ever could. Underneath is a fundamentally different computational primitive that introduces new challenges for the development of software tools that aid designers of corresponding quantum algorithms. The different computational primitives render classical simulation of quantum circuits particularly challenging. While the logic simulation of conventional circuits is comparatively simple with linear complexity with respect to the number of gates, quantum circuit simulation has to deal with the exponential memory requirements to represent quantum states on non-quantum hardware with respect to the number of qubits. Decision Diagrams&nbsp;(DDs) address this challenge through exploitation of redundancies in matrices and vectors to provide significantly more compact representations in many cases. Moreover, the probabilistic nature of quantum computations enables another angle to tackle the complexity: Quantum algorithms are resistant to some degree against small inaccuracies in the quantum state as these only lead to small changes in the outcome probabilities. We propose to exploit this resistance against (small) errors to gain even more compact decision diagrams. In this work, we investigate the potential of approximation in quantum circuit simulation in detail. To this end, we first present four dedicated schemes that exploit the error resistance and efficiently approximate quantum states represented by decision diagrams. Subsequently, we propose two simulation strategies that utilize those approximations schemes in order to improve the efficiency of DD-based quantum circuit simulation, while, at the same time, allowing the user to control the resulting degradation in accuracy. We empirically show that the proposed approximation schemes reduce the size of decision diagrams substantially and also analytically prove the effect of multiple approximations on the attained accuracy. Eventually, this enables speed-ups of the resulting approximate quantum circuit simulation of up to several orders of magnitudes¡ªagain, while controlling the fidelity of the result.",ACM
"Nishio, Shin and Pan, Yulu and Satoh, Takahiko and Amano, Hideharu and Meter, Rodney Van",Extracting Success from IBM¡¯s 20-Qubit Machines Using Error-Aware Compilation,2020,10.1145/3386162,https://doi.org/10.1145/3386162,Journal,J. Emerg. Technol. Comput. Syst.,"NISQ (Noisy, Intermediate-Scale Quantum) computing requires error mitigation to achieve meaningful computation. Our compilation tool development focuses on the fact that the error rates of individual qubits are not equal, with a goal of maximizing the success probability of real-world subroutines such as an adder circuit. We begin by establishing a metric for choosing among possible paths and circuit alternatives for executing gates between variables placed far apart within the processor, and test our approach on two IBM 20-qubit systems named Tokyo and Poughkeepsie. We find that a single-number metric describing the fidelity of individual gates is a useful but imperfect guide.Our compiler uses this subsystem and maps complete circuits onto the machine using a beam search-based heuristic that will scale as processor and program sizes grow. To evaluate the whole compilation process, we compiled and executed adder circuits, then calculated the Kullback¨CLeibler divergence (KL-divergence, a measure of the distance between two probability distributions). For a circuit within the capabilities of the hardware, our compilation increases estimated success probability and reduces KL-divergence relative to an error-oblivious placement.",ACM
"Smith, Kaitlin N. and Ravi, Gokul Subramanian and Murali, Prakash and Baker, Jonathan M. and Earnest, Nathan and Javadi-Cabhari, Ali and Chong, Frederic T.",TimeStitch: Exploiting Slack to Mitigate Decoherence in Quantum Circuits,2022,10.1145/3548778,https://doi.org/10.1145/3548778,Journal,ACM Transactions on Quantum Computing,"Quantum systems have the potential to demonstrate significant computational advantage, but current quantum devices suffer from the rapid accumulation of error that prevents the storage of quantum information over extended periods. The unintentional coupling of qubits to their environment and each other adds significant noise to computation, and improved methods to combat decoherence are required to boost the performance of quantum algorithms on real machines. While many existing techniques for mitigating error rely on adding extra gates to the circuit&nbsp;[13, 20, 56], calibrating new gates&nbsp;[50], or extending a circuit¡¯s runtime&nbsp;[32], this article¡¯s primary contribution leverages the gates already present in a quantum program without extending circuit duration. We exploit circuit slack for single-qubit gates that occur in idle windows, scheduling the gates such that their timing can counteract some errors.Spin-echo corrections that mitigate decoherence on idling qubits act as inspiration for this work. Theoretical models, however, fail to capture all sources of noise in Noisy Intermediate Scale Quantum devices, making practical solutions necessary that better minimize the impact of unpredictable errors in quantum machines. This article presents TimeStitch: a novel framework that pinpoints the optimum execution schedules for single-qubit gates within quantum circuits. TimeStitch, implemented as a compilation pass, leverages the reversible nature of quantum computation to boost the success of circuits on real quantum machines. Unlike past approaches that apply reversibility properties to improve quantum circuit execution&nbsp;[35], TimeStitch amplifies fidelity without violating critical path frontiers in either the slack tuning procedures or the final rescheduled circuit. On average, compared to a state-of-the-art baseline, a practically constrained TimeStitch achieves a mean 38% relative improvement in success rates, with a maximum of 106%, while observing bounds on circuit depth. When unconstrained by depth criteria, TimeStitch produces a mean relative fidelity increase of 50% with a maximum of 256%. Finally, when TimeStitch intelligently leverages periodic dynamical decoupling within its scheduling framework, a mean 64% improvement is observed over the baseline, relatively outperforming stand-alone dynamical decoupling by 19%, with a maximum of 287%.",ACM
"Rasch, Ari and Schulze, Richard and Steuwer, Michel and Gorlatch, Sergei",Efficient Auto-Tuning of Parallel Programs with Interdependent Tuning Parameters via Auto-Tuning Framework (ATF),2021,10.1145/3427093,https://doi.org/10.1145/3427093,Journal,ACM Trans. Archit. Code Optim.,"Auto-tuning is a popular approach to program optimization: it automatically finds good configurations of a program¡¯s so-called tuning parameters whose values are crucial for achieving high performance for a particular parallel architecture and characteristics of input/output data. We present three new contributions of the Auto-Tuning Framework (ATF), which enable a key advantage in general-purpose auto-tuning: efficiently optimizing programs whose tuning parameters have interdependencies among them. We make the following contributions to the three main phases of general-purpose auto-tuning: (1) ATF generates the search space of interdependent tuning parameters with high performance by efficiently exploiting parameter constraints; (2) ATF stores such search spaces efficiently in memory, based on a novel chain-of-trees search space structure; (3) ATF explores these search spaces faster, by employing a multi-dimensional search strategy on its chain-of-trees search space representation. Our experiments demonstrate that, compared to the state-of-the-art, general-purpose auto-tuning frameworks, ATF substantially improves generating, storing, and exploring the search space of interdependent tuning parameters, thereby enabling an efficient overall auto-tuning process for important applications from popular domains, including stencil computations, linear algebra routines, quantum chemistry computations, and data mining algorithms.",ACM
"Huang, Yipeng and Holtzen, Steven and Millstein, Todd and Van den Broeck, Guy and Martonosi, Margaret",Logical abstractions for noisy variational Quantum algorithm simulation,2021,10.1145/3445814.3446750,https://doi.org/10.1145/3445814.3446750,Conference paper,ASPLOS '21: Proceedings of the 26th ACM International Conference on Architectural Support for Programming Languages and Operating Systems,"Due to the unreliability and limited capacity of existing quantum computer prototypes, quantum circuit simulation continues to be a vital tool for validating next generation quantum computers and for studying variational quantum algorithms, which are among the leading candidates for useful quantum computation. Existing quantum circuit simulators do not address the common traits of variational algorithms, namely: 1) their ability to work with noisy qubits and operations, 2) their repeated execution of the same circuits but with different parameters, and 3) the fact that they sample from circuit final wavefunctions to drive a classical optimization routine. We present a quantum circuit simulation toolchain based on logical abstractions targeted for simulating variational algorithms. Our proposed toolchain encodes quantum amplitudes and noise probabilities in a probabilistic graphical model, and it compiles the circuits to logical formulas that support efficient repeated simulation of and sampling from quantum circuits for different parameters. Compared to state-of-the-art state vector and density matrix quantum circuit simulators, our simulation approach offers greater performance when sampling from noisy circuits with at least eight to 20 qubits and with around 12 operations on each qubit, making the approach ideal for simulating near-term variational quantum algorithms. And for simulating noise-free shallow quantum circuits with 32 qubits, our simulation approach offers a 66\texttimes{} reduction in sampling cost versus quantum circuit simulation techniques based on tensor network contraction.",ACM
"Das, Poulami and Tannu, Swamit and Dangwal, Siddharth and Qureshi, Moinuddin",ADAPT: Mitigating Idling Errors in Qubits via Adaptive Dynamical Decoupling,2021,10.1145/3466752.3480059,https://doi.org/10.1145/3466752.3480059,Conference paper,MICRO '21: Proceedings of the 54th Annual IEEE/ACM International Symposium on Microarchitecture,"The fidelity of applications on near-term quantum computers is limited by hardware errors. In addition to errors that occur during gate and measurement operations, a qubit is susceptible to idling errors, which occur when the qubit is idle and not actively undergoing any operations. To mitigate idling errors, prior works in the quantum devices community have proposed Dynamical Decoupling (DD), that reduces stray noise on idle qubits by continuously executing a specific sequence of single-qubit operations that effectively behave as an identity gate. Unfortunately, existing DD protocols have been primarily studied for individual qubits and their efficacy at the application-level is not yet fully understood. Our experiments show that naively enabling DD for every idle qubit does not necessarily improve fidelity. While DD reduces the idling error-rates for some qubits, it increases the overall error-rate for others due to the additional operations of the DD protocol. Furthermore, idling errors are program-specific and the set of qubits that benefit from DD changes with each program. To enable robust use of DD, we propose Adaptive Dynamical Decoupling (ADAPT), a software framework that estimates the efficacy of DD for each qubit combination and judiciously applies DD only to the subset of qubits that provide the most benefit. ADAPT employs a Decoy Circuit, which is structurally similar to the original program but with a known solution, to identify the DD sequence that maximizes the fidelity. To avoid the exponential search of all possible DD combinations, ADAPT employs a localized algorithm that has linear complexity in the number of qubits. Our experiments on IBM quantum machines (with 16-27 qubits) show that ADAPT improves the application fidelity by 1.86x on average and up-to 5.73x compared to no DD and by 1.2x compared to DD on all qubits.",ACM
"Alam, Mahabubul and Kundu, Satwik and Ghosh, Swaroop",Knowledge Distillation in Quantum Neural Network Using Approximate Synthesis,2023,10.1145/3566097.3567877,https://doi.org/10.1145/3566097.3567877,Conference paper,ASPDAC '23: Proceedings of the 28th Asia and South Pacific Design Automation Conference,"Recent assertions of a potential advantage of Quantum Neural Network (QNN) for specific Machine Learning (ML) tasks have sparked the curiosity of a sizable number of application researchers. The parameterized quantum circuit (PQC), a major building block of a QNN, consists of several layers of single-qubit rotations and multi-qubit entanglement operations. The optimum number of PQC layers for a particular ML task is generally unknown. A larger network often provides better performance in noiseless simulations. However, it may perform poorly on hardware compared to a shallower network. Because the amount of noise varies amongst quantum devices, the optimal depth of PQC can vary significantly. Additionally, the gates chosen for the PQC may be suitable for one type of hardware but not for another due to compilation overhead. This makes it difficult to generalize a QNN design to wide range of hardware and noise levels. An alternate approach is to build and train multiple QNN models targeted for each hardware which can be expensive. To circumvent these issues, we introduce the concept of knowledge distillation in QNN using approximate synthesis. The proposed approach will create a new QNN network with (i) a reduced number of layers or (ii) a different gate set without having to train it from scratch. Training the new network for a few epochs can compensate for the loss caused by approximation error. Through empirical analysis, we demonstrate ¡Ö71.4% reduction in circuit layers, and still achieve ¡Ö16.2% better accuracy under noise.",ACM
"H\""{a}ner, Thomas and Steiger, Damian S.",0.5 petabyte simulation of a 45-qubit quantum circuit,2017,10.1145/3126908.3126947,https://doi.org/10.1145/3126908.3126947,Conference paper,"SC '17: Proceedings of the International Conference for High Performance Computing, Networking, Storage and Analysis","Near-term quantum computers will soon reach sizes that are challenging to directly simulate, even when employing the most powerful supercomputers. Yet, the ability to simulate these early devices using classical computers is crucial for calibration, validation, and benchmarking. In order to make use of the full potential of systems featuring multi- and many-core processors, we use automatic code generation and optimization of compute kernels, which also enables performance portability. We apply a scheduling algorithm to quantum supremacy circuits in order to reduce the required communication and simulate a 45-qubit circuit on the Cori II super-computer using 8, 192 nodes and 0.5 petabytes of memory. To our knowledge, this constitutes the largest quantum circuit simulation to this date. Our highly-tuned kernels in combination with the reduced communication requirements allow an improvement in time-to-solution over state-of-the-art simulations by more than an order of magnitude at every scale.","ACM, IEEE"
"Chicano, Francisco and Dahi, Zakaria and Luque, Gabriel",An Efficient QAOA via a Polynomial QPU-Needless Approach,2023,10.1145/3583133.3596409,https://doi.org/10.1145/3583133.3596409,Conference paper,GECCO '23 Companion: Proceedings of the Companion Conference on Genetic and Evolutionary Computation,"The Quantum Approximate Optimization Algorithm (QAOA) is a hybrid quantum algorithm described as ansatzes that represent both the problem and the mixer Hamiltonians. Both are parameterizable unitary transformations executed on a quantum machine/simulator and whose parameters are iteratively optimized using a classical device to optimize the problem's expectation value. To do so, in each QAOA iteration, most of the literature uses a quantum machine/simulator to measure the QAOA outcomes. However, this poses a severe bottleneck considering that quantum machines are hardly constrained (e.g. long queuing, limited qubits, etc.), likewise, quantum simulation also induces exponentially-increasing memory usage when dealing with large problems requiring more qubits. These limitations make today's QAOA implementation impractical since it is hard to obtain good solutions with a reasonably-acceptable time/resources. Considering these facts, this work presents a new approach with two main contributions, including (I) removing the need for accessing quantum devices or large-sized classical machines during the QAOA optimization phase, and (II) ensuring that when dealing with some k-bounded pseudo-Boolean problems, optimizing the exact problem's expectation value can be done in polynomial time using a classical computer.",ACM
"Malina, Lukas and Dobias, Patrik and Hajny, Jan and Choo, Kim-Kwang Raymond",On Deploying Quantum-Resistant Cybersecurity in Intelligent Infrastructures,2023,10.1145/3600160.3605038,https://doi.org/10.1145/3600160.3605038,Conference paper,"ARES '23: Proceedings of the 18th International Conference on Availability, Reliability and Security","As quantum-safe algorithms are increasingly implemented in security protocols used in current and emerging digital services, there is also a corresponding need to map the current state of security protocols and applications and their preparedness for the post-quantum era. In this paper, we review current security recommendations, existing security libraries, and the support of Post-Quantum Cryptography (PQC) in widely-used security protocols. We also present a practical assessment of recently selected PQC algorithms by the National Institute of Standards and Technologies (NIST) PQC standardization on typical platforms that can be deployed in intelligent infrastructures (e.g., smartphones and single-boards), and recently recommended hash-based signatures for software/firmware signing. Finally, we discuss how incoming post-quantum migration affects selected areas in intelligent infrastructures.",ACM
"Hong, Xin and Feng, Yuan and Li, Sanjiang and Ying, Mingsheng",Equivalence Checking of Dynamic Quantum Circuits,2022,10.1145/3508352.3549479,https://doi.org/10.1145/3508352.3549479,Conference paper,ICCAD '22: Proceedings of the 41st IEEE/ACM International Conference on Computer-Aided Design,"Despite the rapid development of quantum computing these years, state-of-the-art quantum devices still contain only a limited number of qubits. One possible way to execute more realistic algorithms in near-term quantum devices is to employ dynamic quantum circuits (DQCs). In DQCs, measurements can happen during the circuit, and their outcomes can be processed with classical computers and used to control other parts of the circuit. This technique can help significantly reduce the qubit resources required to implement a quantum algorithm. In this paper, we give a formal definition of DQCs and then characterise their functionality in terms of ensembles of linear operators, following the Kraus representation of superoperators. We further interpret DQCs as tensor networks, implement their functionality as tensor decision diagrams (TDDs), and reduce the equivalence of two DQCs to checking if they have the same TDD representation. Experiments show that embedding classical logic into conventional quantum circuits does not incur a significant time and space burden.",ACM
"Gaj, Kris",Challenges and Rewards of Implementing and Benchmarking Post-Quantum Cryptography in Hardware,2018,10.1145/3194554.3194615,https://doi.org/10.1145/3194554.3194615,Conference paper,GLSVLSI '18: Proceedings of the 2018 Great Lakes Symposium on VLSI,"Practical quantum computers have been recently selected as one of 10 breakthrough technologies of 2017 by the MIT Technology Review. Although various fields of human activity, such as chemistry, medicine, and materials science, are likely to be dramatically affected by practical quantum computers, the most likely immediate impact will take place in the area of cryptography and cyber security. As a result of this potential threat, a new field of science has emerged, called Post-Quantum Cryptography (PQC). PQC is devoted to the design and analysis of cryptographic algorithms that are resistant against any known attacks using quantum computers, but by themselves can be implemented using classical computing platforms, based on traditional modern semiconductor technologies. In this paper, we provide an overview and motivation for the PQC, NIST Standardization Effort, cryptographic competitions, and hardware benchmarking of candidates in cryptographic contests. Five major families of PQC schemes, code-, hash-, isogeny-, lattice-, and multivariate-based, are shortly introduced. The challenges of fair and comprehensive hardware benchmarking of PQC submissions are highlighted, together with the possible ways of overcoming these difficulties, such as the use of a common API, development packages, specialized libraries, and high-level synthesis.",ACM
"Camacho-Ruiz, Eros and S\'{a}nchez-Solano, Santiago and Brox, Piedad and Mart\'{\i}nez-Rodr\'{\i}guez, Macarena C.",Timing-Optimized Hardware Implementation to Accelerate Polynomial Multiplication in the NTRU Algorithm,2021,10.1145/3445979,https://doi.org/10.1145/3445979,Journal,J. Emerg. Technol. Comput. Syst.,"Post-quantum cryptographic algorithms have emerged to secure communication channels between electronic devices faced with the advent of quantum computers. The performance of post-quantum cryptographic algorithms on embedded systems has to be evaluated to achieve a good trade-off between required resources (area) and timing. This work presents two optimized implementations to speed up the NTRUEncrypt algorithm on a system-on-chip. The strategy is based on accelerating the most time-consuming operation that is the truncated polynomial multiplication. Hardware dedicated modules for multiplication are designed by exploiting the presence of consecutive zeros in the coefficients of the blinding polynomial. The results are validated on a PYNQ-Z2 platform that includes a Zynq-7000 SoC from Xilinx and supports a Python-based programming environment. The optimized version that exploits the presence of double, triple, and quadruple consecutive zeros offers the best performance in timing, in addition to considerably reducing the possibility of an information leakage against an eventual attack on the device, making it practically negligible.",ACM
"Rynbach, Andre Van and Ahsan, Muhammad and Kim, Jungsang",A Quantum Computing Performance Simulator Based on Circuit Failure Probability and Fault Path Counting,2018,10.1145/3154837,https://doi.org/10.1145/3154837,Journal,J. Emerg. Technol. Comput. Syst.,"Quantum computing performance simulators are needed to provide practical metrics for the effectiveness of executing theoretical quantum information processing protocols on physical hardware. In this work, we present a tool to simulate the execution of fault-tolerant quantum computation by automating the tracking of common fault paths for error propagation through an encoded circuit block and quantifying the failure probability of each encoded qubit throughout the circuit. Our simulator runs a fault path counter on encoded circuit blocks to determine the probability that two or more errors remain on the encoded qubits after each block is executed, and it combines errors from all the encoded blocks to estimate performance metrics such as the logical qubit failure probability, the overall circuit failure probability, the number of qubits used, and the time required to run the overall circuit. Our technique efficiently estimates the upper bound of the error probability and provides a useful measure of the error threshold at low error probabilities where conventional Monte Carlo methods are ineffective. We describe a way of simplifying the fault-tolerant measurement process in the Steane code to reduce the number of error correction steps necessary. We present simulation results comparing the execution of quantum adders, which constitute a major part of Shor¡¯s algorithm.",ACM
"Mandal, Suraj and Basu Roy, Debapriya",Design of a Lightweight Fast Fourier Transformation for FALCON using Hardware-Software Co-Design,2024,10.1145/3649476.3660370,https://doi.org/10.1145/3649476.3660370,Conference paper,GLSVLSI '24: Proceedings of the Great Lakes Symposium on VLSI 2024,"Lattice-based post-quantum cryptographic algorithm FALCON needs to execute the time-critical Fast-Fourier Transformation (FFT). Existing works in the literature have explored hardware for FFT of FALCON using Cooley-Tukey. In this work, we have designed an efficient hardware-software co-design of FFT for FALCON using Winograd¡¯s FFT method. Winograd¡¯s FFT is a widely adopted technique for FFT and reduces the multiplication counts for higher-radix FFT than the Cooley-Tukey, with a penalty of some extra addition/subtraction. Our Winograd radix-8 framework for FFT outperforms the traditional Cooley-Tukey method. Moreover,our proposed architecture is flexible in adopting different instruction sets and can also be configured for any type of FFT method with specific instruction sets.",ACM
"Lee, Kaitlyn and Donnelly, Brian and Sery, Tomer and Ilan, Dan and Cambou, Bertrand and Gowanlock, Michael",Evaluating Accelerators for a High-Throughput Hash-Based Security Protocol,2023,10.1145/3605731.3605745,https://doi.org/10.1145/3605731.3605745,Conference paper,ICPP Workshops '23: Proceedings of the 52nd International Conference on Parallel Processing Workshops,"Security threats are rising due to widely available computational power and near-future quantum computers. New cryptographic protocols have been developed to address these challenges, but very few protocols take advantage of parallel computing. In this paper, we propose optimizations to the cryptography protocol Response-Based Cryptography (RBC). Since the protocol is general-purpose, it can be incorporated into post-quantum cryptography systems to authenticate users in resource-constrained environments, like Internet of Thing (IoT) devices. The optimizations proposed in this paper allow for clients to be authenticated faster. Additionally, this paper makes a cross-platform comparison of the performance of the optimized RBC protocol on the Graphics Processing Unit (GPU), the Central Processing Unit (CPU), and the Associative Processing Unit (APU). We find that the GPU and APU yield similar performance but the APU can be much more energy efficient. Furthermore, we evaluate the multi-GPU scalability of the algorithm and achieve a minimum speedup of 2.66 \texttimes{} on 3 \texttimes{} A100 GPUs.",ACM
"Pukhovsky, Valery and Gushanskiy, Sergey and Potapov, Viktor",Developing a Hardware Approach to Simulating Quantum Computing Using an Optimization Algorithm,2022,10.1145/3503823.3503894,https://doi.org/10.1145/3503823.3503894,Conference paper,PCI '21: Proceedings of the 25th Pan-Hellenic Conference on Informatics,"In the past few decades, there has been an acute problem of creating a quantum computer that uses quantum mechanical effects such as quantum parallelism and quantum entanglement for computations. Using these mechanisms, the quantum computer is able to solve some of the NP-class problems in polynomial time. A hardware approach to modeling quantum computing is considered, and a general mathematical model of the operation of a quantum computer is described, and a technique for mathematical modeling of quantum computing is presented. At the stage of consideration of the method of mathematical modeling, the most resource-intensive parts of the model are indicated. Also, issues related to data parallelization on a hardware accelerator, which are planned to be used to simulate quantum computing, were considered, and algorithms for the operation of this type of accelerator were given. A more compact data format is proposed, which is recommended to be used when implementing the accelerator. Using the proposed format, it is possible to reduce the resources spent on elementary arithmetic operations. The possibility of introducing an optimization algorithm to minimize the time spent in computations, as well as to speed up the execution of quantum algorithms in simulators of a quantum computer at the stage of the effect of quantum gates on the quantum register model, is proposed. The results of the optimization algorithm and its comparison with the classical mathematical approach using a software model are presented.",ACM
"Wu, Yangjun and Guo, Chu and Fan, Yi and Zhou, Pengyu and Shang, Honghui",NNQS-Transformer: an Efficient and Scalable Neural Network Quantum States Approach for Ab initio Quantum Chemistry,2023,10.1145/3581784.3607061,https://doi.org/10.1145/3581784.3607061,Conference paper,"SC '23: Proceedings of the International Conference for High Performance Computing, Networking, Storage and Analysis","Neural network quantum state (NNQS) has emerged as a promising candidate for quantum many-body problems, but its practical applications are often hindered by the high cost of sampling and local energy calculation. We develop a high-performance NNQS method for ab initio electronic structure calculations. The major innovations include: (1) A transformer based architecture as the quantum wave function ansatz; (2) A data-centric parallelization scheme for the variational Monte Carlo (VMC) algorithm which preserves data locality and well adapts for different computing architectures; (3) A parallel batch sampling strategy which reduces the sampling cost and achieves good load balance; (4) A parallel local energy evaluation scheme which is both memory and computationally efficient; (5) Study of real chemical systems demonstrates both the superior accuracy of our method compared to state-of-the-art and the strong and weak scalability for large molecular systems with up to 120 spin orbitals.",ACM
"Jaques, Samuel and H\""{a}ner, Thomas",Leveraging State Sparsity for More Efficient Quantum Simulations,2022,10.1145/3491248,https://doi.org/10.1145/3491248,Journal,ACM Transactions on Quantum Computing,"High-performance techniques to simulate quantum programs on classical hardware rely on exponentially large vectors to represent quantum states. When simulating quantum algorithms, the quantum states that occur are often sparse due to special structure in the algorithm or even in the underlying problem. We thus introduce a new simulation method that exploits this sparsity to reduce memory usage and simulation runtime. Moreover, our prototype implementation includes optimizations such as gate (re)scheduling, which amortizes data structure accesses and reduces memory usage. To benchmark our implementation, we run quantum algorithms for factoring, for computing integer and elliptic curve discrete logarithms, and for chemistry. Our simulator successfully runs a factoring instance of a 20-bit number using 102 qubits, and elliptic curve discrete logarithm over a 10-bit curve with 110 qubits. While previous work needed a supercomputer to simulate such instances of factoring, our approach succeeds in less than four minutes using a single core and less than 100 MB of memory. To the best of our knowledge, we are the first to fully simulate a quantum algorithm to compute elliptic curve discrete logarithms.",ACM
"Jones, Benjamin D. M. and White, David R. and O'Brien, George O. and Clark, John A. and Campbell, Earl T.",Optimising trotter-suzuki decompositions for quantum simulation using evolutionary strategies,2019,10.1145/3321707.3321835,https://doi.org/10.1145/3321707.3321835,Conference paper,GECCO '19: Proceedings of the Genetic and Evolutionary Computation Conference,"One of the most promising applications of near-term quantum computing is the simulation of quantum systems, a classically intractable task. Quantum simulation requires computationally expensive matrix exponentiation; Trotter-Suzuki decomposition of this exponentiation enables efficient simulation to a desired accuracy on a quantum computer. We apply the Covariance Matrix Adaptation Evolutionary Strategy (CMA-ES) algorithm to optimise the Trotter-Suzuki decompositions of a canonical quantum system, the Heisenberg Chain; we reduce simulation error by around 60%. We introduce this problem to the computational search community, show that an evolutionary optimisation approach is robust across runs and problem instances, and find that optimisation results generalise to the simulation of larger systems.",ACM
"Baker, Jonathan M. and Duckering, Casey and Gokhale, Pranav and Brown, Natalie C. and Brown, Kenneth R. and Chong, Frederic T.",Improved Quantum Circuits via Intermediate Qutrits,2020,10.1145/3406309,https://doi.org/10.1145/3406309,Journal,ACM Transactions on Quantum Computing,"Quantum computation is traditionally expressed in terms of quantum bits, or qubits. In this work, we instead consider three-level qutrits. Past work with qutrits has demonstrated only constant factor improvements, owing to the log2(3) binary-to-ternary compression factor. We present a novel technique, intermediate qutrits, to achieve sublinear depth decompositions of the Generalized Toffoli and other arithmetic circuits using no additional ancilla¡ªa significant improvement over linear depth for the best qubit-only equivalents. For example, our Generalized Toffoli construction features a 70\texttimes{} improvement in two-qudit gate count over a qubit-only decomposition. This results in circuit cost reductions for important algorithms like quantum neurons, Grover search, and even Shor¡¯s algorithm. Using a previously developed simulator with near-term noise models, we demonstrate for these models over 90% mean reliability (fidelity) for the Toffoli construction, versus under 30% for the qubit-only baseline. For our other constructions, such as the Incrementer, the A + B adder and the +K adder, we demonstrate the power of intermediate qutrits in producing asymptotic depth improvements with no additional ancilla. Together, these results suggest qutrits offer a promising path toward scaling quantum computation.",ACM
"Baker, Jonathan M. and Schuster, David I. and Chong, Frederic T.",Memory-Equipped Quantum Architectures: The Power of Random Access,2020,10.1145/3410463.3414644,https://doi.org/10.1145/3410463.3414644,Conference paper,PACT '20: Proceedings of the ACM International Conference on Parallel Architectures and Compilation Techniques,"Resonant cavities can be used to extend conventional superconducting transmon-based quantum architectures by adding a few bits of quantum memory to each transmon. Such architectures leverage the long coherence times of cavities creating a ""memory-equipped'' quantum architecture (MEQC) extending the amount of quantum state a machine can manipulate. However, random access to data will have the greatest effect on improving machine performance. Existing transmon architectures are locally connected and performing gates between distant qubits requires expensive pairwise swaps for execution. Added swap operations increase the probability of errors by increasing both operation count and execution time. We develop a complete compilation framework with heuristics to optimize for the load-store execution model of MEQC. We reduce the gate count and depth of compiled quantum programs by an average 1.62x and 1.70x, respectively compared to traditional transmon architectures. Based on small noise simulations, MEQC architectures outperform on programs as small as 10 qubits, and in general the probability of no gate errors, dominant in NISQ era, is greater on MEQC. If idle errors become more significant, MEQC will have a greater advantage. We conclude with an exploration of different architectural choices, such as transmon-transmon connectivity and cavity size, and explore their effect on the performance of the proposed architecture. While we expect due to small initial physical experiments that we have O(10) modes per cavity, the particular choice of cavity size in this 2.5D architecture is an important one. For example, when coherence times are high and we can withstand greater serialization it becomes more advantageous to favor larger cavity sizes. In the early stages of these devices, we expect transmon-transmon interactions to be potentially more expensive than transmon-cavity interactions. Our proposed solution can tolerate potentially up to 12x worse interconnect error.",ACM
"Beirendonck, Michiel Van and D¡¯anvers, Jan-Pieter and Karmakar, Angshuman and Balasch, Josep and Verbauwhede, Ingrid",A Side-Channel-Resistant Implementation of SABER,2021,10.1145/3429983,https://doi.org/10.1145/3429983,Journal,J. Emerg. Technol. Comput. Syst.,"The candidates for the NIST Post-Quantum Cryptography standardization have undergone extensive studies on efficiency and theoretical security, but research on their side-channel security is largely lacking. This remains a considerable obstacle for their real-world deployment, where side-channel security can be a critical requirement. This work describes a side-channel-resistant instance of Saber, one of the lattice-based candidates, using masking as a countermeasure. Saber proves to be very efficient to masking due to two specific design choices: power-of-two moduli and limited noise sampling of learning with rounding. A major challenge in masking lattice-based cryptosystems is the integration of bit-wise operations with arithmetic masking, requiring algorithms to securely convert between masked representations. The described design includes a novel primitive for masked logical shifting on arithmetic shares and adapts an existing masked binomial sampler for Saber. An implementation is provided for an ARM Cortex-M4 microcontroller, and its side-channel resistance is experimentally demonstrated. The masked implementation features a 2.5x overhead factor, significantly lower than the 5.7x previously reported for a masked variant of NewHope. Masked key decapsulation requires less than 3,000,000 cycles on the Cortex-M4 and consumes less than 12kB of dynamic memory, making it suitable for deployment in embedded platforms.",ACM
"Louise, Stephane",A First Step Toward Using Quantum Computing for Low-level WCETs Estimations,2019,10.1145/3335549,https://doi.org/10.1145/3335549,Journal,ACM Trans. Archit. Code Optim.,"Low-Level analysis of Worst Case Execution Time (WCET) is an important field for real-time system validation. It stands between computer architecture and mathematics, as it relies strongly on variants of abstract interpretation. One of the features that causes the largest uncertainty regarding WCET evaluation for low-level analysis of sequential execution on a single processor is taking Cache Memory-related Delays (CMRD) and Cache-related Preemption Delays (CRPD) correctly into account. Research work from the 1990s provides a good basic framework for this problem as long as a task runs without preemption. But when preemption of tasks is allowed, although several formalisms exist, their predictive power is lower and the usual approach relies on analyses of NP-hard problems.In this article, we want to show some potential advantages of using a formalism inspired by Quantum Computing (QC) to evaluate CMRDs with preemptions while avoiding the NP-hard problem underneath. The experimental results, with a classic (non-quantum) numerical approach, on a selection of Malardalen benchmark programs display very good accuracy, while the complexity of the evaluation is a low-order polynomial of the number of memory accesses. While it is not yet a fully parallel quantum algorithm, we provide a first roadmap on how to reach such an objective.",ACM
"Ying, Mingsheng and Ying, Shenggang and Wu, Xiaodi",Invariants of quantum programs: characterisations and generation,2017,10.1145/3009837.3009840,https://doi.org/10.1145/3009837.3009840,Conference paper,POPL '17: Proceedings of the 44th ACM SIGPLAN Symposium on Principles of Programming Languages,"Program invariant is a fundamental notion widely used in program verification and analysis. The aim of this paper is twofold: (i) find an appropriate definition of invariants for quantum programs; and (ii) develop an effective technique of invariant generation for verification and analysis of quantum programs.  Interestingly, the notion of invariant can be defined for quantum programs in two different ways -- additive invariants and multiplicative invariants -- corresponding to two interpretations of implication in a continuous valued logic: the Lukasiewicz implication and the Godel implication. It is shown that both of them can be used to establish partial correctness of quantum programs.  The problem of generating additive invariants of quantum programs is addressed by reducing it to an SDP (Semidefinite Programming) problem. This approach is applied with an SDP solver to generate invariants of two important quantum algorithms -- quantum walk and quantum Metropolis sampling. Our examples show that the generated invariants can be used to verify correctness of these algorithms and are helpful in optimising quantum Metropolis sampling.  To our knowledge, this paper is the first attempt to define the notion of invariant and to develop a method of invariant generation for quantum programs.","ACM, Web of Science"
"Wang, Leizhang and Wang, Yuntao and Wang, Baocang",A Trade-off SVP-solving Strategy based on a Sharper pnj-BKZ Simulator,2023,10.1145/3579856.3595802,https://doi.org/10.1145/3579856.3595802,Conference paper,ASIA CCS '23: Proceedings of the 2023 ACM Asia Conference on Computer and Communications Security,"The lattice-based cryptography is one of the most promising candidates in the era of post-quantum cryptography. It is necessary to precisely choose the practical parameters by evaluating the hardness of the underlying hard mathematical problems, such as the shortest vector problem (SVP). Currently, there are two state-of-the-art strategies for solving (approximate) SVP. One is the SVP-solving strategy proposed in G6K[5], which has the least solving time cost but high memory cost requirements; another is to execute progressive BKZ (pBKZ)[8] for pre-processing at first and call the high-dimensional SVP-oracle to find the short vector on the original lattice. Due to the strong pre-processing on the lattice basis, the memory cost of the latter strategy is usually smaller than that of the former strategy, while the time cost of pre-processing is relatively costly. In this paper, we first optimize the pnj-BKZ simulator when the jump value is quite large by giving a refined dimension for free (d4f) estimation. Then, based on our optimized pnj-BKZ simulator, we show a more accurate hardness estimation of LWE by considering technologies such as progressive BKZ pre-processing technology, jump strategy, and d4f technology. Furthermore, based on the sharper pnj-BKZ simulator, we propose an SVP-solving strategy trade-off between G6K and pBKZ, which derives less time cost than pBKZ within less memory compared with G6K. Experimental results show that when solving the TU Darmstadt SVP challenge, our algorithm can save 50%-66% of memory compared with G6K¡¯s default SVP-solving strategy. Moreover, our algorithm speeds up the pre-processing stage by 7-30 times, saving the time cost by 4-6 times compared with the pBKZ default SVP-solving strategy. Using our proposed strategy, we solved the 170-dimensional TU Darmstadt SVP challenge and up to the 176-dimensional ideal lattice challenge.",ACM
"Zulehner, Alwin and Hillmich, Stefan and Markov, Igor L. and Wille, Robert",Approximation of Quantum States Using Decision Diagrams,2020,10.1109/ASP-DAC47756.2020.9045454,https://doi.org/10.1109/ASP-DAC47756.2020.9045454,Conference paper,ASPDAC '20: Proceedings of the 25th Asia and South Pacific Design Automation Conference,"The computational power of quantum computers poses major challenges to new design tools since representing pure quantum states typically requires exponentially large memory. As shown previously, decision diagrams can reduce these memory requirements by exploiting redundancies. In this work, we demonstrate further reductions by allowing for small inaccuracies in the quantum state representation. Such inaccuracies are legitimate since quantum computers themselves experience gate and measurement errors and since quantum algorithms are somewhat resistant to errors (even without error correction). We develop four dedicated schemes that exploit these observations and effectively approximate quantum states represented by decision diagrams. We empirically show that the proposed schemes reduce the size of decision diagrams by up to several orders of magnitude while controlling the fidelity of approximate quantum state representations.","ACM, IEEE"
"Hadfield, Stuart",On the Representation of Boolean and Real Functions as Hamiltonians for Quantum Computing,2021,10.1145/3478519,https://doi.org/10.1145/3478519,Journal,ACM Transactions on Quantum Computing,"Mapping functions on bits to Hamiltonians acting on qubits has many applications in quantum computing. In particular, Hamiltonians representing Boolean functions are required for applications of quantum annealing or the quantum approximate optimization algorithm to combinatorial optimization problems. We show how such functions are naturally represented by Hamiltonians given as sums of Pauli Z operators (Ising spin operators) with the terms of the sum corresponding to the function¡¯s Fourier expansion. For many classes of Boolean functions which are given by a compact description, such as a Boolean formula in conjunctive normal form that gives an instance of the satisfiability problem, it is #P-hard to compute its Hamiltonian representation, i.e., as hard as computing its number of satisfying assignments. On the other hand, no such difficulty exists generally for constructing Hamiltonians representing a real function such as a sum of local Boolean clauses each acting on a fixed number of bits as is common in constraint satisfaction problems. We show composition rules for explicitly constructing Hamiltonians representing a wide variety of Boolean and real functions by combining Hamiltonians representing simpler clauses as building blocks, which are particularly suitable for direct implementation as classical software. We further apply our results to the construction of controlled-unitary operators, and to the special case of operators that compute function values in an ancilla qubit register. Finally, we outline several additional applications and extensions of our results to quantum algorithms for optimization. A goal of this work is to provide a design toolkit for quantum optimization which may be utilized by experts and practitioners alike in the construction and analysis of new quantum algorithms, and at the same time to provide a unified framework for the various constructions appearing in the literature.","ACM, Web of Science"
"Rodrigo, Santiago and Span\`{o",Characterizing the spatio-temporal qubit traffic of a quantum intranet aiming at modular quantum computer architectures,2022,10.1145/3558583.3558846,https://doi.org/10.1145/3558583.3558846,Conference paper,NANOCOM '22: Proceedings of the 9th ACM International Conference on Nanoscale Computing and Communication,"Quantum many-core processors are envisioned as the ultimate solution for the scalability of quantum computers. Based upon Noisy Intermediate-Scale Quantum (NISQ) chips interconnected in a sort of quantum intranet, they enable large algorithms to be executed on current and close future technology. In order to optimize such architectures, it is crucial to develop tools that allow specific design space explorations. To this aim, in this paper we present a technique to perform a spatio-temporal characterization of quantum circuits running in multi-chip quantum computers. Specifically, we focus on the analysis of the qubit traffic resulting from operations that involve qubits residing in different cores, and hence quantum communication across chips, while also giving importance to the amount of intra-core operations that occur in between those communications. Using specific multi-core performance metrics and a complete set of benchmarks, our analysis showcases the opportunities that the proposed approach may provide to guide the design of multi-core quantum computers and their interconnects.",ACM
"Golden, John and Baertschi, Andreas and O'Malley, Dan and Pelofske, Elijah and Eidenbenz, Stephan","JuliQAOA: Fast, Flexible QAOA Simulation",2023,10.1145/3624062.3624220,https://doi.org/10.1145/3624062.3624220,Conference paper,"SC-W '23: Proceedings of the SC '23 Workshops of The International Conference on High Performance Computing, Network, Storage, and Analysis","We introduce JuliQAOA, a simulation package specifically built for the Quantum Alternating Operator Ansatz (QAOA). JuliQAOA does not require a circuit-level description of QAOA problems, or another package to simulate such circuits, instead relying on a more direct linear algebra implementation. This allows for increased QAOA-specific performance improvements, as well as improved flexibility and generality. JuliQAOA is the first QAOA package designed to aid in the study of both constrained and unconstrained combinatorial optimization problems, and can easily include novel cost functions, mixer Hamiltonians, and other variations. JuliQAOA also includes robust and extensible methods for learning optimal angles. Written in the Julia language, JuliQAOA outperforms existing QAOA software packages and scales well to HPC-level resources.",ACM
"Pakin, Scott",Targeting Classical Code to a Quantum Annealer,2019,10.1145/3297858.3304071,https://doi.org/10.1145/3297858.3304071,Conference paper,ASPLOS '19: Proceedings of the Twenty-Fourth International Conference on Architectural Support for Programming Languages and Operating Systems,"From a compiler's perspective, a quantum annealer represents a fundamentally different hardware target from a CPU, GPU, or other von Neumann architecture. Quantum annealers are special-purpose computers that use quantum effects to heuristically determine the set of Boolean variables that minimize a quadratic pseudo-Boolean function (an NP-hard problem). Natively programming such systems involves supplying them with a vector of function coefficients and receiving a vector of function-minimizing Booleans in return. The contribution of this work is to demonstrate how to compile conventional code into a minimization problem for solution on a quantum annealer. The resulting code can run either forward (from inputs to outputs) or backward (from outputs to inputs). We show how this capability can be exploited to simplify the expression and solution of problems in the NP complexity class.",ACM
"Tasopoulos, George and Dimopoulos, Charis and Fournaris, Apostolos P. and Zhao, Raymond K. and Sakzad, Amin and Steinfeld, Ron",Energy Consumption Evaluation of Post-Quantum TLS 1.3 for Resource-Constrained Embedded Devices,2023,10.1145/3587135.3592821,https://doi.org/10.1145/3587135.3592821,Conference paper,CF '23: Proceedings of the 20th ACM International Conference on Computing Frontiers,"Post-Quantum cryptography (PQC), in the past few years, constitutes the main driving force of the quantum resistance transition for security primitives, protocols and tools. TLS is one of the widely used security protocols that needs to be made quantum safe. However, PQC algorithms integration into TLS introduce various implementation overheads compared to traditional TLS that in battery powered embedded devices with constrained resources, cannot be overlooked. While there exist several works, evaluating the PQ TLS execution time overhead in embedded systems there are only a few that explore the PQ TLS energy consumption cost. In this paper, a thorough power/energy consumption evaluation and analysis of PQ TLS 1.3 on embedded systems has been made. A WolfSSL PQ TLS 1.3 custom implementation is used that integrates all the NIST PQC algorithms selected for standardisation as well as 2 out of 3 of those evaluated in NIST Round 4. Also 1 out of 2 of the BSI recommendations have been included. The PQ TLS 1.3 with the various PQC algorithms is deployed in a STM Nucleo evaluation board under a mutual and a unilateral client-server authentication scenario. The power and energy consumption collected results are analyzed in detail. The performed comparisons and overall analysis provide very interesting results indicating that the choice of the PQC algorithms in TLS 1.3 to be deployed on an embedded system may be very different depending on the device use as an authenticated or not authenticated, client or server. Also, the results indicate that in some cases, PQ TLS 1.3 implementations can be equally or more energy consumption efficient compared to traditional TLS 1.3.",ACM
"Pessl, Peter and Bruinderink, Leon Groot and Yarom, Yuval",To BLISS-B or not to be: Attacking strongSwan's Implementation of Post-Quantum Signatures,2017,10.1145/3133956.3134023,https://doi.org/10.1145/3133956.3134023,Conference paper,CCS '17: Proceedings of the 2017 ACM SIGSAC Conference on Computer and Communications Security,"In the search for post-quantum secure alternatives to RSA and ECC, lattice-based cryptography appears to be an attractive and efficient option. A particularly interesting lattice-based signature scheme is BLISS, offering key and signature sizes in the range of RSA moduli. A range of works on efficient implementations of BLISS is available, and the scheme has seen a first real-world adoption in strongSwan, an IPsec-based VPN suite. In contrast, the implementation-security aspects of BLISS, and lattice-based cryptography in general, are still largely unexplored.At CHES 2016, Groot Bruinderink et al. presented the first side-channel attack on BLISS, thus proving that this topic cannot be neglected. Nevertheless, their attack has some limitations. First, the technique is demonstrated via a proof-of-concept experiment that was not performed under realistic attack settings. Furthermore, the attack does not apply to BLISS-B, an improved variant of BLISS and also the default option in strongSwan. This problem also applies to later works on implementation security of BLISS.In this work, we solve both of the above problems. We present a new side-channel key-recovery algorithm against both the original BLISS and the BLISS-B variant. Our key-recovery algorithm draws on a wide array of techniques, including learning-parity with noise, integer programs, maximimum likelihood tests, and a lattice-basis reduction. With each application of a technique, we reveal additional information on the secret key culminating in a complete key recovery.Finally, we show that cache attacks on post-quantum cryptography are not only possible, but also practical. We mount an asynchronous cache attack on the production-grade BLISS-B implementation of strongSwan. The attack recovers the secret signing key after observing roughly 6000 signature generations.",ACM
"Zheng, Jieyu and He, Feng and Shen, Shiyu and Xue, Chenxi and Zhao, Yunlei",Parallel Small Polynomial Multiplication for Dilithium: A Faster Design and Implementation,2022,10.1145/3564625.3564629,https://doi.org/10.1145/3564625.3564629,Conference paper,ACSAC '22: Proceedings of the 38th Annual Computer Security Applications Conference,"The lattice-based signature scheme CRYSTALS-Dilithium is one of the two signature finalists in the third round NIST post-quantum cryptography (PQC) standardization project. For applications of low-power Internet-of-Things (IoT) devices, recent research efforts have been focusing on the performance optimization of PQC algorithms on embedded systems. In particular, performance optimization is more demanding for PQC signature algorithms that are usually significantly more time-consuming than PQC public-key encryption counterparts. For most cryptographic algorithms based on algebraic lattices including Dilithium, the fundamental and most time-consuming operation is polynomial multiplication over rings. For this computational task, number theoretic transform (NTT) is the most efficient multiplication method for NTT-friendly rings, and is now the typical technique for performing fast polynomial multiplications when implementing lattice-based PQC algorithms. The key observation of this work is that, besides multiplications of polynomials of standard forms, Dilithium involves a list of multiplications for polynomials of very small coefficients. Can we have more efficient methods for multiplying such polynomials of small coefficients? Under this motivation, we present in this work a parallel small polynomial multiplication algorithm to speed up the implementations of Dilithium. We complete both C reference implementation and ARM Neon implementation. Moreover, we conducted some speed tests in combination with Becker¡¯s Neon NTT [4]. The results show that, in comparison with the C reference implementation of Dilithium submitted to the third round of the NIST PQC competition, our reference implementation with the proposed parallel small polynomial multiplication is faster: specifically, our Sign and Verify speed up 18% and 19% respectively for Dilithium-2 (30% and 7% for Dilithium-3, 27% and 3% for Dilithium-5, respectively). As for the Arm Neon implementation, we achieved a performance improvement of about 64% in Sign and 50% in Verify for Dilithium-2 (60% and 32% for Dilithium-3) compared with the C reference implementation of Dilithium submitted to the third round of the NIST PQC competition. We aslo compared our work with the state-of-the-art Arm Neon implementation of Dilithium [4], the results show our speed of Sign is 13.4% faster for Dilithium-2 and 8.0% faster for Dilithium-3, achieving a new record of fast Dilithium implementation.",ACM
"Chong, Frederic T.","Quantum Computing is Getting Real: Architecture, PL, and OS Roles in Closing the Gap between Quantum Algorithms and Machines",2018,10.1145/3296957.3177152,https://doi.org/10.1145/3296957.3177152,Journal,SIGPLAN Not.,"Quantum computing is at an inflection point, where 50-qubit (quantum bit) machines have been built, 100-qubit machines are just around the corner, and even 1000-qubit machines are perhaps only a few years away. These machines have the potential to fundamentally change our concept of what is computable and demonstrate practical applications in areas such as quantum chemistry, optimization, and quantum simulation. Yet a significant resource gap remains between practical quantum algorithms and real machines. There is an urgent shortage of the necessary computer scientists to work on software and architectures to close this gap. I will outline several grand research challenges in closing this gap, including programming language design, software and hardware verification, defining and perforating abstraction boundaries, cross-layer optimization, managing parallelism and communication, mapping and scheduling computations, reducing control complexity, machine-specific optimizations, learning error patterns, and many more. I will also describe the resources and infrastructure available for starting research in quantum computing and for tackling these challenges.","ACM, Web of Science"
"Duckering, Casey and Baker, Jonathan M. and Litteken, Andrew and Chong, Frederic T.",Orchestrated trios: compiling for efficient communication in Quantum programs with 3-Qubit gates,2021,10.1145/3445814.3446718,https://doi.org/10.1145/3445814.3446718,Conference paper,ASPLOS '21: Proceedings of the 26th ACM International Conference on Architectural Support for Programming Languages and Operating Systems,"Current quantum computers are especially error prone and require high levels of optimization to reduce operation counts and maximize the probability the compiled program will succeed. These computers only support operations decomposed into one- and two-qubit gates and only two-qubit gates between physically connected pairs of qubits. Typical compilers first decompose operations, then route data to connected qubits. We propose a new compiler structure, Orchestrated Trios, that first decomposes to the three-qubit Toffoli, routes the inputs of the higher-level Toffoli operations to groups of nearby qubits, then finishes decomposition to hardware-supported gates.  This significantly reduces communication overhead by giving the routing pass access to the higher-level structure of the circuit instead of discarding it. A second benefit is the ability to now select an architecture-tuned Toffoli decomposition such as the 8-CNOT Toffoli for the specific hardware qubits now known after the routing pass. We perform real experiments on IBM Johannesburg showing an average 35% decrease in two-qubit gate count and 23% increase in success rate of a single Toffoli over Qiskit. We additionally compile many near-term benchmark algorithms showing an average 344% increase in (or 4.44x) simulated success rate on the Johannesburg architecture and compare with other architecture types.",ACM
"Butko, Anastasiia and Michelogiannakis, George and Donofrio, David and Shalf, John",TIGER: topology-aware task assignment approach using ising machines,2019,10.1145/3310273.3321556,https://doi.org/10.1145/3310273.3321556,Conference paper,CF '19: Proceedings of the 16th ACM International Conference on Computing Frontiers,"Optimal mapping of a parallel code's communication graph is increasingly important as both system size and heterogeneity increase. However, the topology-aware task assignment problem is an NP-complete graph isomorphism problem. Existing task scheduling approaches are either heuristic or based on physical optimization algorithms, providing different speed and solution quality tradeoffs. Ising machines such as quantum and digital annealers have recently become available offering an alternative hardware solution to solve certain types of optimization problems. We propose an algorithm that allows expressing the problem for such machines and a domain specific partition strategy that enables to solve larger scale problems. TIGER - topology-aware task assignment mapper tool - implements the proposed algorithm and automatically integrates task - communication graph and an architecture graph into the quantum software environment. We use D-Wave's quantum annealer to demonstrate the solving algorithm and evaluate the proposed tool flow in terms of performance, partition efficiency and solution quality. Results show significant speed-up of the tool flow and reliable solution quality while using TIGER together with the proposed partition.",ACM
"Heckey, Jeff and Patil, Shruti and JavadiAbhari, Ali and Holmes, Adam and Kudrow, Daniel and Brown, Kenneth R. and Franklin, Diana and Chong, Frederic T. and Martonosi, Margaret",Compiler Management of Communication and Parallelism for Quantum Computation,2015,10.1145/2694344.2694357,https://doi.org/10.1145/2694344.2694357,Conference paper,ASPLOS '15: Proceedings of the Twentieth International Conference on Architectural Support for Programming Languages and Operating Systems,"Quantum computing (QC) offers huge promise to accelerate a range of computationally intensive benchmarks. Quantum computing is limited, however, by the challenges of decoherence: i.e., a quantum state can only be maintained for short windows of time before it decoheres. While quantum error correction codes can protect against decoherence, fast execution time is the best defense against decoherence, so efficient architectures and effective scheduling algorithms are necessary. This paper proposes the Multi-SIMD QC architecture and then proposes and evaluates effective schedulers to map benchmark descriptions onto Multi-SIMD architectures. The Multi-SIMD model consists of a small number of SIMD regions, each of which may support operations on up to thousands of qubits per cycle.Efficient Multi-SIMD operation requires efficient scheduling. This work develops schedulers to reduce communication requirements of qubits between operating regions, while also improving parallelism.We find that communication to global memory is a dominant cost in QC. We also note that many quantum benchmarks have long serial operation paths (although each operation may be data parallel). To exploit this characteristic, we introduce Longest-Path-First Scheduling (LPFS) which pins operations to SIMD regions to keep data in-place and reduce communication to memory. The use of small, local scratchpad memories also further reduces communication. Our results show a 3% to 308% improvement for LPFS over conventional scheduling algorithms, and an additional 3% to 64% improvement using scratchpad memories. Our work is the most comprehensive software-to-quantum toolflow published to date, with efficient and practical scheduling techniques that reduce communication and increase parallelism for full-scale quantum code executing up to a trillion quantum gate operations.",ACM
"Susungi, Adilla and Rink, Norman A. and Castrill\'{o}n, Jer\'{o}nimo and Huismann, Immo and Cohen, Albert and Tadonki, Claude and Stiller, J\""{o}rg and Fr\""{o}hlich, Jochen",Towards compositional and generative tensor optimizations,2017,10.1145/3136040.3136050,https://doi.org/10.1145/3136040.3136050,Conference paper,GPCE 2017: Proceedings of the 16th ACM SIGPLAN International Conference on Generative Programming: Concepts and Experiences,"Many numerical algorithms are naturally expressed as operations on tensors (i.e. multi-dimensional arrays). Hence, tensor expressions occur in a wide range of application domains, e.g. quantum chemistry and physics; big data analysis and machine learning; and computational fluid dynamics. Each domain, typically, has developed its own strategies for efficiently generating optimized code, supported by tools such as domain-specific languages, compilers, and libraries. However, strategies and tools are rarely portable between domains, and generic solutions typically act as ''black boxes'' that offer little control over code generation and optimization. As a consequence, there are application domains without adequate support for easily generating optimized code, e.g. computational fluid dynamics. In this paper we propose a generic and easily extensible intermediate language for expressing tensor computations and code transformations in a modular and generative fashion. Beyond being an intermediate language, our solution also offers meta-programming capabilities for experts in code optimization. While applications from the domain of computational fluid dynamics serve to illustrate our proposed solution, we believe that our general approach can help unify research in tensor optimizations and make solutions more portable between domains.",ACM
"Patel, Tirthak and Potharaju, Abhay and Li, Baolin and Roy, Rohan Basu and Tiwari, Devesh","Experimental evaluation of NISQ quantum computers: error measurement, characterization, and implications",2020,10.5555/3433701.3433762,https://dl.acm.org/doi/10.5555/3433701.3433762,Conference paper,"SC '20: Proceedings of the International Conference for High Performance Computing, Networking, Storage and Analysis","Noisy Intermediate-Scale Quantum (NISQ) computers are being increasingly used for executing early-stage quantum programs to establish the practical realizability of existing quantum algorithms. These quantum programs have uses cases in the realm of high-performance computing ranging from molecular chemistry and physics simulations to addressing NP-complete optimization problems. However, NISQ devices are prone to multiple types of errors, which affect the fidelity and reproducibility of the program execution. As the technology is still primitive, our understanding of these quantum machines and their error characteristics is limited. To bridge that understanding gap, this is the first work to provide a systematic and rich experimental evaluation of IBM Quantum Experience (QX) quantum computers of different scales and topologies. Our experimental evaluation uncovers multiple important and interesting aspects of benchmarking and evaluating quantum program on NISQ machines. We have open-sourced our experimental framework and dataset to help accelerate the evaluation of quantum computing systems.",ACM
"Mccaskey, Alexander and Nguyen, Thien and Santana, Anthony and Claudino, Daniel and Kharazi, Tyler and Finkel, Hal",Extending C++ for Heterogeneous Quantum-Classical Computing,2021,10.1145/3462670,https://doi.org/10.1145/3462670,Journal,ACM Transactions on Quantum Computing,"We present qcor¡ªa language extension to C++ and compiler implementation that enables heterogeneous quantum-classical programming, compilation, and execution in a single-source context. Our work provides a first-of-its-kind C++ compiler enabling high-level quantum kernel (function) expression in a quantum-language agnostic manner, as well as a hardware-agnostic, retargetable compiler workflow targeting a number of physical and virtual quantum computing backends. qcor leverages novel Clang plugin interfaces and builds upon the XACC system-level quantum programming framework to provide a state-of-the-art integration mechanism for quantum-classical compilation that leverages the best from the community at-large. qcor translates quantum kernels ultimately to the XACC intermediate representation, and provides user-extensible hooks for quantum compilation routines like circuit optimization, analysis, and placement. This work details the overall architecture and compiler workflow for qcor, and provides a number of illuminating programming examples demonstrating its utility for near-term variational tasks, quantum algorithm expression, and feed-forward error correction schemes.",ACM
"Gokhale, Pranav and Baker, Jonathan M. and Duckering, Casey and Brown, Natalie C. and Brown, Kenneth R. and Chong, Frederic T.",Asymptotic improvements to quantum circuits via qutrits,2019,10.1145/3307650.3322253,https://doi.org/10.1145/3307650.3322253,Conference paper,ISCA '19: Proceedings of the 46th International Symposium on Computer Architecture,"Quantum computation is traditionally expressed in terms of quantum bits, or qubits. In this work, we instead consider three-level qutrits. Past work with qutrits has demonstrated only constant factor improvements, owing to the log2(3) binary-to-ternary compression factor. We present a novel technique using qutrits to achieve a logarithmic depth (runtime) decomposition of the Generalized Toffoli gate using no ancilla-a significant improvement over linear depth for the best qubit-only equivalent. Our circuit construction also features a 70x improvement in two-qudit gate count over the qubit-only equivalent decomposition. This results in circuit cost reductions for important algorithms like quantum neurons and Grover search. We develop an open-source circuit simulator for qutrits, along with realistic near-term noise models which account for the cost of operating qutrits. Simulation results for these noise models indicate over 90% mean reliability (fidelity) for our circuit construction, versus under 30% for the qubit-only baseline. These results suggest that qutrits offer a promising path towards scaling quantum computation.","ACM, IEEE"
"de Almeida, Alexandre A. A. and Dueck, Gerhard W. and da Silva, Alexandre C. R.",Finding optimal qubit permutations for IBM's quantum computer architectures,2019,10.1145/3338852.3339829,https://doi.org/10.1145/3338852.3339829,Conference paper,SBCCI '19: Proceedings of the 32nd Symposium on Integrated Circuits and Systems Design,"IBM offers quantum processors for Clifford+T circuits. The only restriction is that not all CNOT gates are implemented and must be substituted with alternate sequences of gates. Each CNOT has its own mapping with a respective cost. However, by permuting the qubits, the number of CNOT that need mappings can be reduced. The problem is to find a good permutation without an exhaustive search. In this paper we propose a solution for this problem. The permutation problem is formulated as an Integer Linear Programming (ILP) problem. Solving the ILP problem, the lowest cost permutation for the CNOT mappings is guaranteed. To test and validated the proposed formulation, quantum architectures with 5 and 16 qubits were used. The ILP formulation along with mapping techniques found circuits with up to 64% fewer gates than other approaches.",ACM
"Murali, Prakash and Baker, Jonathan M. and Javadi-Abhari, Ali and Chong, Frederic T. and Martonosi, Margaret",Noise-Adaptive Compiler Mappings for Noisy Intermediate-Scale Quantum Computers,2019,10.1145/3297858.3304075,https://doi.org/10.1145/3297858.3304075,Conference paper,ASPLOS '19: Proceedings of the Twenty-Fourth International Conference on Architectural Support for Programming Languages and Operating Systems,"A massive gap exists between current quantum computing (QC) prototypes, and the size and scale required for many proposed QC algorithms. Current QC implementations are prone to noise and variability which affect their reliability, and yet with less than 80 quantum bits (qubits) total, they are too resource-constrained to implement error correction. The term Noisy Intermediate-Scale Quantum (NISQ) refers to these current and near-term systems of 1000 qubits or less. Given NISQ's severe resource constraints, low reliability, and high variability in physical characteristics such as coherence time or error rates, it is of pressing importance to map computations onto them in ways that use resources efficiently and maximize the likelihood of successful runs. This paper proposes and evaluates backend compiler approaches to map and optimize high-level QC programs to execute with high reliability on NISQ systems with diverse hardware characteristics. Our techniques all start from an LLVM intermediate representation of the quantum program (such as would be generated from high-level QC languages like Scaffold) and generate QC executables runnable on the IBM Q public QC machine. We then use this framework to implement and evaluate several optimal and heuristic mapping methods. These methods vary in how they account for the availability of dynamic machine calibration data, the relative importance of various noise parameters, the different possible routing strategies, and the relative importance of compile-time scalability versus runtime success. Using real-system measurements, we show that fine grained spatial and temporal variations in hardware parameters can be exploited to obtain an average 2.9x (and up to 18x) improvement in program success rate over the industry standard IBM Qiskit compiler. Despite small qubit counts, NISQ systems will soon be large enough to demonstrate ""quantum supremacy"", i.e., an advantage over classical computing. Tools like ours provide significant improvements in program reliability and execution time, and offer high leverage in accelerating progress towards quantum supremacy.",ACM
"Kim, Jongmin and Lee, Gwangho and Kim, Sangpyo and Sohn, Gina and Rhu, Minsoo and Kim, John and Ahn, Jung Ho",ARK: Fully Homomorphic Encryption Accelerator with Runtime Data Generation and Inter-Operation Key Reuse,2023,10.1109/MICRO56248.2022.00086,https://doi.org/10.1109/MICRO56248.2022.00086,Conference paper,MICRO '22: Proceedings of the 55th Annual IEEE/ACM International Symposium on Microarchitecture,"Homomorphic Encryption (HE) is one of the most promising post-quantum cryptographic schemes that enable privacy-preserving computation on servers. However, noise accumulates as we perform operations on HE-encrypted data, restricting the number of possible operations. Fully HE (FHE) removes this restriction by introducing the bootstrapping operation, which refreshes the data; however, FHE schemes are highly memory-bound. Bootstrapping, in particular, requires loading GBs of evaluation keys and plaintexts from off-chip memory, which makes FHE acceleration fundamentally bottlenecked by the off-chip memory bandwidth.In this paper, we propose ARK, an Accelerator for FHE with Runtime data generation and inter-operation Key reuse. ARK enables practical FHE workloads with a novel algorithm-architecture co-design to accelerate bootstrapping. We first eliminate the off-chip memory bandwidth bottleneck through runtime data generation and inter-operation key reuse. This approach enables ARK to fully exploit on-chip memory by substantially reducing the size of the working set. On top of such algorithmic enhancements, we build ARK microarchitecture that minimizes on-chip data movement through an efficient, alternating data distribution policy based on the data access patterns and a streamlined dataflow organization of the tailored functional units ---including base conversion, number-theoretic transform, and automorphism units. Overall, our co-design effectively handles the heavy computation and data movement overheads of FHE, drastically reducing the cost of HE operations, including bootstrapping.",ACM
"Wang, Fanmeng and Xu, Hongteng and Chen, Xi and Lu, Shuqi and Deng, Yuqing and Huang, Wenbing",MPerformer: An SE(3) Transformer-based Molecular Perceptron,2023,10.1145/3583780.3614974,https://doi.org/10.1145/3583780.3614974,Conference paper,CIKM '23: Proceedings of the 32nd ACM International Conference on Information and Knowledge Management,"Molecular perception aims to construct 3D molecules from 3D atom clouds (i.e., atom types and corresponding 3D coordinates), determining bond connections, bond orders, and other molecular attributes within molecules. It is essential for realizing many applications in cheminformatics and bioinformatics, such as modeling quantum chemistry-derived molecular structures in protein-ligand complexes. Additionally, many molecular generation methods can only generate molecular 3D atom clouds, requiring molecular perception as a necessary post-processing. However, existing molecular perception methods mainly rely on predefined chemical rules and fail to leverage 3D geometric information, whose performance is sub-optimal fully. In this study, we propose MPerformer, an SE(3) Transformer-based molecular perceptron exhibiting SE(3)-invariance, to construct 3D molecules from 3D atom clouds efficiently. Besides, we propose a multi-task pretraining-and-finetuning paradigm to learn this model. In the pretraining phase, we jointly minimize an attribute prediction loss and an atom cloud reconstruction loss, mitigating the data imbalance issue of molecular attributes and enhancing the robustness and generalizability of the model. Experiments show that MPerformer significantly outperforms state-of-the-art molecular perception methods in precision and robustness, benefiting various molecular generation scenarios.",ACM
"Dangwal, Siddharth and Ravi, Gokul Subramanian and Das, Poulami and Smith, Kaitlin N. and Baker, Jonathan Mark and Chong, Frederic T.",VarSaw: Application-tailored Measurement Error Mitigation for Variational Quantum Algorithms,2024,10.1145/3623278.3624764,https://doi.org/10.1145/3623278.3624764,Conference paper,"ASPLOS '23: Proceedings of the 28th ACM International Conference on Architectural Support for Programming Languages and Operating Systems, Volume 4","For potential quantum advantage, Variational Quantum Algorithms (VQAs) need high accuracy beyond the capability of today's NISQ devices, and thus will benefit from error mitigation. In this work we are interested in mitigating measurement errors which occur during qubit measurements after circuit execution and tend to be the most error-prone operations, especially detrimental to VQAs. Prior work, JigSaw, has shown that measuring only small subsets of circuit qubits at a time and collecting results across all such `subset' circuits can reduce measurement errors. Then, running the entire (`global') original circuit and extracting the qubit-qubit measurement correlations can be used in conjunction with the subsets to construct a high-fidelity output distribution of the original circuit. Unfortunately, the execution cost of JigSaw scales polynomially in the number of qubits in the circuit, and when compounded by the number of circuits and iterations in VQAs, the resulting execution cost quickly turns insurmountable.To combat this, we propose VarSaw, which improves JigSaw in an application-tailored manner, by identifying considerable redundancy in the JigSaw approach for VQAs: spatial redundancy across subsets from different VQA circuits and temporal redundancy across globals from different VQA iterations. VarSaw then eliminates these forms of redundancy by commuting the subset circuits and selectively executing the global circuits, reducing computational cost (in terms of the number of circuits executed) over naive JigSaw for VQA by 25x on average and up to 1000x, for the same VQA accuracy. Further, it can recover, on average, 45% of the infidelity from measurement errors in the noisy VQA baseline. Finally, it improves fidelity by 55%, on average, over JigSaw for a fixed computational budget. VarSaw can be accessed here: https://github.com/siddharthdangwal/VarSaw",ACM
"H\""{a}ner, Thomas and Steiger, Damian S. and Smelyanskiy, Mikhail and Troyer, Matthias",High performance emulation of quantum circuits,2016,10.5555/3014904.3015003,https://dl.acm.org/doi/10.5555/3014904.3015003,Conference paper,"SC '16: Proceedings of the International Conference for High Performance Computing, Networking, Storage and Analysis","As quantum computers of non-trivial size become available in the near future, it is imperative to develop tools to emulate small quantum computers. This allows for validation and debugging of algorithms as well as exploring hardware-software co-design to guide the development of quantum hardware and architectures. The simulation of quantum computers entails multiplications of sparse matrices with very large dense vectors of dimension 2n, where n denotes the number of qubits, making this a memory-bound and network bandwidth-limited application. We introduce the concept of a quantum computer emulator as a component of a software framework for quantum computing, enabling a significant performance advantage over simulators by emulating quantum algorithms at a high level rather than simulating individual gate operations. We describe various optimization approaches and present benchmarking results, establishing the superiority of quantum computer emulators in terms of performance.","ACM, IEEE"
"Saarinen, Markku-Juhani O. and Newell, G. Richard and Marshall, Ben",Building a Modern TRNG: An Entropy Source Interface for RISC-V,2020,10.1145/3411504.3421212,https://doi.org/10.1145/3411504.3421212,Conference paper,ASHES'20: Proceedings of the 4th ACM Workshop on Attacks and Solutions in Hardware Security,"The currently proposed RISC-V True Random Number Generator (TRNG) architecture breaks with previous ISA TRNG practice by splitting the Entropy Source (ES) component away from cryptographic PRNGs into a separate interface, and in its use of polling. We describe the interface, its use in cryptography, and offer additional discussion, background, and rationale for various aspects of it. This design is informed by lessons learned from earlier mainstream ISAs, recently introduced SP 800-90B and FIPS 140-3 entropy audit requirements, AIS 31 and Common Criteria, current and emerging cryptographic needs such as post-quantum cryptography, and the goal of supporting a wide variety of RISC-V implementations and applications. Many of the architectural choices are a result of quantitative observations about random number generators in secure microcontrollers, the Linux kernel, and cryptographic libraries. We further compare the architecture to some contemporary random number generators and describe a minimalistic TRNG reference implementation that uses the Entropy Source together with RISC-V AES instructions.",ACM
"Balduzzi, Giovanni and Chatterjee, Arghya and Li, Ying Wai and Doak, Peter W. and Haehner, Urs and D'Azevedo, Ed F. and Maier, Thomas A. and Schulthess, Thomas",Accelerating DCA++ (Dynamical Cluster Approximation) Scientific Application on the Summit supercomputer,2024,10.1109/PACT.2019.00041,https://doi.org/10.1109/PACT.2019.00041,Conference paper,PACT '19: Proceedings of the International Conference on Parallel Architectures and Compilation Techniques,"Optimizing scientific applications on today's accelerator-based high performance computing systems can be challenging, especially when multiple GPUs and CPUs with heterogeneous memories and persistent non-volatile memories are present. An example is Summit, an accelerator-based system at the Oak Ridge Leadership Computing Facility (OLCF) that is rated as the world's fastest supercomputer to-date. New strategies are thus needed to expose the parallelism in legacy applications, while being amenable to efficient mapping to the underlying architecture.In this paper we discuss our experiences and strategies to port a scientific application, DCA++, to Summit. DCA++ is a high-performance research application that solves quantum many-body problems with a cutting edge quantum cluster algorithm, the dynamical cluster approximation.Our strategies aim to synergize the strengths of the different programming models in the code. These include: (a) streamlining the interactions between the CPU threads and the GPUs, (b) implementing computing kernels on the GPUs and decreasing CPU-GPU memory transfers, (c) allowing asynchronous GPU communications, and (d) increasing compute intensity by combining linear algebraic operations.Full-scale production runs using all 4600 Summit nodes attained a peak performance of 73.5 PFLOPS with a mixed precision implementation. We observed a perfect strong and weak scaling for the quantum Monte Carlo solver in DCA++, while encountering about 2\texttimes{} input/output (I/O) and MPI communication overhead on the time-to-solution for the full machine run. Our hardware agnostic optimizations are designed to alleviate the communication and I/O challenges observed, while improving the compute intensity and obtaining optimal performance on a complex, hybrid architecture like Summit.","ACM, IEEE"
"Cho, Joo Yeon and Sergeev, Andrew",Post-quantum MACsec key agreement for ethernet networks,2020,10.1145/3407023.3409220,https://doi.org/10.1145/3407023.3409220,Conference paper,"ARES '20: Proceedings of the 15th International Conference on Availability, Reliability and Security","The industrial demand on MACsec in Ethernet networks is increasing substantially, in particular for 5G networks, mainly due to its efficiency paired with strong security. MKA (MACsec Key Agreement) is a companion protocol of MACsec that provides methods of authentication and cryptographic key establishment. In this paper, the MACsec and MKA protocol are analysed under a quantum attack scenario. Even though the threat of quantum computers should not be overstated, it is necessary to provide a new countermeasure that is robust against this potential, yet critical risk. Symmetric-key crypto algorithms defined in MACsec and MKA can achieve 128-bit quantum security if 256-bit keys are mandated. However, classical public-key crypto schemes are known to be vulnerable to quantum attacks so that MKA protocol needs to support post-quantum public-key crypto schemes. We implemented a McEliece-based key establishment which is the most conservative post-quantum public-key cryptosystem with a large size of key, yet feasible for MKA. For entity authentication, we implemented a XMSS hash-based signature scheme that is standardised in IETF. We verified by experiments that selected schemes fit well for a MACsec-enabled Ethernet network.",ACM
"J\""{u}nger, Michael and Lobe, Elisabeth and Mutzel, Petra and Reinelt, Gerhard and Rendl, Franz and Rinaldi, Giovanni and Stollenwerk, Tobias",Quantum Annealing versus Digital Computing: An Experimental Comparison,2021,10.1145/3459606,https://doi.org/10.1145/3459606,Journal,ACM J. Exp. Algorithmics,"Quantum annealing is getting increasing attention in combinatorial optimization. The quantum processing unit by D-Wave is constructed to approximately solve Ising models on so-called Chimera graphs. Ising models are equivalent to quadratic unconstrained binary optimization (QUBO) problems and maximum cut problems on the associated graphs. We have tailored branch-and-cut as well as semidefinite programming algorithms for solving Ising models for Chimera graphs to provable optimality and use the strength of these approaches for comparing our solution values to those obtained on the current quantum annealing machine, D-Wave 2000Q. This allows for the assessment of the quality of solutions produced by the D-Wave hardware. In addition, we also evaluate the performance of a heuristic by Selby. It has been a matter of discussion in the literature how well the D-Wave hardware performs at its native task, and our experiments shed some more light on this issue. In particular, we examine how reliably the D-Wave computer can deliver true optimum solutions and present some surprising results.",ACM
"Suau, Adrien and Staffelbach, Gabriel and Calandra, Henri",Practical Quantum Computing: Solving the Wave Equation Using a Quantum Approach,2021,10.1145/3430030,https://doi.org/10.1145/3430030,Journal,ACM Transactions on Quantum Computing,"In the last few years, several quantum algorithms that try to address the problem of partial differential equation solving have been devised: on the one hand, ¡°direct¡± quantum algorithms that aim at encoding the solution of the PDE by executing one large quantum circuit; on the other hand, variational algorithms that approximate the solution of the PDE by executing several small quantum circuits and making profit of classical optimisers. In this work, we propose an experimental study of the costs (in terms of gate number and execution time on a idealised hardware created from realistic gate data) associated with one of the ¡°direct¡± quantum algorithm: the wave equation solver devised in [32]. We show that our implementation of the quantum wave equation solver agrees with the theoretical big-O complexity of the algorithm. We also explain in great detail the implementation steps and discuss some possibilities of improvements. Finally, our implementation proves experimentally that some PDE can be solved on a quantum computer, even if the direct quantum algorithm chosen will require error-corrected quantum chips, which are not believed to be available in the short-term.",ACM
"Saravanan, Vedika and Saeed, Samah Mohamed",Graph Neural Networks for Idling Error Mitigation,2022,10.1145/3508352.3549444,https://doi.org/10.1145/3508352.3549444,Conference paper,ICCAD '22: Proceedings of the 41st IEEE/ACM International Conference on Computer-Aided Design,"Dynamical Decoupling (DD)-based protocols have been shown to reduce the idling errors encountered in quantum circuits. However, the current research in suppressing idling qubit errors suffers from scalability issues due to the large number of tuning quantum circuits that should be executed first to find the locations of the DD sequences in the target quantum circuit, which boost the output state fidelity. This process becomes tedious as the size of the quantum circuit increases. To address this challenge, we propose a Graph Neural Network (GNN) framework, which mitigates idling errors through an efficient insertion of DD sequences into quantum circuits by modeling their impact at different idle qubit windows. Our paper targets maximizing the benefit of DD sequences using a limited number of tuning circuits. We propose to classify the idle qubit windows into critical and non-critical (benign) windows using a data-driven reliability model. Our results obtained from IBM Lagos quantum computer show that our proposed GNN models, which determine the locations of DD sequences in the quantum circuits, significantly improve the output state fidelity by a factor of 1.4x on average and up to 2.6x compared to the adaptive DD approach, which searches for the best locations of DD sequences at run-time.",ACM
"Patel, Tirthak and Tiwari, Devesh",DisQ: a novel quantum output state classification method on IBM quantum computers using openpulse,2020,10.1145/3400302.3415619,https://doi.org/10.1145/3400302.3415619,Conference paper,ICCAD '20: Proceedings of the 39th International Conference on Computer-Aided Design,"Superconducting quantum computing technology has ushered in a new era of computational possibilities. While a considerable research effort has been geared toward improving the quantum technology and building the software stack to efficiently execute quantum algorithms with reduced error rate, effort toward optimizing how quantum output states are defined and classified for the purpose of reducing the error rate is still limited. To this end, this paper proposes DisQ, a quantum output state classification approach which reduces error rates of quantum programs on NISQ devices.",ACM
"Ravi, Gokul Subramanian and Smith, Kaitlin and Baker, Jonathan M. and Kannan, Tejas and Earnest, Nathan and Javadi-Abhari, Ali and Hoffmann, Henry and Chong, Frederic T.",Navigating the Dynamic Noise Landscape of Variational Quantum Algorithms with QISMET,2023,10.1145/3575693.3575739,https://doi.org/10.1145/3575693.3575739,Conference paper,"ASPLOS 2023: Proceedings of the 28th ACM International Conference on Architectural Support for Programming Languages and Operating Systems, Volume 2","In the Noisy Intermediate Scale Quantum (NISQ) era, the dynamic nature of quantum systems causes noise sources to constantly vary over time. Transient errors from the dynamic NISQ noise landscape are challenging to comprehend and are especially detrimental to classes of applications that are iterative and/or long-running, and therefore their timely mitigation is important for quantum advantage in real-world applications. The most popular examples of iterative long-running quantum applications are variational quantum algorithms (VQAs). Iteratively, VQA¡¯s classical optimizer evaluates circuit candidates on an objective function and picks the best circuits towards achieving the application¡¯s target. Noise fluctuation can cause a significant transient impact on the objective function estimation of the VQA iterations¡¯ tuning candidates. This can severely affect VQA tuning and, by extension, its accuracy and convergence. This paper proposes QISMET: Quantum Iteration Skipping to Mitigate Error Transients, to navigate the dynamic noise landscape of VQAs. QISMET actively avoids instances of high fluctuating noise which are predicted to have a significant transient error impact on specific VQA iterations. To achieve this, QISMET estimates transient error in VQA iterations and designs a controller to keep the VQA tuning faithful to the transient-free scenario. By doing so, QISMET efficiently mitigates a large portion of the transient noise impact on VQAs and is able to improve the fidelity by 1.3x-3x over a traditional VQA baseline, with 1.6-2.4x improvement over alternative approaches, across different applications and machines.",ACM
"Fu, X. and Rol, M. A. and Bultink, C. C. and van Someren, J. and Khammassi, N. and Ashraf, I. and Vermeulen, R. F. L. and de Sterke, J. C. and Vlothuizen, W. J. and Schouten, R. N. and Almudever, C. G. and DiCarlo, L. and Bertels, K.",An experimental microarchitecture for a superconducting quantum processor,2017,10.1145/3123939.3123952,https://doi.org/10.1145/3123939.3123952,Conference paper,MICRO-50 '17: Proceedings of the 50th Annual IEEE/ACM International Symposium on Microarchitecture,"Quantum computers promise to solve certain problems that are intractable for classical computers, such as factoring large numbers and simulating quantum systems. To date, research in quantum computer engineering has focused primarily at opposite ends of the required system stack: devising high-level programming languages and compilers to describe and optimize quantum algorithms, and building reliable low-level quantum hardware. Relatively little attention has been given to using the compiler output to fully control the operations on experimental quantum processors. Bridging this gap, we propose and build a prototype of a flexible control microarchitecture supporting quantum-classical mixed code for a superconducting quantum processor. The microarchitecture is based on three core elements: (i) a codeword-based event control scheme, (ii) queue-based precise event timing control, and (iii) a flexible multilevel instruction decoding mechanism for control. We design a set of quantum microinstructions that allows flexible control of quantum operations with precise timing. We demonstrate the microarchitecture and microinstruction set by performing a standard gate-characterization experiment on a transmon qubit.","ACM, IEEE"
"Gosh, Saptarshi and EL Boudani, Brahim and Dagiuklas, Tasos and Iqbal, Muddesar",SO-KDN: A Self-Organised Knowledge Defined Networks Architecture for Reliable Routing,2021,10.1145/3459955.3460617,https://doi.org/10.1145/3459955.3460617,Conference paper,ICISS '21: Proceedings of the 4th International Conference on Information Science and Systems,"¡°When you are destined for an important appoint-ment, you would obviously opt for the most reliable route instead of the shortest in order to be well prepared¡±. Modern networking is presently undergoing through a quantum leap. To cope up with ambitious demands and user expectations, it is becoming more complex both structurally and functionally. Software Defined Networking (SDN) happens to be an instance of such advancements. It has significantly leveraged the network programmability, abstraction, and automation. Eventually, with acceptance form all major network infrastructure such as 5G and Cloud, SDN is becoming the standard of future networking. Likewise, Machine Learning (ML) has become the trendiest skill-in-demand recently. With its superiority of analyzing data, makes it applicable for almost every possible domain. The attempt to applying the power of ML in networking has not been too long, it allows the network to be more intelligent and capable enough to take optimal decisions to address some of its native problems. This gives rise to Self- Organized Networking (SON). In this article, Routing using Deep Neural Network (DNN) on top of SDN is addressed. We proposed a Self-organized Knowledge Defined Network (SO-KDN) architecture and an intelligent routing algorithm, that reactively finds the most reliable route, i.e., a route having least probability of fluctuation. This reduces network overhead due to re-routing and optimizes traffic congestion. Experimental data show a mean 90% accurate forecast in reliability prediction.",ACM
"Baker, Jonathan M. and Duckering, Casey and Hoover, Alexander and Chong, Frederic T.",Time-sliced quantum circuit partitioning for modular architectures,2020,10.1145/3387902.3392617,https://doi.org/10.1145/3387902.3392617,Conference paper,CF '20: Proceedings of the 17th ACM International Conference on Computing Frontiers,"Current quantum computer designs will not scale. To scale beyond small prototypes, quantum architectures will likely adopt a modular approach with clusters of tightly connected quantum bits and sparser connections between clusters. We exploit this clustering and the statically-known control flow of quantum programs to create tractable partitioning heuristics which map quantum circuits to modular physical machines one time slice at a time. Specifically, we create optimized mappings for each time slice, accounting for the cost to move data from the previous time slice and using a tunable lookahead scheme to reduce the cost to move to future time slices. We compare our approach to a traditional statically-mapped, owner-computes model. Our results show strict improvement over the static mapping baseline. We reduce the non-local communication overhead by 89.8% in the best case and by 60.9% on average. Our techniques, unlike many exact solver methods, are computationally tractable.",ACM
"Mykhailova, Mariia and Svore, Krysta M.",Teaching Quantum Computing through a Practical Software-driven Approach: Experience Report,2020,10.1145/3328778.3366952,https://doi.org/10.1145/3328778.3366952,Conference paper,SIGCSE '20: Proceedings of the 51st ACM Technical Symposium on Computer Science Education,"Quantum computing harnesses quantum laws of nature to enable new types of algorithms, not efficiently possible on traditional computers, that may lead to breakthroughs in crucial areas like materials science and chemistry. There is rapidly growing demand for a quantum workforce educated in the basics of quantum computing, in particular in quantum programming. However, there are few offerings for non-specialists and little information on best practices for training computer science and engineering students. In this report we describe our experience teaching an undergraduate course on quantum computing using a practical, software-driven approach. We centered our course around teaching quantum algorithms through hands-on programming, reducing the significance of traditional written assignments and relying instead on self-paced programming exercises (""Quantum Katas''), a variety of programming assignments, and a final project. We observed that the programming sections of the course helped students internalize theoretical material presented during the lectures. In the survey results, students indicated that the programming exercises and the final project contributed the most to their learning process. We describe the motivation for centering the course around quantum programming, discuss major artifacts used in this course, and present our lessons learned and best practices for a future improved course offering. We hope that our experience will help guide instructors who want to adopt a practical approach to teaching quantum computing and will enable more undergraduate programs to offer quantum programming as an elective.",ACM
"O'Neill, Maire and O'Sullivan, Elizabeth and McWilliams, Gavin and Saarinen, Markku-Juhani and Moore, Ciara and Khalid, Ayesha and Howe, James and del Pino, Rafael and Abdalla, Michel and Regazzoni, Francesco and Valencia, Felipe and G\""{u}neysu, Tim and Oder, Tobias and Waller, Adrian and Jones, Glyn and Barnett, Anthony and Griffin, Robert and Byrne, Andrew and Ammar, Bassem and Lund, David",Secure architectures of future emerging cryptography SAFEcrypto,2016,10.1145/2903150.2907756,https://doi.org/10.1145/2903150.2907756,Conference paper,CF '16: Proceedings of the ACM International Conference on Computing Frontiers,"Funded under the European Union's Horizon 2020 research and innovation programme, SAFEcrypto will provide a new generation of practical, robust and physically secure post-quantum cryptographic solutions that ensure long-term security for future ICT systems, services and applications. The project will focus on the remarkably versatile field of Lattice-based cryptography as the source of computational hardness, and will deliver optimised public key security primitives for digital signatures and authentication, as well identity based encryption (IBE) and attribute based encryption (ABE). This will involve algorithmic and design optimisations, and implementations of lattice-based cryptographic schemes addressing cost, energy consumption, performance and physical robustness. As the National Institute of Standards and Technology (NIST) prepares for the transition to a post-quantum cryptographic suite B, urging organisations that build systems and infrastructures that require long-term security to consider this transition in architectural designs; the SAFEcrypto project will provide Proof-of-concept demonstrators of schemes for three practical real-world case studies with long-term security requirements, in the application areas of satellite communications, network security and cloud. The goal is to affirm Lattice-based cryptography as an effective replacement for traditional number-theoretic public-key cryptography, by demonstrating that it can address the needs of resource-constrained embedded applications, such as mobile and battery-operated devices, and of real-time high performance applications for cloud and network management infrastructures.",ACM
"Smith, Kaitlin N. and Thornton, Mitchell A.",A quantum computational compiler and design tool for technology-specific targets,2019,10.1145/3307650.3322262,https://doi.org/10.1145/3307650.3322262,Conference paper,ISCA '19: Proceedings of the 46th International Symposium on Computer Architecture,"Quantum computing, once just a theoretical field, is quickly advancing as physical quantum technology increases in size, capability, and reliability. In order to fully harness the power of a general quantum computer or an application-specific device, compilers and tools must be developed that optimize specifications and map them to a realization on a specific architecture. In this work, a technique and prototype tool for synthesizing algorithms into a quantum computer is described and evaluated. Most recently reported methods produce technologically-independent reversible cascades comprised of a functionally complete set of operators with no regard to actual technologically-dependent cell libraries or constraints due to a device's pre-configured interconnectivity. In contrast, our prototype tool synthesizes algorithms into technologically-dependent specifications that consist of a set of primitives and connectivity constraints present in the computer architecture. The tool performs optimizations based on actual architectural constraints, and a high-quality technology-dependent synthesized result is achieved through the use of optimizing cost functions derived from real hardware and architecture parameters. Additionally, another important aspect of our tool is the incorporation of internal formal equivalence checking that ensures the initially specified algorithm is functionally equivalent to the optimized, technologically-mapped output. Experimental results are provided that target the IBM Q family of quantum computers.","ACM, IEEE"
"Raymond, Jack and Stevanovic, Radomir and Bernoudy, William and Boothby, Kelly and McGeoch, Catherine C. and Berkley, Andrew J. and Farr\'{e",Hybrid Quantum Annealing for Larger-than-QPU Lattice-structured Problems,2023,10.1145/3579368,https://doi.org/10.1145/3579368,Journal,ACM Transactions on Quantum Computing,"Quantum processing units (QPUs) executing annealing algorithms have shown promise in optimization and simulation applications. Hybrid algorithms are a natural bridge to larger applications. We present a simple greedy method for solving larger-than-QPU lattice-structured Ising optimization problems. The method, implemented in the open source D-Wave Hybrid framework, uses a QPU coprocessor operating with generic parameters. Performance is evaluated for standard spin-glass problems on two lattice types with up to 11,616 spin variables, double the size that is directly programmable on any available QPU. The proposed method is shown to converge to low-energy solutions faster than an open source simulated annealing method that is either directly employed or substituted as a coprocessor in the hybrid method. Using newer Advantage QPUs in place of D-Wave 2000Q QPUs is shown to enhance convergence of the hybrid method to low energies and to achieve a lower final energy.",ACM
"Roy, Debapriya Basu and Fritzmann, Tim and Sigl, Georg",Efficient hardware/software co-design for post-quantum crypto algorithm SIKE on ARM and RISC-V based microcontrollers,2020,10.1145/3400302.3415728,https://doi.org/10.1145/3400302.3415728,Conference paper,ICCAD '20: Proceedings of the 39th International Conference on Computer-Aided Design,"Post-quantum cryptography has emerged as a very attractive research topic due to the recent advancements in the development of quantum computers. Among the different available post-quantum public-key algorithms, Supersingular Isogeny Key-Encapsulation (SIKE) has posed a unique design challenge due to its resource intensive arithmetic but is characterized by small key sizes. Existing implementations of SIKE either focus on dedicated accelerators on FPGA platforms or on assembly optimized software implementations on ARM. A full FPGA implementation, though offering low latency and high performance, suffers from the disadvantage of having a large area footprint and a low flexibility. On the other hand, a pure software implementation has lower performance compared to FPGA implementations. In this paper, we propose hardware/software co-design methodologies for SIKE and integrate a redundant number based finite field accelerator into two microcontroller platforms based on ARM and RISC-V. The result shows that our implementation on ARM Cortex-A9 enhanced with a field accelerator offers significant speedup in terms of clock cycles when compared to standalone software implementations on ARM32 and ARM64. Moreover, to show how the communication overhead between processor and accelerator can be mitigated, we integrated the finite field accelerator directly into the core of a RISC-V processor. To the best of our knowledge, this is the first design that applies hardware/software co-design methodologies to implement SIKE on ARM and RISC-V platforms. Our proposed design requires 65500 K clock cycles to execute SIKEp434 on an ARM Cortex-A9 processor. On RISC-V, our proposed design requires only 36900 K clock cycles.","ACM, IEEE"
"Golden, John and B\""{a}rtschi, Andreas and O¡¯Malley, Daniel and Eidenbenz, Stephan",Fair Sampling Error Analysis on NISQ Devices,2022,10.1145/3510857,https://doi.org/10.1145/3510857,Journal,ACM Transactions on Quantum Computing,"We study the status of fair sampling on Noisy Intermediate Scale Quantum (NISQ) devices, in particular the IBM Q family of backends. Using the recently introduced Grover Mixer-QAOA algorithm for discrete optimization, we generate fair sampling circuits to solve six problems of varying difficulty, each with several optimal solutions, which we then run on twenty backends across the IBM Q system. For a given circuit evaluated on a specific set of qubits, we evaluate: how frequently the qubits return an optimal solution to the problem, the fairness with which the qubits sample from all optimal solutions, and the reported hardware error rate of the qubits. To quantify fairness, we define a novel metric based on Pearson¡¯s ¦Ö2 test. We find that fairness is relatively high for circuits with small and large error rates, but drops for circuits with medium error rates. This indicates that structured errors dominate in this regime, while unstructured errors, which are random and thus inherently fair, dominate in noisier qubits and longer circuits. Our results show that fairness can be a powerful tool for understanding the intricate web of errors affecting current NISQ hardware.",ACM
"Alam, Mahabubul and Saki, Abdullah Ash- and Ghosh, Swaroop",An efficient circuit compilation flow for quantum approximate optimization algorithm,2020,10.5555/3437539.3437749,https://dl.acm.org/doi/10.5555/3437539.3437749,Conference paper,DAC '20: Proceedings of the 57th ACM/EDAC/IEEE Design Automation Conference,"Quantum approximate optimization algorithm (QAOA) is a promising quantum-classical hybrid algorithm to solve hard combinatorial optimization problems. The two-qubits gates used in quantum circuit for QAOA are commutative i.e., the order of gates can be altered without changing the logical output. This re-ordering leads to execution of more gates in parallel and a smaller number of additional gates to compile the QAOA circuit resulting in lower circuit depth and gate-count which is beneficial for circuit run-time and noise. A lower number of gates means a lower accumulation of gate errors, and a lower circuit depth means the quantum bits will have a lower time to decohere (lose state). However, finding the best re-ordered circuit is a difficult problem and does not scale well with circuit size. This paper presents a compilation flow with 3 approaches to find an optimal re-ordered circuit with reduced depth and gate count. Our approaches can reduce gate count up to 23.21% and circuit depth up to 53.65%. Our approaches are compiler agnostic, can be integrated with existing compilers, and scalable.",ACM
"Ushijima-Mwesigwa, Hayato and Negre, Christian F. A. and Mniszewski, Susan M.",Graph Partitioning using Quantum Annealing on the D-Wave System,2017,10.1145/3149526.3149531,https://doi.org/10.1145/3149526.3149531,Conference paper,PMES'17: Proceedings of the Second International Workshop on Post Moores Era Supercomputing,"Graph partitioning (GP) applications are ubiquitous throughout mathematics, computer science, chemistry, physics, bio-science, machine learning, and complex systems. Post Moore's era supercomputing has provided us an opportunity to explore new approaches for traditional graph algorithms on quantum computing architectures. In this work, we explore graph partitioning using quantum annealing on the D-Wave 2X machine. Motivated by a recently proposed graph-based electronic structure theory applied to quantum molecular dynamics (QMD) simulations, graph partitioning is used for reducing the calculation of the density matrix into smaller subsystems rendering the calculation more computationally efficient. Unconstrained graph partitioning as community clustering based on the modularity metric can be naturally mapped into the Hamiltonian of the quantum annealer. On the other hand, when constraints are imposed for partitioning into equal parts and minimizing the number of cut edges between parts, a quadratic unconstrained binary optimization (QUBO) reformulation is required. This reformulation may employ the graph complement to fit the problem in the Chimera graph of the quantum annealer. Partitioning into 2 parts and k parts concurrently for arbitrary k are demonstrated with benchmark graphs, random graphs, and small material system density matrix based graphs. Results for graph partitioning using quantum and hybrid classical-quantum approaches are shown to be comparable to current ""state of the art"" methods and sometimes better.",ACM
"Li, Cathy Yuanchen and Sot\'{a}kov\'{a",SalsaPicante: A Machine Learning Attack on LWE with Binary Secrets,2023,10.1145/3576915.3623076,https://doi.org/10.1145/3576915.3623076,Conference paper,CCS '23: Proceedings of the 2023 ACM SIGSAC Conference on Computer and Communications Security,"Learning with Errors (LWE) is a hard math problem underpinning many proposed post-quantum cryptographic (PQC) systems. The only PQC Key Exchange Mechanism (KEM) standardized by NIST [13] is based on module LWE [2], and current publicly available PQ Homomorphic Encryption (HE) libraries are based on ring LWE. The security of LWE-based PQ cryptosystems is critical, but certain implementation choices could weaken them. One such choice is sparse binary secrets, desirable for PQ HE schemes for efficiency reasons. Prior work SALSA[51] demonstrated a machine learning-based attack on LWE with sparse binary secrets in small dimensions (n ¡Ü = 128) and low Hamming weights (h ¡Ü = 4). However, this attack assumes access to millions of eavesdropped LWE samples and fails at higher Hamming weights or dimensions.We present PICANTE, an enhanced machine learning attack on LWE with sparse binary secrets, which recovers secrets in much larger dimensions (up to n=350) and with larger Hamming weights (roughly n/10, and up to h=60 for n=350). We achieve this dramatic improvement via a novel preprocessing step, which allows us to generate training data from a linear number of eavesdropped LWE samples (4n) and changes the distribution of the data to improve transformer training. We also improve the secret recovery methods of SALSA and introduce a novel cross-attention recovery mechanism allowing us to read off the secret directly from the trained models. While PICANTE does not threaten NIST's proposed LWE standards, it demonstrates significant improvement over SALSA and could scale further, highlighting the need for future investigation into machine learning attacks on LWE with sparse binary secrets.",ACM
"Shi, Yunong and Leung, Nelson and Gokhale, Pranav and Rossi, Zane and Schuster, David I. and Hoffmann, Henry and Chong, Frederic T.",Optimized Compilation of Aggregated Instructions for Realistic Quantum Computers,2019,10.1145/3297858.3304018,https://doi.org/10.1145/3297858.3304018,Conference paper,ASPLOS '19: Proceedings of the Twenty-Fourth International Conference on Architectural Support for Programming Languages and Operating Systems,"Recent developments in engineering and algorithms have made real-world applications in quantum computing possible in the near future. Existing quantum programming languages and compilers use a quantum assembly language composed of 1- and 2-qubit (quantum bit) gates. Quantum compiler frameworks translate this quantum assembly to electric signals (called control pulses) that implement the specified computation on specific physical devices. However, there is a mismatch between the operations defined by the 1- and 2-qubit logical ISA and their underlying physical implementation, so the current practice of directly translating logical instructions into control pulses results in inefficient, high-latency programs. To address this inefficiency, we propose a universal quantum compilation methodology that aggregates multiple logical operations into larger units that manipulate up to 10 qubits at a time. Our methodology then optimizes these aggregates by (1) finding commutative intermediate operations that result in more efficient schedules and (2) creating custom control pulses optimized for the aggregate (instead of individual 1- and 2-qubit operations). Compared to the standard gate-based compilation, the proposed approach realizes a deeper vertical integration of high-level quantum software and low-level, physical quantum hardware. We evaluate our approach on important near-term quantum applications on simulations of superconducting quantum architectures. Our proposed approach provides a mean speedup of $5times$, with a maximum of $10times$. Because latency directly affects the feasibility of quantum computation, our results not only improve performance but also have the potential to enable quantum computation sooner than otherwise possible.",ACM
"Karl, Patrick and Schupp, Jonas and Sigl, Georg",Performance and Communication Cost of Hardware Accelerators for Hashing in Post-Quantum Cryptography,2024,10.1145/3676965,https://doi.org/10.1145/3676965,Journal,ACM Trans. Embed. Comput. Syst.,"SPHINCS+ is a signature scheme included in the first NIST post-quantum standard, that bases its security on the underlying hash primitive. As most of the runtime of SPHINCS+ is caused by the evaluation of several hash- and pseudo-random functions, offloading this computation to dedicated hardware accelerators is a natural step. In this work, we evaluate different architectures for hardware acceleration of such a hash primitive with respect to its use-case and evaluate them in the context of SPHINCS+. We attach hardware accelerators for different hash primitives (SHAKE128 and Ascon-Xof for both, full and round-reduced versions) to CPU interfaces having different transfer speeds. We show, that for most use-cases, data transfer determines the overall performance if accelerators are equipped with FIFOs and that reducing the number of rounds in the permutation does not necessarily lead to significant performance improvements when using hardware acceleration. This work extends on a conference paper accepted at COSADE¡¯24, first published in&nbsp;[19], and written by the same authors, where different architectures for hardware accelerators of hash functions are benchmarked and evaluated for SPHINCS+ as a case study. In this paper, we provide results for additional parameter sets for SPHINCS+ and improve the performance of one of the accelerators by adding an additional RISC-V instruction for faster absorption. We then extend the performance benchmark by including the algorithms CRYSTALS-Kyber, CRYSTALS-Dilithium and Falcon. Finally we provide a power/energy comparison for the accelerators.",ACM
"Dinneen, Michael J. and Hua, Richard",Formulating graph covering problems for adiabatic quantum computers,2017,10.1145/3014812.3014830,https://doi.org/10.1145/3014812.3014830,Conference paper,ACSW '17: Proceedings of the Australasian Computer Science Week Multiconference,"We provide efficient quadratic unconstrained binary optimization (QUBO) formulations for the Dominating Set and Edge Cover combinatorial problems suitable for adiabatic quantum computers, which are viewed as a real-world enhanced model of simulated annealing (e.g. a type of genetic algorithm with quantum tunneling). The number of qubits (dimension of QUBO matrices) required to solve these set cover problems are O(n + n lg n) and O(m + n lg n) respectively, where n is the number of vertices and m is the number of edges. We also extend our formulations for the Minimum Vertex-Weighted Dominating Set problem and the Minimum Edge-Weighted Edge Cover problem. Experimental results for the Dominating Set and Edge Cover problems using a D-Wave Systems quantum computer with 1098 active qubit-coupled processors are also provided for a selection of known common graphs.",ACM
"Ma, Linjian and Ye, Jiayu and Solomonik, Edgar",AutoHOOT: Automatic High-Order Optimization for Tensors,2020,10.1145/3410463.3414647,https://doi.org/10.1145/3410463.3414647,Conference paper,PACT '20: Proceedings of the ACM International Conference on Parallel Architectures and Compilation Techniques,"High-order optimization methods, including Newton's method and its variants as well as alternating minimization methods, dominate the optimization algorithms for tensor decompositions and tensor networks. These tensor methods are used for data analysis and simulation of quantum systems. In this work, we introduce AutoHOOT, the first automatic differentiation (AD) framework targeting at high-order optimization for tensor computations. AutoHOOT takes input tensor computation expressions and generates optimized derivative expressions. In particular, AutoHOOT contains a new explicit Jacobian / Hessian expression generation kernel whose outputs maintain the input tensors' granularity and are easy to optimize. The expressions are then optimized by both the traditional compiler optimization techniques and specific tensor algebra transformations. Experimental results show that AutoHOOT achieves competitive CPU and GPU performance for both tensor decomposition and tensor network applications compared to existing AD software and other tensor computation libraries with manually written kernels. The tensor methods generated by AutoHOOT are also well-parallelizable, and we demonstrate good scalability on a distributed memory supercomputer.",ACM
"Saeed, Samah Mohamed and Wille, Robert and Karri, Ramesh",Locking the Design of Building Blocks for Quantum Circuits,2019,10.1145/3358184,https://doi.org/10.1145/3358184,Journal,ACM Trans. Embed. Comput. Syst.,"The research community expects that quantum computers will give economical results for particular problems on which the classical computers break down. Examples include factoring of large numbers, searching in a big database, or simulating chemical reactions to design new drugs. Attempts are ongoing to build up a practical quantum computer. Users (clients) can implement quantum circuits to run on these quantum computers. However, before running the quantum circuit on the quantum computer, the users (clients) should compile, optimize, decompose, and technology map the quantum circuit. In the current embodiment, the resulting quantum circuit runs on a remote and untrusted quantum computer server -- introducing security risks. This study explores the risk of outsourcing the quantum circuit to the quantum computer by focusing on quantum oracles. Quantum oracles are pivotal building blocks and require specialized expertise and means to design. Hence, the designer may protect this proprietary quantum oracle intellectual property (IP) and hide his/her private information. We investigate how to manage that on a quantum computer server using the IBM project QX quantum computer and Qiskit tools as an exemplar.",ACM
"Akhtar, Md Shahbaz and G, Krishnakumar and B, Vishnu and Sinha, Abhishek",Fast and Secure Routing Algorithms for Quantum Key Distribution Networks,2023,10.1109/TNET.2023.3246114,https://doi.org/10.1109/TNET.2023.3246114,Journal,IEEE/ACM Trans. Netw.,"We investigate the problem of fast and secure packet routing in multi-hop Quantum Key Distribution (QKD) networks. We consider a practical trusted-node setup where a QKD protocol randomly generates symmetric private key pairs over each QKD-enabled link in a network. Packets are first encrypted with the available quantum keys and then transmitted on a point-to-point basis. A fundamental problem in this setting is the design of a secure and capacity-achieving routing policy that takes into account the time-varying availability of the encryption keys and diverse physical-layer link capacities. To address this problem, we propose a new secure throughput-optimal policy called Tandem Queue Decomposition (TQD). The TQD policy is designed by incorporating the QKD process into the Universal Max Weight (UMW) routing policy. We show that the TQD policy achieves the entire secure capacity region for a broad class of traffic, including unicast, broadcast, multicast, and anycast. The TQD policy operates by reducing the problem to the generalized network flow problem without the key availability constraints over a transformed network. The throughput-optimality of the TQD policy is established using the Lyapunov stability theory by carefully analyzing the interdependent queueing process and the key-storage dynamics. Finally, we demonstrate the practical efficiency of the TQD policy over the existing routing algorithms by numerically comparing their performance on a realistic simulator built on top of the state-of-the-art OMNeT++ network simulator platform.",ACM
"Cui, Weilong and Tzimpragos, Georgios and Tao, Yu and Mcmahan, Joseph and Dangwal, Deeksha and Tsiskaridze, Nestan and Michelogiannakis, George and Vasudevan, Dilip P. and Sherwood, Timothy",Language Support for Navigating Architecture Design in Closed Form,2019,10.1145/3360047,https://doi.org/10.1145/3360047,Journal,J. Emerg. Technol. Comput. Syst.,"As computer architecture continues to expand beyond software-agnostic microarchitecture to specialized and heterogeneous logic or even radically different emerging computing models (e.g., quantum cores, DNA storage units), detailed cycle-level simulation is no longer presupposed. Exploring designs under such complex interacting relationships (e.g., performance, energy, thermal, frequency) calls for a more integrative but higher-level approach. We propose Charm, a modeling language supporting closed-form high-level architecture modeling. Charm enables mathematical representations of mutually dependent architectural relationships to be specified, composed, checked, evaluated, reused, and shared. The language is interpreted through a combination of automatic symbolic evaluation, scalable graph transformation, and efficient compiler techniques, generating executable DAGs and optimized analysis procedures. Charm also exploits the advancements in satisfiability modulo theory solvers to automatically search the design space to help architects explore multiple design knobs simultaneously (e.g., different CNN tiling configurations). Through two case studies, we demonstrate that Charm allows one to define high-level architecture models in a clean and concise format, maximize reusability and shareability, capture unreasonable assumptions, and significantly ease design space exploration at a high level.","ACM, Web of Science"
"Pasandi, Ghasem and Pedram, Massoud",Depth-bounded Graph Partitioning Algorithm and Dual Clocking Method for Realization of Superconducting SFQ Circuits,2020,10.1145/3412389,https://doi.org/10.1145/3412389,Journal,J. Emerg. Technol. Comput. Syst.,"Superconducting Single Flux Quantum (SFQ) logic with switching delay of 1ps and switching energy of 10?19J is a potential emerging candidate for replacing Complementary Metal Oxide Semiconductor (CMOS) to achieve very high speed and ultra energy efficiency. Conventional SFQ circuits need Full Path Balancing (FPB), which tends to require insertion of many path balancing buffers (D-Flip-Flops). FPB method increases total power consumption as well as total area of the chip. This article presents a novel scheme for realization of superconducting SFQ circuits by introducing a new depth-bounded graph partitioning algorithm in combination with a dual clocking method (slow and fast clock pulses) that minimizes the aforesaid path balancing overheads. Experimental results show that the proposed solution reduces total number of path balancing buffers and total static power consumption by an average of 2.68\texttimes{} and 60%, respectively, when compared to the best of other methods for realizing SFQ circuits. However, our scheme degrades the peak throughput; therefore, it is especially valuable when the actual throughput of the SFQ circuit is much lower than the peak theoretical throughput. This is typically the case due to high-level data dependencies of the application that feeds data into an SFQ circuit.",ACM
"Gabor, Thomas and Feld, Sebastian and Safi, Hila and Phan, Thomy and Linnhoff-Popien, Claudia",Insights on Training Neural Networks for QUBO Tasks,2020,10.1145/3387940.3391470,https://doi.org/10.1145/3387940.3391470,Conference paper,ICSEW'20: Proceedings of the IEEE/ACM 42nd International Conference on Software Engineering Workshops,"Current hardware limitations restrict the potential when solving quadratic unconstrained binary optimization (QUBO) problems via the quantum approximate optimization algorithm (QAOA) or quantum annealing (QA). Thus, we consider training neural networks in this context. We first discuss QUBO problems that originate from translated instances of the traveling salesman problem (TSP): Analyzing this representation via autoencoders shows that there is way more information included than necessary to solve the original TSP. Then we show that neural networks can be used to solve TSP instances from both QUBO input and autoencoders' hidden state representation. We finally generalize the approach and successfully train neural networks to solve arbitrary QUBO problems, sketching means to use neuromorphic hardware as a simulator or an additional co-processor for quantum computing.",ACM
"Pasandi, Ghasem and Pedram, Massoud",Balanced Factorization and Rewriting Algorithms for Synthesizing Single Flux Quantum Logic Circuits,2019,10.1145/3299874.3317967,https://doi.org/10.1145/3299874.3317967,Conference paper,GLSVLSI '19: Proceedings of the 2019 Great Lakes Symposium on VLSI,"Single Flux Quantum (SFQ) logic with switching energy of 100zJ1 and switching delay of 1ps is a promising post-CMOS candidate. Logic synthesis of these magnetic-pulse-based circuits is a very important step in their design flow with a big impact on the total area, power consumption, and critical path delay. SFQ circuits has some properties different from CMOS which should be taken into consideration in the design and implementation flow of these circuits. One of these properties is requirement of path balancing in the standard SFQ circuit design. Standard CMOS-based rewriting and factorization algorithms fail to preserve the balancing property of SFQ circuits. Therefore, they end up generating circuits with huge path balancing overheads. Our proposed balanced factorization and rewriting algorithms are designed specifically to solve this problem. Experimental results show that a combination of balanced factorization and rewriting algorithms reduces the path balancing overhead by an average of 63% for 15 benchmark circuits, and area by up to 23% compared to state-of-the-art logic synthesis tools.",ACM
"Trummer, Immanuel and Koch, Christoph",Multiple query optimization on the D-Wave 2X adiabatic quantum computer,2016,10.14778/2947618.2947621,https://doi.org/10.14778/2947618.2947621,Journal,Proc. VLDB Endow.,"The D-Wave adiabatic quantum annealer solves hard combinatorial optimization problems leveraging quantum physics. The newest version features over 1000 qubits and was released in August 2015. We were given access to such a machine, currently hosted at NASA Ames Research Center in California, to explore the potential for hard optimization problems that arise in the context of databases.In this paper, we tackle the problem of multiple query optimization (MQO). We show how an MQO problem instance can be transformed into a mathematical formula that complies with the restrictive input format accepted by the quantum annealer. This formula is translated into weights on and between qubits such that the configuration minimizing the input formula can be found via a process called adiabatic quantum annealing. We analyze the asymptotic growth rate of the number of required qubits in the MQO problem dimensions as the number of qubits is currently the main factor restricting applicability. We experimentally compare the performance of the quantum annealer against other MQO algorithms executed on a traditional computer. While the problem sizes that can be treated are currently limited, we already find a class of problem instances where the quantum annealer is three orders of magnitude faster than other approaches.",ACM
"Wagner, Alexander and Oberhansl, Felix and Schink, Marc","To Be, or Not to Be Stateful: Post-Quantum Secure Boot using Hash-Based Signatures",2022,10.1145/3560834.3563831,https://doi.org/10.1145/3560834.3563831,Conference paper,ASHES'22: Proceedings of the 2022 Workshop on Attacks and Solutions in Hardware Security,"While research in post-quantum cryptography (PQC) has gained significant momentum, it is only slowly adopted for real-world products. This is largely due to concerns about practicability and maturity. The secure boot process of embedded devices is one scenario where such restraints can result in fundamental security problems. In this work, we present a flexible hardware/software co-design for hash-based signature (HBS) schemes which enables the move to a post-quantum secure boot today. These signature schemes stand out due to their straightforward security proofs and are on the fast track to standardisation. In contrast to previous works, we exploit the performance intensive similarities of the stateful LMS and XMSS schemes as well as the stateless SPHINCS+ scheme. Thus, we enable designers to use a stateful or stateless scheme depending on the constraints of each individual application. To show the feasibility of our approach, we compare our results with hardware accelerated implementations of classical asymmetric algorithms. Further, we lay out the usage of different HBS schemes during the boot process. We compare different schemes, show the importance of parameter choices, and demonstrate the performance gain with different levels of hardware acceleration.",ACM
"Akavia, Adi and Shaul, Hayim and Weiss, Mor and Yakhini, Zohar",Linear-Regression on Packed Encrypted Data in the Two-Server Model,2019,10.1145/3338469.3358942,https://doi.org/10.1145/3338469.3358942,Conference paper,WAHC'19: Proceedings of the 7th ACM Workshop on Encrypted Computing &amp; Applied Homomorphic Cryptography,"Developing machine learning models from federated training data, containing many independent samples, is an important task that can significantly enhance the potential applicability and prediction power of learned models. Since single users, like hospitals or individual labs, typically collect data-sets that do not support accurate learning with high confidence, it is desirable to combine data from several users without compromising data privacy. In this paper, we develop a privacy-preserving solution for learning a linear regression model from data collectively contributed by several parties (""data owners''). Our protocol is based on the protocol of Giacomelli et al. (ACNS 2018) that utilized two non colluding servers and Linearly Homomorphic Encryption (LHE) to learn regularized linear regression models. Our methods use a different LHE scheme that allows us to significantly reduce both the number and runtime of homomorphic operations, as well as the total runtime complexity. Another advantage of our protocol is that the underlying LHE scheme is based on a different (and post-quantum secure) security assumption than Giacomelli et al. Our approach leverages the Chinese Remainder Theorem, and Single Instruction Multiple Data representations, to obtain our improved performance. For a 1000 x 40 linear regression task we can learn a model in a total of 3 seconds for the homomorphic operations, compared to more than 100 seconds reported in the literature. Our approach also scales up to larger feature spaces: we implemented a system that can handle a 1000 x 100 linear regression task, investing minutes of server computing time after a more significant offline pre-processing by the data owners. We intend to incorporate our protocol and implementations into a comprehensive system that can handle secure federated learning at larger scales.",ACM
"Santana, Roberto and Zhu, Zheng and Katzgraber, Helmut G.",Evolutionary Approaches to Optimization Problems in Chimera Topologies,2016,10.1145/2908812.2908914,https://doi.org/10.1145/2908812.2908914,Conference paper,GECCO '16: Proceedings of the Genetic and Evolutionary Computation Conference 2016,"Chimera graphs define the topology of one of the first commercially available quantum computers. A variety of optimization problems have been mapped to this topology to evaluate the behavior of quantum enhanced optimization heuristics in relation to other optimizers, being able to efficiently solve problems classically to use them as benchmarks for quantum machines. In this paper we investigate for the first time the use of Evolutionary Algorithms (EAs) on Ising spin glass instances defined on the Chimera topology. Three genetic algorithms (GAs) and three estimation of distribution algorithms (EDAs) are evaluated over 1000 hard instances of the Ising spin glass constructed from Sidon sets. We focus on determining whether the information about the topology of the graph can be used to improve the results of EAs and on identifying which are the characteristics of the Ising instances that influence the success rate of GAs and EDAs. Chimera graphs define the topology of one of the first commercially available quantum computers. A variety of optimization problems have been mapped to this topology to evaluate the behavior of quantum enhanced optimization heuristics in relation to other optimizers, being able to efficiently solve problems classically to use them as benchmarks for quantum machines. In this paper we investigate for the first time the use of Evolutionary Algorithms (EAs) on Ising spin glass instances defined on the Chimera topology. Three genetic algorithms (GAs) and three estimation of distribution algorithms (EDAs) are evaluated over 1000 hard instances of the Ising spin glass constructed from Sidon sets. We focus on determining whether the information about the topology of the graph can be used to improve the results of EAs and on identifying the characteristics of the Ising instances that influence the success rate of GAs and EDAs.",ACM
"Howe, J. and Moore, C. and O'Neill, M. and Regazzoni, F. and G\""{u}neysu, T. and Beeden, K.",Lattice-based Encryption Over Standard Lattices In Hardware,2016,10.1145/2897937.2898037,https://doi.org/10.1145/2897937.2898037,Conference paper,DAC '16: Proceedings of the 53rd Annual Design Automation Conference,"Lattice-based cryptography has gained credence recently as a replacement for current public-key cryptosystems, due to its quantum-resilience, versatility, and relatively low key sizes. To date, encryption based on the learning with errors (LWE) problem has only been investigated from an ideal lattice standpoint, due to its computation and size efficiencies. However, a thorough investigation of standard lattices in practice has yet to be considered. Standard lattices may be preferred to ideal lattices due to their stronger security assumptions and less restrictive parameter selection process.In this paper, an area-optimised hardware architecture of a standard lattice-based cryptographic scheme is proposed. The design is implemented on a FPGA and it is found that both encryption and decryption fit comfortably on a Spartan-6 FPGA. This is the first hardware architecture for standard lattice-based cryptography reported in the literature to date, and thus is a benchmark for future implementations. Additionally, a revised discrete Gaussian sampler is proposed which is the fastest of its type to date, and also is the first to investigate the cost savings of implementing with ¦Ë/2-bits of precision.Performance results are promising compared to the hardware designs of the equivalent ring-LWE scheme, which in addition to providing stronger security proofs; generate 1272 encryptions per second and 4395 decryptions per second.",ACM
"Gupta, Shikha and Taneja, Sheetal and Kumar, Naveen",Quantum inspired genetic algorithm for community structure detection in social networks,2014,10.1145/2576768.2598277,https://doi.org/10.1145/2576768.2598277,Conference paper,GECCO '14: Proceedings of the 2014 Annual Conference on Genetic and Evolutionary Computation,Community detection is a key problem in social network analysis. We propose a two-phase algorithm for detecting community structure in social networks. First phase employs a local-search method to group together nodes that have a high chance of falling in a single community. The second phase is bi-partitioning strategy that optimizes network modularity and deploys a variant of quantum-inspired genetic algorithm. The proposed algorithm does not require any knowledge of the number of communities beforehand and works well for both directed and undirected networks. Experiments on synthetic and real-life networks show that the method is able to successfully reveal community structure with high modularity.,ACM
"Davydov, Denis and Kronbichler, Martin",Algorithms and Data Structures for Matrix-Free Finite Element Operators with MPI-Parallel Sparse Multi-Vectors,2020,10.1145/3399736,https://doi.org/10.1145/3399736,Journal,ACM Trans. Parallel Comput.,"Traditional solution approaches for problems in quantum mechanics scale as O(M3), where M is the number of electrons. Various methods have been proposed to address this issue and obtain a linear scaling O(M). One promising formulation is the direct minimization of energy. Such methods take advantage of physical localization of the solution, allowing users to seek it in terms of non-orthogonal orbitals with local support.This work proposes a numerically efficient implementation of sparse parallel vectors within the open-source finite element library deal.II. The main algorithmic ingredient is the matrix-free evaluation of the Hamiltonian operator by cell-wise quadrature. Based on an a-priori chosen support for each vector, we develop algorithms and data structures to perform (i) matrix-free sparse matrix multivector products (SpMM), (ii) the projection of an operator onto a sparse sub-space (inner products), and (iii) post-multiplication of a sparse multivector with a square matrix. The node-level performance is analyzed using a roofline model. Our matrix-free implementation of finite element operators with sparse multivectors achieves a performance of 157 GFlop/s on an Intel Cascade Lake processor with 20 cores. Strong and weak scaling results are reported for a representative benchmark problem using quadratic and quartic finite element bases.",ACM
"Mera, Jose Maria Bermudo and Turan, Furkan and Karmakar, Angshuman and Roy, Sujoy Sinha and Verbauwhede, Ingrid",Compact domain-specific co-processor for accelerating module lattice-based KEM,2020,10.5555/3437539.3437650,https://dl.acm.org/doi/10.5555/3437539.3437650,Conference paper,DAC '20: Proceedings of the 57th ACM/EDAC/IEEE Design Automation Conference,"We present a domain-specific co-processor to speed up Saber, a post-quantum key encapsulation mechanism competing on the NIST Post-Quantum Cryptography standardization process. Contrary to most lattice-based schemes, Saber doesn't use NTT-based polynomial multiplication. We follow a hardware-software co-design approach: the execution is performed on an ARM core and only the most computationally expensive operation, i.e., the polynomial multiplication, is offloaded to the co-processor to obtain a compact design. We exploit the idea of distributed computing at micro-architectural level together with novel algorithmic optimizations to achieve approximately a 6 times speedup with respect to optimized software at a small area cost, which we demonstrate on a Zynq-7000 ARM/FPGA SoC.",ACM
"Pakin, Scott",Navigating a Maze using a Quantum Annealer,2017,10.1145/3149526.3149532,https://doi.org/10.1145/3149526.3149532,Conference paper,PMES'17: Proceedings of the Second International Workshop on Post Moores Era Supercomputing,"Quantum annealers exploit quantum effects in an attempt to minimize a classical Hamiltonian function with a higher likelihood of reaching optimality than can be expected from simulated annealing. The key programming challenge is how to express algorithms in terms of the specific Hamiltonian supported by the quantum-annealing hardware. In this paper, we present an algorithm for finding the shortest path through a maze not via a traditional backtracking mechanism but rather by expressing the shortest path as the globally optimal value of a Hamiltonian.",ACM
"Nugteren, Cedric",CLBlast: A Tuned OpenCL BLAS Library,2018,10.1145/3204919.3204924,https://doi.org/10.1145/3204919.3204924,Conference paper,IWOCL '18: Proceedings of the International Workshop on OpenCL,"This work introduces CLBlast, an open-source BLAS library providing optimized OpenCL routines to accelerate dense linear algebra for a wide variety of devices. It is targeted at machine learning and HPC applications and thus provides a fast matrix-multiplication routine (GEMM) to accelerate the core of many applications (e.g. deep learning, iterative solvers, astrophysics, computational fluid dynamics, quantum chemistry). CLBlast has five main advantages over other OpenCL BLAS libraries: 1) it is optimized for and tested on a large variety of OpenCL devices including less commonly used devices such as embedded and low-power GPUs, 2) it can be explicitly tuned for specific problem-sizes on specific hardware platforms, 3) it can perform operations in half-precision floating-point FP16 saving bandwidth, time and energy, 4) it has an optional CUDA back-end, 5) and it can combine multiple operations in a single batched routine, accelerating smaller problems significantly. This paper describes the library and demonstrates the advantages of CLBlast experimentally for different use-cases on a wide variety of OpenCL hardware.",ACM
"Koteshwara, Sandhya and Kumar, Manoj and Pattnaik, Pratap",Analysis and Hardware Optimization of Lattice Post-Quantum Cryptography Workloads,2021,10.1145/3458903.3458905,https://doi.org/10.1145/3458903.3458905,Conference paper,HASP '20: Proceedings of the 9th International Workshop on Hardware and Architectural Support for Security and Privacy,"The mathematical constructs, nature of computations and challenges in optimizing lattice post-quantum cryptographic algorithms on modern many-core processors are discussed in this paper. Identification of time-consuming functions and subsequent hardware optimization using vector units and hardware accelerators of one of the candidates, CRYSTALS-Kyber, leads to performance improvement of around 52% for its SHA3 variant and 83% for its AES variant. Detailed Cycles-per-Instruction (CPI) stack breakdown before and after optimization indicates a CPI of around 0.5 and dominance of load/store operations in these workloads.",ACM
"Bos, Joppe and Costello, Craig and Ducas, Leo and Mironov, Ilya and Naehrig, Michael and Nikolaenko, Valeria and Raghunathan, Ananth and Stebila, Douglas","Frodo: Take off the Ring! Practical, Quantum-Secure Key Exchange from LWE",2016,10.1145/2976749.2978425,https://doi.org/10.1145/2976749.2978425,Conference paper,CCS '16: Proceedings of the 2016 ACM SIGSAC Conference on Computer and Communications Security,"Lattice-based cryptography offers some of the most attractive primitives believed to be resistant to quantum computers. Following increasing interest from both companies and government agencies in building quantum computers, a number of works have proposed instantiations of practical post-quantum key exchange protocols based on hard problems in ideal lattices, mainly based on the Ring Learning With Errors (R-LWE) problem. While ideal lattices facilitate major efficiency and storage benefits over their non-ideal counterparts, the additional ring structure that enables these advantages also raises concerns about the assumed difficulty of the underlying problems. Thus, a question of significant interest to cryptographers, and especially to those currently placing bets on primitives that will withstand quantum adversaries, is how much of an advantage the additional ring structure actually gives in practice. Despite conventional wisdom that generic lattices might be too slow and unwieldy, we demonstrate that LWE-based key exchange is quite practical: our constant time implementation requires around 1.3ms computation time for each party; compared to the recent NewHope R-LWE scheme, communication sizes increase by a factor of 4.7x, but remain under 12 KiB in each direction. Our protocol is competitive when used for serving web pages over TLS; when partnered with ECDSA signatures, latencies increase by less than a factor of 1.6x, and (even under heavy load) server throughput only decreases by factors of 1.5x and 1.2x when serving typical 1 KiB and 100 KiB pages, respectively. To achieve these practical results, our protocol takes advantage of several innovations. These include techniques to optimize communication bandwidth, dynamic generation of public parameters (which also offers additional security against backdoors), carefully chosen error distributions, and tight security parameters.",ACM
"Faz-Hernandez, Armando and L\'{o}pez, Julio and de Oliveira, Ana Karina D. S.",SoK: A Performance Evaluation of Cryptographic Instruction Sets on Modern Architectures,2018,10.1145/3197507.3197511,https://doi.org/10.1145/3197507.3197511,Conference paper,APKC '18: Proceedings of the 5th ACM on ASIA Public-Key Cryptography Workshop,"The latest processors have included extensions to the instruction set architecture tailored to speed up the execution of cryptographic algorithms. Like the AES New Instructions (AES-NI) that target the AES encryption algorithm, the release of the SHA New Instructions (SHA-NI), designed to support the SHA-256 hash function, introduces a new scenario for optimizing cryptographic software. In this work, we present a performance evaluation of several cryptographic algorithms, hash-based signatures and data encryption, on platforms that support AES-NI and/or SHA-NI. In particular, we revisited several optimization techniques targeting multiple-message hashing, and as a result, we reduce by 21% the running time of this task by means of a pipelined SHA-NI implementation. In public-key cryptography, multiple-message hashing is one of the critical operations of the XMSS and XMSS^MT post-quantum hash-based digital signatures. Using SHA-NI extensions, signatures are computed 4x faster; however, our pipelined SHA-NI implementation increased this speedup factor to 4.3x. For symmetric cryptography, we revisited the implementation of AES modes of operation and reduced by 12% and 7% the running time of CBC decryption and CTR encryption, respectively.",ACM
"Fu, X. and Riesebos, L. and Lao, L. and Almudever, C. G. and Sebastiano, F. and Versluis, R. and Charbon, E. and Bertels, K.",A heterogeneous quantum computer architecture,2016,10.1145/2903150.2906827,https://doi.org/10.1145/2903150.2906827,Conference paper,CF '16: Proceedings of the ACM International Conference on Computing Frontiers,"In this paper, we present a high level view of the heterogeneous quantum computer architecture as any future quantum computer will consist of both a classical and quantum computing part. The classical part is needed for error correction as well as for the execution of algorithms that contain both classical and quantum logic. We present a complete system stack describing the different layers when building a quantum computer. We also present the control logic and corresponding data path that needs to be implemented when executing quantum instructions and conclude by discussing design choices in the quantum plane.",ACM
"Aysu, Aydin and Yuce, Bilgiday and Schaumont, Patrick",The Future of Real-Time Security: Latency-Optimized Lattice-Based Digital Signatures,2015,10.1145/2724714,https://doi.org/10.1145/2724714,Journal,ACM Trans. Embed. Comput. Syst.,"Advances in quantum computing have spurred a significant amount of research into public-key cryptographic algorithms that are resistant against postquantum cryptanalysis. Lattice-based cryptography is one of the important candidates because of its reasonable complexity combined with reasonable signature sizes. However, in a postquantum world, not only the cryptography will change but also the computing platforms. Large amounts of resource-constrained embedded systems will connect to a cloud of powerful server computers. We present an optimization technique for lattice-based signature generation on such embedded systems; our goal is to optimize latency rather than throughput. Indeed, on an embedded system, the latency of a single signature for user identification or message authentication is more important than the aggregate signature generation rate. We build a high-performance implementation using hardware/software codesign techniques. The key idea is to partition the signature generation scheme into offline and online phases. The signature scheme allows this separation because a large portion of the computation does not depend on the message to be signed and can be handled before the message is given. Then, we can map complex precomputation operations in software on a low-cost processor and utilize hardware resources to accelerate simpler online operations. To find the optimum hardware architecture for the target platform, we define and explore the design space and implement two design configurations. We realize our solutions on the Altera Cyclone-IV CGX150 FPGA. The implementation consists of a NIOS soft-core processor and a low-latency hash and polynomial multiplication engine. On average, the proposed low-latency architecture can generate a signature with a latency of 96 clock cycles at 40MHz, resulting in a response time of 2.4¦Ìs for a signing request. On equivalent platforms, this corresponds to a performance improvement of 33 and 105 times compared to previous hardware and software implementations, respectively.","ACM, Web of Science"
"Nomura, Ken-ichi and Kalia, Rajiv K. and Nakano, Aiichiro and Vashishta, Priya and Shimamura, Kohei and Shimojo, Fuyuki and Kunaseth, Manaschai and Messina, Paul C. and Romero, Nichols A.",Metascalable quantum molecular dynamics simulations of hydrogen-on-demand,2014,10.1109/SC.2014.59,https://doi.org/10.1109/SC.2014.59,Conference paper,"SC '14: Proceedings of the International Conference for High Performance Computing, Networking, Storage and Analysis","We enabled an unprecedented scale of quantum molecular dynamics simulations through algorithmic innovations. A new lean divide-and-conquer density functional theory algorithm significantly reduces the prefactor of the O(N) computational cost based on complexity and error analyses. A globally scalable and locally fast solver hybridizes a global real-space multigrid with local plane-wave bases. The resulting weak-scaling parallel efficiency was 0.984 on 786,432 IBM Blue Gene/Q cores for a 50.3 million-atom (39.8 trillion degrees-of-freedom) system. The time-to-solution was 60-times less than the previous state-of-the-art, owing to enhanced strong scaling by hierarchical band-spacedomain decomposition and high floating-point performance (50.5% of the peak). Production simulation involving 16,661 atoms for 21,140 time steps (or 129,208 self-consistent-field iterations) revealed a novel nanostructural design for on-demand hydrogen production from water, advancing renewable energy technologies. This metascalable (or ""design once, scale on new architectures"") algorithm is used for broader applications within a recently proposed divide-conquer-recombine paradigm.",ACM
A. Bajaj; A. Abraham,Test Case Prioritization and Reduction Using Hybrid Quantum-behaved Particle Swarm Optimization,2022,10.1109/CEC55065.2022.9870238,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9870238,Conference Paper,2022 IEEE Congress on Evolutionary Computation (CEC),"Regression testing is an integral part of the software evolution and maintenance phase as it ensures that the modified software is working correctly after any upgrades. Test case prioritization and reduction minimize cost and effort needed for retesting by scheduling critical test cases before the less critical ones and removing redundant test cases. The criticality and redundancy of the test cases depend on several testing criteria. This paper empirically analyzed the effect of different testing criteria like code and fault coverage on the techniques' performance. This paper proposed a discrete Quantum-behaved particle swarm optimization (QPSO) for enhancing efficiency of test case prioritization. The algorithm is improved by replacing the random distribution with Gaussian probability to escape from the local optima. The evolution stagnation issue is further resolved by hybridizing it with genetic algorithm (QPSO-GA). In addition to prioritizing the test cases, the algorithm also reduces the test suite size through the test suite reduction approach. The experiments are conducted on different versions of three pro-grams from the open-source software infrastructure repository. The performance is compared with the average percentage of statement coverage, fault detection, and their combinations with the cost. Consequently, suite reduction, fault detection capability losses, and coverage loss percentage are also drawn for test suite reduction. The proposed algorithms outperformed the random search, ant colony optimization, differential evolution, GA, PSO, and adaptive PSO for all the evaluation metrics.",IEEE
M. I. Mazhar; A. Tiwari; N. Ali; Britant; A. Patil; R. K. Neiwal,Benchmarking Matrix Multiplications For Variable Qubit Size And Depth,2024,10.23919/ITUK62727.2024.10772828,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10772828,Conference Paper,2024 ITU Kaleidoscope: Innovation and Digital Transformation for a Sustainable World (ITU K),"To emulate a quantum computation on a classical computer i.e. the evolution of the unitary operations on the wave function of the particle in quantum mechanics, we have to perform unitary matrix and normalized vector multiplications in the high-level programming languages of Python, C++, Java, etc. Quantum Libraries already available perform the matrix-vector multiplication in the backend using the numpy libraries of Python like Qiskit or use a C++ wrapper to further optimize the runtime it as in Qiskit-Aer Simulators. Since a fully functioning fault-tolerant computer is decades away, it is in our best interest to design new quantum algorithms and develop accelerator test beds for Quantum Emulations. All the quantum computer operations can be emulated on a classical computer, with the only downside being that the matrix multiplications scale up as O (N3) in runtime. In contrast, the quantum computer scales it up as O (N2 log2N), where N = 2n, where N is the matrix dimension, where n is the number of qubits, so the runtime for quantum emulations on the classical computer increases exponentially with increase in number of qubits and increases linearly with increase in number of depths, complexity wise. Though it is not possible to change the exponential index, it is possible to reduce the runtime for quantum emulations on classical computers by use of GPU and Alveo Accelerator Cards, and also code optimization on the software side like using a C++ wrapper. In this paper, we will benchmark the matrix-matrix multiplications on HPC Accelerator Cards varying the qubit size and the depth of the quantum circuit and provide a universal mathematical equation for the runtime on the GPU and Alveo Vector Cards for two variables of qubit size and quantum circuit depth. So a theoretical limit on qubit size and qubit depth exactly can be established for quantum emulations on present classical supercomputers.",IEEE
Y. Xie; X. Yang; Q. Zhu; Z. Bi,Fault Location in Active Distribution Network Under Hybrid Classical Quantum Computing Architecture,2024,10.1109/ACCESS.2024.3482308,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10720757,Journal,IEEE Access,"At present, research on the combination of quantum computing and artificial intelligence algorithms applied to the fault location of distribution networks is very sufficient. Because this type of algorithm usually uses the switching function in logical form, it leads to numerical instability and is difficult to expand to the problem of a larger scale distribution network. Therefore, in this study, we propose a hybrid classical quantum computing architecture model for the fusion of quantum annealing and fault location in distribution networks. Firstly, an algebraic objective function suitable for D-wave quantum computer was constructed according to the distributed idea, and the feasibility of the model was verified by using quantum platform. Then, a decoupling optimization model was proposed to improve the poor accuracy of the model in the case of multiple faults, and the decoupling optimization operation was completed by classical calculation and verified experimentally on the quantum platform. Then the original model and decoupled optimization model were applied to fault scenarios of 20-node single power distribution network, 33-node single power distribution network, 9-node distribution network with distributed generation source(DG), 16-node distribution network with DGs, and 33-node distribution network with DGs. The performance of the two models was compared in five aspects: the accuracy of fault location, quantum bit resource consumption, model parameter range, running time and fault tolerance performance. Finally, the quantum classical hybrid decoupling optimization model was compared with the simulated annealing algorithm, the quantum annealing algorithm and the improved quantum annealing algorithm in three aspects of accuracy, running time and quantum bit consumption resources. Both the comparison between the two models constructed in this paper and the comparison between the hybrid model and the classical model can reflect that the decoupled optimization model is committed to realizing the fault location of a larger scale distribution network with fewer quantum bits, and can play the advantages of the classical quantum hybrid architecture model.",IEEE
A. K. Mandal; M. Nadim; C. K. Roy; B. Roy; K. A. Schneider,Evaluating the Performance of a D-Wave Quantum Annealing System for Feature Subset Selection in Software Defect Prediction,2024,10.1109/QCE60285.2024.10261,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10821057,Conference Paper,2024 IEEE International Conference on Quantum Computing and Engineering (QCE),"Predicting software defects early in the development process not only enhances the quality and reliability of the software but also decreases the cost of development. A wide range of machine learning techniques can be employed to create software defect prediction models, but the effectiveness and accuracy of these models are often influenced by the choice of appropriate feature subset. Since finding the optimal feature subset is computationally intensive, heuristic and metaheuristic approaches are commonly employed to identify near-optimal solutions within a reasonable time frame. Recently, the quantum computing paradigm quantum annealing (QA) has been deployed to find solutions to complex optimization problems. This opens up the possibility of addressing the feature subset selection problem with a QA machine. Although several strategies have been proposed for feature subset selection using a QA machine, little exploration has been done regarding the viability of a QA machine for feature subset selection in software defect prediction. This study investigates the potential of D-Wave QA system for this task, where we formulate a mutual information (MI)-based filter approach as an optimization problem and utilize a D-Wave Quantum Processing Unit (QPU) solver as a QA solver for feature subset selection. We evaluate the performance of this approach using multiple software defect datasets from the AEEM, JIRA, and NASA projects. We also utilize a D-Wave classical solver for comparative analysis. Our experimental results demonstrate that QA-based feature subset selection can enhance software defect prediction. Although the D-Wave QPU solver exhibits competitive prediction performance with the classical solver in software defect prediction, it significantly reduces the time required to identify the best feature subset compared to its classical counterpart.",IEEE
J. Speer; J. K. Nurminen,Program Equivalence Checking for the Facilitation of Quantum Offloading,2021,10.1109/CCWC51732.2021.9375948,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9375948,Conference Paper,2021 IEEE 11th Annual Computing and Communication Workshop and Conference (CCWC),"Computational offloading involves the transfer of computational tasks to a separate device. We apply this concept to quantum computing, whereby particular algorithms (i.e. ¡°quantum algorithms¡±) are automatically recognized and executed on a quantum computer. We propose a method that utilizes program equivalence checking to discern between code suited for execution on a conventional computer and a quantum computer. This process involves comparing a quantum algorithm's implementation with code written by a programmer, with semantic equivalence between the two implying that the programmer's code should be executed on a quantum computer instead of a conventional computer. Using a novel compiler optimization verification tool named CORK, we test for semantic equivalence between a portion of Shor's algorithm (the ¡°prototype¡±) and various modified versions of this code (representing the arbitrary code written by a programmer). Some of the modified versions are intended to be semantically equivalent to the prototype while others semantically inequivalent. Our approach is able to correctly determine semantic equivalence or semantic inequivalence in a majority of cases.",IEEE
A. Muqeet; S. Ali; P. Arcaini,Quantum Program Testing Through Commuting Pauli Strings on IBM¡¯s Quantum Computers,2024,10.1145/3691620.3695275,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10764879,Conference Paper,2024 39th IEEE/ACM International Conference on Automated Software Engineering (ASE),"The most promising applications of quantum computing are centered around solving search and optimization tasks, particularly in fields such as physics simulations, quantum chemistry, and finance. However, the current quantum software testing methods face practical limitations when applied in industrial contexts: (i) they do not apply to quantum programs most relevant to the industry, (ii) they require a full program specification, which is usually not available for these programs, and (iii) they are incompatible with error mitigation methods currently adopted by main industry actors like IBM. To address these challenges, we present QOPS, a novel quantum software testing approach. QOPS introduces a new definition of test cases based on Pauli strings to improve compatibility with different quantum programs. QOPS also introduces a new test oracle that can be directly integrated with industrial APIs such as IBM¡¯s Estimator API and can utilize error mitigation methods for testing on real noisy quantum computers. We also leverage the commuting property of Pauli strings to relax the requirement of having complete program specifications, making QOPS practical for testing complex quantum programs in industrial settings. We empirically evaluate QOPS on 194,982 real quantum programs, demonstrating effective performance in test assessment compared to the state-of-the-art with a perfect F1-score, precision, and recall. Furthermore, we validate the industrial applicability of QOPS by assessing its performance on IBM¡¯s three real quantum computers, incorporating both industrial and open-source error mitigation methods.CCS Concepts? Software and its engineering ¡ú Correctness; ? Theory of computation ¡ú Quantum computation theory; ? Computer systems organization ¡ú Quantum computing",IEEE
K. B. Prakash,Unleashing Quantum Neural Networks: Solving Parameterized Quantum Circuit Challenges,2024,10.1109/AMATHE61652.2024.10582073,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10582073,Conference Paper,2024 International Conference on Advances in Modern Age Technologies for Health and Engineering Science (AMATHE),"A possible approach to tackling computationally demanding issues beyond the capabilities of conventional algorithms is the use of quantum circuits, which provide a fundamental foundation for utilizing the power of quantum computation. This abstract examines how quantum circuits are implemented, emphasizing important topics such as circuit optimization, gate operations, and qubit manipulation. We explore different methods of encoding quantum information into topological qubits, trapped ions, and superconducting circuits, among other physical qubit formats. Furthermore, we go over the function of gate operations in quantum circuits, emphasizing crucial gates like phase, Hadamard, and CNOT gates, which serve as the foundation for quantum algorithms. Additionally, we look at methods for maximizing the efficiency and dependability of quantum processing by designing quantum circuits to minimize gate counts, depth, and error rates. To enhance the capabilities of quantum computing, this abstract presents a novel synthesis of quantum neural networks (QNNs) and quantum parameterized circuits. Through the use of parameterized quantum circuits' inherent flexibility, our approach makes it easier to design and optimize quantum circuits with flexible parameters, providing a flexible foundation for a variety of quantum algorithms. Using this amalgamation, we unleash the capacity of quantum computers to address intricate optimization and machine learning assignments with unparalleled effectiveness and expandability. Our solution bridges the gap between traditional machine learning approaches and quantum computing paradigms by enabling the smooth integration of classical data processing techniques with quantum computation. We use quantum states as data representations in our implementation of quantum neural networks, and we optimize trainable parameters to meet predetermined goals. This new paradigm opens up the investigation of the inherent features of quantum states and provides new perspectives on their processing power compared to their classical counterparts. We show, by thorough testing and analysis, how effective quantum parameterized circuits and QNNs are at solving practical problems in a variety of fields. Our work sets the ground for revolutionary breakthroughs in quantum information processing by pushing the boundaries of quantum computation and machine learning integration, offering hitherto unseen insights and solutions to challenging challenges in science, engineering, and beyond.",IEEE
D. Zoni; A. Galimberti; W. Fornaciari,Efficient and Scalable FPGA-Oriented Design of QC-LDPC Bit-Flipping Decoders for Post-Quantum Cryptography,2020,10.1109/ACCESS.2020.3020262,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9180360,Journal,IEEE Access,"Considering code-based cryptography, quasi-cyclic low-density parity-check (QC-LDPC) codes are foreseen as one of the few solutions to design post-quantum cryptosystems. The bit-flipping algorithm is at the core of the decoding procedure of such codes when used to design cryptosystems. An effective design must account for the computational complexity of the decoding and the code size required to ensure the security margin against attacks led by quantum computers. To this end, it is of paramount importance to deliver efficient and flexible hardware implementations to support quantum-resistant public-key cryptosystems, since available software solutions cannot cope with the required performance. This manuscript proposes an efficient and scalable architecture for the implementation of the bit-flipping procedure targeting large QC-LDPC codes for post-quantum cryptography. To demonstrate the effectiveness of our solution, we employed the nine configurations of the LEDAcrypt cryptosystem as representative use cases for QC-LDPC codes suitable for post-quantum cryptography. For each configuration, our template architecture can deliver a performance-optimized decoder implementation for all the FPGAs of the Xilinx Artix-7 mid-range family. The experimental results demonstrate that our optimized architecture allows the implementation of large QC-LDPC codes even on the smallest FPGA of the Xilinx Artix-7 family. Considering the implementation of our decoder on the Xilinx Artix-7 200 FPGA, the experimental results show an average performance speedup of 5 times across all the LEDAcrypt configurations, compared to the official optimized software implementation of the decoder that employs the Intel AVX2 extension.","IEEE, Web of Science"
A. Giorgio,Project and Implementation of a Quantum Logic Gate Emulator on FPGA Using a Model-Based Design Approach,2024,10.1109/ACCESS.2024.3377458,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10472476,Journal,IEEE Access,"Quantum computing emulators are widely used for testing quantum algorithms ideally before executing them on real quantum processors. Therefore, researchers are very active in developing emulators primarily on FPGAs. This project is complex and requires a long time and a specific expertise if carried out following the low-level design approach using a Hardware Description Language (HDL). This paper describes, step by step, the process of quick designing a quantum gate emulator using a much simpler high-level design approach. It begins with the development of a quantum gate simulator in the MATLAB? environment, and subsequently translates it into an HDL design for FPGA implementation by using the MATLAB¡¯s HDL Coder toolbox. However, while code translation may seem straightforward using MATLAB toolboxes, it becomes a non-trivial task when transitioning from a quantum computing simulator to an HDL-based quantum computing emulator. Thus, it was necessary to conduct an in-depth study to implement a quantum computing simulator in MATLAB, enabling an error-free translation of HDL code. The developed method enables the designer to leverage the highly useful and straightforward model-based design approach offered by MATLAB, rather than directly the more complex HDL approach, returning a highly optimized HDL code for configuring the FPGA as a quantum computing emulator. This topic makes the design of quantum emulators on FPGA quick, reliable, optimized and without the need for specialized hardware design skills. Additionally, two implementation examples have been described using Altera/Intel FPGA on development boards DE1_SoC and DE5a-NET DDR4 provided by Terasic Inc.",IEEE
A. Guerrieri; G. Da Silva Marques; F. Regazzoni; A. Upegui,H-Saber: An FPGA-Optimized Version for Designing Fast and Efficient Post-Quantum Cryptography Hardware Accelerators,2023,10.1109/ISQED57927.2023.10129356,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10129356,Conference Paper,2023 24th International Symposium on Quality Electronic Design (ISQED),"With the performance promises of quantum computers, standard encryption algorithms can be defeated. For this reason, a set of new quantum-resistant algorithms have been proposed and submitted for a standardization contest initiated by NIST. While the submission requirement was ANSI C for the reference implementation, NIST encouraged providing software implementations optimized for different target platforms, such as high-performance CPUs, embedded microcontrollers, and FPGAs. Yet, none of the algorithms submitted any FPGA-optimized code, due to the large and expensive development time required for coding at RTL. High-Level synthesis (HLS) covers the gap by creating automatically hardware code for FPGA out of C/C++. However, the quality of results is suboptimal due to the limitation imposed by the inadequacy of source code for HLS. In this paper, we propose a version of Saber¡¯s code optimized for FPGA targets. We show how we detected and improved the performance of the reference code, achieving competitive results compared to the hand-made RTL-based designs.",IEEE
A. P. Ngo; H. T. Nguyen,Quantum Combinatorial Optimization Algorithms for Network Reconfiguration: QRAO vs. QAOA,2024,10.1109/NAPS61145.2024.10741660,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10741660,Conference Paper,2024 56th North American Power Symposium (NAPS),"This paper reviews a hybrid quantum-classical distributed algorithm for NP-hard combinatorial optimization problems, which is embedded in IBM Qiskit's Alternating Direction Method of Multipliers (ADMM) optimizer. We demonstrate a proof of concept for solving Mixed-Integer Convex Programs (MICP) in power system applications using a use case on power distribution network reconfiguration in IBM quantum computers. Using the Qiskit ADMM optimizer, the MICP is decomposed into two subproblems: a quadratic unconstrained binary optimization (QUBO) solved by quantum algorithms and a convex one solved by classical solvers. Our essential contribution is integrating the Quantum Random Access Optimization (QRAO) into the quantum-classical distributed framework and the existing Quantum Approximate Optimization Algorithm (QAOA) implemented in the Qiskit ADMM Optimizer. QRAO utilizes Quantum Random Access Codes (QRACs) to minimize qubit requirements and utilizes quantum state rounding for solution extraction. We examine the impact of noise on solutions derived from QRAO and compare them with results from QAOA using a use case on network reconfiguration in response to faults in the power distribution system.",IEEE
M. Amy; D. Maslov; M. Mosca,Polynomial-Time T-Depth Optimization of Clifford+T Circuits Via Matroid Partitioning,2014,10.1109/TCAD.2014.2341953,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6899791,Journal,IEEE Transactions on Computer-Aided Design of Integrated Circuits and Systems,"Most work in quantum circuit optimization has been performed in isolation from the results of quantum fault-tolerance. Here we present a polynomial-time algorithm for optimizing quantum circuits that takes the actual implementation of fault-tolerant logical gates into consideration. Our algorithm resynthesizes quantum circuits composed of Clifford group and  $T$  gates, the latter being typically the most costly gate in fault-tolerant models, e.g., those based on the Steane or surface codes, with the purpose of minimizing both  $T$ -count and  $T$ -depth. A major feature of the algorithm is the ability to resynthesize circuits with ancillae at effectively no additional cost, allowing space-time trade-offs to be easily explored. The tested benchmarks show up to 65.7% reduction in  $T$ -count and up to 87.6% reduction in  $T$ -depth without ancillae, or 99.7% reduction in  $T$ -depth using ancillae.",IEEE
L. Wei; Z. Ma; Y. Cheng; Q. Liu,Genetic Algorithm Based Quantum Circuits Optimization for Quantum Computing Simulation,2021,10.1109/IISA52424.2021.9555575,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9555575,Conference Paper,"2021 12th International Conference on Information, Intelligence, Systems & Applications (IISA)","Quantum computing simulation platform can simulate the computation results of the quantum computer based on traditional computers, which is an effective way to promote the development of quantum computing software, algorithms and hardware at the current immature stage of the real quantum computer. Since quantum computers have exponential calculation acceleration compared with traditional computers, the main problems in implementing quantum computing simulation on traditional computers are low computational efficiency and long time-consuming. A quantum circuit which is a sequence of quantum gates acting on a collection of qubits is the general quantum computing model. So by the means of quantum circuit optimization, the calculation speed can be significantly increased while keeping the calculation result unchanged. The existing empirical rules of quantum circuit optimization methods have limitations and there is no common and automatic quantum circuit optimization method. In this paper, a general and automatic quantum circuit optimization method based on the genetic algorithm is proposed, by which the equivalent optimal quantum circuit is obtained through a finite number of searching in a large searching space. This method is not limited by the hardware of the quantum computing simulation and the composition of the quantum circuit. The experimental results show that for the QFT algorithm of 29 qubits, the running time can be shortened by 41.4% and for the variational circuit of 6 qubits, the running time can be shortened by 18.8% compared with the state-of-the-art quantum circuit optimization method. So this method can improve the quantum computing simulation capability and operating efficiency and provide a rapid development way for quantum algorithms and applications.",IEEE
D. J; M. Chandran,An optimized clustering model for heterogeneous cross-project defect prediction using Quantum Crow search,2022,10.1109/ICoSEIT55604.2022.10030011,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10030011,Conference Paper,2022 1st International Conference on Software Engineering and Information Technology (ICoSEIT),"To improve the process of software development, the present technology pushes its boundary in software defect prediction by incorporating heterogenous cross projects, where the source and the target projects used for training and testing are with different metrics. Existing literature of Heterogeneous Cross Project Defect Prediction HCPDP focus on certainty theory where the case of inconsistency and hesitancy in categorizing unknown modules as defect or defect free is still challenging. The primary objective of this paper is to build an uncertainty model which has the ability to determine more precisely the inconsistent and vague unknown pattern of modules using unsupervised algorithm. The proposed model introduced uncertainty theory based unsupervised learning model to effectively handle the issue of hesitancy in determining software modules as defect or defect free. This paper contributed quantum crow search optimization algorithm to choose potential feature subset for feature reduction on target projects for mapping the source and target project to a projective matrix. The similarity among the instances are determined and clustered using intuitionistic fuzzy $C$ means clustering. Each instance is represented in terms of belongingness, non-belongingness and hesitancy degree to handle vagueness and inconsistency avail in the HCPDP datasets. We conduct experiments on six different projects from five heterogenous datasets and results proved that the performance of the Quantum Crow Search Optimized Intuitionistic Fuzzy C Means Clustering (QCSO-IFCMC) achieves higher accuracy with its ability of avoiding local converge in software defect prediction compared to the existing state of arts clustering models.",IEEE
A. R. Borah,Enhancing Network Slicing Efficiency in Self-Organizing Networks Using Quantum Computing,2023,10.1109/ICOSEC58147.2023.10276206,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10276206,Conference Paper,2023 4th International Conference on Smart Electronics and Communication (ICOSEC),"With the proliferation of mobile devices and the growing demand for diverse applications, network operators are facing significant challenges in efficiently managing and optimizing network resources. Network slicing has emerged as a promising solution to address these challenges by enabling the creation of multiple virtual networks on a shared physical infrastructure. However, achieving optimal network slicing efficiency remains a critical task due to resource allocation and management complexity. This research proposes a novel approach to enhance network slicing efficiency in self-organizing networks (SONs) using quantum computing. Quantum computing offers unprecedented computational power and the ability to process large-scale optimization problems efficiently. By harnessing the power of quantum algorithms, the study aims to address the resource allocation and optimization challenges in network slicing. The proposed approach leverages quantum-inspired optimization algorithms, such as quantum annealing and quantum-inspired evolutionary algorithms, to tackle the resource allocation problem. These algorithms exploit the inherent parallelism and superposition properties of quantum computing to explore a vast search space and identify optimal solutions in a significantly reduced time compared to classical optimization techniques. Moreover, a quantum-assisted self-organizing mechanism is introduced that dynamically adapts network slices based on real-time traffic patterns and quality of service requirements. This mechanism utilizes quantum machine learning techniques to analyze network data and predict future traffic demands, enabling proactive resource allocation and efficient utilization. To evaluate the effectiveness of the proposed approach, extensive simulations and comparisons with classical optimization techniques are conducted in a realistic SON environment using the NS2 Simulator. The results demonstrate the superior performance of quantum computing-based approach, showcasing improved network slicing efficiency, reduced resource wastage, and enhanced service quality",IEEE
M. P. Usaola; I. G. -R. de Guzm¨¢n; M. ?. Serrano; M. Piattini,Generating Quantum Software from Truth Tables,2024,10.1109/QCE60285.2024.10282,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10820993,Conference Paper,2024 IEEE International Conference on Quantum Computing and Engineering (QCE),"Quantum computing promises significant advancements over classical computing by enabling exponential speedups for specific problems. Despite its potential, quantum software development remains challenging due to its complexity, cost, and susceptibility to errors. Aligned with the novel paradigm of Quantum Software Engineering (QSE), this paper introduces a tool designed to automate the generation of quantum software components from truth tables. The tool simplifies the development process by allowing users to specify expected output values for given inputs, which the tool then translates into the corresponding quantum code. This approach reduces the manual effort required and helps ensure accuracy in quantum program development. Our method not only streamlines quantum software generation but also optimizes the resulting quantum circuits by minimizing unnecessary computations. The paper provides a detailed overview of the algorithm, tool implementation, and potential applications, highlighting the tool's efficacy in facilitating more efficient quantum software development.",IEEE
Y. Peng; X. Li; Z. Liang; Y. Wang,HyQ2:?A?Hybrid?Quantum?Neural?Network for?NextG?Vulnerability?Detection,2024,10.1109/TQE.2024.3481280,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10716796,Journal,IEEE Transactions on Quantum Engineering,"As fifth-generation (5G) and next-generation communication systems advance and find widespread application in critical infrastructures, the importance of vulnerability detection becomes increasingly critical. The growing complexity of these systems necessitates rigorous testing and analysis, with stringent requirements for both accuracy and speed. In this article, we present a state-of-the-art supervised hybrid quantum neural network named HyQ2 for vulnerability detection in next-generation wireless communication systems. The proposed HyQ2 is integrated with graph-embedded and quantum variational circuits to validate and detect vulnerabilities from the 5G system's state transitions based on graphs extracted from log files. We address the limitations of classical machine learning models in processing the intrinsic linkage relationships of high-dimensional data. These models often suffer from dead neurons and excessively large outputs caused by the unbounded range of the rectified linear unit (ReLU) activation function. We propose the HyQ2 method to overcome these challenges, which constructs quantum neurons by selecting random neurons' outputs from a classical neural network. These quantum neurons are then utilized to capture more complex relationships, effectively limiting the ReLU output. Using only two qubits, our validation results demonstrate that HyQ2 outperforms traditional classical machine learning models in vulnerability detection. The small and compact variational circuit of HyQ2 minimizes the noise and errors in the measurement. Our results demonstrate that HyQ2 achieves a high area under the curve (AUC) value of 0.9708 and an accuracy of 95.91%. To test the model's performance in quantum noise environments, we simulate quantum noise by adding bit flipping, phase flipping, amplitude damping, and depolarizing noise. The results show that the prediction accuracy and receiver operating characteristic AUC value fluctuate around 0.2%, indicating HyQ2¡¯s robustness in noisy quantum environments. In addition, the noise resilience and robustness of the HyQ2 algorithm were substantiated through experiments on the IBM quantum machine with only a 0.2% decrease compared to the simulation results.",IEEE
X. Zhang; J. Zhang; Y. Hu; T. Tang; J. Yang; Y. Zhang,Structural Damage Recognition Based on the Finite Element Method and Quantum Particle Swarm Optimization Algorithm,2020,10.1109/ACCESS.2020.3026068,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9204631,Journal,IEEE Access,"Structural damage recognition is always the concerned focus in many fields like aerospace, petroleum and petrochemical industry, industrial production and civil life. For damage recognition in complex structure or structural interior, especially somewhere sensors can't go, minor damage is often hard identified by not only traditional nondestructive testing methods like ultrasonic testing, radiographic testing, magnetic particle testing, penetrant testing, eddy current testing, but also the current popular ultrasonic guided wave based on the piezoelectric wafer, electromagnetic acoustic transducer or magnetostrictive sensor, which is mainly because the response signals are always affected by many structural features. In this article, the advanced global search algorithm, quantum particle swarm optimization algorithm is first combined with the finite element method to accurately recognize the structural damage based on the conductance-frequency spectrum resulted from electromechanical impedance method. Meanwhile, the objective function is designed to compare the difference of peak frequency variations in the experiment and finite element calculation respectively. By adopting the stiffness reduction method of the elements near the structural damage, the identification efficiency is largely improved for no need to repeatedly partition the model grid. And after multiple iteration optimization of the artificial intelligence algorithm - quantum particle swarm optimization algorithm, the identification error of damage parameters including location and degree can be reduced to below 4 percent. Therefore, the combination of finite element method and quantum particle swarm optimization algorithm is quite effective for guaranteeing high accuracy and efficiency for damage parameters' recognition in complex structures.",IEEE
D. Owusu-Antwi; P. Gokhale,Low-level circuit optimization for the quantum approximate optimization algorithm,2023,10.1049/icp.2023.3269,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10401153,Conference Paper,Quantum Engineering and Technology Conference (QET 2023),"Quantum computer systems require robust software integration to support quantum algorithm development towards addressing practical challenges in many important problem areas including logistics, chemistry, and AI/ML. Researchers predict quantum algorithms will achieve computational advantage over classical algorithms for these specific problem areas in the Noisy Intermediate Scale Quantum (NISQ) era [1]. We consider one such algorithm, the Quantum Approximate Optimization Algorithm (QAOA), a variational quantum algorithm for solving combinatorial optimization problems [2]. QAOA promises to be a practical alternative to inefficient classical algorithms for large problem sizes, but quantum hardware capabilities lag behind the requirements for practical application. We show that the Superstaq quantum compiler can support performance improvements for QAOA by exploiting optimization opportunities only revealed at levels lower than logic gates, i.e., at the level of pulses, quantum hardware instructions.",IEEE
J. Romero-Alvarez; J. Alvarado-Valiente; E. Moguel; J. Garcia-Alonso; J. M. Murillo,A Workflow for the Continuous Deployment of Quantum Services,2023,10.1109/SSE60056.2023.00015,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10234337,Conference Paper,2023 IEEE International Conference on Software Services Engineering (SSE),"The rapid advancements in quantum computing have opened new possibilities for solving complex problems in various fields, including cryptography, optimization, and simulation. However, the current approaches to quantum computing often require a deep understanding of quantum hardware and low-level programming languages, making it difficult for software developers to create and deploy quantum services. This paper argues for the adaptation of Service-Oriented Computing principles to quantum computing, enabling a level of abstraction from hardware that allows developers to focus on application development. This will allow developers to create and deploy quantum services, similarly to how Service-Oriented Computing has made it easier to develop traditional software services. This paper presents a Continuous Deployment approach for quantum service development, which involves the generation and deployment of quantum services. To do that, we propose an extension of the OpenAPI specification to generate services implementing a quantum algorithm. To validate the feasibility of the proposed process, we use a variety of quantum algorithm implementations to test their generation and deployment of quantum services.",IEEE
H. M. H. Saad; R. K. Chakrabortty; S. Elsayed,Quantum-Inspired Differential Evolution for Resource-Constrained Project-Scheduling: Preliminary Study,2021,10.1109/CEC45853.2021.9504970,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9504970,Conference Paper,2021 IEEE Congress on Evolutionary Computation (CEC),"The Resource-Constrained Project Scheduling Problem (RCPSP) is an NP-hard optimisation problem that can be found in many real-world applications. Considerable research effort has been put into overcoming the difficulties in solving the RCPSP by proposing innovative heuristics, meta-heuristics and their hybridisation. However, finding optimal solutions is still not guaranteed. It is known that quantum-inspired metaheuristics can improve population diversity and the quality of solutions but little has been published on adapting them to solving RCPSPs. Here, we examine the performance of a Quantum-Inspired Differential Evolution (QIDE) algorithm in solving such problems. The proposed QIDE uses a quantum population that is initialised using the rotation quantum gate and quantum superposition in the continuous domain, and then evolved using the differential-evolution operators. A local search is also adopted to accelerate convergence. The performance of the QIDE algorithm was tested by solving problems with 30 and 60 activities from the PSPLIB benchmark datasets. The QIDE algorithm outperformed another quantum-based particle swarm algorithm and some other meta-heuristics.",IEEE
V. Shankar; S. Chang,Performance of Caffe on QCT Deep Learning Reference Architecture ¡ª A Preliminary Case Study,2017,10.1109/CSCloud.2017.49,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7987173,Conference Paper,2017 IEEE 4th International Conference on Cyber Security and Cloud Computing (CSCloud),"Deep learning is a sub-set of machine learning practice employing models based on various learning network architectures and algorithms in the field of artificial intelligence. Businesses planning to adopt a deep learning solution should comprehend a set of complex choices in hardware, software, configuration and optimizations to setup a functional deep learning solution. This paper will describe the reference architecture built on Intel Knights Landing processor and omni-path interconnection. We provide a simplified guide to deploy, configure and optimize deep learning solutions based on an array of compute, storage, networking and software components offered by Quanta Cloud Technology. The performance data is presented and it shows good scaling and accuracy on processing the data from IMAGENET.",IEEE
I. Krikidis; C. Psomas; A. Kumar Singh; K. Jamieson,Optimizing Configuration Selection in Reconfigurable-Antenna MIMO Systems: Physics-Inspired Heuristic Solvers,2024,10.1109/TCOMM.2024.3420768,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10577169,Journal,IEEE Transactions on Communications,"Reconfigurable antenna multiple-input multiple-output (MIMO) is a foundational technology for the continuing evolution of cellular systems, including upcoming 6G communication systems. In this paper, we address the problem of flexible/reconfigurable antenna configuration selection for point-to-point MIMO antenna systems by using physics-inspired heuristics. Firstly, we optimize the antenna configuration to maximize the signal-to-noise ratio (SNR) at the receiver by leveraging two basic heuristic solvers, i.e., coherent Ising machines (CIMs), that mimic quantum mechanical dynamics, and quantum annealing (QA), where a real-world QA architecture is considered (D-Wave). A mathematical framework that converts the configuration selection problem into CIM- and QA- compatible unconstrained quadratic formulations is investigated. Numerical and experimental results show that the proposed designs outperform classical counterparts and achieve near-optimal performance (similar to exhaustive search with exponential complexity) while ensuring polynomial complexity. Moreover, we study the optimal antenna configuration that maximizes the end-to-end Shannon capacity. A simulated annealing (SA) heuristic which achieves near-optimal performance through appropriate parameterization is adopted. A modified version of the basic SA that exploits parallel tempering to avoid local maxima is also studied, which provides additional performance gains. Extended numerical studies show that the SA solutions outperform conventional heuristics (which are also developed for comparison purposes), while the employment of the SNR-based solutions is highly sub-optimal.",IEEE
R. Tokami; Y. Suzuki; Y. Tokunaga,Quantum Circuit Fragments: Efficient and Verifiable Format for Quantum Circuits,2024,10.1109/QCE60285.2024.10319,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10821167,Conference Paper,2024 IEEE International Conference on Quantum Computing and Engineering (QCE),"An efficient and intuitive format of quantum programs is an indispensable component to handle large-scale quantum computers. Representing and manipulating a sequence of quantum instructions as a network of quantum gates, i.e., quantum circuits, is one of the most successful approaches. Quantum circuits are intuitive since there are similar representations in classical engineering, such as electric or digital circuits. However, due to their differences from these classical circuits, naively automated manipulation and optimization for quantum circuit networks easily tend to an ill-defined format. To avoid this problem, a flexible and verifiable network format of quantum circuits is strongly demanded. In this extended poster abstract, we propose a representation with these properties, named quantum circuit fragments. In our representation, the connectivity of several types of wires in quantum circuits, qubit, control, and measurement-feedback wiring, are kept as three sets. We also provide a linear time algorithm to validate that our format can be converted to quantum circuits. Using our preliminary software to treat quantum circuit fragments, Q-Divide, we demonstrated that code complexity can be halved in practical cases. Thus, our work improves the efficiency of quantum computer development and motivates further exploration for efficient representation and manipulation of large-scale quantum programs.",IEEE
S. Ghosh; J. R. Hammond; A. J. Pe?a; P. Balaji; A. H. Gebremedhin; B. Chapman,One-Sided Interface for Matrix Operations Using MPI-3 RMA: A Case Study with Elemental,2016,10.1109/ICPP.2016.28,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7573817,Conference Paper,2016 45th International Conference on Parallel Processing (ICPP),"A one-sided programming model separates communication from synchronization, and is the driving principle behind partitioned global address space (PGAS) libraries such as Global Arrays (GA) and SHMEM. PGAS models expose a rich set of functionality that a developer needs in order to implement mathematical algorithms that require frequent multidimensional array accesses. However, use of existing PGAS libraries in application codes often requires significant development effort in order to fully exploit these programming models. On the other hand, a vast majority of scientific codes use MPI either directly or indirectly via third-party scientific computation libraries, and need features to support application-specific communication requirements (e.g., asynchronous update of distributed sparse matrices, commonly arising in machine learning workloads). For such codes it is often impractical to completely shift programming models in favor of special one-sided communication middleware. Instead, an elegant and productive solution is to exploit the one-sided functionality already offered by MPI-3 RMA (Remote Memory Access). We designed a general one-sided interface using the MPI-3 passive RMA model for remote matrix operations in the linear algebra library Elemental, we call the interface we designed RMAInterface. Elemental is an open source library for distributed-memory dense and sparse linear algebra and optimization. We employ RMAInterface to construct a Global Arrays-like API and demonstrate its performance scalability and competitivity with that of the existing GA (with ARMCI-MPI) for a quantum chemistry application.",IEEE
R. Ho; K. Hung,Exploring Quantum Machine Learning for Electroencephalogram Classification,2023,10.1109/ISCAIE57739.2023.10165407,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10165407,Conference Paper,2023 IEEE 13th Symposium on Computer Applications & Industrial Electronics (ISCAIE),"Quantum machine learning (QML) is a relatively new discipline emerging from the concepts of machine learning and quantum computing, whereby quantum algorithms are used to solve machine learning tasks. This paper explores the use of quantum machine learning for electroencephalogram (EEG) classification. In particular, a previously proposed EEG feature extraction method and classification framework for classifying dementia subjects were followed in this study. A quantum classifier replaced the classical classifier component of the framework, and the classification accuracies between the quantum and classical classifiers were compared. This study has demonstrated that applying QML in healthy-dementia classification can be implemented using near-term quantum devices or quantum simulators with moderate performance. The quantum classifier achieved an overall classification accuracy of 81.67% and 79.17% in a train-test split performance test and an n $\times$ k-fold cross-validation test, respectively. However, the quantum approach did not produce higher classification accuracies than the classical classifier. Despite the promise of quantum advantages, further investigation and optimization are required to improve its effectiveness.",IEEE
S. J. Amruth; T. M. Nigelesh; V. S. Shruthik; V. S. Reddy; M. Belwal,A Quantum Computation Language-based Quantum Compiler,2024,10.1109/ICCCNT61001.2024.10724823,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10724823,Conference Paper,2024 15th International Conference on Computing Communication and Networking Technologies (ICCCNT),"Quantum computing is a revolution in computational theory that uses the principles of quantum mechanics to perform computations that are beyond the capacity of classical computers. It works with the special features of the quantum bits or qubits to encode and transform the information in manners conventional bits cannot imagine. A quantum compiler is a software tool designed to translate high-level quantum language code into executable quantum instructions. This paper aims to develop a quantum compiler for translating Quantum Computation Language source codes into quantum bytecodes which can later be executed on a Quantum Virtual Machine. This compiler will have a combinational structure that includes a frontend for interpreting the QCL code, an intermediate representation for optimizing quantum algorithms, and a backend for generating efficient quantum bytecode. Optimization techniques will be applied to improve the functioning of the quantum circuits. The compiler will also include an error handling module to handle the errors. The successful deployment of a quantum compiler for QCL has many implications and unlocks opportunities for advancements in quantum technologies.",IEEE
M. Mykhailova,Teaching Quantum Computing Using Microsoft Quantum Development Kit and Azure Quantum,2023,10.1109/QCE57702.2023.20320,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10313841,Conference Paper,2023 IEEE International Conference on Quantum Computing and Engineering (QCE),"This report describes my experience teaching a graduate-level quantum computing course at Northeastern University in the academic year 2022¨C23. The course takes a practical, software-driven approach to the course, teaching basic quantum concepts and algorithms through hands-on programming assignments and a software-focused final project. The course guides learners through all stages of the quantum software development process, from solving quantum computing problems and implementing solutions to debugging quantum programs, optimizing the code, and running the code on quantum hardware. This report offers instructors who want to adopt a similar practical approach to teaching quantum computing a comprehensive guide to getting started.",IEEE
M. V. Jankovic,Quantum Low Entropy based Associative Reasoning¨CQLEAR Learning,2018,10.1109/NEUREL.2018.8587003,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8587003,Conference Paper,2018 14th Symposium on Neural Networks and Applications (NEUREL),"It is well known that the field of pattern recognition is concerned with the automatic discovery of regularities in data through the use of computer algorithms and with the use of these regularities to take actions such as classifying the data into different categories. There are many algorithms based on different theoretical backgrounds that could be used for pattern recognition in practical applications. Generally, most of the algorithms are applied in areas like classification, regression or change point detection.Recently, it has been shown that a probabilistic model based on two of the main concepts in quantum physics ¨C a density matrix and the Born rule, can be suitable for the modeling of learning algorithms in biologically plausible artificial neural networks framework. It has been shown that the proposed probabilistic interpretation is suitable for modeling on-line learning algorithms for Independent/Principal/Minor Component Analysis, which could be realized on parallel hardware based on very simple computational units. Also, it has been shown that the quantum entropy of the system, related to that model, can be successfully used in the problems like change point or anomalies detection as well as simple classification problems. Here another application of the proposed quantum probabilistic model is going to be presented. A general paradigm called QLEAR learning (Quantum Low Entropy based Associative Reasoning) would be presented and tested in classification context. Proposed method potentially can overcome the problem that classifier performance depends greatly on the characteristics of the data to be classified. It is known that until now, there is no single classifier that works best on all given problems (a phenomenon that may be explained by the no-free-lunch theorem). Here we will try to propose a classification algorithm that, actually, automatically adjusts its performance according to characteristics of the data on which it is applied. An interesting aspect is that proposed method inherently solves the problem of unbalanced classes (classes that have significantly different size). The proposed paradigm can be applied in any area in which standard classification techniques are applied. The method is going to be analyzed in the context of classification, prediction and solving some mathematical problems.We¡¯ll analyze, mainly, the case in which data is represented by vectors. Generalization toward multiway data would be discussed only on one example. The approach is based on the idea that classification can be understood as supervised clustering, where quantum entropy, in the context of the quantum probabilistic model, will be used as a ¡°capturer¡± (measure, or external index) of the ¡°natural structure¡± of the data. By using quantum entropy we don¡¯t make any assumption about linear separability of the data that are going to be classified. The basic idea is to find close neighbours to a query sample and then use relative change in the quantum entropy as a measure of similarity of the newly arrived sample with the representatives of interest. In other words, method is based on calculation of quantum entropy of the referent system and its relative change with the addition of the newly arrived sample. Referent system consists of vectors/matrices that represent individual classes and that are the most similar, in Euclidean distance sense, to the vector that is analyzed. The classification problem is analysed in the context of measuring similarities to prototype examples of categories. The proposed method could be seen as a hybrid of nearest neighbor and optimization machine learning technique which deals naturally with the multiclass setting, has reasonable computational complexity both in training and at run time, and yields excellent results in practice.",IEEE
R. Sangle; T. Khare; P. V. Seshadri; Y. Simmhan,Comparing the Orchestration of Quantum Applications on Hybrid Clouds,2023,10.1109/CCGridW59191.2023.00069,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10181218,Conference Paper,"2023 IEEE/ACM 23rd International Symposium on Cluster, Cloud and Internet Computing Workshops (CCGridW)","Early quantum computers are being offered by Cloud providers, with the ability to run Hybrid Quantum-Classical (HQC) applications that span Quantum and Classical (binary) computing resources. These HQC algorithms help benchmark and validate the performance of such near-term quantum hardware. Equally important is the software platform that allows a remote user to program the quantum computer on the cloud. The recent Qiskit Runtime platform from IBM allows a seamless and prioritized access to quantum backends and co-located classical hardware within their hybrid cloud for optimized execution of HQC workloads. In contrast, IBM¡¯s Circuit API offers finer application definition but the classical resources are not co-located but placed farther away. Here, we study and contrast the execution flows of a Variational Quantum Eigensolver (VQE) application defined using Qiskit Runtime, and an equivalent implementation using the Circuit API. We quantify the latencies of the various components in these execution. This offers insights on how to better orchestrate the execution of quantum applications across such hybrid resources.",IEEE
O. Ghoniem; H. Elsayed; H. Soubra,Quantum Gate Count Analysis,2023,10.1109/ICICIS58388.2023.10391119,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10391119,Conference Paper,2023 Eleventh International Conference on Intelligent Computing and Information Systems (ICICIS),"In recent years, interest in quantum computers has grown significantly. While commercial quantum computers are not available yet, both private and public sector investment into developing quantum computers has developed considerably. One of the key challenges in quantum computing is optimizing the performance of the quantum hardware devices. Different factors can be put into consideration regarding this point, including the number of gates used by the processors to execute different quantum computations and operations. This paper focuses on developing quantum hardware metrics that can be used to measure the performance of a quantum processor in terms of number of quantum gates needed to execute different quantum algorithms. The proposed metrics have been implemented and experimental evaluations have been conducted on various IBM back-end Quantum Computers and using 4 different algorithms: a 5-Qubit entangled circuit algorithm, a 5-Qubit implementation of Grover¡¯s quantum search algorithm, a 5-Qubit implementation of Simon¡¯s quantum algorithm and the 7-Qubit implementation of Steane¡¯s error correction quantum algorithm. In addition, quantitative data on the number of quantum gates used by quantum processors to execute the different quantum algorithms were gathered, which enabled the analysis of how the availability and compatibility of different gate sets affect the overall number of quantum gates needed in the execution of the different quantum algorithms.",IEEE
K. -A. Shim,A Survey on Post-Quantum Public-Key Signature Schemes for Secure Vehicular Communications,2022,10.1109/TITS.2021.3131668,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9646494,Journal,IEEE Transactions on Intelligent Transportation Systems,"Basic security requirements such as confidentiality, user authentication and data integrity, are assured by using public-key cryptography (PKC). In particular, public-key signature schemes provide non-repudiation, integrity of transmitted messages and authentication. The presence of a large scale quantum computer would be a real threat to break the most widely used public-key cryptographic algorithms in practice, RSA, DSA, ECDSA signature schemes and Diffie-Hellman key exchange. Thus, all security protocols and applications where these public-key cryptographic algorithms are used are vulnerable to quantum-computer attacks. There are five directions of cryptographic primitives secure against a quantum computer: multivariate quadratic equation-based, hash-based, lattice-based, code-based and supersingular isogeny-based cryptography. These primitives could serve as replacements for current public-key cryptographic algorithms to prepare for post-quantum era. It is important to prioritize the fields to be replaced by post-quantum cryptography (PQC) since it is hard to replace the currently deployed PKC with PQC at the same time. The fields directly connected to human life such as vehicular communications should be the primary targets of PQC applications. This survey is dedicated to providing guidelines for adapting the most suitable post-quantum candidates to the requirements of various devices and suggesting efficient and physically secure implementations that can be built into existing embedded applications as easily as traditional PKC. It focuses on the five types of post-quantum signature schemes and investigates their theoretical backgrounds, structures, state-of-the-art constructions and implementation aspects on various platforms raging from resource constrained IoT devices to powerful servers connected to the devices for secure communications in post-quantum era. It offers appropriate solutions to find tradeoffs between key sizes, signature lengths, performance, and security for practical applications.",IEEE
C. -S. Lee; M. -H. Wang; J. -K. Chiang; N. Kubota; E. Sato-Shimokawara; Y. Nojima; G. Acampora; P. -Y. Wu; S. -C. Chiu; S. -C. Yang; C. -Z. Siow,Quantum Computational Intelligence with Generative AI Image for Human-Machine Interaction,2024,10.1109/FUZZ-IEEE60900.2024.10611970,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10611970,Conference Paper,2024 IEEE International Conference on Fuzzy Systems (FUZZ-IEEE),"This paper introduces a Quantum Computational Intelligence (QCI) agent equipped with a content attention ontology model, specifically designed to enhance human-machine interaction based on a Generative Artificial Intelligence (GAI) image generation agent for Taiwanese/English learning and experience. Its diverse primary applications include social media analysis on Facebook groups and YouTube learning videos related to the 2023 IEEE CIS Education Portal (EP) Subcommittee, as well as in the areas of Taiwanese/English language learning and dialogue experience with GAI image generation. To establish the knowledge and inference models for the QCI agent, we initially developed a Taiwanese/English learning and experience ontology, including a content attention ontology, and an image attention ontology. The QCI agent utilizes metrics such as the number of views, posts, and comments to predict the fuzzy number of reactions. In addition, the GAI image agent generates Taiwanese speech-based/English text-based images and evaluates the fuzzy similarity score between Taiwanese/English and the attention ontology together with the Sentence BERT (SBERT) agent. This Taiwanese/English fuzzy similarity score is further validated through human assessments, with these evaluations subsequently serving as an additional metric for comparative analysis of Human-Machine Interaction (HMI). Furthermore, the GAI image agent is designed to create images and Chinese/English texts from text/speech translated by the Meta AI Universal Speech Translator (UST) Taiwanese/English agent. A Particle Swarm Optimization (PSO)-based machine learning mechanism is employed to train the QCI model for assessing learners' performance and predicting the performance of others. The National University of Tainan (NUTN) Taiwan-Large Language Model (NUTN.TW-LLM) agent has been further enhanced to support interactive learning experiences for HMI. An SBERT-based assessment agent is used to calculate fuzzy similarities between questions and answers in Taiwanese/English experiences and dialogues. Experimental results demonstrate the feasibility and efficacy of the proposed QCI model, equipped with QCI&AI-FML (Artificial Intelligence-Fuzzy Markup Language) and machine learning capabilities, for social media and language learning applications on HMI. In the future, we will extend the QCI model to various HMI applications for student learning around the world.",IEEE
S. Khurana; M. J. Nene,Machine Learning in the Quantum Era,2023,10.1109/INCOFT60753.2023.10425372,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10425372,Conference Paper,2023 2nd International Conference on Futuristic Technologies (INCOFT),"Machine Learning (ML) has been extensively utilized in various scientific and engineering domains. But the inherent constraints and computational complexity that arise in classical machine learning are particularly evident when dealing with large-scale, high-dimensional datasets or when attempting to solve intricate optimisation problems. Quantum systems exhibit unconventional patterns that are typically not effectively generated by traditional systems and can also tackle high dimensional and large size datasets efficiently. Therefore, it is believed that quantum computing systems may outperform traditional computing devices in machine learning tasks. Quantum Machine Learning (QML) has emerged as a rapidly developing field that combines the concepts of quantum mechanics and machine learning to solve complex problems across various disciplines. The domain of quantum machine learning investigates the development and execution of quantum software with the potential to facilitate machine learning at a much superior pace compared to traditional computers. However, the major challenges encountered are hardware limitations, noise, and development of quantum algorithms. The objective of this paper is to provide an insight on the foundational principles, essential algorithms, various associated platforms, potential applications and challenges being faced by QML. As data continues to grow in size and complexity, together with the emergence of nonlinear and high-dimensional real-world situations, the computing benefits offered by QML have the potential to facilitate significant advancements in the fields of healthcare, finance, robotics, logistics, communication, and cyber security. This paper presents the basis for future research work related to development of quantum algorithms in the domain of machine learning.",IEEE
W. Lavrijsen; A. Tudor; J. M¨¹ller; C. Iancu; W. de Jong,Classical Optimizers for Noisy Intermediate-Scale Quantum Devices,2020,10.1109/QCE49297.2020.00041,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9259985,Conference Paper,2020 IEEE International Conference on Quantum Computing and Engineering (QCE),"We present a collection of optimizers tuned for usage on Noisy Intermediate-Scale Quantum (NISQ) devices. Optimizers have a range of applications in quantum computing, including the Variational Quantum Eigensolver (VQE) and Quantum Approximate Optimization (QAOA) algorithms. They are also used for calibration tasks, hyperparameter tuning, in machine learning, etc. We analyze the efficiency and effectiveness of different optimizers in a VQE case study. VQE is a hybrid algorithm, with a classical minimizer step driving the next evaluation on the quantum processor. While most results to date concentrated on tuning the quantum VQE circuit, we show that, in the presence of quantum noise, the classical minimizer step needs to be carefully chosen to obtain correct results. We explore state-of-the-art gradient-free optimizers capable of handling noisy, black-box, cost functions and stress-test them using a quantum circuit simulation environment with noise injection capabilities on individual gates. Our results indicate that specifically tuned optimizers are crucial to obtaining valid science results on NISQ hardware, and will likely remain necessary even for future fault tolerant circuits.",IEEE
X. Wang; S. Ali; T. Yue; P. Arcaini,Quantum Approximate Optimization Algorithm for Test Case Optimization,2024,10.1109/TSE.2024.3479421,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10715683,Journal,IEEE Transactions on Software Engineering,"Test case optimization (TCO) reduces the software testing cost while preserving its effectiveness. However, to solve TCO problems for large-scale and complex software systems, substantial computational resources are required. Quantum approximate optimization algorithms (QAOAs) are promising combinatorial optimization algorithms that rely on quantum computational resources, with the potential to offer increased efficiency compared to classical approaches. Several proof-of-concept applications of QAOAs for solving combinatorial problems, such as portfolio optimization, energy optimization in power systems, and job scheduling, have been proposed. Given the lack of investigation into QAOA's application for TCO problems, and motivated by the computational challenges of TCO problems and the potential of QAOAs, we present IGDec-QAOA to formulate a TCO problem as a QAOA problem and solve it on both ideal and noisy quantum computer simulators, as well as on a real quantum computer. To solve bigger TCO problems that require many qubits, which are unavailable these days, we integrate a problem decomposition strategy with the QAOA. We performed an empirical evaluation with five TCO problems and four publicly available industrial datasets from ABB, Google, and Orona to compare various configurations of IGDec-QAOA, assess its decomposition strategy of handling large datasets, and compare its performance with classical algorithms (i.e., Genetic Algorithm (GA) and Random Search). Based on the evaluation results achieved on an ideal simulator, we recommend the best configuration of our approach for TCO problems. Also, we demonstrate that our approach can reach the same effectiveness as GA and outperform GA in two out of five test case optimization problems we conducted. In addition, we observe that, on the noisy simulator, IGDec-QAOA achieved similar performance to that from the ideal simulator. Finally, we also demonstrate the feasibility of IGDec-QAOA on a real quantum computer in the presence of noise.","IEEE, Web of Science"
S. Y. -C. Chen; C. -H. H. Yang; J. Qi; P. -Y. Chen; X. Ma; H. -S. Goan,Variational Quantum Circuits for Deep Reinforcement Learning,2020,10.1109/ACCESS.2020.3010470,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9144562,Journal,IEEE Access,"The state-of-the-art machine learning approaches are based on classical von Neumann computing architectures and have been widely used in many industrial and academic domains. With the recent development of quantum computing, researchers and tech-giants have attempted new quantum circuits for machine learning tasks. However, the existing quantum computing platforms are hard to simulate classical deep learning models or problems because of the intractability of deep quantum circuits. Thus, it is necessary to design feasible quantum algorithms for quantum machine learning for noisy intermediate scale quantum (NISQ) devices. This work explores variational quantum circuits for deep reinforcement learning. Specifically, we reshape classical deep reinforcement learning algorithms like experience replay and target network into a representation of variational quantum circuits. Moreover, we use a quantum information encoding scheme to reduce the number of model parameters compared to classical neural networks. To the best of our knowledge, this work is the first proof-of-principle demonstration of variational quantum circuits to approximate the deep Q-value function for decision-making and policy-selection reinforcement learning with experience replay and target network. Besides, our variational quantum circuits can be deployed in many near-term NISQ machines.",IEEE
P. G. Balaji; P. Chamikar; O. Chowdary; M. Belwal,Optimizing Compiler for Quantum Computing Using Qiskit Terra,2024,10.1109/ICCCNT61001.2024.10726185,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10726185,Conference Paper,2024 15th International Conference on Computing Communication and Networking Technologies (ICCCNT),"The recent times of fast development of quantum computers has been followed by many researchers who want to run the larger and more difficult quantum algorithms on it and they have promised such speedup several times. Notwithstanding this, commercial quantum computers are currently fraught with instability and errors. This paper is centered on development of the customized compiler for quantum computing with aid of Qiskit Terra, a QIS framework. We target central classes such as circuit representation structures, programming techniques based on OpenQASM, challenges in the QC architecture, high-level routing optimization, and the structure of the Qiskit Terra compiler. In every circuit, the optimization is provided by methods of Qiskit Terra, including Trivial Layout, Noise Adaptive Layout, Dense Layout, and Custom Layout. These optimization levels address many problems that emerge when circuits are being compiled and executed, and thus, the optimization levels seek to boost circuit efficiency, reduce the count of gates, and enhance the overall performance. The introduction of numerous optimization passes starting from unroller passes that translate gates, the layout passes that map virtual to physical qubits, and the optimization algorithm aimed at the runtime reduction. Modern quantum compilation technologies are being currently developed based on economic (and theoretical) analyses to underpin the investigation and development of optimal quantum computation procedures.",IEEE
J. Guo; M. Ying,Software Pipelining for Quantum Loop Programs,2023,10.1109/TSE.2022.3232623,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10002313,Journal,IEEE Transactions on Software Engineering,"We propose a method for performing software pipelining on quantum for-loop programs to exploit parallelism in and across iterations. We redefined concepts useful in program optimization, including array aliasing, instruction dependency, and resource conflict required in optimizing quantum programs. Using these concepts, we present a software pipelining framework exploiting instruction-level parallelism in quantum loop programs. This method is further enhanced with several improvements to reduce total gate count and program depth. The optimization method is then evaluated on some popular quantum algorithms like Grover and QAOA, and compared under different configurations and with several baseline compilers. The evaluation results show that our approach can schedule loop programs with depth close to the depth of the entire loop unrolling while generating smaller code sizes and consuming much less time. This is the first step towards optimization of a quantum program with such loop control flow, as far as we know.","IEEE, Web of Science"
V. Uotila,Tensor Decompositions and Adiabatic Quantum Computing for Discovering Practical Matrix Multiplication Algorithms,2024,10.1109/QCE60285.2024.00053,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10821361,Conference Paper,2024 IEEE International Conference on Quantum Computing and Engineering (QCE),"Quantum computing and modern tensor-based computing have a strong connection, which is especially demonstrated by simulating quantum computations with tensor networks. The other direction is less studied: quantum computing is not often applied to tensor-based problems. Considering tensor decompositions, we focus on discovering practical matrix multiplication algorithms and develop two algorithms to compute decompositions on quantum computers. The algorithms are expressed as higher-order unconstrained binary optimization (HUBO) problems, which are translated into quadratic unconstrained binary optimization (QUBO) problems. Our first algorithm is decompositional to keep the optimization problem feasible for the current quantum devices. Starting from a suitable initial point, the algorithm discovers tensor decomposition corresponding to the famous Strassen matrix multiplication algorithm, utilizing the current quantum annealers. Since the decompositional algorithm does not guarantee minimal length for found tensor decompositions, we develop a holistic algorithm that can find fixed-length decompositions. Theoretically, by fixing a shorter length than the length for the best-known decomposition, we can ensure that the solution to the holistic optimization problem would yield faster matrix multiplication algorithms.",IEEE
D. Zoni; A. Galimberti; W. Fornaciari,Flexible and Scalable FPGA-Oriented Design of Multipliers for Large Binary Polynomials,2020,10.1109/ACCESS.2020.2989423,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9075203,Journal,IEEE Access,"With the recent advances in quantum computing, code-based cryptography is foreseen to be one of the few mathematical solutions to design quantum resistant public-key cryptosystems. The binary polynomial multiplication dominates the computational time of the primitives in such cryptosystems, thus the design of efficient multipliers is crucial to optimize the performance of post-quantum public-key cryptographic solutions. This manuscript presents a flexible template architecture for the hardware implementation of large binary polynomial multipliers. The architecture combines the iterative application of the Karatsuba algorithm, to minimize the number of required partial products, with the Comba algorithm, used to optimize the schedule of their computations. In particular, the proposed multiplier architecture supports operands in the order of dozens of thousands of bits, and it offers a wide range of performance-resources trade-offs that is made independent from the size of the input operands. To demonstrate the effectiveness of our solution, we employed the nine configurations of the LEDAcrypt public-key cryptosystem as representative use cases for large-degree binary polynomial multiplications. For each configuration we showed that our template architecture can deliver a performance-optimized multiplier implementation for each FPGA of the Xilinx Artix-7 mid-range family. The experimental validation performed by implementing our multiplier for all the LEDAcrypt configurations on the Artix-7 12 and 200 FPGAs, i.e., the smallest and the largest devices of the Artix-7 family, demonstrated an average performance gain of 3.6x and 33.3x with respect to an optimized software implementation employing the gf2x C library.","IEEE, Web of Science"
K. Murakami; J. Zhao,Automated Synthesis of Quantum Circuits using Neural Network,2022,10.1109/QRS57517.2022.00075,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10062443,Conference Paper,"2022 IEEE 22nd International Conference on Software Quality, Reliability and Security (QRS)","While the ability to build quantum computers is improving dramatically, developing quantum algorithms is very limited and relies on human insight and ingenuity. Although several quantum programming languages have been developed, it is challenging for software developers unfamiliar with quantum computing to learn and use these languages. It is, therefore, necessary to develop tools to support developing new quantum algorithms and programs automatically. This paper proposes AutoQC, an approach to automatically synthesizing quantum circuits using the neural network from input and output pairs. We consider a quantum circuit a sequence of quantum gates and synthesize a quantum circuit probabilistically by prioritizing through a neural network at each step. The experimental results highlight the ability of AutoQC to synthesize some essential quantum circuits at a lower cost.",IEEE
H. Bayraktar; A. Charara; D. Clark; S. Cohen; T. Costa; Y. -L. L. Fang; Y. Gao; J. Guan; J. Gunnels; A. Haidar; A. Hehn; M. Hohnerbach; M. Jones; T. Lubowe; D. Lyakh; S. Morino; P. Springer; S. Stanwyck; I. Terentyev; S. Varadhan; J. Wong; T. Yamaguchi,cuQuantum SDK: A High-Performance Library for Accelerating Quantum Science,2023,10.1109/QCE57702.2023.00119,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10313722,Conference Paper,2023 IEEE International Conference on Quantum Computing and Engineering (QCE),"We present the NVIDIA cuQuantum SDK [1], a state-of-the-art library of composable primitives for GPU-accelerated quantum circuit simulations. As the size of quantum devices continues to increase, making their classical simulation progressively more difficult, the availability of fast and scalable quantum circuit simulators becomes vital for quantum algorithm developers, as well as quantum hardware engineers focused on the validation and optimization of quantum devices. The cuQuantum SDK was created to accelerate and scale up quantum circuit simulators developed by the quantum information science community by enabling them to utilize efficient scalable software building blocks optimized for NVIDIA GPU-based platforms. The functional building blocks provided cover the needs of both state vector- and tensor network- based simulators, including approximate tensor network simulation methods based on matrix product state, projected entangled pair state, and other factorized tensor representations. By leveraging the enormous computing power of the latest NVIDIA GPU architectures, quantum circuit simulators that have adopted the cuQuantum SDK demonstrate significant acceleration, compared to CPU-only execution, for both the state vector and tensor network simulation methods. Furthermore, by utilizing the parallel primitives available in the cuQuantum SDK, one can easily transition to distributed GPU-accelerated platforms, including those furnished by cloud service providers and high-performance computing systems deployed by supercomputing centers, extending the scale of possible quantum circuit simulations. The rich capabilities provided by the cuQuantum SDK are conveniently made available via both Python and C application programming interfaces, where the former is directly targeting a broad Python quantum community and the latter allows tight integration with simulators written in any programming language.",IEEE
M. Sch?ffel; J. Feldmann; N. Wehn,Code-based Cryptography in IoT: A HW/SW Co-Design of HQC,2022,10.1109/WF-IoT54382.2022.10152031,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10152031,Conference Paper,2022 IEEE 8th World Forum on Internet of Things (WF-IoT),"Recent advances in quantum computing pose a serious threat on the security of widely used public-key cryp-tosystems. Thus, new post-quantum cryptographic algorithms have been proposed as part of the associated US NIST process to enable secure, encrypted communication in the age of quantum computing. Many hardware accelerators for structured lattice-based algorithms have already been published to meet the strict power, area and latency requirements of low-power IoT edge de-vices. However, the security of these algorithms is still uncertain. Currently, many new attacks against the lattice structure are investigated to judge on their security. In contrast, code-based algorithms, which rely on deeply explored security metrics and are appealing candidates in the NIST process, have not yet been investigated to the same depth in the context of IoT due to the computational complexity and memory footprint of state-of-the-art software implementations. In this paper, we present to the best of our knowledge the first HW /SW co-design based implementation of the code-based Hamming Quasi Cyclic Key-Encapsulation Mechanism. We profile and evaluate this algorithm in order to explore the trade-off between software optimizations, tightly coupled hardware acceleration by instruction set extension and modular, loosely coupled accelerators. We provide detailed results on the energy consumption and performance of our design and compare it to existing implementations of lattice- and code-based algorithms. The design was implemented in two technologies: FPGA and ASIC. Our results show that code-based algorithms are valid alternatives in low-power IoT from an implementation perspective.",IEEE
X. Zhao; T. Yang; D. Liu; H. Shen,Cognitive radio spectrum allocation based on improved quantum genetic algorithm,2024,10.1109/NGDN61651.2024.10744191,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10744191,Conference Paper,2024 Sixth International Conference on Next Generation Data-driven Networks (NGDN),"With the rapid development of wireless communication technology, the contradiction between the limited spectrum resources and demand has become increasingly prominent. Based on this, a cognitive radio spectrum allocation algorithm based on an improved quantum genetic algorithm is proposed. This algorithm is based on the graph theory coloring model. It firstly initializes the population. Secondly, during the population evolution process, it updates the population by dynamically adjusting the quantum rotating door by calculating the quantum rotation angle, and improves the selection operator, crossover operator and mutation operator to accelerate the convergence speed of the algorithm, and finally map the optimal individual to the spectrum allocation matrix to obtain the optimal spectrum allocation scheme. Experimental results show that compared with traditional quantum genetic algorithms, genetic algorithms and particle swarm algorithms, the improved quantum genetic algorithm has faster convergence speed, higher search efficiency and higher spectrum utilization.",IEEE
X. -C. Wu; S. Premaratne; K. Rasch,Invited Paper: Introduction to Hybrid Quantum-Classical Programming Using C++ Quantum Extension,2023,10.1109/ICCAD57390.2023.10323946,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10323946,Conference Paper,2023 IEEE/ACM International Conference on Computer Aided Design (ICCAD),"The rapid development of quantum computing technology has led to an increasing need for efficient and accessible programming tools that can bridge the gap between classical and quantum computing paradigms. In this paper, we introduce the Intel?Quantum SDK, a powerful software development kit designed to facilitate hybrid quantum-classical programming using the C++ Quantum Extension. The SDK provides a comprehensive set of tools and libraries that enable developers to harness the power of quantum computing while leveraging their existing knowledge of classical programming techniques. By incorporating quantum algorithms and operations within a familiar C++ framework, the Intel Quantum SDK empowers programmers to create innovative hybrid applications that can tackle complex problems and drive advancements in various fields, including cryptography, optimization, and materials science. This paper will guide readers through the essential concepts, features, and capabilities of the Intel Quantum SDK. This seamless integration of quantum and classical programming paradigms paves the way for the development of innovative and efficient solutions to complex computational challenges, ultimately driving the advancement of quantum computing technology and its real-world applications.",IEEE
N. R. Vora; Y. Xu; A. Hasim; N. Fruitwala; N. Nguyen; H. Liao; J. Balewski; A. Rajagopala; K. Nowrouzi; Q. Ji; K. B. Whaley; I. Siddiqi; P. Nguyen; G. Huang,QubiCML: ML-Powered Real-Time Quantum State Discrimination Enabling Mid-Circuit Measurements,2024,10.1109/QCE60285.2024.10332,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10821106,Conference Paper,2024 IEEE International Conference on Quantum Computing and Engineering (QCE),"This work addresses the critical challenge of accurately and swiftly identifying quantum states in superconducting quantum processors, with a particular focus on qubit (two-level) states. It introduces QubiCML, an innovative FPGA-based system designed for in-situ, real-time quantum state discrim-ination, which is essential for mid-circuit measurements and the implementation of advanced error correction techniques. By integrating a multi-layer neural network on the FPGA platform, QubiCML achieves exceptional accuracy and low latency in distinguishing quantum states. Traditional methods of quantum state discrimination rely heavily on offline data processing, which is inadequate due to the brief coherence time of quantum states and significant communication delays. QubiCML overcomes these limitations by utilizing in-situ machine learning for state discrimination, enabling real-time state determination in just 54 ns. It optimizes readout RF pulses and digital local oscillator (DLO) signals, significantly enhancing the fidelity of state discrimination. This capability enables mid-circuit measurements (MCM), which we successfully deployed using the QubiCML system. The system has been rigorously evaluated on in-house superconducting quantum processors, demonstrating an impressive average accuracy of 98.5%. QubiCML's modular architecture supports scalability across various qubits, making it adaptable to different quantum computing setups. Its real-time feedback capabilities are particularly beneficial for efficient quantum algorithm development and optimization. This system represents a groundbreaking advance-ment in the field of quantum computing, offering a robust tool for real-time quantum state discrimination. QubiCML has the potential to become the standard method for state discrimination, providing the quantum computing community with a powerful solution to push the boundaries of current technology.",IEEE
A. M. Gejea; S. Mayakannan; R. M. Palacios; A. A. Hamad; B. Sundaram; W. Alghamdi,A Novel Approach to Grover's Quantum Algorithm Simulation: Cloud-Based Parallel Computing Enhancements,2023,10.1109/ICOSEC58147.2023.10276383,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10276383,Conference Paper,2023 4th International Conference on Smart Electronics and Communication (ICOSEC),"A truly universal quantum computer is still on the small scale at the present. There has been no transition from the laboratory use of quantum computers to more widespread use of the technology. As a result, quantum simulation has emerged as the accepted norm for supporting the validation of quantum algorithms. Many conventional algorithms benefit from grover's quantum search method because it accelerates their usage of search heuristics. For better multi-core load balancing, memory utilization, and simulation efficiency, this research presented a high-performance grover method simulation that combines the benefits of grover's technique with the parallel of cloud computing. This study also suggests and experimentally compares five distinct cloud-based computing architectures that are well-suited to quantum simulation. Through research and testing, this study also verifies the optimization's efficiency. Depending on the size of the current configuration, the experimental results reveal that the simulation can reach 31 bits.",IEEE
M. Walters; S. S. Roy,Constant-Time BCH Error-Correcting Code,2020,10.1109/ISCAS45731.2020.9180846,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9180846,Conference Paper,2020 IEEE International Symposium on Circuits and Systems (ISCAS),"Error-correcting codes can be useful in reducing decryption failure rate of several lattice-based and code-based public-key encryption schemes. Two schemes, namely LAC and HQC, in NIST's round 2 phase of its post-quantum cryptography standardisation project use the strong error-correcting BCH code. However, direct application of the BCH code in decryption algorithms of public-key schemes could open new avenues to the attacks. For example, a recent attack [1] exploited non-constant-time execution of BCH code to reduce the security of LAC. In this paper we analyse the BCH error-correcting code, identify computation steps that cause timing variations and design a constant-time BCH implementation. We implement our algorithm in software and evaluate its resistance against timing attacks by performing leakage detection tests. To study the computational overhead of the countermeasures, we integrated our constant-time BCH code in the reference and optimised implementations of the LAC scheme as a case study, and observed nearly 1.1 and 1.4 factor slowdown respectively for the CCA-secure primitives.",IEEE
P. Das; E. Kessler; Y. Shi,The Imitation Game: Leveraging CopyCats for Robust Native Gate Selection in NISQ Programs,2023,10.1109/HPCA56546.2023.10071025,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10071025,Conference Paper,2023 IEEE International Symposium on High-Performance Computer Architecture (HPCA),"Quantum programs are written in high-level languages, whereas quantum hardware can only execute low-level native gates. To run programs on quantum systems, each high- level instruction must be decomposed into native gates. This process is called gate nativization and is performed by the compiler. Recent quantum computers support a richer native gate set to reduce crosstalk by tackling frequency crowding and enable compilers to generate quantum executables with fewer native gates. On these systems, any two-qubit CNOT instruction can be decomposed using more than a single two-qubit native gate. For example, a CNOT can be decomposed using either XY, CPHASE, or CZ native gates on Rigetti machines. Unfortunately, two-qubit native gates have high-error rates and exhibit temporal and spatial variations, which limits the success-rate of quantum programs. Therefore, identifying the native gate that maximizes the success-rate of each CNOT operation in a program is crucial.Our experiments on Rigetti machines show that noise-adaptive gate nativization to select the native gate with the highest fidelity for each CNOT operation is often sub-optimal at the application level. This is because the performance of such nativization heavily depends on the correctness of the device calibration data which only provides the average gate fidelities and may not accurately capture the error trends specific to the qubit state space of a program. Moreover, the calibration data may go stale due to device drifts going undetected. To overcome these limitations, we propose Application-specific Native Gate Selection (ANGEL). ANGEL designs a CopyCat that imitates a given program but has a known solution. Then, ANGEL employs the CopyCat to test different combinations of native gates and learn the optimal combination, which is then used to nativize the given program. To avoid an exponential search, ANGEL uses a divide-and-conquer- based localized search, the complexity of which scales linear with the number of device links used by the program. Our evaluations on Rigetti Aspen-11 show that ANGEL improves the success-rate of programs by 1.40x on average and by up-to 2x.",IEEE
P. Nedungadi; S. Surendran; K. -Y. Tang; R. Raman,Big Data and AI Algorithms for Sustainable Development Goals: A Topic Modeling Analysis,2024,10.1109/ACCESS.2024.3516500,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10794768,Journal,IEEE Access,"This study makes significant contributions to the field by examining the transformative role of big data and artificial intelligence (AI) in advancing Sustainable Development Goals (SDGs), particularly healthcare (SDG3), sustainable energy (SDG7), and industry and infrastructure (SDG9). Using BERTopic modeling, a machine learning technique, this research systematically analyzes literature from 2013 to 2024, providing an overview of AI and big data applications mapped to SDGs which is a first. This structured approach identifies key SDGs impacted by these technologies and highlights interdisciplinary methods that further enhance SDG outcomes. AI applications notably improve healthcare by advancing disease tracking, tailored treatments, and precision medicine, fostering universal healthcare and reducing noncommunicable disease mortality. In energy, AI-driven solutions optimize forecasting, grid management, and renewable integration, while in industry, they bolster infrastructure resilience through innovations like predictive maintenance and automated quality control within Industry 4.0 frameworks. The integration of automated text analysis and semantic context captures broad trends, contributing both methodologically and substantively at the intersection of AI and sustainability. Despite these advancements, the study underscores ethical concerns, including data privacy, security, and algorithmic biases. Interdisciplinary collaboration among healthcare professionals, engineers, environmental scientists, and AI experts is crucial to developing ethical, scalable AI solutions. The study suggests future research focus on AI transparency, scaling across diverse sectors, and integrating advanced techniques such as neurosymbolic AI and quantum neural networks to enhance system reliability. These insights offer practical implications, reinforcing the potential of AI and big data to address global challenges sustainably while calling for balanced attention to ethical and regulatory dimensions.","IEEE, Scopus"
C. Liang; Z. Li; M. Zhang; L. Han,A Superconducting Quantum Chip Architecture Design Method for Quantum Programs,2023,10.1109/ISCTIS58954.2023.10213168,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10213168,Conference Paper,2023 3rd International Symposium on Computer Technology and Information Science (ISCTIS),"In the field of superconducting quantum computing, chip architecture design is an important research direction. Currently, most chips are designed for general-purpose architectures, and the fixed connection structure is difficult to ensure the flexibility of mapping, adding extra gate operations and affecting the execution efficiency of different quantum programs. To this end, this paper proposes a superconducting quantum chip architecture design method for quantum programs. The method aims at reducing the number of gates after mapping, and generates a chip architecture with higher fitness by combining the two-qubit gate information of quantum programs through an improved genetic algorithm. The experimental results show that the chip architecture generated by this method outperforms two 2 * 8 scale square lattice generic architectures in 33 test samples, with an average reduction of 35.3 % and 17.9% in the total number of gates optimized, respectively, which verifies the effectiveness of this method.",IEEE
N. Franco; T. Wollschl?ger; N. Gao; J. M. Lorenz; S. G¨¹nnemann,Quantum Robustness Verification: A Hybrid Quantum-Classical Neural Network Certification Algorithm,2022,10.1109/QCE53715.2022.00033,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9951230,Conference Paper,2022 IEEE International Conference on Quantum Computing and Engineering (QCE),"In recent years, quantum computers and algorithms have made significant progress indicating the prospective importance of quantum computing (QC). Especially combinatorial optimization has gained a lot of attention as an application field for near-term quantum computers, both by using gate-based QC via the Quantum Approximate Optimization Algorithm and by quantum annealing using the Ising model. However, demonstrating an advantage over classical methods in real-world applications remains an active area of research. In this work, we investigate the robustness verification of ReLU networks, which involves solving many-variable mixed-integer programs (MIPs), as a practical application. Classically, complete verification techniques struggle with large networks as the combinatorial space grows exponentially, implying that realistic networks are difficult to be verified by classical methods. To alleviate this issue, we propose to use QC for neural network verification and introduce a hybrid quantum procedure to compute provable certificates. By applying Benders decomposition, we split the MIP into a quadratic unconstrained binary optimization and a linear program which are solved by quantum and classical computers, respectively. We further improve existing hybrid methods based on the Benders decomposition by reducing the overall number of iterations and placing a limit on the maximum number of qubits required. We show that, in a simulated environment, our certificate is sound, and provides bounds on the minimum number of qubits necessary to approximate the problem. Finally, we evaluate our method within simulations and on quantum hardware.",IEEE
H. Dietz; P. Eberhart; A. Rule,Basic Operations And Structure Of An FPGA Accelerator For Parallel Bit Pattern Computation,2021,10.1109/ICRC53822.2021.00029,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9743163,Conference Paper,2021 International Conference on Rebooting Computing (ICRC),"Parallel Bit Pattern computing (PBP) has been proposed as a way to dramatically reduce power consumption per computation by minimizing the total number of gate operations. In part, this reduction is accomplished by employing aggressive compiler optimization technology to gate-level representations of computations at runtime. Massive SIMD parallelism is used to obtain speedups while executing the optimized bit-serial code. However, the PBP model also can potentially exponentially reduce the number of active gates for each such operation by recognizing and operating on symbolically-compressed patterns of bits, rather than on each individual bit within a vector. This not only provides for efficient execution of traditional parallel code, but by using bit vectors to represent entangled superposition, enables quantum-like computation to be efficiently implemented using conventional circuitry. Building on lessons learned from various software and Verilog prototypes, this paper proposes a new set of basic operations and interface structure suitable for using inexpensive Xilinx Zynq-7000 boards to implement FGPA-hardware-accelerated PBP computation. Emphasis is on how these operations will implement quantum-like computation, as the first prototype system is currently still under development.",IEEE
K. Zaman; A. Marchisio; M. Kashif; M. Shafique,PO-QA: A Framework for Portfolio Optimization using Quantum Algorithms,2024,10.1109/QCE60285.2024.00166,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10821300,Conference Paper,2024 IEEE International Conference on Quantum Computing and Engineering (QCE),"Portfolio Optimization (PO) is a financial problem aiming to maximize the net gains while minimizing the risks in a given investment portfolio. The novelty of Quantum algorithms lies in their acclaimed potential and capability to solve complex problems given the underlying Quantum Computing (QC) infrastructure. Utilizing QC's applicable strengths to the finance industry's problems, such as PO, allows us to solve these problems using quantum-based algorithms such as Variational Quantum Eigensolver (VQE) and Quantum Approximate Optimization Algorithm (QAOA). While the Quantum potential for finance is highly impactful, the architecture and composition of the quantum circuits have not yet been properly defined as robust financial frameworks/algorithms as state of the art in present literature for research and design development purposes. In this work, we propose a novel scalable framework, denoted PO-QA, to systematically investigate the variation of quantum parameters (such as rotation blocks, repetitions, and entanglement types) to observe their subtle effect on the overall performance. In our paper, the performance is measured and dictated by convergence to similar ground-state energy values for resultant optimal solutions by each algorithm variation set for QAOA and VQE to the exact eigensolver (classical solution). Our results provide effective insights into comprehending PO from the lens of Quantum Machine Learning in terms of convergence to the classical solution, which is used as a benchmark. This study paves the way for identifying efficient configurations of quantum circuits for solving PO and unveiling their inherent inter-relationships.",IEEE
R. R. Dornala; S. Ponnapalli; K. T. Sai; S. R. K. R. Koteru; R. R. Koteru; B. Koteru,Quantum based Fault-Tolerant Load Balancing in Cloud Computing with Quantum Computing,2023,10.1109/ICIMIA60377.2023.10426349,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10426349,Conference Paper,2023 3rd International Conference on Innovative Mechanisms for Industry Applications (ICIMIA),"Cloud computing has become an integral part of modern information technology infrastructure, providing scalability and flexibility to meet the demands of various applications. However, ensuring high availability and fault tolerance in cloud services is crucial for maintaining uninterrupted operations. Load balancing plays a vital role in distributing traffic efficiently across multiple servers to avoid overload and minimize service disruptions. Existing load balancing techniques require help to adapt to dynamic workloads, making them less reliable in cloud environments. Quantum computing handles complex optimization problems and offers a promising avenue for enhancing load balancing in the cloud. This research explores the concept of Fault-Tolerant Load Balancing (FTLB) in cloud computing with the integration of quantum computing. It investigates how quantum algorithms can optimize load-balancing decisions in real-time, considering dynamic workloads and server failures¨C the proposed novel quantum-load balancing (NQ-LB) algorithm designed to improve fault tolerance and resource utilization. The study employs a comparative analysis, evaluating the performance of the quantum-inspired load-balancing approach against classical load-balancing methods. We consider factors such as response time, resource allocation, fault tolerance, and scalability in a cloud computing environment. The results reveal the potential benefits of quantum computing in achieving fault-tolerant load balancing, particularly in scenarios with rapidly changing workloads and server failures. This research contributes to the advancement of cloud computing by harnessing the capabilities of quantum computing to enhance fault tolerance and load balancing. The findings can have implications for industries that rely on highly available cloud services, offering a more resilient infrastructure for critical applications.",IEEE
L. Wen; W. Zhang; X. Jin; Z. Liu,Detection of Research Front Topic Based on Data of NSF Artificial Intelligence Project,2019,10.1109/AIAM48774.2019.00023,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8950768,Conference Paper,2019 International Conference on Artificial Intelligence and Advanced Manufacturing (AIAM),"Artificial intelligence in the United States has been the world's leading, and the detection of research front topic based on the data of NSF artificial intelligent projects is helpful for us to obtain quantitative information for prioritized technologies that could be used for technology management and decision making for research funding and technology investment in the field of artificial intelligent. PLDA model was used to identify topic contained in the NSF project data in the field of artificial intelligence from 2013 to 2018. The funding time, funding amount and centrality indexes of the topic were taken as three indexes to judge research front topics. Threshold value was set according to Pareto Law. And 17 research front topics in the artificial intelligence field were determined. The results showed that 13 aspects, including intelligent system and intelligent community, quantum technology, molecular programming, intelligent simulation, underwater communication and positioning, big data analysis and so on, are the main research front contents concerned in the field of artificial intelligence in the United State.",IEEE
H. Lee; K. Jun,Quantum Optimization Computed Tomography Algorithm with Constraints,2024,10.1109/QCE60285.2024.00077,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10821455,Conference Paper,2024 IEEE International Conference on Quantum Computing and Engineering (QCE),"The emergence of quantum annealers has catalyzed the development of quantum optimization algorithms across various fields. The formulation of a quadratic unconstrained binary optimization (QUBO) model for quantum linear systems suggests that quantum optimization algorithms can play an important role in science and engineering. Recently, a QUBO model was developed by applying a quantum linear system to computed tomography (CT) image reconstruction to clearly show the internal structure of the sample. To date, ultra-clear CT images have not been reconstructed using quantum optimization algorithms owing to limitations in logical qubits. However, the quantum CT image reconstruction algorithm using a quantum linear system provides confidence in the accuracy of the CT image by leveraging the difference between the global and theoretical minimum energies. In this paper, we propose an algorithm that can use two or more QUBO models for CT image reconstruction. The proposed algorithm formulates several QUBO models from CT image reconstruction and verifies them using the hybrid solver of the D-Wave system. The proposed algorithm suggests that quantum-optimized CT algorithms can make greater progress in the future.",IEEE
V. Hahanov; I. Iemelianov; S. Chumachenko; I. Hahanov; I. Hahanova,Quantum sequencer for the minimal test synthesis of black-box functionality,2017,10.1109/EWDTS.2017.8110148,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8110148,Conference Paper,2017 IEEE East-West Design & Test Symposium (EWDTS),"Quantum memory-driven computing on the classical computers for design and test of black-box functionality is considered. A method for synthesis and minimization test for the black-box functionality, based on a qubit derivative matrix and sequencer for searching a quasi-optimum coverage, is proposed. Examples of quantum memory-driven design and test minimization of the Schneider logic circuit are presented. An architecture and algorithm for parallel search of a quasi-minimal set of test vectors based on the logical structure is developed. The technological advantages of the qubit coverage leverage for increasing the speed of performance due to the parallel solution of the test synthesis and analysis for single stuck-at-faults of external and internal variables are shown.",IEEE
E. Villar-Rodriguez; E. Osaba; I. Oregi,Analyzing the behaviour of D'WAVE quantum annealer: fine-tuning parameterization and tests with restrictive Hamiltonian formulations,2022,10.1109/SSCI51031.2022.10022300,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10022300,Conference Paper,2022 IEEE Symposium Series on Computational Intelligence (SSCI),"Despite being considered as the next frontier in computation, Quantum Computing is still in an early stage of development. Indeed, current commercial quantum computers suffer from some critical restraints, such as noisy processes and a limited amount of qubits, among others, that affect the performance of quantum algorithms. Despite these limitations, researchers have devoted much effort to propose different frameworks for efficiently using these Noisy Intermediate-Scale Quantum (NISQ) devices. One of these procedures is D'WAVE Systems' quantum-annealer, which can be used to solve optimization problems by translating them into an energy minimization problem. In this context, this work is focused on providing useful insights and information into the behaviour of the quantum-annealer when addressing real-world combinatorial optimization problems. Our main motivation with this study is to open some quantum computing frontiers to non-expert stakeholders. To this end, we perform an extensive experimentation, in the form of a parameter sensitive analysis. This experimentation has been conducted using the Traveling Salesman Problem as benchmarking problem, and adopting two QUBOs: state-of-the-art and a heuristically generated. Our analysis has been performed on a single 7-noded instance, and it is based on more than 200 different parameter configurations, comprising more than 3700 unitary runs and 7 million of quantum reads. Thanks to this study, findings related to the energy distribution and most appropriate parameter settings have been obtained. Finally, an additional study has been performed, aiming to determine the efficiency of the heuristically built QUBO in further TSP instances.",IEEE
M. Incudini; D. L. Bosco; F. Martini; M. Grossi; G. Serra; A. D. Pierro,Automatic and Effective Discovery of Quantum Kernels,2024,10.1109/TETCI.2024.3499993,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10812182,Article,IEEE Transactions on Emerging Topics in Computational Intelligence,"Quantum computing can empower machine learning models by enabling kernel machines to leverage quantum kernels for representing similarity measures between data. Quantum kernels are able to capture relationships in the data that are not efficiently computable on classical devices. However, there is no straightforward method to engineer the optimal quantum kernel for each specific use case. We present an approach to this problem, which employs optimization techniques, similar to those used in neural architecture search and AutoML, to automatically find an optimal kernel in a heuristic manner. To this purpose we define an algorithm for constructing a quantum circuit implementing the similarity measure as a combinatorial object, which is evaluated based on a cost function and then iteratively modified using a meta-heuristic optimization technique. The cost function can encode many criteria ensuring favorable statistical properties of the candidate solution, such as the rank of the Dynamical Lie Algebra. Importantly, our approach is independent of the optimization technique employed. The results obtained by testing our approach on a high-energy physics problem demonstrate that, in the best-case scenario, we can either match or improve testing accuracy with respect to the manual design approach, showing the potential of our technique to deliver superior results with reduced effort.",IEEE
F. Gemeinhardt; M. Eisenberg; S. Klikovits; M. Wimmer,Model-Driven Optimization for Quantum Program Synthesis with MOMoT,2023,10.1109/MODELS-C59198.2023.00100,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10350515,Conference Paper,2023 ACM/IEEE International Conference on Model Driven Engineering Languages and Systems Companion (MODELS-C),"In the realm of classical software engineering, model-driven optimization has been widely used for different problems such as (re)modularization of software systems. In this paper, we investigate how techniques from model-driven optimization can be applied in the context of quantum software engineering. In quantum computing, creating executable quantum programs is a highly non-trivial task which requires significant expert knowledge in quantum information theory and linear algebra. Although different approaches for automated quantum program synthesis exist¡ªe.g., based on reinforcement learning and genetic programming¡ªthese approaches represent tailor-made solutions requiring dedicated encodings for quantum programs. This paper applies the existing model-driven optimization approach MOMoT to the problem of quantum program synthesis. We present the resulting platform for experimenting with quantum program synthesis and present a concrete demonstration for a well-known Quantum algorithm.",IEEE
H. Oliveira Martins; A. C. Alves Nascimento,QC-MDPC McEliece: an Optimized Implementation of a New McEliece Variant,2015,10.1109/TLA.2015.7164228,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7164228,Journal,IEEE Latin America Transactions,"This paper presents the implementation of an optimized version of a McEliece variant. The McEliece cryptosystem is an example of code-based cryptography which is an alternative to the most popular and commercial cryptosystems nowadays as it is believed to be immune to quantum computing. It has simple and fast algorithms, but its drawback is the size of the keys it has to deal with. By substituting the Goppa codes of the McEliece original proposal by LDPC and MDPC codes it's possible to achieve much smaller keys. And by applying programming technics such as parallelization of operations and also utilizing efficient decoders of LDPC codes it's possible to achieve really good results and optimal performances of the code-based cryptosystem showing that it really has to be considered as a strong substitute to RSA and DSA as quantum computers emerge to easily compute discrete logarithms and factor large integers.",IEEE
J. Dandin; S. Chickerur,Accelerating fluid flow in Quantum Computing using GPU,2023,10.1109/IC2E357697.2023.10262791,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10262791,Conference Paper,"2023 International Conference on Computer, Electronics & Electrical Engineering & their Applications (IC2E3)","In the last few years, quantum computing has evolved as the next big technological breakthrough. Many big companies are actively researching this area and have built open-source frameworks which can be used to develop solutions for problems that connect be solved by classical computers. One such problem is the solution of Navier-Stokes equations which takes exponential time for simulation but using quantum computers, they can be solved in polynomial time. But the current state of quantum computation does not enable everyone to test their implementation on a real quantum computer. In this situation, a simulator enables rapid prototype and testing techniques and algorithms for when the real quantum computer is ready. This paper focuses on simulating fluid flow algorithms using a quantum framework, such as Navier- Stokes equations, with the lattice Boltzmann method (LBM) used to numerically solve the relevant system of equations on both CPU and GPU to speed up the process. The quantum framework used in this paper is Qiskit, an open-source software development kit created by IBM that allows developers to create and test quantum algorithms. NVIDIA cuQuantum is an SDK of optimized libraries and tools for expediting quantum computing operations used in this paper to solve the fundamental problem of modeling large-size quantum circuits using the power of GPU",IEEE
R. Jha; S. Bishnoi; V. V,Efficiently Combining Quantum Mechanics and Algorithm Design for Optimization,2024,10.1109/INOCON60754.2024.10511306,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10511306,Conference Paper,2024 3rd International Conference for Innovation in Technology (INOCON),"Quantum mechanics offers capability benefits for optimization due to its capability to carry out calculations in parallel, but conventional quantum algorithms for optimization have commonly relied on heuristic techniques. Latest advances in algorithm layout have led to the development of new strategies for correctly combining quantum mechanics and set of rules layout for optimization. This paper critiques those new strategies and discusses their capability for enhanced optimization performance. A number of the important thing techniques mentioned encompass quantum annealing, variation quantum Eigen solvers, and quantum walks. Those techniques offer more than a few changes-offs in terms of accuracy and computational complexity. Its miles argued that they could offer positive advantages over traditional optimization algorithms, but careful consideration of the available resources is still critical for attaining the pleasant optimization results. Notwithstanding the modern-day barriers, similarly studies into the capacity of mixing quantum mechanics and set of rules design for optimization holds great promise for the sphere.",IEEE
P. V. Ananda Mohan; A. Jacob; R. S. Patil,Public Key Cryptographic Implementation Validation: A Review,2022,10.1109/PKIA56009.2022.9952350,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9952350,Conference Paper,2022 IEEE International Conference on Public Key Infrastructure and its Applications (PKIA),"This paper reviews the Validation procedures of Implementation in hardware, software, and firmware of Public Key Cryptographic algorithms. NIST standardized several algorithms for the present era a few years ago. Detailed test procedures for algorithm validation and Crypto module validation of implementations have been developed. In the Post-Quantum cryptography scenario, algorithm selection will take place in the coming few months, for which validation procedures need to be established by NIST. These algorithms are for KEM (Key Encapsulation Module) and Digital signatures. The symmetric encryption algorithms continue to be the same as before, using AES with a key length of 256 bits. This paper reviews the scope of validation for traditional Public key algorithms for illustration in this paper. Next, we look at a typical Post Quantum KEM and Digital signature algorithm and discuss the validation procedures to be followed.",IEEE
W. E. Maouaki; N. Innan; A. Marchisio; T. Said; M. Bennai; M. Shafique,Quantum Clustering for Cybersecurity,2024,10.1109/QCE60285.2024.10243,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10821094,Conference Paper,2024 IEEE International Conference on Quantum Computing and Engineering (QCE),"In this study, we develop a novel quantum machine learning (QML) framework to analyze cybersecurity vulnerabilities using data from the 2022 CISA Known Exploited Vulnerabilities catalog, which includes detailed information on vulnerability types, severity levels, common vulnerability scoring system (CVSS) scores, and product specifics. Our framework preprocesses this data into a quantum-compatible format, enabling clustering analysis through our advanced quantum techniques, QCSWAPK-means and QkerneIK-means. These quantum algorithms demonstrate superior performance compared to state-of-the-art classical clustering techniques like k-means and spectral clustering, achieving Silhouette scores of 0.491, Davies-Bouldin indices below 0.745, and Calinski-Harabasz scores exceeding 884, indicating more distinct and well-separated clusters. Our frame-work categorizes vulnerabilities into distinct groups, reflecting varying levels of risk severity: Cluster 0, primarily consisting of critical Microsoft-related vulnerabilities; Cluster 1, featuring medium severity vulnerabilities from various enterprise software vendors and network solutions; Cluster 2, with high severity vulnerabilities from Adobe, Cisco, and Google; and Cluster 3, encompassing vulnerabilities from Microsoft and Oracle with high to medium severity. These findings highlight the potential of QML to enhance the precision of vulnerability assessments and prioritization, advancing cybersecurity practices by enabling more strategic and proactive defense mechanisms.",IEEE
M. Nankya; A. Mugisa; Y. Usman; A. Upadhyay; R. Chataut,Security and Privacy in E-Health Systems: A Review of AI and Machine Learning Techniques,2024,10.1109/ACCESS.2024.3469215,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10697161,Journal,IEEE Access,"The adoption of electronic health (e-health) systems has transformed healthcare delivery by harnessing digital technologies to enhance patient care, optimize operations, and improve health outcomes. This paper provides a comprehensive overview of the current state of e-health systems, tracing their evolution from traditional paper-based records to advanced Electronic Health Record Systems(EHRs) and examining the diverse components and applications that support healthcare providers and patients. A key focus is on the emerging trends in AI-driven cybersecurity for e-health, which are essential for protecting sensitive health data. AI¡¯s capabilities in continuous monitoring, advanced pattern recognition, real-time threat response, predictive analytics, and scalability fundamentally change the security landscape of e-health systems. The paper discusses how AI strengthens data security through techniques like anomaly detection, automated countermeasures, and adaptive learning algorithms, enhancing the efficiency and accuracy of threat detection and response. Furthermore, the paper delves into future directions and research opportunities in AI-driven cybersecurity for e-health. These include the development of advanced threat detection systems that adapt through continuous learning, quantum-resistant encryption to safeguard against future threats, and privacy-preserving AI techniques that protect patient confidentiality while ensuring data remains useful for analysis. The importance of automating regulatory compliance, securing data interoperability via blockchain, and prioritizing ethical AI development are also highlighted as critical research areas. By emphasizing innovative security solutions, collaborative efforts, ongoing research, and ethical practices, the e-health sector can build resilient and secure healthcare infrastructures, ultimately enhancing patient care and health outcomes.",IEEE
P. Li; J. Liu; Y. Li; H. Zhou,Exploiting Quantum Assertions for Error Mitigation and Quantum Program Debugging,2022,10.1109/ICCD56317.2022.00028,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9978402,Conference Paper,2022 IEEE 40th International Conference on Computer Design (ICCD),"An assertion is a predicate that should be evaluated true during program execution. In this paper, we present the development of quantum assertion schemes and show how they are used for hardware error mitigation and software debugging. Compared to assertions in classical programs, quantum assertions are challenging due to the no-cloning theorem and potentially destructive measurement. We discuss how these challenges can be circumvented such that certain properties of quantum states can be verified non-destructively during program execution. Furthermore, we show that besides detecting program bugs, dynamic assertion circuits can mitigate noise effects via post-selection of the assertion results. Our case studies demonstrate the use of quantum assertions in various quantum algorithms.",IEEE
Z. Huang; L. Qian; D. Cai,Analysis on the recent development of quantum computer and quantum neural network technology,2022,10.1109/ICAICA54878.2022.9844614,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9844614,Conference Paper,2022 IEEE International Conference on Artificial Intelligence and Computer Applications (ICAICA),"Many countries have invested a large amount of scientific research funds into supporting quantum information technology and proposed many policies to support the three main quantum technology fields: quantum sensing, quantum communication and quantum computing. Many science and technology giants have also provided quantum cloud computing experimental platforms that can provide quantum access online. With the investment of various technologies and resources, quantum information technology has developed rapidly. The combination of quantum computing and neural networks is a research branch that has attracted much attention in the field of quantum computing in recent years. It mainly involves the study of how to exploit the computational acceleration advantage of quantum computing to deal with various problems solved by neural networks in traditional artificial intelligence. In this paper, the recent development of the quantum computer is widely investigated, and a quantum neural network is briefly analyzed. Finally, the performance of the quantum neural network and quantum optimization is discussed, and future research directions are proposed.","IEEE, Scopus"
C. Gong; Z. Dong; A. Gani; H. Qi,Quantum Ciphertext Dimension Reduction Scheme for Homomorphic Encrypted Data,2021,10.1109/TrustCom53373.2021.00127,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9724344,Conference Paper,"2021 IEEE 20th International Conference on Trust, Security and Privacy in Computing and Communications (TrustCom)","At present, in the face of the huge and complex data in cloud computing, the parallel computing ability of quantum computing is particularly important. Quantum principal component analysis algorithm is used as a method of quantum state tomography. We perform feature extraction on the eigenvalue matrix of the density matrix after feature decomposition to achieve dimensionality reduction, proposed quantum principal component extraction algorithm (QPCE). Compared with the classic algorithm, this algorithm achieves an exponential speedup under certain conditions. The specific realization of the quantum circuit is given. And considering the limited computing power of the client, we propose a quantum homomorphic ciphertext dimension reduction scheme (QHEDR), the client can encrypt the quantum data and upload it to the cloud for computing. And through the quantum homomorphic encryption scheme to ensure security. After the calculation is completed, the client updates the key locally and decrypts the ciphertext result. We have implemented a quantum ciphertext dimensionality reduction scheme implemented in the quantum cloud, which does not require interaction and ensures safety. In addition, we have carried out experimental verification on the QPCE algorithm on IBM's real computing platform. Experimental results show that the algorithm can perform ciphertext dimension reduction safely and effectively.",IEEE
P. Senapati; Z. Wang; W. Jiang; T. S. Humble; B. Fang; S. Xu; Q. Guan,Towards Redefining the Reproducibility in Quantum Computing: A Data Analysis Approach on NISQ Devices,2023,10.1109/QCE57702.2023.00060,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10313593,Conference Paper,2023 IEEE International Conference on Quantum Computing and Engineering (QCE),"Although the building of quantum computers has kept making rapid progress in recent years, noise is still the main challenge for any application to leverage the power of quantum computing. Existing works addressing noise in quantum devices proposed noise reduction when deploying a quantum algorithm to a specified quantum computer. The reproducibility issue of quantum algorithms has been raised since the noise levels vary on different quantum computers. Importantly, existing works largely ignore the fact that the noise of quantum devices varies as time goes by. Therefore, reproducing the results on the same hardware will even become a problem. We analyze the reproducibility of quantum machine learning (QML) algorithms based on daily model training and execution data collection. Our analysis shows a correlation between our QML models' test accuracy and quantum computer hardware's calibration features. We also demonstrate that noisy simulators for quantum computers are not a reliable tool for quantum machine learning applications.",IEEE
J. Wang,Application of QPSO algorithm in layout optimization of construction platform of prefabricated buildings,2022,10.1049/icp.2022.2518,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10042361,Conference Paper,The International Conference on Forthcoming Networks and Sustainability (FoNeS 2022),"With the development of the times, the construction industry has become one of the important pillars of the national economy, but the architectural style under the traditional model is no longer suitable for my country's increasing demand for high-quality construction products. my country's construction industry has now entered a high-quality In the stage of development, prefabricated buildings have entered the era of rise. Prefabricated buildings generally adopt standardized design and standardized construction methods. The buildings have the characteristics of green, environmental protection and high efficiency. With the development of prefabricated buildings, the integration of QPSO algorithm and prefabricated technology has become a hot spot in current architectural design. This paper adopts The QPSO algorithm is applied to the layout optimization of the construction platform of the prefabricated building group, and the corresponding construction platform layout optimization scheme is proposed. In view of the weakness of the QPSO algorithm in the single particle search energy in the complex environment, the pheromone mechanism in the ACO algorithm is introduced to obtain The improved quantum particle swarm optimization algorithm, this paper mainly studies the layout optimization scheme of the construction platform of the prefabricated building group, verifies the feasibility of the entire optimization and simulation process, and forms a systematic, scientific and operable platform management process, from theory to practice. Prefabricated assembly Research on platform layout optimization and simulation of modern buildings. The final results of the research show that when the construction cost of the frame component is 50 yuan, the number of iterations of the QPSO algorithm is 196, the number of iterations of the PSO algorithm is 168, and the number of iterations of the GA algorithm is 156, and the number of iterations of the QPSO algorithm is greater than the other two algorithms.",IEEE
F. Ahmed; P. M?h?nen,Quantum Computing for Artificial Intelligence Based Mobile Network Optimization,2021,10.1109/PIMRC50174.2021.9569339,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9569339,Conference Paper,"2021 IEEE 32nd Annual International Symposium on Personal, Indoor and Mobile Radio Communications (PIMRC)","In this paper, we discuss how certain radio access network optimization problems can be modelled using the concept of constraint satisfaction problems in artificial intelligence, and solved at scale using a quantum computer. As a case study, we discuss root sequence index (RSI) assignment problem ¡ª an important LTE/NR physical random access channel configuration related automation use-case. We formulate RSI assignment as quadratic unconstrained binary optimization (QUBO) problem constructed using data ingested from a commercial mobile network, and solve it using a cloud-based commercially available quantum computing platform. Results show that quantum annealing solver can successfully assign conflict-free RSIs. Comparison with well-known heuristics reveals that some classic algorithms are even more effective in terms of solution quality and computation time. The non-quantum advantage is due to the fact that current implementation is a semi-quantum proof-of-concept algorithm. Also, the results depend on the type of quantum computer used. Nevertheless, the proposed framework is highly flexible and holds tremendous potential for harnessing the power of quantum computing in mobile network automation.",IEEE
S. Zhang; X. Zhou; T. Qiu; D. O. Wu,Quantum-Inspired Robust Networking Model With Multiverse Co-Evolution for Scale-Free IoT,2024,10.1109/TMC.2024.3439511,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10648662,Journal,IEEE Transactions on Mobile Computing,"The robustness of scale-free Internet of Things (IoT) topology is seriously affected by malicious attacks. Improving the tolerance to node failures is critical to the stability of IoT systems. Heuristic algorithms, especially genetic algorithms, enhance the stability of network topology through the evolution of population chromosomes. However, the loss of genetic diversity makes the optimization easily fall into local optimum. Although the problem can be alleviated by adjusting population size and genetic probability, the genetic diversity is still not guaranteed in the limited number of iterations. Inspired by the quantum superposition that simultaneously operates on an exponential number of states, we propose a quantum-inspired robust networking model with multiverse co-evolution for the scale-free IoT (Q-Robust). This model designs quantum chromosomes with double-chain structures to represent the connections between all nodes. Then we present the quantum measurement method of quantum chromosomes based on the degree distribution of nodes. Furthermore, this model constructs a primary-secondary quantum multiverse co-evolution mechanism to improve the convergence efficiency of topology evolution. The experimental results show that the topology robustness optimized by Q-Robust is about 60% and 10% higher than the initial topology and the state-of-the-art topology evolution algorithm, respectively.",IEEE
H. Makhanov; K. Setia; J. Liu; V. Gomez¨CGonzalez; G. Jenaro¨CRabadan,Quantum Computing Applications for Flight Trajectory Optimization,2024,10.1109/QCNC62729.2024.00019,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10628295,Conference Paper,"2024 International Conference on Quantum Communications, Networking, and Computing (QCNC)","Major players in the global aerospace industry are shifting their focus toward achieving net carbon-neutral operations by 2050. A considerable portion of the overall carbon emission reduction is expected to come from new aircraft technologies, such as flight path optimization. In pursuing these sustainability objectives, we delve into the capacity of quantum computing to tackle computational challenges associated with flight path optimization, an essential operation within the aerospace engineering domain with important ecological and economic considerations. In recent years, the quantum computing field has made significant strides, paving the way for improved performance over classical algorithms. In order to effectively apply quantum algorithms in real-world scenarios, it is crucial to thoroughly examine and tackle the intrinsic overheads and constraints that exist in the present implementations of these algorithms. Our study delves into the application of quantum computers in flight path optimization problems and introduces a customizable modular framework designed to accommodate specific simulation requirements. We examine the running time of a hybrid quantum-classical algorithm across various quantum architectures and their simulations on CPUs and GPUs. A temporal comparison between the conventional classical algorithm and its quantum-improved counterpart indicates that achieving the theoretical speedup in practice may necessitate further innovation. We present our results from running the quantum algorithms on IBM hardware and discuss potential approaches to accelerate the incorporation of quantum algorithms within the problem domain.",IEEE
T. Chen; Z. Zhang; H. Wang; J. Gu; Z. Li; D. Z. Pan; F. T. Chong; S. Han; Z. Wang,QuantumSEA: In-Time Sparse Exploration for Noise Adaptive Quantum Circuits,2023,10.1109/QCE57702.2023.00015,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10313775,Conference Paper,2023 IEEE International Conference on Quantum Computing and Engineering (QCE),"Parameterized Quantum Circuits (PQC) have obtained increasing popularity thanks to their great potential for near-term Noisy Intermediate-Scale Quantum (NISQ) computers. Achieving quantum advantages usually requires a large number of qubits and quantum circuits with enough capacity. However, limited coherence time and massive quantum noises severely constrain the size of quantum circuits that can be executed reliably on real machines. To address these two pain points, we propose QuantumSEA, an in-time sparse exploration for noise-adaptive quantum circuits, aiming to achieve two key objectives: (1) implicit circuits capacity during training - by dynamically exploring the circuit's sparse connectivity and sticking a fixed small number of quantum gates throughout the training which satisfies the coherence time and enjoy light noises, enabling feasible executions on real quantum devices; (2) noise robustness - by jointly optimizing the topology and parameters of quantum circuits under real device noise models. In each update step of sparsity, we leverage the moving average of historical gradients to grow necessary gates and utilize salience-based pruning to eliminate insignificant gates. Extensive experiments are conducted with 7 Quantum Machine Learning (QML) and Variational Quantum Eigensolver (VQE) benchmarks on 6 simulated or real quantum computers, where QuantumSEA consistently surpasses noise-aware search, human-designed, and randomly generated quantum circuit baselines by a clear performance margin. For example, even in the most challenging on-chip training regime, our method establishes state-of-the-art results with only half the number of quantum gates and ~ 2 ¡Átime saving of circuit executions. Codes are available at https://github.com/VITA-Group/QuantumSEA.",IEEE
P. Griffin; R. Sampat,Quantum Computing for Supply Chain Finance,2021,10.1109/SCC53864.2021.00066,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9592468,Conference Paper,2021 IEEE International Conference on Services Computing (SCC),"Applying quantum computing to real world applications to assess the potential efficacy is a daunting task for non-quantum specialists. This paper shows an implementation of two quantum optimization algorithms applied to portfolios of trade finance portfolios and compares the selections to those chosen by experienced underwriters and a classical optimizer. The method used is to map the financial risk and returns for a trade finance portfolio to an optimization function of a quantum algorithm developed in a Qiskit tutorial. The results show that whilst there is no advantage seen by using the quantum algorithms, the performance of the quantum algorithms has no statistically significant degradation. Therefore, it is promising that in the future, with expected improvements in quantum hardware, the theoretically superior processing speeds, and data volumes that quantum offers, will also be applicable to trade finance.",IEEE
Q. Zhu; X. Yu; Y. Zhao; A. Nag; J. Zhang,Resource Allocation in Quantum-Key-Distribution- Secured Datacenter Networks With Cloud¨CEdge Collaboration,2023,10.1109/JIOT.2023.3242725,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10039056,Journal,IEEE Internet of Things Journal,"Datacenter networks (DCNs) with cloud¨Cedge collaboration are emerging to satisfy the communication, computation, and caching (3C) requirements of future services such as cloud-based IoT services. However, the enroute data over DCNs with cloud¨Cedge collaboration is likely to suffer from cyberattacks such as eavesdropping. A large number of services require not only 3C resources, but also cryptographic resources for encryption to ensure high security. Quantum key distribution (QKD) is a practical approach to provide secret keys for remote users with information-theoretic security against attacks from quantum computing. A QKD-secured DCN (QKD-DCN) with cloud¨Cedge collaboration can be deployed to satisfy the communication, computation, caching, and cryptographic (4C) requirements of services. This article innovatively solves the new 4C resource-allocation (4CRA) problem in the network to minimize the cryptographic resource consumption. It formulates an integer linear programming (ILP) model and proposes a heuristic cryptographic-dependent 4CRA algorithm to find optimal solutions. The proposed algorithm is compared with two baseline 4CRA algorithms which, respectively, consider the minimized service delivery latency and the first-fit resource availability. Analytical simulations show that the proposed algorithm minimizes the key-resource-consumption ratio and the average key-resource consumption under static and dynamic traffic scenarios in different network topologies.",IEEE
M. Sarkar; J. Pradhan; A. Kumar Singh; H. Nenavath,A Novel Hybrid Quantum Architecture for Path Planning in Quantum-Enabled Autonomous Mobile Robots,2024,10.1109/TCE.2024.3423416,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10585333,Journal,IEEE Transactions on Consumer Electronics,"Autonomous mobile robots are being used increasingly as consumer devices around the globe, such as for fetching items and cleaning purposes, to name a few, in households and industries. Such robots are being employed to traverse a set of target locations and provide the necessary services. In a 2-dimensional environment, these robots are required to traverse following a Hamiltonian path to reduce energy consumption and time requirements. This problem can be formulated as a Travelling Salesman Problem (TSP), an NP-hard problem. Moreover, upon urgent requirements, these robots must traverse in real-time, demanding speedy path planning from the TSP instance. Among the well-known optimization techniques for solving the TSP problem, Ant Colony Optimization has a good stronghold in providing good approximate solutions. Moreover, ACO not only provides near-optimal solutions for TSP instances but can also output optimal or near-optimal solutions for many other demanding hard optimization problems. However, most of the implementations of Ant Colony Optimization on quantum or hybrid quantum architecture proposed in the literature require conversion of classical data to qubits before being fed to the algorithm, and cannot be automated. But quantum-enabled mobile robots require automated path formation after receiving the commands from the environment. The novelties of the proposed work are many-fold. Firstly, the proposed work allows ACO to be applied as its classical counterparts, allowing automation in path formation in quantum-enabled mobile robots. Secondly, this allows a new way of incorporating quantum processing unit in the research of quantum-enabled mobile robots. Researchers around the globe have been trying to incorporate quantum computing in autonomous mobile robots, and true to the best of authors¡¯ knowledge, no work in path planning for multiple targets in quantum-enabled mobile robots have been found in literature. Thirdly, quantum processing unit has been applied at exactly that point where it will be most useful, as in NISQ era quantum computer is not reliable for arithmetic processing. Simulation results of the proposed Hybrid Quantum Ant Colony Optimization algorithm on several TSP instances have shown promising results with average error percentage from optimumresults of only 6.985%. Hence, it is expected that the proposed work to be important in future research of fusing the two rising domains of quantum computing and autonomous mobile robots.",IEEE
A. Jordon; P. P. Angara; S. Joshi,Implementing the Simplex Method with Grover¡¯s Search,2021,10.1109/QCE52317.2021.00066,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9605316,Conference Paper,2021 IEEE International Conference on Quantum Computing and Engineering (QCE),"The simplex method, as proposed by Dantzig in 1947, is a widely-used practical algorithm for solving Linear Programs (LPs)¡ªsystems of linear inequalities headed by a single linear objective function. We examine the difficulty of implementing quantum subroutines outlined by Nannicini in Fast quantum subroutines for the simplex method. Classically, choosing an entering variable in an LP with n optimization variables, m constraints, and at most dc non-zero entries per column requires $O\left({d_c^{0.7}{m^{1.9}} + {m^{2 + o(1) + {d_c}n}}}\right)$ time using the fastest known algorithm for sparse matrix multiplication. By using quantum subroutines Nannicini¡¯s approach results in $O\left({\frac{1}{\varepsilon }\kappa d\sqrt n \left({{d_c}n + dm}\right)}\right)$ time, where ? hides polylogarithmic factors. We examine the implementation of subroutine FindColumn (A,B,?) that selects a valid entering variable (if any) using quantum search and quantum phase estimation algorithms; here, A is the constraint matrix, B is the basis and ? is optimality tolerance. We focus on challenges presented by transforming the matrices and vectors given by an LP into quantum states and the preparation of the oracle. We discuss our implementation and encountered challenges when implementing the algorithm using IBM¡¯s Quantum Experience.",IEEE
E. Osaba; E. Villar-Rodriguez; I. Oregi; A. Moreno-Fernandez-de-Leceta,Hybrid Quantum Computing - Tabu Search Algorithm for Partitioning Problems: Preliminary Study on the Traveling Salesman Problem,2021,10.1109/CEC45853.2021.9504923,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9504923,Conference Paper,2021 IEEE Congress on Evolutionary Computation (CEC),"Quantum Computing is considered as the next frontier in computing, and it is attracting a lot of attention from the current scientific community. This kind of computation provides to researchers with a revolutionary paradigm for addressing complex optimization problems, offering a significant speed advantage and an efficient search ability. Anyway, Quantum Computing is still in an incipient stage of development. For this reason, present architectures show certain limitations, which have motivated the carrying out of this paper. In this paper, we introduce a novel solving scheme coined as hybrid Quantum Computing - Tabu Search Algorithm. Main pillars of operation of the proposed method are a greater control over the access to quantum resources, and a considerable reduction of non-profitable accesses. To assess the quality of our method, we have used 7 different Traveling Salesman Problem instances as benchmarking set. The obtained outcomes support the preliminary conclusion that our algorithm is an approach which offers promising results for solving partitioning problems while it drastically reduces the access to quantum computing resources. We also contribute to the field of Transfer Optimization by developing an evolutionary multiform multitasking algorithm as initialization method.",IEEE
P. Bhaskaran; S. Prasanna,An Accuracy Analysis Of Classical And Quantum Machine Learning Algorithms Using Different Datasets,2024,10.1109/ICNWC60771.2024.10537433,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10537433,Conference Paper,2024 2nd International Conference on Networking and Communications (ICNWC),"Classical machine learning has practical significant advancements and extensive acceptance across various domains, enabling the growth of precise predictive models. The purpose of this work is to examine the accuracy gained by various machine learning algorithms, both classical and quantum. In addition, the study delves into the fundamental ideas and principles that form the backbone of quantum machine learning algorithms, such as quantum data representation, quantum feature mapping, and quantum optimization strategies. Experiments use classical machine learning models trained and tested on traditional hardware to measure evaluation metrics like classification accuracy, precision, recall, and F1-score for quantum machine learning models executed on quantum computing platforms or simulators. In quantum SVM, the seed dataset obtained 100% accuracy, and the supermarket dataset obtained 69% accuracy when compared to classical SVM. The findings imply that, under some conditions, quantum machine learning algorithms show the capacity to beat their conventional counterparts in terms of accuracy.",IEEE
X. Yuan; B. Huang,An improved quantum-behaved gravitional search algorithm for high-dimensional multi-modal optimization,2019,10.1109/ICISCE48695.2019.00036,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9107751,Conference Paper,2019 6th International Conference on Information Science and Control Engineering (ICISCE),"A quantum-behaved gravitional search algorithm based on levy flight (LQ-GSA) is proposed on the basis of analyzing the mechanism of quantum-behaved gravitional search algorithm (QGSA), aiming at solving high dimensional multimodal optimization problems. Firstly, an adaptive dynamic adjustment strategy is proposed for the unique parameter of QGSA-contraction and expansion coefficient (CE), so as to maintain the diversity of population evolution. Secondly, levy flight strategy is introduced in the process of particle location update to expand the search range of particles and enhance the ability of particles to jump out of local optimal. Finally, through the optimization experiment results of six standard test functions in different dimensions, it is shown that LQ-GSA is significantly better than other comparison algorithms in terms of convergence accuracy, convergence speed and stability. With the increase of dimension, the advantages become more prominent, the algorithm shows better performance in solving multi-dimensional and multi-modal optimization problems.",IEEE
Y. Liu; L. Wu; Z. Zhang; X. Zhang; J. Zhou; Y. Yang; L. Wu,Hardware Design of PQC Classic McEliece Finite Field Operations and Encryption Module,2023,10.1109/ASID60355.2023.10426507,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10426507,Conference Paper,"2023 IEEE 17th International Conference on Anti-counterfeiting, Security, and Identification (ASID)","The security of existing cryptosystems mostly relies on the difficulty of solving integer factorization problems and discrete logarithm problems. However, in recent years, with the rapid development of quantum computers, the time required to solve these difficult problems has been significantly reduced, which will pose significant risks to the transmission of information. Post-quantum algorithms are a type of cryptographic algorithm specifically designed to resist quantum computer attacks. The National Institute of Standards and Technology of the United States(NIST) has completed four rounds of selection work from 2016 to 2022. The Classic McEliece algorithm is the only Post-Quantum Cryptography (PQC) algorithm that has been selected for the fourth round of selection after more than 50 years. However, currently, the research and implementation of this algorithm are mostly focused on the software algorithm level, while the hardware implementation can be said to be very few. At the same time, hardware-implemented cryptographic algorithms have certain advantages in terms of security, algorithm execution speed, and other aspects compared to software. In this paper, the arithmetic part and the encryption part of the Classic McEliece algorithm are designed, and a UVM verification platform is built to verify its functionality. Finally, the hardware circuit is verified on the SAKURA-G FPGA development board, relevant resource consumption was collected and compared with the work of the predecessors.",IEEE
T. Zheng; J. Chen; Z. Zhang; Z. Gong; Y. Chen,Bank Credit Score Card Selection and Threshold Determination Based on Quantum Annealing Algorithm and Genetic Algorithm,2023,10.1109/ICPICS58376.2023.10235447,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10235447,Conference Paper,"2023 IEEE 5th International Conference on Power, Intelligent Computing and Systems (ICPICS)","With the progress of the times, influenced by the rapid development of Internet finance and financial technology, the demand for lending is gradually increasing, and the lending services provided by banks are also gradually increasing, and the calculation of bank loan income is more cumbersome. Therefore, in practice, banks tend to assess the credit of their customers through credit scorecards. The assessment is divided into two types: single credit card assessment and combined credit card assessment. Today's society is a highly centralized information society, quantum computers reflect great potential in computing, storage space quantum bits is 2n times than classical bits, and quantum computing can simultaneously calculate multiple numbers at the same time, in various scenarios graph coloring, traveler problem, vehicle path optimization problem, all reflect the great advantages of quantum computing. To this end, this paper takes the selection and threshold determination of bank scorecards as the research object, establishes the QUBO model for scorecard selection and threshold determination considering single scorecard and combined score cards respectively, and solves the model based on quantum annealing algorithm and genetic algorithm respectively. The case validation shows that the model developed and the applied solution method can effectively find the optimal single and combination scorecards.",IEEE
H. Matsuyama; W. -h. Huang; K. Nishimura; Y. Yamashiro,Efficient Internal Strategies in Quantum Relaxation Based Branch-and-Bound,2024,10.1109/QCE60285.2024.00062,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10821426,Conference Paper,2024 IEEE International Conference on Quantum Computing and Engineering (QCE),"A combinatorial optimization problem is to find an optimal combination under the constraints. This is one of the potential applications for quantum computers. Quantum Random Access Optimization (QRAO) is the quantum optimization algorithm that encodes multiple classical variables into a single qubit to construct a quantum Hamiltonian, thereby reducing the number of qubits required. The energy of the ground state of the QRAO Hamiltonian provides a lower bound on the original problem's optimal value before encoding. This property allows the QRAO Hamiltonian to be used as a relaxation of the original problem, and it is thus referred to as a quantum relaxed Hamiltonian. In the Branch-and-Bound method, solving the relaxation problem plays a significant role. In this study, we developed Quantum Relaxation based Branch-and-Bound (QR-BnB), a method incorporating quantum relaxation into the Branch-and-Bound framework. We solved the MaxCut Problem and the Travelling Salesman Problem in our experiments. In all instances in this study, we obtained the optimal solution whenever we successfully computed the exact lower bound through quantum relaxation. Internal strategies, such as relaxation methods and variable selection, influence the convergence of the Branch-and-Bound. Thus, we have further developed the internal strategies for QR-BnB and examined how these strategies influence its convergence. We show that our variable selection strategy via the expectation value of the Pauli operators gives better convergence than the naive random choice. QRAO deals with only unconstrained optimization problems, but QR-BnB can handle constraints more flexibly because of the Branch-and-Bound processes on the classical computing part. We demonstrate that in our experiments with the Travelling Salesman Problem, the convergence of QR-BnB became more than three times faster by using the information in the constraints.",IEEE
S. Sridevi; B. Indira; S. S. Dutta; S. Sandeep; A. Sreenivasan,Quantum Enhanced Support Vector Machine with Instantaneous Quantum Polynomial Encoding for Improved Cyclone Classification,2023,10.1109/ICRTAC59277.2023.10480791,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10480791,Conference Paper,2023 6th International Conference on Recent Trends in Advance Computing (ICRTAC),"The paradigm of classical machine learning has been greatly revolutionized by the integration of the quantum computing paradigm, which has made it possible to solve complicated issues that were previously unsolvable by conventional computers. One such problem is accurately classifying cyclones with minimal data samples and feature parameters. In this paper, we investigate the superior learning capabilities of the Instantaneous Quantum Polynomial Embedding-based kernel Support Vector Machine classifier when compared to the classical Support Vector Machine (SVM) classifier, especially in scenarios with less sample size and feature vector size. Surprisingly, our outcomes reveal that the quantum kernel strategy outperforms its traditional counterpart, even with a smaller sample-based dataset. This incredible performance can be attributed to the quantum core strategy¡¯s exceptional ability to extract complex attributes, which enables it to extract more relevant insights from a smaller number of data points. We present a Quantum Kernel Support Vector Machine (QKSVM) built as a Quantum Kernel Circuit (QKC) in three configurations with varied qubit counts utilizing distinct embedding techniques: Angle embedding (QKSVM Angle), Instantaneous Quantum Polynomial embedding (QKSVM IQP), and Quantum Approximation Optimization Algorithm (QKSVM QAOA) embedding. Our results demonstrate that the QKSVM approach surpasses traditional SVM, especially when IQP embedding is employed. The QSVM model trained with four Principal Component Analysis (PCA) based selected relevant features outperforms the other QKC variations in cyclone classification, obtaining an excellent test accuracy rate of 91.66%.",IEEE
P. Senapati; S. Y. -C. Chen; B. Fang; T. M. Athawale; A. Li; W. Jiang; C. C. Lu; Q. Guan,PQML: Enabling the Predictive Reproducibility on NISQ Machines for Quantum ML Applications,2024,10.1109/QCE60285.2024.00168,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10821454,Conference Paper,2024 IEEE International Conference on Quantum Computing and Engineering (QCE),"Quantum computing represents a groundbreaking approach to high-performance computing. In recent years, quantum computers have progressed from single-qubit processors to systems boasting over 400 qubits. The presence of such a large number of qubits offers significant advantages, including enhanced computational speed¡ªa capability beyond classical computing methods. However, the current stage of quantum computing is referred to as the noisy intermediate-scale quantum (NISQ) era. The existence of noise in this era presents challenges in testing quantum computing applications, leading to considerable variance in application results. Furthermore, the diverse noise characteristics observed across different machines exacerbate this issue, complicating the selection of the appropriate machine for application execution. In response to these challenges, we introduce our Predictive Quantum Machine Learning (PQML) tool. This tool is designed to predict outcomes when executing identical quantum machine learning applications¡ªspecifically, a critical suite of variational quantum algorithms¡ªacross various quantum computers during the NISQ era. This effort relies on data collected over a 12-month period. To the best of our knowledge, this study represents the first attempt to ensure reproducibility across quantum computers for complex circuits. Additionally, we have developed a model capable of forecasting the accuracy of quantum computers for variational quantum algorithms, with a particular emphasis on quantum machine learning as a case study.",IEEE
T. Lisas; R. de Fr¨¦in,IQGO: Iterative Quantum Gate Optimiser for Quantum Data Embedding,2024,10.1109/ACCESS.2024.3520491,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10807205,Journal,IEEE Access,"Quantum kernel methods and Variational Quantum Classifiers (VQCs) have recently gained significant interest in the field of Machine Learning (ML). They have the potential to achieve superior generalisation whilst using smaller datasets and fewer parameters compared to their classical counterparts. However, kernel methods which leverage feature map embedding, often struggle with overfitting, which compromises their generalisation performance on unseen data. VQCs which utilise Parameterised Quantum Circuits (PQCs) to model the relationship between input data and the output, are susceptible to the Barren Plateau (BP) problem. To address these challenges, we introduce an adaptive quantum embedding optimisation algorithm, namely the Iterative Quantum Gate Optimiser (IQGO), which is suited to the task of tabular data classification. IQGO employs a Greedy Search algorithm to optimise the quantum embedding. Empirical evidence on noiseless simulations show that it addresses both the overfitting and the BP problem. We demonstrate the efficacy of IQGO on simulations of 21 qubits for the quantum kernel and 4 qubits for the VQC. Using small tabular datasets, we benchmark our approach against contemporary state-of-the-art classical algorithms. These promising results suggest that quantum algorithms may perform well at data classification problems. We test 5 binary classification problems and show that in 3 of them the IQGO algorithm admits competitive or better performance in terms of generalisation than existing state-of-the-art algorithms.",IEEE
R. Thimmaraju; A. Obulesh; M. S. Reddy,Quantum Computation and Simulation A Distinguished Demonstration Using the BruteForce Algorithm,2020,10.1109/INOCON50539.2020.9298345,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9298345,Conference Paper,2020 IEEE International Conference for Innovation in Technology (INOCON),"From the ashes of Moore's Law and from the womb of Neven's law, raised the motivation to develop a system, i.e, a Quantum Computer, that reshapes the future of the computing industry by providing an exponential speed up. From the past decade, the development of quantum computing technology has been picking up the pace by increasing the qubit count and improving fidelity with circuit optimization and error correction. This document starts by defining the properties of a quantum computer and then draws a fine line between quantum computers and simulators by demonstrating how a quantum simulator works and showing the code to an ideal quantum simulator which concludes by showing the discrepancies between the current classical computer, quantum computer, and a quantum simulator by finding the secret number in a box using a classical algorithm called Brute Force and executing it with the three above mentioned computing methods.",IEEE
C. O¡¯Meara; M. Fern¨¢ndez-Campoamor; G. Cortiana; J. Bernab¨¦-Moreno,Quantum Software Architecture Blueprints for the Cloud: Overview and Application to Peer-2-Peer Energy Trading,2023,10.1109/SusTech57309.2023.10129617,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10129617,Conference Paper,2023 IEEE Conference on Technologies for Sustainability (SusTech),"Applied quantum computing research has often focused on determining business-driven use-cases and applications of quantum algorithms which may provide advantage, either runtime or solution quality, over their classical counterparts. Often missed, yet equally important, is the discussion on how to actually run quantum software applications or models in a production environment where they run in an event-based or scheduled manner thereby providing the results to the enterprise which has spent time upskilling their development team and developing the quantum software solution.In this paper, we introduce a hybrid classical-quantum cloud architecture blueprint which starts from the code-level software development level, and extends to the production-ready quantum software application level. We then, for the first time, introduce a novel sample optimization application used in the energy industry for Peer-2-Peer energy trading and deploy it using the proposed cloud architecture blueprint. We demonstrate sample output of the live-running application where trading optimizations occurs on an hourly basis via remote connection to a quantum computing cloud backend.",IEEE
G. Zhang; W. Ma; K. Xing; L. Xing; K. Wang,Quantum-Inspired Distributed Memetic Algorithm,2022,10.23919/CSMS.2022.0021,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10004910,Journal,Complex System Modeling and Simulation,"This paper proposed a novel distributed memetic evolutionary model, where four modules distributed exploration, intensified exploitation, knowledge transfer, and evolutionary restart are coevolved to maximize their strengths and achieve superior global optimality. Distributed exploration evolves three independent populations by heterogenous operators. Intensified exploitation evolves an external elite archive in parallel with exploration to balance global and local searches. Knowledge transfer is based on a point-ring communication topology to share successful experiences among distinct search agents. Evolutionary restart adopts an adaptive perturbation strategy to control search diversity reasonably. Quantum computation is a newly emerging technique, which has powerful computing power and parallelized ability. Therefore, this paper further fuses quantum mechanisms into the proposed evolutionary model to build a new evolutionary algorithm, referred to as quantum-inspired distributed memetic algorithm (QDMA). In QDMA, individuals are represented by the quantum characteristics and evolved by the quantum-inspired evolutionary optimizers in the quantum hyperspace. The QDMA integrates the superiorities of distributed, memetic, and quantum evolution. Computational experiments are carried out to evaluate the superior performance of QDMA. The results demonstrate the effectiveness of special designs and show that QDMA has greater superiority compared to the compared state-of-the-art algorithms based on Wilcoxon's rank-sum test. The superiority is attributed not only to good cooperative coevolution of distributed memetic evolutionary model, but also to superior designs of each special component.",IEEE
T. Tomesh; K. Gui; P. Gokhale; Y. Shi; F. T. Chong; M. Martonosi; M. Suchara,Optimized Quantum Program Execution Ordering to Mitigate Errors in Simulations of Quantum Systems,2021,10.1109/ICRC53822.2021.00013,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9743179,Conference Paper,2021 International Conference on Rebooting Computing (ICRC),"Simulating the time evolution of a physical system at quantum mechanical levels of detail - known as Hamiltonian Simulation (HS) - is an important and interesting problem across physics and chemistry. For this task, algorithms that run on quantum computers are known to be exponentially faster than classical algorithms; in fact, this application motivated Feynman to propose the construction of quantum computers. Nonetheless, there are challenges in reaching this performance potential. Prior work has focused on compiling circuits (quantum programs) for HS with the goal of maximizing either accuracy or gate cancellation. Our work proposes a compilation strategy that simultaneously advances both goals. At a high level, we use classical optimizations such as graph coloring and travelling salesperson to order the execution of quantum programs. Specifically, we group together mutually commuting terms in the Hamiltonian (a matrix characterizing the quantum mechanical system) to improve the accuracy of the simulation. We then rearrange the terms within each group to maximize gate cancellation in the final quantum circuit. These optimizations work together to improve HS performance and result in an average 40% reduction in circuit depth. This work advances the frontier of HS which in turn can advance physical and chemical modeling in both basic and applied sciences.",IEEE
N. Rengaswamy; R. Calderbank; S. Kadhe; H. D. Pfister,Logical Clifford Synthesis for Stabilizer Codes,2020,10.1109/TQE.2020.3023419,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9195023,Journal,IEEE Transactions on Quantum Engineering,"Quantum error-correcting codes are used to protect qubits involved in quantum computation. This process requires logical operators to be translated into physical operators acting on physical quantum states. In this article, we propose a mathematical framework for synthesizing physical circuits that implement logical Clifford operators for stabilizer codes. Circuit synthesis is enabled by representing the desired physical Clifford operator in CN¡ÁN as a 2m ¡Á 2m binary symplectic matrix, where N = 2m. We prove two theorems that use symplectic transvections to efficiently enumerate all binary symplectic matrices that satisfy a system of linear equations. As a corollary, we prove that for an [[m, k]] stabilizer code every logical Clifford operator has 2r(r+1)/2 symplectic solutions, where r = m - k, up to stabilizer degeneracy. The desired physical circuits are then obtained by decomposing each solution into a product of elementary symplectic matrices, that correspond to elementary circuits. This enumeration of all physical realizations enables optimization over the ensemble with respect to a suitable metric. Furthermore, we show that any circuit that normalizes the stabilizer can be transformed into a circuit that centralizes the stabilizer, while realizing the same logical operation. Our method of circuit synthesis can be applied to any stabilizer code, and this paper discusses a proof of concept synthesis for the [[6, 4, 2]] CSS code. Programs implementing the algorithms in this article, which includes routines to solve for binary symplectic solutions of general linear systems and our overall LCS (logical circuit synthesis) algorithm, can be found at https://github.com/nrenga/symplectic-arxiv18a",IEEE
C. R. Garc¨ªa; O. Bouchmal; C. Stan; P. Giannakopoulos; B. Cimoli; J. J. V. Olmos; S. Rommel; I. T. Monroy,Secure and Agile 6G Networking ¨C Quantum and AI Enabling Technologies,2023,10.1109/ICTON59386.2023.10207418,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10207418,Conference Paper,2023 23rd International Conference on Transparent Optical Networks (ICTON),"This paper proposes a novel architecture for enabling ultra-fast and ultra-safe 6G networks that can support complex and challenging real-time applications based on four key enabling technologies: 1) performance prediction, 2) AI-enabled task offloading, 3) quantum machine learning, and 4) quantum-resistant communication. With the emergence of 6G applications where the real-time quality of experience is prioritized, AI-enabled task offloading leverages the benefits of edge computing. Moreover, the execution time of complex applications can be reduced by using quantum computers at the edge or in the cloud. In addition, by incorporating quantum key distribution and post-quantum cryptography, we can ensure the safety of mobile networks in the quantum computing era. Collectively, these technologies will provide ultra-fast and ultra-safe 6G networks, meeting the requirements of challenging real-time applications that were not supported in the previous generations, thus advancing the state of the art of mobile communication networks.",IEEE
M. Coccia; S. Roshani; M. Mosleh,Evolution of Quantum Computing: Theoretical and Innovation Management Implications for Emerging Quantum Industry,2024,10.1109/TEM.2022.3175633,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9800933,Journal,IEEE Transactions on Engineering Management,"Quantum computing is a vital research field in science and technology. One of the fundamental questions hardly known is how quantum computing research is developing to support scientific advances and the evolution of path-breaking technologies for economic, industrial, and social change. This study confronts the question here by applying methods of computational scientometrics for publication analyses to explain the structure and evolution of quantum computing research and technologies over a 30-year period. Results reveal that the evolution of quantum computing from 1990 to 2020 has a considerable average increase of connectivity in the network (growth of degree centrality measure), a moderate increase of the average influence of nodes on the flow between nodes (little growth of betweenness centrality measure), and a little reduction of the easiest access of each node to all other nodes (closeness centrality measure). This evolutionary dynamics is due to the increase in size and complexity of the network in quantum computing research over time. This study also suggests that the network of quantum computing has a transition from hardware to software research that supports accelerated evolution of technological pathways in quantum image processing, quantum machine learning, and quantum sensors. Theoretical implications of this study show the morphological evolution of the network in quantum computing from a symmetric to an asymmetric shape driven by new inter-related research fields and emerging technological trajectories. Findings here suggest best practices of innovation management based on R&D investments in new technological directions of quantum computing having a high potential for growth and impact in science and markets.",IEEE
Y. -n. Zhang; H. Yang; Z. -k. Lin; Q. Dai; Y. -f. Li,A Test Suite Reduction Method Based on Novel Quantum Ant Colony Algorithm,2017,10.1109/ICISCE.2017.176,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8110403,Conference Paper,2017 4th International Conference on Information Science and Control Engineering (ICISCE),"Test Suite Reduction is to find a subset of the original test suite which contains less test cases than original one but covers the same test request. In order to reduce the size of the data processed by Ant Colony Algorithm, this paper firstly chooses the test case set to form a candidate set. Then, based on the ant colony algorithm, QEA (Quantum-inspired Evolutionary Algorithm) and quantum revolving gate are introduced. The advantages of entanglement and coherence of quantum computation are introduced. In addition, we propose a Test Suite Reduction method based on Modified Quantum Ant Colony Algorithm. Finally we make quantity of simulation experiments compared the result of other algorithms, we find that the modified quantum ant colony system can solve the problem more efficiently and perform much better.",IEEE
C. Murugesh; S. Murugan,Modelling of Optimal Quantum Neural Network for DDoS Attack Classification in Wireless Sensor Networks,2023,10.1109/ICAIS56108.2023.10073673,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10073673,Conference Paper,2023 Third International Conference on Artificial Intelligence and Smart Energy (ICAIS),"Wireless Sensor networks (WSN) are a new technology and are huge potential that is utilized in crucial moments such as battlefields and commercial applications namely habitat monitoring and smart homes, building, traffic surveillance, etc. Among the main problems WSNs currently affecting is security. But the utilization of sensor nodes (SNs) from the unattended platform creates the networks vulnerable to variation of potential attacks, the inherent power and memory restrictions of SNs create ordinary security solutions impossible. This article develops a Spotted Hyena Optimizer with Quantum Neural Network for DDoS Attack Classification (SHOQNN-AC) technique for WSN. The major intention of the SHOQNN-AC technique lies in the proper identification of DDoS attacks in the WSN. To accomplish this, the SHOQNN-AC technique performs data scaling process using min-max scaler. For DDoS attack detection, the SHOQNN-AC technique employs QNN classification model which proficiently recognizes the DDoS attacks in the network. To boost the attack detection efficiency of the SHOQNN-AC technique, the SHO algorithm is exploited for parameter selection procedure. The performance validation of SHOQNN-AC technique is tested on benchmark WSN-DS dataset. The experimental outcome demonstrates the significance of the SHOQNN-AC algorithm over other models.",IEEE
J. Wang; P. Lin; Y. Huang; X. Xie; S. Xu; L. Zhang,Simulation of Quantum Chip Packaging Based on Superconducting Material Interconnection System,2024,10.1109/ICEPT63120.2024.10668742,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10668742,Conference Paper,2024 25th International Conference on Electronic Packaging Technology (ICEPT),"With the rapid development of big data, artificial intelligence, Internet of Things and other technologies, quantum computers have emerged. It has unparalleled advantages in the fields of complex problem optimization, physical system simulation and encryption. Among them, superconducting quantum computing has become the mainstream direction of quantum computer development due to its advantages of scalability and process compatibility. However, there is no mature process integration scheme for large-scale quantum computer packaging technology with more than 100 bits. In this paper, for the packaging requirements of general-purpose large-bit superconducting quantum chips, a process simulation study based on the interconnection system of low-temperature superconducting In bumps and Al bonding filaments is carried out. Through the optimization of the interconnection structure of the package box structure, SMA terminals, high-speed substrate and other interconnection structures, the parasitic capacitance-generating structure is localized, electromagnetic leakage patterns are clarified, and a multilevel interconnection scheme with good electromagnetic shielding and low loss is obtained. Optimization of In bump and Al bonding process, the interconnect optimization scheme of substrate slotting and three-wire bonding is obtained, with insertion loss > -ldB and reflection loss >-20dB. The overall insertion loss of the multilevel interconnect structure is > -3dB and reflection loss >-15dB, which meets the demand of high-quality signal transmission. The results of this study demonstrate the quantum chip signal transmission and simulation modeling method, and provide a new idea for the cross-scale finite element electromagnetic simulation of superconducting quantum chips.",IEEE
J. Zhang; D. Zhang; G. Shen; J. Yang,Research on fault diagnosis of marine diesel engine based on probabilistic neural network optimized by quantum genetic algorithm,2021,10.1109/AUTEEE52864.2021.9668645,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9668645,Conference Paper,"2021 IEEE 4th International Conference on Automation, Electronics and Electrical Engineering (AUTEEE)","In order to solve the problems of manual diagnosis of diesel engine faults, such as difficult diagnosis, time-consuming diagnosis and various fault types, a method of intelligent diagnosis of diesel engine faults based on quantum genetic algorithm to optimize PNNmodel was proposed. Firstly, a fault diagnosis model based on PNN is established according to the structure and operation characteristics of the marine diesel engine, and then the smoothing parameter of the probabilistic network model is optimized by using the efficient optimization ability of quantum genetic algorithm, and finally a fault diagnosis model with high accuracy based on PNN is constructed. The simulation results show that the fault diagnosis algorithm of marine diesel engine based on probabilistic neural network optimized by quantum genetic algorithm has obvious advantages in diagnosis accuracy and convergence speed: the diagnosis accuracy can reach 94.4%, and the diagnosis speed is 40% faster than that of BP neural network model.",IEEE
V. Hlukhov; B. Havano,"Principles of Digital Quantum Coprocessor Based on a FPGA, which Operates under the Control of a Classical Computer",2019,10.1109/ACITT.2019.8779932,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8779932,Conference Paper,2019 9th International Conference on Advanced Computer Information Technologies (ACIT),"Classical quantum computer is analog probabilistic computer. The digital quantum computer that can be implemented in FPGA is described in the article. Digital quantum coprocessor is designed to implement algorithms for execution on analog quantum computers. A digital quantum coprocessor operates under the control of a classical computer and together they are digital quantum computer. The digital quantum coprocessor is a set of digital units called digital qubits that have multibit data input and one bit data output each. The digital qubit is a wave function calculator. There is pseudo random number generator (PRNG) in described digital qubit to generate the probabilistic output bit. One bit qubit output qb is formed by the probable reduction of its multibit result x to one bit (0 or 1) according to result value x and pseudo random code k (x is an angle which determines the position of normalized vector with length 1 in polar grid, it is a result of multibit input data calculation). The decision about output state is made after the functional conversion of the qubit multibit result x to result probability p - sin.x and subsequent comparison p with the pseudo random code k. Qb -1 when k <; p (as in classical quantum computer). In article the alternative variant of decision option with p - arcsin(sqrt(k)) and qb - 1 when x > p is described. This variant allows use one PRNG for all digital qubits. Qubit presentation as vector in Bloch's sphere and vector in polar grid is discussed in the work. Also two types of coprocessor data formats (Cartesian and polar) are described. Instruction set of digital quantum coprocessor based in vector presentation in polar coordinates are discussed.",IEEE
A. S. Dalvi; J. Whitlow; M. D'Onofrio; L. Riesebos; T. Chen; S. Phiri; K. R. Brown; J. M. Baker,One-Time Compilation of Device-Level Instructions for Quantum Subroutines,2024,10.1109/QCE60285.2024.00107,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10821465,Conference Paper,2024 IEEE International Conference on Quantum Computing and Engineering (QCE),"A large class of problems in the current era of quantum devices involve interfacing between the quantum and classical system. These include calibration procedures, charac-terization routines, and variational algorithms. The control in these routines iteratively switches between the classical and the quantum computer. This results in the repeated compilation of the program that runs on the quantum system, scaling directly with the number of circuits and iterations. The repeated compilation results in a significant overhead throughout the routine. In practice, the total runtime of the program (classical compilation plus quantum execution) has an additional cost proportional to the circuit count. At practical scales, this can dominate the round-trip CPU-QPU time, between 5% and 80%, depending on the proportion of quantum execution time. To avoid repeated device-level compilation, we identify that machine code can be parametrized corresponding to pulse/gate parameters which can be dynamically adjusted during execution. Therefore, we develop a device-level partial-compilation (DLPC) technique that reduces compilation overhead to nearly constant, by using cheap remote procedure calls (RPC) from the QPU control software to the CPU. We then demonstrate the performance speedup of this on optimal pulse calibration, system characterization using randomized benchmarking (RB), and variational algorithms. We execute this modified pipeline on real trapped-ion quantum computers and observe significant reductions in compilation time, as much as 2.7x speedup for small-scale VQE problems.",IEEE
Y. Hindy; J. Pointing; M. Tolunay; S. Venkatarao; M. Motta; J. A. Latone,Application of the Variational Quantum Eigensolver to the Ultimate Pit Problem,2023,10.1109/QCE57702.2023.00083,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10313729,Conference Paper,2023 IEEE International Conference on Quantum Computing and Engineering (QCE),"Determining the ultimate pit profile that maximizes the profit while minimizing the cost of mine extraction is a fundamental problem in open-pit mining. The development of quantum computing hardware and advances in heuristic quantum algorithms make it possible to explore quantum computing as a solution for the ultimate pit problem. Here, we cast the ultimate pit problem as a Hamiltonian ground-state search problem, which we approximately solve using the variational quantum eigensolver algorithm. Moreover, we use a domain decomposition approach to extend the reach of today's small-scale quantum hardware. We demonstrate the procedure on IBMQ devices using four qubits. To the best of our knowledge, this is the first attempt to use heuristic quantum algorithms to map small-scale instances of the ultimate pit problem on quantum hardware.",IEEE
D. W. Kim; D. I. Maulana; W. Jung,Kyber Accelerator on FPGA Using Energy-Efficient LUT-Based Barrett Reduction,2022,10.1109/ISOCC56007.2022.10031533,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10031533,Conference Paper,2022 19th International SoC Design Conference (ISOCC),"Contemporary cryptographic algorithms such as RSA and ECC can collapse due to the development of quantum computing. NIST has announced the first standardized post-quantum cryptography algorithms that are resilient to the quantum computer's attack, among which CRYSTALS-KYBER is the only algorithm for public-key encryption. This algorithm uses the number theoretic transform (NTT) to reduce the time complexity of the polynomial multiplication. However, NTT itself is still a big computational bottleneck of the entire algorithm. Also, modulo reduction consumes almost half of the energy of the butterfly unit for processing NTT. This paper presents a Kyber accelerator using LUT-based Barrett reduction, which reduces the energy for modulo operation by 40.6% from the original Barrett reduction. The test system is implemented on the Xilinx Zynq UltraScale+ ZCU104 and shows 113.3x speedup for NTT and 1.78x speedup for Kyber compared to the original CPU.",IEEE
B. Lee; M. Perkowski,Quantum Machine Learning Based on Minimizing Kronecker-Reed-Muller Forms and Grover Search Algorithm with Hybrid Oracles,2016,10.1109/DSD.2016.30,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7723581,Conference Paper,2016 Euromicro Conference on Digital System Design (DSD),"This paper formulates the generic Machine Learning (ML) problem into finding the simplest spectral transform form (i.e. one having as many zero coefficients as possible) for an (in)complete binary function. The classical binary logic synthesis problem can be modeled to minimize a single output Boolean function with a two-level structure consisting of an exclusive-OR (EXOR) of ANDs of literals. The innovative approach in this paper is to build and simulate an accelerator that reduces learning to find the exact minimum expression of all 3n Kronecker Reed Muller (KRO) forms of a Boolean function with n input variables. This is in contrast to the previously studied quantum algorithm for the Fixed Polarity Reed-Muller forms (FPRM) which only selects from 2n possible forms. The algorithm, based on repeated application of a ternary Grover's Quantum Search algorithm, was simulated to find the minimum KRO form using a hybrid ternary/binary quantum oracle. This hybrid quantum system was simulated in Matlab and proved to be correct. The method can be also used as a future Quantum EDA Tool for exact minimization of AND/EXOR circuits, including reversible and quantum circuits.",IEEE
J. -Y. Wu,An improved quantum-behaved particle swarm optimization method for solving constrained global optimization problems,2015,10.1109/ISCIT.2015.7458331,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7458331,Conference Paper,2015 15th International Symposium on Communications and Information Technologies (ISCIT),"A standard quantum-behaved quantum particle swarm optimization (QPSO) method outperforms a standard PSO approach in search ability and only needs a few parameter settings. To improve the capabilities of a standard QPSO algorithm, this study develops (1) a Cauchy mutation operator to increase the diversity of particles in a population, (2) an operator based on evolution generations to update a contraction expansion coefficient and (3) an elitist strategy to remain the strong particles. The proposed IQPSO algorithm is applied to solve constrained global optimization problems. This study compares the numerical results obtained using the IQPSO algorithm with those obtained using evolutionary algorithms and particle swarm optimization methods. Numerical results show that the proposed IQPSO approach can obtain the global optimal solution for a CGO problem and outperforms to some published algorithms.",IEEE
S. S. Cranganore; V. De Maio; I. Brandic; T. M. A. Do; E. Deelman,Molecular Dynamics Workflow Decomposition for Hybrid Classic/Quantum Systems,2022,10.1109/eScience55777.2022.00048,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9973678,Conference Paper,2022 IEEE 18th International Conference on e-Science (e-Science),"Since we are entering the Post-Moore Law era and consequently the limit of Von Neumann's architecture, the scientific community is looking for alternatives to satisfy the growing computing power demands of scientific applications. Quantum computing promises to achieve a computational advantage over the classic Von Neumann architecture. However, the limited capabilities of current noisy intermediate-scale quantum (NISQ) devices require quantum computers to interoperate with classic systems, forming the so-called hybrid quantum systems. Research on hybrid quantum systems led to the design of Variational Quantum Algorithms, currently the most promising way to move towards quantum advantage. However, execution time and accuracy of variational quantum algorithms are affected by different hyperparameters, including selected cost functions and parametrized quantum circuits. Consequently, providing developers with methods to select the right set of parameters is of paramount importance. In this work, we provide a formal method for the selection of hyperparameters in variational quantum algorithms, which will support quantum algorithms developers in the design of quantum applications, and evaluate it on a real-world scientific application, showing a reduction of error up to 31%.",IEEE
K. S. Szatm¨¢ry; P. M. Kozlovszky,Comparison of C# and Qiskit Runtimes on K-Means Clustering,2023,10.1109/CANDO-EPE60507.2023.10418018,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10418018,Conference Paper,2023 IEEE 6th International Conference and Workshop ?buda on Electrical and Power Engineering (CANDO-EPE),"International literature suggests that quantum computers hold the potential for exponential speedup over classical computers, particularly for certain types of optimization problems. However, the practical application of quantum k-means is currently limited by the capabilities of available quantum hardware. As quantum technology improves and more efficient algorithms are developed, quantum k-means may offer advantages for larger datasets and high-dimensional data. This essay presents a comparative study of the k-means clustering algorithm implemented in two runtime environments, C# and Qiskit, with a focus on investigating the potential existence of quantum supremacy for a defined problem. The experiment involves randomly generated data and data tables of different sizes and dimensions. The classical approach utilizes a brute-force enumeration method, while the quantum approach employs a quadratic programming algorithm on a quantum computer using Qiskit. Results show that for small problem sizes, the classical brute-force approach exhibits superior runtime performance compared to the quantum approach. However, the study highlights the challenges in achieving quantum supremacy, as the performance of quantum computers is highly dependent on machine capabilities and qubit numbers.",IEEE
D. Padilha; S. Weinstock; M. Hodson,QxSQA: GPGPU-Accelerated Simulated Quantum Annealer within a Non-Linear Optimization and Boltzmann Sampling Framework,2019,10.1109/HPEC.2019.8916450,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8916450,Conference Paper,2019 IEEE High Performance Extreme Computing Conference (HPEC),"We introduce QxSQA, a GPGPU-Accelerated Simulated Quantum Annealer based on Path-Integral Monte Carlo (PIMC). QxSQA is tuned for finding low-energy solutions to integer, non-linear optimization problems of up to 214 (16,384) binary variables with quadratic interactions on a single GPU instance. Experimental results demonstrate QxSQA can solve Maximum Clique test problems of 8,100 binary variables with planted solutions in under one minute, with linear scaling against key optimization parameters on other large-scale problems. Through the PIMC formulation, QxSQA also functions as an accurate sampler of Boltzmann distributions for machine learning applications. Experimental characterization of Boltzmann sampling results for a reinforcement learning problem showed good convergence performance at useful scales. Our implementation integrates as a solver within our QxBranch developer platform, positioning developers to efficiently develop applications using QxSQA, and then test the same application code on a quantum annealer or universal quantum computer hardware platform such as those from D-Wave Systems, IBM, or Rigetti Computing.",IEEE
L. Bergadano; A. Ceschini; P. Chiavassa; E. Giusto; B. Montrucchio; M. Panella; A. Rosato,Q-SCALE: Quantum Computing-Based Sensor Calibration for Advanced Learning and Efficiency,2024,10.1109/QCE60285.2024.00044,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10821428,Conference Paper,2024 IEEE International Conference on Quantum Computing and Engineering (QCE),"In a world burdened by air pollution, the integration of state-of-the-art sensor calibration techniques utilizing Quantum Computing (QC) and Machine Learning (ML) holds promise for enhancing the accuracy and efficiency of air quality monitoring systems in smart cities. This article investigates the process of calibrating inexpensive optical fine-dust sensors through advanced methodologies such as Deep Learning (DL) and Quantum Machine Learning (QML). The objective of the project is to compare four sophisticated algorithms from both the classical and quantum realms to discern their disparities and explore possible alternative approaches to improve the precision and dependability of particulate matter measurements in urban air quality surveillance. Classical Feed-Forward Neural Networks (FFNN) and Long Short-Term Memory (LSTM) models are evaluated against their quantum counterparts: Variational Quantum Regressors (VQR) and Quantum LSTM (QLSTM) circuits. Through meticulous testing, including hyperparameter optimization and cross-validation, the study assesses the potential of quantum models to refine calibration performance. Our analysis shows that: the FFNN model achieved superior calibration accuracy on the test set compared to the VQR model in terms of lower L1 loss function (2.92 vs 4.81); the QLSTM slightly outperformed the LSTM model (loss on the test set: 2.70 vs 2.77), despite using fewer trainable weights (66 vs 482).",IEEE
N. Khammassi; I. Ashraf; X. Fu; C. G. Almudever; K. Bertels,QX: A high-performance quantum computer simulation platform,2017,10.23919/DATE.2017.7927034,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7927034,Conference Paper,"Design, Automation & Test in Europe Conference & Exhibition (DATE), 2017","Quantum computing is rapidly evolving especially after the discovery of several efficient quantum algorithms solving intractable classical problems such as Shor's factoring algorithm. However the realization of a large-scale physical quantum computer is very challenging and the number of qubits that are currently under development is still very low, namely less than 15. In the absence of large size platforms, quantum computer simulation is critical for developing and testing quantum algorithms and investigating the different challenges facing the design of quantum computer hardware. What makes quantum computer simulation on classical computers particularly challenging are the memory and computational resource requirements. In this paper, we introduce a universal quantum computer simulator, called QX, that takes as input a specially designed quantum assembly language, called QASM, and provides, through agressive optimisations, high simulation speeds and large number of qubits. QX allows the simulation of up to 34 fully entangled qubits on a single node using less than 270 GB of memory. Our experiments using different quantum algorithms show that QX achieves significant simulation speedup over similar state-of-the-art simulation environment.",IEEE
N. Samanvita; S. A; K. Durai; S. Dixit,Exploring Thermometer Code Addition and Subtraction in Quantum Computing,2023,10.1109/ICRASET59632.2023.10420322,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10420322,Conference Paper,2023 International Conference on Recent Advances in Science and Engineering Technology (ICRASET),"Quantum computing, a new technology, has the potential to alter a wide range of fields, from encryption and chemistry to optimisation. Among its fundamental operations, addition and subtraction of integers are the most important. This study looks into the fascinating world of quantum computation, focusing on the clever thermometer code method to addition and subtraction. We reveal the underlying workings of these operations using Qiskit, an open-source quantum computing platform, by analysing the algorithms and quantum circuits that fuel them. We uncover the performance complexities of these quantum processes by thorough research over a wide range of input conditions. The findings show the way forward in a world filled with quantum promise. Thermometer code arithmetic emerges as a potent weapon in the quantum toolbox, with the potential to transform the way we calculate. This report is more than simply a look into quantum possibilities; it's a call to action, urging researchers to push their boundaries and realise the full potential of this revolutionary technology.",IEEE
F. Orlando; D. Volpe; G. Orlandi; F. Rientc; M. Vacca; M. Graziano,Engineering Discrete Simulated Bifurcation for an FPGA Digital Ising Machine,2024,10.1109/QCE60285.2024.10373,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10821098,Conference Paper,2024 IEEE International Conference on Quantum Computing and Engineering (QCE),"Simulated Adiabatic Bifurcation (aSB) is a quantum-inspired algorithm that provides approximate solutions for large-scale optimization problems using the Ising model. It emulates the quantum adiabatic evolution of a network of non-linear Kerr oscillators on classical platforms. These oscillators undergo bifurcation, where each branch corresponds to a spin state, with the network creating an energy imbalance to deter-mine the optimal solution. This approach is highly parallelizable, making it suitable for implementation on GPUs and FPGAs. However, classical emulation introduces analog errors, potentially compromising performance. To address this, alternative methods like ballistic (bSB) and discrete (dSB) evolutions were developed, with the ballistic approach further enhanced by thermal fluctuations (HbSB). Our comprehensive analysis of bSB, dSB, and HbSB using benchmark Max-Cut and knapsack problems aimed to identify the best balance of speed, area, and accuracy. We found that fixed-point number representation allows more algorithm iterations within the same timeframe as floating-point representation. The proposed FPGA architecture implements d $S$ B and its heated version, leveraging high parallelizability and efficient memory or-ganization. This design supports larger coefficients and improves problem-solving efficiency without multipliers for matrix-vector evaluation. Challenges include mitigating data dependency between matrix-vector multiplication and time evolution, and developing a preconditioning method for adapting problem coefficients, making the architecture suitable for real-world applications and potential ASIC release.",IEEE
A. Witt,Queue-aware Network Control Algorithm with a High Quantum Computing Readiness¡ªEvaluated in Discrete-time Flow Simulator for Fat-Pipe Networks,2024,10.1109/HPSR62440.2024.10636008,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10636008,Conference Paper,2024 IEEE 25th International Conference on High Performance Switching and Routing (HPSR),"The emerging technology of quantum computing has the potential to change the way how problems will be solved in the future. This work presents a centralized network control algorithm executable on already existing quantum computer which are based on the principle of quantum annealing like the D-Wave Advantage?. We introduce a resource reoccupation algorithm for traffic engineering in wide-area networks. The proposed optimization algorithm changes traffic steering and resource allocation in case of overloaded transceivers. Settings of active components like fiber amplifiers and transceivers are not changed for the reason of stability. This algorithm is beneficial in situations when the network traffic is fluctuating in time scales of seconds or spontaneous bursts occur. Further, we developed a discrete-time flow simulator to study the algorithm¡¯s performance in wide-area networks. Our network simulator considers backlog and loss modeling of buffered transmission lines. Concurring flows are handled equally in case of a backlog. This work provides an ILP-based network configuring algorithm that is applicable on quantum annealing computers. We showcase, that traffic losses can be reduced significantly by a factor of 2 if a resource reoccupation algorithm is applied in a network with bursty traffic. As resources are used more efficiently by reoccupation in heavy load situations, overprovisioning of networks can be reduced. Thus, this new form of network operation leads toward a zero-margin network. We show that our newly introduced network simulator enables analyses of short-time effects like buffering within fat-pipe networks. As the calculation of network configurations in real-sized networks is typically time-consuming, quantum computing can enable the proposed network configuration algorithm for application in realsized wide-area networks.",IEEE
S. Upadhyay; S. Ghosh,SHARE: Secure Hardware Allocation and Resource Efficiency in Quantum Systems,2024,10.1109/QCE60285.2024.00130,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10821365,Conference Paper,2024 IEEE International Conference on Quantum Computing and Engineering (QCE),"Quantum computing (QC) is poised to revolutionize problem-solving across various fields, with research suggesting that systems with over 50 qubits may achieve quantum advantage-surpassing supercomputers in certain optimization tasks. As the hardware size of Noisy Intermediate-Scale Quantum (NISQ) computers continues to grow, Multi-tenant computing (MTC) has emerged as a viable approach to enhance hardware utilization by allowing shared resource access across multiple quantum programs. However, MTC can also bring challenges and security concerns. This paper focuses on optimizing quantum hardware utilization in shared environments by implementing multi-programming strategies that not only enhance hardware utilization but also effectively manage associated risks like crosstalk and fault injection. We propose a novel partitioning and allocation method called Community-Based Dynamic Allocation Partitioning (COMDAP) and Secure COMDAP to refine and secure multi-programming capabilities in quantum systems. COMDAP ensures equitable and efficient resource distribution, addresses the issues of suboptimal partitioning, and significantly improves hardware utilization. We report a 23% average improvement in hardware utilization rate compared to existing greedy heuristics, with rates averaging 92%. COMDAP introduces an average increase of approximately 0.05X in $\Delta \mathbf{CX}$, alongside a 3.5% average reduction in PST across benchmarks.",IEEE
M. Federer; D. M¨¹ssig; S. Klaiber; S. Lenk,Application-oriented quantum computing benchmark for an electromobility use case,2022,10.1109/QCE53715.2022.00105,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9951272,Conference Paper,2022 IEEE International Conference on Quantum Computing and Engineering (QCE),"The reduction of CO2 emissions is one of the major challenges in the current century. A game-changer might be quantum computing due to the proposed capabilities. A key field of interest for reducing CO2 emissions is the energy sector being transformed from fossil-based to be based on renewable energies and simultaneously combining electricity, heating, mobility, and manufacturing industries.Here, we study an use case for optimal charging scheduling of battery-electric service vehicles considering the requirements of their tasks, local solar power generation, and their battery capabilities to minimize power grid usage and so CO2 emissions from fossil-based electricity generation.The study compares benchmark results obtained classically with results obtained by the quantum approximate optimization algorithm (QAOA) to show the current capability of gate-based quantum optimization for a real-world use case. We present different formulations of the optimization problem and specific considerations for our use case necessary to yield optimal solutions reproducible with IBM¡¯s gate-based quantum computers. Here, we used Qiskit¡¯s built-in QAOA method but also self-made methods to examine the influence of the complexity of the problem formulation (penalty factors, landscape of cost function, etc.) as well as the dependence on parameters of the QAOA method (classical optimizer, result extraction, etc.). To obtain reliable results, we used different physical backends and simulations.Finally, we summarize or results and address future improvements for the used QAOA approach for automated real-world applications.",IEEE
K. Bertels; A. Sarkar; T. Hubregtsen; M. Serrao; A. A. Mouedenne; A. Yadav; A. Krol; I. Ashraf; C. G. Almudever,Quantum Computer Architecture Toward Full-Stack Quantum Accelerators,2020,10.1109/TQE.2020.2981074,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9076341,Journal,IEEE Transactions on Quantum Engineering,"This article presents the definition and implementation of a quantum computer architecture to enable creating a new computational device¡ªa quantum computer as an accelerator. A key question addressed is what such a quantum computer is and how it relates to the classical processor that controls the entire execution process. In this article, we present explicitly the idea of a quantum accelerator that contains the full stack of the layers of an accelerator. Such a stack starts at the highest level describing the target application of the accelerator. The next layer abstracts the quantum logic outlining the algorithm that is to be executed on the quantum accelerator. In our case, the logic is expressed in the universal quantum-classical hybrid computation language developed in the group, called OpenQL, which visualized the quantum processor as a computational accelerator. The OpenQL compiler translates the program to a common assembly language, called cQASM, which can be executed on a quantum simulator. The cQASM represents the instruction set that can be executed by the microarchitecture implemented in the quantum accelerator. In a subsequent step, the compiler can convert the cQASM to generate the eQASM, which is executable on a particular experimental device incorporating the platform-specific parameters. This way, we are able to distinguish clearly the experimental research toward better qubits, and the industrial and societal applications that need to be developed and executed on a quantum device. The first case offers experimental physicists with a full-stack experimental platform using realistic qubits with decoherence and error-rates, whereas the second case offers perfect qubits to the quantum application developer, where there is neither decoherence nor error-rates. We conclude the article by explicitly presenting three examples of full-stack quantum accelerators, for an experimental superconducting processor, for quantum accelerated genome sequencing and for near-term generic optimization problems based on quantum heuristic approaches. The two later full-stack models are currently being actively researched in our group.",IEEE
W. -L. Wang; S. Hussain; N. V. Rondinelli; M. -H. Tang; S. U. Rehman Khan,Recursive Generation of Multi-Qubits Control Gate to Facilitate the Grover's Quantum Algorithm in Large Scale Database Search,2024,10.1109/QRS-C63300.2024.00108,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10727063,Conference Paper,"2024 IEEE 24th International Conference on Software Quality, Reliability, and Security Companion (QRS-C)","Context: Grover's algorithm is a powerful tool in the realm of quantum computing because it offers exponential speedup over classical linear searching for unstructured / unsorted search problems. However, it is challenging to construct efficient and scalable circuits for a multi-input control gate in the algorithm, particularly with a huge number of qubit inputs. Problem: Traditional circuit construction methods often require manual composition for the multi-input gate from basic quantum gates, which can be time consuming and error prone, thus hindering practical implementation. Moreover, the number of simple gates in the composition grows exponentially with the addition of each qubit. Method: This research provides an approach to recursively generate the oracle using Toffoli gates as the fundamental units to enhance scalability and reusability while maintaining effectiveness. The methodology leverages IBM Qiskit and Quantum Lab to simulate quantum computation to prove the practicality and feasibility. Result: The findings from the experiments between recursively and non-recursively generated circuits suggest that our recursive approach can offer comparable accuracy and computational complexity compared to the non-recursive approach. However, it tends to require a larger number of basic quantum gates due to a lack of circuit optimization. Conclusion: The results showcase the applicability of utilizing recursion as a speedy and economical alternative to generate circuits when implementing the Grover's algorithm. It not only presents potential scalability benefits, but also creates an avenue for further research on test verification and performance improvement to the computing community when running in actual quantum hardware.",IEEE
Z. Liu; S. Li,A quantum krill herd algorithm based chance constrained programming for surfactant flooding,2020,10.1109/CCDC49329.2020.9164783,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9164783,Conference Paper,2020 Chinese Control And Decision Conference (CCDC),"This paper presents a chance constrained programming (CCP) based on quantum krill herd algorithm (QKH) to solve an engineering optimization for surfactant flooding in oil development. First, an optimal control model describing surfactant flooding mechanism is established. In this model, the fluctuant oil price is the uncertainty needs to be addressed, the injection concentration of surfactant is the control variable and the net present value is the objective function. The chance constrained programming (CCP) is adopted to transform the uncertain model into a deterministic nonlinear programming model. Then a quantum krill herd algorithm (QKH) is presented to solve the model. Compared with the standard krill herd algorithm (KH), QKH has a superior global searching ability and computational efficiency owing to the quantum representation. At last, an actual optimization model for surfactant flooding is solved by the proposed method and the optimal injection strategy is obtained.",IEEE
R. Subramanian; S. Ranganathan; V. Ramasamy,"Gateway to Ocean Data Management: Ocean Best Practices, Information and Visualisation for moored ocean observation network",2022,10.1109/OCEANSChennai45887.2022.9775375,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9775375,Conference Paper,OCEANS 2022 - Chennai,"Oceans continuously interact with the overlying atmosphere, which dynamically varies and significantly impacts the weather and climate. The data over the oceans is complex and time series observations are vital. The knowledge we acquire from the data collected will help us to manage in oceans long term. Recent developments in ocean observation platforms and the advancements in sensor technologies have paved the way for modern and reliable deep sea instrumented buoy systems that offer most suitable and dependable platforms for uninterrupted data collection and transmission of the data in real-time to the shore through satellite communication networks. Ocean Observation Systems, an operational programme of National Institute of Ocean Technology, Chennai, under Ministry of Earth Sciences, Govt. of India has been deploying and maintaining moored data buoys in Indian waters since 1997. The data, received in compressed numerical data packets, takes a reasonable amount of time to decipher, infer and uncover some of the potentially valuable information it contains. Hence, validation and analysis of the data for making decisions during natural hazards has become colossal and relatively complicated. The challenge is to develop a rugged mechanism the harnessing information technology to generate the information required for ocean sustenance, which warrants partnering with Information Technology. To modern societies, digital communications and information technologies have become fundamental and referred as ""connected society.""Scientific community expect data to accurately represent the phenomenon that was measured. The data collected over prolonged periods are of immense use for scientists, to carry out scientific analyses, and frame strategic policies. Today, precise electronics and high-performance computers have altered our expectations of scientific data management, much as it has altered the expectations for many other elements of society and we find portentous agreement with improved data management strategies. CORNEA ¨C Centre for Ocean Realtime iNformation viEw and Archives is a high-end IT infrastructure built with computational and visual capabilities to bring significant benefits to ocean researchers. Large quantum of data received from buoys contain information about various parameters such as meteorlogical, oceanographic (surface and subsurface). Mining them for predictive analysis and tracking the history of sensors is a challenge. This stresses the need for automated mechanism to collage the information and present it on demand, minimizing the challenges faced retrieving the same through manual means. ADDRESS (ADvanced Data REception and AnalysiS System) is a software tool developed for visualization within the context of data and information, heuristic way of interpretation, analysis, automated quality control, reliable data reception and dissemination using modern software technologies, which are the linchpin to a successful Ocean Observation Programme driven in the Information Technology era. Further, the buoy data is disseminated to the global community through Global Telecommunication Systems (GTS). The data and metadata from Indian buoy programme is acclaimed by the global scientific community. Ocean Best Practices methodology recognized by ""International Oceanographic Data and Information Exchange"" (IODE) of the Intergovernmental Oceanographic Commission (IOC) - UNESCO, is adopted to achieve quality and consistency in observation.Data from Indian buoy programme is also portrayed in OceanOPS (formerly JCOMMOPS), the agency that establishes a common platform, coordinates within and amongst ocean observation communities across the globe. Apart from regional, data from collaborative projects such as OMNI-RAMA are exhibited through interactive webportals with wealth of data and information to the scientific community blending international efforts.The culmination of this paper reveals how technology, confined is standards and best practices deployed, transform the way the ocean data is accessed, utilized, augmented, and transformed into information and knowledge.",IEEE
E. E. Moghaddam; H. Beyranvand; J. A. Salehi,Resource Allocation in Space Division Multiplexed Elastic Optical Networks Secured With Quantum Key Distribution,2021,10.1109/JSAC.2021.3064641,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9373587,Journal,IEEE Journal on Selected Areas in Communications,"Elastic Optical Network (EON) is a promising solution to address the high capacity, low latency, and flexibility requirements of the upcoming 5th-generation (5G) networks. Furthermore, Multi-Core Fibers (MCFs) and Space Division Multiplexing (SDM) technique can be utilized to overcome the capacity limitation of the conventional Single Mode Fibers (SMFs). On the other hand, Quantum Key Distribution (QKD) is an effective solution to address the security issues in 5G transport networks. In this paper, we investigate the performance of QKD over elastic optical networks with multi-core fibers and address the resource allocation problem for quantum and classical channels of QKD (QChs and CChs) and conventional data channels (DChs). To do so, we calculate the background noise caused by different noise sources and accordingly calculate the Secret Key Rate (SKR) in quantum channels. Then, we propose an Integer Linear Programming formulation and a heuristic algorithm to allocate network resources (spectrum, core, and links) to QChs, CChs, and DChs, with the objective of maximizing the secret key rate and minimizing the number of utilized frequency slots (FSs). Finally, we evaluate the proposed ILP and heuristic algorithm in terms of SKR and the number of utilized FSs. In our simulations, we consider core and metro topologies, fixed and distance adaptive launch power for classical signals, different fiber specifications, and different assumptions regarding the relative locations of quantum and classical channels in a multi-core fiber.",IEEE
A. Awad; A. Hawash; B. Abdalhaq,A Genetic Algorithm (GA) and Swarm-Based Binary Decision Diagram (BDD) Reordering Optimizer Reinforced With Recent Operators,2023,10.1109/TEVC.2022.3170212,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9762787,Journal,IEEE Transactions on Evolutionary Computation,"The use of binary decision diagrams (BDDs) has proliferated in numerous fields. When a system criterion is formulated in form of a Boolean function, its BDD is constructed. Each node in the BDD is further mapped into another form to be exploited in the system analysis. However, the cost of the resultant mapping form is directly related to the BDD size which can be effectively reduced through applying proper variable reordering followed by applying reduction rules that preserve the fidelity of the BDD in correctly representing the input Boolean function. Although several algorithms have been proposed in the literature to find the optimal order of variables in the BDD, the scalability of such algorithms is a serious barrier when it comes to complex systems with exponential explosion in the possible number of orders in the search space. Furthermore, solely exploring the search space in BDD reordering is not sufficient since better permutations might be obtained with slight tuning of the candidate solutions. Thus, a sufficient degree of equilibrium between exploration and exploitation should be preserved during the evolution of the reordering algorithm. In this article, we propose a BDD optimizer driven by either genetic algorithm (GA) or swarm engines. The proposed GA-based BDD reordering optimizer iteratively processes an essentially large population with a randomized mixing of low destructive crossover/mutation operators. The proposed swarm-based optimizer, on the other hand, maps a vector of real numbers into a permutation to further construct its companion BDD. The generation of the next vector is guided by recent parameter and parameter-less swarm algorithms that are armed with effective mechanisms to simultaneously conduct exploration and exploitation. Experimental results show that our proposed optimizer effectively reduces the resultant BDD size for input Boolean functions with almost linear computational complexity. Furthermore, it has been found that exploiting recent swarm optimizers with spiral movement in BDD reordering problem can outperform GA for large scale Boolean functions. Finally, as a real-world application, our proposed algorithm is applied to reversible logic synthesis to show the achieved reduction in the quantum cost (QC) associated with BDD-based synthesis.",IEEE
Z. Hu; M. Zhou; Y. Ma; J. Wang; Z. Yin; B. D. Gerardot,Entangled Quantum Imaging Method Based on Two-step Adaptive Sampling Optimization,2025,10.1109/JSTQE.2025.3527018,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10833681,Article,IEEE Journal of Selected Topics in Quantum Electronics,"In recent years, quantum information technology, as a subversive and strategic technology that has attracted much attention, acquires, transmits, and processes information by means of unique physical phenomena such as quantum entanglement, nonlocality, and non-cloning. Quantum imaging technology achieves non-local imaging of targets by extracting entangled light quantum information with temporal and spatial correlation characteristics. By using the anti-interference and anti-turbulence characteristics of quantum entangled states, quantum imaging technology can break through the physical limits of traditional imaging fields, thereby improving imaging resolution and sensitivity. The latest technological development in quantum imaging has prompted researchers to study high-resolution and fast quantum imaging based on the spatial correlation characteristics of entangled photon pairs. In this circumstance, we propose a novel quantum imaging method based on two-step adaptive sampling optimization and carry out experimental verification. In concrete terms, in order to solve the problem that the efficiency of entangled light quantum imaging is limited by Digital Micromirror Device (DMD) sampling, we select the two-step adaptive sampling optimization algorithm to reduce the influence of DMD scanning on imaging efficiency. At the same time, for the sake of solving the problem that the quality of entangled photon quantum imaging is limited by the accuracy of coincidence counting, we add delay difference calculation in the imaging process and correct the signal photon arrival time pulse sequence to ensure the accuracy of coincidence counting. Finally, we conduct a large number of experiments to evaluate the performance of the two-step adaptive sampling optimization algorithm and verify the superiority of the proposed entangled quantum imaging method practically.",IEEE
W. Qiao; Z. Yang,Solving Large-Scale Function Optimization Problem by Using a New Metaheuristic Algorithm Based on Quantum Dolphin Swarm Algorithm,2019,10.1109/ACCESS.2019.2942169,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8843967,Journal,IEEE Access,"Meta-heuristic algorithm has been a research hotspot in solving the optimal solution of large-scale functions. However, meta-heuristic algorithms are prone to fall into local optimum problems, such as the recently proposed dolphin swarm algorithm (DSA). To solve this problem, in this study, the quantum search algorithm is introduced into DSA. In addition, to test the performance of the proposed quantum dolphin swarm algorithm (QDSA), six commonly used large-scale functions (e.g. Rotated hyper-ellipsoid function) are taken as examples. Furthermore, some advanced algorithms (e.g. whale optimization algorithm (WOA)) are used for comparison. The results show that the ability of QDSA to obtain global optimal solution is obviously improved compared with DSA, and the performance of QDSA is superior to other algorithms considered for comparison. Finally, it can be concluded that such a novel meta-heuristic algorithm may help to improve the problem of solving the optimal solution of large-scale functions.",IEEE
P. Demetriou; C. J. Haupt; K. J. Nixon,A Quantum Variational Approach to Debugging Combinational Logic Circuits,2021,10.1109/ISVLSI51109.2021.00083,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9516796,Conference Paper,2021 IEEE Computer Society Annual Symposium on VLSI (ISVLSI),"The application of a quantum approach to combinational logic circuit debugging for future use in Very Large-Scale Integration system design is presented. Although previous work in this area has sped up debugging solutions through the use of satisfiability solvers, the solutions remain classically intractable for large systems. Additionally, whilst many quantum algorithms have shown promise in solving classically intractable problems, there have been few domain-specific implementations, particularly where hard and soft constraints exist and multiple solutions are required. A Quantum Alternating Operator Ansatz is applied to a reduction of the satisfiability problem into a maximum independent set problem. While the Quantum Alternating Operator Ansatz approach constrains the optimization to feasible solutions, the resulting ansatz is both too large for current Noisy Intermediate-Scale Quantum devices and to simulate using a Hamiltonian formulation with gradient-based optimisers. Therefore, a circuit driven simulation is preferred. A small example of a debugging problem is simulated using the aforementioned approach.",IEEE
H. J. Waring,Distributing Compilation to Enable High Throughput Scalable Quantum Workloads,2024,10.1109/QCE60285.2024.10406,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10821132,Conference Paper,2024 IEEE International Conference on Quantum Computing and Engineering (QCE),"The increasing quality and availability of Quantum Processing Units (QPUs) is fueling a growing interest in quan-tum computing across many technological areas. The resulting increase in demand for QPU resources necessitates Quantum Computing as a Service (QCaaS) providers to support a high throughput of quantum workloads. A major runtime bottleneck in current QCaaS software stacks is the computationally-intensive compilation step which requires significant compute. To address this, Oxford Quantum Circuits has introduced distributed compilation whereby quantum programs are com-piled in parallel and stored until the QPU is available. This has replaced our previous serial compilation approach where each program was compiled immediately prior to execution. From experiments using our production compilers and a simulated backend representing the QPU, we show that distributed com-pilation has resulted in a 78 % reduction in processing time as compared to serial compilation. This demonstrates that there are sizeable performance gains to program throughput attainable through the introduction of distributed compilation into a QCaaS architecture. We posit that the usefulness of this feature will only grow given the increasing complexity of quantum programs and the growing popularity of quantum-classical hybrid algorithms.",IEEE
M. A. Shafique; A. Munir; I. Latif,"Quantum Computing: Circuits, Algorithms, and Applications",2024,10.1109/ACCESS.2024.3362955,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10423012,Journal,IEEE Access,"Quantum computing, a transformative field that emerged from quantum mechanics and computer science, has gained immense attention for its potential to revolutionize computation. This paper aims to address the fundamentals of quantum computing and provide a comprehensive guide for both novices and experts in the field of quantum computing. Beginning with the foundational principles of quantum computing, we introduce readers to the fundamental concepts of qubits, superposition, entanglement, interference, and noise. We explore quantum hardware, quantum gates, and basic quantum circuits. This study offers insight into the current phase of quantum computing, including the noisy intermediate-scale quantum (NISQ) era and its potential for solving real-world problems. Furthermore, we discuss the development of quantum algorithms and their applications, with a focus on famous algorithms like Shor¡¯s algorithm and Grover¡¯s algorithm. We also touch upon quantum computing¡¯s impact on various industries, such as cryptography, optimization, machine learning, and material science. By the end of this paper, readers will have a solid understanding of quantum computing¡¯s principles, applications, and the steps involved in developing quantum circuits. Our goal is to provide a valuable resource for those eager to embark on their quantum computing journey and for researchers looking to stay updated on this rapidly evolving field.",IEEE
T. Tanimoto; S. Matsuo; S. Kawakami; Y. Tabuchi; M. Hirokawa; K. Inoue,Practical Error Modeling Toward Realistic NISQ Simulation,2020,10.1109/ISVLSI49217.2020.00060,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9155029,Conference Paper,2020 IEEE Computer Society Annual Symposium on VLSI (ISVLSI),"In quantum computing, research and development of devices, architecture, optimization techniques, algorithms, and applications are evolving with eagerness in parallel. To make these work mutually beneficial, practical and accurate quantum computer simulators as system-wide design frameworks are necessary. In this paper, we focus on measurement and initialization errors of qubits. These errors are inevitable because these procedures are interfaces between classical and quantum information processing. We model the quantum non-demolition detection technique as measurement and initialization methods and implement them on Intel-QS, a high-performance quantum simulator. Our case study with quantum Fourier transform on 8 qubits configuration demonstrates the importance of taking these errors into account. That is, post-selection, which improves the initialization fidelity, can enlarge the gap between the theoretical result and incorrect outputs by 3.35 times.",IEEE
W. Xuan; Z. Zhao; L. Fan; Z. Han,Minimizing Delay in Network Function Visualization with Quantum Computing,2021,10.1109/MASS52906.2021.00022,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9637726,Conference Paper,2021 IEEE 18th International Conference on Mobile Ad Hoc and Smart Systems (MASS),"Network function virtualization (NFV) is a crucial technology for the 5G network development because it can improve the flexibility of employing hardware and reduce the construction of base stations. There are vast service chains in NFV to meet users¡¯ requests, which are composed of a sequence of network functions. These virtual network functions (VNFs) are implemented in virtual machines by software and virtual environment. How to deploy VMs to process VNFs of the service chains as soon as possible when users¡¯ requests are received is very challenging to solve by traditional algorithms on a large scale. Compared with traditional algorithms, quantum computing has better computational performance because of quantum parallelism. We build an integer linear programming model of the VNF scheduling problem with the objective of minimizing delays, and transfer it into the quadratic unconstrained binary optimization (QUBO) model. Our proposed heuristic algorithm employs a quantum annealer to solve the model. Finally, we evaluate the computational results and explore the feasibility of leveraging quantum computing to solve the VNF scheduling problem.",IEEE
E. Chamma; A. McGee; A. Gillmann; I. McNallan; M. Mahmoud,Feasible Applications of Quantum Computing in Varying Fields,2023,10.1109/CSCI62032.2023.00080,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10590379,Conference Paper,2023 International Conference on Computational Science and Computational Intelligence (CSCI),"This paper explores the potential impact of quantum computing in several fields, including medicine, finance, cybersecurity, cryptography, high-performance computing and hacking. Quantum computing has the potential to revolutionize these fields by providing significant advancements in processing power, enabling the development of new algorithms and computing methods that were previously impossible with classical computing. The paper explores the potential risks of quantum computing in the context of hacking, as quantum computers can potentially break through existing security systems and create new threats to privacy and security. Quantum computing has the potential to break through current encryption methods and develop new, more secure encryption techniques. High-performance computing can benefit from quantum computing through faster simulations and optimization of complex systems. In the field of medicine, quantum computing can be used to accelerate drug discovery and personalize medicine by simulating molecular interactions at the atomic level. Finally, in finance, quantum computing can be utilized for portfolio optimization, risk management, and algorithmic trading. This paper concludes that quantum computing has immense potential for improving various fields, but it is important to consider the associated risks and challenges. Moreover, there is a need for further research and development in areas such as post-quantum cryptography, algorithm development and cybersecurity. The potential of quantum computing and its intersection with other technologies highlight the long path towards classical computing's maturation.",IEEE
J. M. Rivas-Moscoso; A. Melgar; L. Pot¨¬; K. Krilakis; L. Velasco; S. Bahrani; M. S. Moreolo; I. T. Monroy; P. Nguyen; M. Ruiz; D. K. Syvridis; A. Mandilara; A. Pagano; J. Morales; A. Pastor; R. Nejabati; R. Wang; P. N. Goki; A. S¨¢nchez-Maci¨¢n; S. Civelli; S. Rommel; C. R. Garc¨ªa; M. Iqbal; R. Oliveira; J. C. Hern¨¢ndez-Hern¨¢ndez; D. Larrabeiti; J. Folgueira,"A Security Plane Architecture for Ultra-Low-Energy, High-Capacity Optical Transport Networks",2024,10.1109/QCNC62729.2024.00044,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10628339,Conference Paper,"2024 International Conference on Quantum Communications, Networking, and Computing (QCNC)","The evolution toward agile, ultra-low-energy, high-capacity optical transport networks can benefit from solutions incorporating multi-band, multi-fiber, and point-to-multipoint (P2MP)/sliceable high-capacity transport technologies carefully designed to simplify network hierarchy and minimize optical-electrical-optical (OED) conversions. To guarantee quantum-secure communications, these networks require a thorough reassessment of their security plane architecture, acting as a transversal plane to the data and control planes. In this paper, we propose a programmable Quantum Key Distribution (QKD) network built upon multi-protocol QKD systems, including entangled QKD for P2MP secure access/metro scenarios, Quantum Random Key Generation (QRNG) modules as alternative entropy sources for links where QKD system deployment is not economically viable, and hybrid classic/QKD/Post-Quantum Cryptography (PQC) primitives for greater flexibility and backward compatibility. Authentication services are performed through physically-unclonable-function (PUF) certification authorities, particularly implementing strong Rayleigh-backscattering-pattern or speckle-pattern-based optical Physically Unclonable Functions (OP-UFs). These security technologies leverage on agnostic key management system (KMS) and quantum digital twin (QDT) assisted performance optimization, e.g. for artificial intelligence (AI)-based State of Polarization (SOP) compensation. Key relay between border nodes is realized by means of a combination of a centralized PUF and a procedure to securely exchange keys between KMSs based on ETSI-014 and PQC. The KMS can feed keys to encryptors implemented at the different data-plane layers, but the proposed architecture favors encryption relying on physical-layer security techniques to align with the above design principle aimed at a flatter network and fewer OEO conversions. Examples of this are Light Path SECurity (LPSec) techniques, consisting of two nested physical ciphers ensuring a high-security level, and all-optical steganography. Coexistence of classical and quantum signals is generally feasible in the access and metro segments, whereas in the backbone segment it needs to be evaluated on a case-by-case basis.",IEEE
J. Giraldo; J. Ossorio; N. M. Villegas; G. Tamura; U. Stege,QPLEX: Realizing the Integration of Quantum Computing into Combinatorial Optimization Software,2023,10.1109/QCE57702.2023.00118,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10313812,Conference Paper,2023 IEEE International Conference on Quantum Computing and Engineering (QCE),"Quantum computing has the potential to surpass the capabilities of current classical computers when solving complex problems. Combinatorial optimization has emerged as one of the key target areas for quantum computers as problems found in this field play a critical role in many different industrial application sectors (e.g., enhancing manufacturing operations or improving decision processes). Currently, there are different types of high-performance optimization software (e.g., ILOG CPLEX and Gurobi) that support engineers and scientists in solving optimization problems using classical computers. In order to utilize quantum resources, users require domain-specific knowledge of quantum algorithms, SDKs and libraries, which can be a limiting factor for any practitioner who wants to integrate this technology into their workflows. Our goal is to add software infrastructure to a classical optimization package so that application developers can interface with quantum platforms readily when setting up their workflows. This paper presents a tool for the seamless utilization of quantum resources through a classical interface. Our approach consists of a Python library extension that provides a backend to facilitate access to multiple quantum providers. Our pipeline enables optimization software developers to experiment with quantum resources selectively and assess performance improvements of hybrid quantum-classical optimization solutions.",IEEE
T. Schmale; B. Temesi; N. Trittschanke; N. Pulido-Mateo; I. Elenskiy; L. Krinner; T. Dubielzig; C. Ospelkaus; H. Weimer; D. Borcherding,Real-time hybrid quantum-classical computations for trapped ions with Python control-flow,2023,10.1109/QSW59989.2023.00031,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10234276,Conference Paper,2023 IEEE International Conference on Quantum Software (QSW),"In recent years, the number of hybrid algorithms that combine quantum and classical computations has been continuously increasing. These two approaches to computing can mutually enhance each others¡¯ performances thus bringing the promise of more advanced algorithms that can outmatch their pure counterparts. In order to accommodate this new class of codes, a proper environment has to be created, which enables the interplay between the quantum and classical hardware.For many of these hybrid processes the coherence time of the quantum computer arises as a natural time constraint, making it crucial to minimize the classical overhead. For ion-trap quantum computers however, this is a much less limiting factor than with superconducting technologies, since the relevant timescale is on the order of seconds instead of microseconds. In fact, we show that the operating time-scales of trapped-ion quantum computers are compatible with the execution speed of the Python programming language, enabling us to develop an interpreted scheme for real-time control of quantum computations. In particular, compilation of all instructions in advance is not necessary, unlike with superconducting qubits. This keeps the implementation of hybrid algorithms simple and also lets users benefit from the rich environment of existing Python libraries.In order to show that this approach of interpreted quantum-classical computations (IQCC) is feasible, we bring real-world examples and evaluate them in realistic benchmarks.",IEEE
X. Yan; R. Ma,Research on Fault Prediction Method of Analog Circuits Based on DCQGA-SVR,2019,10.1109/ICICM48536.2019.8977201,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8977201,Conference Paper,2019 IEEE 4th International Conference on Integrated Circuits and Microsystems (ICICM),"Aiming at the shortcomings of analog circuit fault prediction technology, the DCQGA-SVR analog circuit fault prediction method is proposed. Firstly, the failure mechanism of electrolytic capacitor and power MOSFET in analog circuit is analyzed. The fault parameters that can be used to reflect circuit fault, map electrolytic capacitor and power MOSFET are researched. The average output power is extracted as the characteristic parameter of circuit fault. Secondly, the double-chain quantum genetic algorithm is used to optimize the support vector machine regression algorithm to predict the fault feature parameters, and then the fault prediction model is established. Finally, the Boost circuit is used as the simulation test circuit, and compared with the traditional QGA-SVR algorithm and LS-SVM algorithm. The results show that the proposed prediction method has small mean square error and can effectively predict the fault.",IEEE
D. Namakshenas; A. Yazdinejad; A. Dehghantanha; G. Srivastava,Federated Quantum-Based Privacy-Preserving Threat Detection Model for Consumer Internet of Things,2024,10.1109/TCE.2024.3377550,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10472634,Journal,IEEE Transactions on Consumer Electronics,"The Internet of Things (IoT) has significantly impacted the evolution of consumer-oriented smart environments, primarily due to its capacity for transformative device-to-device communication. While this capability enhances user convenience and experience in the Consumer IoT sector, it also generates vast amounts of data. While beneficial for consumer insight and electronic optimization, this data is vulnerable to security breaches. We focus on Machine Learning-based threat detection systems to address these challenges within Consumer IoT. While effective in recognizing threats, these systems often overlook crucial privacy considerations, a critical aspect in the realm of consumer devices. To counter this, Federated Learning (FL) emerges as a promising solution for maintaining data privacy in Consumer IoT. However, FL faces its own challenges, especially when dealing with malicious clients. This paper addresses two primary challenges in Consumer IoT threat detection. First, we tackle an unaddressed issue in FL: the rigorous validation of its clients. The advent of quantum computing could render traditional validation techniques obsolete. We introduce a quantum-centric registration and authentication strategy to overcome this, ensuring stringent client validation in an FL framework. The second challenge involves protecting clients¡¯ model weights within FL. We propose the integration of Additive Homomorphic Encryption into our model, offering a robust solution that secures the privacy of FL participants without compromising on computational efficiency. Our empirical results underscore the efficacy of our approach, achieving an average accuracy of 94.93% on the N-baIoT dataset and 91.93% on the Edge-IIoTset dataset, showcasing consistent and robust performance across diverse client configurations. This approach can potentially significantly improve the security and privacy landscape of Consumer IoT.",IEEE
Y. Liu; C. Li; J. Xiao; Z. Li; W. Chen; X. Qu; J. Zhou,QEGWO: Energy-Efficient Clustering Approach for Industrial Wireless Sensor Networks Using Quantum-Related Bioinspired Optimization,2022,10.1109/JIOT.2022.3189807,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9825738,Journal,IEEE Internet of Things Journal,"Compared with conventional wireless sensor networks (WSNs), industrial WSNs (IWSNs) have stricter requirements in real-time data transmission, energy consumption, and energy uniformity. To fulfill these requirements, a new energy-efficient clustering approach using quantum-related bioinspired optimization, i.e., quantum elite gray wolf optimization (QEGWO), is proposed to improve the performance of IWSNs. Innovatively, a new quantum operator, including quantum probability amplitude, quantum rotation gate, and quantum NOT gate, is designed in QEGWO to enhance its global search capability. This quantum operator need not query the quantum rotation angle table in updating quantum probability amplitude with the quantum rotation gate, which reduces the computational complexity of introducing quantum optimization into the clustering problem of IWSNs. Moreover, to enhance the convergence performance of the clustering algorithm, a multielite strategy is proposed to preserve the historical optimal individuals generated in the iterative process by establishing a dynamic elite pool. Compared with the state-of-the-art clustering approaches, extensive simulations in four different scenarios are carried out, and the results demonstrate that the proposed QEGWO outperforms other comparison approaches in delay, energy consumption, and energy uniformity.",IEEE
V. Uotila,Quantum Natural Language Processing Application for Estimating SQL Query Metrics,2024,10.1109/QCE60285.2024.10321,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10821070,Conference Paper,2024 IEEE International Conference on Quantum Computing and Engineering (QCE),"Quantum Natural Language Processing (QNLP) is built on a novel, category theoretical quantum machine learning model, which we use to solve a well-researched problem in the database field: estimating metrics for SQL queries. The metrics we focus on are latency (i.e., the execution time), cost (i.e., a value of how expensive the query is in total), and cardinality (i.e., the number of rows in the result table). The critical link between QNLP and the database problem lies in using grammars, such as context-free grammar. Both natural language and SQL queries admit grammatical presentations, which allow us to develop a comprehensive framework for applying QNLP methods to solve the query estimation problem. The model comprises an encoding mechanism and a training phase, integrating classical and quantum subroutines. The encoding mechanism transforms SQL queries into parametrized quantum circuits as in QNLP. Classical optimization algorithms optimize the circuit parameters during training to predict query metrics. Comparing our model to the QNLP models, our model achieves accuracy comparable to the QNLP model in binary classification tasks. Additionally, we expand upon previous research by implementing multi-class classification tasks and comparing the cardinality estimation results to those of state-of-the-art databases. Our theoretical analysis of the quantum machine learning model includes calculations of its expressibility and entangling capabilities. The analysis reveals that the model possesses beneficial properties, making it suitable to be executed on near-term quantum hardware.",IEEE
R. Wille; L. Berent; T. Forster; J. Kunasaikaran; K. Mato; T. Peham; N. Quetschlich; D. Rovara; A. Sander; L. Schmid; D. Sch?nberger; Y. Stade; L. Burgholzer,The MQT Handbook : A Summary of Design Automation Tools and Software for Quantum Computing,2024,10.1109/QSW62656.2024.00013,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10646543,Conference Paper,2024 IEEE International Conference on Quantum Software (QSW),"Quantum computers are becoming a reality and numerous quantum computing applications with a near-term perspective (e.g., for finance, chemistry, machine learning, and optimization) and with a long-term perspective (e.g., for cryptography or unstructured search) are currently being investigated. However, designing and realizing potential applications for these devices in a scalable fashion requires automated, efficient, and user-friendly software tools that cater to the needs of end users, engineers, and physicists at every level of the entire quantum software stack. Many of the problems to be tackled in that regard are similar to design problems from the classical realm for which sophisticated design automation tools have been developed in the previous decades.The Munich Quantum Toolkit (MQT) is a collection of software tools for quantum computing developed by the Chair for Design Automation at the Technical University of Munich which explicitly utilizes this design automation expertise. Our overarching objective is to provide solutions for design tasks across the entire quantum software stack. This entails high-level support for end users in realizing their applications, efficient methods for the classical simulation, compilation, and verification of quantum circuits, tools for quantum error correction, support for physical design, and more. These methods are supported by corresponding data structures (such as decision diagrams or the ZX-calculus) and core methods (such as SAT encodings/solvers). All of the developed tools are available as open-source implementations and are hosted on github.com/cda-tum.Note: A live version of this document is available at mqt.readthedocs.io.",IEEE
A. Nurhayati; A. G. Darmoyono,A Comparison of Hybrid Methods of the Krill Herd Algorithm,2018,10.1109/INCAE.2018.8579364,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8579364,Conference Paper,2018 International Conference on Applied Engineering (ICAE),"Krill herd algorithm is motivated by the movement of krill herd in the sea. It is a heuristic search method for finding global optimum value. This paper presents a comparison between a mix Krill Herd Quantum Particle Swarm Optimization (KHQPSO) algorithm, a Biogeography Krill Herd (BKH) algorithm and Harmony Search Krill Herd (HSKH) algorithm as a combination of Krill Herd algorithm. The results of the study prove that BKH has better performance than KHQPSO and HSKH algorithm for solving standard test functions.",IEEE
L. Xu; S. Zhao; N. Li; Q. Gao; T. Wang; W. Xue,Application of QGA-BP for Fault Detection of Liquid Rocket Engines,2019,10.1109/TAES.2018.2890352,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8610386,Journal,IEEE Transactions on Aerospace and Electronic Systems,"In order to overcome the shortcomings of traditional back propagation (BP) and single genetic algorithm (GA), a method based on quantum GA (QGA) is proposed to optimize the BP neural network for fault detection of liquid rocket engines. In this QGA-BP method, a dynamic improvement strategy is adopted to adjust the rotation angle according to the evolution situation, and a quantum catastrophe strategy is used as an operation criterion during evolution. Then, the improved QGA is used to optimize the weight and threshold of the BP neural network from multiple spots. This method is applied to a typical fault detection process of a liquid rocket engine. Representative history test data of engine state is used to verify this method, and the results show that the convergence speed, the evolution generation, and the accuracy of fault detection of the QGA-BP model are all improved compared with the traditional BP neural network and the single GA.",IEEE
C. Lu; U. Banerjee; K. Basu,Design and Analysis of a Scalable and Efficient Quantum Circuit for LWE Matrix Arithmetic,2022,10.1109/ICCD56317.2022.00026,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9978441,Conference Paper,2022 IEEE 40th International Conference on Computer Design (ICCD),"Quantum computing furnishes exponential speed up over classical computing in specific areas. For example, Shor¡¯s algorithm can factor two numbers in a polynomial time complexity. Thus, many encryption algorithms that rely on large number factorization are potentially vulnerable to quantum computers. In order to address this, the National Institute of Standard and Test (NIST) has organized a competition to evaluate several post quantum cryptography (PQC) algorithms, that are secure from the attacks from quantum computers. Several of these lattice-based PQC encryption algorithms are based on Learning With Errors (LWE) computation. Conversely, LWE is the heaviest computation in a classical computer, which incurs significant portion of the latency overhead for the entire encryption algorithm. In this paper, we design an optimized quantum circuit for LWE computation. The proposed quantum circuit does not need any ancillary qubits and scales efficiently and easily if there are more qubits available on a higher qubit quantum computer.",IEEE
J. Zhou; Z. Tian; Z. Li; C. Huang,Low-Complexity Parameter Estimation Algorithm Based on Two-Stage QPSO-OMP,2023,10.1109/APMC57107.2023.10439948,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10439948,Conference Paper,2023 Asia-Pacific Microwave Conference (APMC),"Single access point (AP) localization techniques are commonly used due to their cost-effectiveness and the absence of time synchronization requirements across multiple APs. However, these techniques involve the estimation of multiple parameters, which can lead to challenges such as increased time consumption and storage requirements. To overcome these challenges, this paper presents a two-stage quantum particle swarm optimization-orthogonal matching search (QPSO-OMP) algorithm. In the first stage, the OMP algorithm is employed to obtain a rough parameter range and effectively narrow down the search space. This helps reduce the computational burden and storage pressure on the device. In the second stage, the QPSO algorithm is utilized to perform accurate parameter estimation, further improving the efficiency of the localization process. Through simulation experiments, it has been demonstrated that the proposed algorithm offers a significant reduction in time complexity while maintaining a comparable level of localization effectiveness.",IEEE
T. Q. Duong; J. A. Ansere; B. Narottama; V. Sharma; O. A. Dobre; H. Shin,"Quantum-Inspired Machine Learning for 6G: Fundamentals, Security, Resource Allocations, Challenges, and Future Research Directions",2022,10.1109/OJVT.2022.3202876,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9870532,Journal,IEEE Open Journal of Vehicular Technology,"Quantum computing is envisaged as an evolving paradigm for solving computationally complex optimization problems with a large-number factorization and exhaustive search. Recently, there has been a proliferating growth of the size of multi-dimensional datasets, the input-output space dimensionality, and data structures. Hence, the conventional machine learning approaches in data training and processing have exhibited their limited computing capabilities to support the sixth-generation (6G) networks with highly dynamic applications and services. In this regard, the fast developing quantum computing with machine learning for 6G networks is investigated. Quantum machine learning algorithm can significantly enhance the processing efficiency and exponentially computational speed-up for effective quantum data representation and superposition framework, highly capable of guaranteeing high data storage and secured communications. We present the state-of-the-art in quantum computing and provide a comprehensive overview of its potential, via machine learning approaches. Furthermore, we introduce quantum-inspired machine learning applications for 6G networks in terms of resource allocation and network security, considering their enabling technologies and potential challenges. Finally, some dominating research issues and future research directions for the quantum-inspired machine learning in 6G networks are elaborated.",IEEE
B. Poggel; N. Quetschlich; L. Burgholzer; R. Wille; J. M. Lorenz,Recommending Solution Paths for Solving Optimization Problems with Quantum Computing,2023,10.1109/QSW59989.2023.00017,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10234262,Conference Paper,2023 IEEE International Conference on Quantum Software (QSW),"Solving real-world optimization problems with quantum computing requires choosing between a large number of options concerning formulation, encoding, algorithm and hardware. Finding good solution paths is challenging for end users and researchers alike. We propose a framework designed to identify and recommend the best-suited solution paths in an automated way. This introduces a novel abstraction layer that is required to make quantum-computing-assisted solution techniques accessible to end users without requiring a deeper knowledge of quantum technologies. State-of-the-art hybrid algorithms, encoding and decomposition techniques can be integrated in a modular manner and evaluated using problem-specific performance metrics. Equally, tools for the graphical analysis of variational quantum algorithms are developed. Classical, fault tolerant quantum and quantum-inspired methods can be included as well to ensure a fair comparison resulting in useful solution paths. We demonstrate and validate our approach on a selected set of options and illustrate its application on the capacitated vehicle routing problem (CVRP). We also identify crucial requirements and the major design challenges for the proposed abstraction layer within a quantum-assisted solution workflow for optimization problems.",IEEE
N. Quetschlich; V. Koch; L. Burgholzer; R. Wille,A Hybrid Classical Quantum Computing Approach to the Satellite Mission Planning Problem,2023,10.1109/QCE57702.2023.00079,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10313734,Conference Paper,2023 IEEE International Conference on Quantum Computing and Engineering (QCE),"Hundreds of satellites equipped with cameras orbit the Earth to capture images from locations for various purposes. Since the field of view of the cameras is usually very narrow, the optics have to be adjusted and rotated between single shots of different locations. This is even further complicated by the fixed speed-determined by the satellite's altitude-such that the decision what locations to select for imaging becomes even more complex. Therefore, classical algorithms for this Satellite Mission Planning Problem (SMPP) have already been proposed decades ago. However, corresponding classical solutions have only seen evolutionary enhancements since then. Quantum computing and its promises, on the other hand, provide the potential for revolutionary improvement. Therefore, in this work, we propose a hybrid classical quantum computing approach to solve the SMPP combining the advantages of quantum hardware with decades of classical optimizer development. Using the Variational Quantum Eigensolver (VQE), Quantum Approximate Optimization Algorithm (QAOA), and its warm-start variant (W-QAOA), we demonstrate the applicability of solving the SMPP for up to 21 locations to choose from. This proof-of-concept-which is avail-able on GitHub (https://github.com/cda-tum/mqt-problemsolver) as part of the Munich Quantum Toolkit (MQT)-showcases the potential of quantum computing in this application domain and represents a first step toward competing with classical algorithms in the future.",IEEE
C. B. S. Maior; L. M. M. Ara¨²jo; I. D. Lins; M. D. C. Moura; E. L. Droguett,Prognostics and Health Management of Rotating Machinery via Quantum Machine Learning,2023,10.1109/ACCESS.2023.3255417,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10065474,Journal,IEEE Access,"Prognostics and Health Management (PHM) concerns predicting machines¡¯ behavior to support maintenance decisions through failure modes diagnosis and prognosis. Diagnosis is broadly applied in the context of rotating machines¡¯ state classification using several traditional Machine Learning (ML) and Deep Learning (DL) methods. Recently, Quantum Computing (QC), a new and expanding research field, has contributed to different purposes and contexts, such as optimization, artificial intelligence, simulation, cybersecurity, pharmaceutics, and the energy sector. Despite the current limitations in terms of hardware, QC has been studied as an alternative for improving models¡¯ speed and computational efficiency. Specifically, this paper proposes a Quantum Machine Learning (QML) approach to diagnose rolling bearings, which are essential components in rotating machinery, based on vibration signals. We apply hybrid models involving the encoding and construction of parameterized quantum circuits (PQC) connected to a classical neural network, the Multi-Layer Perceptron (MLP). We consider combinations of the Variational Quantum Eigensolver (VQE) framework with rotation gates and different entanglement (two-qubits) gates (CNOT, CZ and iSWAP). For each PQC configuration, we assess the impact of the number of layers (1, 5 and 10). We use two databases of different complexity levels not previously explored with QML, namely CWRU and JNU, with 10 and 12 failure modes, respectivel. For CWRU, all QML models presented higher accuracy than the classical MLP. For JNU, all QML models were superior to classical MLP as well. These results suggest that, despite the current limitations of quantum environments, QML models are promising tools to be further investigated in PHM.","IEEE, Scopus"
Z. Duan; X. Qian; W. Song,Multi-Strategy Enhancde Slime Mould Algorithm for Optimization Problems,2025,10.1109/ACCESS.2025.3527509,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10835057,Article,IEEE Access,"The slime mould algorithm (SMA) simulates the mechanism by which slime moulds optimize paths through chemical signaling and morphological changes, enabling efficient exploration and exploitation of the solution space. While SMA is simple and flexible, it faces challenges such as slow convergence and a tendency to become trapped in local optima. To address these limitations, this paper introduces an enhanced algorithm that integrates bloch sphere-based Elite Population Initialization with an adaptive search operator strategy based on cauchy inverse cumulative distribution(QCMSMA). The proposed algorithm employs a Bloch sphere-based elite population initialization strategy, which utilizes quantum state mapping to enhance diversity and incorporates elite selection to guarantee high-quality initial solutions, ultimately improving optimization performance. An adaptive search operator leveraging the Cauchy inverse cumulative distribution is employed to dynamically adjust step sizes, improving exploration and efficiency. Additionally, a local Gaussian perturbation mutation strategy is incorporated to mitigate the risk of premature convergence to local optima.The QCMSMA algorithm was rigorously evaluated using 23 benchmark functions and the CEC2017 test suite. Comparative analysis against several well-known optimization algorithms was performed, accompanied by statistical assessments using theWilcoxon rank-sum test and Friedman ranking analysis. Experimental results indicate that QCMSMA consistently outperforms its counterparts in terms of optimization efficiency, convergence speed, and stability. Finally, the algorithm was applied to a real-world unmanned aerial vehicle(UAV) path planning problem, demonstrating its practical engineering applicability and effectiveness in solving complex optimization tasks.",IEEE
K. Glatting; J. Meyer; S. Huber; G. Krieger,Quantum Optimization for Phase Unwrapping in SAR Interferometry,2024,10.1109/JSTARS.2024.3519701,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10806567,Article,IEEE Journal of Selected Topics in Applied Earth Observations and Remote Sensing,"Phase unwrapping is the reconstruction of a phase given its values mod 2¦Ð. Phase unwrapping is an important image processing technique used in synthetic aperture radar interferometry, in the context of height estimation and ground deformation. By formulating the phase unwrapping problem as a global minimisation problem, Lp norm techniques form the backbone of many established phase unwrapping algorithms. The L0 norm is commonly agreed to produce the best unwrapping solutions, but the necessary brute-force calculations are infeasible for the phase unwrapping of SAR interferograms. Developments in variational quantum algorithms suggest computational advantages, when compared to classical approaches, for a multitude of applications. We therefore investigate the application of quantum algorithms to the phase unwrapping problem and introduce and derive an approximate L0 norm optimisation solver utilising the quantum approximate optimisation algorithm. This hybrid algorithm uses classical nonconvex parameter optimisation to produce optimal parameters for a quantum circuit encoding the L0 phase unwrapping. Subsequent execution of this quantum circuit allows for an estimate of the solution of the phase unwrapping problem with advantages compared to brute force approaches. We validate our approach for small topographies, by demonstrating improved results when compared to established L1 optimisation.",IEEE
D. Dong; X. Xing; H. Ma; C. Chen; Z. Liu; H. Rabitz,"Learning-Based Quantum Robust Control: Algorithm, Applications, and Experiments",2020,10.1109/TCYB.2019.2921424,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8759071,Journal,IEEE Transactions on Cybernetics,"Robust control design for quantum systems has been recognized as a key task in quantum information technology, molecular chemistry, and atomic physics. In this paper, an improved differential evolution algorithm, referred to as multiple-samples and mixed-strategy DE (msMS_DE), is proposed to search robust fields for various quantum control problems. In msMS_DE, multiple samples are used for fitness evaluation and a mixed strategy is employed for the mutation operation. In particular, the msMS_DE algorithm is applied to the control problems of: 1) open inhomogeneous quantum ensembles and 2) the consensus goal of a quantum network with uncertainties. Numerical results are presented to demonstrate the excellent performance of the improved machine learning algorithm for these two classes of quantum robust control problems. Furthermore, msMS_DE is experimentally implemented on femtosecond (fs) laser control applications to optimize two-photon absorption and control fragmentation of the molecule CH2BrI. The experimental results demonstrate the excellent performance of msMS_DE in searching for effective fs laser pulses for various tasks.",IEEE
B. Caraveo; L. Shih; I. -S. Suh; T. Humble,Quantum/AI Topology-Aware Latency-Adaptive HPC Workflow Scheduling Optimization,2024,10.1109/QCE60285.2024.10431,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10821099,Conference Paper,2024 IEEE International Conference on Quantum Computing and Engineering (QCE),"The growing demand for more powerful high-performance computing (HPC) systems has led to a steady rise in energy consumption by supercomputing worldwide. This study is focused on comparing our Application-Topology Mapper (ATMapper) to the popular Simple Linux Utility for Resource Management (SLURM) for the purpose of exploring methods that can further optimize job-scheduling within HPC systems. ATMapper is an Artificial-Intelligence based approach to job-scheduling that is currently being enhanced with quantum annealing (QA) to generate optimal schedules faster. We are applying QA to speedup our ATMapper process to achieve higher computing efficiency, thereby reducing HPC energy consumption. Here, we examine how four job-scheduling approaches perform in processor node assignment when using an example network architecture of 4 interconnected nodes. Using a specialized script, we are assessing the schedule of a computation flow with 11 interdependent tasks. The data movements among nodes were tracked to count for the number of interactions (network hops) between nodes needed to complete the tasks. The total number of hops and the job completion time were then used to quantify the efficiency of the different mapping approaches. In addition to SLURM, we also compare our ATMapper to the QA-enabled LBNL TIGER and the D-Wave Distributed Computing processor assignment approaches. The preliminary results showed that our topology-aware, latency-adaptive ATMapper is significantly more efficient when compared to the other scheduling approaches due to its load-imbalance network allocation. The scheduler displayed a computing efficiency of 53% by performing significantly fewer network hops than its alternatives. By reducing the number of hops, ATMapper was able to perform all 11 tasks by using only 3 nodes out of given 4. This research indicates the potential to use QA/AI for HPC job-scheduling. Later, we will test a SLURM simulator program to draw further comparisons on the effectiveness of ATMapper's scheduling approach. The results of this comparison will serve as a baseline for later improving SLURM's performance using a QA-enhanced ATMapper approach.",IEEE
D. Bucher; D. Porawski; B. Wimmer; J. N¨¹?lein; C. O¡¯Meara; N. Mohseni; G. Cortiana; C. Linnhoff-Popien,Evaluating Quantum Optimization for Dynamic Self-Reliant Community Detection,2024,10.1109/TSG.2024.3483657,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10722861,Article,IEEE Transactions on Smart Grid,"Power grid partitioning is an important requirement for resilient distribution grids. Since electricity production is progressively shifted to the distribution side, dynamic identification of self-reliant grid subsets becomes crucial for operation. This problem can be represented as a modification to the well-known NP-hard Community Detection (CD) problem. We formulate it as a Quadratic Unconstrained Binary Optimization (QUBO) problem suitable for solving using quantum computation, which is expected to find better-quality partitions faster. The formulation aims to find communities with maximal self-sufficiency and minimal power flowing between them. To assess quantum optimization for sizeable problems, we develop a hierarchical divisive method that solves sub-problem QUBOs to perform grid bisections. Furthermore, we propose a customization of the Louvain heuristic that includes self-reliance. In the evaluation, we first demonstrate that this problem examines exponential runtime scaling classically. Then, using different IEEE power system test cases, we benchmark the solution quality for multiple approaches: D-Wave¡¯s hybrid quantum-classical solvers, classical heuristics, and a branch-and-bound solver. As a result, we observe that the hybrid solvers provide very promising results, both with and without the divisive algorithm, regarding solution quality achieved within a given time frame. Directly utilizing D-Wave¡¯s Quantum Annealing (QA) hardware shows inferior partitioning.",IEEE
T. Itoko; R. Raymond,Sampling Strategy Optimization for Randomized Benchmarking,2021,10.1109/QCE52317.2021.00036,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9605302,Conference Paper,2021 IEEE International Conference on Quantum Computing and Engineering (QCE),"Randomized benchmarking (RB) is a widely used method for estimating the average fidelity of gates implemented on a quantum computing device. The stochastic error of the average gate fidelity estimated by RB depends on the sampling strategy (i.e., how to sample sequences to be run in the protocol). The sampling strategy is determined by a set of configurable parameters (an RB configuration) that includes Clifford lengths (a list of the number of independent Clifford gates in a sequence) and the number of sequences for each Clifford length. The RB configuration is often chosen heuristically and there has been little research on its best configuration. Therefore, we propose a method for fully optimizing an RB configuration so that the confidence interval of the estimated fidelity is minimized while not increasing the total execution time of sequences. By experiments on real devices, we demonstrate the efficacy of the optimization method against heuristic selection in reducing the variance of the estimated fidelity.",IEEE
D. Martyniuk; J. Jung; A. Paschke,Quantum Architecture Search: A Survey,2024,10.1109/QCE60285.2024.00198,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10821367,Conference Paper,2024 IEEE International Conference on Quantum Computing and Engineering (QCE),"Quantum computing has made significant progress in recent years, attracting immense interest not only in research laboratories but also in various industries. However, the application of quantum computing to solve real-world problems is still hampered by a number of challenges, including hardware limitations and a relatively under-explored landscape of quantum algorithms, especially when compared to the extensive development of classical computing. The design of quantum circuits, in particular parameterized quantum circuits (PQCs), which contain learnable parameters optimized by classical methods, is a non-trivial and time-consuming task requiring expert knowledge. As a result, research on the automated generation of PQCs, known as quantum architecture search (QAS), has gained considerable interest. QAS focuses on the use of machine learning and optimization-driven techniques to generate PQCs tailored to specific problems and characteristics of quantum hardware. In this paper, we provide an overview of QAS methods by examining relevant research studies in the field. We discuss the main challenges in designing and performing an automated search for an optimal PQC, and survey ways to address them to ease future research.",IEEE
C. Ibrahim; D. Lykov; Z. He; Y. Alexeev; I. Safro,Constructing Optimal Contraction Trees for Tensor Network Quantum Circuit Simulation,2022,10.1109/HPEC55821.2022.9926353,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9926353,Conference Paper,2022 IEEE High Performance Extreme Computing Conference (HPEC),"One of the key problems in tensor network based quantum circuit simulation is the construction of a contraction tree which minimizes the cost of the simulation, where the cost can be expressed in the number of operations as a proxy for the simulation running time. This same problem arises in a variety of application areas, such as combinatorial scientific computing, marginalization in probabilistic graphical models, and solving constraint satisfaction problems. In this paper, we reduce the computationally hard portion of this problem to one of graph linear ordering, and demonstrate how existing approaches in this area can be utilized to achieve results up to several orders of magnitude better than existing state of the art methods for the same running time. To do so, we introduce a novel polynomial time algorithm for constructing an optimal contraction tree from a given order. Furthermore, we introduce a fast and high quality linear ordering solver, and demonstrate its applicability as a heuristic for providing orderings for contraction trees. Finally, we compare our solver with competing methods for constructing contraction trees in quantum circuit simulation on a collection of randomly generated Quantum Approximate Optimization Algorithm Max Cut circuits and show that our method achieves superior results on a majority of tested quantum circuits. Reproducibility: Our source code and data are available at https://github.com/cameton/HPEC2022_ContractionTrees.",IEEE
M. Roetteler; K. M. Svore; D. Wecker; N. Wiebe,Design automation for quantum architectures,2017,10.23919/DATE.2017.7927196,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7927196,Conference Paper,"Design, Automation & Test in Europe Conference & Exhibition (DATE), 2017","We survey recent strides made towards building a software framework that is capable of compiling quantum algorithms from a high-level description down to physical gates that can be implemented on a fault-tolerant quantum computer. We discuss why compilation and design automation tools such as the ones in our framework are key for tackling the grand challenge of building a scalable quantum computer. We then describe specialized libraries that have been developed using the LIQUi|¡µ programming language. This includes reversible circuits for arithmetic as well as new, truly quantum approaches that rely on quantum computer architectures that allow the probabilistic execution of gates, a model that can reduce time and space overheads in some cases. We highlight why these libraries are useful for the implementation of many quantum algorithms. Finally, we survey the tool Revs that facilitate resource efficient compilation of higher-level irreversible programs into lower-level reversible circuits while trying to optimize the memory footprint of the resulting reversible networks. This is motivated by the limited availability of qubits for the foreseeable future.",IEEE
S. K. Kandula; N. Katam; P. R. Kangari; A. Hijmal; R. Gurrala; M. Mahmoud,Quantum Computing Potentials for Drug Discovery,2023,10.1109/CSCI62032.2023.00240,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10590603,Conference Paper,2023 International Conference on Computational Science and Computational Intelligence (CSCI),"The pharmaceutical industry relies heavily on the drug discovery process to develop new medications that can help treat various diseases. This process is highly crucial but also very time-consuming, as it involves screening a massive number of chemical compounds to identify those that can be developed into effective treatments. Traditional computing methods are often inadequate for this task due to the complexity and vastness of the data involved. Quantum computing is an emerging field that has gained significant attention in recent years due to its ability to perform complex computations at a much faster pace than classical computers. Quantum computing uses the principles of quantum mechanics, which differ significantly from classical computing. Drug discovery involves a process of identifying new drugs with the desired biological activity to treat specific diseases. This process can be quite lengthy, time-consuming, and expensive, often taking many years to develop a single drug. However, quantum computing has the potential to revolutionize the drug discovery process. Its ability to perform complex calculations quickly and efficiently could significantly speed up the drug discovery process, making it more cost-effective and accurate. Quantum computing's potential in drug discovery requires further research to fully understand and develop practical applications. The use of quantum computing requires the development of specialized algorithms and software tailored to quantum computing. Further investment in research and development is needed to fully leverage the potential of this technology. This paper explores the potential of quantum computing in drug discovery. We will analyze the benefits of using quantum computing in drug discovery, including faster and more accurate data processing, improved optimization, and more efficient screening of chemical compounds. Our paper will also discuss the challenges and limitations that need to be addressed to fully leverage the potential of quantum computing in drug discovery. This will include discussing potential applications of quantum computing in drug discovery, as well as the need for further investment in research and development to fully realize the potential of this technology. Overall, our paper will provide a comprehensive analysis of the potential of quantum computing in drug discovery, exploring both the benefits and challenges associated with this technology and providing recommendations for future research and development.",IEEE
T. O. Olowu; M. Moghaddami; A. I. Sarwat,"Soft-switching, Self-tuning and Optimization Technique for Solid State Transformers Based on Direct AC-AC Matrix Converter Topology",2020,10.1109/IAS44978.2020.9334728,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9334728,Conference Paper,2020 IEEE Industry Applications Society Annual Meeting,"Solid state transformers (SSTs) offers some distinct advantages compared to the traditional low frequency ones . One of the design challenges with SST, is its reliability and efficiency. The use of matrix converters (MC) for direct AC-AC conversion is one of the most effective SST topologies. It eliminates the need for DC link capacitors and consequently improves its reliability. This paper proposes a novel and simplified logic based control circuit using quantum energy injection/absorption principle that achieves a zero voltage switching (and resonant current tracking for self-tuning), for all the MC switches from light loads to heavy loads. The proposed controller consists of just logic gates which minimizes costs and eliminates the need for complex programming of micro-controllers such as FPGAs and DSPs. A simplified design multi-objective optimization technique for a 5kW high frequency transformer (HFT) using the AMCC -50 core is also proposed. The proposed design optimization of the HFT enables careful selection of the HFT parameters which minimizes its cost, achieves reasonable leakage inductance and reduces the total loss as its design objectives. The HFT optimization is done using MATLAB coupled with ANSYS and FEMM. Using one of the Pareto optimal solutions of the HFT, a 5kW, 17kHz, 208/208V , SST using the proposed controller is simulated using Matlab/SIMULINK. The HFT optimization results show the effectiveness of the proposed optimization algorithm while the SST simulation results the verify effectiveness of the proposed controller.",IEEE
V. Hahanov; W. Gharibi; E. Litvinova; M. Liubarskyi; A. Hahanova,Quantum memory-driven computing for test synthesis,2017,10.1109/EWDTS.2017.8110147,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8110147,Conference Paper,2017 IEEE East-West Design & Test Symposium (EWDTS),"Memory-driven computing for the design and test of digital devices is considered. One of the possible solutions to the problem of design and test theory and methods of quantum memory-driven computing on the classical computers for their subsequent application in all fields of human activity is proposed. Engineering-focused definitions of computing types are presented, including quantum one, which leverages the superposition and entanglement notions, and also memory-driven computing. The necessity of joint and parallel solving the problem of the creation of a market-accessible quantum computer and development of quantum-focused applications and cloud services is explained. Examples of quantum memory-driven design and test of digital circuit fragments are presented. A method for synthesis and minimization test for the black-box functionality, based on a qubit derivative matrix and sequencer for searching a quasioptimum coverage, is proposed.",IEEE
H. Nagarajan; O. Lockwood; C. Coffrin,QuantumCircuitOpt: An Open-source Framework for Provably Optimal Quantum Circuit Design,2021,10.1109/QCS54837.2021.00010,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9651462,Conference Paper,2021 IEEE/ACM Second International Workshop on Quantum Computing Software (QCS),"In recent years, the quantum computing community has seen an explosion of novel methods to implement non-trivial quantum computations on near-term hardware. An important direction of research has been to decompose an arbitrary entangled state, represented as a unitary, into a quantum circuit, that is, a sequence of gates supported by a quantum processor. It has been well known that circuits with longer decompositions and more entangling multi-qubit gates are error-prone for the current noisy, intermediate-scale quantum devices. To this end, there has been a significant interest to develop heuristic-based methods to discover compact circuits. We contribute to this effort by proposing QuantumCircuitOpt (QCOpt), a novel open-source framework which implements mathematical optimization formulations and algorithms for decomposing arbitrary unitary gates into a sequence of hardware-native gates. A core innovation of QCOpt is that it provides optimality guarantees on the quantum circuits that it produces. In particular, we show that QCOpt can find up to 57% reduction in the number of necessary gates on circuits with up to four qubits, and in run times less than a few minutes on commodity computing hardware. We also validate the efficacy of QCOpt as a tool for quantum circuit design in comparison with a naive brute-force enumeration algorithm. We also show how the QCOpt package can be adapted to various built-in types of native gate sets, based on different hardware platforms like those produced by IBM, Rigetti and Google. We hope this package will facilitate further algorithmic exploration for quantum processor designers, as well as quantum physicists.",IEEE
A. Sarker; M. M. Kermani; R. Azarderakhsh,Fault Detection Architectures for Inverted Binary Ring-LWE Construction Benchmarked on FPGA,2021,10.1109/TCSII.2020.3025857,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9203825,Journal,IEEE Transactions on Circuits and Systems II: Express Briefs,"Ring learning with errors (RLWE) is an efficient lattice-based cryptographic scheme that has worst-case reduction to lattice problem, conjectured to be quantum-hard. Ring-BinLWE is an optimized variant of RLWE problem using binary error distribution, resulting in highly-efficient hardware implementation. Efficient and low-complexity architectures in hardware, thwarting natural and malicious faults, are essential for lattice-based post-quantum cryptography (PQC) algorithms. In this brief, we explore efficient fault detection approaches for implementing the Ring-BinLWE problem. This brief, for the first time, investigates fault detection schemes for all three stages of RLWE encryption. Utilizing the stuck-at fault model, we employ recomputing with encoded operands schemes to achieve high error coverage. We simulate and implement our schemes on a field-programmable gate array (FPGA) platform. Our schemes provide low hardware overhead (area overhead of 15.74%, delay overhead of 7.74%, and power consumption overhead of 4.06%), with high error coverage, which can be suitable for resource-constrained as well as high-performance usage models.",IEEE
M. Sadi; Y. He; Y. Li; M. Alam; S. Kundu; S. Ghosh; J. Bahrami; N. Karimi,Special Session: On the Reliability of Conventional and Quantum Neural Network Hardware,2022,10.1109/VTS52500.2021.9794194,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9794194,Conference Paper,2022 IEEE 40th VLSI Test Symposium (VTS),"Neural Networks (NNs) are being extensively used in critical applications such as aerospace, healthcare, autonomous driving, and military, to name a few. Limited precision of the underlying hardware platforms, permanent and transient faults injected unintentionally as well as maliciously, and voltage/temperature fluctuations can potentially result in malfunctions in NNs with consequences ranging from substantial reduction in the network accuracy to jeopardizing the correct prediction of the network in worst cases. To alleviate such reliability concerns, this paper discusses the state-of-the-art reliability enhancement schemes that can be tailored for deep learning accelerators. We will discuss the errors associated with the hardware implementation of Deep-Learning (DL) algorithms along with their corresponding countermeasures. An in-field self-test methodology with a high test coverage is introduced, and an accurate high-level framework, so-called FIdelity, is proposed that enables the designers to evaluate DL accelerators in presence of such errors. Then, a state-of-the-art robustness-preserving training algorithm based on the Hessian Regularization is introduced. This algorithm alleviates the perturbations during inference time with negligible degradation in the accuracy of the network. Finally, Quantum Neural Networks (QNNs) and the methods to make them resilient against a variety of vulnerabilities such as fault injection, spatial and temporal variations in Qubits, and noise in QNNs are discussed.",IEEE
C. Lee; Y. Kim; K. Shim; W. Lee,Key-count differential-based proactive key relay algorithm for scalable quantum-secured networking,2023,10.1364/JOCN.478620,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10113548,Journal,Journal of Optical Communications and Networking,"By overcoming the distance limit in quantum key distribution (QKD) technology, key relaying over trusted nodes is regarded as an essential function for practical quantum-secured networking. The key relay function consumes a series of costly quantum key resources to establish an end-to-end key in QKD networks (QKDNs); thus, an efficient key relay algorithm is required. To investigate this problem, we developed an integer linear programming (ILP) formulation that maximizes a balanced summation between max-min fairness and efficiency in the key relay. Inspired by the ILP model, this study developed a key-count differential-based proactive key relay (DPKR) heuristic algorithm to provide a scalable solution for key relays in QKDNs. The proposed DPKR algorithm iteratively selects a set of nodes by considering the key-count differential between nodes and establishes an end-to-end key by relaying it over the selected nodes. Owing to the proactive key relay model, an effective key relay route in the key management layer in the QKDN can be calculated solely by the key-count status in the key management layer. The proposed DPKR algorithm reduces manifold order-of-magnitude in the algorithm computation time at the cost of an acceptable loss in the average and minimum numbers of keys from those of the ILP optimization model. The computation time evaluation clearly manifests a scalability of the DPKR algorithm in quantum-secured networking.",IEEE
N. Quetschlich; L. Burgholzer; R. Wille,Compiler Optimization for Quantum Computing Using Reinforcement Learning,2023,10.1109/DAC56929.2023.10248002,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10248002,Conference Paper,2023 60th ACM/IEEE Design Automation Conference (DAC),"Any quantum computing application, once encoded as a quantum circuit, must be compiled before being executable on a quantum computer. Similar to classical compilation, quantum compilation is a sequential process with many compilation steps and numerous possible optimization passes. Despite the similarities, the development of compilers for quantum computing is still in its infancy¡ªlacking mutual consolidation on the best sequence of passes, compatibility, adaptability, and flexibility. In this work, we take advantage of decades of classical compiler optimization and propose a reinforcement learning framework for developing optimized quantum circuit compilation flows. Through distinct constraints and a unifying interface, the framework supports the combination of techniques from different compilers and optimization tools in a single compilation flow. Experimental evaluations show that the proposed framework¡ªset up with a selection of compilation passes from IBM¡¯s Qiskit and Quantinuum¡¯s TKET¡ªsignificantly outperforms both individual compilers in 73% of cases regarding the expected fidelity. The framework is available on GitHub (https://github.com/cda-tum/MQTPredictor) as part of the Munich Quantum Toolkit (MQT).",IEEE
A. Guerrieri; G. D. Silva Marques; F. Regazzoni; A. Upegui,Optimizing Lattice-based Post-Quantum Cryptography Codes for High-Level Synthesis,2022,10.1109/DSD57027.2022.00109,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9996866,Conference Paper,2022 25th Euromicro Conference on Digital System Design (DSD),"High-level synthesis is a mature Electronics Design Automation (EDA) technology for building hardware design in a short time. It produces automatically HDL code for FPGAs out of C/C++, bridging the gap from algorithm to hardware. Nevertheless, sometimes the QoR (Quality of Results) can be sub-optimal due to the difficulties of HLS in handling general-purpose software code. In this paper, we explore the current difficulties of HLS while synthesizing Lattice-based Post-Quantum Cryptog-raphy (PQC) algorithms. We propose code-level optimizations to overcome the limitations of high-level synthesis increasing the QoR of generated hardware. We analyzed and improved the results for the algorithms competing in the 3rd round of the NIST standardization process. We show how, starting from the original reference code submitted for the competition, original performance and resource utilization can be improved, in some cases with a speedup factor up to $200\times$ or an area reduction of 80%.",IEEE
H. Li; J. Liang; H. Fan; Y. Tang,Design Space Exploration for Efficient Quantum Most-Significant Digit-First Arithmetic,2023,10.1109/TC.2022.3215891,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9924609,Journal,IEEE Transactions on Computers,"Quantum computing has been considered as an emerging approach in addressing problems which are not easily solvable using classical computers. In parallel to the physical implementation of quantum processors, quantum algorithms have been actively developed for real-life applications to show quantum advantages, many of which benefit from quantum arithmetic algorithms and their efficient implementations. As one of the most important operations, quantum addition has been adopted in Shor's algorithm and quantum linear algebra algorithms. Although various least-significant digit-first quantum adders have been introduced in previous work, interest in investigating the efficient implementation of most-significant digit-first addition is growing. In this work, we propose a novel design method for most-significant digit-first addition with several quantum circuit optimisations to reduce the number of quantum bits (i.e. qubits), quantum gates, and circuit depth. An open-source library of different arithmetic operators based on our proposed method is presented, where all circuits are implemented on IBM Qiskit SDK. Extensive experiments demonstrate that our proposed design, together with the optimisation techniques, reduces T-depth by up-to 4.0¡Á, T-count by 3.5¡Á, and qubit consumption by 1.2¡Á.",IEEE
W. Zhang; W. Shi; J. Zhuo,Quantum-PSO based system stabilizer optimization for shipboard power system,2016,10.1109/ChiCC.2016.7554912,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7554912,Conference Paper,2016 35th Chinese Control Conference (CCC),"A quantum particle swarm optimization (QPSO) method for the shipboard power system stabilizer optimal is proposed in this paper. The proposed optimized strategy is inspired by trajectory analysis of the particle swarm optimization and quantum mechanics, and aims at enhancing global search capability. The attractive features of particle swarm optimization are its algorithm simplicity, fast convergence and can avoid the optimization jump into local optimal solution. The simulations are conducted under load change disturbance and short-circuit fault cases for the shipboard power system stabilizer optimization. Simulation results show that the quantum particle swarm optimization strategy can achieve success in shipboard power system dynamic control which indicates the effectiveness, feasibility and robustness of the proposed approach.",IEEE
V. A. Bogatyrev; V. S. Moskvin,Optimizing Traffic Flow Using Quantum Annealing,2024,10.1109/TIRVED63561.2024.10769819,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10769819,Conference Paper,2024 Intelligent Technologies and Electronic Devices in Vehicle and Road Transport Complex (TIRVED),"This paper investigates the use of quantum annealing for optimizing traffic flow, serving as a case study for broader applications in network optimization tasks. We start by modeling the traffic network as a quantum system, where intersections, roads, and traffic parameters are represented as qubits within a quantum annealing framework. The optimization process is outlined, illustrating how the quantum system evolves to identify low-energy states that correspond to optimal traffic flow configurations. By harnessing the unique properties of quantum mechanics, such as superposition and quantum tunneling, quantum annealing has the potential to efficiently explore extensive solution spaces beyond the capabilities of classical algorithms. This research aims to expand the understanding of how quantum computing can be applied to complex network optimization challenges, providing insights that could lead to more efficient, responsive, and sustainable management systems across various domains.",IEEE
F. Zhang; B. Yang; X. Dong; S. Guilley; Z. Liu; W. He; F. Zhang; K. Ren,Side-Channel Analysis and Countermeasure Design on ARM-Based Quantum-Resistant SIKE,2020,10.1109/TC.2020.3020407,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9181442,Journal,IEEE Transactions on Computers,"The implementations of post-quantum cryptographic algorithms have been newly explored, whereas, the protection against side-channel attacks shall be considered upfront, since it can have a non-negligible impact on security and performance. In this article, the security of supersingular isogeny key encapsulation (SIKE), a second-round candidate of NIST's on-going post-quantum standardization process, is thoroughly evaluated under side-channel analysis. First, the vulnerabilities of reference and optimized implementations of SIKE are thoroughly analyzed in terms of both horizontal and vertical side-channel leakage. After the optimized SIKE, which is based on Three-point Montgomery Differential Ladder algorithm, is proved to be constant-time and there is no horizontal leakage, a vertical vulnerability is analyzed based on the source code at the algorithmic level, and a theoretical differential power analysis (DPA) attack is proposed. In order to exploit this vulnerability, the differential electromagnetic attack (DEMA) is put into practice to extract the private key of SIKE based on a 32-bit ARM platform. To the best of our knowledge, this is the first practical side-channel attack at SIKE implemented on real ARM-based devices. Our experiments show that the DEMA needs only hundreds of electromagnetic traces to carry out the attack. More importantly, an efficient window-based countermeasure is proposed to eliminate the vertical leakage and prevent side-channel attacks with only a little overhead. The security of our countermeasure is carefully evaluated against most of well-known power analysis attacks. Through careful evaluation and comparison with other countermeasures, this method can lead to higher security at a very small cost in terms of time and memory.",IEEE
C. Qin; B. Han,A Novel Hybrid Quantum Particle Swarm Optimization With Marine Predators for Engineering Design Problems,2022,10.1109/ACCESS.2022.3226813,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9970307,Journal,IEEE Access,"computational efficiency of the quantum particle swarm optimization (QPSO) is significantly higher than that of the traditional particle swarm optimization when solving the parameters of the optimization problem model. However, the exploration and exploitation abilities of the QPSO are weak, based on the historical best position and the global best position. Enlightened by the multi-stage search strategies of marine predators algorithm, we propose a novel hybrid quantum particle swarm optimization algorithm with marine predators (HMPQPSO) in this paper. The evolutionary process of the algorithm is divided two stages: firstly, the Brownian motion of the predator is introduced to the exploration. The randomness and uniformity of which can expand the solution space of particles; secondly, the Levy motion strategy and dynamic parameter strategy are used to update the position, which can accelerate the convergence of the algorithm and enhance the diversity of the algorithm. Meanwhile, both fish aggregation devices(FADs) and opposition-based learning strategy incorporated are used to increase the diversity of the population and prevent the phenomenon of premature particle aggregation. The algorithm is applied to distinct types of CEC2017 benchmark test functions and four multidimensional nonlinear structure design optimization problems, as compared to other recent algorithms. The results demonstrate that the convergence speed and accuracy of HMPQPSO are notably superior to that of other algorithms.",IEEE
L. Giuffrida; D. Volpe; G. A. Cirillo; M. Zamboni; G. Turvani,Engineering Grover Adaptive Search: Exploring the Degrees of Freedom for Efficient QUBO Solving,2022,10.1109/JETCAS.2022.3202566,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9869620,Journal,IEEE Journal on Emerging and Selected Topics in Circuits and Systems,"Quantum computers have the potential to solve Quadratic Unconstrained Binary Optimization (QUBO) problems with lower computational complexity than classical ones. Considering the current limitations of quantum hardware, the joint use of classical and quantum paradigms could exploit both advantages. Quantum routines can make some complex tasks for classical computers feasible. For example, in the Grover Adaptive Search (GAS) procedure, the problem cost function is classically shifted iteratively, whenever a negative value is found through the quantum Grover Search (GS) algorithm, until the minimum is achieved. This quantum-classical approach is characterized by many degrees of freedom, e.g. the number of GS iterations in each call and the stop condition of the algorithm, which should be appropriately tuned for an effective and fast convergence to the optimal solution. The availability of software routines could permit the best management of the GAS parameters. This work proposes new mechanisms for GAS parameters management and compares them with the existing ones, like one available in the Qiskit framework. The proposed mechanisms can automatically arrange the parameters according to the algorithm evolution and their previous experience, thus ensuring a more frequent and faster achievement of the optimal solution. Even though these strategies can be further improved, the results are encouraging. The analysis is done to identify the best policy for different problems. It lays the foundation for designing an automatic toolchain for QUBO solving, which can obtain the best possible implementation of the GAS algorithm for each submitted problem.",IEEE
S. Pathak; A. Mani; A. Chatterjee,A Cooperative Hybrid Quantum-Inspired Salp Swarm and Differential Evolution for Solving CEC 2022 Benchmark and Controller Placement Problems in Software Defined Networks,2024,10.1109/ACCESS.2024.3414930,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10557608,Journal,IEEE Access,"This paper introduces a Cooperative Model of Salp Swarm Optimization (CMSSO), which combines four algorithms: Salp Swarm Algorithm (SSA), Elite Opposition Learning-based SSA (EOSSA), Elite Opposition Quantum-inspired SSA (EQSSA), and Individual Dependent Approach for Differential Evolution (IDA-DE). These algorithms collaborate to tackle single-objective numerical optimization benchmarks from CEC-2022. SSA is a robust population-based metaheuristic renowned for its efficacy in practical optimization tasks. EOL and Quantum-inspired evolutionary algorithms exhibit enhanced capabilities in navigating search spaces compared to standard evolutionary algorithms. The objective of this cooperative model is to preserve the diversity and computational prowess of SSA while leveraging the strengths of these advanced algorithms. The multiobjective controller placement problem in Software Defined Networks (SDN) involves assigning switches to controllers, impacting network Quality of Service (QoS). Previous studies often focused on propagation latency for this assignment. However, our paper addresses this problem considering propagation latency between switches and controllers, inter-controller latency, and load balancing as multiobjective optimization. The experimental results confirmed the effectiveness of the proposed approach and showed that CMSSO is competitive with the standard SSA approaches.","IEEE, Web of Science"
M. M. A. Moni; M. Niloy; A. H. Chowdhury; F. J. Khan; M. F. -U. -A. Juboraj; A. Chakrabarty,Comparative Analysis of Process Scheduling Algorithm using AI models,2022,10.1109/ICCIT57492.2022.10055395,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10055395,Conference Paper,2022 25th International Conference on Computer and Information Technology (ICCIT),"Process scheduling is an integral part of operating systems. The most widely used scheduling algorithm in operating systems is Round Robin, but the average waiting time in RR is often quite long. The purpose of this study is to propose a new algorithm to minimize waiting time and process starvation by determining the optimal time quantum by predicting CPU burst time. For burst time prediction, we are using the machine learning algorithms like linear regression, decision tree, k-nearest neighbors, and Neural Network Model Multi-Layer Perceptron. Moreover, for 10000 predicted burst time of processes with the same configuration, we have compared the average turnaround time, the average waiting time and the number of context switches of the proposed modified round robin algorithm with Traditional Round Robin, Modified Round Robin, Optimized Round Robin and Self-Adjustment Round Robin. The proposed modified round robin i.e. Absolute Difference Based Time Quantum Round Robin (ADRR) is found to be almost 2 times faster than the other algorithm in terms of process scheduling for the used dataset which contains a huge load of processes.",IEEE
D. Upadhyay; K. B. Sharma; M. Gupta; A. Upadhyay,Channel Capacity Enhancement in Dual Branch MRC under Extreme Fading Using Quantum Computing,2024,10.1109/TENSYMP61132.2024.10752246,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10752246,Conference Paper,2024 IEEE Region 10 Symposium (TENSYMP),"We have investigated the potential of channel capacity and signal integrity enhancement in dual branch MRC systems even under extreme fading through classical and quantum computing. We have used the classical algorithm to gauge the performance of the quantum algorithm, including QAOA and QEC. Our simulation results show that quantum-assisted MRC work optimally by providing superior SNR and BER. Quantum algorithms not only maximizes the effective channel capacity but also minimizes end-to-end system latency and number of error rate more efficiently. The addition of Quantum Machine Learning for the dynamic parameter setting in real-time has demonstrated that it may be possible to combat severe fading effects. To the best of our knowledge, this paper laid the cornerstone to explore more opportunities in implementing quantum-enabled techniques for advanced telecommunication system development to realize more robust and efficient technologies.",IEEE
A. Gangwar; A. Upadhyay; A. S. Azad,Optimised Smart AI Surveillance in Quantum Computing Age,2022,10.1109/I2CT54291.2022.9824610,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9824610,Conference Paper,2022 IEEE 7th International conference for Convergence in Technology (I2CT),"With the advancements in the digital world, crime investigations & video surveillance has also become smart using Artificial Intelligence and IoT like technologies. And the security of the sensitive information transferred between IoT devices only relies on the most robust available classical cryptographic methods. But the prime concern involves the easy breaking of the classical approaches of cryptography soon with the relentless advancement of technology. Thereby, the research mainly focuses on two areas. First, optimising intelligent video surveillance for crime investigations by implementing the ideology of the blockchain, and Deep Learning Neural Networks algorithms for reduced processing yet faster and accurate results. Second, implementation of Quantum Cryptography for better future-proofing and further research for future improvements. The discussion of results shows the optimal usability of deploying this idea and future scopes for improved data security.",IEEE
A. Davletova; V. Yatskiv; S. Ivasiev; S. Kulyna; T. Tsavolyk; V. Drapak,Enhancing Cryptographic System Security based on Finite Fields,2024,10.1109/ACIT62333.2024.10712491,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10712491,Conference Paper,2024 14th International Conference on Advanced Computer Information Technologies (ACIT),"An analysis of modern research in the field of post-quantum cryptography is carried out, which demonstrates the importance of developing algorithms capable of resisting quantum threats. Alternative approaches to optimizing cryptographic systems based on error correction codes have been explored. It is proposed to use $\boldsymbol{G F}(\boldsymbol{q})$ for the development of stable cryptographic systems, which provides a high degree of randomness and unpredictability of encryption. The use of finite Galois fields for key generation enables the adaptation of security levels to specific needs and requirements by selecting the field size, thereby enhancing the security and efficiency of encryption systems.",IEEE
S. Kasi; J. Sud; K. Jamieson; G. S. Ravi,A Quantum Approximate Optimization Algorithm-Based Decoder Architecture for NextG Wireless Channel Codes,2024,10.1109/QCE60285.2024.00051,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10821436,Conference Paper,2024 IEEE International Conference on Quantum Computing and Engineering (QCE),"Forward Error Correction (FEC) provides reliable data flow in wireless networks despite the presence of noise and interference. However, its processing demands significant fraction of a wireless network's resources, due to its computationally-expensive decoding process. This forces network designers to compromise between performance and implementation complexity. In this paper, we investigate a novel processing architecture for FEC decoding, one based on the quantum approximate optimization algorithm (QAOA), to evaluate the potential of this emerging quantum compute approach in resolving the decoding performance-complexity tradeoff. We present FDeQ, a QAOA-based FEC Decoder design targeting the popular NextG wireless Low Density Parity Check (LDPC) and Polar codes. To accelerate QAOA-based decoding towards practical utility, FDeQ exploits temporal similarity among the FEC decoding tasks. This similarity is enabled by the fixed structure of a particular FEC code, which is independent of any time-varying wireless channel noise, ambient interference, and even the payload data. We evaluate FDeQ at a variety of system parameter settings in both ideal (noiseless) and noisy QAOA simulations, and show that FDeQ achieves successful decoding with error performance at par with state-of-the-art classical decoders at low FEC code block lengths. Furthermore, we present a holistic resource estimation analysis, projecting quantitative targets for future quantum devices in terms of the required qubit count and gate duration, for the application of FDeQ in practical wireless networks, highlighting scenarios where FDeQ may outperform state-of-the-art classical FEC decoders.",IEEE
A. Kim,Hybrid Quantum-Classical Neural Network for Diagnosis of Autism Spectrum Disorder,2024,10.1109/QCE60285.2024.10348,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10821225,Conference Paper,2024 IEEE International Conference on Quantum Computing and Engineering (QCE),"Autism Spectrum Disorder (ASD) affects almost 3% of children worldwide, and due to the complexity and heterogeneity of ASD, accurate and efficient diagnosis is difficult to achieve. Qualitative diagnosis based on observation of behavior has a major risk of misdiagnosis. Meanwhile, the most efficient quantitative algorithms in modern literature are similarly problematic, with misdiagnosis rates of up to 44 %, execution times of over 7 hours, and all algorithms are purely classical. This project is an implementation of a hybrid quantum-classical neural network (HQCNN) to improve upon classical neural networks by applying quantum algorithms while only using fMRI data. The proposed neural network implements a variational quantum deflation (VQD) algorithm, an extension of the variational quantum eigensolver (VQE) framework for finding the first $k$ excited states of a Hamiltonian. This study shows that the VQD algorithm produces eigenvalues effectively equivalent to the classically computed ones, and the general algorithm has up to 70% accuracy with less than an hour of execution time, a major improvement from the 56% accuracy and over 7 hour runtimes of most classical algorithms. With the development of quantum computing technology, the VQD algorithm will continue to be optimized. Furthermore, the HQCNN is generally scalable, and only requires fMRI data for analysis. This study shows a faster and more accurate diagnosis of ASD using quantum algorithms.",IEEE
T. Can; N. Rengaswamy; R. Calderbank; H. D. Pfister,Kerdock Codes Determine Unitary 2-Designs,2020,10.1109/TIT.2020.3015683,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9164978,Journal,IEEE Transactions on Information Theory,"The non-linear binary Kerdock codes are known to be Gray images of certain extended cyclic codes of length codewords by ¡÷ z ¡Ì-1 produces stabilizer states, that are N = 2 over Z4. We show that exponentiating these Z4-valued quantum states obtained using only Clifford unitaries. These states are also the common eigenvectors of commuting Hermitian matrices forming maximal commutative subgroups (MCS) of the Pauli group. We use this quantum description to simplify the derivation of the classical weight distribution of Kerdock codes. Next, we organize the stabilizer states to form N + 1 mutually unbiased bases and prove that automorphisms of the Kerdock code permute their corresponding MCS, thereby forming a subgroup of the Clifford group. When represented as symplectic matrices, this subgroup is isomorphic to the projective special linear group PSL(2, N). We show that this automorphism group acts transitively on the Pauli matrices, which implies that the ensemble is Pauli mixing and hence forms a unitary 2-design. The Kerdock design described here was originally discovered by Cleve et al. (2016), but the connection to classical codes is new which simplifies its description and translation to circuits significantly. Sampling from the design is straightforward, the translation to circuits uses only Clifford gates, and the process does not require ancillary qubits. Finally, we also develop algorithms for optimizing the synthesis of unitary 2-designs on encoded qubits, i.e., to construct logical unitary 2-designs. Software implementations are available at https://github.com/nrenga/symplectic-arxiv18a, which we use to provide empirical gate complexities for up to 16 qubits.","IEEE, Web of Science"
J. Zhao; P. Xu; X. Wu; J. Pei; H. Fu; Y. Li,Power Losses Optimization of MMCs Based on Quantum Genetic Algorithm for HVdc Transmission Application,2024,10.1109/TCSI.2024.3486576,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10750512,Article,IEEE Transactions on Circuits and Systems I: Regular Papers,"Modular multilevel converters (MMCs) obtain widespread utilization in high-voltage direct current (HVdc) applications scenarios. The cost of power losses plays a significant part in MMC¡¯s operating costs. Hence, this article proposes a quantum genetic algorithm-based power losses optimization control (QGA-PLOC). By comprehensively considering the power losses of the MMC, the quantum genetic algorithm determines the first-best value of the injected second circulating current magnitude and phase angle in the arm, as well as the optimal MMC power losses under given conditions. The quantum genetic algorithm incorporates the quantum state vector representation into genetic encoding and utilizes quantum logic gates for chromosome evolution, greatly improving the algorithm¡¯s performance and significantly enhancing its computational efficiency and global optimization capability. Moreover, introducing the quantum genetic algorithm into the field of MMC power losses optimization offers a new path to address the acquisition of the optimal circulating current reference value in power loss optimization problems. MMC Simulation and experiment are also conducted, and the research results verify the effectiveness of the proposed QGA-PLOC for MMCs.",IEEE
S. Chanda; M. Mohanpurkar; R. Hovsapian,Architecture for Quantum-in-the Loop Real-Time Simulations for Designing Resilient Smart Grids,2023,10.1109/ATEE58038.2023.10108354,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10108354,Conference Paper,2023 13th International Symposium on Advanced Topics in Electrical Engineering (ATEE),"With the power grid growing more complex every day with the inclusion of new sensors and regulatory approvals that enable end-users and small local developers to participate in the grid, it is becoming challenging for conventional smart grid simulation, emulation, and testing technologies to keep up. In this work, we propose that quantum-encoded real-time simulations can be helpful under the new paradigm and operational circumstances to solve optimization problems for power grids. By leveraging the principles of quantum mechanics, the proposed quantum-in-loop (QIL) framework will enable better and faster optimization solutions based on real-world, real-time data streams, facilitating the real-time planning and operations of electrical grids that rely on millions of distributed sensors and controllers. Furthermore, QIL will allow researchers and engineers to assist utilities in designing, developing, and de-risking algorithms to optimize power grid operation and resilience by considering inputs from millions of grid-connected devices. QIL framework is being developed to have a self-limiting triage mechanism, which will help engineers and practitioners identify fundamental physical limits on quantum processors, revealing what quantum algorithms can and cannot do in utility-specific use cases and must continue to count on classical high-performance computing infrastructure.",IEEE
M. Haghparast; E. Moguel; J. Garcia-Alonso; T. Mikkonen; J. M. Murillo,Innovative Approaches to Teaching Quantum Computer Programming and Quantum Software Engineering,2024,10.1109/QCE60285.2024.10287,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10821196,Conference Paper,2024 IEEE International Conference on Quantum Computing and Engineering (QCE),"Quantum computing is an emerging field that promises to revolutionize various domains, such as simulation optimization, data processing, and more, by leveraging the principles of quantum mechanics. This paper outlines innovative pedagogical strategies developed by university lecturers in Fin-land and Spain for teaching quantum computer programming and quantum software engineering. Our curriculum integrates essential tools and methodologies such as containerization with Docker, Qiskit, PennyLane, and Ocean SDK to provide a comprehensive learning experience. The approach consists of several steps, from introducing the fundamentals of quantum mechanics to hands-on labs focusing on practical use cases. We believe quantum computer programming is an important topic and one that is hard to teach, so having a teaching agenda and guidelines for teaching can be of great help.",IEEE
J. Jiang; J. Zhou; H. Ma; L. Meng,Foot Trajectory Optimization of the Chebyshev Wheel-legged Robot Based on Quantum Particle Swarm Optimization,2023,10.1109/ICMRA59796.2023.10708634,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10708634,Conference Paper,"2023 6th International Conference on Mechatronics, Robotics and Automation (ICMRA)(","To obtain the optimal foot trajectory of the Chebyshev wheel-legged robot and improve its moving speed and obstacle-crossing ability, a method of foot trajectory optimization of the Chebyshev linkage mechanism based on a quantum particle swarm optimization algorithm was proposed. The motion process of the Chebyshev linkage mechanism is analyzed, and the displacement equation of the foot is derived by geometric relation. The design parameters are determined, the objective function of foot trajectory optimization is constructed, the constraint conditions are set, and the optimization coefficient is introduced to adapt to different actual optimization requirements. The elementary particle swarm optimization algorithm and quantum particle swarm optimization algorithm were used to solve the problem, the foot trajectory was drawn through calculation, and the motion performance of the wheel-legged robot was simulated and verified by simulation software. The results show that the quantum particle swarm optimization algorithm has fast convergence speed, strong optimization ability, high solving efficiency, and stronger applicability. The research results can provide a reference scheme for the dimensional design of the Chebyshev wheel-legged robot walking mechanism.",IEEE
A. N. Raikov; M. Pirani,Human-Machine Duality: What¡¯s Next in Cognitive Aspects of Artificial Intelligence?,2022,10.1109/ACCESS.2022.3177657,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9780404,Journal,IEEE Access,"The goal of the paper is to find means for the unification of human-machine duality in collective behavior of people and machines, by conciliating approaches that proceed in opposite directions. The first approach proceeds top-down from non-formalizable, cognitive, uncaused, and chaotic human consciousness towards purposeful and sustainable human-machine interaction. The second approach proceeds bottom-up from intelligent machines towards high-end computing and is based on formalizable models leveraging multi-agent architectures. The resulting work reviews the extent, the merging points, and the potential of hybrid artificial intelligence frameworks that accept the idea of strong artificial intelligence. These models concern the pairing of connectionist and cognitive architectures, conscious and unconscious actions, symbolic and conceptual realizations, emergent and brain-based computing, and automata and subjects. The special authors¡¯ convergent methodology is considered, which is based on the integration of inverse problem-solving on topological spaces, cognitive modelling, quantum field theory, category theory methods, and holonic approaches. It aims to a more purposeful and sustainable human-machine interaction in form of algorithms or requirements, rules of strategic conversations or network brainstorming, and cognitive semantics. The paper addresses the reduction of the impact of AI development on ethics violation. The findings delivered are used to provide perspectives on the shaping of societal, ethical, and normative aspects in the symbiosis between humans and machines. Implementations in real practice are represented.",IEEE
R. W. J. Overwater; M. Babaie; F. Sebastiano,Neural-Network Decoders for Quantum Error Correction Using Surface Codes: A Space Exploration of the Hardware Cost-Performance Tradeoffs,2022,10.1109/TQE.2022.3174017,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9772289,Journal,IEEE Transactions on Quantum Engineering,"Quantum error correction (QEC) is required in quantum computers to mitigate the effect of errors on physical qubits. When adopting a QEC scheme based on surface codes, error decoding is the most computationally expensive task in the classical electronic back-end. Decoders employing neural networks (NN) are well-suited for this task but their hardware implementation has not been presented yet. This work presents a space exploration of fully connected feed-forward NN decoders for small distance surface codes. The goal is to optimize the NN for the high-decoding performance, while keeping a minimalistic hardware implementation. This is needed to meet the tight delay constraints of real-time surface code decoding. We demonstrate that hardware-based NN-decoders can achieve the high-decoding performance comparable to other state-of-the-art decoding algorithms whilst being well below the tight delay requirements $(\approx 440\ \text{ns})$ of current solid-state qubit technologies for both application-specific integrated circuit designs $(< \!30\ \text{ns})$ and field-programmable gate array implementations $(<\! 90\ \text{ns})$. These results indicate that NN-decoders are viable candidates for further exploration of an integrated hardware implementation in future large-scale quantum computers.",IEEE
L. Heng,Fast Clustering Optimization Method of Large-Scale Online Data Flow Based on Evolution Incentive,2014,10.1109/ISDEA.2014.113,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6977642,Conference Paper,2014 Fifth International Conference on Intelligent Systems Design and Engineering Applications,"In order to optimize large-scale online data stream clustering quality and algorithm performance, a fast clustering optimization method is proposed based on line data flow evolution incentive. Firstly, in the online stage, the high density partition algorithm is used to generate micro cluster set, and the set takes the snapshot window as the time scale. The micro cluster set is updated in real-time. In the offline stage, the micro cluster set is read, and the improved quantum genetic algorithm and the evolution incentive function are used for the iterative optimization in clustering center. Finally, the adaptive mutation operator is taken as the optimal variation operation for the populations. The global search ability of the algorithm is improved. Simulation results show that algorithm has better clustering accuracy, and the convergence speed is high with less memory cost. It has good application value in practice.",IEEE
B. RaviTeja; T. S. Balakrishnan,Accurate Forecast Value for Stock Index and Bitcoin Price Using Novel Quantum Enforcing Algorithm in Comparison of Bernstein Vazirani Algorithm,2024,10.1109/ICAIT61638.2024.10690751,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10690751,Conference Paper,2024 Second International Conference on Advances in Information Technology (ICAIT),"This study examines the optimisation of stock index and Bitcoin price forecast with the help of the developed Novel Quantum Enforcing Algorithm (NQEA) and comparing it with the existing Bernstein-Vazirani (BV) Algorithm. The study involves two groups: We have therefore sample sets of 10 in Group 1 using the NQEA and Group 2 using the BV Algorithm. Both algorithms are embedded in technical analysis applications which are very essential when analysing the markets. The given study uses 1400 samples for training purposes and 1856 for testing so that the resultological evaluation was comprehensive. Extreme statistical significance levels are usually fixed at 0. Hypotheses H1 H4: 5 for hypothesis H1 to H4 and 0. 2 for H5, directing the examination of the variability of performance. The findings carried out suggest that the NQEA has an accuracy rate of 95 per cent. 89% that is slightly higher than the accuracy rate of BV Algorithm at 88% thus the two are statistically significantly different $\mathrm{p}=0.001,\mathrm{p} < 0$. In the same way the NQEA has a comparatively smaller loss rate of 11. It has a 99. 80% efficiency, and reliability thus has been commended for its effectiveness. Finally, as it can be depicted through the results of the NQEA, this system offers accurate forecasting with a rate of 95%. 8980% compared to 88. Mean accuracy scores of 69% for the SVM Classifier, and mean accuracy of 00% for the BV Algorithm after 14 iterations under the Test Set of Figures also show the great prospect of the above models in anticipating the directions in the financial",IEEE
M. S. Kaya; K. ?nce,Using Quantum Resistant Variants of NIST IR 8454 Lightweight Encryption Algorithms in Image Encryption,2024,10.1109/IDAP64064.2024.10710906,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10710906,Conference Paper,2024 8th International Artificial Intelligence and Data Processing Symposium (IDAP),"This work examines the potential of quantum resistant variants of NIST IR 8454 lightweight encryption algorithms in the field of image encryption. Selected algorithms from ASCON, TinyJAMBU and SPARKLE families were analyzed using various performance metrics. The research includes entropy analysis, correlation analysis, histogram analysis, NPCR and UACI tests, PSNR and SSIM tests, and calculation speed analysis. The results show that all tested algorithms meet the basic security requirements for image encryption. In particular, an increase in entropy of approximately $13 \%$ in encrypted images, significant reduction in pixel correlations, and high sensitivity to small changes in the input image are observed. While ASCON80pq shows the fastest performance, all algorithms provide basic resistance to quantum attacks. This work reveals that quantumresistant lightweight encryption algorithms are promising for image security, especially in resource-constrained environments such as IoT. However, it is emphasized that these algorithms need to be further investigated in different image types, specific attack scenarios and real-world applications.",IEEE
A. C. Ramos; M. Vellasco,Quantum-inspired Evolutionary Algorithm for Feature Selection in Motor Imagery EEG Classification,2018,10.1109/CEC.2018.8477705,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8477705,Conference Paper,2018 IEEE Congress on Evolutionary Computation (CEC),"In Brain-Computer Interfaces, one of the most relevant tasks is the selection of a subset of features that efficiently describes the EEG signal, excluding redundant and irrelevant features. This procedure reduces the dimensionality of the dataset (avoiding the dimensionality curse) and improves the classification accuracy of the system. One of the most successful models applied for this task is the use of an Evolutionary Algorithm in a wrapper approach. These models produce excellent results but present the drawback of a considerable high processing time, a critical limitation for its application on real Brain-Computer Interfaces (BCI) systems. Quantum-inspired Evolutionary Algorithms can be an alternative wrapper approach for the feature selection task, given that they outperform classical Evolutionary Algorithms in the exploration and exploitation of the search space, obtaining the global solution much faster. These algorithm employs concepts and principles from the Quantum Mechanics to probabilistically describe a set of different states between the classical logic states 0 and 1. In this paper, a Quantum-inspired Evolutionary Algorithm is developed and tested over three different subjects from publicly available datasets. In the proposed model, Wavelet Packet Decomposition is employed to analyze the time-frequency characteristics of the signals, and a Multilayer Perceptron Neural Network is employed as a classifier.",IEEE
A. Shehata; T. Naughton; I. -S. Suh,Integrating Quantum Computing with High-Performance Computing: A Streamlined Approach,2024,10.1109/QCE60285.2024.10413,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10821180,Conference Paper,2024 IEEE International Conference on Quantum Computing and Engineering (QCE),"In recent years, quantum computing has demon-strated the potential to revolutionize specific algorithms and applications by solving problems exponentially faster than classical computers. However, its widespread adoption for general computing remains a future prospect. This paper discusses the integration of quantum computing within High-Performance Computing (HPC) environments, focusing on a resource management framework designed to streamline quantum simulators' use and enhance runtime performance and efficiency. The proposed framework facilitates hybrid applications' transition from simulation backends to real quantum hardware, optimizing resource utilization and providing a flexible infrastructure for developing and testing quantum algorithms.",IEEE
M. Bisheh-Niasar; D. Lo; A. Parthasarathy; B. Pelton; B. Pillilli; B. Kelly,PQC Cloudization: Rapid Prototyping of Scalable NTT /INTT Architecture to Accelerate Kyber,2023,10.1109/PAINE58317.2023.10318029,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10318029,Conference Paper,2023 IEEE Physical Assurance and Inspection of Electronics (PAINE),"The advent of quantum computers poses a serious challenge to the security of cloud infrastructures and services, as they can potentially break the existing public-key cryptosystems, such as Rivest-Shamir-Adleman (RSA) and Elliptic Curve Cryptography (ECC). Even though the gap between today's quantum computers and the threats they pose to current public-key cryptography is large, the cloud landscape should act proactively and initiate the transition to the post-quantum era as early as possible. To comply with that, the U.S. government issued a National Security Memorandum in May 2022 that mandated federal agencies to migrate to post-quantum cryptosystems (PQC) by 2035. To ensure the long-term security of cloud computing, it is imperative to develop and deploy PQC resistant to quantum attacks. A promising class of post-quantum cryptosystems is based on lattice problems, which require polynomial arithmetic. In this paper, we propose a scalable number-theoretic transform (NTT) architecture that significantly enhances the performance of polynomial multiplication. Our proposed design exploits multilevels of parallelism to accelerate the NTT computation on reconfigurable hardware. We use the high-level synthesis (HLS) method to implement our design, which allows us to describe the NTT algorithm in a high-level language and automatically generate optimized hardware code. HLS facilitates rapid prototyping and enables us to explore different design spaces and trade-offs on the hardware platforms. Our experimental results show that our design achieves 11¡Á speedup compared to the state-of-the-art requiring only 14 clock cycles for an NTT computation over a polynomial of degree 256. To demonstrate the applicability of our design, we also present a coprocessor architecture for Kyber that utilizes our scalable NTT core.",IEEE
P. N. Singh; S. Aarthi,Quantum Circuits ¨C An Application in Qiskit-Python,2021,10.1109/ICICV50876.2021.9388498,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9388498,Conference Paper,2021 Third International Conference on Intelligent Communication Technologies and Virtual Mobile Networks (ICICV),"For many practical applications, Quantum computers offer major speed-ups over traditional machines. The production of quantum chips has recently made tremendous strides, with the quantity of Qubits increasing and fidelity increasing. The smallest unit of information is the binary digit i.e. bit in general computing. In Quantum Computing the term Qubit (Quantum Bit) is used for the same purpose. In order to differentiate between a classical bit and a Qubit, Bra-Ket or Dirac notation is used. So, the Qubits are represented as |0¡µ and |1¡µ and are often read as Ket 0 for zero state and Ket 1 for one state. In this paper mainly programming and application sides of Quantum Computing are focused. For that, Qiskit module and its tools are used in Python programming language. General circuit optimization scheme is given. The Quantum circuits with the concept of Quantum Gates implemented are stronger compared to the optimizing algorithm and with faster execution time. In addition, for prime factorization, access to IBM's Quantum computer is carried out successfully.",IEEE
C. Zhang; C. Zhu; Y. Li; M. Nie; Y. Zhu,Path Integral Monte Carlo Quantum Annealing-based Clustering and Routes Optimization of Clustered UAV Network,2021,10.1109/PAAP54281.2021.9720448,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9720448,Conference Paper,"2021 12th International Symposium on Parallel Architectures, Algorithms and Programming (PAAP)","For large-scale and highly mobile unmanned aerial vehicular networks(UAVNets), routes planning plays an important role in energy-efficient data transmission. Based on quantum annealing, we propose a routes planning algorithm to minimize the energy consumption. The simulation results by using the path integration Monte Carlo method show that in the same times of iteration, the quantum annealing algorithm can obtain better results than the simulated annealing algorithm, and the success rates are also greatly improved. Compared with the simulated annealing algorithm, the average energy consumption of the proposed algorithm is reduced by about 21%, and the reliability of the routes programming results is relatively higher according to the simulation results. Quantum annealing-based algorithm can also be used in other combinatorial optimization problem in information network.",IEEE
L. Shuguang; B. Lin,"Progress, Application and Prospect of Quantum Genetic Algorithm",2018,10.1109/ICECOME.2018.8644838,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8644838,Conference Paper,2018 IEEE International Conference on Electronics and Communication Engineering (ICECE),"The quantum genetic algorithm (QGA) is derived from the integration of quantum computation and genetic algorithm. It is characterized with advantages like strong global optimization ability, fast convergence speed and small population size. In this paper, the principle, method and basic flow of quantum genetic algorithm (QGA) are introduced, and the research progress of QGA in recent years is reviewed, including the coding extension of theoretical basis, the innovation of operators, the rotation angle of quantum gates, the optimization of complex high-dimensional functions, and hybrid algorithms, and then he application status of QGA is also discussed. Finally, the future development direction of QGA is put forward.",IEEE
U. Banerjee; A. Pathak; A. P. Chandrakasan,2.3 An Energy-Efficient Configurable Lattice Cryptography Processor for the Quantum-Secure Internet of Things,2019,10.1109/ISSCC.2019.8662528,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8662528,Conference Paper,2019 IEEE International Solid-State Circuits Conference - (ISSCC),"Modern public key protocols, such as RSA and elliptic curve cryptography (ECC), will be rendered insecure by Shor's algorithm [1] when large-scale quantum computers are built. Therefore, cryptographers are working on quantum-resistant algorithms, and lattice-based cryptography has emerged as a prime candidate [1]. However, high computational complexity of these algorithms makes it challenging to implement lattice-based protocols on resource-constrained IoT devices, which need to secure data against both present and future adversaries. To address this challenge, we present a lattice cryptography processor with configurable parameters, which enables up to two orders of magnitude energy savings and 124K-gate reduction in system area through architectural optimizations. The ASIC demonstrates multiple lattice-based protocols proposed in Round 1 of the NIST post-quantum standardization process.",IEEE
J. P. Pinilla; S. J. E. Wilton,Quantum-Assisted Machine Learning Framework: Training and Evaluation of Boltzmann Machines Using Quantum Annealers,2024,10.1109/QCE60285.2024.00197,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10821288,Conference Paper,2024 IEEE International Conference on Quantum Computing and Engineering (QCE),"This paper describes the components and configurations available in a new quantum-assisted machine learning (QAML) framework. QAML is an open source package that provides a new and flexible test-bed for algorithms to train and evaluate Boltzmann machines (BMs) using quantum annealers. Quantum annealing processors enable the training capabilities for both restricted (RBM) and general Boltzmann machines (BM). These methods rely on the fidelity of samples from those devices, which approximate the characteristic Boltzmann distribution of the BM models. The models and optimization functions are built on top of the PyTorch and D-Wave Ocean libraries. The goal of this paper is to introduce developers and researchers to a familiar, yet flexible, software development framework, to explore the use of quantum computing in machine learning applications. The framework is open-source and has been made publicly available.",IEEE
H. Guo; B. Jiang; Y. Wu; S. Wei,Enhancing Quantum Information Encryption System Security: An Optimization Approach with BFGS-Supported VQE Solver,2024,10.1109/ISCIPT61983.2024.10673100,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10673100,Conference Paper,2024 9th International Symposium on Computer and Information Processing Technology (ISCIPT),"With the rapid development in the field of quantum computing, the security of traditional encryption algorithms is facing serious challenges. And quantum key distribution (QKD) provides a new way to solve the key distribution problem, and QKD protocol has become a new hotspot of encryption technology. This research makes a breakthrough in optimizing and applying the unstructured QKD security proof model, which is not only applicable to a variety of QKD protocols, but also dramatically reduces the dependence on mathematical skills for solving the security key. By replacing the original classical optimization solver with a VQE optimization solver based on the BFGS algorithm, this research successfully improves the processing efficiency, simplifies the pairwise constraints, and optimizes the key rate optimization solving algorithm. In practical applications, it successfully implements the secure key rate computation and solving for the QKD protocol BB84 without security vulnerability, the measurement device independent QKD protocol, and the QKD protocol BB84 under laser seed attack. Through these application cases, this project not only verifies the wide applicability of the model, but also significantly improves the computation speed and the accuracy of key rate estimation by improving the key components in the model.",IEEE
W. Ding; C. -T. Lin; M. Prasad; Z. Cao; J. Wang,A Layered-Coevolution-Based Attribute-Boosted Reduction Using Adaptive Quantum-Behavior PSO and Its Consistent Segmentation for Neonates Brain Tissue,2018,10.1109/TFUZZ.2017.2717381,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7953563,Journal,IEEE Transactions on Fuzzy Systems,"The main challenge of attribute reduction in large data applications is to develop a new algorithm to deal with large, noisy, and uncertain large data linking multiple relevant data sources, structured or unstructured. This paper proposes a new and efficient layered-coevolution-based attribute-boosted reduction algorithm (LCQ-ABR*) using adaptive quantum-behavior particle swarm optimization (PSO). First, the quantum rotation angle of an evolutionary particle is updated by a dynamic change of self-adapting step size. Second, a self-adaptive partitioning strategy is employed to group particles into different memeplexes, and the quantum-behavior mechanism with the particles' states depicted by the wave function cooperates to achieve superior performance in their respective memeplexes. Third, a new layered coevolutionary model with multiagent interaction is constructed to decompose a complex attribute set, and it can self-adapt the attribute sizes among different layers and produce the reasonable decompositions by exploiting any interdependence among multiple relevant attribute subsets. Fourth, the decomposed attribute subsets are evolved to compute the positive region and discernibility matrix by using their best quantum particles, and the global optimal reduction set is induced successfully. Finally, extensive comparative experiments are provided to illustrate that LCQ-ABR* has better feasibility and effectiveness of attribute reduction on large-scale and uncertain dataset problems with complex noise as compared with representative algorithms. Moreover, LCQ-ABR* can be successfully applied in the consistent segmentation for neonatal brain three-dimensional MRI, and the consistent segmentation results further demonstrate its stronger applicability.","IEEE, Web of Science"
J. Singh; A. Mani; H. P. Singh; D. S. Rana,Towards Multipartite Adaptive Binary & Real Coded Quantum-Inspired Evolutionary Algorithm for Solving Multi-Objective Unit Commitment Problem with Thermal Units and Wind Farm,2021,10.1109/RDCAPE52977.2021.9633584,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9633584,Conference Paper,"2021 4th International Conference on Recent Developments in Control, Automation & Power Engineering (RDCAPE)","Air pollution, greenhouse gas emission reduction, and scheduling of a large number of generating units with incorporating efficient use of fossil fuels are now the most important issues. The current effort presents a Multipartite Adaptive Binary & Real coded Quantum-inspired Evolutionary Algorithm (MABRQIEA) for the solution of the Unit Commitment Problems (UCP) in power systems. A mathematical model is used to represent the wind-thermal unit commitment problem. The Prospective approach used in the present work is an Evolutionary Algorithm (EAs) inspired by basic principles of quantum computing and is an enhanced variant of the quantum evolutionary algorithm. A repair-based constraint handling method is also used to mollify the constraints. The suggested approach is applied to a test system of 10 units. The approach is applied for 24 hours time duration and results are compared with a well-reputed method.",IEEE
Y. Song; E. H. -M. Sha; L. Xu; Q. Zhuge; Z. Shao,Mera: Memory Reduction and Acceleration for Quantum Circuit Simulation via Redundancy Exploration,2024,10.1109/ICCD63220.2024.00087,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10818024,Conference Paper,2024 IEEE 42nd International Conference on Computer Design (ICCD),"With the development of quantum computing, quantum processor demonstrates the potential supremacy in specific applications, such as Grover's database search and popular quantum neural networks (QNNs). For better calibrating the quantum algorithms and machines, quantum circuit simulation on classical computers becomes crucial. However, as the number of quantum bits (qubits) increases, the memory requirement grows exponentially. In order to reduce memory usage and accelerate simulation, we propose a multi-level optimization, namely Mera, by exploring memory and computation redundancy. First, for a large number of sparse quantum gates, we propose two compressed structures for low-level full-state simulation. The corresponding gate operations are designed for practical implementations, which are relieved from the longtime compression and decompression. Second, for the dense Hadamard gate, which is definitely used to construct the superposition, we design a customized structure for significant memory saving as a regularity-oriented simulation. Meanwhile, an ondemand amplitude updating process is optimized for execution acceleration. Experiments show that our compressed structures increase the number of qubits from 17 to 35, and achieve up to $6.9 \times$ acceleration for QNN.",IEEE
Z. Boreiri; A. N. Azad; N. Majd,Optimized Quantum Circuits in Quantum Image Processing Using Qiskit,2022,10.1109/MVIP53647.2022.9738550,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9738550,Conference Paper,2022 International Conference on Machine Vision and Image Processing (MVIP),"Quantum image representation is an essential component of quantum image processing and plays a critical role in quantum information processing. Flexible Representation of Quantum Images (FRQI) presents pixel colors and associated locations as a state to represent images on quantum computers. A fundamental part of the quantum image processing system is quantum image compression (QIC), which is utilized to maintain and retrieve binary images. This compression allows us to minimize the number of controlled rotation gates in the quantum circuits. This paper designed optimized quantum circuits and simulated them using Qiskit on a real quantum computer based on minimum boolean expressions to retrieve the 8¡Á4 binary single-digit images. To demonstrate the feasibility and efficacy of quantum image representation, quantum circuits for images were developed using FRQI, and quantum image representation experiments were done on IBM Quantum Experience (IBMQ). We were able to visualize quantum information by doing the quantum measurement on the image information that we had prepared. Without utilizing this method, the number of controlled rotation gates is equal to the number of pixels in the image; however, we showed that by using the QIC algorithm, we could decrease the number of gates significantly. On these images, the maximum and minimum compression ratios of QIC are 90.63% and 68.75%, respectively.",IEEE
Q. Zhang; O. Ayoub; A. Gatto; J. Wu; F. Musumeci; M. Tornatore,"Routing, Channel, Key-Rate, and Time-Slot Assignment for QKD in Optical Networks",2024,10.1109/TNSM.2023.3290920,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10168191,Journal,IEEE Transactions on Network and Service Management,"Quantum Key Distribution (QKD) is currently being explored as a solution to the threats posed to current cryptographic protocols by the evolution of quantum computers and algorithms. However, single-photon quantum signals used for QKD permit to achieve key rates strongly limited by link performance (e.g., loss and noise) and propagation distance, especially in multi-node QKD networks, making it necessary to design a scheme to efficiently and timely distribute keys to the various nodes. In this work, we introduce the new problem of joint Routing, Channel, Key-rate and Time-slot Assignment (RCKTA), which is addressed with four different network settings, i.e., allowing or not the use of optical bypass (OB) and trusted relay (TR). We first prove the NP-hardness of the RCKTA problem for all network settings and formulate it using a Mixed Integer Linear Programming (MILP) model that combines both quantum channels and quantum key pool (QKP) to provide an optimized solution in terms of number of accepted key rate requests and key storing rate. To deal with problem complexity, we also propose a heuristic algorithm based on an auxiliary graph, and show that it is able to obtain near-optimal solutions in polynomial time. Results show that allowing OB and TR achieves an acceptance ratio of 39% and 14% higher than that of OB and TR, respectively. Remarkably, these acceptance ratios are obtained with up to 46% less QKD modules (transceivers) compared to TR and only few (less than 1 per path) additional QKD modules than OB.",IEEE
X. Li; Y. Zhao; X. Yu; H. Wang; W. Chen; S. Wang; J. Zhang,Joint Bandwidth and Key on Demand (BKoD) Provisioning for Dynamic Service of Optical Transport Networks in F6G,2024,10.1109/TNSM.2024.3387758,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10509634,Journal,IEEE Transactions on Network and Service Management,"In the sixth-generation fixed network (F6G), network security becomes an important topic. Encryption is an effective method to prevent network attacks and realize network security. Quantum key distribution (QKD) is a promising technology to effectively address the challenge by providing secret keys due to the laws of quantum physics. New services such as high immersion experience and holographic have the characteristics of time-varying bandwidth and requirements. The introduction of optical service unit (OSU) technology makes it possible to provide the exact bandwidth used by the service. In optical transport networks, a lightpath needs to be established before service transmission, and will be removed after service transmission. Signaling is used for lightpath establishment, removal, and bandwidth adjustment. Data information transmitted in data layer and signaling information transmitted in control layer are highly vulnerable to cyberattacks, such as eavesdropping. The supply of bandwidth and key resources need to be optimized to achieve secure and stable service transmission in optical networks. Hence, how to realize bandwidth and key on demand (BKoD) provisioning for dynamic services is a key problem. To improve the flexibility of bandwidth and key resource allocation and utilization, a QKD-secured OSU-based optical transport network can be deployed. In this paper, a novel QKD-secured OSU-based optical transport network architecture is proposed and a service aware dynamic resource provisioning (SADRP) algorithm is proposed to realize BKoD. The proposed architecture uses the QKD technique to provide keys for both signaling information and data information for the first time. The proposed algorithm supplies resources according to the dynamic demand of bandwidth and key, so as to achieve the balance between dynamic demand and static resource utilization. Simulations results show that compared with the benchmark algorithm, the SADRP algorithm reduces blocking probability by 4.16%, reduces bandwidth resource utilization rate by 4.39%, reduces key resource utilization rate by 3.48%, and improves security rate by 4.17%.",IEEE
H. -W. Chiang; C. -F. Nien; H. -Y. Cheng; K. -P. Huang,ReAIM: A ReRAM-based Adaptive Ising Machine for Solving Combinatorial Optimization Problems,2024,10.1109/ISCA59077.2024.00015,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10609617,Conference Paper,2024 ACM/IEEE 51st Annual International Symposium on Computer Architecture (ISCA),"Recently, in light of the success of quantum computers, research teams have actively developed quantum-inspired computers using classical computing technology. One notable success story is the Ising Machine (IM), which excels in efficiently solving NP-hard combinatorial optimization problems (COPs) in various domains such as finance, drug development, and logistics. However, IMs may encounter the von Neumann bottleneck due to significant data transfers between computing and memory units. To tackle this issue, processing-in-memory (PiM) leveraging resistive random-access memory (ReRAM) has emerged as a potential solution. Nonetheless, existing ReRAM-based IM accelerators face challenges stemming from non-ideal ReRAM devices and the limited flexibility in selecting solver algorithms. To overcome these limitations, we propose ReAIM, a ReRAMbased Adaptive Ising Machine, co-designed with an adaptive parameter search algorithm to dynamically select an appropriate solver algorithm and hardware/software parameters for the target COP. Based on our in-depth analysis, ReAIM accounts for the impact of both software parameters, such as the choice of local search algorithm and the number of spin flips, and hardware characteristics, including ReRAM-induced errors. Its reconfigurable architecture and optimized mapping/scheduling strategies enable efficient execution of the adaptive algorithm across various COPs, even for large-scale problems. Compared to the state-of-the-art SRAM-based IM accelerator, ReAIM achieves a $2.2 \times$ shorter time-to-solution (TTS), showcasing superior hardware performance without compromising solution quality.",IEEE
C. Yooyuen; R. Bavontaweepanya; P. Prechaprapranwong; R. Sarochawikasit,Quantum Benchmark Suite for IBM's Backend Based on SupermarQ,2024,10.1109/JCSSE61278.2024.10613716,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10613716,Conference Paper,2024 21st International Joint Conference on Computer Science and Software Engineering (JCSSE),"The benchmark of Noisy Intermediate-Scale Quantum (NISQ) computers plays a major role in the research and development of quantum devices and algorithms. Our study aims to investigate a single metric of benchmarking for the Noisy Intermediate-Scale Quantum device. We use state-of-the-art applications to generate a device-score according to our proposed formula. Our study utilizes Quantum Volume (QV) to determine the qubit circuit size for each device. Furthermore, we utilize SupermarQ to determine each application's benchmark score, utilizing their 5 feature vectors to indicate the circuit performance, and applying their circuit optimization techniques to configure the transpiler. Our experiment shows that device-score of the simulated IBM backend are directly correlated to Quantum Volume. However, it should be noted that topology and gate error are also embedded in the benchmark scores of the applications. Because of this, our study introduces the device-score, a single number metric that provides a more precise scale with the assistance of Quantum Volume and SupermarQ.",IEEE
J. E. Ruiz; P. H. Pereira; G. M. Penello; G. M. Torelly; P. L. Souza; M. P. Pires,Mapping and Optimization of Oscillator Strength in Quantum Bragg Mirror Detectors as a Function of their Dimensions,2023,10.1109/SBMicro60499.2023.10302557,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10302557,Conference Paper,2023 37th Symposium on Microelectronics Technology and Devices (SBMicro),"In this work, we estimate the oscillator strength of the optical transitions in quantum Bragg mirror detectors (QBMDs) and determine which structure provides its maximum value. The thicknesses of the quantum wells (QWs) and barriers of the probed structures strongly influence the wavefunctions and, thus, the optical transitions of the active region. For this reason, the structure geometry must be carefully chosen to achieve high oscillator strength at the desired operation energy. Since the QBMD has several QWs and barriers to be optimized, we have performed a series of approximately 350,000 simulations to map the transition energy and the oscillator strength to fully understand the role played by the thickness of each layer of a base structure with 7 quantum wells in total. Due to the computational cost of conducting these simulations for every possible configuration, we shifted to genetic algorithms to find optimal solutions with less constraints in the simulation. Finally, we present a validation of our genetic algorithm, which shows that it consistently finds high-performing structures as validated by the high oscillator strength values obtained. Overall, our study highlights the promising potential of genetic algorithms as a powerful tool for optimizing the properties of QBMDs.",IEEE
T. -F. Chen; J. -H. R. Jiang; M. -H. Hsieh,Partial Equivalence Checking of Quantum Circuits,2022,10.1109/QCE53715.2022.00082,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9951285,Conference Paper,2022 IEEE International Conference on Quantum Computing and Engineering (QCE),"Equivalence checking of quantum circuits is an essential element in quantum program compilation, in which a quantum program can be synthesized into different quantum circuits that may vary in the number of qubits, initialization requirements, and output states. Verifying the equivalences among the implementation variants requires proper generality. Although different notions of quantum circuit equivalence have been defined, prior methods cannot check observational equivalence between two quantum circuits whose qubits are partially initialized, which is referred to as partial equivalence. In this work, we prove a necessary and sufficient condition for two circuits to be partially equivalent. Based on the condition, we devise algorithms for checking quantum circuits whose partial equivalence cannot be verified by prior approaches. Experiment results confirm the generality and demonstrate the efficiency and effectiveness of our method. Our result may unleash the optimization power of quantum program compilation to take more aggressive steps.",IEEE
D. Dong; C. -C. Shu; J. Chen; X. Xing; H. Ma; Y. Guo; H. Rabitz,Learning Control of Quantum Systems Using Frequency-Domain Optimization Algorithms,2021,10.1109/TCST.2020.3018500,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9184981,Journal,IEEE Transactions on Control Systems Technology,"We investigate two classes of quantum control problems by using frequency-domain optimization algorithms in the context of ultrafast laser control of quantum systems. In the first class of problems, the system model is known and a frequency-domain gradient-based optimization algorithm is applied for searching an optimal control field to selectively and robustly manipulate the population transfer in atomic rubidium. The other class of quantum control problems involves an experimental system with an unknown model. In this case, we introduce a differential evolution algorithm with a mixed strategy to search for optimal control fields and demonstrate the capability in an ultrafast laser control experiment for the fragmentation of Pr(hfac)3 molecules.",IEEE
A. Singh; Y. Kumar; P. Yadav; N. Tripathi; A. Bhargava; A. Rana,Overcoming Quantum Hardware Challenges: Navigating the Landscape of Quantum Computing,2024,10.1109/IC3SE62002.2024.10593317,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10593317,Conference Paper,"2024 International Conference on Communication, Computer Sciences and Engineering (IC3SE)","Quantum computing has surfaced as a revolutionary idea with the potential to transform industries ranging from cryptography to drug discovery. However, alongside its promise, quantum computing faces formidable challenges, particularly in the realm of hardware development and scalability. One of the central challenges lies in the creation and scaling of dependable hardware infrastructure. At present, quantum computers can only manipulate a limited number of qubits for brief periods before succumbing to noise-induced disruptions. This constraint severely curtails their ability to execute complex computations and address real-world problems with efficiency. Furthermore, the relentless march towards miniaturization presents a significant hurdle. As transistors shrink in size, quantum effects increasingly interfere with their behavior, posing a barrier to further hardware miniaturization and scalability. Moreover, the quest to increase qubit counts stands as a pivotal milestone in advancing quantum computing capabilities. However, achieving higher qubit counts is fraught with challenges. These include the maintenance of qubit coherence and stability, the mitigation of unwanted inter-qubit interactions, and overcoming logistical hurdles in fabrication and control systems. Each of these challenges presents a significant roadblock on the path to realizing the full potential of quantum computing. Despite these formidable obstacles, researchers and scientists are actively engaged in the pursuit of solutions. Through innovative approaches and rigorous experimentation, they are striving to overcome the barriers impeding hardware development and scalability. By addressing these challenges, quantum computing stands poised to unlock unprecedented computational power and drive breakthroughs in fields ranging from optimization and machine learning to materials science and beyond. Thus, while the road ahead may be fraught with challenges, the transformative potential of quantum computing compels us to persevere in our quest to harness the power of the quantum realm.",IEEE
S. M. S; C. R. Byrareddy,Optimization of MIMO RADAR Waveform: Classical and QPSO Technique,2023,10.1109/ICAECIS58353.2023.10170054,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10170054,Conference Paper,"2023 International Conference on Advances in Electronics, Communication, Computing and Intelligent Information Systems (ICAECIS)","The optimization of MIMO RADAR waveform using hybrid approach of classical and Quantum Particle Swarm Optimization (QPSO) Technique has been effectively utilized in the design of Antenna system. In this system, three particles were selected as Code1, Code2 and Code3 in QPSO Technique using MATLAB. The simulated results for the designed systems have been evaluated based on the uniform distribution and normal distribution. The process has been evaluated for the band width of 5 MHz and a pulse width of 100 and 150 ?s. The technique has been designed in such a way that the range of value of maximum Auto side lobe peak value (ASP) and minimum cross correlation peak (CP) value should be with in 1 and 0. The designed algorithm using aforesaid codes justifies the simulated results. The obtained results are in good agreement with the designed algorithm. The wave forms suggested that designed process parameters are well within the simulated range of the system. The correlation combination of all the three codes suggested the best combination of codes to be used in the system.",IEEE
N. Quetschlich; L. Burgholzer; R. Wille,Predicting Good Quantum Circuit Compilation Options,2023,10.1109/QSW59989.2023.00015,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10234267,Conference Paper,2023 IEEE International Conference on Quantum Software (QSW),"Any potential application of quantum computing, once encoded as a quantum circuit, needs to be compiled in order to be executed on a quantum computer. Deciding which qubit technology, which device, which compiler, and which corresponding settings are best for the considered problem¡ªaccording to a measure of goodness¡ªrequires expert knowledge and is overwhelming for end-users from different domains trying to use quantum computing to their advantage. In this work, we treat the problem as a statistical classification task and explore the utilization of supervised machine learning techniques to optimize the compilation of quantum circuits. Based on that, we propose a framework that, given a quantum circuit, predicts the best combination of these options and, therefore, automatically makes these decisions for end-users. Experimental evaluations show that, considering a prototypical setting with 3000 quantum circuits, the proposed framework yields promising results: for more than three quarters of all unseen test circuits, the best combination of compilation options is determined. Moreover, for more than 95% of the circuits, a combination of compilation options within the top-three is determined¡ªwhile the median compilation time is reduced by more than one order of magnitude. Furthermore, the resulting methodology not only provides end-users with a prediction of the best compilation options, but also provides means to extract explicit knowledge from the machine learning technique. This knowledge helps in two ways: it lays the foundation for further applications of machine learning in this domain and, also, allows one to quickly verify whether a machine learning algorithm is reasonably trained. The corresponding framework and the pre-trained classifier are publicly available on GitHub (https://github.com/cda-tum/MQTPredictor) as part of the Munich Quantum Toolkit (MQT).",IEEE
K. N. Smith; M. A. Thornton,Quantum Logic Synthesis with Formal Verification,2019,10.1109/MWSCAS.2019.8885132,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8885132,Conference Paper,2019 IEEE 62nd International Midwest Symposium on Circuits and Systems (MWSCAS),"Quantum computers capable of practical information processing are emerging rapidly. As these devices become more advanced, tools will be needed for converting generalized quantum algorithms into formally-verified forms that are executable on real quantum machines. In this work, a prototype tool is presented that transforms quantum algorithms into executable specifications where optimization procedures yield 9-24 % cost improvement on a range of benchmarks. Additionally, the tool incorporates formal verification internally with Quantum Multiple-valued Decision Diagrams to confirm that the generated technology-dependent executable is functionally equivalent to the original, technology-independent algorithm. Experimental results are provided that target the Rigetti family of quantum processing units although the tool may also target other architectures.",IEEE
S. Jannu; S. Dara; C. Thuppari; A. Vidyarthi; D. Ghosh; P. Tiwari; G. Muhammad,Energy Efficient Quantum-Informed Ant Colony Optimization Algorithms for Industrial Internet of Things,2024,10.1109/TAI.2022.3220186,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9941476,Journal,IEEE Transactions on Artificial Intelligence,"One of the most prominent research areas in information technology is the Internet of Things (IoT) as its applications are widely used, such as structural monitoring, health care management systems, agriculture and battlefield management, and so on. Due to its self-organizing network and simple installation of the network, the researchers have been attracted to pursue research in the various fields of IoTs. However, a huge amount of work has been addressed on various problems confronted by IoT. The nodes densely deploy over critical environments and those are operated on tiny batteries. Moreover, the replacement of dead batteries in the nodes is almost impractical. Therefore, the problem of energy preservation and maximization of IoT networks has become the most prominent research area. However, numerous state-of-the-art algorithms have addressed this issue. Thus, it has become necessary to gather the information and send it to the base station in an optimized method to maximize the network. Therefore, in this article, we propose a novel quantum-informed ant colony optimization (ACO) routing algorithm with the efficient encoding scheme of cluster head selection and derivation of information heuristic factors. The algorithm has been tested by simulation for various network scenarios. The simulation results of the proposed algorithm show its efficacy over a few existing evolutionary algorithms using various performance metrics, such as residual energy of the network, network lifetime, and the number of live IoT nodes.",IEEE
S. Kan; Z. Du; M. Palma; S. A. Stein; C. Liu; W. Wei; J. Chen; A. Li; Y. Mao,Scalable Circuit Cutting and Scheduling in a Resource-Constrained and Distributed Quantum System,2024,10.1109/QCE60285.2024.00127,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10821424,Conference Paper,2024 IEEE International Conference on Quantum Computing and Engineering (QCE),"Despite rapid developments in quantum computing, current systems remain limited in practical applications due to their constrained qubit counts and quality. Technologies such as superconducting, trapped ions, and neutral atom quantum computing are progressing towards fault tolerance. However, they face challenges in scalability and control. Recent efforts have concentrated on multi-node quantum systems that connect smaller quantum devices to execute larger circuits. Future demonstrations aim to utilize quantum channels for system coupling, but current methods often resort to classical communication with circuit cutting techniques. This involves dividing large circuits into smaller subcircuits and reconstructing them after execution. Existing cutting methods face challenges such as lengthy search times with increasing numbers of qubits and gates. Moreover, they often struggle to efficiently use resources across various worker configurations in a multi-node system. To address these challenges, we propose FitCut, a novel approach that transforms quantum circuits into weighted graphs. FitCut employs a community-based, bottom-up approach to cut circuits based on resource constraints such as qubit counts on each worker. Additionally, it includes a scheduling algorithm that optimizes resource utilization across workers. Implemented with Qiskit and evaluated extensively, FitCut significantly outperforms existing tools such as Qiskit Circuit Knitting Toolbox, reducing time costs by factors ranging from 3 to 2000 and improving resource utilization rates by up to 388% on the worker side, leading to a system-wide improvement of 286% in accumulated circuit depth.",IEEE
D. Ozog; A. Kamil; Y. Zheng; P. Hargrove; J. R. Hammond; A. Malony; W. de Jong; K. Yelick,A Hartree-Fock Application Using UPC++ and the New DArray Library,2016,10.1109/IPDPS.2016.108,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7516041,Conference Paper,2016 IEEE International Parallel and Distributed Processing Symposium (IPDPS),"The Hartree-Fock (HF) method is the fundamental first step for incorporating quantum mechanics into many-electron simulations of atoms and molecules, and it is an important component of computational chemistry toolkits like NWChem. The GTFock code is an HF implementation that, while it does not have all the features in NWChem, represents crucial algorithmic advances that reduce communication and improve load balance by doing an up-front static partitioning of tasks, followed by work stealing whenever necessary. To enable innovations in algorithms and exploit next generation exascale systems, it is crucial to support quantum chemistry codes using expressive and convenient programming models and runtime systems that are also efficient and scalable. This paper presents an HF implementation similar to GTFock using UPC++, a partitioned global address space model that includes flexible communication, asynchronous remote computation, and a powerful multidimensional array library. UPC++ offers runtime features that are useful for HF such as active messages, a rich calculus for array operations, hardware-supported fetch-and-add, and functions for ensuring asynchronous runtime progress. We present a new distributed array abstraction, DArray, that is convenient for the kinds of random-access array updates and linear algebra operations on block-distributed arrays with irregular data ownership. We analyze the performance of atomic fetch-and-add operations (relevant for load balancing) and runtime attentiveness, then compare various techniques and optimizations for each. Our optimized implementation of HF using UPC++ and the DArrays library shows up to 20% improvement over GTFock with Global Arrays at scales up to 24,000 cores.",IEEE
J. Tian; B. Wu; Z. Wang,High-Speed FPGA Implementation of SIKE Based on an Ultra-Low-Latency Modular Multiplier,2021,10.1109/TCSI.2021.3094889,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9501949,Journal,IEEE Transactions on Circuits and Systems I: Regular Papers,"The supersingular isogeny key encapsulation (SIKE) protocol, as one of the post-quantum protocol candidates, is widely regarded as the best alternative for curve-based cryptography. However, the long latency, caused by the serial large-degree isogeny computation which is dominated by modular multiplications, has made it less competitive than most popular post-quantum candidates. In this paper, we propose a high-speed and low-latency architecture for our recently presented optimized SIKE algorithm. Firstly, we design a new field arithmetic logic unit (FALU) with many algorithmic transformations and architectural optimizations. Especially, for the FALU, an extremely low-latency modular multiplier is devised based on a modified algorithm by fully parallelizing and highly optimizing the small-size multipliers and the reduction submodules. Secondly, we develop a compact control logic and update the instructions based on the benchmark provided in the newest SIKE library, fitting well with our design. Thirdly, an efficient memory access method is proposed by scheduling the input and output of the arithmetic logic unit (ALU) in two identical RAMs, which can significantly reduce the latency. Finally, we code the proposed architectures using the Verilog language and integrate them into the SIKE library. The implementation results on a Xilinx Virtex-7 FPGA show that for SIKEp751, our design only costs 9.3 ms with a frequency of 155.8 MHz, about 2¡Á faster than the state-of-the-art, and achieves the best area efficiency among existing works. Particularly, the modular multiplier merely needs 16 clock cycles, reducing the delay by nearly one order of magnitude with a small factor of increase in hardware resource.",IEEE
R. -G. Li; H. -N. Wu,Iterative Approach With Optimization-Based Execution Scheme for Parameter Identification of Distributed Parameter Systems and its Application in Secure Communication,2020,10.1109/TCSI.2020.2983570,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9062304,Journal,IEEE Transactions on Circuits and Systems I: Regular Papers,"This paper addresses a general method for parameter identification in distributed parameter systems (DPSs) based on a reference model and measurement information. Moreover, the developed identification method is used to deal with secure communication problems. Firstly, in combination with the historical information measured by sensors, an iterative approach based on an approximator is put forward. Meanwhile, an execution scheme for the iterative approach is provided by an optimization policy. Subsequently, by bringing new mechanisms into quantum particle swarm optimization (QPSO) algorithm to enhance its search capability, we propose quantum-leading-following-based optimization (QLFBO) algorithm, which serves the optimization policy. Further, the global convergence for QLFBO algorithm is proved combined with the parameter identification problem of DPSs, and the computational complexity on this algorithm is discussed in detail. Finally, simulation experiments on the diffusion-reaction model are carried out by the iterative approach based on QLFBO algorithm under different measurement ways. Simultaneously, secure communication depending on this model is performed in the double-scroll Chua's circuit and a lotus image via the investigated iterative strategy and encryption-decryption scheme. Simulation results verify the validity and practicability of the developed method.",IEEE
A. Khot; T. Kim; A. R. Akash; C. H. Kim; W. Moy,Quantum-Inspired Machine Learning Framework using a Physics-based Ising Solver Chip,2024,10.1109/ICPS59941.2024.10639986,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10639986,Conference Paper,2024 IEEE 7th International Conference on Industrial Cyber-Physical Systems (ICPS),"Quantum machine learning (QML) is transforming the field of machine learning (ML), which typically utilizes a quantum computing such as gate model-based and annealing-based computing. Recently, Ising solver chips have been developed to emulate the superposition and entanglement properties of quantum physics using the current silicon manufacturing technologies. The chips have potential to solve complex combinatorial optimization problems (COP) with significantly low power consumption and price. This paper proposes quantum-inspired ML (QiML) framework that provides an approach to train the traditional ML models using a physics-based Ising solver chip to develop QiMLs. To validate the feasibility of the proposed framework, a quantum-inspired support vector machine (QiSVM) is developed and the results are compared with a quantum SVM trained by a commercial D-Wave quantum annealer and a conventional SVM to solve real-world problems. The proposed QiML framework will open new frontiers for advancing ML technologies for industry cyber-physical system applications.",IEEE
M. Graber; M. Wesp; K. Hofmann,A Fast Graph Minor Embedding Heuristic for Oscillator Based Ising Machines,2022,10.1109/Austrochip56145.2022.9940722,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9940722,Conference Paper,2022 Austrochip Workshop on Microelectronics (Austrochip),"The demand for high-efficient computing power is constantly increasing. While digital CMOS designs are dom-inating, more research is focusing on novel computing ar-chitectures. Recently, so-called Oscillator-based Ising Machines (OIMs) have become a promising computing approach, which can solve optimization problems using configurable coupling between oscillators. OIMs are based on well-established CMOS silicon technologies and can even be integrated with a processor as hard-ware accelerators. Similarly to quantum computing, OIMs solve graph problems by directly representing them in their hardware. Consequently, the nodes and edges of a problem graph must be mapped to the available hardware-specific network. Since such graph embedding is required before every computation, it has a crucial impact on performance. We propose a heuristic embedding algorithm to transform quickly and efficiently an input problem onto a target hardware. The heuristic is optimized for OIM systems and supports various hardware topologies including routing channels. Using the heuristic algorithm, we analyze different hardware topologies to further improve OIM designs.",IEEE
P. Gokhale; C. Carnahan; W. Clark; T. Tomesh; F. T. Chong,"Deep Learning for Low-Latency, Quantum-Ready RF Sensing",2024,10.1109/QCE60285.2024.00158,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10821350,Conference Paper,2024 IEEE International Conference on Quantum Computing and Engineering (QCE),"Recent work has shown the promise of applying deep learning to enhance software processing of radio frequency (RF) signals. In parallel, hardware developments with quantum RF sensors based on Rydberg atoms are breaking longstanding barriers in frequency range, resolution, and sensitivity. In this paper, we describe our implementations of quantum-ready machine learning approaches for RF signal classification. Our primary objective is latency: while deep learning offers a more powerful computational paradigm, it also traditionally incurs latency overheads that hinder wider scale deployment. Our work spans three axes. (1) A novel continuous wavelet transform (CWT) based recurrent neural network (RNN) architecture that enables flexible online classification of RF signals on-the-fly with reduced sampling time. (2) Low-latency inference techniques for both GPU and CPU that span over 100x reductions in inference time, enabling real-time operation with sub-millisecond inference. (3) Quantum-readiness validated through application of our models to physics-based simulation of Rydberg atom QRF sensors. Altogether, our work bridges towards next-generation RF sensors that use quantum technology to surpass previous physical limits, paired with latency-optimized AI/ML software that is suitable for real-time deployment.",IEEE
S. Fadli; B. S. Rawal,Hybrid Quantum-Classical Machine Learning for Near Real-time Space to Ground Communication of ISS Lightning Imaging Sensor Data,2023,10.1109/CCWC57344.2023.10099338,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10099338,Conference Paper,2023 IEEE 13th Annual Computing and Communication Workshop and Conference (CCWC),"Near real-time sensor data is growing exponentially faster than our ability to sense and make sense of it as the current classical computing and supercomputing approaches require an enormous volume of computational resources, storage, and training time. Quantum computing is posed to exponentially outperforms today's high-performance computers and accelerate the evolution of information occurring in classical systems and sensor networks. The Lightning Imaging Sensor (LIS) mounted on the International Space Station (ISS) locates, senses, and detects lightning activities from low Earth orbit and measures radiant energy at millisecond timing over a broad regional spectrum. In this paper, we are introducing a space-to-ground hybrid quantum-classical machine learning architecture to demonstrate the application potential and the feasibility of Hybrid Quantum Neural Networks using the ISS LIS lightning dataset and a corresponding background dataset as inputs (1) to train a classical deep neural network model (2) where the feature extraction outputs are encoded as quantum states using multiple calibrated quantum encoding patterns (3) then used as part of a quantum feature mapping process, (4) allowing for enhanced hybrid QNN training, optimization, and auto-differentiation, setting the path towards polynomial advantage. The following is how the rest of the paper is structured: The introduction is covered in section I, and the motivation and our contribution are covered in section II. Section III presents related works. Section IV describes the NRT lightning imaging sensor. Section V describes the space- to-ground hybrid quantum architecture. Section VI. Space-to-ground hybrid quantum-classical machine learning architecture. Section VII describes quantum machine learning. Section VIII presents a performance analysis. Finally, section XI concludes the research paper.",IEEE
N. Nithya; S. Itapu,Design Of Low Area Interconnect Architecture for CPU-GPU Network-On-Chips (NoCs),2023,10.1109/CONECCT57959.2023.10234778,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10234778,Conference Paper,"2023 IEEE International Conference on Electronics, Computing and Communication Technologies (CONECCT)","This paper¡¯s major objective is to suggest a creative strategy for improving CPU performance in real-time operating systems by developing a fresh way for the round-robin CPU scheduling algorithm. Round-robin and priority scheduling methods are combined in the proposed method to create the Priority based Round-Robin CPU Scheduling algorithm. This algorithm addresses the starvation prevention issue present in round-robin scheduling while including the benefits of priority ordering. By giving different priorities to processes, it also adds the idea of ageing. Due to its flaws, such as high context transition rates, prolonged wait times, lengthy responses, prolonged turnaround times, and limited throughput, the current round-robin CPU scheduling algorithms are not suited for real-time operating systems. These restrictions are removed by the suggested approach, which also fixes the round-robin algorithm¡¯s problems. The study compares the proposed algorithm with the existing round-robin scheduling method based on a number of variables, including time quantum, average waiting time, average turnaround time, and number of context shifts, in order to assess its efficacy. Although the semiconductor industry has a lot of interest in CPU-GPU multi-core research, the problems raised in the literature have not yet been solved. This project focuses on the creation of a novel heterogeneous crossbar style network-on-chip (NoC) that connects heterogeneous CPU-GPU processors in order to overcome these issues.",IEEE
Y. Ruan; L. Yuan; W. Yuan; Y. He; L. Lu,Temperature Compensation and Pressure Bias Estimation for Piezoresistive Pressure Sensor Based on Machine Learning Approach,2021,10.1109/TIM.2021.3089236,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9454454,Journal,IEEE Transactions on Instrumentation and Measurement,"The requirements for accuracy of piezoresistive pressure sensors in modern society are becoming increasingly high. Besides, a wide application range of sensor is required. However, due to the influence of material properties, many piezoresistive pressure sensors have high temperature coefficient, which limits their application temperature range. With the change of ambient temperature, the response characteristic of the sensor has strong nonlinearity. To solve the above-mentioned crucial problems, a dynamic chaos quantum-behaved particle swarm optimization optimized multiple kernel relevance vector machine (DCQPSO-MKRVM) algorithm is presented in this article. First, a basic theory of temperature effect is given and a new idea of temperature compensation is proposed. Second, the multi-kernel relevance vector machine (MKRVM) is adopted to estimate the bias values of input pressure. Through heterogeneous kernel learning method, the kernels of MKRVM maintain diversity to obtain higher estimation accuracy. Third, dynamic chaos quantum-behaved particle swarm optimization (DCQPSO) is employed to optimize the optimal sparse weights of kernel functions in MKRVM. Moreover, the dynamic parameter is applied for the boundary of chaos search between original quantum-behaved particle swarm optimization (QPSO) swarm and the chaos swarm. The experimental result indicates the complex nonlinear relationship of temperature effect, and the method proposed in this article can effectively and accurately estimate the bias of input pressure fast to achieve temperature compensation goal. The mean relative accuracy (MRA) of estimation results achieves 99.5%. It proves that the method proposed in this article is applicable and effective for industrial applications.",IEEE
S. Hu; P. Liu; C. -F. Chen; M. Pistoia,Poster: Automatically Solving NP-Complete Problems on a Quantum Computer,2018,10.1145/3183440.3194959,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8449528,Conference Paper,2018 IEEE/ACM 40th International Conference on Software Engineering: Companion (ICSE-Companion),"In recent years, tremendous efforts from both the industrial and the academic research communities have been put into bringing forth quantum computing technologies. With the potential proliferation of universal quantum computers on the horizon, quantum computing, however, is still severely grounded by numerous grave barriers, which lead to its low accessibility and practicality. For example, the vastly different underlying computing models, combined with the steep background knowledge requirements, makes it extremely difficult, if possible at all, for most software engineering researchers and practitioners to even begin to design or implement quantum algorithms or softwares in practice. To overcome this problem, we, in this paper, propose a design that largely circumvents said accessibility and practicality barriers, by providing an end-to-end quantum computing framework for solving NP-complete problems via reduction. We fully implemented a toolkit under our design framework. With this toolkit, software engineering researchers and practitioners would be able to enjoy the speedup and scalability benefits of universal quantum computers without necessarily having to have prior knowledge on quantum computing.",IEEE
M. N. Arira; J. Suryana,Design and Implementation of a Transmitter for Quantum Communication Based on Faint Pulse Laser,2023,10.1109/TSSA59948.2023.10366900,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10366900,Conference Paper,"2023 17th International Conference on Telecommunication Systems, Services, and Applications (TSSA)","The advent of quantum computers marks the beginning of the quantum 2.0 era. Unlike classical computers, quantum computers have faster and more efficient computational abilities, enabling them to break classical encryption such as the RSA (Rivest-Shamir-Adlemar) algorithm in a matter of minutes. To address this threat, a quantum communication system is required, which possesses quantum properties as well. The urgency of developing an independent and autonomous quantum communication system is crucial for a country. In this research, a transmitter for quantum communication based on faint pulse laser is developed. A weakened laser diode is used as the photon source. The laser diode weakening is achieved using a laser driver that generates short-duration pulse signals. By combining AND and XOR logic gates in such a way that when given a square wave input, the output of the logic gate system can produce short-duration pulses. The information in this communication system consists of randomly implemented keys, realized using the myRIO board and serving as a subsystem for random port selection. The designed laser driver produces pulse signals with a width of 128 nanoseconds and an amplitude of 1.5168 V. Additionally, the random port selection subsystem has been successfully designed using the myRIO board. Random numbers from ¡®0¡¯ to ¡®3¡¯ are generated uniformly. From 100 observation samples, an expected value of 1.445 and a variance of 0.911 are obtained. In the subsequent research, observations of single photon and the generated keys will be conducted.",IEEE
G. R. Figlarz; F. P. Hessel,Applied Post-Quantum Secure Method for IoT Devices: A Case Study for Autonomous Vehicles Communication,2022,10.1109/WF-IoT54382.2022.10152075,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10152075,Conference Paper,2022 IEEE 8th World Forum on Internet of Things (WF-IoT),"Autonomous vehicles (AV) have as one of their characteristics the constant exchange of data with other vehicles, radio base stations, pedestrians and infrastructure. Despite this data exchange using the most modern security techniques, vehicles have been the target of constant cyber-attacks. Emerging technologies such as quantum computing have been tested to minimize these attacks. Particularly, this work investigates the possibility of using post-quantum computing techniques in IoT (Internet of Things) devices, more specifically in AVs. Considering the functionalities of a vehicle nowadays, it is possible to say that a vehicle is composed of a set of IoT devices. Therefore, in this paper, we propose a post-quantum secure method to be used in IoT devices for data exchange between AVs and a 5G base station. In this method, the post-quantum algorithm NTRU is implemented in an edge computing IoT architecture between the source of the CVs data and the edge layer, which is a vulnerable spot for quantum-attacks. We simulated the implementation of the algorithm in a case study and monitored how the algorithm performed. The proposed methodology was capable of providing secure communication between IoT and edge layer. However, the message length and parameters from the algorithm can slow down the communication.",IEEE
P. Shoran; A. Sinha; H. R. Mahmood; V. Sharma; P. Jha; B. Kumar; A. Alkhayyat,Enhancing Software Cost Estimation using COCOMO Cost Driver Features with Battle Royale Optimization and Quantum Ensemble Meta-Regression Technique,2023,10.1109/ICCCNT56998.2023.10307113,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10307113,Conference Paper,2023 14th International Conference on Computing Communication and Networking Technologies (ICCCNT),"This research suggests a unique method for improving software cost estimates by combining Battle Royale Optimisation (BRO) and Quantum Ensemble Meta-Regression Technique (QEMRT) with COCOMO cost driver characteristics. The strengths of these three strategies are combined in the suggested strategy to increase the accuracy of software cost estimation. The COCOMO model is a popular software cost-estimating methodology that considers several cost factors. BRO is a metaheuristic algorithm that mimics the process of the fittest people being selected naturally and was inspired by the Battle Royale video game. The benefits of quantum computing and ensemble learning are combined in the machine learning approach known as QEMRT. Using a correlation-based feature selection technique, we first identified the most important COCOMO cost drivers in our study. To get the best-fit model, we then used BRO to optimize the weights of these cost drivers. To further increase the estimation's accuracy, QEMRT was utilized to meta-regress the optimized model. The suggested method was tested on two datasets for software cost estimating that are available to the public, and the outcomes were compared with other cutting-edge approaches. The experimental findings demonstrated that our suggested strategy beat the other approaches in terms of accuracy, robustness, and stability. In conclusion, the suggested method offers a viable strategy for improving the accuracy of software cost estimation, which might help software development organizations by improving project planning and resource allocation.",IEEE
B. Arslan; M. Ulker; S. Akleylek; S. Sagiroglu,"A study on the use of quantum computers, risk assessment and security problems",2018,10.1109/ISDFS.2018.8355318,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8355318,Conference Paper,2018 6th International Symposium on Digital Forensic and Security (ISDFS),"In the computer based solutions of the problems in today's world; if the problem has a high complexity value, different requirements can be addressed such as necessity of simultaneous operation of many computers, the long processing times for the operation of algorithms, and computers with hardware features that can provide high performance. For this reason, it is inevitable to use a computer based on quantum physics in the near future in order to make today's cryptosystems unsafe, search the servers and other information storage centers on internet very quickly, solve optimization problems in the NP-hard category with a very wide solution space and analyze information on large-scale data processing and to process high-resolution image for artificial intelligence applications. In this study, an examination of quantum approaches and quantum computers, which will be widely used in the near future, was carried out and the areas in which such innovation can be used was evaluated. Malicious or non-malicious use of quantum computers with this capacity, the advantages and disadvantages of the high performance which it provides were examined under the head of security, the effect of this recent technology on the existing security systems was investigated.",IEEE
B. McDonough; A. Mari; N. Shammah; N. T. Stemen; M. Wahl; W. J. Zeng; P. P. Orth,Automated quantum error mitigation based on probabilistic error reduction,2022,10.1109/QCS56647.2022.00015,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10025519,Conference Paper,2022 IEEE/ACM Third International Workshop on Quantum Computing Software (QCS),"Current quantum computers suffer from a level of noise that prohibits extracting useful results directly from longer computations. The figure of merit in many near-term quantum algorithms is an expectation value measured at the end of the computation, which experiences a bias in the presence of hardware noise. A systematic way to remove such bias is probabilistic error cancellation (PEC). PEC requires a full characterization of the noise and introduces a sampling overhead that increases exponentially with circuit depth, prohibiting high-depth circuits at realistic noise levels. Probabilistic error reduction (PER) is a related quantum error mitigation method that systematically reduces the sampling overhead at the cost of reintroducing bias. In combination with zero-noise extrapolation, PER can yield expectation values with an accuracy comparable to PEC. Noise reduction through PER is broadly applicable to near-term algorithms, and the automated implementation of PER is thus desirable for facilitating its widespread use. To this end, we present an automated quantum error mitigation software framework that includes noise tomography and application of PER to user-specified circuits. We provide a multi-platform Python package that implements a recently developed Pauli noise tomography (PNT) technique for learning a sparse Pauli noise model and exploits a Pauli noise scaling method to carry out PER. We also provide software tools that leverage a previously developed toolchain, employing PyGSTi for gate set tomography and providing a functionality to use the software Mitiq for PER and zero-noise extrapolation to obtain error-mitigated expectation values on a user-defined circuit.",IEEE
X. Guo; J. Winklmann; D. Stober; S. Cao; M. Schulz,An FPGA-Accelerated Atom Sorting Unit for Neutral Atom Quantum Computers,2024,10.1109/QCE60285.2024.10399,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10821015,Conference Paper,2024 IEEE International Conference on Quantum Computing and Engineering (QCE),"Neutral atoms have been proven to be a promising physical platform for quantum computing because of their longer coherence time and good scalability. To operate neutral-atom quantum computers, an essential step before computation is to assemble the atoms as a defect-free array. This process is called atom rearrangement or atom sorting, which typically requires a long analysis time on classical computers. To optimize the sorting process, we propose a hardware-friendly sorting algorithm (oriented for FPGA acceleration) to be able to analyze the atom array with four independent quadrants and process each quadrant in parallel. Tested on a Xilinx ZCU216 FPGA, our design can finish the sorting analysis procedure with a 50 $\times 50$ loaded atoms array with around 1.0 $\mu s$. Compared to the CPU implementation, we achieved an acceleration of around $50\times$ speedup in algorithm analysis time. In addition, the design exhibits good scalability in execution time, making it suitable for large-scale quantum systems.",IEEE
I. -D. Gheorghe-Pop; N. Tcholtchev; T. Ritter; M. Hauswirth,Quantum DevOps: Towards Reliable and Applicable NISQ Quantum Computing,2020,10.1109/GCWkshps50303.2020.9367411,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9367411,Conference Paper,2020 IEEE Globecom Workshops (GC Wkshps,"Quantum Computing is emerging as one of the great hopes for boosting current computational resources and enabling the application of ICT for optimizing processes and solving complex and challenging domain specific problems. However, the Quantum Computing technology has not matured to a level where it can provide a clear advantage over high performance computing yet. Towards achieving this ""quantum advantage"", a larger number of Qubits is required, leading inevitably to a more complex topology of the computing Qubits. This raises additional difficulties with decoherence times and implies higher Qubit error rates. Nevertheless, the current Noisy Intermediate-Scale Quantum (NISQ) computers can prove useful despite the intrinsic uncertainties on the quantum hardware layer. In order to utilize such error-prone computing resources, various concepts are required to address Qubit errors and to deliver successful computations. In this paper describe and motivate the need for the novel concept of Quantum DevOps. which entails regular checking of the reliability of NISQ Quantum Computing (QC) instances. By means of testing the computational reliability of basic quantum gates and computations (C-NOT, Hadamard, etc.)it consequently estimates the likelihood for a large scale critical computation (e.g. calculating hourly traffic flow models for a city) to provide results of sufficient quality. Following this approach to select the best matching (cloud) QC instance and having it integrated directly with the processes of development, testing and finally the operations of quantum based algorithms and systems enables the Quantum DevOps concept.",IEEE
S. Kan; M. Palma; Z. Du; S. A. Stein; C. Liu; J. Chen; A. Li; Y. Mao,Benchmarking Optimizers for Qumode State Preparation with Variational Quantum Algorithms,2024,10.1109/QCE60285.2024.00182,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10821429,Conference Paper,2024 IEEE International Conference on Quantum Computing and Engineering (QCE),"Quantum state preparation involves preparing a target state from an initial system, a process integral to applications such as quantum machine learning and solving systems of linear equations. A qumode is a quantum-mechanical harmonic oscillator representing a continuous variable system. Recently, there has been a growing interest in qumodes due to advancements in the field and their potential applications. However there is a notable gap in the literature specifically addressing this area. This paper aims to bridge this gap by providing performance benchmarks of various optimizers used in state preparation with Variational Quantum Algorithms. We conducted extensive testing across multiple scenarios, including different target states, both ideal and sampling simulations, and varying numbers of basis gate layers. Our evaluations offer insights into the complexity of learning each type of target state and demonstrate that some optimizers perform better than others in this context. Notably, the Powell optimizer was found to be exceptionally robust against sampling errors, making it a preferred choice in scenarios prone to such inaccuracies. Additionally, the Simultaneous Perturbation Stochastic Approximation (SPSA) optimizer was distinguished for its efficiency and ability to handle increased parameter dimensionality effectively.",IEEE
B. Tan; J. Cong,Optimal qubit mapping with simultaneous gate absorption,2021,10.1109/ICCAD51958.2021.9643554,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9643554,Conference Paper,2021 IEEE/ACM International Conference On Computer Aided Design (ICCAD),"Before quantum error correction (QEC) is achieved, quantum computers focus on noisy intermediate-scale quantum (NISQ) applications. Compared to the well-known quantum algorithms requiring QEC, like Shor's or Grover's algorithm, NISQ applications have different structures and properties to exploit in compilation. A key step in compilation is mapping the qubits in the program to physical qubits on a given quantum computer, which has been shown to be an NP-hard problem. In this paper, we present OLSQ-GA, an optimal qubit mapper with a key feature of simultaneous SWAP gate absorption during qubit mapping, which we show to be a very effective optimization technique for NISQ applications. For the class of quantum approximate optimization algorithm (QAOA), an important NISQ application, OLSQ-GA reduces depth by up to 50.0% and SWAP count by 100% compared to other state-of-the-art methods, which translates to 55.9% fidelity improvement. The solution optimality of OLSQ-GA is achieved by the exact SMT formulation. For better scalability, we augment our approach with additional constraints in the form of initial mapping or alternating matching, which speeds up OLSQ-GA by up to 272X with no or little loss of optimality.",IEEE
B. Dave; S. Yadev; M. Mathuria; Y. M. Sharma,Optimize task scheduling act by modified round robin scheme with vigorous time quantum,2017,10.1109/ISS1.2017.8389310,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8389310,Conference Paper,2017 International Conference on Intelligent Sustainable Systems (ICISS),"This paper deal with an advanced scheduling algorithm to improve efficiency of an employed system. To optimize the performance of a working system the proposed approach adopts the functionality of round robin algorithm with a new integrated process for opt an effective time quantum actively. Instead of consuming fixed time quantum the designed approach repeatedly elects an optimal quantum time during the execution of process, set time quantum actively on the base of process burst time that remains in ready queue. Apart to setting an optimal quantum time the designed approach give more attention to trim down the context switching of process in queue or resources. A number of simulations have carried out to demonstrate the efficiency of proposed algorithm and each and every simulation has presents that introduced approach efficiently improves the issues of traditional as well as modern scheduling algorithms.",IEEE
S. Ahmadunnisa; S. E. Mathe,Multi-LFSR Architectures for BRLWE-Based Post Quantum Cryptography,2024,10.1109/ACCESS.2024.3426990,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10595062,Journal,IEEE Access,"The advancement in quantum computing has led to a significant progress in the development of public-key cryptosystems, referred as Post Quantum Cryptography (PQC) which has robust security to withstand both classical and quantum attacks. Lattice-based cryptography, one of the most promising PQC candidate offers low complexity and has strong security proof relying on the hardness of Learning-with-errors (LWE) problem. A variant of LWE, Ring-learning-with-error (RLWE) performs arithmetic operations over a polynomial ring and has more efficient implementations compared to LWE. Recent works propose Binary-ring-learning-with-error (BRLWE), a new variant of RLWE which has less key size and more efficient implementations compared to both LWE and RLWE-based schemes. In this paper, an algorithm is developed for BRLWE-based scheme based on decomposing the arithmetic operation  $H.L\; mod (x^{n}+1) + M$  into desired number of segments. The arithmetic operation includes polynomial multiplication and addition over the ring  $x^{n}+1$  where H and M are two integer polynomials and L is a binary polynomial. We illustrate two efficient hardware architectures Dual-LFSR (DL) and Quad-LFSR (QL) to enable parallel execution of individual segments employing LFSR structures to have a significant reduction in latency compared to the existing works. Despite of having larger area, the reduction in latency leads to an improvement in other performance metrics such as delay, Area-Delay Product (ADP), Power-Delay Product (PDP), throughput and efficiency making the proposed structures well suitable for PQC schemes. Experimental results show that the proposed architectures when compared with the recently reported work has 23% and 25% ADP improvement with DL and QL structures respectively when n = 256.",IEEE
Z. Wang; J. Li; K. Xue; Z. Li; R. Li; N. Yu; Q. Sun; J. Lu,Fair-EAS: Entanglement Allocation and Selection for Process-Oriented Fairness in Quantum Communication Networks,2024,10.1109/TCOMM.2024.3516497,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10794776,Article,IEEE Transactions on Communications,"Quantum communication networks enable advanced quantum applications through remote entanglement distribution among source-destination pairs. Despite efforts to optimize entanglement distribution, fairness in multi-request scenarios has been neglected, potentially causing issues like ¡°request starvation¡±. To address such issue, this paper concentrates on the unique properties of entangled systems and introduces a process-oriented fairness metric, i.e., expected throughput, departing from conventional approaches used in classical networks. Furthermore, we propose an entanglement distribution scheme named Fair-EAS, which prioritizes entanglement allocation and selection for batching multiple requests to maximize overall throughput while maintaining max-min fairness. To facilitate a convenient solution, we transform the nonlinearity of the problem into an equivalent linear programming formulation and decouple the solution into offline and online phases. In the offline phase, we design a multi-round water-filling-like optimization algorithm to determine the optimal path set for predicting entanglement allocation. In the online phase, we introduce an adaptive compensation algorithm and an entanglement ¡°fragment¡± exhaustion algorithm to dynamically adjust the path set based on successfully generated entangled pairs. Comprehensive simulations show that Fair-EAS outperforms the existing schemes in terms of fairness by significantly enhancing the minimum throughput and throughput deviation among multiple requests while maintaining an overall throughput close to the optimal level.",IEEE
S. Islam; K. Mus; R. Singh; P. Schaumont; B. Sunar,Signature Correction Attack on Dilithium Signature Scheme,2022,10.1109/EuroSP53844.2022.00046,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9797351,Conference Paper,2022 IEEE 7th European Symposium on Security and Privacy (EuroS&P),"Motivated by the rise of quantum computers, existing public-key cryptosystems are expected to be replaced by post-quantum schemes in the next decade in billions of devices. To facilitate the transition, NIST is running a standardization process which is currently in its final Round. Only three digital signature schemes are left in the competition, among which Dilithium and Falcon are the ones based on lattices. Besides security and performance, significant attention has been given to resistance against implementation attacks that target side-channel leakage or fault injection response. Classical fault attacks on signature schemes make use of pairs of faulty and correct signatures to recover the secret key which only works on deterministic schemes. To counter such attacks, Dilithium offers a randomized version which makes each signature unique, even when signing identical messages. In this work, we introduce a novel Signature Correction Attack which not only applies to the deterministic version but also to the randomized version of Dilithium and is effective even on constant-time implementations using AVX2 instructions. The Signature Correction Attack exploits the mathematical structure of Dilithium to recover the secret key bits by using faulty signatures and the public-key. It can work for any fault mechanism which can induce single bit-flips. For demonstration, we are using Rowhammer induced faults. Thus, our attack does not require any physical access or special privileges, and hence could be also implemented on shared cloud servers. Using Rowhammer attack, we inject bit flips into the secret key s1 of Dilithium, which results in incorrect signatures being generated by the signing algorithm. Since we can find the correct signature using our Signature Correction algorithm, we can use the difference between the correct and incorrect signatures to infer the location and value of the flipped bit without needing a correct and faulty pair. To quantify the reduction in the security level, we perform a thorough classical and quantum security analysis of Dilithium and successfully recover 1,851 bits out of 3,072 bits of secret key $s_{1}$ for security level 2. Fully recovered bits are used to reduce the dimension of the lattice whereas partially recovered coefficients are used to to reduce the norm of the secret key coefficients. Further analysis for both primal and dual attacks shows that the lattice strength against quantum attackers is reduced from 2128 to 281 while the strength against classical attackers is reduced from 2141 to 289. Hence, the Signature Correction Attack may be employed to achieve a practical attack on Dilithium (security level 2) as proposed in Round 3 of the NIST post-quantum standardization process.",IEEE
S. K. Panda; S. Sen,SRRA: A Novel Skewness-Based Algorithm for Cloudlet Scheduling,2023,10.1109/QRS60937.2023.00080,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10366718,Conference Paper,"2023 IEEE 23rd International Conference on Software Quality, Reliability, and Security (QRS)","Cloud computing enables developers to deploy and host applications without focusing on installing and maintaining the infrastructure. The developers can utilize the services provided by the cloud service providers (CSPs) to offer scalable solutions to customer applications. As a result, CSPs are deluged with different batches of cloudlets (tasks) from diverse customer applications. Therefore, developing an algorithm that selects and processes applications intelligently to minimize the execution time and maximize the throughput becomes challenging. Many researchers have shown the round-robin (RR) scheduling algorithm variants to tackle this problem. One such variant is the dynamic RR heuristic algorithm (DRRHA) that utilizes the mean of the burst times (BTs) of cloudlets in the ready queue (RQ) to calculate the time quantum (TQ). However, DRRHA has not considered skewness. This paper introduces a novel skewness-based RR algorithm (SRRA) for cloudlet scheduling. The algorithm dynamically determines the TQ for each cloudlet based on the skewness of the BTs of cloudlets in the RQ. The algorithm has two variants: SRRA with minimum TQ (SRRA-Min) and SRRA with median TQ (SRRA-Med). The two variants of the proposed algorithm exhibit improved performance in terms of total execution time (TET) and throughput compared to DRRHA, individually and collectively. These comparisons are conducted using CloudSim Plus under two scenarios: constant skewness with varying cloudlets and constant cloudlets with varying skewness.",IEEE
G. A. Cirillo; G. Turvani; M. Simoni; M. Graziano,Advances in Molecular Quantum Computing: from Technological Modeling to Circuit Design,2020,10.1109/ISVLSI49217.2020.00033,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9155017,Conference Paper,2020 IEEE Computer Society Annual Symposium on VLSI (ISVLSI),"Molecules are serious candidates for building hardware for quantum computers. They can encode quantum information onto electron or nuclear spins and some of them show important features as the scalability of the number of qubits and a universal set of quantum gates. In this paper we present our advances in the development of a classical simulation infrastructure for molecular Quantum Computing: starting from the definition of simplified models taking into account the main physical features of each analyzed molecule, quantum gates are defined over these models, thus permitting to take into account the real behavior of each technology during the simulation. An interface with a hardware-agnostic description language has been also developed. The knowledge of the behavior of real systems permits to optimize the design of quantum circuits at both physical and compilation levels. Elementary quantum algorithms have been simulated on three different molecular technologies by changing the physical parameters of polarization and manipulation and quantum circuit design strategies. Results confirm the dependency of the fidelity of the results on both levels, thus proving that the choice of optimal operating points and circuit optimization techniques as virtual-Z gates are fundamental for ensuring the execution of quantum circuits with negligible errors.",IEEE
X. -C. Wu; D. M. Debroy; Y. Ding; J. M. Baker; Y. Alexeev; K. R. Brown; F. T. Chong,TILT: Achieving Higher Fidelity on a Trapped-Ion Linear-Tape Quantum Computing Architecture,2021,10.1109/HPCA51647.2021.00023,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9407237,Conference Paper,2021 IEEE International Symposium on High-Performance Computer Architecture (HPCA),"Trapped-ion qubits are a leading technology for practical quantum computing. In this work, we present an architectural analysis of a linear-tape architecture for trapped ions. In order to realize our study, we develop and evaluate mapping and scheduling algorithms for this architecture. In particular, we introduce TILT, a linear ¡°Turing-machinelike¡± architecture with a multilaser control ¡°head,¡± where a linear chain of ions moves back and forth under the laser head. We find that TILT can substantially reduce communication as compared with comparable-sized Quantum Charge Coupled Device (QCCD) architectures. We also develop two important scheduling heuristics for TILT. The first heuristic reduces the number of swap operations by matching data traveling in opposite directions into an ¡°opposing swap.¡±, and also avoids the maximum swap distance across the width of the head, as maximum swap distances make scheduling multiple swaps in one head position difficult. The second heuristic minimizes ion chain motion by scheduling the tape to the position with the maximal executable operations for every movement. We provide application performance results from our simulation, which suggest that TILT can outperform QCCD in a range of NISQ applications in terms of success rate (up to 4.35x and 1.95x on average). We also discuss using TILT as a building block to extend existing scalable trapped-ion quantum computing proposals.",IEEE
Z. Morrell; M. Vuffray; S. Misra; C. Coffrin,QuantumAnnealing: A Julia Package for Simulating Dynamics of Transverse Field Ising Models,2024,10.1109/QCE60285.2024.00096,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10821282,Conference Paper,2024 IEEE International Conference on Quantum Computing and Engineering (QCE),"Analog Quantum Computers are promising tools for improving performance on applications such as modeling behavior of quantum materials, providing fast heuristic solutions to optimization problems, and simulating quantum systems. Due to the challenges of simulating dynamic quantum systems, there are relatively few classical tools for modeling the behavior of these devices and verifying their performance. QuantumAnnealing.jl provides a toolkit for performing simulations of Analog Quantum Computers on classical hardware. This package includes functionality for simulation of the time evolution of the Transverse Field Ising Model, replicating annealing schedules used by real world annealing hardware, implementing custom annealing schedules, and more. This allows for rapid prototyping of models expected to display interesting behavior, verification of the performance of quantum devices, and easy comparison against the expected behavior of quantum devices against classical approaches for small systems. The software is provided as open-source and is available through Julia's package registry system.",IEEE
Y. Fu; J. Zhao,Exploring Molecular Flexible Docking Problems with Evolutionary Algorithm,2018,10.1109/DCABES.2018.00069,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8572567,Conference Paper,2018 17th International Symposium on Distributed Computing and Applications for Business Engineering and Science (DCABES),"In quantum-behaved particle swarm optimization algorithm (QPSO), the mean best position is employed as a global attractor to attract the particles for searching solutions globally. To improve the QPSO global convergence performance further, this article proposes an improved QPSO algorithm based on joint modeling of individual particles evolutionary process (IEQPSO). To ascertain the effectiveness of the proposed variant of the QPSO algorithm, several benchmark test functions have been considered. The experimental results show the superiority of the proposed approach on benchmark test functions. To assess the effectiveness and feasibility of the proposed method on real problems, it was used for the energy optimization of molecular docking, and compared with the classical Lamarckian genetic (LGA) algorithm. The numerical results reveal the reliability of the proposed approach for sampling conformation under high flexibility rotalable bonds.",IEEE
T. Tomesh; Z. H. Saleem; M. A. Perlin; P. Gokhale; M. Suchara; M. Martonosi,Divide and Conquer for Combinatorial Optimization and Distributed Quantum Computation,2023,10.1109/QCE57702.2023.00009,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10313799,Conference Paper,2023 IEEE International Conference on Quantum Computing and Engineering (QCE),"Scaling the size of monolithic quantum computer systems is a difficult task. As the number of qubits within a device increases, a number of factors contribute to decreases in yield and performance. To meet this challenge, distributed architectures composed of many networked quantum computers have been proposed as a viable path to scalability. Such systems will need algorithms and compilers that are tailored to their distributed architectures. In this work we introduce the Quantum Divide and Conquer Algorithm (QDCA), a hybrid variational approach to mapping large combinatorial optimization problems onto distributed quantum architectures. This is achieved through the combined use of graph partitioning and quantum circuit cutting. The QDCA, an example of application-compiler co-design, alters the structure of the variational ansatz to tame the exponential compilation overhead incurred by quantum circuit cutting. The result of this cross-layer co-design is a highly flexible algorithm which can be tuned to the amount of classical or quantum computational resources that are available, and can be applied to both near- and long-term distributed quantum ar-chitectures. We simulate the QDCA on instances of the Maximum Independent Set problem and find that it is able to outperform similar classical algorithms. We also evaluate an 8-qubit QDCA ansatz on a superconducting quantum computer and show that circuit cutting can help to mitigate the effects of noise. Our work demonstrates how many small-scale quantum computers canwork together to solve problems 85 % larger than their own qubit count, motivating the development and potential of large-scale distributed quantum computing.",IEEE
J. Zhu; Y. Yuan; L. Nie; W. Tang; M. Li; H. Wu; X. Zhao; G. Xing; F. Zhang,A 28 nm 75.6 KOPS 13 nJ Computing-in-Memory Pipeline Number Theoretic Transform Accelerator for PQC,2025,10.1109/TCSII.2024.3481996,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10720080,Journal,IEEE Transactions on Circuits and Systems II: Express Briefs,"Lattice-based cryptography (LBC) exploits the learning with errors (LWE) problem and is the main algorithm standardized for Post-Quantum Cryptography (PQC). Number theoretic transforms (NTT) account for most of the latency and energy in the computation of the LWE problem. This brief presents a Compute-in-Memory (CIM) configurable-pipeline NTT accelerator for PQC. The accelerator incorporates a bidirectional pipeline array to minimize data latency, CIM processing elements to reduce memory access, and a parallel PQC circuit for LBC protocol deployment. A 28 nm chip of the accelerator consumes only 13 nJ per 256-point NTT, while achieving a throughput of 75.6 KOPS that achieves a remarkable reduction of up to 78% in clock cycles and a 45% reduction in energy consumption than state-of-the-art designs.",IEEE
F. J. Aguiar Rampazzo; R. D. de Meneses; C. Teixeira; M. A. A. Henriques,A Low-Memory Implementation of a Hybrid Trusted Platform Module,2024,10.1109/SIoT63830.2024.10780492,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10780492,Conference Paper,2024 Symposium on Internet of Things (SIoT),"In Industry 4.0, as data traffic increases, securing connected devices is critical. Remote attestation with TPMs provides a robust way to ensure device integrity and authenticity, while TPM provides secure storage for integrity measurements, enhancing system security. To address the risks posed by quantum computers to asymmetric cryptography, this work prioritizes optimizing memory requirements for TPMs that incorporate quantum-secure algorithms. The focus lies on a hybrid approach, combining traditional and post-quantum algorithms, with a detailed analysis of their impact on memory consumption.",IEEE
S. Das; A. Mandal; R. Mukherjee,An Adaptive Differential Evolution Algorithm for Global Optimization in Dynamic Environments,2014,10.1109/TCYB.2013.2278188,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6587535,Journal,IEEE Transactions on Cybernetics,"This article proposes a multipopulation-based adaptive differential evolution (DE) algorithm to solve dynamic optimization problems (DOPs) in an efficient way. The algorithm uses Brownian and adaptive quantum individuals in conjunction with the DE individuals to maintain the diversity and exploration ability of the population. This algorithm, denoted as dynamic DE with Brownian and quantum individuals (DDEBQ), uses a neighborhood-driven double mutation strategy to control the perturbation and thereby prevents the algorithm from converging too quickly. In addition, an exclusion rule is used to spread the subpopulations over a larger portion of the search space as this enhances the optima tracking ability of the algorithm. Furthermore, an aging mechanism is incorporated to prevent the algorithm from stagnating at any local optimum. The performance of DDEBQ is compared with several state-of-the-art evolutionary algorithms using a suite of benchmarks from the generalized dynamic benchmark generator (GDBG) system used in the competition on evolutionary computation in dynamic and uncertain environments, held under the 2009 IEEE Congress on Evolutionary Computation (CEC). The simulation results indicate that DDEBQ outperforms other algorithms for most of the tested DOP instances in a statistically meaningful way.",IEEE
T. Liu; G. Ramachandran; R. Jurdak,Towards Quantum Resilient IoT: A Backward-Compatible Approach to Secure BLE Key Exchange Against Quantum Threats,2024,10.1109/IoTDI61053.2024.00019,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10562170,Conference Paper,2024 IEEE/ACM Ninth International Conference on Internet-of-Things Design and Implementation (IoTDI),"There¡¯s a significant move towards the adoption of Post-Quantum Cryptography (PQC). While there have been initiatives to transition conventional TCP/IP-based networks to PQC, Quantum Resilient Internet of Things (IoT) networks have not been as widely discussed. Presently, Bluetooth Low Energy (BLE) employs the Elliptic Curve Diffie-Hellman algorithm for Secure Connection (SC) pairing, which is vulnerable to quantum threats. In this study, we introduce a backward-compatible Post-Quantum Key Exchange (PQKE) protocol for BLE, utilizing the Kyber-512 algorithm that has been adopted by the National Institute of Standards and Technology as a post quantum Key Encapsulation Mechanism. Although Kyber-512 is quantum resilient, it has large key pairs and ciphertexts, which presents critical challenges for the limited computational resources of IoT devices. Our performance assessment reveals that with an Attribute Protocol Maximum Transmission Unit (ATT MTU) of 65 bytes, the pairing time increases by approximately 9 folds using our PQKE in comparison to the traditional BLE SC pairing, mainly due to increased data transmission. Nevertheless, by employing a larger ATT MTU, the pairing time of our PQKE mechanism can be minimized to be of the same order of magnitude as current pre-quantum key exchange for BLE. We therefore advocate for the adoption of larger ATT MTU sizes in quantum resilient BLE pairing to ensure the performance and usability of the technology in a post-quantum world.",IEEE
F. Peng; X. Chen,Quantum-Inspired Algorithm Enhances Efficiency in Antenna Optimization,2024,10.1109/TAP.2024.3433505,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10618990,Journal,IEEE Transactions on Antennas and Propagation,"This article proposes a quantum-inspired algorithm (QIA) for the efficient optimization of antennas. Due to the complexity of electromagnetic (EM) wave theory, performing a full-wave simulation on an antenna is often computationally expensive and time-consuming. Consequently, this article introduces entangled states from quantum computing into antenna optimization, facilitating efficient exploration of optimal antenna design solutions. The specific contributions of this article are given as follows: 1) a method is proposed for creating internal entangled states among different antenna design variables within a single-antenna design solution, enabling the algorithm to effectively avoid less promising regions during the exploration of vast solution spaces, thereby making the search more targeted; and 2) a method is introduced for creating external entangled states between multiple-antenna design solutions, allowing the algorithm to process the evolution of multiple design solutions in parallel. With the aid of quantum entangled states, these contributions enable a more balanced exploration and exploitation of antenna design solutions, thereby enhancing the optimization speed of the antennas.",IEEE
M. Hodson; D. Fletcher; D. Padilha; T. Cook,Rapid prototyping with symbolic computation: Fast development of quantum annealing solutions,2016,10.1109/HPEC.2016.7761632,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7761632,Conference Paper,2016 IEEE High Performance Extreme Computing Conference (HPEC),"Quantum computing promises to improve the speed and scalability of computations over that of classical computing hardware. At this early stage of quantum computer hardware development, software frameworks which support rapid prototyping of quantum solutions on small-scale hardware or simulators are necessary to explore the application of quantum algorithms to hard computational problems. We present a software library, ¡°QxLib,¡± which incorporates symbolic computation of optimization functions for quantum annealers as one means to enable rapid prototyping. We demonstrate its effectiveness on integer linear programming and integer factorization problems.",IEEE
L. Lu; Y. He; T. Wang; T. Shi; B. Li,Self-Powered Wireless Sensor for Fault Diagnosis of Wind Turbine Planetary Gearbox,2019,10.1109/ACCESS.2019.2925426,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8747487,Journal,IEEE Access,"This paper proposes a wind turbine planetary gearbox (PGB) fault diagnosis method based on a self-powered wireless sensor. The proposed wireless sensor, which consists of a piezoelectric energy harvester, a power management circuit, a microcontroller unit (MCU), a radio-frequency (RF) module, and an accelerometer, can acquire the vibration signals of wind turbine PGB by the accelerometer. The piezoelectric energy harvester utilizing vibration environment is optimized as a power supply for the proposed wireless sensor, including the MCU, RF module, and accelerometer. An ac¨Cdc converter combined with a low-dropout voltage regulator is developed to provide stable dc voltage for the proposed wireless sensor. Stacked denoising autoencoder (SDAE) shows excellent performance in learning robust features from the noised signal. Thus, in this paper, the SDAE method is adopted to learn robust and distinguishable features from measured signals. Then, the least squares support vector machine (LSSVM) is employed to classify features extracted by the SDAE. Both the SDAE and LSSVM are optimized by quantum particle swarm optimization (QPSO). The experimental results show that the presented power supply can generate 3.3-V dc voltage, which ensures regular operation of the rest of the wireless sensor. The proposed wireless sensor can achieve a reliable communication distance of 40.8 m in the test environment. Furthermore, the SDAE approach and LSSVM show excellent performance in feature extraction and fault diagnosis, respectively. The experimental results indicate that the proposed method is effective in terms of fault diagnosis for the wind turbine PGB.",IEEE
J. A. Monta?ez-Barrera; P. van den Heuvel; D. Willsch; K. Michielsen,Improving Performance in Combinatorial Optimization Problems with Inequality Constraints: An Evaluation of the Unbalanced Penalization Method on D-Wave Advantage,2023,10.1109/QCE57702.2023.00067,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10313601,Conference Paper,2023 IEEE International Conference on Quantum Computing and Engineering (QCE),"Combinatorial optimization problems are one of the target applications of current quantum technology, mainly because of their industrial relevance, the difficulty of solving large instances of them classically, and their equivalence to Ising Hamiltonians using the quadratic unconstrained binary optimization (QUBO) formulation. Many of these applications have inequality constraints, usually encoded as penalization terms in the QUBO formulation using additional variables known as slack variables. The slack variables have two disadvantages: (i) these variables extend the search space of optimal and suboptimal solutions, and (ii) the variables add extra qubits and connections to the quantum algorithm. Recently, a new method known as unbalanced penalization has been presented to avoid using slack variables. This method offers a trade-off between additional slack variables to ensure that the optimal solution is given by the ground state of the Ising Hamiltonian, and using an unbalanced heuristic function to penalize the region where the inequality constraint is violated with the only certainty that the optimal solution will be in the vicinity of the ground state. This work tests the unbalanced penalization method using real quantum hardware on D-Wave Advantage for the traveling salesman problem (TSP). The results show that the unbalanced penalization method outperforms the solutions found using slack variables and sets a new record for the largest TSP solved with quantum technology.",IEEE
F. He; Q. Song; H. Yuan; Y. Ma; X. Fu; C. Luo,Quantum Rotation Gate-Based Particle Swarm Algorithm for Test Data Anomaly Detection Model Hyperparameter Optimization,2023,10.1109/ICAIBD57115.2023.10206193,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10206193,Conference Paper,2023 6th International Conference on Artificial Intelligence and Big Data (ICAIBD),"Particle Swarm Optimization (PSO) is a popular algorithm used for optimization problems in various domains. However, the PSO algorithm suffers from some limitations, e.g., premature convergence and slow convergence rate. In this paper, we propose a new algorithm called Quantum Rotation Gate Particle Swarm Optimization (QPSO), which is based on the quantum rotation gate to address these shortcomings. The proposed QPSO algorithm aims to improve the optimization capability of the original PSO. We applied QPSO to optimize the neural network architecture for numerical anomaly detection on the self-noise aerodynamic wind tunnel test data set. Good results are achieved and the effectiveness of the proposed method is demonstrated. Compared to the original PSO algorithm, QPSO outperforms it in terms of convergence rate and accuracy.",IEEE
Y. Xu; G. Huang; J. Balewski; R. Naik; A. Morvan; B. Mitchell; K. Nowrouzi; D. I. Santiago; I. Siddiqi,QubiC: An Open-Source FPGA-Based Control and Measurement System for Superconducting Quantum Information Processors,2021,10.1109/TQE.2021.3116540,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9552516,Journal,IEEE Transactions on Quantum Engineering,"As quantum information processors grow in quantum bit (qubit) count and functionality, the control and measurement system becomes a limiting factor to large-scale extensibility. To tackle this challenge and keep pace with rapidly evolving classical control requirements, full control stack access is essential to system-level optimization. We design a modular field-programmable gate array (FPGA)-based system called QubiC to control and measure a superconducting quantum processing unit. The system includes room temperature electronics hardware, FPGA gateware, and engineering software. A prototype hardware module is assembled from several commercial off-the-shelf evaluation boards and in-house-developed circuit boards. Gateware and software are designed to implement basic qubit control and measurement protocols. System functionality and performance are demonstrated by performing qubit chip characterization, gate optimization, and randomized benchmarking sequences on a superconducting quantum processor operating at the Advanced Quantum Testbed at the Lawrence Berkeley National Laboratory. The single-qubit and two-qubit process fidelities are measured to be 0.9980 $\pm$ 0.0001 and 0.948 $\pm$ 0.004, respectively, by randomized benchmarking. With fast circuit sequence loading capability, the QubiC performs randomized compiling experiments efficiently and improves the feasibility of executing more complex algorithms.","IEEE, Web of Science"
C. P. Autry; W. Henderson; M. Magal; A. W. Roscoe,Leveraging the Decentralised Open IoT Security Protocol ((d)OISP)?: Facilitating Edge-Based Artificial Intelligence in Large-Scale Network Infrastructures,2023,10.1109/ICECET58911.2023.10389601,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10389601,Conference Paper,"2023 International Conference on Electrical, Computer and Energy Technologies (ICECET)","There is an increasing demand for integrating edge-based Artificial Intelligence (AI) into complex large-scale network infrastructures. This need is driven by the requirement for faster data processing, reduced latency, minimized cyberattack surfaces, and the preservation of bandwidth and lowered energy consumption. Yet, one significant hurdle has consistently stood out: ensuring a secure, authenticated seamless point-to point exchange of information in decentralized systems across heterogeneous devices and platforms without the use of central authority. This paper presents a novel approach to this challenge by leveraging the decentralized Open IoT Security Protocol ((d)OISP). We delve into the architectural design, operational dynamics, and merits of (d)OISP, with its decentralized nature, promises to enhance quantum-safe security measures by utilizing quantum safe standardized cryptosystems and offering a unified protocol that caters to diverse devices without necessitating a central point of control. By incorporating (d)OISP into networks, not only is data exchange made more secure, but the efficiency of edge-based AI operations is notably enhanced, especially in large-scale settings.","IEEE, Scopus"
C. Zhang; Y. He; S. Jiang; T. Wang; L. Yuan; B. Li,"Transformer Fault Diagnosis Method Based on Self-Powered RFID Sensor Tag, DBN, and MKSVM",2019,10.1109/JSEN.2019.2919868,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8726315,Journal,IEEE Sensors Journal,"A novel transformer fault diagnosis method using self-powered radio frequency identification (RFID) sensor tag, deep belief network (DBN), and multiple kernel support vector machine (MKSVM) is presented. The self-powered RFID sensor tag is applied to measure transformer vibration signals, which has advantages of convenience, long-term monitoring, low power consumption, and fast location. Then, the DBN is employed to extract features from the measured signals, and the DBN method¡¯s extraction performance is improved by optimizing its learning rates and momentum factors. The extracted features of the same fault are highly centralized, and the features of the different faults are obviously separated. Based on the features, the MKSVM is utilized to construct a transformer fault diagnosis model, and the MKSVM¡¯s penalty factor and kernel weights are optimized through a quantum-behaved particle swarm optimization (QPSO) algorithm. Finally, a mean signal deviation (MSD) metric is presented to locate the fault position. In this experiment, a 10 kV transformer is used to demonstrate the proposed transformer fault diagnosis procedure, and the diagnosis results reflect that the proposed method can effectively measure the transformer vibration signals, extract the essential features, construct an accurate diagnosis model, and locate the fault position.",IEEE
S. Aktar; A. -H. A. Badawy; N. Santhi,Quantum Netlist Compiler (QNC),2022,10.1109/HPEC55821.2022.9926351,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9926351,Conference Paper,2022 IEEE High Performance Extreme Computing Conference (HPEC),"Over the last decade, Quantum Computing hardware has rapidly developed and become a very intriguing, promising, and active research field among scientists world-wide. To achieve the desired quantum functionalities, quantum algorithms require translation from a high-level description to a machine-specific physical operation sequence. In contrast to classical compilers, state-of-the-art quantum compilers are in their infancy. We believe there is a research need for a quantum compiler that can deal with generic unitary operators and generate basic unitary operations according to quantum machines' diverse underlying technologies and characteristics. In this work, we introduce the Quantum Netlist Compiler (QNC) that converts arbitrary unitary operators or desired initial states of quantum algorithms to OpenQASM-2.0 circuits enabling them to run on actual quantum hardware. Extensive simulations were run on the IBM quantum systems. The results show that QNC is well suited for quantum circuit optimization and produces circuits with competitive success rates in practice.",IEEE
K. Sinha; R. Dalvi; M. G. Chandra; S. Chatterjee,MetQuan - A Comprehensive Toolkit for Variational Quantum Sensing and Metrology,2024,10.1109/COMSNETS59351.2024.10427198,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10427198,Conference Paper,2024 16th International Conference on COMmunication Systems & NETworkS (COMSNETS),"In the rapidly progressing field of quantum metrology, precise parameter estimation is crucial for advanced applications. We are in the process of developing ¡°MetQuan¡±, a novel toolkit tailored explicitly for variational quantum sensing and metrology. By exploiting foundational principles from quantum mechanics, variational quantum algorithms, and metrology, MetQuan aspires to offer a user-focused platform that coherently melds theoretical depth with hands-on utility. A cornerstone of this nascent toolkit is its broad interoperability with preeminent quantum libraries such as Qiskit, QuTiP, Cirq, PennyLane, and QuanEstimation. Furthermore, understanding the inherent challenges posed by quantum noise, MetQuan is designed to simulate and optimize quantum sensing protocols under various noise conditions, providing tools for users to develop strategies to mitigate quantum noise across different quantum hardware specifications. Additionally, MetQuan provides integrated benchmarking tools, enabling comprehensive comparisons of variational quantum metrology results with traditional methodologies. This work outlines the foundational principles, design, and potential impacts of MetQuan in the quantum metrology landscape.",IEEE
P. P. Angara; U. Stege; A. MacLean; H. A. M¨¹ller; T. Markham,Teaching Quantum Computing to High-School-Aged Youth: A Hands-On Approach,2022,10.1109/TQE.2021.3127503,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9613752,Journal,IEEE Transactions on Quantum Engineering,"Quantum computing is aninterdisciplinary field that lies at the intersection of mathematics, quantum physics, and computer science, and finds applications in areas including optimization, machine learning, and simulation of chemical, physical, and biological systems. It has the potential to help solve problems that so far have no satisfying method solving them, and to provide significant speedup to solutions when compared with their best classical approaches. In turn, quantum computing may allow us to solve problems for inputs that so far are deemed practically intractable. With the computational power of quantum computers and the proliferation of quantum development kits, quantum computing is anticipated to become mainstream, and the demand for a skilled workforce in quantum computing is expected to increase significantly. Therefore, quantum computing education is ramping up. This article describes our experiences in designing and delivering quantum computing workshops for youth (Grades 9¨C12). We introduce students to the world of quantum computing in innovative ways, such as newly designed unplugged activities for teaching basic quantum computing concepts. We also take a programmatic approach and introduce students to the IBM Quantum Experience using Qiskit and Jupyter notebooks. Our contributions are as follows. First, we present creative ways to teach quantum computing to youth with little or no experience in science, technology, engineering, and mathematics areas; second, we discuss diversity and highlight various pathways into quantum computing from quantum software to quantum hardware; and third, we discuss the design and delivery of online and in-person motivational, introductory, and advanced workshops for youth.","IEEE, Web of Science"
P. P. Angara; U. Stege; A. MacLean,Quantum Computing for High-School Students An Experience Report,2020,10.1109/QCE49297.2020.00047,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9259970,Conference Paper,2020 IEEE International Conference on Quantum Computing and Engineering (QCE),"Quantum computing is an emerging field that can revolutionize our ability to solve problems and enable breakthroughs in many areas including optimization, machine learning, chemistry, and drug design. With the increasing computational power of quantum computers and the proliferation of quantum development kits, the demand for a skilled workforce in quantum computing increases significantly. The theory of quantum computing lies at the crossroads of quantum physics, mathematics, and computer science. The field of quantum computing has matured and can now be explored by all students. While today, quantum computers and simulators are readily accessible and programmable over the internet, quantum computing education is just ramping up. This paper describes our experiences in organizing and delivering quantum computing workshops for high-school students with little or no experience in the abovementioned fields. We introduce students to the world of quantum computing in innovative ways, such as newly designed ¡°unplugged¡± activities for teaching basic quantum computing concepts. Overall, we take a programmatic approach and introduce students to the IBM Q Experience using Qiskit and Jupyter notebooks. Our experiences and findings suggest that basic quantum computing concepts are palatable for high-school students, and-due to significant differences between classical and quantum computing-early exposure to quantum computing is a valuable addition to the set of problem-solving and computing skills that high-schoolers obtain before entering university.",IEEE
Y. Y. Hong; J. B. D. Santos,Day-Ahead Spatiotemporal Wind Speed Forecasting Based on a Hybrid Model of Quantum and Residual Long Short-Term Memory Optimized by Particle Swarm Algorithm,2023,10.1109/JSYST.2023.3265982,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10109785,Journal,IEEE Systems Journal,"Fluctuations in wind speed result in intermittent wind power generation. In a power grid, wind power intermittency has serious repercussions, including poor system reliability, increased reserve capacity requirement, and increased operating costs. Wind speed must be accurately predicted to enable the day-ahead power market to schedule dispatchable generation resources and determine the market prices. This article proposes a novel hybrid model of quantum and residual long short-term memory (LSTM) optimized by particle swarm optimization (PSO) for day-ahead spatiotemporal wind speed forecasting. The hyperparameters (time series, time lag, dropout rate, and learning rate) and the structure parameter of the residual LSTM are tuned by PSO. To improve the accuracy of the proposed model, a quantum embedding layer is added to the optimized residual-LSTM neural network. According to the test results, the proposed model is highly accurate and outperforms numerous machine learning methods and deep learning algorithms.",IEEE
B. Zhang; G. Zheng; N. V. Huynh,A Hybrid Quantum-Classical Autoencoder Framework for End-to-End Communication Systems,2024,10.1109/LWC.2024.3524330,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10818754,Article,IEEE Wireless Communications Letters,"This paper investigates the application of quantum machine learning to End-to-End (E2E) communication systems in wireless fading scenarios. We introduce a novel hybrid quantum-classical autoencoder architecture that combines parameterized quantum circuits with classical deep neural networks (DNNs). Specifically, we propose a hybrid quantum-classical autoencoder (QAE) framework to optimize the E2E communication system. Our results demonstrate the feasibility of the proposed hybrid system, and reveal that it is the first work that can achieve comparable block error rate (BLER) performance to classical DNN-based and conventional channel coding schemes, while significantly reducing the number of trainable parameters. Additionally, the proposed QAE exhibits steady and superior BLER convergence over the classical autoencoder baseline.",IEEE
A. A. Saki; A. Suresh; R. O. Topaloglu; S. Ghosh,Split Compilation for Security of Quantum Circuits,2021,10.1109/ICCAD51958.2021.9643478,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9643478,Conference Paper,2021 IEEE/ACM International Conference On Computer Aided Design (ICCAD),"An efficient quantum circuit (program) compiler aims to minimize the gate-count - through efficient instruction translation, routing, gate, and cancellation - to improve run-time and noise. Therefore, a high-efficiency compiler is paramount to enable the game-changing promises of quantum computers. To date, the quantum computing hardware providers are offering a software stack supporting their hardware. However, several third-party software toolchains, including compilers, are emerging. They support hardware from different vendors and potentially offer better efficiency. As the quantum computing ecosystem becomes more popular and practical, it is only prudent to assume that more companies will start offering software-as-a-service for quantum computers, including high-performance compilers. With the emergence of third-party compilers, the security and privacy issues of quantum intellectual properties (IPs) will follow. A quantum circuit can include sensitive information such as critical financial analysis and proprietary algorithms. Therefore, submitting quantum circuits to untrusted compilers creates opportunities for adversaries to steal IPs. In this paper, we present a split compilation methodology to secure IPs from untrusted compilers while taking advantage of their optimizations. In this methodology, a quantum circuit is split into multiple parts that are sent to a single compiler at different times or to multiple compilers. In this way, the adversary has access to partial information. With analysis of over 152 circuits on three IBM hardware architectures, we demonstrate the split compilation methodology can completely secure IPs (when multiple compilers are used) or can introduce factorial time reconstruction complexity while incurring a modest overhead (~ 3% to ~ 6% on average).",IEEE
D. Soni; R. Karri,Efficient Hardware Implementation of PQC Primitives and PQC algorithms Using High-Level Synthesis,2021,10.1109/ISVLSI51109.2021.00061,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9516714,Conference Paper,2021 IEEE Computer Society Annual Symposium on VLSI (ISVLSI),"Efficient and quantum-resistant Post-Quantum Cryptographic (PQC) algorithms need to be built before development of large-scale quantum, which will break RSA and Elliptic Curve cryptography based existing public key infrastructure. Cryptographers are developing quantum-resistant PQC algorithms, which consist of PQC primitives. These primitives act as a basic building blocks that play a vital role in security and resource utilization. Hence, efficient and precise implementation of PQC primitives is crucial for stable PQC algorithms. This paper implements and optimizes PQC primitives using High-level synthesis. High-level synthesis produces area-optimized and speed-optimized solutions for the primitives. These solutions create efficient and constant-time PQC designs that keep the hardware secure against timing side-channel attack.",IEEE
Y. Gao; Z. Liang; M. Lee; Y. Xing; H. Zhang; M. Pomeroy; J. Ma; H. Lu; W. Moore,Characterizing CT Reconstruction of Pre-log Transmission Data toward Ultra-low Dose Imaging by Texture Measures,2018,10.1109/NSSMIC.2018.8824295,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8824295,Conference Paper,2018 IEEE Nuclear Science Symposium and Medical Imaging Conference Proceedings (NSS/MIC),"Tremendous research efforts have been devoted to minimizing the radiation exposure to patients by acquiring the X-ray computed tomography (CT) transmission data at as low radiation exposure as reasonably practical (ALARP) and developing the corresponding image reconstruction methods. To address the ALARP radiation, this study aims to develop texture-enhancing image reconstruction algorithms and texture-based image quality evaluation strategies because image textures play an essential role for many clinical tasks. The image reconstruction is based on the maximum a posteriori probability given the acquired data, where the a priori knowledge is learnt tissue textures from the existing diagnostic full-dose CT image, and the transmission data fidelity is modeled by a shift Poisson statistic considering both the X-ray quanta fluctuation and the system electronic background noise. The image evaluation is based on the regional gray-scale co-occurrence texture measures. Evaluation of the developed methodologies was performed on patient data acquired with 120kVp and 100 mAs settings, followed on simulated data at 20, 10, 5 and 1mAs. The image texture measures showed a monotonic drop as the dose level decreased from 20 to 1 mAs. The most striking observation is a critical turning point on the plot of the relative change of texture measure vs. the mAs levels. This critical turning point indicates the minimum dose level that a CT scanner hardware configuration and image reconstruction software can achieve with a reasonable image quality. The effect of the background noise is also evaluated through the simulated data in this study.",IEEE
J. Dong; Y. Fu; X. Qin; Z. Dong; F. Xiao; J. Lin,ECO-BIKE: Bridging the Gap Between PQC BIKE and GPU Acceleration,2024,10.1109/TIFS.2024.3443617,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10643845,Journal,IEEE Transactions on Information Forensics and Security,"Advancements in quantum computing pose a threat to public-key cryptosystems, leading to the development of post-quantum cryptography. NIST is standardizing candidate algorithms, with BIKE, a code-based key encapsulation mechanism, among those under consideration. Performance is crucial in NIST PQC standardization process, and researchers have introduced a range of optimization techniques for BIKE across various platforms. To the best of our knowledge, our Efficient CryptOgraphy BIKE (ECO-BIKE) represents the first attempt at optimizing the implementation of BIKE on GPU architecture. In this paper, we introduce a comprehensive construction of a 3-threading parallel architecture tailored for the BIKE cryptosystem. This architecture covers a range of computational tasks, addressing operations from low-level to high-level computations. These include a parallel dense polynomial multiplication scheme with a better memory access pattern and a better XOR calculation, which forms the basis for a comprehensive parallel execution framework for the entire BIKE algorithm. Targeted optimizations are implemented for specific modules (KEYGEN, ENCAPS, DECAPS), which collectively enhance the overall efficiency of the algorithm. Our ECO-BIKE exhibits exceptional throughput performance on the NVIDIA GeForce RTX 4090. In the 3-thread mode, the throughput of the KEYGEN, ENCAPS, and DECAPS modules reaches 24.033 kops/s, 277.789 kops/s, and 5.817 kops/s, respectively. Our proposed optimal parallel multiplication scheme achieves a significantly higher overall throughput of 481.302 kops/s. These results highlight the substantial computational advantages our approach provides for cryptographic workloads.",IEEE
L. Nguyen; Z. Jiang,A Quantum Probabilistic Comparator: Circuit Implementation,2023,10.1109/NAECON58068.2023.10365860,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10365860,Conference Paper,NAECON 2023 - IEEE National Aerospace and Electronics Conference,"Decision making in stochastic autonomous systems, which considers uncertainty of many factors, is always a challenge. The problem can typically be addressed by probabilistic methods such as approximate stochastic optimization or Monte Carlo (MC) simulation. The potential solution may usually be constrained by the system's computing power, due to the size of the probabilistic problem. This paper aims to present and implement a quantum probabilistic comparison (QPC) algorithm that can help to find a desired solution or make decision between two random variables under uncertainty. This approach takes advantage of quantum computing to perform parallel comparison and fast calculation of the probability of matched state vectors. In the presented scheme, two random variables have different values (e.g., 2, 4, 8, or more values) and different probability distributions. The data of the variables are encoded to the basis states of the corresponding qubits. The quantum probabilistic comparator is used to make up the quantum output matrix that stores the comparison solutions as well as their probability probabilities. Moreover, unlike the existing quantum comparator algorithm, which uses bit string comparison approaches, the proposed probabilistic comparator is not only comparing the basis state, but also accumulating the outcome's probabilities. The calculation results of the quantum probabilistic comparator circuit are compared with those from classical computation and quantum circuit simulation as well as on an IBM quantum computer, for analysis and verification.",IEEE
R. Shaydulin; A. Galda,Error Mitigation for Deep Quantum Optimization Circuits by Leveraging Problem Symmetries,2021,10.1109/QCE52317.2021.00046,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9605320,Conference Paper,2021 IEEE International Conference on Quantum Computing and Engineering (QCE),"High error rates and limited fidelity of quantum gates in near-term quantum devices are the central obstacles to successful execution of the Quantum Approximate Optimization Algorithm (QAOA). In this paper we introduce an application-specific approach for mitigating the errors in QAOA evolution by leveraging the symmetries present in the classical objective function to be optimized. Specifically, the QAOA state is projected into the symmetry-restricted subspace, with projection being performed either at the end of the circuit or throughout the evolution. Our approach improves the fidelity of the QAOA state, thereby increasing both the accuracy of the sample estimate of the QAOA objective and the probability of sampling the binary string corresponding to that objective value. We demonstrate the efficacy of the proposed methods on QAOA applied to the MaxCut problem, although our methods are general and apply to any objective function with symmetries, as well as to the generalization of QAOA with alternative mixers. We experimentally verify the proposed methods on an IBM Quantum processor, utilizing up to 5 qubits. When leveraging a global bit-flip symmetry, our approach leads to a 23% average improvement in quantum state fidelity.",IEEE
Y. K. Wong; Y. Zhou; Y. S. Liang; H. Qiu; Y. X. Wu; B. He,The New Answer to Drug Discovery: Quantum Machine Learning in Preclinical Drug Development,2023,10.1109/PRML59573.2023.10348356,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10348356,Conference Paper,2023 IEEE 4th International Conference on Pattern Recognition and Machine Learning (PRML),"The Research & Development (R&D) phase of drug development Drug discovery and development (D&D) is a complex and costly endeavor, typically requiring six to nine years [1] and four hundred to fourteen hundred million USD [2] for the research and development (R&D) phase alone. To transform this process, we propose a novel concept that combines Quantum-based Machine Learning network (QML) and Quantum Computing Simulation (QS) to expedite the R&D phase to three to six months and reduce the cost to merely fifty to eighty thousand USD. Our approach takes as inputs the target protein/gene structure and the primary assay [3]. For Hit Generation [3], the QML network generates potential hits [4] based on the molecular structure of the target protein, while the QS filters molecules from the primary assay according to their reaction and binding efficacy with the target protein. Then, for Lead Optimization [3], the resulting molecules from QML and QS are compared, and the ones that are common to both processes are subjected to dozens of molecular variations, while others are only modified slightly. Finally, all optimized molecules undergo multiple rounds of QS filtering with high standards for reaction efficacy and safety, producing a few dozen pre-clinical-trial-ready drugs. Our concept of QML and QS integration can also be applied to other fields, such as agricultural research, genetic editing, and aerospace engineering. Keywords: Quantum Computer, Hit to Lead, Lead Optimization Simulation, Machine Learning.",IEEE
S. Thelen; H. Safi; W. Mauerer,Approximating under the Influence of Quantum Noise and Compute Power,2024,10.1109/QCE60285.2024.10291,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10821110,Conference Paper,2024 IEEE International Conference on Quantum Computing and Engineering (QCE),"The quantum approximate optimisation algorithm (QAOA) and its variants are at the core of many scenarios that aim at combining the power of quantum computers (QC) and classical high-performance computing (HPC) appliances for combinatorial optimisation. Several obstacles challenge concrete benefits now and in the foreseeable future: Imperfections quickly degrade algorithmic performance below practical utility; over-heads arising from alternating between classical and quantum primitives can counter any advantage; and the choice of parameters or algorithmic variant can substantially influence runtime and result quality. Selecting the appropriate combination is a non-trivial issue, as it not only depends on end-user requirements, but also on details of the hardware and software stack. Appropriate automation can alleviate the burden of choosing optimal combinations for end-users: They should not be required to understand technicalities like detail differences between QAOA variants, required number of QAOA layers, or necessary measurement samples. Yet, they should receive the best possible satisfaction of their non-functional requirements, be it performance or other. We determine factors that influence approximation quality and temporal behaviour of four QAOA variants using comprehensive density-matrix-based numerical simulations targeting three widely studied optimisation problems. Our simulations consider ideal quantum computation, and a continuum of scenarios troubled by realistic imperfections. Our quantitative results, accompanied by a comprehensive reproduction package, show strong performance differences between QAOA variants that can be pinpointed to narrow and specific effects. We identify influential co-variables and relevant non-functional quality goals that, as we argue, mark the rele-vant ingredients for designing appropriate software engineering abstraction mechanisms and automated tool-chains for devising quantum solutions from higher-level problem specifications.",IEEE
J. Golden; A. B?rtschi; D. O¡¯Malley; S. Eidenbenz,Threshold-Based Quantum Optimization,2021,10.1109/QCE52317.2021.00030,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9605298,Conference Paper,2021 IEEE International Conference on Quantum Computing and Engineering (QCE),"We propose and study Th-QAOA (pronounced Threshold QAOA), a variation of the Quantum Alternating Operator Ansatz (QAOA) that replaces the standard phase separator operator, which encodes the objective function, with a threshold function that returns a value 1 for solutions with an objective value above the threshold and a 0 otherwise. We vary the threshold value to arrive at a quantum optimization algorithm. We focus on a combination with the Grover Mixer operator; the resulting GM-Th-QAOA can be viewed as a generalization of Grover¡¯s quantum search algorithm and its minimum/maximum finding cousin to approximate optimization.Our main findings include: (i) we provide intuitive arguments and show empirically that the optimum parameter values of GM-Th-QAOA (angles and threshold value) can be found with O(log(p) ¡Á log M) iterations of the classical outer loop, where p is the number of QAOA rounds and M is an upper bound on the solution value (often the number of vertices or edges in an input graph), thus eliminating the notorious outer-loop parameter finding issue of other QAOA algorithms; (ii) GM-Th-QAOA can be simulated classically with little effort up to 100 qubits through a set of tricks that cut down memory requirements; (iii) somewhat surprisingly, GM-Th-QAOA outperforms non-thresholded GM-QAOA in terms of approximation ratios achieved. This third result holds across a range of optimization problems (MaxCut, Max k-VertexCover, Max k-DensestSubgraph, MaxBisection) and various experimental design parameters, such as different input edge densities and constraint sizes.",IEEE
G. Ahmadi-Assalemi; H. Al-Khateeb; G. Epiphaniou; A. Aggoun,Super Learner Ensemble for Anomaly Detection and Cyber-Risk Quantification in Industrial Control Systems,2022,10.1109/JIOT.2022.3144127,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9684524,Journal,IEEE Internet of Things Journal,"Industrial control systems (ICSs) are integral parts of smart cities and critical to modern societies. Despite indisputable opportunities introduced by disruptor technologies, they proliferate the cybersecurity threat landscape, which is increasingly more hostile. The quantum of sensors utilized by ICS aided by artificial intelligence (AI) enables data collection capabilities to facilitate automation, process streamlining, and cost reduction. However, apart from the operational use, the sensors generated data combined with AI can be innovatively utilized to model anomalous behavior as part of layered security to increase resilience to cyberattacks. We introduce a framework to profile anomalous behavior in ICS and derive a cyber-risk score. A novel super learner ensemble for one-class classification is developed, using overlapping rolling windows with stratified,  $k$ -fold,  $n$ -repeat cross-validation applied to each base learner followed by majority voting to derive the best learner. Our approach is demonstrated on a liquid distribution sensor data set. The experimental results reveal that the proposed technique achieves an overall  $F1$ -score of 99.13%, an anomalous recall score of 99% detecting anomalies lasting only 17 s. The key strength of the framework is the low computational complexity and error rate. The framework is modular, generic, applicable to other ICS, and transferable to other smart city sectors.","IEEE, Scopus"
M. M. Teja; J. V. R. Ravindra; S. R. S. Reddy; I. Yashwanth,Quantum Modular Multiplication: A New Frontier in Quantum Computing,2023,10.1109/I2CT57861.2023.10126376,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10126376,Conference Paper,2023 IEEE 8th International Conference for Convergence in Technology (I2CT),"Quantum modular multipliers are a promising development in the field of quantum computing that aim to perform modular multiplication faster and more efficiently than classical algorithms. This is achieved by encoding the numbers being multiplied into quantum bits (qubits) and using quantum gates to manipulate them in a way that represents the calculation. Since quantum physics principles like superposition and entanglement dramatically speed up processing compared to conventional computing, many calculations may be run simultaneously. Quantum modular multipliers have the potential to have a significant impact in a range of fields, including cryptography and beyond, since they offer a faster and more efficient way to do modular multiplications. Several fields, including simulation, optimization, and cryptography, can benefit from the use of quantum computing.One of the crucial operations in many of these applications is modular multiplication, a sort of multiplication that requires obtaining the remainder of the product of two numbers when divided by a third number. In this paper, we provide a novel modular multiplication method based on a quantum algorithm. To examine its complexity and compare it to that of current adders, we employ a novel form of adder that is intended to not retain the final carry. This adder's decrease percentage in terms of gates and depth is roughly 70%. Our method takes advantage of the special qualities of qubits to complete the computation significantly more quickly than conventional algorithms. It is based on the fundamental ideas of quantum physics, such as superposition and entanglement.",IEEE
V. Sridharan; P. M. Mohan; M. Gurusamy,QoC-Aware Control Traffic Engineering in Software Defined Networks,2020,10.1109/TNSM.2019.2940863,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8832197,Journal,IEEE Transactions on Network and Service Management,"In a distributed Software Defined Networking (SDN) architecture, the Quality of Service (QoS) experienced by a traffic flow through an SDN switch is primarily dependant on the SDN controller to which that switch is mapped. We propose a new controller-quality metric known as the Quality of Controller (QoC) which is defined based on the controller's reliability and response time. We model the controller reliability based on Bayesian inference while its response time is modelled as a linear approximation of the M/M/1 queue. We develop a QoC-aware approach for solving (i) the switch-controller mapping problem and, (ii) control traffic distribution among the mapped controllers. Each switch is mapped to multiple controllers to enable resilience with the switch-controller mapping and control traffic distribution based on the QoC metric which is the combined cost of controller reliability and response time. We first develop an optimization programming formulation that maximizes the minimum QoC among the set of controllers to solve the above problem. Since the optimization problem is computationally prohibitive for large networks, we develop a heuristic algorithm - Qoc-Aware switch-coNTroller Mapping (QuANTuM) - that solves the problem of switch-controller mapping and control traffic distribution in two stages such that the minimum of the controller QoC is maximized. Through simulations, we show that the heuristic results are within 18% of the optimum while achieving a fair control traffic distribution with a QoC min-max ratio of up to 95%.","IEEE, Web of Science"
Y. Yang; J. Huang; Z. Wang; J. Ye; Z. Sun; J. Fan; S. Chen; H. Li; X. Li; Y. Cao,A Template Attack on Reduction Without Reference Device on Kyber,2023,10.1109/ATS59501.2023.10318019,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10318019,Conference Paper,2023 IEEE 32nd Asian Test Symposium (ATS),"In July 2022, the National Institute of Standards and Technology (NIST) announced its selection of four algorithms for post-quantum cryptography standardization in advance. Among these algorithms, Kyber was chosen as the only key encapsulation mechanism (KEM). In the Kyber KEM, the modular reduction function is utilized in numerous areas. We have discovered that by modeling controllable modular reduction functions, unknown modular reduction functions can be targeted. And attacks can then be constructed. Henceforth, profiling can be mounted on the target device. In this paper, we present a machine-learning-based key recovery attack on Kyber, without needing a reference device. We have effectively attacked the modular reduction function. Furthermore, this vulnerability that enables the reuse of the same function could be utilized in other attacks.",IEEE
B. Mete; M. Schulz; M. Ruefenacht,Predicting the Optimizability for Workflow Decisions,2022,10.1109/QCS56647.2022.00013,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10025536,Conference Paper,2022 IEEE/ACM Third International Workshop on Quantum Computing Software (QCS),"With the rapid advancement of quantum technologies, the integration between classical and quantum computing systems is an active area of research critical to future development. The coupling between these systems requires both to be as efficient as possible. One of the key elements to increase efficiency on the quantum side is circuit optimization. The goal is to execute the circuit on the desired hardware in less time and with less complexity, thereby reducing the impact of noise on the quantum system. However, the optimization process does not guarantee to generate improved results, yet it is always a computationally highly complex task that can create significant load for the classical computing side. To mitigate this problem, we propose a novel approach to predict the optimizability of any circuit using a Machine Learning-based algorithm within the decision workflow. This optimizes the most suitable circuits thereby increasing efficiency of the optimization process itself.",IEEE
M. R. Magar; D. Pandit; D. Nguyen; N. Nguyen,DC Optimal Power Flow in Unit Commitment Using Quantum Computing: An ADMM Approach,2024,10.1109/NAPS61145.2024.10741684,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10741684,Conference Paper,2024 56th North American Power Symposium (NAPS),"This paper introduces an approach to solve unit commitment-based DC optimal power flow using the quantum-based alternating direction method of multipliers optimizer. The substantial interconnection of current generation and loads and the widespread incorporation of renewable energy have significantly altered and increased the complexity of the grid. As a result, efficient planning and operation of the power grid have become central focuses. This paper proposes an advanced method to solve DC-optimal power flow via quantum heuristic approaches leveraging the power of both quantum and classical computing. This is achieved by splitting the procedure to decompose a mixed binary quadratic problem into a quadratic unconstrained binary optimization sub-problem which is solved using a quantum approximate optimization algorithm. Following this, a continuous convex-constrained sub-problem is solved with a classical optimization solver. Within the DC-OPF, the startup cost and shutdown cost of each generator are incorporated in addition to the general cost function with the generator's cost coefficients. The DC-OPF is solved using the IBM Qiskit software development kit on an IEEE-14 bus system. The results obtained are then validated with the results obtained from classical methods using MATPOWER.",IEEE
C. Ross; G. Gradoni; Q. J. Lim; Z. Peng,Engineering Reflective Metasurfaces With Ising Hamiltonian and Quantum Annealing,2022,10.1109/TAP.2021.3137424,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9665281,Journal,IEEE Transactions on Antennas and Propagation,"We present a novel and flexible method to optimize the phase response of reflective metasurfaces (MSs) toward the desired scattering profile. The scattering power is expressed as a spin-chain Hamiltonian using the radar cross section (RCS) formalism. For MSs reflecting an oblique plane wave, an Ising Hamiltonian is obtained. Thereby, the problem of achieving the scattering profile is recast into finding the ground-state solution of the associated Ising Hamiltonian. To rapidly explore the configuration states, we encode the Ising coefficients with quantum annealing (QA) algorithms, taking advantage of the fact that the adiabatic evolution efficiently performs energy minimization in the Ising model. Finally, the optimization problem is solved on the D-Wave 2048-qubit quantum adiabatic optimizer machine for binary phase as well as quadriphase reflective MSs. Even though the work is focused on the phase modulation of MSs, we believe this approach paves the way to fast optimization of reconfigurable intelligent surfaces (RISs) that are modulated in both amplitude and phase for multi-beam generation in and beyond 5G/6G mobile networks.",IEEE
M. G. Meena; Y. Zhang; W. Jiang; Y. Lin; S. G¨¹nther; X. Gao,Towards a Quantum Algorithm for the Incompressible Nonlinear Navier-Stokes Equations,2024,10.1109/QCE60285.2024.00083,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10821279,Conference Paper,2024 IEEE International Conference on Quantum Computing and Engineering (QCE),"In this work, we present novel concepts for quantum algorithms to solve transient, nonlinear partial differential equations (PDEs). The challenge lies in how to effectively represent, encode, process, and evolve the nonlinear system of PDEs on quantum computers. We will discuss the new techniques using the incompressible Navier-Stokes equations as an example, because it represents the fundamental nonlinear feature and yet removes certain complexity in physics, allowing us to focus on the design of quantum algorithms. Previous attempts solving nonlinear PDEs in quantum computation have often involved storing multiple copies of solutions or employing linearizations. Neither is practical due to exponential scaling with evolution time or insufficient solution accuracy. We propose a new framework based on matrix product states (MPSs) and matrix product operators (MPOs), in addition to the Krylov subspace methods. For example, the solution variables of the Navier-Stokes equations are represented by MPSs, and the linear and nonlinear terms are processed by MPOs. The time evolution of the operators is attained by a fast-forwarding algorithm using Krylov subspace methods. Furthermore, we discuss various techniques for efficient encoding of MPSs, measurement reduction for MPOs, and use of tensor operations to treat multi-variate, multi-physics characteristics of Navier-Stokes.",IEEE
L. Tosi; P. Rocca,A Quantum Optimization Method for Antenna Array Thinning,2024,10.23919/EuCAP60739.2024.10501035,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10501035,Conference Paper,2024 18th European Conference on Antennas and Propagation (EuCAP),"An innovative design methodology based on a hybrid quantum computing technique aimed at optimizing the thinning configuration of the array elements for interference suppression purposes is presented in this work. The optimization approach exploits the Quantum Approximate Optimization Algorithm (QAOA) and a set of selected numerical results, carried out through a quantum computer emulator, is discussed to point out the peculiarities of the proposed method.",IEEE
M. Ahmadian; M. Ruiz; J. Comellas; L. Velasco,Cost-Effective ML-Powered Polarization-Encoded Quantum Key Distribution,2022,10.1109/JLT.2022.3157527,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9729998,Journal,Journal of Lightwave Technology,"Secure communications have become a requirement for virtually all kind of applications. Currently, two distant parties can generate shared random secret keys by using public key cryptography. However, quantum computing represents one of the greatest threats for the finite complexity of the mathematics behind public key cryptography. In contrast, Quantum Key Distribution (QKD) relies on properties of quantum mechanics, which enables eavesdropping detection and guarantees the security of the key. Among QKD systems, polarization encoded QKD has been successfully tested in laboratory experiments and recently demonstrated in closed environments. The main drawback of QKD is its high cost, which comes, among others, from: i) the requirements for the quantum transmitters and receivers; and ii) the need of carefully selecting the fibers supporting the quantum channel to minimize the environmental effects that could dramatically change the polarization state of photons. In this paper, we propose a Machine Learning (ML) -based polarization tracking and compensation that is able to keep shared secret key exchange to high rates even under large fiber stressing events. Exhaustive results using both synthetic and experimental data show remarkable performance, which can simplify the design of both quantum transmitter and receiver, as well as enable the use of aerial optical cables, thus reducing total QKD system cost.",IEEE
R. Reeder; A. Udal; E. Velmre; A. Valavanis; J. Cooper; A. Grier; P. Harrison,Numerical aspects of the development of Quantum Cascade Laser simulation software,2014,10.1109/BEC.2014.7320550,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7320550,Conference Paper,2014 14th Biennial Baltic Electronic Conference (BEC),"One of the most efficient device producing coherent high power radiation in terahertz range in electromagnetic spectrum is Quantum Cascade Laser (QCL). During over a decade of history, together with intensive development of terahertz quantum cascade lasers, respecting simulation software tools has been developed too. The process of development of simulation software is a sophisticated task, because many fields of science meet there - quantum electronics, computing technologies, software development etc. The progress in computing power have made simulation tools much more handy, as calculations of non-complex quantum well heterostructures can be run on a personal computer during a considerable time. Simulation of Quantum Cascade Lasers with complex structures can still be very time-consuming. In this paper few strategies on how to improve and optimize QWWAD software tools are analysed, implemented and corresponding results presented. Improvement of eigenvalue problem solution gave 20 times faster algorithm in solving Schr?dinger equation. Other ideas did not give remarkable success.",IEEE
R. Singh; B. Bhushan,Evolving Intelligent System for Trajectory Tracking of Unmanned Aerial Vehicles,2022,10.1109/TASE.2021.3072339,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9411686,Journal,IEEE Transactions on Automation Science and Engineering,"This article develops an evolving type-2 quantum fuzzy neural network (eT2QFNN) control scheme for achieving trajectory tracking with unmanned aerial vehicles (UAVs). The proposed approach involves quantum membership functions, automatic rule growing process, and parameter adjustment learning scenario to deal with the problems of inadequacy, uncertainties, and noise in conventional control techniques. Furthermore, the proposed approach is operated in a parallel structure with the proportional derivative (PD) controller to compensate the transients in performance and learn the dynamic characteristics of the system. Besides, a sliding theory-based adaptive law is equipped with the control approach to compensate for the nonlinearity of the UAV. To assess the performance, numerical simulations and real-time experiments are carried for pitch and yaw axes control of two degrees of freedom (2DoF) helicopter test rig with the proposed approach. The simulations and experiments are aimed at achieving an offline path tracking with an objective to minimize the deviation error and improve the time response characteristics of the UAVs. The results depict the robustness of the proposed approach in terms of integral time absolute error for a helicopter following various trajectories. Note to Practitioners¡ªThis article addresses the problem of trajectory tracking and attitude control in a two-rotor UAV system. In practical application, there are multiple end users for an efficiently controlled UAV system. Generally, the trajectory tracking and attitude control are associated with the capability of UAVs to perform vertical take-off, landing, maneuver, and cyclic rotation as per the change in path. Furthermore, the control of UAVs for trajectory tracking and attitude provides a unified framework in efficiently following the desired path and maintaining the desired attitude. This has potential applications in the field of search and rescue operations, surveillance, military applications, environmental exploration, and aerial cinematography. Although trajectory tracking and attitude control problems have been studied a lot, the drawbacks due to uncertainties, immediate response to trajectory changes, and attitude settling are still open and challenging. This article proposed an eT2QFNN for a two rotor of UAV system with PD controller using automatic rule growing process. Sufficient trajectories are developed to make the UAV follow them under the proposed approach. Both simulation and real-time experiments were conducted and the results of the developed controller are compared with conventional approaches.",IEEE
Y. -M. Jun; I. -C. Choi,Optimal Multi-Bit Toffoli Gate Synthesis,2023,10.1109/ACCESS.2023.3243798,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10041026,Journal,IEEE Access,"Multi-bit Toffoli gates form an essential quantum gate class for quantum algorithms. They should be efficiently decomposed into elementary single- or multi-qubit quantum gates, such as CNOT, T, and Hadarmard, for a scalable implementation of a quantum algorithm. We propose an engineering method for the practical synthesis of a multi-bit Toffoli gate. Two optimization models and their closed-form solutions are presented for optimal decomposition of the multi-bit Toffoli gate. These models are based on linearized multi-objective integer programming with parameters such as the number of target ancillae, ancillae states, and basis gates. The proposed method supports the systematic handling of quantum circuit constraints, including the total number of available qubits and maximum circuit depth, which depend on various quantum hardware specifications. Our approach exhibits promise in the noisy intermediate-scale quantum environment by providing a rapid and optimal method for synthesizing multi-bit Toffoli gates in diverse and unpredictable quantum hardware specifications.",IEEE
C. -H. Ou; Y. -H. Li; C. -Y. Chen; C. -H. Wu; Y. -C. Tsai; Z. -Y. Yan; C. -R. Chang,Quantum-Inspired Optimization for Task Scheduling in Software Development Projects,2023,10.1109/QCE57702.2023.10276,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10313889,Conference Paper,2023 IEEE International Conference on Quantum Computing and Engineering (QCE),"Software project development, characterized by numerous tasks and several engineers, necessitates effective project scheduling and personnel allocation for successful and timely completion. Tackling the inherent complexities of Software Project Scheduling (SPS) including personnel quality requirements and capability constraints is of paramount importance for software companies. This study aims to engineer robust project scheduling to enhance task completion efficiency, reduce resource waste, and ensure the punctual delivery of project milestones. Our proposed solution models the problem as a Software Project Scheduling Problem (SPSP), subsequently transformed into a Quadratic Unconstrained Binary Optimization (QUBO) model using quantum-inspired techniques. This model is then solved using a digital annealing device. We examine our proposed quantum-inspired method's effectiveness in solving SPSP through this experimental implementation, comparing its performance with the Simulated Annealing (SA) algorithm. The experimental findings reveal that the objective function, encapsulating the weighted sum of all job personnel costs and job end times, produced superior outcomes under the Digital Annealing (DA) algorithm compared to the SA algorithm. Moreover, the DA algorithm demonstrated greater stability and reduced runtime as the volume of input data expanded.",IEEE
K. Dasari; S. P. Dongari; A. R. Chirra; S. S. Devireddy; H. R. Boddireddy; M. Mahmoud,Demystifying Quantum Blockchain for Healthcare,2023,10.1109/CSCI62032.2023.00238,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10590543,Conference Paper,2023 International Conference on Computational Science and Computational Intelligence (CSCI),"Using blockchain technology and quantum computing together is a burgeoning area of research that has the potential to revolutionize data storage and processing. Although blockchain technology has already significantly advanced in decentralized data storage and secure transactions, traditional computing methods must improve speed, scalability, and security. However, with the development of quantum computing, these limitations may soon be outdated. By leveraging optimization algorithms, quantum computing can accelerate the mining of new blocks on the blockchain. This, in turn, can improve the overall performance of blockchain networks and enable more efficient transactions. Furthermore, quantum computing can strengthen blockchain security by enhancing cryptographic protocols and preventing attacks on the network. Additionally, quantum computing can optimize complex mathematical calculations necessary for blockchain applications. In this paper, we will explore the various potential applications of the quantum blockchain technology in healthcare, and the current state of research and development in this field. In addition, we will discuss the challenges that must be overcome to utilize this technology fully. We aim to stimulate further research and innovation in this emerging field by shedding more light on it.",IEEE
L. Wan; H. Li; G. Zhang; C. Li; J. Man; M. Xiao,Rolling Bearing Fault Diagnosis Method Based on Parallel QPSO-BPNN Under Spark-GPU Platform,2021,10.1109/ACCESS.2021.3072596,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9400414,Journal,IEEE Access,"Facing the massive rolling bearing vibration data, how to improve the training efficiency, diagnosis efficiency, and diagnosis accuracy of the rolling bearing fault diagnosis model is a challenge. Considering that the Spark-GPU platform provides powerful distributed parallel computing capabilities and back propagation neural network (BPNN) optimized by quantum particle swarm optimization (QPSO) algorithm has the characteristics of low computational complexity and high diagnosis accuracy, a rolling bearing fault diagnosis method based on parallel QPSO-BPNN under Spark-GPU platform is proposed. First, the distributed parallelization of QPSO-BPNN model based on Spark-GPU platform is realized, which can improve the training efficiency and diagnosis efficiency of rolling bearing fault diagnosis model in the big data environment. Second, in order to improve the convergence speed of fault diagnosis model, a parameter update strategy suitable for the distributed parallel training of QPSO-BPNN model is designed. At each iteration during training, the local parameters of each worker node are collected to the master node, and the global parameters are updated according to the weights and synchronized to each worker node. Third, a combination strategy of multiple QPSO-BPNN models based on ensemble learning is proposed. The weighted voting method is adopted to combine the output results of different QPSO-BPNN models to obtain the best fault diagnosis result of a sample, which can improve the fault diagnosis accuracy to a certain extent. Experimental results show that the proposed method can quickly perform model training and fault diagnosis for large-scale rolling bearing vibration data, and the fault diagnosis accuracy reaches 98.73%.",IEEE
H. Johnson; N. Bornman; T. Kim; D. Van Zanten; S. Zorzetti; J. Saniie,Demonstrating the Potential of Adaptive LMS Filtering on FPGA-Based Qubit Control Platforms for Improved Qubit Readout in 2D and 3D Quantum Processing Units,2024,10.1109/QCE60285.2024.00156,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10821444,Conference Paper,2024 IEEE International Conference on Quantum Computing and Engineering (QCE),"Advancements in quantum computing underscore the critical need for sophisticated qubit readout techniques to accurately discern quantum states. This abstract presents our research intended for optimizing readout pulse fidelity for 2D and 3D Quantum Processing Units (QPUs), the latter coupled with Superconducting Radio Frequency (SRF) cavities. Focusing specifically on the application of the Least Mean Squares (LMS) adaptive filtering algorithm, we explore its integration into the FPGA-based control systems to enhance the accuracy and efficiency of qubit state detection by improving Signal-to-Noise Ratio (SNR). Implementing the LMS algorithm on the Zynq UltraScale+ RFSoC Gen 3 devices (RFSoC 4x2 FPGA and ZCU216 FPGA) using the Quantum Instrumentation Control Kit (QICK) open-source platform, we aim to dynamically test and adjust the filtering parameters in real-time to characterize and adapt to the noise profile presented in quantum computing readout signals. Our preliminary results demonstrate the LMS filter's capability to maintain high readout accuracy while efficiently managing FPGA resources. These findings are expected to contribute to developing more reliable and scalable quantum computing architectures, highlighting the pivotal role of adaptive signal processing in quantum technology advancements.",IEEE
S. Krishnan; S. R; M. S. Sathiamurthy,Evaluation of Equivalency Certificates for International Students using Quantum AI of Fairness and Efficiency QAA,2024,10.1109/ICEEICT61591.2024.10718455,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10718455,Conference Paper,"2024 Third International Conference on Electrical, Electronics, Information and Communication Technologies (ICEEICT)","International student mobility is essential for developing worldwide cooperation and educational exchange. However, the existing method of evaluating international academic qualifications, which frequently relies on Equivalency Certificates, encounters notable obstacles such as subjectivity, lengthy processing periods, and possible biases. In order to tackle these problems, this research suggests an innovative method that use quantum amplitude amplification (QAA) to transform the process of evaluating equivalency certificates for overseas students. QAA utilises the computing capabilities of quantum algorithms to effectively and precisely assess the comparability of educational qualifications across various academic systems. Our project seeks to optimise the equivalency certificate evaluation process by combining quantum computing and artificial intelligence approaches. This will provide a more dependable and unbiased framework for assessing the qualifications of international students. This article provides a detailed analysis of current approaches and proposes new algorithms based on QAA. The main objective is to outline a plan for using QAA in the assessment of equivalency certificates. The prospective ramifications of this strategy encompass enhanced clarity, decreased processing durations, and heightened precision in assessing the qualifications of international students, so promoting seamless transitions into higher education or employment in foreign nations. This paper reviews current equivalence assessment methodologies, proposes QAA-based algorithms tailored for this purpose, and outlines a roadmap for applying QAI to equivalency certificate evaluation. Beyond enhancing accuracy and efficiency, this research has the potential to promote global creativity and collaboration by improving the evaluation process for international students.","IEEE, Scopus"
T. Li; Y. Yu; J. Wang; R. Xie; X. Wang,Sensor fault diagnosis for electro-hydraulic actuator based on QPSO-LSSVR,2016,10.1109/CGNCC.2016.7828932,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7828932,Conference Paper,"2016 IEEE Chinese Guidance, Navigation and Control Conference (CGNCC)","In this paper, a novel fault diagnosis method based on quantum particle swarm optimization (QPSO) and least square support vector regression (LSSVR) algorithm, was proposed to detect sensor faults for electro-hydraulic actuators. Prediction model based on LSSVR algorithm is established to forecast sensor output. By calculating the residual between the forecast output of the LSSVR model and the actual output of the sensor, a fault can be indicated. Furthermore, to improve the prediction accuracy of the LSSVR model, QPSO is employed to optimize the hyper-parameters used in the LSSVR model. Simulation experiments show that, compared with PSO-LSSVR, the prediction error of QPSO-LSSVR is smaller and the convergence rate is faster. The effectiveness of the fault diagnosis method for detecting several typical sensor faults, which occurred in the actuator system, is also verified in the simulation experiments.",IEEE
S. Wei; J. Zhou; S. Chen,Delay-Aware Multipath Parallel SFC Orchestration,2022,10.1109/ACCESS.2022.3221744,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9947072,Journal,IEEE Access,"With the development of network functions virtualization and software defined networking, the service function chain (SFC) orchestration issue is a big challenge for high reliability and low latency services. At present, many studies propose solutions in terms of physical node mapping or link mapping for SFC. In this paper, we consider parallel transmission by dividing the SFC request flow into multiple sub-flows. To solve the problem of orchestrating parallel SFC under the premise of being able to meet the delay requirements of delay-sensitive classes of services, we divide the problem into two parts: virtual network functions mapped to physical servers and virtual links mapped to physical links. In the first part, we find suitable physical nodes for deployment by the simulated annealing algorithm. In the second part, we construct the link mapping problem as a multi-objective optimization problem. We solve this multi-objective optimization problem by quantum genetic algorithm. Finally, the mapping scheme for parallel SFC is generated. We have conducted comparative analyses of the algorithms through simulation experiments. The results show that the method proposed in this paper can effectively improve the orchestration efficiency of parallel SFC. The algorithm we build can not only minimize the resource consumption and routing energy consumption but also meet the delay requirements well. Therefore, this paper has high practical significance in diverse delay-sensitive service applications and provides a solution for future multipath parallel SFC orchestration.","IEEE, Web of Science"
N. Dilillo; E. Giusto; E. Dri; B. Baheri; Q. Guan; B. Montrucchio; P. Rech,Understanding the Effect of Transpilation in the Reliability of Quantum Circuits,2023,10.1109/QCE57702.2023.10220,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10313838,Conference Paper,2023 IEEE International Conference on Quantum Computing and Engineering (QCE),"Transpiling is a necessary step to map a logical quantum algorithm to a circuit executed on a physical quantum machine, according to the available gate set and connectivity topology. Different transpiling approaches try to minimize the most critical parameters for the current transmon technology, such as Depth and CNOT number. Crucially, these approaches do not take into account the reliability of the circuit. In particular, transpilation can modify how radiation-induced transient faults propagate. In this paper, we aim at advancing the understanding of transpilation impact on fault propagation by investigating the low-level reliability of several transpiling approaches. We considered 4 quantum algorithms transpiled for 2 different architectures, increasing the number of qubits, and all possible logical-to-physical qubit mapping, adding to a total of 4, 640 transpiled circuits. We inject a total of 202, 124 faults and track their propagation. Our experiments show that by simply choosing the proper transpilation, the reliability of the circuit can improve by up to 14%.",IEEE
B. Liu,Damage Detection of Civil Structures Based on Quantum Behavior Particle Swarm Optimization Algorithm,2023,10.1109/ICICACS57338.2023.10099904,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10099904,Conference Paper,2023 IEEE International Conference on Integrated Circuits and Communication Systems (ICICACS),"In the field of civil engineering, the design and manufacture of structural materials is a very important part of engineering construction. With the continuous development of China's construction industry, the requirements for the quality of civil structural components are getting higher and higher. Therefore, in order to detect the damage of civil structures in time, this paper proposes a quantum behavior particle swarm optimization algorithm to improve the detection capability of civil structures. In this paper, a neural network adaptive learning technology and wavelet transform threshold clustering algorithm based on Monte Carlo simulation, random sequence prediction and support vector machine regression are obtained by combining statistical description method and experimental method. The experimental results show that the minimum error of wavelet detection can reach 2.4%, indicating that the algorithm has certain advantages in civil engineering results detection.",IEEE
H. Kuang; Y. Zhao; Y. Sun; J. Han,General Vector Instruction Extension for GF(2m) Polynomial Operation in Post-quantum Cryptography,2023,10.1109/ASICON58565.2023.10396597,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10396597,Conference Paper,2023 IEEE 15th International Conference on ASIC (ASICON),"We present a general vector instruction extension applicable for both ARM NEON and RISC-V Vector Extension. The extension targets efficient bit-manipulation and can provide considerable speedup for applications in GF(2m) such as code-based post-quantum cryptography schemes. The effectiveness of the extension is evaluated by using the custom instructions to optimize the kernel operations in BIKE key-encapsulation schemes. We first innovate vectorized versions of bit-polynomial multiplication and inversion algorithms in GF(2m) and propose vector instruction extension. Furthermore, a configurable hardware unit has been proposed to support custom operations of different bandwidths at little cost and constant latency. Both experiments on Xilinx UltraScale+ ZCU104 for ARM and simulations on gem5 for RISC-V have been carried out. Compared to portable C implementation, the result shows a speedup for bit-polynomial multiplication and inversion of up to 13x and 16x in ARM, 13x and 22x in RISC-V respectively.",IEEE
K. Goodenough; S. de Bone; V. Addala; S. Krastanov; S. Jansen; D. Gijswijt; D. Elkouss,Near-Term n to k Distillation Protocols Using Graph Codes,2024,10.1109/JSAC.2024.3380094,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10479665,Journal,IEEE Journal on Selected Areas in Communications,"Noisy hardware forms one of the main hurdles to the realization of a near-term quantum internet. Distillation protocols allows one to overcome this noise at the cost of an increased overhead. We consider here an experimentally relevant class of distillation protocols, which distill  $n$  to  $k$  end-to-end entangled pairs using bilocal Clifford operations, a single round of communication and a possible final local operation depending on the observed measurement outcomes. In the case of permutationally invariant depolarizing noise on the input states, we find a correspondence between these distillation protocols and graph codes. We leverage this correspondence to find provably optimal distillation protocols in this class for several tasks important for the quantum internet. This correspondence allows us to investigate use cases for so-called non-trivial measurement syndromes. Furthermore, we detail a recipe to construct the circuit used for the distillation protocol given a graph code. We use this to find circuits of short depth and small number of two-qubit gates. Additionally, we develop a black-box circuit optimization algorithm, and find that both approaches yield comparable circuits. Finally, we investigate the teleportation of encoded states and find protocols which jointly improve the rate and fidelities with respect to prior art.","IEEE, Web of Science"
H. D. Lu; B. Y. Chen; F. M. Guo,The model optimized of mini packaging for quantum dots photodetector readout,2015,10.1109/ICEP-IAAC.2015.7111081,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7111081,Conference Paper,2015 International Conference on Electronics Packaging and iMAPS All Asia Conference (ICEP-IAAC),"The paper shows the research of readout model optimized and mini packaging for the quantum dots photodetector array. The genetic algorithms are used to quantum dots photodetector modeling for accurate readout photoelectric response signal. Three kinds different equivalent circuit model were compared each other and simulated with Cadence IC design software respectively. We developed CTIA readout structure for the quantum dots photodetector array, the readout noise and different substrate materials has simulated by ADS to minimize noise and interference. Two kinds of silicon interposer, namely via-with-one-line and via-with-four-line, have been compared, and demonstrate the via-with-four-line silicon interposer is better than via-with-one-line silicon. Other interposers such as PCB and ceramic interposers still reduce more crosstalk and suppress noise. We still designed the data acquisition and processing analysis unit system, providing Wi-Fi interface to communicate with the PC software to complete the tasks like data acquisition, digital filtering, spectral display, network communication, human-computer interaction etc. Based on high sensitivity of the quantum dots photodetector, the system integrated has more short integration time (10 us), lower noise, and better ability to resist overflow and large dynamic range.",IEEE
H. Chai; S. Leng; J. Hu; K. Yang,Resources allocation in SWIPT aided fog computing networks,2017,10.1109/ICAIT.2017.8388922,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8388922,Conference Paper,2017 9th International Conference on Advanced Infocomm Technology (ICAIT),"Fog computing has emerging as a promising technique to meet the ultra-low latency services in wireless network such as Augmented Reality (AR). The fog paradigm tends to distribute computing, storage, control, network resources and services closer to terminal devices as much as possible while most of User Equipments (UEs) do not have constant power supply thus the power supplement has developed as a nontrivial challenge to realize the paradigm. In this paper, simultaneous wireless information and power transfer (SWIPT) is introduced as a power resource to guarantee the UEs complete their computing tasks. We proposed a power, time and data allocation scheme to minimize the total consumption of energy at source node while maintaining the latency requirement. A Quantum particle swarm optimization (QPSO) algorithm in introduced to solve the non-convex problem, numerical results reveal that our proposed allocation scheme consumes less energy than the conventional particle swarm optimization approach.",IEEE
S. M. GBASHI; O. O. OLATUNJI; P. A. ADEDEJI; N. MADUSHELE,Hybrid Quantum Convolutional Neural Network for Defect Detection in a Wind Turbine Gearbox,2024,10.1109/PowerAfrica61624.2024.10759407,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10759407,Conference Paper,2024 IEEE PES/IAS PowerAfrica,"Convolutional neural networks (CNNs) have been acknowledged for their effectiveness in vibration-based fault detection. However, when used to model high-dimensional vibration signals, the training cost increases exponentially. In this study, we present a hybrid quantum-classical approach that leverages the computational efficiency of quantum states to improve the training of a CNN fault diagnostic model. The proposed framework is validated with vibration signals from the intermediate speed shaft bearing of a wind turbine gearbox. We assess the performance of the hybrid quantum classical CNN (HQC-CNN) model across various optimizers, including adaptive moment estimation (Adam), stochastic gradient descent (SGD), and adaptive gradient algorithm (Adagrad). The Adam and SGD- based HQC-CNN models both showed superior resilience to overfitting at higher training epochs; however, while the Adam- based model required 93 seconds of run time to reach optimal classification accuracy, the SGD-based model required 243 seconds. All models achieved above 99.2% gearbox health state prediction accuracy. The Adam optimizer is recommended for integration into the HQC-CNN model to minimize computational resources while ensuring precise diagnosis of wind turbine gearbox health conditions.",IEEE
Q. Huang; D. Winderl; A. Meijer-van de Griend; R. Yeung,Redefining Lexicographical Ordering: Optimizing Pauli String Decompositions for Quantum Compiling,2024,10.1109/QCE60285.2024.00108,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10821336,Conference Paper,2024 IEEE International Conference on Quantum Computing and Engineering (QCE),"In quantum computing, the efficient optimization of Pauli string decompositions is a crucial aspect for the compilation of quantum circuits for many applications, such as chemistry simulations and quantum machine learning. In this paper, we propose a novel algorithm for the synthesis of trotterized time-evolution operators that results in circuits with significantly fewer gates than previous solutions. Our synthesis procedure takes the qubit connectivity of a target quantum computer into account. As a result, the generated quantum circuit does not require routing, and no additional CNOT gates are needed to run the resulting circuit on a target device. We compare our algorithm against Paulihedral and TKET, and show a significant improvement for randomized circuits and different molecular ansatzes. We also investigate the Trotter error introduced by our ordering of the terms in the Hamiltonian versus default ordering and the ordering from the baseline methods and conclude that our method on average does not increase the Trotter error.",IEEE
S. -H. Chiew; K. Poirier; R. Mishra; U. Bornheimer; E. Munro; S. H. Foon; C. W. Chen; W. S. Lim; C. W. Nga,Multiobjective Optimization and Network Routing With Near-Term Quantum Computers,2024,10.1109/TQE.2024.3386753,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10502334,Journal,IEEE Transactions on Quantum Engineering,"Multiobjective optimization is a ubiquitous problem that arises naturally in many scientific and industrial areas. Network routing optimization with multiobjective performance demands falls into this problem class, and finding good quality solutions at large scales is generally challenging. In this work, we develop a scheme with which near-term quantum computers can be applied to solve multiobjective combinatorial optimization problems. We study the application of this scheme to the network routing problem in detail, by first mapping it to the multiobjective shortest-path problem. Focusing on an implementation based on the quantum approximate optimization algorithm (QAOA)¡ªthe go-to approach for tackling optimization problems on near-term quantum computers¡ªwe examine the Pareto plot that results from the scheme and qualitatively analyze its ability to produce Pareto-optimal solutions. We further provide theoretical and numerical scaling analyses of the resource requirements and performance of QAOA and identify key challenges associated with this approach. Finally, through Amazon Braket, we execute small-scale implementations of our scheme on the IonQ Harmony 11-qubit quantum computer.",IEEE
S. Jiang; S. Yang,An improved quantum-behaved particle swarm optimization algorithm based on linear interpolation,2014,10.1109/CEC.2014.6900354,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6900354,Conference Paper,2014 IEEE Congress on Evolutionary Computation (CEC),"Quantum-behaved particle swarm optimization (QPSO) has shown to be an effective algorithm for solving global optimization problems that are of high complexity. This paper presents a new QPSO algorithm, denoted LI-QPSO, which employs a model-based linear interpolation method to strengthen the local search ability and improve the precision and convergence performance of the QPSO algorithm. In LI-QPSO, linear interpolation is used to approximate the objective function around a pre-chosen point with high quality in the search space. Then, local search is used to generate a promising trial point around this pre-chosen point, which is then used to update the worst personal best point in the swarm. Experimental results show that the proposed algorithm provides some significant improvements in performance on the tested problems.",IEEE
J. Jiang; J. Xu; Y. Xie; Y. Zhu; Z. Li; C. Yang,A Cooperative Computation Offloading Scheme for Dense Wireless Sensor-assisted Smart Grid Networks,2021,10.1109/ICCCS52626.2021.9449185,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9449185,Conference Paper,2021 IEEE 6th International Conference on Computer and Communication Systems (ICCCS),"The emerging applications in wireless sensor-based smart grid networks has provided higher demands on latency, and such latency-sensitive applications also require dense computations, especially in dense wireless sensor networks. To further satisfy the huge demands on communication and computation resources, mobile edge computing (MEC) has been proposed to offload computation tasks from terminals to nearby MEC servers that are deployed on wireless sensors. However, in the practical scenario, due to the expensive cost of deploying MEC servers, the amount of the deployed MEC servers is always limited, i.e., it may be much lower than that of sensors or terminals. As a result, the computation offloading in MEC-assisted dense wireless sensor network still faces open challenges. To address the above issue, we propose a joint MEC and device-to-device(D2D)-based computation offloading scheme. Specifically, we formulate the computation offloading problem as a joint access selection and resource allocation optimization, which minimizes the energy consumption while requested bandwidths and delay are satisfied. Then, we solve the formulated problem by designing a quantum behaved particle swarm optimization (QPSO) algorithm. The simulation results demonstrate that the proposed scheme can improve the efficiency of computation offloading and decrease the energy consumption in the MEC-assisted dense wireless sensor-based smart grid networks.",IEEE
O. J. Nwobodo; K. Wereszczy¨½ski; G. S. Kuaban; P. Skurowski; K. A. Cyran,An Adaptation of Fitts¡¯ Law for Performance Evaluation and Optimization of Augmented Reality (AR) Interfaces,2024,10.1109/ACCESS.2024.3498444,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10752958,Journal,IEEE Access,"There is growing widespread adoption of augmented reality in tech-driven industries and sectors of society, such as medicine, gaming, flight simulation, education, interior design and modelling, entertainment, construction, tourism, repair and maintenance, public safety, agriculture, and quantum computing. However, ensuring smooth and intuitive interactions with augmented objects is challenging, requiring practical performance evaluation and optimization models to assess and improve users¡¯ experiences with AR-enhanced systems. In this paper, we apply Fitts¡¯ Law to model and predict interaction task difficulty with objects distributed across four spatial quadrants. We use genetic optimization algorithms to fine-tune Fitts¡¯ Law parameters, achieving a model that significantly enhances predictive accuracy. Our optimized model demonstrates an approximately 40% reduction in interaction task difficulty across all quadrants, leading to a more ergonomic and intuitive user interface. This study contributes to the Human-Computer Interaction (HCI) field by offering a refined metric for evaluating and optimizing AR interfaces and addressing the unique challenges of three-dimensional interaction environments. Therefore, we propose a practical framework for the performance evaluations and optimization of augmented reality and other user interfaces.",IEEE
A. Bentellis; A. Matic-Flierl; C. B. Mendl; J. M. Lorenz,Benchmarking the Variational Quantum Eigensolver using different quantum hardware,2023,10.1109/QCE57702.2023.00065,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10313698,Conference Paper,2023 IEEE International Conference on Quantum Computing and Engineering (QCE),"The Variational Quantum Eigensolver (VQE) is a promising quantum algorithm for applications in chemistry within the Noisy Intermediate-Scale Quantum (NISQ) era. The ability for a quantum computer to simulate electronic structures with high accuracy would have a profound impact on material and biochemical science with potential applications e.g., to the development of new drugs. However, considering the variety of quantum hardware architectures, it is still uncertain which hardware concept is most suited to execute the VQE for e.g., the simulation of molecules. Aspects to consider here are the required connectivity of the quantum circuit used, the size and the depth and thus the susceptibility to noise effects. Besides theo-retical considerations, empirical studies using available quantum hardware may help to clarify the question of which hardware technology might be better suited for a certain given application and algorithm. Going one step into this direction, within this work, we present results using the VQE for the simulation of the hydrogen molecule, comparing superconducting and ion trap quantum computers. The experiments are carried out with a standardized setup of ansatz and optimizer, selected to reduce the number of required iterations. The findings are analyzed considering different quantum processor types, calibration data as well as the depth and gate counts of the circuits required for the different hardware concepts after transpilation.",IEEE
C. Campbell; F. T. Chong; D. Dahl; P. Frederick; P. Goiporia; P. Gokhale; B. Hall; S. Issa; E. Jones; S. Lee; A. Litteken; V. Omole; D. Owusu-Antwi; M. A. Perlin; R. Rines; K. N. Smith; N. Goss; A. Hashim; R. Naik; E. Younis; D. Lobser; C. G. Yale; B. Huang; J. Liu,Superstaq: Deep Optimization of Quantum Programs,2023,10.1109/QCE57702.2023.00116,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10313801,Conference Paper,2023 IEEE International Conference on Quantum Computing and Engineering (QCE),"We describe Superstaq, a quantum software platform that optimizes the execution of quantum programs by tailoring to underlying hardware primitives. For benchmarks such as the Bernstein-Vazirani algorithm and the Qubit Coupled Cluster chemistry method, we find that deep optimization can improve program execution performance by at least 10x compared to prevailing state-of-the-art compilers. To highlight the versatility of our approach, we present results from several hardware platforms: superconducting qubits (AQT @ LBNL, IBM Quantum, Rigetti), trapped ions (QSCOUT), and neutral atoms (Infleqtion). Across all platforms, we demonstrate new levels of performance and new capabilities that are enabled by deeper integration between quantum programs and the device physics of hardware.",IEEE
A. Delilbasic; B. Le Saux; M. Riedel; K. Michielsen; G. Cavallaro,A Single-Step Multiclass SVM Based on Quantum Annealing for Remote Sensing Data Classification,2024,10.1109/JSTARS.2023.3336926,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10329968,Journal,IEEE Journal of Selected Topics in Applied Earth Observations and Remote Sensing,"In recent years, the development of quantum annealers has enabled experimental demonstrations and has increased research interest in applications of quantum annealing, such as in quantum machine learning and in particular for the popular quantum support vector machine (SVM). Several versions of the quantum SVM have been proposed, and quantum annealing has been shown to be effective in them. Extensions to multiclass problems have also been made, which consist of an ensemble of multiple binary classifiers. This article proposes a novel quantum SVM formulation for direct multiclass classification based on quantum annealing, called quantum multiclass SVM (QMSVM). The multiclass classification problem is formulated as a single quadratic unconstrained binary optimization problem solved with quantum annealing. The main objective of this article is to evaluate the feasibility, accuracy, and time performance of this approach. Experiments have been performed on the D-Wave Advantage quantum annealer for a classification problem on remote sensing data. Results indicate that, despite the memory demands of the quantum annealer, QMSVM can achieve an accuracy that is comparable to standard SVM methods, such as the one-versus-one (OVO), depending on the dataset (compared to OVO: 0.8663 versus 0.8598 on Toulouse, 0.8123 versus 0.8521 on Potsdam). More importantly, it scales much more efficiently with the number of training examples, resulting in nearly constant time (compared to OVO: 85.72 versus 248.02 s on Toulouse, 58.89 versus 580.17 s on Potsdam). This article shows an approach for bringing together classical and quantum computation, solving practical problems in remote sensing with current hardware.",IEEE
C. J. Wood,Special Session: Noise Characterization and Error Mitigation in Near-Term Quantum Computers,2020,10.1109/ICCD50377.2020.00016,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9283531,Conference Paper,2020 IEEE 38th International Conference on Computer Design (ICCD),"A detailed understanding of the noise processes and errors in near-term quantum computers is essential for accurate calibration of gates, and for achieving optimal performance when executing near-term applications such as quantum chemistry, optimization, or machine learning problems. This paper introduces several sources of noise in superconducting qubit based quantum computers such as those deployed by IBM, describes some of the main techniques for characterizing the resulting errors, and for mitigating the effects of certain errors without access to quantum error correction. We demonstrate experimental application of these techniques on an IBM Quantum system using the open source Qiskit software library.",IEEE
N. Onizawa; R. Sasaki; D. Shin; W. J. Gross; T. Hanyu,Stochastic Simulated Quantum Annealing for Fast Solution of Combinatorial Optimization Problems,2024,10.1109/ACCESS.2024.3431540,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10605786,Journal,IEEE Access,"Combinatorial optimization problems are frequently classified as NP-hard, which means that the time needed to find the optimal solution generally increases exponentially with the problem size. However, the existing research gap highlights the necessity to develop combinatorial optimization methods capable of scaling to large problems while maintaining low solution latency. In this paper, we introduce stochastic simulated quantum annealing (SSQA) for fast solution of combinatorial optimization problems. SSQA is designed based on stochastic computing, which can simulate quantum annealing (QA) by using multiple replicas of spins (probabilistic bits) in classical computing. The use of stochastic computing leads to an efficient parallel spin-state update algorithm, enabling quick search for a solution around the global minimum energy. Therefore, SSQA realizes quantum-like annealing for large-scale problems and can handle fully connected models in combinatorial optimization, unlike QA. The proposed method is evaluated in MATLAB on graph isomorphism problems, which are typical combinatorial optimization problems. It can handle a 100-times larger problem size compared to QA and a 25-times larger problem size compared to a traditional SA method, respectively, for similar convergence probabilities. The time to solution of SSQA is 11.5 times and 423 times smaller than that of the conventional stochastic simulated annealing method and traditional SA, respectively, when solving a 2,025-node combinatorial optimization problem.",IEEE
J. Kalloor; M. Weiden; E. Younis; J. Kubiatowicz; B. De Jong; C. Iancu,Quantum Hardware Roofline: Evaluating the Impact of Gate Expressivity on Quantum Processor Design,2024,10.1109/QCE60285.2024.00100,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10821315,Conference Paper,2024 IEEE International Conference on Quantum Computing and Engineering (QCE),"The design space of current quantum computers is expansive, with no obvious winning solution, leaving practitioners with a crucial question: ¡°What is the optimal system configuration to run an algorithm?¡± This paper explores hardware design trade-offs across NISQ systems to better guide algorithm and hardware development. Algorithmic workloads and fidelity models drive the evaluation to appropriately capture architectural features such as gate expressivity, fidelity, and crosstalk. As a result of our analysis, we extend the criteria for gate design and selection from only maximizing average fidelity to a more comprehensive approach that additionally considers expressivity with respect to algorithm structures. A custom synthesis-driven compilation workflow that produces minimal circuit representations for a given system configuration drives our methodology and allows us to analyze any gate set effectively. In this work, we focus on native entangling gates (CNOT, ECR, CZ, ZZ, XX, Sycamore, ¡ÌiSWAP), proposed gates (B Gate, 4¡ÌCNOT, -8¡ÌCNOT), as well as parameterized gates (FSim, XY). By providing a method to evaluate the suitability of algorithms for hardware platforms, this work emphasizes the importance of hardware-software codesign for quantum computing.",IEEE
P. Medisetty; L. K. Kumar Pallapothu; P. Chand Evuru; K. B. Prakash; V. M. S. Vulavalapudi; G. P. S. Varma,The Quantum Graph Recurrent Neural Network,2023,10.1109/SmartTechCon57526.2023.10391361,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10391361,Conference Paper,2023 Second International Conference On Smart Technologies For Smart Nation (SmartTechCon),"Machine learning that combines the power of graph neural networks has its own significance in developing quick report analysis for various dynamic data which traditional statistical models may not be able to accomplish. Alongside the use of Quantum Computing in Neural Networks have become increasingly important over the years due to their ability to learn and process complex patterns. The Importance of QNN lies in the approaches it follows like entanglement, interference multiple super positional states, parallel computing, and backpropagation trainings which cannot be possible for Classical Neural Networks to work with. Also, the QNN, GNN integrates with the Quantum Machine Learning techniques like PennyLane that acts as an OpenShift framework to execute the optimized, trained algorithms for quick computational outcomes. This paper contains the use of Quantum Neural Networking, Quantum Machine Learning.",IEEE
T. Q. Duong; L. D. Nguyen; B. Narottama; J. A. Ansere; D. V. Huynh; H. Shin,"Quantum-Inspired Real-Time Optimization for 6G Networks: Opportunities, Challenges, and the Road Ahead",2022,10.1109/OJCOMS.2022.3195219,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9849061,Journal,IEEE Open Journal of the Communications Society,"It is envisioned that 6G, unlike its predecessor 5G, will depart from connected machines and connected people to connected intelligence. The main goal of 6G networks is to support massive connectivity for time-sensitive and computation-sensitive services in mission-critical applications. The creation of real-time optimization (RTO) enabled by the fast growing data analytic and machine learning will seize the opportunities for 6G wireless networks to support such immersive services such as virtual reality (VR), augmented reality (AR), mixed reality (MR), and tactile Internet. Recently, with the rapid development of quantum computers, quantum-inspired optimization and machine learning algorithms have been exploited as efficient solutions for future wireless networks. In this article, we provide a comprehensive view on the new concept of quantum-inspired RTO and its application to the optimal resource allocation for 6G wireless networks. Our main contributions are to introduce some of the initial research results and introduce the potentiality of quantum-inspired RTO on some 6G emerging technologies. Not only do we review the fundamental principles; we also explore the challenges and opportunities of this exciting research direction.",IEEE
T. Nelson; A. Rivera; P. Balaprakash; M. Hall; P. D. Hovland; E. Jessup; B. Norris,Generating Efficient Tensor Contractions for GPUs,2015,10.1109/ICPP.2015.106,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7349652,Conference Paper,2015 44th International Conference on Parallel Processing,"Many scientific and numerical applications, including quantum chemistry modeling and fluid dynamics simulation, require tensor product and tensor contraction evaluation. Tensor computations are characterized by arrays with numerous dimensions, inherent parallelism, moderate data reuse and many degrees of freedom in the order in which to perform the computation. The best-performing implementation is heavily dependent on the tensor dimensionality and the target architecture. In this paper, we map tensor computations to GPUs, starting with a high-level tensor input language and producing efficient CUDA code as output. Our approach is to combine tensor-specific mathematical transformations with a GPU decision algorithm, machine learning and auto tuning of a large parameter space. Generated code shows significant performance gains over sequential and Open MP parallel code, and a comparison with Open ACC shows the importance of auto tuning and other optimizations in our framework for achieving efficient results.",IEEE
I. Krikidis,MIMO With Analogue 1-Bit Phase Shifters: A Quantum Annealing Perspective,2024,10.1109/LWC.2024.3382095,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10479582,Journal,IEEE Wireless Communications Letters,"In this letter, we study the analogue pre/post-coding vector design for a point-to-point multiple-input multiple-output (MIMO) system with 1-bit phase shifters. Specifically, we focus on the signal-to-noise ratio (SNR) maximization problem which corresponds to a combinatorial NP-hard due to the binary phase resolution. Two classical computation heuristics are proposed, i.e., i) an 1-bit real-valued approximation of the optimal digital designs, and ii) an alternating optimization where a Rayleigh quotient problem is solved at each iteration. An iterative quantum annealing (QA)-based heuristic is also investigated, which outperforms classical counterparts and achieves near-optimal performance while ensuring polynomial time complexity. Experimental results in a real-world D-WAVE QA device validate the efficiency of the proposed QA approach.",IEEE
C. Ren; M. Xu; H. Yu; Z. Xiong; Z. Zhang; D. Niyato,Variational Quantum Circuit and Quantum Key Distribution-Based Quantum Federated Learning: A Case of Smart Grid Dynamic Security Assessment,2024,10.1109/ICC51166.2024.10622783,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10622783,Conference Paper,ICC 2024 - IEEE International Conference on Communications,"This paper proposes a hybrid Quantum Federated Learning (QFL) method, called QQFL, a revolutionary approach for Dynamic Security Assessment (DSA) optimized for modern smart grids. Built on the synergy of measurement-device-independent QKD (MDI-QKD) and Variational Quantum Circuit (VQC), QQFL uniquely addresses the challenges of centralized structures and vulnerabilities in existing ML-based DSA techniques. It enables accurate label predictions for quantum states encoded from classical DSA data while ensuring data security via QKD networks. A novel mechanism, the DNN-based MDI-QKD optimizer, ensures optimal secret key exchange. Unlike traditional methods reliant solely on classical CPUs, QQFL integrates QPUs for executing computational tasks. Given the imperative of frequent data transmission in modern rapidly changing smart grid environment, QQFL emphasizes swift online learning and dynamic deployment. Testing on the synthetic Illinois 49-machine 200-bus system affirms QQFL's superior the DSA accuracy while upholding the data privacy of smart grids. Ultimately, QQFL enhances the security, reliability, confidentiality, and robustness of sophisticated smart grids.",IEEE
V. Saravanan; S. M. Saeed,Decomposition-Based Watermarking of Quantum Circuits,2021,10.1109/ISQED51717.2021.9424311,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9424311,Conference Paper,2021 22nd International Symposium on Quality Electronic Design (ISQED),"Quantum computing is an emerging computing paradigm that is expected to offer decisive advantages for critical applications. The design flow of quantum circuits poses problematic security challenges in the presence of variable errors and limited resources (qubits) to support error correction. Yet, quantum computers can be very powerful for several applications if proper hardware/software approaches are deployed.In the current embodiment, quantum circuits are expected to be used for several applications including financial analysis and machine learning in which a designer wants to protect the Intellectual Property (IP) of the quantum circuits. In this paper, we propose a watermarking approach for quantum circuits, which embeds a secret signature during the decomposition phase to verify the ownership of the IP. We evaluate the effectiveness of the proposed approach using Quantum Approximate optimization Algorithm (QAOA) used for solving a Max-Cut problem.",IEEE
U. Ullah; B. Garcia-Zapirain,Quantum Machine Learning Revolution in Healthcare: A Systematic Review of Emerging Perspectives and Applications,2024,10.1109/ACCESS.2024.3353461,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10398184,Journal,IEEE Access,"Quantum computing (QC) stands apart from traditional computing systems by employing revolutionary techniques for processing information. It leverages the power of quantum bits (qubits) and harnesses the unique properties exhibited by subatomic particles, such as superposition, entanglement, and interference. These quantum phenomena enable quantum computers to operate on an entirely different level, exponentially surpassing the computational capabilities of classical computers. By manipulating qubits and capitalising on their quantum states, QC holds the promise of solving complex problems that are currently intractable in the case of traditional computers. The potential impact of QC extends beyond its computational power and reaches into various critical sectors, including healthcare. Scientists and engineers are working diligently to overcome various challenges and limitations associated with QC technology. These include issues related to qubit stability, error correction, scalability, and noise reduction. In such a scenario, our proposed work provides a concise summary of the most recent state of the art based on articles published between 2018 and 2023 in the healthcare domain. Additionally, the approach follows the necessary guidelines for conducting a systematic literature review. This includes utilising research questions and evaluating the quality of the articles using specific metrics. Initially, a total of 2,038 records were acquired from multiple databases, with 468 duplicate records and 1,053 records unrelated to healthcare subsequently excluded. A further 258, 68, and 39 records were eliminated based on title, abstract, and full-text criteria, respectively. Ultimately, the remaining 49 articles were subject to evaluation, thus providing a brief overview of the recent literature and contributing to existing knowledge and comprehension of Quantum Machine Learning (QML) algorithms and their applications in the healthcare sector. This analysis establishes a foundational framework for forthcoming research and development at the intersection of QC and machine learning, ultimately paving the way for innovative approaches to addressing complex challenges within the healthcare domain.",IEEE
B. Colombier; V. -F. Dr?goi; P. -L. Cayrel; V. Grosso,Profiled Side-Channel Attack on Cryptosystems Based on the Binary Syndrome Decoding Problem,2022,10.1109/TIFS.2022.3198277,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9854893,Journal,IEEE Transactions on Information Forensics and Security,"The NIST standardization process for post-quantum cryptography has been drawing the attention of researchers to the submitted candidates. One direction of research consists in implementing those candidates on embedded systems and that exposes them to physical attacks in return. The Classic McEliece cryptosystem, which is among the four finalists of round 3 in the Key Encapsulation Mechanism category, builds its security on the hardness of the syndrome decoding problem, which is a classic hard problem in code-based cryptography. This cryptosystem was recently targeted by a laser fault injection attack leading to message recovery. Regrettably, the attack setting is very restrictive and it does not tolerate any error in the faulty syndrome. Moreover, it depends on the very strong attacker model of laser fault injection, and does not apply to optimised implementations of the algorithm that make optimal usage of the machine words capacity. In this article, we propose a to change the angle and perform a message-recovery attack that relies on side-channel information only. We improve on the previously published work in several key aspects. First, we show that side-channel information, obtained with power consumption analysis, is sufficient to obtain an integer syndrome, as required by the attack framework. This is done by leveraging classic machine learning techniques that recover the Hamming weight information very accurately. Second, we put forward a computationally-efficient method, based on a simple dot product and information-set decoding algorithms, to recover the message from the, possibly inaccurate, recovered integer syndrome. Finally, we present a masking countermeasure against the proposed attack.",IEEE
E. Karabulut; E. Alkim; A. Aysu,"Efficient, Flexible, and Constant-Time Gaussian Sampling Hardware for Lattice Cryptography",2022,10.1109/TC.2021.3107729,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9522059,Journal,IEEE Transactions on Computers,"This paper proposes a discrete Gaussian sampling hardware design that can flexibly support different sampling parameters, that is more efficient (in area-delay product) compared to the majority of earlier proposals, and that has constant execution time. The proposed design implements a Cumulative Distribution Table (CDT) approach, reduces the table size with Gaussian convolutions, and adopts an innovative fusion tree search algorithm to achieve a compact and fast sampling technique¡ªto our best knowledge, this is the first hardware implementation of fusion tree search algorithm. The proposed hardware can support all the discrete Gaussian distributions used in post-quantum digital signatures and key encapsulation algorithms (FALCON, qTESLA, and FrodoKEM), the homomorphic encryption library of SEAL, and other algorithms such BLISS digital signature and LP public-key encryption. Our proposed hardware can be configured at design-time to optimize a single configuration or at run-time to support multiple Gaussian distribution parameters. Our design, furthermore, has constant-time behavior by design, eliminating timing side-channel attacks¡ªthis is achieved by reading all table contents at the same time to also reduce the latency. The results on a Xilinx Virtex-7 FPGA show that our solution can outperform all prior proposals in area-delay product by 1.67¨C235.88¡Á, only falling short to those designed for the LP encryption scheme.",IEEE
C. Jiang; Z. Bai; R. Scalettar,A Fast Selected Inversion Algorithm for Green's Function Calculation in Many-Body Quantum Monte Carlo Simulations,2016,10.1109/IPDPS.2016.69,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7516042,Conference Paper,2016 IEEE International Parallel and Distributed Processing Symposium (IPDPS),"The Hubbard Hamiltonian provides a theoretical framework for describing electron interactions of quantum many-body systems in condensed matter physics. Determinant Quantum Monte Carlo (DQMC) simulations of the Hubbard Hamiltonian have contributed greatly to understanding important properties of materials. Physical measurements such as superconductivity and magnetic susceptibility are based on selected entries of a large set of Green's functions. The computations of Green's functions are equivalent to computing selected blocks of the inverses of large p-cyclic matrices. The performance of the state-of-art algorithm for computing Green's functions is around 100 Gflops on a 12-core Intel ""Ivy Bridge"" processor. In this paper, we describe a fast selected inversion (FSI) algorithm for computing selected entries of Green's functions and present a parallel implementation using hybrid MPI/OpenMP programming. The FSI algorithm rests on three ideas: (1) applying a block cyclic reduction for a structure-preserving reduction, (2) computing the inverse of the reduced block p-cyclic matrix by a structured orthogonal factorization, (3) using the block entries of the inverse of the reduced block p-cyclic matrix as seeds to rapidly form the selected inversion in parallel. Performance results of the new FSI algorithm on Edison, National Energy Research Scientific Computing Center (NERSC)'s Cray XC30 supercomputer, show an 80% improvement to 180 Gflops on the Intel ""Ivy Bridge"" processor. The parallel applications of the FSI algorithm for computing selected entries of multiple Green's functions reach to 20 -- 30 Tflops on 100 compute nodes with 2400 cores. The preliminary results show that the FSI algorithm speeds up a full DQMC simulation of the Hubbard Hamiltonian by a factor of five, reducing from three and a half hours down to only forty minutes on the l2-core processor.",IEEE
C. Rasmussen; S. M. Saeed,Time-Aware Re-Synthesis for Secure Quantum Systems,2024,10.1109/HOST55342.2024.10545389,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10545389,Conference Paper,2024 IEEE International Symposium on Hardware Oriented Security and Trust (HOST),"The demand for reliable quantum computing platforms has led to significant progress in the development of quantum circuit synthesis and compilation methods that map quantum algorithms to the target quantum architecture. In this paper, we show that the synthesis tools can offer opportunities to enhance the security of quantum systems. We propose a time-aware framework for injecting signatures into quantum circuits. We explore different threat models including quantum circuit IP piracy and the unauthorized circuit execution on the quantum hardware. Our proposed framework supports time-aware block/sub-circuit construction and key-based re-synthesis. We validate the effectiveness of our proposed methods using different quantum benchmarks executed on real-world quantum computers. Our results show that our proposed methods are very stealthy for heavily optimized quantum circuits.",IEEE
P. A. Ganeshamurthy; K. Ghosh; C. O'Meara; G. Cortiana; J. Schiefelbein-Lach; A. Monti,Next Generation Power System Planning and Operation With Quantum Computation,2024,10.1109/ACCESS.2024.3509743,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10772098,Journal,IEEE Access,"Innovative solutions and developments are being inspected to tackle rising electrical power demand to be supplied by clean forms of energy. The integration of renewable energy generations, varying nature loads, importance of active role of distribution system and consumer participation in grid operation has changed the landscape of classical power grids. Implementation of smarter applications to plan, monitor, operate the grid safely are deemed paramount for efficient, secure and reliable functioning of grid. These smarter applications for modern power systems demand capabilities such as real-time monitoring, dynamic security analysis, stochastic power flow calculations, large-scale data analytics, and high-dimensional combinatorial and constrained optimization. Although sophisticated computations to process gigantic volume of data to produce useful information in a time critical manner is the paradigm of future grid operations, these enhanced functionalities impose significantly higher computational demands compared to traditional approaches used in conventional power systems. Advancements in quantum technologies holds promising solution for dealing with demanding computational complexity of power system related applications. In this article, we lay out clear motivations for seeking quantum solutions for solving computational burden challenges associated with power system applications. Next, we present the fundamental principles of quantum computing, introduce key quantum algorithms, and offer a comparison of the computational load between classical and quantum approaches for few important mathematical problems, indicating their relevance to various power system applications. Additionally, we provide an overview of quantum solutions for various power system related applications available in current literature and suggest future topics for research. We further highlight challenges with existing quantum solutions for exploiting full quantum capabilities. To this end, this article serves as a bridge for power engineers to the quantum domain by outlining fundamental principles of quantum computation, facilitating a smoother transition to the future of power system computations and also provides quantum experts with insights into new application areas for quantum computing within power systems.",IEEE
S. S. V. D. Rangoju; O. P. Patel; N. Bharill,Advanced Quantum Inspired Evolutionary Algorithm for Multivariate Optimization,2022,10.1109/SNPD54884.2022.10051777,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10051777,Conference Paper,"2022 IEEE/ACIS 23rd International Conference on Software Engineering, Artificial Intelligence, Networking and Parallel/Distributed Computing (SNPD)","In real life, there are many applications where we need to take care of multiple parameters to get the optimized result. Similarly, many scientific and engineering problems require optimization of various parameters to get desired results. Many algorithms work well with a few variables to get optimized results, but on increasing the number of variables, they do not perform well. In this paper, we proposed an advanced quantum-inspired evolutionary algorithm (A-QEAM) to solve optimization problems where the tuning of multiple parameters or variables is required. A-QEAM is characterized by the principle of quantum computing such as superposition and qubit. This algorithm uses a qubit in place of the classical bit. The proposed algorithm is tested on mathematical functions consisting of 2 variables, 10 variables, 30 variables, and 50 variables. The result shows that the proposed algorithm performs well even on increasing the number of variables.",IEEE
A. P. Fournaris; G. Tasopoulos; M. Brohet; F. Regazzoni,Running Longer To Slim Down: Post-Quantum Cryptography on Memory-Constrained Devices,2023,10.1109/COINS57856.2023.10189268,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10189268,Conference Paper,2023 IEEE International Conference on Omni-layer Intelligent Systems (COINS),"Since we are getting closer to the realisation of a quantum computer capable of breaking the currently deployed public key cryptosystems, we need to be ready with the next generation of quantum-safe cryptosystems. In the case of small, low-memory embedded/cyber physical systems frequently used in the IoT world, the adoption of these post-quantum cryptography algorithms (PQC) is far from being straightforward. Currently available implementations are mostly characterized by high memory requirements that make the adoption on constrained devices a difficult challenge. In this work, we explore the feasibility of implementing quantum resistant cryptography on memory-restricted devices and we present the strategies that should be adopted while tackling the problem. We summarize and discuss the most common techniques currently available in literature for trading speed with reduced memory footprint. Discussed techniques range from strategies to minimise the static memory required by an implementation to techniques to deal with large artifact sizes. We show that, by using the appropriated optimization technique, even PQC schemes that require an amount of memory that largely exceeds the memory available on certain devices, can be successfully implemented, while also leaving enough memory for other applications that might reside on the same device.",IEEE
A. Li; D. Liu; X. Li; T. Huang; S. Yang; J. Lu; A. Hu,A Flexible Instruction-based Post-quantum Cryptographic Processor with Modulus Reconfigurable Arithmetic Unit for Module LWR&E,2022,10.1109/A-SSCC56115.2022.9980779,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9980779,Conference Paper,2022 IEEE Asian Solid-State Circuits Conference (A-SSCC),"Post-quantum cryptography (PQC) uses novel difficult mathematical principles to defend the cracking of quantum computers which threaten the traditional crypto system such as Rivest¨CShamir¨C Adleman (RSA) and elliptic curves cryptography (ECC). The lattice-based PQC schemes are currently the most potential candidates. The software methods of these schemes are usually low speed, and optimized dedicated hardware design can accelerate the algorithms. Saber and Kyber are two PQC algorithms which are based on difficult lattice problems of ¡°Module Learning with Rounding¡± (M-LWR) and ¡°Module Learning with Errors¡± (M-LWE). They have different modulus computing domains, which are $2 ^{13}$ and prime 3329 respectively. These characteristics lead to complicated solution and slow operation of conventional implementation, which is not conducive to resource efficiency and flexibility. In this work, we proposed a reconfigurable arithmetic unit with variable modulus domains, and combined with custom instruction-set architecture to design a flexible crypto processor for M-LWR and M-LWE. The work achieved the flexible implementation of variable parameters and instruction programming under the strategy of resource efficiency and performance trade-off, and verified on the FPGA platform.",IEEE
J. -M. Yao; Q. Li; H. -K. Mao; A. A. A. El-Latif,A Practical Multi-Protocol Collaborative Quantum Key Distribution Networking Scheme for Consumer Electronics Devices,2024,10.1109/TCE.2024.3467010,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10690175,Article,IEEE Transactions on Consumer Electronics,"The development of emerging consumer technologies such as the Internet of Things (IoT), artificial intelligence (AI), and cloud computing brings convenience but also raises critical concerns about securing communication data. Quantum computing threatens the security of classical public key cryptography, making post-quantum data protection essential. Quantum Key Distribution (QKD) networks offer a solution, but the dependence on trusted relays raises security concerns. The existing QKD networks mainly consist of two types: measurement-device-dependent protocol based QKD networks which have a high dependence on trusted relays, and measurement-device-independent protocol based QKD networks which have a weak dependence on trusted relays but communication capability is limited. This paper proposes a Multi-Protocol Collaborative (MPC) networking cell combining both types of QKD protocol, which can reduce the dependence on trusted relays while maintaining a high communication capacity, and consequently has an enhanced practicality. An optimal topology method is also designed to further enhance the performance of the networks. Results show that communication capacity is improved 37 times compared to measurement-device-independent protocol based QKD networks. In addition, 23% reduction in the dependence on trusted relays compared to measurement-device-dependent protocol based QKD networks. By overcoming the trade-off between trust and capacity, this work significantly advances the practicalization of QKD networks in consumer electronics.",IEEE
W. Ding; C. -T. Lin; Z. Cao,Deep Neuro-Cognitive Co-Evolution for Fuzzy Attribute Reduction by Quantum Leaping PSO With Nearest-Neighbor Memeplexes,2019,10.1109/TCYB.2018.2834390,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8362716,Journal,IEEE Transactions on Cybernetics,"Attribute reduction with many patterns and indicators has been regarded as an important approach for largescale data mining and machine learning tasks. However, it is extremely difficult for researchers to inadequately extract knowledge and insights from multiple overlapping and interdependent fuzzy datasets from the current changing and interconnected big data sources. This paper proposes a deep neuro-cognitive coevolution for fuzzy attribute reduction (DNCFAR) that contains a combination of quantum leaping particle swarm optimization with nearest-neighbor memeplexes. A key element of DNCFAR resides in its deep neuro-cognitive cooperative co-evolution structure, which is explicitly permitted to identify interdependent variables and adaptively decompose them in the same neurosubpopulation, with minimizing the complexity and nonseparability of interdependent variables among different fuzzy attribute subsets. Next DNCFAR formalizes to the different types of quantum leaping particles with nearest-neighbor memeplexes to share their respective solutions and deeply cooperate to evolve the assigned fuzzy attribute subsets. The experimental results demonstrate that DNCFAR can achieve competitive performance in terms of average computational efficiency and classification accuracy while reinforcing noise tolerance. Furthermore, it can be well applied to clearly identify different longitudinal surfaces of infant cerebrum regions, which indicates its great potential for brain disorder prediction based on fMRI.",IEEE
S. Sinha; D. Santhadevi; S. Tokas; V. Kareer,Quantum cryptanalysis using digital ant in pervasive environment,2016,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7724948,Conference Paper,2016 3rd International Conference on Computing for Sustainable Global Development (INDIACom),"Nowadays security is providing essential provision to prevent unauthorized or illegal access. It has become an essential part of every framework in electronic age. In the present scenario as the world data in increasing exponentially-with time interval, there is an increased threat of malicious data. Hence, security becomes the vital component to make this growing electronic usage leds to a sustainable development in society. Swarm intelligence is an upcoming field; through its stochastic behavior it has the capabilities to solve a greater range of optimization problem. Using the property of Meta heuristic techniques of finding the most optimized solution authors attempted to use them for security purposes. Paper discusses about an agent based meta heuristic based approach to develop cyber defense mechanism where a team of human and software ants mitigate security threat posed in a pervasive environment. The DigitalAnts? system architecture will wander through entire network in identifying the invaders i.e. viruses, trojan horses etc. Also, the quantum theory is used to generate the polynomial data analogous to pheromone in Ant Colony Optimization.","IEEE, Scopus"
A. Trisnandar; M. Teguh Kurniawan,A Survey on Techniques Used to Improve Network Performance and Flexibility in Software Defined Network,2024,10.1109/ICITISEE63424.2024.10729893,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10729893,Conference Paper,"2024 8th International Conference on Information Technology, Information Systems and Electrical Engineering (ICITISEE)","Software Defined Networks (SDN) has revolutionized modern network architecture by providing enhanced flexibility, agility, and programmability. This paradigm change makes centralized control and dynamic network configuration feasible by separating the control plane from the data plane. Various studies have explored techniques to optimize network performance within SDN frameworks. Critical approaches include load balancing, efficient controller selection, and performance analysis, which aim to improve metrics such as throughput and latency. Innovative methods, such as evolutionary synchronization-aware controller placement and integration with machine learning, further enhance SDN's adaptability to complex network environments. SDN's flexibility is underscored by its ability to dynamically allocate resources, manage Quality of Service (QoS), and control network flows. This programmability supports diverse applications and environments, ensuring efficient resource utilization and cost-effective operations. SDN's integration with emerging technologies like quantum networking and machine learning extends its adaptability, enabling the creation of innovative network architectures. Research highlights SDN's potential across various contexts, including vehicular ad-hoc networks, wireless sensor networks, and IoT applications. Techniques such as the African Vulture Routing Optimization (A VRO) algorithm and Ant Colony Optimization (ACO) have significantly improved network performance, underscoring SDN's robustness and versatility. In summary, SDN provides a robust framework for modern network management, offering enhanced flexibility, scalability, and performance optimization in diverse networking scenarios.",IEEE
Y. Zhang; Y. Gong; L. Fan; Y. Wang; Z. Han; Y. Guo,Quantum-Assisted Joint Caching and Power Allocation for Integrated Satellite-Terrestrial Networks,2024,10.1109/TNSE.2024.3435444,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10614917,Journal,IEEE Transactions on Network Science and Engineering,"LowEarth orbit (LEO) satellite network can complement terrestrial networks for achieving global wireless coverage and improving delay-sensitive Internet services. This paper proposes an integrated satellite-terrestrial network (ISTN) architecture to provide ground users with seamless and reliable content delivery services. For optimal service provisioning in this architecture, we formulate an optimization model to maximize the network throughput by jointly optimizing content delivery policy, cache placement, and transmission power allocation. The resulting optimization model is a large-scale mixed-integer nonlinear program (MINLP) that is intractable for classical computer solvers. Inspired by quantum computing techniques, we propose a hybrid quantum-classical generalized Benders' decomposition (HQCGBD) algorithm to address this challenge. Specifically, we first exploit the generalized Benders' decomposition (GBD) to decompose the problem into a master problem and a subproblem and then leverage the state-of-the-art quantum annealer to solve the challenging master problem. Furthermore, a multi-cut strategy is designed in HQCGBD to accelerate the solution process by leveraging the quantum advantages in parallel computing. Simulation results demonstrate the superiority of the proposed HQCGBD algorithm and validate the effectiveness of the proposed cache-enabled ISTN architecture.",IEEE
Y. Zhang; Y. Gong; L. Fan; Y. Wang; Z. Han; Y. Guo,Quantum-Assisted Joint Virtual Network Function Deployment and Maximum Flow Routing for Space Information Networks,2025,10.1109/TMC.2024.3466857,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10691643,Journal,IEEE Transactions on Mobile Computing,"Network function virtualization (NFV)-enabled space information network (SIN) has emerged as a promising method to facilitate global coverage and seamless service. This paper proposes a novel NFV-enabled SIN to provide end-to-end communication and computation services for ground users. Based on the multi-functional time expanded graph (MF-TEG), we jointly optimize the user association, virtual network function (VNF) deployment, and flow routing strategy (U-VNF-R) to maximize the total processed data received by users. The original problem is a mixed-integer linear program (MILP) that is intractable for classical computers. Inspired by quantum computing techniques, we propose a hybrid quantum-classical Benders¡¯ decomposition (HQCBD) algorithm. Specifically, we convert the master problem of the Benders¡¯ decomposition into the quadratic unconstrained binary optimization (QUBO) model and solve it with quantum computers. To further accelerate the optimization, we also design a multi-cut strategy based on the quantum advantages in parallel computing. Numerical results demonstrate the effectiveness and efficiency of the proposed algorithm and U-VNF-R scheme.",IEEE
S. Wang; R. Zhao; Z. Yu; L. Wang,Optimized implementations of stream cipher ZUC-256 algorithm,2022,10.1109/IAECST57965.2022.10061968,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10061968,Conference Paper,2022 4th International Academic Exchange Conference on Science and Technology Innovation (IAECST),"ZUC-256 is a more secure stream cipher based on ZUC-128 developed independently by China, which emerged mainly to cope with the advent of 5G communication and the post-quantum cipher era. Based on the ZUC-256 encryption algorithm, this paper focuses on its working phase and proposes two optimization methods for the working phase, one is a pipelined structure that focuses more on increasing the frequency, and the other is based on the specificity of the modulo operation in the algorithm, which focuses on reducing the resource overhead. The final validation results show that the first method increased frequency by 37.2% and the second method reduced resource overhead by 18.7%. These two optimization methods show that the ZUC algorithm is quite flexible in balancing different throughputs with resource overheads.",IEEE
M. Gowrishankar; J. Wright; D. Claudino; P. Lotshaw; T. Nguyen; A. McCaskey; T. Humble,Numerical Simulations of Noisy Quantum Circuits for Computational Chemistry,2022,10.1109/QCE53715.2022.00128,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9951241,Conference Paper,2022 IEEE International Conference on Quantum Computing and Engineering (QCE),"The opportunities afforded by near-term quantum computers to calculate the ground-state properties of small molecules depend on the structure of the computational ansatz as well as the errors induced by device noise. Here we investigate the behavior of these noisy quantum circuits using numerical simulations to estimate the accuracy and fidelity of the prepared quantum states relative to the ground truth obtained by conventional means. We implement several different types of ansatz circuits derived from unitary coupled cluster theory for the purposes of estimating the ground-state energy of sodium hydride using the variational quantum eigensolver algorithm. We show how relative error in the energy and the fidelity scale with the levels of gate-based noise, the internuclear configuration, the ansatz circuit depth, and the parameter optimization methods.",IEEE
A. ZAIOU; B. MATEI; Y. BENNANI; M. HIBTI,Convex Non-negative Matrix Factorization Through Quantum Annealing,2021,10.1109/HPCC-DSS-SmartCity-DependSys53884.2021.00191,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9780934,Conference Paper,"2021 IEEE 23rd Int Conf on High Performance Computing & Communications; 7th Int Conf on Data Science & Systems; 19th Int Conf on Smart City; 7th Int Conf on Dependability in Sensor, Cloud & Big Data Systems & Application (HPCC/DSS/SmartCity/DependSys)","In this paper we provide the quantum version of the Convex Non-negative Matrix Factorization algorithm (Convex-NMF) by using the D-wave quantum annealer. More precisely, we use D-wave 2000Q to find the low rank approximation of a fixed real-valued matrix $X$ by the product of two non-negative matrices factors $W$ and $G$ such that the Frobenius norm of the difference $X$ - XWG is minimized. In order to solve this optimization problem we proceed in two steps. In the first step we transform the global real optimization problem depending on $W, G$ into two quadratic unconstrained binary optimization problems (QUBO) depending on $W$ and $G$ respectively. In the second step we use an alternative strategy between the two QUBO problems corresponding to $W$ and $G$ to find the global solution. The running of these two QUBO problems on D-wave 2000Q need to use an embedding to the chimera graph of D-wave 2000Q, this embedding is limited by the number of qubits of D-wave 2000Q. We perform a study on the maximum number of real data to be used by our approach on $\mathbf{D}$ -wave 2000Q. The proposed study is based on the number of qubits used to represent each real variable. We also tested our approach on D-Wave 2000Q with several randomly generated data sets to prove that our approach is faster than the classical approach and also to prove that it gets the best results.",IEEE
S. Pathak; A. Mani; A. Chatterjee,An Opposition Learning-based Quantum Inspired Salp Swarm Optimization for The Multiobjective Controller Placement Problem,2023,10.1109/UPCON59197.2023.10434821,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10434821,Conference Paper,"2023 10th IEEE Uttar Pradesh Section International Conference on Electrical, Electronics and Computer Engineering (UPCON)","This paper tackles the multiobjective controller placement problem in Software Defined Networks (SDN), a complex optimization challenge affecting network Quality of Service (QoS). In contrast to prior approaches focusing solely on propagation latency, our method considers propagation latency, inter-controller latency, and load balancing when allocating switches to controllers. We introduce EQSSA, a hybrid model that combines Elite Opposition Learning (EOL), Quantum Computing, and the Salp Swarm Optimization Algorithm (SSA). SSA is a powerful meta-heuristic for real-world optimization problems, while EOL adds cost-effectiveness and efficiency to problem-solving. Quantum-inspired techniques enhance exploration and exploitation compared to standard methods. The hybridization aims to maintain SSA's diversity and computing power. We formulate the multiobjective controller placement problem (MOCPP) based on Pareto optimality and employ EQSSA for evaluation. Experimental results, compared to standard SSA and tested on well-known benchmarks, affirm the effectiveness of our approach, demonstrating EQSSA's competitiveness in solving MOCPP and offering a promising solution to SDN controller placement challenges.",IEEE
S. -I. Chu; S. -A. Ke,Area-Time Efficient Hardware Implementation for Binary Ring-LWE Based Post-Quantum Cryptography,2024,10.1109/TETC.2024.3482324,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10733832,Article,IEEE Transactions on Emerging Topics in Computing,"Post-quantum cryptography (PQC) has recently gained intensive attention as the existing public-key cryptosystems are vulnerable to quantum attacks. The ring-learning-with-errors (RLWE)-based PQC is one promising type of the lattice-based schemes. A light variant, called binary RLWE (BRLWE), was developed with applications to Internet-of-Things (IoT) and edge computing. However, deploying the number theoretic transform (NTT) is not beneficial to the parameter settings of the BRLWE-based scheme. This paper presents three high-speed architectures of decryption for the BRLWE-based scheme with low area-time complexity. The first one is modified and corrected from the low-latency design of the previous work. The second and third ones utilize the multiplexer-based design for multiplication and innovatively exploit the property of the skew-circulant matrix to reduce the computational latency. Moreover, the third one applies the Karatsuba algorithm to reduce the number of multiplications. However, the results demonstrate that it is not in favor of the design since the multiplication is involved in an integer and a binary number, not both integers. Let the lengths of the secret and public keys be $n$ and $n\log _{2}q$ bits. The synthesized results reveal that the second and third architectures are superior to the lookup table (LUT)-based and linear- feedback shift register (LFSR)-based designs in the previous works in terms of area-time complexity. The FPGA implementation results indicate the second design outperforms the Karatsuba and Toeplitz matrix vector product (TMVP)-initiated accelerators in the literatures by reductions of 62.4% and 51.7% in area-time complexity for the case of $(n, q) = (256, 256)$. As $(n,q)=(512,256)$, the improvements are 44.3% and 28.3%. The third architecture is also superior to these high-speed designs. The proposed implementations are efficient in area-time complexity and are suitable for high-performance applications.",IEEE
Y. Cao; Y. Zhao; J. Li; R. Lin; J. Zhang; J. Chen,Hybrid Trusted/Untrusted Relay-Based Quantum Key Distribution Over Optical Backbone Networks,2021,10.1109/JSAC.2021.3064662,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9373434,Journal,IEEE Journal on Selected Areas in Communications,"Quantum key distribution (QKD) has demonstrated a great potential to provide future-proofed security, especially for 5G and beyond communications. As the critical infrastructure for 5G and beyond communications, optical networks can offer a cost-effective solution to QKD deployment utilizing the existing fiber resources. In particular, measurement-device-independent QKD shows its ability to extend the secure distance with the aid of an untrusted relay. Compared to the trusted relay, the untrusted relay has obviously better security, since it does not rely on any assumption on measurement and even allows to be accessed by an eavesdropper. However, it cannot extend QKD to an arbitrary distance like the trusted relay, such that it is expected to be combined with the trusted relay for large-scale QKD deployment. In this work, we study the hybrid trusted/untrusted relay based QKD deployment over optical backbone networks and focus on cost optimization during the deployment phase. A new network architecture of hybrid trusted/untrusted relay based QKD over optical backbone networks is described, where the node structures of the trusted relay and untrusted relay are elaborated. The corresponding network, cost, and security models are formulated. To optimize the deployment cost, an integer linear programming model and a heuristic algorithm are designed. Numerical simulations verify that the cost-optimized design can significantly outperform the benchmark algorithm in terms of deployment cost and security level. Up to 25% cost saving can be achieved by deploying QKD with the hybrid trusted/untrusted relay scheme while keeping much higher security level relative to the conventional point-to-point QKD protocols that are only with the trusted relays.","IEEE, Web of Science"
S. Ebrahimi; S. Bayat-Sarmadi; H. Mosanaei-Boorani,Post-Quantum Cryptoprocessors Optimized for Edge and Resource-Constrained Devices in IoT,2019,10.1109/JIOT.2019.2903082,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8660431,Journal,IEEE Internet of Things Journal,"By exponential increase in applications of the Internet of Things (IoT), such as smart ecosystems or e-health, more security threats have been introduced. In order to resist known attacks for IoT networks, multiple security protocols must be established among nodes. Thus, IoT devices are required to execute various cryptographic operations, such as public key encryption/decryption. However, classic public key cryptosystems, such as Rivest-Shammir-Adlemon and elliptic curve cryptography are computationally more complex to be efficiently implemented on IoT devices and are vulnerable regarding quantum attacks. Therefore, after complete development of quantum computing, these cryptosystems will not be secure and practical. In this paper, we propose InvRBLWE, an optimized variant for binary learning with errors over the ring (Ring-LWE) scheme that is proven to be secure against quantum attacks and is highly efficient for hardware implementations. We propose two architectures for InvRBLWE: 1) a high-speed architecture targeting edge and powerful IoT devices and 2) an ultralightweight architecture, which can be implemented on resource-constrained nodes in IoT. The proposed architectures are scalable regarding security levels and we provide experimental results for two versions of the InvRBLWE scheme providing 84 and 190 bits of classic security. Our implementation results on field programmable gate array dominate the best of the classic and post-quantum previous implementations. Moreover, our two different application specific integrated circuit (ASIC) implementations show improvement in terms of speed, area, power, and/or energy. To the best of our knowledge, we are the first to implement learning with error-based cryptosystems on ASIC platform.",IEEE
B. Zhao; Z. Wei; B. Liu; Jinshu Su; Ilsun You,Providing adaptive quality of security in quantum networks,2015,10.4108/eai.19-8-2015.2260982,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7332609,Conference Paper,"2015 11th International Conference on Heterogeneous Networking for Quality, Reliability, Security and Robustness (QSHINE)","Recently, several Quantum Key Distribution (QKD) networks, such as Tokyo QKD, SECOQC, have been built to evaluate the quantum based OTP(One Time Pad) secure communication. As an ideal unconditional secure technique, OTP requires the key rate the same as the information rate. However, comparing with high speed information traffic (Gbps), the key generation rate of QKD is very poor(Kbps). Therefore, in practical QKD networks, it is difficult to support numerous applications and multiple users simultaneously. To address this issue, we argue that it is more practical to provide quality of security instead of OTP in quantum networks. We further propose ASM, an Adaptive Security Selection Mechanism for quantum networks based on the Analytic Hierarchy Process (AHP). In ASM, services can select an appropriate encryption algorithm that satisfies the proper security level and performance metrics under the limit of the key generation rate. We also implement ASM under our RT-QKD platform, and evaluate its performance. Experimental results demonstrate that ASM can select the optimal algorithm to meet the requirement of security and performance under an acceptable cost.",IEEE
S. Xu; X. Chen; Y. Guo; S. -M. Yiu; S. Gao; B. Xiao,Efficient and Secure Post-Quantum Certificateless Signcryption with Linkability for IoMT,2024,10.1109/TIFS.2024.3520007,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10806671,Article,IEEE Transactions on Information Forensics and Security,"Internet of Medical Things (IoMT) has gained significant research focus in both academic and medical institutions. Nevertheless, the sensitive data involved in IoMT raises concerns regarding user validation and data privacy. To address these concerns, certificateless signcryption (CLSC) has emerged as a promising solution, offering authenticity, confidentiality, and unforgeability. Unfortunately, most existing CLSC schemes are impractical for IoMT due to their heavy computational and storage requirements. Additionally, these schemes are vulnerable to quantum computing attacks. Therefore, research focusing on designing an efficient post-quantum CLSC scheme is still farreaching. In this work, we propose PQ-CLSCL, a novel post-quantum CLSC scheme with linkability for IoMT. Our proposed design facilitates secure transmission of medical data between physicians and patients, effectively validating user legitimacy and minimizing the risk of private information leakage. To achieve this, we leverage lattice sampling algorithms and hash functions to generate the partial secret key, and then employ the sign-then-encrypt method as well as design link label. We also formalize and prove the security of our design, including indistinguishability against chosen-ciphertext attacks (IND-CCA2), existential unforgeability against chosen-message attacks (EU-CMA), and linkability. Finally, through comprehensive performance evaluation, our computation overhead is just 5% of some other existing schemes. The evaluation results demonstrate that our solution is practical and efficient.",IEEE
G. Jang; D. Kim; I. -H. Lee; H. Jung,Cooperative Beamforming With Artificial Noise Injection for Physical-Layer Security,2023,10.1109/ACCESS.2023.3252503,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10058521,Journal,IEEE Access,"In the sixth-generation (6G) communications, how to deploy and manage massively connected Internet-of-Things (IoT) nodes will be one of the key technical challenges, because 6G is expected to provide 10 times higher connection, compared to 5G. At the same time, due to the sharp growth in connected devices and newly adopted technologies, learning-based attacks and big data breaches are expected to occur more frequently. With the advances of quantum computing in the future, conventional cryptography-based security protocols may be obsolete in the future wireless networks, which makes physical layer security (PLS) an attractive alternative or complement for secure communications. In this context, cooperative beamforming (CB)-based PLS schemes are known to be effective solutions to guarantee high secrecy rate with IoT devices, which have limited power and hardware complexity. However, the existing CB-based PLS algorithms suffer from extremely low secrecy rate, in case that eavesdroppers are close to the intended receiver. To overcome such critical issue, in this paper, we propose a CB-based PLS with artificial noise (AN) injection, which can be realized in a fully distributed manner to minimize the overhead in the IoT networks with a large number of devices. We analyze the array factor using the virtual antenna array (VAA) created by the proposed PLS algorithm. Then, the secrecy rate is derived in a closed-form expression, which can be used to optimize the performance for given system parameters in both the absence and presence of channel state information (CSI) error. The proposed scheme provides considerably higher secrecy rate compared to the conventional CB-based PLS schemes, when an eavesdropper exists near to the intended receiver. Furthermore, through simulation and numerical results, we show that the secrecy rate of the proposed scheme can be maximized by adjusting the ratio between the data beamformer and AN injection beamformer components. As a result, the proposed method shows a performance improvement of up to two times compared to the conventional CB-based PLS schemes, in terms of the secrecy rate. Such performance gain increases as the angular location of Eve becomes closer to that of Bob, which corresponds to the most vulnerable situation of the conventional CB-based PLS algorithms.",IEEE
Y. Zhu; W. Zhu; Y. Ouyang; J. Sun; M. Zhu; Q. Zhao; J. Yang; C. Chen; Q. Tao; G. Yang; A. Zhang; S. Wei; L. Liu,16.2 A 28nm 69.4kOPS 4.4¦ÌJ/Op Versatile Post-Quantum Crypto-Processor Across Multiple Mathematical Problems,2024,10.1109/ISSCC49657.2024.10454332,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10454332,Conference Paper,2024 IEEE International Solid-State Circuits Conference (ISSCC),"The migration towards post-quantum cryptography (PQC) is in progress to secure communications and transactions against the impending quantum threat, while three key-encapsulation mechanisms (KEM) and one digital signature (DS) scheme are being standardized by NIST [1]. This multi-year migration poses serious challenges to PQC implementations for compatibility and performance requirements in various scenarios and settings: 1) Performance limitations caused by diverse computation patterns and relatively higher computation costs. 2) Crypto-agility resulting from different mathematical problems, various security parameters, or even different standardization bodies. 3.) Domain-specific optimization to address the long-term security of the evolving algorithm families. However, most existing PQC accelerators [2, 3, 5] were only customized for specific algorithms based on unique mathematical problems. The latest configurable PQC processor [4] did not support Falcon and Sphincs+, which are being drafted for standardization. To address this issue, a versatile PQC processor fabricated in 28nm is presented with three key features: 1) task-clustering-based architecture for scalable processing with aggressive parallelism; 2) region-based task-path (TP) with dynamic update for agile cryptographic computing; 3) efficient PQC task-operators (TO), including hash/sample, format, floating-point/complex, encoding/decoding operators, for further improvements on throughput and energy-efficiency. Based on these contributions, the proposed chip supports all predominant schemes in NIST¡¯s PQC standardization, while still delivering 44.6% and 10.3% improvements in the throughput and energy-delay product (EDP), respectively, relative to a state-of-the-art design [4].",IEEE
S. Perriello; A. Barenghi; G. Pelosi,A Quantum Circuit to Execute a Key-Recovery Attack Against the DES and 3DES Block Ciphers,2024,10.1109/QCE60285.2024.00011,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10821442,Conference Paper,2024 IEEE International Conference on Quantum Computing and Engineering (QCE),"Quantum computing enabled cryptanalytic techniques are able to concretely reduce the security margin of existing cryptographic primitives. While this reduction is only polynomial for symmetric cryptosystems, it still provides a reduction in their security margin. In this work, we propose a detailed quantum circuit designed to cryptanalyze both the Data Encryption Standard (DES) cryptosystem, and its successor Triple-DES (3DES), currently standardized in ISO/IEC 18033¨C3, and still widely employed in satellite data and bank card encryption. To do so, we introduce the first quantum circuit implementation of the 8 substitution tables (a.k.a. S-boxes), applying a bitslicing strategy, which is currently the most efficient classical combinatorial circuit design in terms of number of two inputs Boolean gates. Secondly, we present the complete quantum circuits required to attack both DES and 3DES leveraging Grover's algorithm. We provide finite regime, closed form equations, delineating the circuits complexities in terms of the number of qubits, gates, depth and number of qubits multiplied by depth. The complexity analysis is based on two distinct gate sets: a NOT-CNOT-Toffoli (NCT) extended with the Hadamard gate; and the fault-tolerant Clifford+T. Finally, akin to the classical attack to the 3DES, we introduce a meet-in-the-middle strategy relying on an exponential amount of Quantum Random Access Memory. Our findings show that the 3DES with keying option 2, the most widely employed variant of 3DES, can be attacked with a circuit depth of approximately $2^{67}$ and less than a thousand qubits. This is close to the $2^{64}$ value suggested by NIST for the depth achievable sequentially by a single quantum computer in a decade. Our technique can be further sped up parallelizing the approach onto multiple devices, pointing to the practicality of cryptanalyzing 3DES in such a scenario.",IEEE
F. Fan; Y. Shi; T. Guggemos; X. X. Zhu,Hybrid Quantum Deep Learning With Superpixel Encoding for Earth Observation Data Classification,2024,10.1109/TNNLS.2024.3518108,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10819477,Article,IEEE Transactions on Neural Networks and Learning Systems,"Earth observation (EO) has inevitably entered the Big Data era. The computational challenge associated with analyzing large EO data using sophisticated deep learning models has become a significant bottleneck. To address this challenge, there has been a growing interest in exploring quantum computing as a potential solution. However, the process of encoding EO data into quantum states for analysis potentially undermines the efficiency advantages gained from quantum computing. This article introduces a hybrid quantum deep learning model that effectively encodes and analyzes EO data for classification tasks. The proposed model uses an efficient encoding approach called superpixel encoding, which reduces the quantum resources required for large image representation by incorporating the concept of superpixels. To validate the effectiveness of our model, we conducted evaluations on multiple EO benchmarks, including Overhead-MNIST, So2Sat LCZ42, and SAT-6 datasets. In addition, we studied the impacts of different interaction gates and measurements on classification performance to guide model optimization. The experimental results suggest the validity of our model for accurate classification of EO data. Our models and code are available on https://github.com/zhu-xlab/SEQNN.",IEEE
J. -Y. Wu,An evolutionary multi-layer perceptron neural network for solving unconstrained global optimization problems,2016,10.1109/ICIS.2016.7550765,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7550765,Conference Paper,2016 IEEE/ACIS 15th International Conference on Computer and Information Science (ICIS),"This study presents an evolutionary multi-layer perceptron neural network (EvoMLPNN) method, which consists of an MLPNN and an improved quantum-behaved particle swarm optimization (IQPSO) method. This study develops a network topology of an MLPNN that can be used to solve unconstrained global optimization (UGO) problems, and optimizes the weights of the MLPNN by using the IQPSO approach. To evaluate the performance of the proposed EvoMLPNN approach, a set of benchmark UGO problems was used and the numerical results obtained using the EvoMLPNN method were compared with those obtained using published algorithms. Experimental results show that the proposed EvoMLPNN method can find a global optimization solution for each test UGO problem and can solve highly dimensional UGO problems, and that the numerical results of the EvoMLPNN approach outperform to those of some published algorithms.",IEEE
W. Velasquez; F. Jijon-Veliz; M. S. Alvarez-Alvarado,Optimal Wireless Sensor Networks Allocation for Wooded Areas Using Quantum-Behaved Swarm Optimization Algorithms,2023,10.1109/ACCESS.2023.3243541,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10041811,Journal,IEEE Access,"This paper aims to present a robust algorithm developed that aims to minimize the number of sensor nodes in a WSN using three quantum-behaved swarm optimization techniques based on Lorentz (QPSO-LR), Rosen¨CMorse (QPSO-RM), and Coulomb-like Square Root (QPSO-CS) potential fields. The algorithm aims to allocate the minimum number of wireless sensors in forested areas without losing connectivity in an environment with a high penetration of vegetation. The proposed approach incorporates a propagation model that locates the sensor nodes, calculates the approximate separation distance between each one, verifies Line of Sight (LOS) compliance, and avoids considerable intrusions in the first Fresnel zone. The results validate the robustness of the quantum-behaved swarm optimization algorithms in comparison to traditional particle swarm optimization (PSO).",IEEE
D. Bhattacharjee; A. A. Saki; M. Alam; A. Chattopadhyay; S. Ghosh,MUQUT: Multi-Constraint Quantum Circuit Mapping on NISQ Computers: Invited Paper,2019,10.1109/ICCAD45719.2019.8942132,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8942132,Conference Paper,2019 IEEE/ACM International Conference on Computer-Aided Design (ICCAD),"Rapid advancement in the domain of quantum technologies have opened up researchers to the real possibility of experimenting with quantum circuits, and simulating small-scale quantum programs. Nevertheless, the quality of currently available qubits and environmental noise pose a challenge in smooth execution of the quantum circuits. Therefore, efficient design automation flows for mapping a given algorithm to the Noisy Intermediate Scale Quantum (NISQ) computer becomes of utmost importance. State-of-the-art quantum design automation tools are primarily focused on reducing logical depth, gate count and qubit counts with recent emphasis on topology-aware (nearest-neighbour compliance) mapping. In this work, we extend the technology mapping flows to simultaneously consider the topology and gate fidelity constraints while keeping logical depth and gate count as optimization objectives. We provide a comprehensive problem formulation and multi-tier approach towards solving it. The proposed automation flow is compatible with commercial quantum computers, such as IBM QX and Rigetti. Our simulation results over 10 quantum circuit benchmarks, show that the fidelity of the circuit can be improved up to 3.37 ¡Á with an average improvement of 1.87 ¡Á.",IEEE
U. Chukwu; R. Dridi; J. Berwald; M. Booth; J. Dawson; D. Le; M. Wainger; S. P. Reinhardt,Constrained-optimization Approach Delivers Superior Classical Performance for Graph Partitioning via Quantum-ready Method,2020,10.1109/HPEC43674.2020.9286230,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9286230,Conference Paper,2020 IEEE High Performance Extreme Computing Conference (HPEC),"Graph partitioning is one of an important set of well-known compute-intense (NP-hard) graph problems that devolve to discrete constrained optimization. We sampled solutions to the problem via two different quantum-ready methods to understand the strengths and weaknesses of each method. First we formulated and sampled the problem as a quadratic unconstrained binary optimization (QUBO) problem, via the best known QUBO formulation, using a best-in-class QUBO sampler running purely classically. Second, we formulated the problem at a higher level, as a set of constraints and an objective function, and sampled it with a recently developed constrained-optimization sampler (which generates QUBOs and also samples them classically). We find that both approaches often deliver better partitions than the purpose-built classical graph partitioners. Further, we find that the constrained-optimization approach is often able to deliver better partitions in less time than the bespoke-QUBO approach, without specific knowledge of the graph-partitioning problem. Stepping back from graph partitioning itself, one key question is whether bespoke algorithms for high-value problems or general tools for classes of problems are more likely to deliver the power of QCs to a broad market of real-world users. We believe this early evidence, though anecdotal, supports the proposition that general tools may contribute significant benefit to a range of problems, expanding the impact of QCs on industry and society. The fact that this benefit is independent of the low-level sampler employed, whether classical software or one of a variety of QC architectures, reinforces the need for further work on high-level optimization. The commercial availability in the cloud of such software today, delivering superior classical performance for some problems, enables quantum-forward organizations to migrate to quantum-ready methods now, accelerating progress toward quantum advantage and ensuring sampler software evolves to address the problems such organizations value.",IEEE
Y. Zhu; W. Zhu; Y. Ouyang; J. Sun; Q. Zhao; M. Zhu; J. Yang; C. Chen; Q. Tao; H. Wang; G. Yang; S. Wei; A. Zhang; L. Liu,PQPU: A 4.4- $\mu$ J/Op 69.4-kOPS Agile Post-Quantum Crypto-Processor Across Multiple Mathematical Problems,2024,10.1109/JSSC.2024.3476949,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10735151,Article,IEEE Journal of Solid-State Circuits,"Post-quantum cryptography (PQC) is currently being standardized to replace the existing public-key cryptography for data security in the era of quantum computing. PQC algorithms exhibit considerable diversity in their underlying mathematical problems, storage requirements, and computational patterns, thus complicating unified PQC architecture design. To address this issue, a unified PQC domain-specific accelerator (DSA), post-quantum processing unit (PQPU), is proposed to address the trade-off between performance and flexibility at the algorithm, architecture, and circuit levels. First, a task-clustering-based framework is proposed to enable task-level parallel execution by utilizing the inherent parallelism and common functions across different PQC algorithms. Second, a region-based dynamically updated task path (TP) is constructed to facilitate automatic task-dependency management, with agile control flow and minimized overheads. Finally, algorithm-hardware co-optimizations are proposed in each task cluster to improve throughput and energy efficiency. Fabricated in a 28-nm process, PQPU has energy efficiency and throughput of 4.4  $\mu$ J/Op and 69.4 kOPS. The energy-delay product (EDP) and throughput achieved are 19.3% and 44.6% compared to the state-of-the-art design, respectively. To the best of our knowledge, PQPU is the first silicon-proven PQC accelerator that supports all valid schemes in NIST PQC standardization.",IEEE
E. Fathalla; M. Azab,"Beyond Classical Cryptography: A Systematic Review of Post-Quantum Hash-Based Signature Schemes, Security, and Optimizations",2024,10.1109/ACCESS.2024.3485602,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10731676,Journal,IEEE Access,"The emergence of quantum computing poses significant risks to the security of current cryptographic systems, particularly those reliant on classical algorithms vulnerable to quantum attacks. This systematic literature review adopts the PRISMA model to critically assess the development, methodologies, and security of post-quantum hash-based signature schemes as resilient alternatives. Through a methodical selection process from leading academic databases, we identify and analyze key contributions to the field within the last decade, focusing on the schemes¡¯ security proofs, enhanced performance, and efficiency metrics. Our analysis reveals a diverse landscape of hash-based signature schemes, their evolving security features against quantum threats, and their practical implementations in securing digital communications. The review highlights the importance of advancing these quantum-resistant technologies, discusses the challenges in their adoption, and outlines future directions for research and standardization efforts. The findings aim to provide a comprehensive resource for researchers, practitioners, and policymakers involved in the transition toward secure cryptographic practices in the quantum era.",IEEE
T. Fritzmann; J. Sep¨²lveda,Efficient and Flexible Low-Power NTT for Lattice-Based Cryptography,2019,10.1109/HST.2019.8741027,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8741027,Conference Paper,2019 IEEE International Symposium on Hardware Oriented Security and Trust (HOST),"Secure communication is being threatened by the foreseeable breakthrough of quantum computers. When a larger quantum computer is developed, traditional public key cryptography will be broken. Lattice-based cryptography appears as an alternative to protect the communications in the era of quantum computers. However, empowering current electronic devices with these new algorithms poses a challenging problem due to tight performance requirements as well as area and power constraints. Polynomial multiplication is the basic and most computationally intensive operation in lattice-based cryptosystems. The Number Theoretic Transform (NTT) is an attractive technique to perform polynomial multiplication efficiently. So far, previous works have focused on developing fast and compact forward and inverse NTT implementations. However, efficient and low-power NTT design has not been considered before although a low power consumption is crucial for many systems, such as battery-powered Internet of Things (IoT) devices. In this paper, we present the first low-power, fast and secure NTT ASIC design for lattice-based cryptography able to support different NTT parameters. The contribution of this work is three-fold. First, the implementation of a fast NTT through three optimization techniques. Second, utilization of methods for ASIC power minimization in the NTT design. Third, review of previously proposed side-channel attacks and discussion about countermeasures for our design. Our proposed architecture requires only n log(n) clock cycles for the forward and inverse NTT and can be implemented using a cheap single port RAM. The results of our work show that it is possible to decrease the power dissipation by more than 30% at nearly no cost.",IEEE
F. Feng; P. Zhang; Y. Zhou; Y. A. Shamash,Noisy-intermediate-scale quantum power system state estimation,2024,10.23919/IEN.2024.0019,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10703139,Journal,iEnergy,"Quantum power system state estimation (QPSSE) offers an inspiring direction for tackling the challenge of state estimation through quantum computing. Nevertheless, the current bottlenecks originate from the scarcity of practical and scalable QPSSE methodologies in the noisy intermediate-scale quantum (NISQ) era. This paper devises a NISQ-QPSSE algorithm that facilitates state estimation on real NISQ devices. Our new contributions include: (1) A variational quantum circuit (VQC)-based QPSSE formulation that empowers QPSSE analysis utilizing shallow-depth quantum circuits; (2) A variational quantum linear solver (VQLS)-based QPSSE solver integrating QPSSE iterations with VQC optimization; (3) An advanced NISQ-compatible QPSSE methodology for tackling the measurement and coefficient matrix issues on real quantum computers; (4) A noise-resilient method to alleviate the detrimental effects of noise disturbances. The encouraging test results on the simulator and real-scale systems affirm the precision, universality, and scalability of our QPSSE algorithm and demonstrate the vast potential of QPSSE in the thriving NISQ era.",IEEE
S. H. Hamdoun; A. Basheer Yousif; M. J. Hussein; H. Mahmood Jawad; M. Barakat; D. Humennyi; H. M. Noori,Integrating Quantum Algorithms into Drone Navigational Modules,2024,10.23919/FRUCT64283.2024.10749929,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10749929,Conference Paper,2024 36th Conference of Open Innovations Association (FRUCT),"Quantum computing in drone technology begins to show potential big time, especially in the possibility of data processing, communication, and how to bring operational efficiency.In this study, the integration of quantum algorithms on drone navigation systems to enhance their efficiency in terms of security and performance is being investigated.However, in the interest of full disclosure, it should be noted that quantum-enabled drones have not been built and tested elsewhere to get an insight from a practical standpoint. This research is based on simulations and hypothetical models, which show that quantum algorithms could improve the optimization of drone operations.A simulation performed showed that the mean path length of data transmission was shortened by 12.4%, both from source to destination and back, compacting the whole process and increasing speed while it decreased packet loss by an average value close to 75% ¡ª when compared with regular methods. High-density urban obstacle avoidance efficiency increased by 26.1%. Though these results demonstrate an impressive theoretical advantage, realizing practical quantum computing on drones has many challenges to be overcome such as miniaturization of hardware components, power consumption and environmental protection. Overcoming these challenges is critical for future explorations into what quantum-integrated drones can achieve.This article presents a holistic overview of the current status of quantum technological advances in drones and sketches out what constitutes crucial steps to make things turn from theoretical calculations to real-life operational systems. Accordingly, this study sets a new foundation for future advancements in this nascent field and offers solutions that could get one step closer to realizing ambitious visions of autonomous aerial systems across multiple domains.",IEEE
A. J. Hendrickson; D. P. Haefner; S. H. Chan; N. R. Shade; E. R. Fossum,PCH-EM: A Solution to Information Loss in the Photon Transfer Method,2024,10.1109/TED.2024.3414369,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10570238,Journal,IEEE Transactions on Electron Devices,"Working from a Poisson-Gaussian noise model, a multisample extension of the photon counting histogram expectation-maximization (PCH-EM) algorithm is derived as a general-purpose alternative to the photon transfer (PT) method. This algorithm is derived from the same model, requires the same experimental data, and estimates the same sensor performance parameters as the time-tested PT method, all while obtaining lower uncertainty estimates. It is shown that as read noise becomes large, multiple data samples are necessary to capture enough information about the parameters of a device under test, justifying the need for a multisample extension. An estimation procedure is devised consisting of initial PT characterization followed by repeated iteration of PCH-EM to demonstrate the improvement in estimating uncertainty achievable with PCH-EM, particularly in the regime of deep subelectron read noise (DSERN). A statistical argument based on the information theoretic concept of sufficiency is formulated to explain how PT data reduction procedures discard information contained in raw sensor data, thus explaining why the proposed algorithm is able to obtain lower uncertainty estimates of key sensor performance parameters, such as read noise and conversion gain. Experimental data captured from a CMOS quanta image sensor with DSERN are then used to demonstrate the algorithm¡¯s usage and validate the underlying theory and statistical model. In support of the reproducible research effort, the code associated with this work can be obtained on the MathWorks file exchange (FEX) (Hendrickson et al., 2024).",IEEE
T. Peham; L. Burgholzer; R. Wille,Equivalence Checking of Quantum Circuits With the ZX-Calculus,2022,10.1109/JETCAS.2022.3202204,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9868772,Journal,IEEE Journal on Emerging and Selected Topics in Circuits and Systems,"As state-of-the-art quantum computers are capable of running increasingly complex algorithms, the need for automated methods to design and test potential applications rises. Equivalence checking of quantum circuits is an important, yet hardly automated, task in the development of the quantum software stack. Recently, new methods have been proposed that tackle this problem from widely different perspectives. One of them is based on the ZX-calculus, a graphical rewriting system for quantum computing. However, the power and capability of this equivalence checking method has barely been explored. The aim of this work is to evaluate the ZX-calculus as a tool for equivalence checking of quantum circuits. To this end, it is demonstrated how the ZX-calculus based approach for equivalence checking can be expanded in order to verify the results of compilation flows and optimizations on quantum circuits. It is also shown that the ZX-calculus based method is not complete¡ªespecially for quantum circuits with ancillary qubits. In order to properly evaluate the proposed method, we conduct a detailed case study by comparing it to two other state-of-the-art methods for equivalence checking: one based on path-sums and another based on decision diagrams. The proposed methods have been integrated into the publicly available QCEC tool (https://github.com/cda-tum/qcec) which is part of the Munich Quantum Toolkit (MQT).","IEEE, Web of Science"
N. Garcia-Buendia; A. J. Mu?oz-Montoro; R. Cortina; J. M. Maqueira-Mar¨ªn; J. Moyano-Fuentes,Mapping the Landscape of Quantum Computing and High Performance Computing Research Over the Last Decade,2024,10.1109/ACCESS.2024.3411307,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10551808,Journal,IEEE Access,"Quantum Computing (QC) is a rapidly evolving research field that has garnered significant attention due to its potential to revolutionize various domains such as cryptography, optimization, and machine learning. In this article, we conduct an extensive analysis of the evolution of QC research within the realm of High Performance Computing (HPC) over a span of ten years, up to 2023. Through bibliometric analysis and advanced science mapping techniques, we uncover key thematic areas that have emerged in the field, including quantum algorithms, simulation, parallel-computing, deep learning, machine learning, and encryption. This analysis highlights the interdisciplinary nature of QC, which intersects with disciplines such as physics, mathematics, computer science, and materials science. Furthermore, our study elucidates the close relationship between HPC and QC, showcasing how advancements in one field can significantly impact the other. The findings of this study not only provide valuable insights into the past trends and research landscape but also serve as a guide for future research directions, enabling the advancement of knowledge and fostering innovation in computer science. Additionally, our analysis sheds light on the global distribution of research contributions, identifying countries and regions that have made significant strides in QC research, thus presenting potential collaboration opportunities. Overall, this comprehensive study contributes to a deeper understanding of the development of QC within the realm of HPC, offering valuable insights and paving the way for future advancements in this exciting field.",IEEE
B. Chichereau; S. Vialle; P. Carribault,Fully Integrated Quantum Method for Classical Register Allocation in LLVM,2024,10.1109/QCE60285.2024.10295,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10821149,Conference Paper,2024 IEEE International Conference on Quantum Computing and Engineering (QCE),"Quantum computing devices are being installed alongside supercomputing clusters to serve as hardware accel-erators. This new type of architecture will require an integrated hybrid software stack. With this goal in mind, we have developed a fully integrated hybrid quantum-classical method in the hope of improving Register Allocation in the classical LLVM compiler. We propose a hybrid variational optimization algorithm for the PBQP formulation of Register Allocation. We implemented this algorithm in C++ inside LLVM using the NVIDIA CUDA-$Q$ framework. The performance of the method is evaluated using NVIDIA CUDA-Q noiseless emulators and shows promising results while still needing further optimizations. Our work constitutes a demonstration of an end-to-end tight integration of a quantum subroutine inside an existing classical codebase of interest with potentially interesting performance in fault-tolerant hardware.",IEEE
A. Okada; H. Yoshida; K. Kidono; T. Matsumori; T. Takeno; T. Kadowaki,Design Optimization of Noise Filter Using Quantum Annealer,2023,10.1109/ACCESS.2023.3271969,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10113307,Journal,IEEE Access,"The use of quantum annealers in black-box optimization to obtain the desired properties of a product with a small number of trials has attracted attention. However, the application of this technique to engineering design problems has been limited. Here, we demonstrate the applicability of black-box optimization with a quantum annealer to the design of electric circuit systems, focusing on  $\pi $ -type noise filters as an example. We develop a framework that uses quantum annealing to find the optimal location of electrical components and conductor paths connecting the components, and confirm that the learning process appropriately works over a number of trials to efficiently search for a design with high performance. The results show the potential applicability of quantum annealing to design problems of electric circuit systems.",IEEE
S. Resch; U. Karpuzcu,On Variable Strength Quantum ECC,2022,10.1109/LCA.2022.3200204,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9863975,Journal,IEEE Computer Architecture Letters,"Quantum error correcting codes (QECC) facilitate timely detection and correction of errors to increase the robustness of qubits. Higher expected error rates necessitate stronger (i.e., larger-distance) QECC to guarantee correct operation. With increasing strength, however, QECC overhead can easily become forbidding. Based on the observation that quantum algorithms exhibit varying spatio-temporal sensitivity to noise (hence, errors), this article explores challenges and opportunities of variable strength QECC where QECC strength gets adapted to the degree of noise tolerance, to minimize QECC overhead without compromising correctness.",IEEE
Y. Jin; Z. Li; F. Hua; T. Hao; H. Zhou; Y. Huang; E. Z. Zhang,Tetris: A Compilation Framework for VQA Applications in Quantum Computing,2024,10.1109/ISCA59077.2024.00029,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10609632,Conference Paper,2024 ACM/IEEE 51st Annual International Symposium on Computer Architecture (ISCA),"Quantum computing has shown promise in solving complex problems by leveraging the principles of superposition and entanglement. Variational quantum algorithms (VQA) are a class of algorithms suited for near-term quantum computers due to their modest requirements of qubits and depths of computation. This paper introduces Tetris ¨C a compilation framework for VQA applications on near-term quantum devices. Tetris focuses on reducing two-qubit gates in the compilation process since a two-qubit gate has an order of magnitude more significant error and execution time than a single-qubit gate. Tetris exploits unique opportunities in the circuit synthesis stage often overlooked by the state-of-the-art VQA compilers for reducing the number of two-qubit gates. Tetris comes with a refined IR of Pauli string to express such a two-qubit gate optimization opportunity. Moreover, Tetris is equipped with a fast bridging approach that mitigates the hardware mapping cost. Overall, Tetris demonstrates a reduction of up to $41.3 \%$ in CNOT gate counts, $37.9 \%$ in circuit depth, and $\mathbf{4 2. 6 \%}$ in circuit duration for various molecules of different sizes and structures compared with the state-of-the-art approaches. Tetris is open-sourced at this link.",IEEE
M. Saravanan; R. Pratap Sircar,Quantum Evolutionary Algorithm for Scheduling Resources in Virtualized 5G RAN Environment,2021,10.1109/5GWF52925.2021.00027,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9605075,Conference Paper,2021 IEEE 4th 5G World Forum (5GWF),"Radio is the most important part of any wireless network. Radio Access Network (RAN) has been virtualized and disaggregated into different functions whose location is best defined by the requirements and economics of the use case. This Virtualized RAN (vRAN) architecture separates network functions from the underlying hardware and so 5G can leverage virtualization of the RAN to implement these functions. The easy expandability and manageability of the vRAN support the expansion of the network capacity and deployment of new features and algorithms for streamlining resource usage. In this paper, we try to address the problem of scheduling 5G vRAN with mid-haul network capacity constraints as a combinatorial optimization problem. We transformed it to a Quadratic Unconstrained Binary Optimization (QUBO) problem by using a newly proposed quantum-based algorithm and compared our implementation with existing classical algorithms. This work has demonstrated the advantage of quantum computers in solving a particular optimization problem in the Telecommunication domain and paves the way for solving critical real-world problems using quantum computers faster and better.",IEEE
C. Mastroianni; L. Scarcello; J. Settino,Quantum Computing Approach for Energy Optimization in a Prosumer Community,2022,10.1109/DASC/PiCom/CBDCom/Cy55231.2022.9927770,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9927770,Conference Paper,"2022 IEEE Intl Conf on Dependable, Autonomic and Secure Computing, Intl Conf on Pervasive Intelligence and Computing, Intl Conf on Cloud and Big Data Computing, Intl Conf on Cyber Science and Technology Congress (DASC/PiCom/CBDCom/CyberSciTech)","This paper presents a quantum approach for the formulation and solution of the prosumer problem, i.e., the problem of minimizing the energy cost incurred by a number of users in an energy community, while addressing the constraints given by the balance of energy and the user requirements. As the problem is NP-complete, a hybrid quantum/classical algorithm could help to acquire a significant speedup, which is particularly useful when the problem size is large. This work describes the steps through which the problem can be transformed, reformulated and given as an input to Quantum Approximate Optimization Algorithm (QAOA), and reports some experimental results, in terms of the quality of the solution and time to achieve it, obtained with a quantum simulator, when varying the number of constraints and, correspondingly, the number of qubits.",IEEE
M. Zhao; N. Deng; H. Wei; N. Zhao,Maximum Key-based Joint Topology Construction and Routing over Quantum Satellite Networks,2023,10.1109/ICCC57788.2023.10233528,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10233528,Conference Paper,2023 IEEE/CIC International Conference on Communications in China (ICCC),"Quantum key resources in quantum satellite networks are fundamental to confidential data forwarding, which highly depends on the network topology. In this paper, we propose a network topology construction scheme via formulating the dynamic link establishment among network nodes as an integer linear programming to maximize the number of available quantum keys in the topology. Then we solve this topology optimization problem through subgradient method based on the Lagrange duality theory. Under the optimized topology, we further propose a key-based routing and resource allocation (KRRA) algorithm to forward secret keys for ground stations. The simulation results show that our scheme performs better than the benchmark method with the minimum route distance in terms of the number of quantum keys and the success probability of real-time secret key forwarding service.",IEEE
X. Wei; J. Liu; L. Fan; Y. Guo; Z. Han; Y. Wang,Optimal Entanglement Distribution Problem in Satellite-based Quantum Networks,2024,10.1109/MNET.2024.3399081,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10526298,Article,IEEE Network,"Satellite-based quantum networks are emerging as a promising solution for the development of a global quantum internet in the near future. The ability to leverage the advantageous lower attenuation of optical signals from satellites to ground presents an exciting opportunity to establish a robust and secure quantum communication infrastructure on a global scale. By utilizing a constellation of satellites, it becomes feasible to continuously distribute high-fidelity quantum entanglements among ground stations over long distances, overcoming the limitations of traditional terrestrial-based quantum communication systems. In this article, we first provide a brief survey of existing solutions for satellite-based entanglement distribution, highlighting the various approaches and technologies that have been employed in this rapidly evolving field. We then delve into a formulated optimal entanglement distribution problem, aiming to optimize the distribution of quantum entanglement resources across the satellite network to maximize efficiency and reliability. This problem is addressed through a detailed exploration of several different methodologies and algorithms, each tailored to specific operational settings and constraints. Our experimental results confirm the efficiency of these approaches and provide valuable insights into their practical implementation and performance. Finally, we identify several key directions for further study and development in the realm of satellite-based quantum networks.",IEEE
S. Upadhyay; S. Ghosh,Stealthy SWAPs: Adversarial SWAP Injection in Multi-Tenant Quantum Computing,2024,10.1109/VLSID60093.2024.00085,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10483319,Conference Paper,2024 37th International Conference on VLSI Design and 2024 23rd International Conference on Embedded Systems (VLSID),"Quantum computing (QC) holds tremendous promise in revolutionizing problem-solving across various domains. It has been suggested in literature that 50+ qubits are sufficient to achieve quantum advantage (i.e., to surpass supercomputers in solving certain class of optimization problems). The hardware size of existing Noisy Intermediate-Scale Quantum (NISQ) computers have been ever increasing over the years. Therefore, Multi-tenant computing (MTC) has emerged as a potential solution for efficient hardware utilization, enabling shared resource access among multiple quantum programs. However, MTC can also bring new security concerns. This paper proposes one such threat for MTC in superconducting quantum hardware i.e., adversarial SWAP gate injection in victim¡¯s program during compilation for MTC. We present a representative scheduler designed for optimal resource allocation. To demonstrate the impact of this attack model, we conduct a detailed case study using a sample scheduler. Exhaustive experiments on circuits with varying depths and qubits offer valuable insights into the repercussions of these attacks. We report a max of $\approx 55$% and a median increase of $\approx 25$% in SWAP overhead. As a countermeasure, we also propose a sample machine learning model for detecting any abnormal user behavior and priority adjustment.",IEEE
X. Zhang; Y. Wei; M. Li; J. Tian; Z. Wang,HRCIM-NTT: An Efficient Compute-in-Memory NTT Accelerator With Hybrid-Redundant Numbers,2025,10.1109/TCSI.2024.3463184,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10700038,Journal,IEEE Transactions on Circuits and Systems I: Regular Papers,"Recently, four NIST-approved Post-Quantum Cryptography (PQC) algorithms are selected to be standardized. Three of them are lattice-based cryptographic schemes and feature the number-theoretic transform (NTT) as the computing bottleneck compelling fast and low-power hardware implementations. In this work, a high-speed and power-efficient NTT accelerator is presented leveraging the compute-in-memory (CIM) technique with bottom-up optimizations. Firstly, a carry-free modular multiplication (CFMM) algorithm is proposed, which utilizes on-the-fly reduction and hybrid-redundant representation to optimize the butterfly unit operation, the cornerstone of NTT. Based on the optimized algorithm, an efficient butterfly unit in memory (BUIM) is developed by co-designing with SRAM circuit, which saves the memory access energy, decreases operation cycles, and obtains ultra-short critical path. Additionally, the data pattern of CIM array is also improved to avoid redundant memory read/write operations, which further reduces memory access overhead. Finally, a combination of pipelined operation flow and constant interstage data mapping strategy is employed to bestow the proposed hybrid-redundant CIM NTT (HRCIM-NTT) architecture with minimized computing cycles and reduced routing overhead. The implementation under 45nm CMOS technology demonstrates that HRCIM-NTT achieves the highest throughput and lowest latency among the existing CIM-based NTT accelerators.",IEEE
P. Gokhale; O. Angiuli; Y. Ding; K. Gui; T. Tomesh; M. Suchara; M. Martonosi; F. T. Chong,Optimization of Simultaneous Measurement for Variational Quantum Eigensolver Applications,2020,10.1109/QCE49297.2020.00054,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9259964,Conference Paper,2020 IEEE International Conference on Quantum Computing and Engineering (QCE),"Variational quantum eigensolver (VQE) is a promising algorithm suitable for near-term quantum computers. VQE aims to approximate solutions to exponentially-sized optimization problems by executing a polynomial number of quantum subproblems. However, the number of subproblems scales as N4 for typical problems of interest-a daunting growth rate that poses a serious limitation for emerging applications such as quantum computational chemistry. We mitigate this issue by exploiting the simultaneous measurability of subproblems corresponding to commuting terms. Our technique transpiles VQE instances into a format optimized for simultaneous measurement, ultimately yielding 8-30x lower cost. Our work also encompasses a synthesis tool for compiling simultaneous measurement circuits with minimal overhead. We demonstrate experimental validation of our techniques by estimating the ground state energy of deuteron with a quantum computer. We also investigate the underlying statistics of simultaneous measurement and devise an adaptive strategy for mitigating harmful covariance terms.",IEEE
S. Padmakala,Quantum and Classical Computing using Machine Learning Techniques,2023,10.1109/ICSCNA58489.2023.10370566,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10370566,Conference Paper,2023 International Conference on Sustainable Communication Networks and Application (ICSCNA),"The field of quantum computing is in the midst of a period of transformation as a result of the recent discovery of quantum entanglement. It is designed to perform computations that classical computers cannot handle since it is based on and operates in compliance with the rules of quantum mechanics. Because it operates on certain premises, it enables this to happen. Quantum bits, also known as qubits, have the unique ability to represent many states at once, unlike their conventional analogues. However, classical bits can only take on the values 0 or 1, and no other values in between. Quantum bits are capable of existing in a wide variety of states simultaneously. As a result of their unique ability to explore multiple solutions at once, quantum computers have the potential to dramatically boost the processing speed with which certain problems may be solved. Furthermore, qubits can show entanglement, in which the state of one qubit becomes intertwined with the state of another qubit, even if the qubits are separated by a great distance. Quantum entanglement describes this strange occurrence. This entanglement provides the way for the creation of new algorithms and enhanced computing power by simplifying the execution of complex interactions. Although difficulties like qubit stability and error correction must be overcome, quantum computing has the potential to revolutionize many different areas, including cryptography, optimization, and scientific discovery. Although significant strides have been made, the implementation of large-scale quantum computers remains in its infancy, necessitating ongoing research and development.",IEEE
D. Alevras; M. Metkar; T. Yamamoto; V. Kumar; T. Friedhoff; J. -E. Park; M. Takeori; M. LaDue; W. Davis; A. Galda,mRNA Secondary Structure Prediction Using Utility-Scale Quantum Computers,2024,10.1109/QCE60285.2024.00064,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10821366,Conference Paper,2024 IEEE International Conference on Quantum Computing and Engineering (QCE),"Recent advancements in quantum computing have created new opportunities for tackling long-standing, complex combinatorial optimization problems that are intractable for classical computers. Predicting the secondary structure of mRNA is one such notoriously difficult problem that can benefit from the rapid advancements in quantum computing technology. Accurate prediction of mRNA secondary structure is crucial for designing RNA-based therapeutics, as it dictates various stages of the mRNA life cycle, including transcription, translation, and decay. The current generation of quantum computers has reached a utility scale, enabling us to explore relatively large problem sizes. In this paper, we examine the feasibility of solving mRNA secondary structures on a quantum computer for sequence lengths up to 60 nucleotides, representing problems in the qubit range of 10 to 80. We use the Conditional Value at Risk (CVaR)-based VQE algorithm to solve optimization problems derived from mRNA secondary structure prediction on the IBM Eagle and Heron quantum processors. Encouragingly, even with minimal error mitigation and fixed-depth circuits, our hardware runs yield accurate predictions of minimum free energy (MFE) structures that match the results of the classical solver CPLEX. Our results provide substantial evidence for the viability of solving mRNA structure prediction problems on a quantum computer and motivate continued research in this direction.",IEEE
M. E. S. Chowdhury; N. Ahmed; L. Jamal,A New Perspective in Designing an Optimized Fault Tolerant Reversible Multiplier,2019,10.1109/ICIEV.2019.8858530,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8858530,Conference Paper,"2019 Joint 8th International Conference on Informatics, Electronics & Vision (ICIEV) and 2019 3rd International Conference on Imaging, Vision & Pattern Recognition (icIVPR)","This paper presents a new approach to design a cost effective fault tolerant reversible multiplier circuit. Unlike existing multiplier circuits that have separate circuits for partial product generation and multi-operand addition, the proposed multiplier, designed using a combination of six distinct blocks, incorporates these two circuits together. It also provides an algorithm that depicts the way of using the blocks in designing a n¡Án fault tolerant reversible multiplier. The proposed multiplier is simulated to verify the correctness of the design and algorithm. The comparative study shows that the proposed multiplier is more optimized than any existing fault tolerant reversible multiplier in terms of quantum cost, garbage outputs and number of gates used. The proposed multiplier can be used to design a reversible fault tolerant arithmetic logic unit.",IEEE
R. Wille; A. Fowler; Y. Naveh,Computer-Aided Design for Quantum Computation,2018,10.1145/3240765.3267469,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8587760,Conference Paper,2018 IEEE/ACM International Conference on Computer-Aided Design (ICCAD),"Quantum computation is currently moving from an academic idea to a practical reality. The recent past has seen tremendous progress in the physical implementation of corresponding quantum computers - also involving big players such as IBM, Google, Intel, Rigetti, Microsoft, and Alibaba. These devices promise substantial speedups over conventional computers for applications like quantum chemistry, optimization, machine learning, cryptography, quantum simulation, and systems of linear equations. The Computer-Aided Design and Verification (jointly referred as CAD) community needs to be ready for this revolutionizing new technology. While research on automatic design methods for quantum computers is currently underway, there is still far too little coordination between the CAD community and the quantum computation community. Consequently, many CAD approaches proposed in the past have either addressed the wrong problems or failed to reach the end users. In this summary paper, we provide a glimpse into both sides. To this end, we review and discuss selected accomplishments from the CAD domain as well as open challenges within the quantum domain. These examples showcase the recent state-of-the-art but also outline the remaining work left to be done in both communities.",IEEE
M. Bhatia; S. K. Sood,Quantum Computing-Inspired Network Optimization for IoT Applications,2020,10.1109/JIOT.2020.2979887,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9031708,Journal,IEEE Internet of Things Journal,"Internet of Things (IoT) is defined as the interconnection of millions of wireless devices to acquire data in a ubiquitous manner. With multiple devices targeting to perceive data over a common platform, it becomes indispensable to analyze accuracy for realizing an optimal IoT environment. Inspired from these aspects, this article presents a novel quantum computing-inspired (IoT-QCiO) optimization technique to maximize data accuracy (DA) in a real-time environment of IoT application. Specifically, the presented model incorporates quantum formalization of sensor-specific parameters to quantify IoT devices in terms of sensors in vicinity (SIV) and optimal sensor space (OSS). The optimality of the presented algorithm is estimated in terms of three key performance indicators of data cost (DC), DA, and data temporal efficiency (DTE). For validation purposes, the proposed algorithm is implemented for monitoring geographical traffic to address vehicular routing problems using 90 WiSense nodes, Raspberry Pi v3, and quantum simulators. Results obtained were compared with several state-of-the-art optimization algorithms. Based on the results, significant improvement was registered for the proposed model in terms of statistical parameters of precision, sensitivity, specificity, and F-measure. Moreover, enhanced values of reliability depict the optimal performance of the proposed approach.",IEEE
L. Guo,Research on Anomaly Detection in Massive Multimedia Data Transmission Network Based on Improved PSO Algorithm,2020,10.1109/ACCESS.2020.2994578,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9093835,Journal,IEEE Access,"With the development of computer network technology and the expansion of network system, sensitive data is facing the threat of hacker attack. Intrusion detection is an active network security defense measure, which is an attempt to invade, an ongoing intrusion or an intrusion that has occurred to identify the process. At present, the detection rate of intrusion detection method is low, the false alarm rate and false alarm rate is high, and the real-time performance is poor. It needs a large number of or complete data to achieve better detection performance. In this paper, the concept, characteristics, classification, research contents and difficulties of traditional intrusion detection for mass multimedia data transmission network are described. Then, the basic principle of neural network and particle swarm optimization (PSO) algorithm and the basic idea of particle swarm optimization algorithm with quantum (QPSO) behaviour are introduced. It is emphasized that QPSO has better convergence performance than PSO algorithm in global optimization problems. In this paper, the concept, characteristics and structure of neural network are described, and the algorithm and classification of wavelet neural network are introduced. Then taking wavelet neural network (WNN) as the object, using the QPSO algorithm as the training algorithm, the concrete operation process is given. The research work in this paper shows that the performance of neural network trained by QPSO algorithm and improved QPSO algorithm is better than that of other intelligent algorithms such as PSO algorithm and genetic algorithm, and the convergence speed is faster than that of PSO algorithm or GA algorithm. QPSO is a high performance neural network training algorithm, which can play a good role in neural network anomaly detection.",IEEE
P. Zheng; S. Luo; P. Chen; D. Liu,A Frequency Measurement Method for Diamond NV Center Magnetometer in High Frequency Alternating Magnetic Fields,2021,10.1109/ICSIP52628.2021.9688692,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9688692,Conference Paper,2021 IEEE 6th International Conference on Signal and Image Processing (ICSIP),"In recent years, the use of a spin quantum interfere-ometer with a diamond Nitrogen-vacancy (NV) center for alternating magnetic field measurement has become a hot topic for magnetic field measurement. This technology can be widely used in various magnetic field measurements. However, due to the limitation of pulse manipulation speed, this method may fail when the frequency of the alternating magnetic field is too high. This is because the microwave pulse speed needs to match the frequency of the alternating magnetic field, and it cannot be measured if the pulse speed is lower than the frequency of the alternating magnetic field. This paper discusses the problem of limited pulse speed, and proposes a solution, called the integer constraint based searching magnetic measurement method (ICSM). Specifically, the hardware requirement is converted into a software solution to realize it. That is, by using the principle that the moment when the phase accumulation is zero is an integer multiple of the period of the alternating magnetic field, the problem is transformed into an optimization model with integer constraints. Then use a search algorithm to find the solutions, getting the frequency of the alternating magnetic field, which is to be measured through the minimum positive period of the magnetic field. Finally, a Monte Carlo simulation experiment is carried out, which can obtain a high accuracy rate at a limited computational cost.",IEEE
A. Sarker; A. Bose; S. Gupta,Design of a compact fault tolerant adder/subtractor circuits using parity preserving reversible gates,2014,10.1109/ICCITechn.2014.7073075,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7073075,Conference Paper,2014 17th International Conference on Computer and Information Technology (ICCIT),"Reversible logic has drawn great attention in recent years due to its emerging propagation in diverse range of areas. In this paper, we present a novel approach to unite addition and subtraction operations; circuits that perform addition/subtraction operations using fault tolerant reversible gates with fault detection capability. Adder and subtractor are basic building blocks of any Arithmetic Logic Unit; in this manner we first present the concept of merging those two circuits into one logical block. Then we introduce all possible approaches to construct fault tolerant united addition-subtraction circuit for not only reducing the number of gate but also minimizing quantum cost and garbages of circuit at a meaningful level. We demonstrate three types of half-adder/subtractor circuits and four types of full-adder/subtractor circuits. Again, we depict an algorithm based on our novel concept and we also present simulations on our proposed circuits. Besides, the comparative analysis of our proposed compact method shows our proposed circuit outperform than existing circuit as highest improvements of proposed circuits are 33.33% for garbage output, 26.66% for quantum cost and 50% for gate count. Finally, overall significance of our proposed designs is presented in conclusion.",IEEE
A. Castiglione; J. G. Esposito; V. Loia; M. Nappi; C. Pero; M. Polsinelli,Integrating Post-Quantum Cryptography and Blockchain to Secure Low-Cost IoT Devices,2024,10.1109/TII.2024.3485796,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10756206,Article,IEEE Transactions on Industrial Informatics,"In the contemporary era, the global proliferation of Internet of Things (IoT) devices exceeds 15 billion, serving functions from wearables to smart grid monitoring. These devices frequently manage sensitive data, underscoring the need for secure and reliable IoT networks leveraging blockchain technology. A key innovation of this study is an approach to mitigate vulnerabilities that quantum computing poses to blockchain-based IoT systems, which existing cryptographic methods cannot effectively address. Quantum computers could exploit these weaknesses to compromise key-pair generation and extract private keys from transaction signatures. To overcome this, the research introduces an optimized implementation of the post-quantum digital signature algorithm Dilithium-5, ensuring blockchain security and quantum readiness. These transaction signatures are designed for low-power, cost-effective microcontrollers, such as the ESP32, making the solution accessible for a wide range of IoT devices. In addition, the study includes a case study involving a post-quantum safe portable device for measuring blood oxygen levels and heart rate, illustrating the practical benefits and effectiveness of the proposed solution in enhancing IoT security against quantum threats. The results demonstrate that the proposed approach ensures quantum-resistant security while maintaining performance efficiency, making it suitable for real-world IoT applications.",IEEE
N. Tara; M. K. I. Sufian; H. M. H. Babu,Nanotechnology-Based Efficient Fault Tolerant Decoder in Reversible Logic,2017,10.1109/WIECON-ECE.2017.8468937,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8468937,Conference Paper,2017 IEEE International WIE Conference on Electrical and Computer Engineering (WIECON-ECE),"Reversible logic has received great attention in last few years as it dissipates very low power. This paper presents the reversible logic synthesis for the n-to-2n fault tolerant decoder, where n is the number of data bits. A low cost 6 ¡Á 6 reversible gate is proposed to design a 2-to-4 reversible fault tolerant decoder which has least delay. An algorithm is derived to construct higher bit order decoder. Theoretical explanations certify the novelty of the proposed design. Comparing with previous works, the proposed design shows significant reduction in gate count, quantum cost and delay, which are 66.66%, 8.33%, 16.66%, respectively, with respect to the corresponding metrics of the best existing 2-to-4 fault tolerant decoder. Area and power consumption of the proposed circuit are also estimated.",IEEE
T. N. Nguyen; D. H. P. Nguyen; M. V. Nguyen; T. V. Le; B. -H. Liu; T. N. Dinh,Maximizing Key Distribution Capability: An Application in Quantum Cryptography,2023,10.1109/QCE57702.2023.00134,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10313749,Conference Paper,2023 IEEE International Conference on Quantum Computing and Engineering (QCE),"Quantum key distribution (QKD) integrated wavelength-division multiplexing (WDM) offers an information-theoretically secure solution to the key exchange problem. In this paper, we investigate the joint problem of how to efficiently schedule QKD to provision sufficient secret keys over WDM networks. Specifically, we propose and formulate the problem of maximizing key distribution capability (MKDC) by employing a mixed integer linear programming (MILP) model for the first time. We then suggest two near-optimal algorithms adopted to address larger-scale problems in polynomial time. One employs the linear programming relaxation technique combined with a rounding algorithm (LPR-RA) and the other is inspired by the fact that the application with a higher risk of disruption is prioritized to recharge secret keys, dubbed progressive serving algorithm (PSA). Simulation results show that both the LPRRA and PSA can approach the best feasible solution or the upper-bound of the problem. In addition, by means of using NetSquid, an open simulator for quantum networks, we conduct experiments to get insight into the BB84, a protocol applied popularly in QKD networks nowadays.",IEEE
F. Zhang; T. -Y. Wu; Y. Wang; R. Xiong; G. Ding; P. Mei; L. Liu,Application of Quantum Genetic Optimization of LVQ Neural Network in Smart City Traffic Network Prediction,2020,10.1109/ACCESS.2020.2999608,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9107118,Journal,IEEE Access,"Accurate prediction of traffic flow in urban networks is of great significance for smart city management. A short-term traffic flow prediction algorithm of Quantum Genetic Algorithm - Learning Vector Quantization (QGA-LVQ) neural network is proposed to forecast the changes of traffic flow. Different from BP neural network, Learning Vector Quantization (LVQ) neural network is of simple structure, easy implementation and better clustering effect. Utilizing the global optimization ability of Quantum Genetic Algorithm (QGA), it is combined with LVQ neural network to overcome some shortcomings of LVQ neural network, including sensitive to initial weights and prone to local minima. In order to test the convergence ability and the timeliness of QGA-LVQ neural network in short-term traffic flow, some contrast experiments are performed. Experimental simulation results show that, QGA-LVQ neural network obtains excellent prediction results in prediction accuracy and convergence speed. Besides, compared with GA-BP neural network and wavelet neural network, QGA-LVQ neural network performs better in short-term traffic flow prediction.",IEEE
H. Choi; S. C. Seo,Fast Implementation of SHA-3 in GPU Environment,2021,10.1109/ACCESS.2021.3122466,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9585122,Journal,IEEE Access,"Recently, Graphic Processing Units (GPUs) have been widely used for general purpose applications such as machine learning applications, acceleration of cryptographic applications (especially, blockchains), etc. The development of CUDA makes this General-Purpose computing on GPU possible. In particular, currently GPU technology has been widely used for server-side applications so as to provide fast and efficient service to a number of clients. In other words, servers need to process a large amount of user data and execute authentication process. Verifying the integrity of transmitted data is essential for ensuring that the data is not modified during transmission. Hash functions are the cryptographic algorithm which can verify the integrity of data and there are SHA-1, SHA-2, and SHA-3 standard hash functions. In 2015, Keccak algorithm was selected for SHA-3 competition by NIST. However, until now, software implementations of SHA-3 have not provided enough performance for various applications. In addition, SHA-3 and SHAKE using SHA-3 are being used in many Post-Quantum Cryptosystems (PQC) submitted to NIST PQC competition. Therefore, SHA-3 optimization research is required in the software environment. We propose an optimized SHA-3 software implementation on GPU environment. For performance efficiency, we propose several techniques including optimization of SHA-3 internal process, inline PTX optimization, optimized memory usage, and the application of asynchronous CUDA stream. As a result of applying the proposed optimization method, our SHA-3(512) (resp. SHA-3(256)) implementation without CUDA stream provides a maximum throughput of 88.51 Gb/s (resp. 171.62 Gb/s) on RTX2080Ti GPU. Furthermore, without the application of CUDA stream, our SHA-3(512) software on GTX1070 provides about 49.73% improved throughput compared with the previous best work on GTX1080, which shows the superiority of our proposed optimization methods. Our optimized SHA-3 software on GPU can be efficiently used for block-chain applications and several PQCs (especially, key generation process in Lattice-based cryptosystems).","IEEE, Web of Science"
P. Dandekar; M. Dandekar; P. Phutane,A Comprehensive Review on Wireless Communication and Networking Advances,2024,10.1109/ICEPES60647.2024.10653526,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10653526,Conference Paper,2024 IEEE 3rd International Conference on Electrical Power and Energy Systems (ICEPES),"How we connect and communicate in a digital environment which is undergoing rapid change has been revolutionized by the significant advancements made in wireless networking and communication in recent years. The most recent advancements in wireless communication and networking technologies are examined in this review article, which also touches on important subjects like 5G and beyond, IoT connectivity, security, and emerging trends. To give readers a complete picture of the current state of wireless communication and networking, we present an overview of the problems, solutions, and potential applications within the field. The foundations of contemporary society in the digital age are wireless communication and networking. The function of virtualization in network management is revealed by an overview of software-defined networking (SDN). Given the growing risk of cyberattacks, security in wireless communication remains of the utmost importance. Topics like encryption, authentication, intrusion detection, and the special considerations related to IoT security are covered, as are challenges and solutions to securing wireless networks. New trends are created as technology develops, such as the rise of edge computing, the use of AI and machine learning, and the intriguing area of quantum communication. We delve into these trends, examining how they might affect wireless networks and the wider technological environment. Although there are still difficulties, we look at spectrum management, interference reduction, and the pursuit of green wireless networking as crucial elements for future advancement. For the wireless environment to remain cohesive and secure, standardization and regulation are essential.",IEEE
A. Mughees; I. Ahmad; A. Nawaz Jadoon,Enhanced Nonlinear Control for Trajectory Tracking Control of a Quad-Copter System Using Redfox Algorithm,2024,10.1109/ACCESS.2024.3404825,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10565896,Journal,IEEE Access,"Quad-copters continue to be an area of active research due to their extensive applications in both civilian and military domains. In this paper, we present an advanced approach to enhance the attitude control of Quad-copters, focusing on trajectory tracking performance. We introduce a state-of-the-art Conditioned Adaptive Barrier Function Integral Terminal Sliding Mode Controller (CABFIT-SMC) for precise attitude control. To optimize the control law parameters effectively, we introduce the Redfox algorithm, a newly developed optimization technique inspired by the intelligence of red foxes in hunting and decision-making. The paper includes an in-depth comparative analysis of the Redfox-optimized CABFIT-SMC with the previously researched quantum particle swarm optimization (QPSO) algorithm, presented in our earlier work. The evaluation involves comparing graphs and tables for six different performance measures. These include mean absolute percentage error, root mean square error, integral square error, integral absolute error, integral time absolute error, and integral time square error. We confirm the stability of the system using Lyapunov stability analysis. To test how well the controller works, we use a challenging 3D-helical trajectory. This helps us see if the optimized controllers perform consistently and effectively. Furthermore, we validate the controllers using a Controller-in-Loop setup, demonstrating their effectiveness under realistic operating conditions. Our results demonstrate the CABFIT-SMC Redfox optimized outperforms QPSO-optimized CABFIT-SMC across all performance metrics, solidifying its effectiveness for precise attitude tracking of Quad-copter systems. The proposed approach contributes to improved maneuverability and control precision, with potential applications in various practical scenarios.",IEEE
E. R. Muten; T. Tlimakhov Yusuf; A. V. Tomut,Modified Layerwise Learning for Data Re-uploading Classifier in High-Energy Physics Event Classification,2021,10.1109/QCE52317.2021.00024,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9605291,Conference Paper,2021 IEEE International Conference on Quantum Computing and Engineering (QCE),"This paper aims to demonstrate the use of modified layerwise learning on a data-reuploading classifier, where the parameterized quantum circuit will be used as a quantum classifier to classify the SUSY dataset. We managed to produce a better result using this approach compared to the previous related research with fewer qubits. We obtained an AUC of 0.849 on a testing dataset with 5000 training and testing samples, trained and tested using a state-vector simulator. We also tested to run the circuit on Rigetti¡¯s Aspen-9 quantum processing unit provided by AWS using the already optimized parameter to predict 2000 samples of the test dataset and obtained an AUC of 0.830.",IEEE
S. Xiao; Y. Wang; J. Zhang; D. Dong; G. J. Mooney; I. R. Petersen; H. Yonezawa,A two-stage solution to quantum process tomography: error analysis and optimal design,2024,10.1109/TIT.2024.3522005,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10814064,Article,IEEE Transactions on Information Theory,"Quantum process tomography is a critical task for characterizing the dynamics of quantum systems and achieving precise quantum control. In this paper, we propose a two-stage solution for both trace-preserving and non-trace-preserving quantum process tomography. Utilizing a tensor structure, our algorithm exhibits a computational complexity of O(MLd2) where d is the dimension of the quantum system and M,L (M ¡Ý d2, L¡Ýd2) represent the numbers of different input states and measurement operators, respectively. We establish an analytical error upper bound and then design the optimal input states and the optimal measurement operators, which are both based on minimizing the error upper bound and maximizing the robustness characterized by the condition number. Numerical examples and testing on IBM quantum devices are presented to demonstrate the performance and efficiency of our algorithm.",IEEE
L. Mescia; G. Mevoli; P. Bia,Quantum based particle swarm optimization for equivalent circuit design of terminal antenna impedance,2022,10.1029/2022RS007433,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9786618,Journal,Radio Science,"In this paper, an improved quantum-behaved particle swarm optimization (QPSO) approach for modeling antenna impedance is illustrated. In the proposed study, the enhanced weighted quantum particles swarm optimization (EWQPSO) is introduced with the aim to achieve local convergence acting on a reduced number of free parameters. To verify the performance of the proposed EWQPSO, several tests involving Ipersphere, Alpine, De Jong, Zakharov, Salomon functions were carried out. The obtained results demonstrated that the convergence is achieved more quickly by the EWPSO than other optimization algorithms based on QPSO. A lumped element equivalent circuit was designed to model the terminal impedance of a broadband planar sinuous antenna in the frequency range from 1 to 3 GHz. The developed EWQPSO algorithm is then used to recover all the parameters characterizing the equivalent circuit. The resulting circuit exhibited a good impedance fidelity over the whole frequency range.","IEEE, Wiley"
D. Lykov; R. Schutski; A. Galda; V. Vinokur; Y. Alexeev,Tensor Network Quantum Simulator With Step-Dependent Parallelization,2022,10.1109/QCE53715.2022.00081,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9951269,Conference Paper,2022 IEEE International Conference on Quantum Computing and Engineering (QCE),"In this work, we present a new large-scale quantum circuit simulator. It is based on the tensor network contraction technique to represent quantum circuits. We propose a novel parallelization algorithm based on step-dependent slicing . In this paper, we push the requirement on the size of a quantum computer that will be needed to demonstrate the advantage of quantum computation with Quantum Approximate Optimization Algorithm (QAOA). We computed a single amplitude of QAOA ansatz state on 210 qubits. The simulation involved 1,785 gates on 1,024 nodes of the Cray XC 40 supercomputer Theta. To the best of our knowledge, this constitutes the largest simulation of QAOA ansatz simulations reported to this date.",IEEE
S. Mondal; S. Patkar; T. K. Pal,Hardware implementation of Ring-LWE lattice cryptography with BCH and Gray coding based error correction,2023,10.1109/VLSID57277.2023.00019,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10089970,Conference Paper,2023 36th International Conference on VLSI Design and 2023 22nd International Conference on Embedded Systems (VLSID),"Lattice structure based cryptographic algorithms are well-known in Post-Quantum-Cryptography (PQC) due to their strong security against quantum computers, better performance and practicality in hardware implementation. Among popular Ring learning with errors (RLWE) lattice problem based cryptosystems, NewHope Simple is a promising key encapsulation mechanism (KEM). The major challenges of the algorithm are timeXarea complexity, bandwidth utilization, and a trade-off between security level and decryption failure rate (DFR). In this paper, we propose a timeXspace optimized hardware implementation of the NewHope Simple KEM along with Bose-Chaudhuri-Hocquenghem (BCH) and weighted Gray coding based error correction technique. The design is validated on Zynq7000 Artix-7 FPGA. The proposed NewHope Simple design achieves 5.03X improvement in areaXtime product than other hardware implementations, and at least 12% enhancement in execution time compared to various Graphics Processing Unit (GPU) based implementations. The result shows that our BCH decoder requires 5.8X lesser computation time than its counterparts. Our error correction technique achieves 10.4% better error rate than BCH for 4 bits per symbol. This improvement in bit error rate (BER) can be exploited to enhance bandwidth utilization and security. The proposed architecture can complete a successful key exchange in 634¦Ìs.",IEEE
R. Agrawal; L. Bu; M. A. Kinsy,A Post-Quantum Secure Discrete Gaussian Noise Sampler,2020,10.1109/HOST45689.2020.9300275,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9300275,Conference Paper,2020 IEEE International Symposium on Hardware Oriented Security and Trust (HOST),"While the notion of achieving ¡°quantum supremacy¡± may be debatable, rapid developments in the field of quantum computing are heading towards more realistic quantum computers. As practical quantum computers start becoming more feasible, the requirement to have quantum secure cryptosystems becomes more compelling. Due to its many advantages, lattice based cryptography has become one of the key candidates for designing secure systems for the post-quantum era. The security of lattice-based cryptography is governed by the small error samples generated from a Gaussian distribution. Hence, the Gaussian distribution lies at the core of these cryptosystems. In this paper, we present the hardware design implementation of three different sampling algorithms including rejection, Box-Muller, and the Ziggurat method for the Gaussian Sampler. Our goal is to provide concrete recommendations for future use and adoption in various cryptosystems based on sampling efficiency, hardware cost and throughput. The key feature of our design implementation is that it performs high-precision sampling to meet the NIST's recommended security level of 112-bits or higher for the postquantum era, which most existing hardware implementations fail to do. Furthermore, our design implementation is highly optimized for FPGA-based implementation and is also generic so that it can be seamlessly integrated into most cryptosystems. Synthesis results are obtained using Vivado design suite for a Xilinx Zynq-7010 CLG400ACX1341 FPGA board.",IEEE
J. Zhao; H. Liu,A Novel Quantum-Behaved Particle Swarm Optimization Algorithm,2015,10.1109/DCABES.2015.31,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7429565,Conference Paper,2015 14th International Symposium on Distributed Computing and Applications for Business Engineering and Science (DCABES),"A novel Quantum-behaved Particle Swarm Optimization algorithm with probability (P-QPSO) is introduced to improve the global convergence property of QPSO. In the proposed algorithm, all the particles keep the original evolution with large probability, and do not update the position of particles with small probability, and re-initialize the position of particles with small probability. Seven benchmark functions are used to test the performance of P-QPSO. The results of experiment show that the proposed technique can increase diversity of population and converge more rapidly than other evolutionary computation methods.",IEEE
K. Zairi; B. Brik; Y. Guellouma; H. Cherroun,Deep Learning-Driven Resource Allocation for MEC-Enabled UAV Collision Avoidance System,2024,10.1109/IWCMC61514.2024.10592571,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10592571,Conference Paper,2024 International Wireless Communications and Mobile Computing (IWCMC),"The Internet of Unmanned Aerial Vehicles (UAVs) envisions critical services like Collision detection and Avoidance among Vehicles (CAVs). These services are typically implemented at the Multi-access Edge Computing (MEC) to enable ultra-low latency communication, ensuring real-time reactions to prevent collisions. To ensure network coverage and optimal connection of UAVs to the nearest MEC host, the CAV must be deployed across all MEC hosts. However, this may impose additional demands on these hots¡¯ available computational and memory resources. We introduce an Artificial Intelligence empowered framework to optimize virtualized resource allocation to the MEC hosts. The framework harnesses the capabilities of Deep Learning (DL) for twofold pivotal objectives: (i) Forecasting UAV Density: the framework predicts the UAV density that each MEC host must accommodate. This anticipatory insight guides resource allocation, adapting it to the anticipated demand dynamics. (ii) Precision in Virtual Resource Allotment: DL is further instrumental in calibrating the precise quantum of virtual resources requisite for the collision detection application to function optimally. This approach ensures the collision avoidance system¡¯s peak efficiency without unduly taxing MEC host computational capacities. Validation of the proposed framework entails empirical analysis. The experimental outcomes underscore the precision of the prediction model and corroborate the resource allocation framework¡¯s efficacy.",IEEE
Q. Zhu; Y. Zhao; H. Xu; L. Huang; C. Qiao,Beyond Entanglement Routing: Source Assignment and All-Optical Switching-Based Distribution,2024,10.1109/TNET.2024.3499358,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10758834,Article,IEEE/ACM Transactions on Networking,"Entanglement routing plays a vital role in distributed quantum computing and quantum networks. Previous works on entanglement routing have addressed several design challenges due to limited quantum resources, failures to establish entanglement, and decoherence of established entanglement, but considered neither the limitations imposed by having a limited number of entangled photon sources (EPSes), nor the benefits of using all-optical (or quantum) switching to distribute entangled photons. In this paper, we first explore the problem of jointly optimizing entanglement routing and EPS assignment, assuming no all-optical switching capability. In other words, a pair of entangled photons generated by one EPS can be distributed to two neighboring quantum nodes. We then relax the above assumption so as to allow a pair of entangled photons generated by one EPS to be distributed to non-adjacent nodes using all-optical switching. We propose two corresponding solutions, namely, entanglement routing and EPS assignment (or ERSA), and ERSAwith all-optical switching-based distribution (or ERSA $+$ D) that aim to maximize the number of entanglement connections between the given set of source-destination (SD) pairs while avoiding starvation and achieving fairness among the SD pairs. In order to obtain efficient solutions in a large discrete solution space in a timely manner, we first formulate each optimization problem as an Integer Linear Programming (ILP), and then propose efficient algorithms to derive near-optimal solutions based on relaxation, Lagrangian decomposition, duality iteration, and rounding techniques. Extensive simulations show that ERSA $+$ Dcan increase network throughput by up to 1652% and 113%, respectively, thanks to EPS assignment optimization, and all-optical switching based entanglement distribution.","IEEE, Web of Science"
C. Yang; Q. Tian; N. Zheng; Y. Zhang; Y. You,The Operating Speed Difference Model of Atlas Platform Based on Deep Learning,2022,10.1109/CISCE55963.2022.9851046,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9851046,Conference Paper,"2022 4th International Conference on Communications, Information System and Computer Engineering (CISCE)","Orbit-free density functional theory is expected to become an ideal theoretical method for large-scale quantum mechanical simulation because it can well balance computational accuracy and speed in large-scale system simulation. With the development of kinetic energy density functionals and localized pseudopotentials, orbit-free density functional theory is also expected to be applied to large-scale simulations. However, further development of efficient and stable corresponding software is required for the widespread application of orbit-free density functional theory. This paper develops an orbit-free density functional theory package ATLAS based on the real-space finite difference method. It uses the numerical stability of its direct energy minimization algorithm, through the simulation test of some periodic systems of Mg, Al, and Al3Mg, and the comparison with the calculation results of PROFESS software package based on orbital density functional theory and CASTEP software package based on KS density functional theory. It is shown that this technology can achieve accurate and stable numerical results in large-scale calculation simulation, which can provide a new choice for scarce calculation simulation software based on orbital density functional theory, and is expected to promote the broader application of orbital density functional theory in the large-scale calculation simulation field.",IEEE
Z. -T. Li; J. -X. Li; Z. -H. Deng; J. -Y. Liang; J. -S. Li,Unraveling the Origin of Low Optical Efficiency for Quantum Dot White Light-Emitting Diodes From the Perspective of Aggregation-Induced Scattering Effect,2021,10.1109/TED.2021.3060698,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9374053,Journal,IEEE Transactions on Electron Devices,"Quantum dots (QDs) are promising materials for various optoelectronic applications. However, the efficiency of QD white light-emitting diodes (QD-white-LEDs) is not at the desired level, particularly when the QD concentration in the silicone matrix is high and the corresponding mechanism has not been fully elucidated. In this study, we experimentally and theoretically investigated the aggregation-induced scattering (AIS) effect of QDs in silicone and unraveled the origin of low efficiency for QD-white-LED devices. Three-dimensional finite-difference time domain and ray tracing simulations were carried out to establish the AIS model for QDs. Results indicate that the AIS effect is stronger for higher QD concentrations and leads to a larger effective aggregate size (EAS), which was confirmed by comparing with the experimental results of QD-silicone films. Furthermore, we found that the AIS effect causes a significant reduction in the radiant efficiencies of QD-white-LEDs when the EAS exceeds 50 particles, which is validated by fabricated devices. According to the spectral energy analysis, the low efficiency of QD-white-LEDs can be attributed to a strong AIS effect at high QD concentrations, causing severe backscattering and reabsorption loss. This study is also important for nondestructive testing the degree of aggregation demonstrated by QDs in a silicone matrix and for precisely modeling QD-white-LEDs.",IEEE
P. He; Y. Tu; T. Bao; L. Sousa; J. Xie,COPMA: Compact and Optimized Polynomial Multiplier Accelerator for High-Performance Implementation of LWR-Based PQC,2023,10.1109/TVLSI.2023.3242640,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10048766,Journal,IEEE Transactions on Very Large Scale Integration (VLSI) Systems,"The rapid progress in quantum computing has initiated a new round of cryptographic innovation, that is, developing postquantum cryptography (PQC) to resist attacks from well-established quantum computers. In this brief, we propose a novel compact and optimized polynomial multiplier accelerator (COPMA) for high-performance implementation of learning-with-rounding (LWR)-based PQC. As not many LWR-based PQC schemes are available in the literature, we have just used Saber, the National Institute of Standards and Technology (NIST) third-round PQC standardization finalist, as a typical case study example. First of all, we have formulated the polynomial multiplication, the major component of Saber, into a novel ¡°subpolynomial¡±-based processing format for compact computation (yet has the potential for fast operation). Then, we have designed the proposed algorithm into an area-efficient polynomial multiplication hardware accelerator with high-frequency operational capability. Finally, we have verified the efficiency of the developed COPMA and have deployed it to build a cryptoprocessor. The implementation and analysis demonstrate the superior performance of the proposed COPMA. The proposed strategy is highly efficient and can be extended to build other PQC hardware accelerators.",IEEE
Q. Tang; X. Zhou; J. Tang,Quantum Evolutionary Algorithm for Parallel Flowshop Scheduling Problem in Chemical Industry,2015,10.1109/ISCID.2015.197,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7468951,Conference Paper,2015 8th International Symposium on Computational Intelligence and Design (ISCID),"This paper studies the typical batching and scheduling problem of parallel flowshop, which is characterized by multi-product, multi-stage, parallel production, production coordination between stages, limit of equipment production capacity and inventory capacity, parallel equipment selection and limitation of batch quantity. This paper presents modified quantum evolutionary algorithm(MQEA) with continuous codes representing the batch size on the every stage to enhance the ability to handle constraints. The computational results show that the MQAE may find optimal or suboptimal solutions in a short run time for all the instances.",IEEE
X. Guo; X. Song; J. -t. Zhou; F. Wang; K. Tang,An Effective Approach to High Strength Covering Array Generation in Combinatorial Testing,2023,10.1109/TSE.2023.3306461,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10224655,Journal,IEEE Transactions on Software Engineering,"Combinatorial testing (CT) is an effective testing method that can detect failures caused by the interaction of parameters of the software under test (SUT). With the increasing complexity of SUT and the parameters involved, the variable strength test suite supporting high strength interaction is challenging in a practical testing scenario. This paper presents a multi-learning-based quantum particle swarm optimization (IQIPSO) for high and variable strength covering array generation (VSCAG). Specifically, a specially designed data structure and several combination location methods are proposed to support and speed up the high-strength VSCAG. Besides, multi-learning strategies, including Lamarckian and Baldwinian learning, are applied to IQIPSO to address the premature convergence leading to a large test suite size. Studies for parameter settings of IQIPSO are presented systematically. The IQIPSO method successfully builds test suites where strength is up to 15 and totally reports 13 new best test suite size records. Extensive experiments demonstrate that IQIPSO tends to outperform most other existing methods.","IEEE, Web of Science"
S. Alam; J. Hutchins; M. S. Hossain; K. Ni; V. Narayanan; A. Aziz,Cryogenic In-Memory Matrix-Vector Multiplication using Ferroelectric Superconducting Quantum Interference Device (FE-SQUID),2023,10.1109/DAC56929.2023.10247669,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10247669,Conference Paper,2023 60th ACM/IEEE Design Automation Conference (DAC),"Next-generation quantum computing (QC) systems, comprising thousands of qubits, are envisioned to accommodate the quantum substrate (qubits) and classical components (control processor, and a digital memory block) in a cryogenic (< 4 Kelvin) environment. Such homogeneous integration will pave the way for superconducting interconnects and reduce the noise arising from thermal gradient. However, in the existing QC systems, cryogenic control processors and memory blocks are still operated following the von Neumann architecture. This leads to significant performance overhead due to the repetitive data movement between physically distinct memory and processing units. Thus, it becomes challenging to implement computationally expensive machine learning (ML) algorithms for efficient error correction and control of qubits in a QC. In-memory implementation of ML algorithms at cryogenic temperature can be a game-changer for a practical QC. Here, we demonstrate a unique technique for cryogenic in-memory matrix vector multiplication (MVM), the most frequently performed operation in ML algorithms, utilizing a ferroelectric superconducting quantum interference device (FE-SQUID)-based memory array. FE-SQUID is a promising cryogenic memory device thanks to its non-volatile nature, voltage-controlled switching, scalability, and compatibility with commercially available superconducting device fabrication processes. Moreover, due to having separate read-write paths, the read operation can be optimized without imposing any limit on the read bias and hence, multiple levels of read current with notable separation can be used to map the inputs for the MVM operation. We use an experimentally-calibrated compact model for FE-SQUID to design and test our proposed system. We evaluate FE-SQUID-based in-memory MVM by performing several classification tasks using MNIST handwritten digits, fashion, and emotion datasets. We achieve 93.83%, 80.49%, and 92.5% accuracy for handwritten digits, fashion, and sentiment classifications, respectively.",IEEE
F. V¨ªt; N. Mirko; S. Miroslav; V. Zden¨§k,System alliances as a tool for solving Smart Cities problems,2015,10.1109/SCSP.2015.7181544,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7181544,Conference Paper,2015 Smart Cities Symposium Prague (SCSP),Basic information on Smart City modeling approach based on the concept of the System alliance is presented. An advantage of this approach inter alia is that System alliances are naturally able to model the synergic effects on interfaces and to minimize various negative impacts. Two ways of interfaces modeling within the alliance are discussed: (i.) Quantum-like models and (ii.) the utilization of the duality: automaton - language. In the first case the superposition of states or even the entanglement concepts are suitable tools for recording non - orthogonal interface parameters and resulting phase sensitivity of the respective interface. In the second approach processes on interfaces are modeled as mutual translations of specific languages. Due to significant uncertainties the methodology of genetic algorithms and grammatical evolution are tested.,IEEE
R. Fu; M. Wang; Y. Kan; O. Chen; N. Yoshikawa; B. Yu; T. -Y. Ho,Buffer and Splitter Insertion for Adiabatic Quantum-Flux-Parametron Circuits,2024,10.1109/TCAD.2024.3461573,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10684033,Article,IEEE Transactions on Computer-Aided Design of Integrated Circuits and Systems,"The extremely low-bit energy characteristic of the adiabatic quantum-flux-parametron (AQFP) circuit makes it a promising candidate for highly energy-efficient computing systems. However, by contrast with conventional circuit design, general logic synthesis tools can not make sure that the circuit functionality of generated AQFP circuits is correct. AQFP circuits require buffer and splitter insertion for dataflow synchronization at all clock phases of the circuit and multi-fan-out driving. Notably, buffers and splitters inserted take up much area and delay in AQFP circuits, also causing a significant increase in energy dissipation. To address this problem, this paper analyzes in detail why buffer and splitter insertion is necessary for AQFP circuits and proposes a global optimization framework for this purpose. This framework consists of three parts: (i) logic level assignment, (ii) splitter tree generation, and (iii) buffer insertion. An integer linear programming algorithm is proposed for the logic level assignment to estimate the globally optimal number of inserted buffers and splitters. Subsequently, a dynamic programming-based multi-way search tree generation algorithm is proposed to construct an optimal splitter tree for each net of the input circuit. Moreover, three optimization strategies are proposed to further enhance the effectiveness and efficiency of our framework. Experimental results on ISCAS¡¯85 and EPFL benchmarks demonstrate the effectiveness and efficiency of our proposed framework compared with the state-of-the-art, particularly with significant advantages on large circuits.",IEEE
A. Bergerault; D. Fortunato; R. Abreu,Generation of Fixed Margin Binary Matrices Using Quantum Annealing,2024,10.1109/QCE60285.2024.10277,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10821158,Conference Paper,2024 IEEE International Conference on Quantum Computing and Engineering (QCE),"Fixed margin binary matrices are used across various scientific fields. However, generating such matrices remains a complicated computational task using classical algorithms since the best algorithm performs in exponential time. In this paper, we model this problem using a Quadratic Unconstrained Binary Optimization (QUBO). Furthermore, we use D-Wave's Quantum Annealing computer and their simulator to generate these matrices. Results obtained through the simulator attest to the capacity of our solution to effectively generate fixed margin binary matrices up to size $9\times 9$ (constraint based on qubits availability). Results obtained from the quantum computer significantly suffer from noise compared to the simulator-based ones; however, we still get exact results with less effectiveness. Our solution and results are publicly available at https://github.com/Niten-luxld-wave-qubo-solver.",IEEE
H. Jiang; L. Wu; J. Hu; Y. Yang; X. Zhang,Hardware Design and Security Analysis for cSHAKE256 in PQC SIAKE,2024,10.1109/ICICM63644.2024.10814276,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10814276,Conference Paper,2024 9th International Conference on Integrated Circuits and Microsystems (ICICM),"With the development of quantum computing, traditional public-key encryption algorithms are facing unprecedented threats, and it is urgent to develop cryptographic algorithms that can resist the attack from quantum computing. SIAKE is a Supersingular Isogeny based authenticated key exchange algorithm. In SIAKE, cSHAKE256 is a key step in 2-Key PKE based on homology calculations. cSHAKE256 is an extensible hash function in the SHA-3 family that further enhances flexibility and security with Customization strings and function names. This paper presents a hardware structure of cSHAKE256 suitable for SIAKE. First, the domain separation module specific to cSHAKE256 is designed. Secondly, the iteration function is optimized to achieve 2 iterations in one cycle. Finally, the 3-stage pipeline structure is adopted in Keccak function algorithm and the wheel constant is simplified, which can greatly improve the throughput and save some resources. The design is verified on FPGA Xilinx Virtex-7, the results show that the designed cSHAKE256 hardware unit has a maximum operating frequency of 217MHz. Finally, the hardware structure of cSHAKE256 is analyzed for side channel security. The design and implementation of cSHAKE256 is proven to be directly applicable to SIAKE, providing it with the necessary security and randomness.",IEEE
G. Acampora; A. Chiatto; S. De Luca; R. Di Pace; A. Massa; R. Schiattarella; A. Vitiello,Application of Quantum Genetic Algorithms to Network Signal Setting Design,2023,10.1109/CEC53210.2023.10254158,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10254158,Conference Paper,2023 IEEE Congress on Evolutionary Computation (CEC),"The regulation of traffic lights in a signalised urban network requires optimizing objective functions that represent performance indicators of one or more intersections (such as delay or queue length). In this scenario, evolutionary algorithms are adopted to find suitable approximate solutions, in cases when no deterministic algorithm for finding the exact solution is known. This paper attempts to further improve the performance of evolutionary approaches by using a hybrid quantum-classical genetic algorithm to find the optimal configuration of the green signal timing regulating the traffic flow across two interacting junctions. The adopted algorithm, run on IBM quantum computer simulators, is shown to be suitable for the optimization problem at hand. Indeed, the experimental results highlight some of the strengths of the proposed technique with respect to the purely evolutionary approach, and encourage the application of this approach to more complex and close-to-real application scenarios.",IEEE
V. Saravanan; S. M. Saeed,Pauli Error Propagation-Based Gate Rescheduling for Quantum Circuit Error Mitigation,2022,10.1109/TQE.2022.3161197,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9740569,Journal,IEEE Transactions on Quantum Engineering,"Noisy intermediate-scale quantum algorithms, which run on noisy quantum computers, should be carefully designed to boost the output state fidelity. While several compilation approaches have been proposed to minimize circuit errors, they often omit the detailed circuit structure information that does not affect the circuit depth or the gate count. In the presence of spatial variation in the error rate of the quantum gates, adjusting the circuit structure can play a major role in mitigating errors. In this article, we exploit the freedom of gate reordering based on the commutation rules to show the impact of gate error propagation paths on the output state fidelity of the quantum circuit, propose advanced predictive techniques to project the success rate of the circuit, and develop a new compilation phase postquantum circuit mapping to improve its reliability. Our proposed approaches have been validated using a variety of quantum circuits with different success metrics, which are executed on IBM quantum computers. Our results show that rescheduling quantum gates based on their error propagation paths can significantly improve the fidelity of the quantum circuit in the presence of variable gate error rates.",IEEE
Y. A. Shah; C. Rafferty; A. Khalid; S. Khan; K. Javeed; M. O¡¯Neill,Efficient Soft Core Multiplier for Post Quantum Digital Signatures,2024,10.1109/ISCAS58744.2024.10558234,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10558234,Conference Paper,2024 IEEE International Symposium on Circuits and Systems (ISCAS),"Multiplication is a core operation in various applications such as cryptography and machine learning. Dedicated DSP blocks are provided by FPGA vendors for multiplication. However, these DSP blocks are limited in number and their location on FPGA is fixed, resulting in routing delays that affects the performance for small size multipliers. In this paper, a high performance and resource efficient 5 ¡Á 5 multiplier is presented that utilizes lookup tables (LUTs) and fast carry chain of the FPGA. The proposed multiplier offers 30% reduction in LUTs compared to Vivado DSP-less inferred multiplier at the cost of a slight increase in critical path delay (CPD). The proposed multiplier requires lesser power consumption and has better area- delay product (ADP) and power-delay product (PDP) metrics. Based on the proposed multiplier, a finite field multiplier is developed for post quantum digital signatures such as QR-UOV, MAYO and MQOM. The matrix-vector architecture is the core operation in multivariate digital signatures and integration of our finite field multiplier in a matrix-vector architecture shows that area is almost halved compared to state-of-the-art.",IEEE
P. He; Y. Tu; J. Xie; H. S. Jacinto,KINA: Karatsuba Initiated Novel Accelerator for Ring-Binary-LWE (RBLWE)-Based Post-Quantum Cryptography,2023,10.1109/TVLSI.2023.3302289,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10225355,Journal,IEEE Transactions on Very Large Scale Integration (VLSI) Systems,"Along with the National Institute of Standards and Technology (NIST) post-quantum cryptography (PQC) standardization process, lightweight PQC-related research, and development have also gained substantial attention from the research community. Ring-binary-learning-with-errors (RBLWE), a ring variant of binary-LWE (BLWE), has been used to build a promising lightweight PQC scheme for emerging Internet-of-Things (IoT) and edge computing applications, namely the RBLWE-based encryption scheme (RBLWE-ENC). The parameter settings of RBLWE-ENC, however, are not in favor of deploying typical fast algorithms like number theoretic transform (NTT). Following this direction, in this work, we propose a Karatsuba initiated novel accelerator (KINA) for efficient implementation of RBLWE-ENC. Overall, we have made several coherent interdependent stages of efforts to carry out the proposed work: 1) we have innovatively used the Karatsuba algorithm (KA) to derive the major arithmetic operation of RBLWE-ENC into a new form for high-performance operation; 2) we have then effectively mapped the proposed algorithm into an efficient hardware accelerator with the help of a number of optimization techniques; and 3) we have also provided detailed complexity analysis and implementation comparison to demonstrate the superior performance of the proposed KINA, e.g., the proposed design with  $u=2$  involves 64.71% higher throughput and 15.37% less area-delay product (ADP) than the state-of-the-art design for  $n=512$  (Virtex-7). The proposed KINA offers flexible processing speed and is suitable for high-performance applications like IoT servers. This work is expected to be useful for lightweight PQC development.",IEEE
H. M; S. Krishna; S. Ayyappan; A. Sahay,Dynamic Resource Allocation for Edge Computing,2024,10.1109/ICCCNT61001.2024.10725885,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10725885,Conference Paper,2024 15th International Conference on Computing Communication and Networking Technologies (ICCCNT),"This research article puts forth a new approach towards dynamic resource allocation within edge computing. As edge computing tries to make computational power closer to where data comes from, it has caught a lot of attention since it could improve time-sensitive applications. Here is an edge computing simulation framework that unites quantum algorithms, game theory-based resource allocation, cross-layer optimization as wells as collaborative scheduling techniques. The framework includes Deutsch-Jozsa quantum algorithm implementations for function evaluation, game theory-based resource allocation, cross-layer optimization, and collaborative multi-edge scheduling algorithms. Also, there are visualization modules for analyzing simulation results including bar charts, pie charts, and heatmaps. The main goal of this framework is to optimize resource usage and satisfy quality of service (QoS) demands in rapidly changing edge environments. Simulation results demonstrate that proposed methodology can improve the efficiency of a dynamic edge computing system by resource utilization enhancement and decrease of latency. Simulations on a real edge computing environment, clearly shows the effectiveness of the proposed framework in improving resource utilization as well as adhering to QoS requirements as opposed to traditional methods. Significant improvements in experimental metrics such as resource utilization rates, task completion times and fairness indices validate the efficiency of the framework for practical implementations.",IEEE
A. Jaiswal; S. Kumar; O. Kaiwartya; P. K. Kashyap; E. Kanjo; N. Kumar; H. Song,Quantum Learning-Enabled Green Communication for Next-Generation Wireless Systems,2021,10.1109/TGCN.2021.3067918,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9383105,Journal,IEEE Transactions on Green Communications and Networking,"Next generation wireless systems have witnessed significant R&D attention from academia and industries to enable wide range of applications for connected environment around us. The technical design of next generation wireless systems in terms of relay and transmit power control is very critical due to the ever-reducing size of these sensor enabled systems. The growing demand of computation capability in these systems for smart decision making further diversified the significance of relay and transmit power control. Towards harnessing the benefits of Quantum Reinforcement Leaning (QRL) in the design of next generation wireless systems, this article presents a framework for joint optimal Relay and transmit Power Selection (QRL-RPS). In QRL-RPS, each sensor node learns using its present and past local state's knowledge to take optimal decision in relay and transmit power selection. Firstly, RPS problem is modelled as a Markov Decision Process (MDP), and then QRL optimization aspect of the MDP problem is formulated focusing on joint optimization of energy consumption and throughput as network utility. Secondly, a QRL-RPS algorithm is developed based on Grover's iteration to solve the MDP problem. The comparative performance evaluation attests the benefit of the proposed framework as compared to the state-of-the-art techniques.",IEEE
W. Shan; W. Wu; S. Shi,SISMA: A Numerical Simulation Software for SIS Mixer Design,2018,10.1109/IRMMW-THz.2018.8510451,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8510451,Conference Paper,"2018 43rd International Conference on Infrared, Millimeter, and Terahertz Waves (IRMMW-THz)","SISMA is a numerical simulation software programmed for the design of SIS mixers with single junction or junction arrays. It is based on quantum mixing theory and a proximation of the nonlinearity up to 2nd harmonic. A new fixed-point iteration algorithm is designed to solve the large-signal nonlinear equation, which enables simulations of SIS mixers with distributed series-connected junction arrays, removing the limitation that only parallel-connected junction arrays can be simulated. The temperature and frequency-dependent complex surface impedances of various superconducting materials can be calculated in the simulation of thin-film superconducting passive components. The graphic interface of this software is a beneficial to fast optimization of the mixer circuit design.",IEEE
M. Ibrahim; N. T. Bronn; G. T. Byrd,Crosstalk-Based Parameterized Quantum Circuit Approximation,2023,10.1109/QCE57702.2023.00014,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10313597,Conference Paper,2023 IEEE International Conference on Quantum Computing and Engineering (QCE),"In this paper, we propose an ansatz approximation approach for variational quantum algorithms (VQAs) that uses one of the hardware's main attributes, its crosstalk behavior, as its main approximation driver. By utilizing crosstalk-adaptive scheduling, we are able to apply a circuit-level approximation/optimization to our ansatz. Our design procedure involves first characterizing the hardware's crosstalk and then approximating the circuit by a desired level of crosstalk mitigation, all while effectively reducing its duration and gate counts. We demonstrate the effect of crosstalk mitigation on expressibility, trainability, and entanglement: key components that drive the utility of parameterized circuits. We tested our approach on real quantum hardware against a base configuration, and our results showed superior performance for the circuit-level optimized ansatz over a base ansatz for two quantum chemistry benchmarks. We take into consideration that applications vary in their response to crosstalk, and we believe that this approximation strategy can be used to create ansatze that are expressive, trainable, and with crosstalk mitigation levels tailored for specific workloads.",IEEE
X. Zou; R. Xie; Q. Tang; T. Huang,Joint Transmission and Transcoding in Computing Power Networks for Livecast: A Quantum-inspired Optimization Approach,2024,10.1109/WCNC57260.2024.10570986,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10570986,Conference Paper,2024 IEEE Wireless Communications and Networking Conference (WCNC),"With the continuous development of network technology and hardware devices, panoramic live cast is promising and widely used in various industries. To meet massive heterogeneous viewer demands, live cast video streams must be transcoded into multiple versions and then transmitted to viewers. By offloading transcoding workloads to network nodes closer to broadcasters and viewers, computing power networks (CPN) have been considered an effective means to provide viewers with a higher quality of experience (QoE). In this paper, we study the joint video transmission and transcoding resource allocation in the CPN-based panoramic livecast system. Considering the versatility and simplicity, we offer a multi-layer network model to capture the stochastic characteristics of transmission and transcoding processes and transform the joint resource allocation problem into a broader shortest path problem (SPP). As the scale of networks expands, the SPP may become intractable on classical computers. This paper explores the viability of solving the SPP on quantum computers by utilizing quantum resources such as superposition and entanglement, then proposes a shortest path algorithm based on the quantum approximate optimization algorithm (QAOA-SPP) for jointly optimizing the latency and overhead of transmission and transcoding. Simulation results indicate that our algorithm can achieve better performance than the benchmark schemes under reasonable parameter settings.",IEEE
M. A. Metawei; H. Said; M. Taher; H. Eldeib; S. M. Nassar,Survey on Hybrid Classical-Quantum Machine Learning Models,2020,10.1109/CCCI49893.2020.9256649,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9256649,Conference Paper,"2020 International Conference on Communications, Computing, Cybersecurity, and Informatics (CCCI)","Optimizing for a classification problem with a 0-1 loss function is an NP-hard problem [1] even for a simple binary classification task. As Preskill stated ¡°We don't expect a quantum computer to solve worst case instances of NP-hard problems, but it might find better approximate solution or find it faster¡± [2]. Hybrid Quantum Classical Platforms harness the full capacity of Near-Term Quantum Computers. In this study, a focus is given on the variational circuits based approach accomplishing various machine learning tasks. We will survey a variety of experimental demonstrations conducted on actual quantum hardware and actively developing simulation software, anticipated to have a broad range of real-world applications in this increasingly growing field.",IEEE
N. A. M. Yunus; Z. M. Hanapi; S. Kamarudin,"6G on the Horizon:Technologies, Requirements, Trends, and Potential Techniques",2024,10.1109/ICECET61485.2024.10698610,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10698610,Conference Paper,"2024 International Conference on Electrical, Computer and Energy Technologies (ICECET","The advance of sixth generation (6G) wireless communication technology represents a paradigm shift in the field of telecommunications, promising unprecedented levels of connectivity, speed, and reliability. This review delves into the fundamental requirements driving the development of $6\mathrm{G}$, highlighting the need for ultra-reliable and low latency. By examining cutting-edge technologies such as terahertz communication, massive Multiple-Input Multiple-Output (MIMO), and Artificial Intelligence (AI) driven network optimization, this paper identifies key trends shaping the future of wireless communication networks. Moreover, it explores potential innovations including holographic communication, self-organizing networks, and quantum communication that have the potential to redefine the capabilities of $6\mathrm{G}$ networks and unlock new opportunities for connectivity and collaboration.",IEEE
G. O¡¯Brien; J. A. Clark,Using Genetic Improvement to Retarget quantum Software on Differing Hardware,2021,10.1109/GI52543.2021.00015,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9474359,Conference Paper,2021 IEEE/ACM International Workshop on Genetic Improvement (GI),"Quantum computers are rapidly developing to a point where they can solve problems faster than any classical computation. In addition, competing standards for languages, models and architectures are also being created. These standards are often bespoke and aimed at optimizing around a single algorithm or problem. This can make it very difficult to reuse these them should the original hardware become unavailable or obsolete. We demonstrate a method that can compile circuits more generally across hardware constraints with the use of a genetic improvement inspired search technique that includes a realistic model of the hardware. We show that this method is effective at selecting gates that can be more easily implemented and run compared to generic optimization. This method reduces the total chance of failure. To ensure that these results are practical, empirical results are generated using different IBM hardware and a selection of real algorithms.",IEEE
K. He; J. Saunderson; H. Fawzi,A Bregman Proximal Perspective on Classical and Quantum Blahut-Arimoto Algorithms,2024,10.1109/TIT.2024.3412129,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10552808,Journal,IEEE Transactions on Information Theory,"The Blahut-Arimoto algorithm is a well-known method to compute classical channel capacities and rate-distortion functions. Recent works have extended this algorithm to compute various quantum analogs of these quantities. In this paper, we show how these Blahut-Arimoto algorithms are special instances of mirror descent, which is a type of Bregman proximal method, and a well-studied generalization of gradient descent for constrained convex optimization. Using recently developed convex analysis tools, we show how analysis based on relative smoothness and strong convexity recovers known sublinear and linear convergence rates for Blahut-Arimoto algorithms. This Bregman proximal viewpoint allows us to derive related algorithms with similar convergence guarantees to solve problems in information theory for which Blahut-Arimoto-type algorithms are not directly applicable. We apply this framework to compute energy-constrained classical and quantum channel capacities, classical and quantum rate-distortion functions, and approximations of the relative entropy of entanglement, all with provable convergence guarantees.",IEEE
J. -H. Phoon; W. -K. Lee; D. C. . -K. Wong; W. -S. Yap; B. -M. Goi; R. C. . -W. Phan,Optimized IoT Cryptoprocessor Based on QC-MPDC Key Encapsulation Mechanism,2020,10.1109/JIOT.2020.2991334,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9082617,Journal,IEEE Internet of Things Journal,"The key encapsulation mechanism (KEM) is an important cryptographic tool to protect communication in the Internet of Things (IoT). In the near future, classical algorithms used to construct KEMs, such as RSA and elliptic curve cryptography, will be vulnerable to attacks from quantum computers. Recently, Yamada et al. proposed the quasicyclic medium density parity check (QC-MDPC) KEM, which is considered one of the most advanced code-based cryptosystems to resist quantum attacks. In this article, an optimized implementation of QC-MDPC KEM for IoT applications is presented. Our main contributions are threefold: 1) the fastest QC-MDPC McEliece decryption in field-programmable gate array (FPGA); 2) the first QC-MDPC KEM implementation in FPGA; and 3) the first iteration count attack-resistant QC-MDPC decoder in FPGA. To improve the decryption speed, we introduce a novel customized rotation engine (CRE) and incorporated several recent techniques reported in the literature, including adaptive threshold and Hamming weight estimation. The best-achieved throughput in our implementation on Xilinx Virtex 7 FPGA is 12.7% faster than the state-of-the-art result reported by Heyse et al. The proposed CRE was then integrated with QC-MDPC KEM to produce a fast and secure KEM. Furthermore, to prevent timing attacks demonstrated recently, a constant-time implementation of the QC-MDPC McEliece decoder was presented.","IEEE, Web of Science"
Y. Zhou; Z. Tang; N. Nikmehr; P. Babahajiani; F. Feng; T. -C. Wei; H. Zheng; P. Zhang,Quantum computing in power systems,2022,10.23919/IEN.2022.0021,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9831167,Journal,iEnergy,"Electric power systems provide the backbone of modern industrial societies. Enabling scalable grid analytics is the keystone to successfully operating large transmission and distribution systems. However, today's power systems are suffering from ever-increasing computational burdens in sustaining the expanding communities and deep integration of renewable energy resources, as well as managing huge volumes of data accordingly. These unprecedented challenges call for transformative analytics to support the resilient operations of power systems. Recently, the explosive growth of quantum computing techniques has ignited new hopes of revolutionizing power system computations. Quantum computing harnesses quantum mechanisms to solve traditionally intractable computational problems, which may lead to ultra-scalable and efficient power grid analytics. This paper reviews the newly emerging application of quantum computing techniques in power systems. We present a comprehensive overview of existing quantum-engineered power analytics from different operation perspectives, including static analysis, transient analysis, stochastic analysis, optimization, stability, and control. We thoroughly discuss the related quantum algorithms, their benefits and limitations, hardware implementations, and recommended practices. We also review the quantum networking techniques to ensure secure communication of power systems in the quantum era. Finally, we discuss challenges and future research directions. This paper will hopefully stimulate increasing attention to the development of quantum-engineered smart grids.",IEEE
A. Che; P. Wu; F. Chu; M. Zhou,Improved Quantum-Inspired Evolutionary Algorithm for Large-Size Lane Reservation,2015,10.1109/TSMC.2015.2417509,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7102759,Journal,"IEEE Transactions on Systems, Man, and Cybernetics: Systems","This paper studies a lane reservation problem for large sport events in big cities. Such events require organizers to deliver certain people and materials from athlete villages to geographically dispersed venues within a given travel duration. A lane reservation strategy is usually adopted in this circumstance to ensure that time-critical transportation tasks can be completed despite heavy urban traffic congestion. However, it causes negative impact on normal traffic. The problem aims to optimally select and reserve some lanes in a transportation network for the exclusive use of the tasks such that the total traffic impact is minimized. To solve the problem, we first develop an improved integer linear program. Then, its properties are analyzed and used to reduce the search space for its optimal solutions. Finally, we develop a fast and effective quantum-inspired evolutionary algorithm for large-size problems. Computational results on instances with up to 500 nodes in the network and 50 tasks show that the proposed algorithm is efficient in yielding high-quality solutions within a relatively short time.",IEEE
S. Liang; Y. Lu; C. Guo; W. Luk; P. H. J. Kelly,PCQ: Parallel Compact Quantum Circuit Simulation,2024,10.1109/FCCM60383.2024.00013,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10653682,Conference Paper,2024 IEEE 32nd Annual International Symposium on Field-Programmable Custom Computing Machines (FCCM),"Since quantum computers are not readily available, much quantum computing research such as quantum algorithm verification has to be conducted on classical computer platforms. While many quantum circuit simulators have been developed on CPUs and GPUs, the potential of FPGAs as a platform with parallel computing capabilities and high energy efficiency has not been fully explored. This paper describes a novel approach with two modes of data movement optimization for an FPGA-based parallel pipelined dataflow architecture targeting a compact computation format. A data decoupling method is adapted to partition computing tasks and data into non-interacting sub- sets, significantly reducing external data interaction overhead. The proposed approach shows significant promise in improving performance and energy efficiency compared with existing state vector based CPU, GPU, and FPGA implementations.",IEEE
M. Li; Q. Zhang; A. Gatto; S. Bregni; G. Verticale; M. Tornatore,DRL-based progressive recovery for quantum-key-distribution networks,2024,10.1364/JOCN.526014,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10637934,Journal,Journal of Optical Communications and Networking,"With progressive network recovery, operators restore network connectivity after massive failures along multiple stages, by identifying the optimal sequence of repair actions to maximize carried live traffic. Motivated by the initial deployments of quantum-key-distribution (QKD) over optical networks appearing in several locations worldwide, in this work we model and solve the progressive QKD network recovery (PQNR) problem in QKD networks to accelerate the recovery after failures. We formulate an integer linear programming (ILP) model to optimize the achievable accumulative key rates during recovery for four different QKD network architectures, considering different capabilities of using trusted relay and optical bypass. Due to the computational limitations of the ILP model, we propose a deep reinforcement learning (DRL) algorithm based on a twin delayed deep deterministic policy gradients (TD3) framework to solve the PQNR problem for large-scale topologies. Simulation results show that our proposed algorithm approaches well compared to the optimal solution and outperforms several baseline algorithms. Moreover, using optical bypass jointly with trusted relay can improve the performance in terms of the key rate by 14% and 18% compared to the cases where only optical bypass and only trusted relay are applied, respectively.","IEEE, Web of Science"
A. Grimaldi; E. Raimondo; A. Giordano; K. Y. ?amsar?; G. Finocchio,A Comparison of Energy Minimization Algorithms for Solving Max-Sat Problem with Probabilistic Ising Machines,2023,10.1109/NANO58406.2023.10231311,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10231311,Conference Paper,2023 IEEE 23rd International Conference on Nanotechnology (NANO),"Ising machines are one of the most promising unconventional computing paradigms in the field of combinatorial optimization. Several ways of employing the Ising model were devised in the latest years and, among them, probabilistic computing with p-bits stands out for its high hardware compatibility and remarkable performance. One of the key elements of the solving process of a given instance of a problem is the energy minimization algorithm used. In this work, classical annealing (CA), parallel tempering (PT), and simulated quantum annealing (SQA) are compared over the same instance of a maximum satisfiability problem. The results show that, for a high number of replicas, SQA performs better than the other two algorithms. Conversely, with contained number of replicas, CA and PT are comparable in performance between each other and both are superior to SQA. Those results call for the development of platforms/protocols where to compare and potentially combine those annealing approaches.",IEEE
Shalini; A. Kumar Gupta; Y. M. Sharma,A novel hybrid scheme to magnify performance of CPU scheduling,2017,10.1109/CESYS.2017.8321189,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8321189,Conference Paper,2017 2nd International Conference on Communication and Electronics Systems (ICCES),"Nowadays, with the rapid progress in time constraint applications the term CPU scheduling become as an essential aspect for a system. Typically, CPU scheduling is a decision making method of an operating system to deals with the problem of sharing system resources (e.g. CPU time and bandwidth) over the numerous process in an optimum way. However, there are lot of algorithms are available to schedule the CPU, gives focus on compelling full advantage of CPU by minimizing waiting time, turnaround time and number of context switches for a set of processes but each and every accessible algorithm performs differently and have their own unique limitations, low capability, non-utilization of resources in a systematic manner and needs to wait for an undefined time period, often cause for a deadlock situation. This paper proposed an innovative hybrid approach based on MLFQ and SJF algorithm for enhance the utilization of CPU. Instead of employing fixed time quantum the designed approach incorporate a new scheme to set up an optimal quantum time dynamically after end of each tasks execution process. A number of simulations have carried out to demonstrate the efficiency of proposed algorithm in terms of short average waiting and turnaround time. The simulation results demonstrate the effectiveness of proposed scheme over the other accessible algorithms.",IEEE
E. Pelofske; A. B?rtschi; J. Golden; S. Eidenbenz,High-Round QAOA for MAX $k$-SAT on Trapped Ion NISQ Devices,2023,10.1109/QCE57702.2023.00064,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10313612,Conference Paper,2023 IEEE International Conference on Quantum Computing and Engineering (QCE),"The Quantum Alternating Operator Ansatz (QAOA) is a hybrid classical-quantum algorithm that aims to sample the optimal solution(s) of discrete combinatorial optimization problems. We present optimized QAOA circuit constructions for sampling MAX $k$-SAT problems, specifically for $k=3$ and $k=4$. The novel 4-SAT QAOA circuit construction we present uses measurement based uncomputation, followed by classical feed forward conditional operations. The QAOA circuit parameters for 3-SAT are optimized via exact classical (noise-free) simulation, using HPC resources to simulate up to 20 rounds on 10 qubits. In order to explore the limits of current NISQ devices we execute these optimized QAOA circuits for random 3-SAT test instances with clause-to-variable ratio 4 on four trapped ion quantum computers: Quantinuum H1-1 (20 qubits), IonQ Harmony (11 qubits), IonQ Aria 1 (25 qubits), and IonQ Forte (30 qubits). The QAOA circuits that are executed include $n=10$ up to $p=20$, and $n=22$ for $p=1$ and $p=2$. The high round circuits use upwards of 9,000 individual gate instructions, making these some of the largest QAOA circuits executed on NISQ devices. Our main finding is that current NISQ devices perform best at low round counts (i.e., $p=1, \ldots, 5$) and then ¨C as expected due to noise ¨C gradually start returning satisfiability truth assignments that are no better than randomly picked solutions as the number of QAOA rounds are further increased.",IEEE
A. Neekabadi; S. J. Kabudian,A New Quantum-PSO Metaheuristic and Its Application to ARMA Modeling of Speech Spectrum,2018,10.1109/ICSPIS.2018.8700530,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8700530,Conference Paper,2018 4th Iranian Conference on Signal Processing and Intelligent Systems (ICSPIS),"In speech signal representation models, autoregressive moving average (ARMA) modeling is used in various applications, such as feature extraction, signal coding, speech synthesis, and speech recognition. In this paper, a new method based on quantum-behaved particle swarm optimization (QPSO) is proposed for estimation of ARMA model coefficients. In the proposed algorithm called PMF-QPSO (probability mass function QPSO), by storing some of the last global best particles in memory, based on their fitnesses, they are given a chance to influence the motion of the next generation particles, which reduces the risk of stopping in local optima and increases the exploration of QPSO algorithm. Also, to ensure the stability of the estimated model, line spectral frequencies (LSF) are used as optimization parameters, and, accordingly, the truncated Laplace distribution is considered for the probability distribution of new particle locations. The implementation of the suggested algorithm in high-order ARMA models on a set of speech signals shows that the proposed method compared to the previous ARMA modeling techniques improves the logarithmic spectral distance measure and compared to the previous QPSO algorithms, performs better in terms of the accuracy and speed of convergence.",IEEE
Y. Tanizawa; R. Takahashi; A. R. Dixon,A routing method designed for a Quantum Key Distribution network,2016,10.1109/ICUFN.2016.7537018,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7537018,Conference Paper,2016 Eighth International Conference on Ubiquitous and Future Networks (ICUFN),"Quantum Key Distribution (QKD) is a technique for sharing encryption keys between two adjacent nodes in an unconditionally secure manner based on quantum theory. From the viewpoint of network system research, QKD is considered to be a building block for providing secure link communication in network systems. Although the communication distance is subject to a limitation attributable to the QKD fundamentals, recent research and some QKD field trials of ¡°key relaying¡± over a ¡°QKD network¡± are overcoming this limitation. It also enables each node on the QKD network to exchange encryption keys with arbitrary nodes on the QKD network. However, the previous research didn't address a routing method on the QKD network in detail. This paper focuses on the routing issues on the QKD network, clarifies the requirements of the routing protocol, and proposes a routing solution designed for the key relaying on the QKD network. The proposed routing solution consists of 4 components: (1) a node interface architecture addressing both encrypted and unencrypted traffics, (2) a path selection algorithm based on the number of keys, (3) an IP address assignment scheme connecting unencrypted interfaces and encrypted interfaces, and (4) a routing protocol deployment method consuming no extra keys. The proposed routing solution allows the QKD network to select a suitable key relaying path according to the QKD system condition and to reduce the extra key consumption, which optimizes the key utilization on the QKD network. The proposed routing solution was implemented with a network emulating QKD technology and evaluated. The evaluation result shows that the proposed routing solution could select a path that stores enough keys, which is suitable for a QKD network. Additional impact analysis reveals that the proposed routing solution could save up to 52% of key consumption depending on the QKD key sharing speed and the routing protocol configuration.",IEEE
V. Monita; R. Munadi; I. D. Irawati,A Quantum Key Distribution Network Routing Performance Based on Software-Defined Network,2023,10.1109/CCWC57344.2023.10099323,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10099323,Conference Paper,2023 IEEE 13th Annual Computing and Communication Workshop and Conference (CCWC),"Quantum key distribution (QKD) is a network security technology that generates encryption keys in real time and randomly during information transmission. This research implements a QKD network based on a software-defined network (SDN) by taking advantage of its advantages, such as saving resources to search for alternative routes and monitoring links to determine whether the conditions in each router network meet the needs or not. Path selection is made using metrics, such as the hop count metric using the routing information protocol (RIP) and the cost using open shortest path first (OSPF). Based on the results of routing performance testing on the QKD network based on SDN, tested ten times to get an average value, OSPF routing is faster at finding alternative routes than RIP routing. The test results for RIP routing throughput of 9.22 ms, delay of 0.76 ms, packet loss of 0.0044%, and convergence time of 10.64 ms. The results for OSPF routing throughput of 9.32 ms, delay of 0.75 ms, packet loss of 0.0039%, and convergence time of 10.51 ms.",IEEE
H. Iesar; W. Iqbal; Y. Abbas; M. Y. Umair; A. Wakeel; F. Illahi; B. Saleem; Z. Muhammad,Revolutionizing Data Center Networks: Dynamic Load Balancing via Floodlight in SDN Environment,2024,10.1109/ICACS60934.2024.10473246,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10473246,Conference Paper,2024 5th International Conference on Advancements in Computational Sciences (ICACS),"In the digital era, the evolution of big data, cloud computing, Internet of Things (IoT), blockchain, and quantum computing demands a preferable networking infrastructure to handle network expansion and network usage optimally. In traditional Data Center Networks (DCNs), bundling of control and data plane in the same networking device limits its functionality for dynamic computation and storage access. The load balancing developed in traditional network infrastructure is not precise, as it is based on the local information of the network. Due to existing static routing mechanisms in traditional networks, most of the network resources are still underutilized. This dissipation of network assets is becoming common in today¡¯s traditional typical networks. SDN emerges as a new platform that promises to control, change, and manage the inherent services of networking nodes by extracting statistics from lower layers of the network topology, facilitating network engineers and administrators. Load balancing in SDN offers a fair load share between network nodes, optimizing the best path along with bandwidth and reducing latency. SDN offers a global view of the whole network in one place, a centralized controller while helping in making satisfactory and upright decisions. In this paper, an SDN-based controller, Floodlight, is chosen for the implementation of dynamic load balancing. The Dijkstra¡¯s algorithm is exercised in our application running on the controller. A data center network, FatTree topology of open flow switches, is deployed to depict the real-life traffic complexity in a data center network. To create a virtual topology of nodes, a Mininet emulation platform is utilized. Different load-balancing verification mechanisms validate that our load- balancing technique is doing a splendid piece of work.",IEEE
T. Tosun; A. Moradi; E. Savas,Exploiting the Central Reduction in Lattice-Based Cryptography,2024,10.1109/ACCESS.2024.3494593,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10747333,Journal,IEEE Access,"This paper questions the side-channel security of central reduction technique, which is widely adapted in efficient implementations of Lattice-Based Cryptography (LBC). We show that the central reduction leads to a vulnerability by creating a strong dependency between the power consumption and the sign of sensitive intermediate values. We exploit this dependency by introducing the novel absolute value prediction function, which can be employed in higher-order non-profiled multi-query Side-Channel Analysis (SCA) attacks. Our results reveal that ¨C compared to classical reduction algorithms ¨C employing the central reduction scheme leads to a two-orders-of-magnitude decrease in the number of required SCA measurements to exploit secrets of masked implementations. We particularly show that our approach is valid for the prime moduli employed by Kyber and Dilithium, the lattice-based post-quantum algorithms selected by NIST. We practically evaluate our introduced approach by performing second-order non-profiled attacks against an open-source masked implementation of Kyber on an ARM Cortex-M4 micro-processor. In our experiments, we revealed the full secret key of the aforementioned masked implementation with only 250 power traces without any forms of profiling or choosing the ciphertexts.",IEEE
M. Barbeau; J. Garcia-Alfaro,Faking and Discriminating the Navigation Data of a Micro Aerial Vehicle Using Quantum Generative Adversarial Networks,2019,10.1109/GCWkshps45667.2019.9024550,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9024550,Conference Paper,2019 IEEE Globecom Workshops (GC Workshops),"We show that the Quantum Generative Adversarial Network (QGAN) paradigm can be employed by an adversary to learn generating data that deceives the monitoring of a Cyber- Physical System (CPS) and to perpetrate a covert attack. As a test case, the ideas are elaborated considering the navigation data of a Micro Aerial Vehicle (MAV). A concrete QGAN design is proposed to generate fake MAV navigation data. Initially, the adversary is entirely ignorant about the dynamics of the CPS, the strength of the approach from the point of view of the bad guy. A design is also proposed to discriminate between genuine and fake MAV navigation data. The designs combine classical optimization, qubit quantum computing and photonic quantum computing. Using the PennyLane software simulation, they are evaluated over a classical computing platform. We assess the learning time and accuracy of the navigation data generator and discriminator versus space complexity, i.e., the amount of quantum memory needed to solve the problem.",IEEE
Y. Li; E. Zio,A quantum-inspired evolutionary approach for non-homogeneous redundancy allocation in series-parallel multi-state systems,2014,10.1109/ICRMS.2014.7107252,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7107252,Conference Paper,"2014 10th International Conference on Reliability, Maintainability and Safety (ICRMS)","Redundancy allocation is a family of well-known reliability optimization problems. The non-homogeneous type of redundancy allocation in series-parallel multi-state systems is among the most difficult ones. Evolutionary algorithms (EAs) are frequently applied to solve the problem, mainly due to the huge search space and the non-closed-form system reliability. This work proposes an efficient approach that combines a quantum-inspired evolutionary algorithm (QEA) with a newly designed local search strategy. Different from the existing EAs, it is able to evolve an explicit probabilistic model to explore the search space in an iterative way. The proposed method is tested on two benchmark problems with the comparisons to the published results. The results are promising in terms of both solution quality and computation efficiency.",IEEE
Y. Kim; J. Song; S. C. Seo,Accelerating Falcon on ARMv8,2022,10.1109/ACCESS.2022.3169784,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9762260,Journal,IEEE Access,"Falcon is one of the promising digital-signature algorithms in NIST¡¯s ongoing Post-Quantum Cryptography (PQC) standardization finalist. Computational efficiency regarding software and hardware is also the main criteria for PQC standardization. In this paper, we present an efficient Falcon software implementation on ARMv8 environment. Until now, most of the software optimization on PQC algorithms have been conducted on 32-bit ARM (Cortex-M4) and typical CPUs (Intel and AMD CPUs). However, ARMv8 including Cortex-A30, 50, and 70 series have been widely used for various IoT (Internet of Things) applications, Edge computing devices, and OBUs (On Board Units) in autonomous driving cars. For optimizing the performance of Falcon, we take full advantage of NEON engine which is a kind of parallel processing unit in ARMv8 MCU. The main computation in Falcon belongs to polynomial multiplications in Complex number domain and Integer domain. Typically, FFT (Fast Fourier Transformation)-based multiplication method and NTT (Number Theoriteic Transform)-based multiplication method have been widely used for efficient polynomial multiplications in Complex number domain and Integer domain, respectively. Thus, in order to enhance the overall performance of Falcon, we improve the FFT-based multiplication method and NTT-based multiplication method by utilizing NEON engine in ARMv8. Specifically, we parallelize the overall process (FFT/NTT transformation, pointwise multiplication, and inverse FFT/NTT transformation) of FFT-based polynomial multiplication method and NTT-based polynomial multiplication method with strategically utilizing the NEON engine and vector instructions. Furthermore, we minimize the number of redundant memory accesses during FFT/NTT-based polynomial multiplication by making the most of available registers in NEON engine. Through the proposed parallel FFT/NTT-based polynomial multiplications, the proposed Falcon software provides 15.1% (resp. 18.1%), 16.5% (resp. 17.1%), and 65.4% (resp. 69.4%) of performance improvement in keypair generation, signing, and verification at security level 1 (resp. 5) compared with the reference Falcon implementation submitted to the final round of NIST PQC competition. Furthermore, as far as we know, this is the first optimized implementation of Falcon on ARMv8 environment.","IEEE, Web of Science"
D. N. Nguyen; V. D. Tran; H. L. Pham; V. T. Duong Le; D. K. Lam; T. H. Tran; Y. Nakashima,HyperNTT: A Fast and Accurate NTT/INTT Accelerator with Multi-Level Pipelining and an Improved K2-RED Module,2024,10.1109/ITC-CSCC62988.2024.10628429,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10628429,Conference Paper,"2024 International Technical Conference on Circuits/Systems, Computers, and Communications (ITC-CSCC)","Post-quantum cryptography is advancing rapidly to counteract the potential threats posed by upcoming quantum computers, with lattice-based algorithms playing a key role. In these algorithms, polynomial multiplication using the number theoretic transform (NTT) presents a significant computational challenge, affecting performance. Existing NTT architectures face challenges in achieving high performance and low area, and the K2-RED module within the NTT is prone to bit overflow errors. Therefore, this paper introduces HyperNTT with three innovative ideas to achieve high throughput, low area consumption, and error-free polynomial multiplication. First, HyperNTT utilizes a multi-stage pipeline with NTT cores that incorporate a fully-pipelined butterfly unit (FPBU) design, reducing the workload per stage by one-third compared to conventional methods. Second, simplified modular reduction modules are recommended to substitute multiplication with shifts and additions, thereby optimizing pipeline efficiency for high-speed performance. Third, a DSP-free HyperNTT with the new K2-RED architecture is proposed to mitigate error cases and balance execution time, area, and energy efficiency. The HyperNTT architectures have been implemented at the System-on-Chip (SoC) level for correctness verification. Besides, FPGA evaluations demonstrate that Hyper-NTT outperforms previous works by 1.2 to 6 times in area-delay product, while the ASIC experiment shows its superiority by at least 2.84 times in area-delay product and power-delay product.",IEEE
M. Li; X. Wang; Y. Gong; Y. Liu; C. Jiang,Binary glowworm swarm optimization for unit commitment,2014,10.1007/s40565-014-0084-9,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9005371,Journal,Journal of Modern Power Systems and Clean Energy,"This paper proposes a new algorithm-binary glowworm swarm optimization (BGSO) to solve the unit commitment (UC) problem. After a certain quantity of initial feasible solutions is obtained by using the priority list and the decommitment of redundant unit, BGSO is applied to optimize the on/off state of the unit, and the Lambda-iteration method is adopted to solve the economic dispatch problem. In the iterative process, the solutions that do not satisfy all the constraints are adjusted by the correction method. Furthermore, different adjustment techniques such as conversion from cold start to hot start, decommitment of redundant unit, are adopted to avoid falling into local optimal solution and to keep the diversity of the feasible solutions. The proposed BGSO is tested on the power system in the range of 10¨C140 generating units for a 24-h scheduling period and compared to quantum-inspired evolutionary algorithm (QEA), improved binary particle swarm optimization (IBPSO) and mixed integer programming (MIP). Simulated results distinctly show that BGSO is very competent in solving the UC problem in comparison to the previously reported algorithms.",IEEE
J. L. Ima?a; P. He; T. Bao; Y. Tu; J. Xie,Efficient Hardware Arithmetic for Inverted Binary Ring-LWE Based Post-Quantum Cryptography,2022,10.1109/TCSI.2022.3169471,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9765848,Journal,IEEE Transactions on Circuits and Systems I: Regular Papers,"Ring learning-with-errors (RLWE)-based encryption scheme is a lattice-based cryptographic algorithm that constitutes one of the most promising candidates for Post-Quantum Cryptography (PQC) standardization due to its efficient implementation and low computational complexity. Binary Ring-LWE (BRLWE) is a new optimized variant of RLWE, which achieves smaller computational complexity and higher efficient hardware implementations. In this paper, two efficient architectures based on Linear-Feedback Shift Register (LFSR) for the arithmetic used in Inverted Binary Ring-LWE (InvBRLWE)-based encryption scheme are presented, namely the operation of  $A\cdot B+C$  over the polynomial ring  $\mathbb {Z}_{q}/(x^{n}+1)$ . The first architecture optimizes the resource usage for major computation and has a novel input processing setup to speed up the overall processing latency with minimized input loading cycles. The second architecture deploys an innovative serial-in serial-out processing format to reduce the involved area usage further yet maintains a regular input loading time-complexity. Experimental results show that the architectures presented here improve the complexities obtained by competing schemes found in the literature, e.g., involving 71.23% less area-delay product than recent designs. Both architectures are highly efficient in terms of area-time complexities and can be extended for deploying in different lightweight application environments.",IEEE
E. C. Behrman; J. E. Steck,Programming quantum annealing computers using machine learning,2017,10.1109/SMC.2017.8122617,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8122617,Conference Paper,"2017 IEEE International Conference on Systems, Man, and Cybernetics (SMC)","Commercial quantum annealing (QA) machines are now being built with hundreds of quantum bits (qubits). These are used as analog computers, to solve optimization problems by annealing to an unknown ground state (the solution), given the Hamiltonian for that problem. We propose and develop a new approach, in which we use machine learning to do the inverse problem: to find the Hamiltonian that will produce a given, desired ground state. We demonstrate successful learning to produce a desired fully entangled state for a two-qubit system, then bootstrap to do the same for three, four, five and six qubits; the amount of additional learning necessary decreases. With these new capabilities the computing possibilities for QA arrays are greatly expanded.",IEEE
A. V. Shvetsov; S. Hamood Alsamhi,"When Holographic Communication Meets Metaverse: Applications, Challenges, and Future Trends",2024,10.1109/ACCESS.2024.3514576,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10788695,Journal,IEEE Access,"Holographic communication represents a transformative technology for reshaping the digital interaction landscape by enabling the creation of realistic, immersive, and interactive 3D experiences. This survey overviews holographic communication and its integration with the Metaverse technologies¡¯ concepts, advantages, uses, and many applications. Furthermore, we examine a new paradigm for integrating holographic communication with the Metaverse, emphasizing how holography enhances immersive quality of virtual environments within the Metaverse, making interactions more lifelike and engaging. Extending the integration of holographic communication and Metaverse, we examine this combination¡¯s numerous uses in various applications across various industries, such as education where virtual classrooms and 3D simulations redefine remote learning, a business where virtual meetings and product demonstrations create more impactful customer engagements, entertainment where immersive gaming and 3D broadcasting transform user experiences, healthcare where remote consultations and surgical simulations enhance medical training and accessibility, and remote assistance where real-time holographic support improves technical troubleshooting. In addition, we discuss the challenges and prospects of integration of holographic communication into Metaverse ecosystems, emphasizing key approaches and technical developments emerging technologies such as AI-driven content optimization, advanced coding and compression techniques, and new paradigms like terahertz communication and quantum holography. This survey highlights the revolutionary potential of holographic communication and offers insightful information on how it will influence digital engagement and connectivity in the future, eventually opening up new avenues in the quickly changing Metaverse landscape.",IEEE
J. Sun; H. Zhu,Self-Sensing Technology of Rotor Displacement for Six-Pole Radial Active Magnetic Bearing Using Improved Quantum Particle Swarm Optimized Cubature Kalman Filter,2022,10.1109/JESTPE.2021.3118491,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9562752,Journal,IEEE Journal of Emerging and Selected Topics in Power Electronics,"In order to solve the problems of high cost and large volume of the displacement sensors in magnetic bearings, an improved quantum particle swarm optimization (IQPSO) algorithm optimized cubature Kalman filter (CKF) prediction model was proposed for a six-pole radial active magnetic bearing (AMB). First, the structure and operation principle of the AMB are introduced, and the mathematical model of the suspension force is derived by the equivalent magnetic circuit method. Combined with CKF, the prediction model of the six-pole radial AMB is established, and the state prediction values obtained by the prediction model at the time of updating stage are optimized by the IQPSO algorithm, and the rotor displacement self-sensing technology is achieved. Then, the simulation system is constructed, and the simulation analysis of floating and anti-interference are carried out, which show the prediction ability and anti-interference performance of IQPSO algorithm optimized CKF prediction model is stronger than standard prediction model. Finally, the verification experiment is carried out on the experimental platform, which proves the feasibility of the method.",IEEE
A. Ferozpuri; K. Gaj,High-speed FPGA Implementation of the NIST Round 1 Rainbow Signature Scheme,2018,10.1109/RECONFIG.2018.8641734,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8641734,Conference Paper,2018 International Conference on ReConFigurable Computing and FPGAs (ReConFig),"Round 1 of the the NIST post-quantum cryptography (PQC) standardization effort began on November 30th, 2017. The competition aims to select the most promising quantum-resistant algorithms, which are currently secure against large scale quantum computers. Multivariate cryptosystems belong to a promising group of PQC schemes and are based on multivariate polynomials over finite fields. Among them are the Unbalanced Oil and Vinegar (UOV) and Rainbow signature schemes, which have been extensively studied since 1999 and 2005, respectively. The main advantage of UOV is high confidence in its security, and the disadvantages include large key and signature sizes. Rainbow is a multi-layer version of UOV that offers better performance, smaller keys, and smaller signatures. This paper presents a high-speed FPGA implementation for the NIST Round 1 PQC submission of Rainbow. We discuss a high-speed design that uses a parameterized system solver, which can solve an n-byn system in n clock cycles. Compared to the previous state-of-the-art, we reduce the number of required multipliers by almost half, speed up execution, and implement Rainbow for higher security levels. Our design supports many parameter sets, which require operations in the fields GF(16) and GF(256). Additionally, in order to make benchmarking easier and fairer, our design follows a universal PQC hardware API, which allows for fair comparison with other post-quantum signature schemes. This design is being made open-source to increase transparency and speed up further optimization.",IEEE
Z. Wang; J. Yang; X. Du; Y. Li; H. Su,Optimization Configuration Method of Industrial User-side Energy Storage,2020,10.1109/SPIES48661.2020.9242978,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9242978,Conference Paper,2020 2nd International Conference on Smart Power & Internet Energy Systems (SPIES),"Aiming at the punishment problem of large industrial users who exceed the maximum demand under the condition of demand electricity price, an optimal configuration model of user-side energy storage system based on the two-layer decision is proposed. Under the condition of the maximum demand billing in the two-part electricity price, the objective function of the outer layer of the model is the total cost of the energy storage system in the life cycle of the energy storage medium, taking into account the cost of electricity price, energy storage battery and related equipment costs, etc. Factors to obtain the configuration results of energy storage capacity and maximum demand; the inner objective function is the cost of daily electricity consumption by users, and the optimal daily combined load curve is obtained. Through numerical simulation, using quantum genetic algorithm and YALMIP toolbox to optimize the two-layer decision model, the capacity configuration, economy and performance of lithium battery and lead-acid battery are compared, and the validity of the model is verified.",IEEE
D. Gao; N. Xia; X. Liu; L. Gao; D. Wang; Y. Liu; M. Peng,Joint Load Adjustment and Sleep Management for Virtualized gNBs in Computing Power Networks,2024,10.1109/TWC.2024.3516077,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10810285,Article,IEEE Transactions on Wireless Communications,"The forthcoming sixth generation (6G) mobile communication system aims to advance technologies that span and integrate computation and communications. Computing power networks (CPNs) and virtualized radio access networks (vRANs) are regarded as two fundamental techniques to achieve this integration. Network functions of virtualized next-generation Node Bs (vgNBs) are implemented on general-purpose servers to process protocol stacks. The energy consumption of vgNBs accounts for a significant portion of energy consumption. However, the proliferation of computing power nodes results in increased energy consumption in CPNs. Power usage effectiveness (PUE) reflects the efficiency of computing nodes while efficiency of computing power (ECP) is adopted to indicate data rates per computing power unit. In this work, a joint load adjustment and sleep management scheme was designed to maximize ECP while minimizing PUE. The optimization problem was formulated as a mixed integer non-linear programming (MINLP) problem, which is NP-hard. A quantum genetic algorithm (QGA) with non-equal size quantum register was suggested to solve this problem. Simulation results demonstrated that the proposed algorithm could outperform benchmark approaches in terms of convergence speed, ECP, PUE, and computing power consumption. When compared to other methods, the proposed approach could improve ECP and computation energy consumption by up to 19.5% and 21.7%, respectively.",IEEE
D. Li; L. Huang; K. Wang; W. Pang; Y. Zhou; R. Zhang,"A General Framework for Accelerating Swarm Intelligence Algorithms on FPGAs, GPUs and Multi-Core CPUs",2018,10.1109/ACCESS.2018.2882455,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8540814,Journal,IEEE Access,"Swarm intelligence algorithms (SIAs) have demonstrated excellent performance when solving optimization problems including many real-world problems. However, because of their expensive computational cost for some complex problems, SIAs need to be accelerated effectively for better performance. This paper presents a high-performance general framework to accelerate SIAs (FASI). Different from the previous work which accelerates SIAs through enhancing the parallelization only, FASI considers both the memory architectures of hardware platforms and the dataflow of SIAs, and it reschedules the framework of SIAs as a converged dataflow to improve the memory access efficiency. FASI achieves higher acceleration ability by matching the algorithm framework to the hardware architectures. We also design deep optimized structures of the parallelization and convergence of FASI based on the characteristics of specific hardware platforms. We take the quantum behaved particle swarm optimization algorithm as a case to evaluate FASI. The results show that FASI improves the throughput of SIAs and provides better performance through optimizing the hardware implementations. In our experiments, FASI achieves a maximum of 290.7 Mb/s throughput which is higher than several existing systems, and FASI on FPGAs achieves a better speedup than that on GPUs and multi-core CPUs. FASI is up to 123 times and not less than 1.45 times faster in terms of optimization time on Xilinx Kintex Ultrascale xcku040 when compares to Intel Core i7-6700 CPU/NVIDIA GTX1080 GPU. Finally, we compare the differences of deploying FASI on hardware platforms and provide some guidelines for promoting the acceleration performance according to the hardware architectures.",IEEE
S. T. Prasad; Sarishma; G. S. Rekha; D. Vekariya; H. Patil; R. Maranan,An Optimized Equivariant Quantum Network for Ingenious Building Monitoring and Control using an Android Application,2024,10.1109/ICSES63445.2024.10763033,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10763033,Conference Paper,2024 4th International Conference on Sustainable Expert Systems (ICSES),"For enhancing the security and functionality of smart environments, motion recognition, classification and intruder detection has to be added into the building monitoring and control system. This research developed a Self-Guided Efficient Net UNet based Equivariant Quantum Network with Alpine Skiing Optimization (SGENUN-EQN-ASO) for improving intruder detection in buildings by utilizing an Android application for real-time motion detection and categorization. To prepare the data for analysis, processing can be done on the Self-Guided Filtering (SGF). An enhanced approach is Essential Objectness, Cascade Networks, Equivariant Quantum Convolutional Neural Networks (EquivQCNN) to enhance the detection precision and EfficientNet-based EE-UNet for precise motion assessment. Thus, the Android application works as monitoring and control interface providing real-time notifications and the answers to detected intrusions. With the use of optimisation techniques like Alpine Skiing Optimisation (ASO), which is used to fine-tune the hyperparameters of Equivariant Quantum Neural Networks (EQNNs), the system is able to provide stable and flexible performance. The results demonstrating that the integration of the latest machine learning approaches into the solutions in smart buildings brings significant enhancement to the detection effectiveness and response times, as to the overall security and management.",IEEE
K. Ramaiah; P. B. Soundarabai,An Intelligent Portfolio Management Scheme Based On Hybrid Deep Reinforcement Learning and Cumulative Prospective Approach,2024,10.1109/ICWITE59797.2024.10503521,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10503521,Conference Paper,"2024 IEEE International Conference for Women in Innovation, Technology & Entrepreneurship (ICWITE)","Stock markets retain an extensive role towards economic growth of diverse countries and it is a place where investors invest assured amount to earn more profit and the issuers pursue the investors for project investing. However, it is deliberated as a challenging task to buy and sell because of its explosive and complex nature. The existing portfolio optimization models are primarily focused on just improving the returns whereas, the selection of optimal assets is least focused. Hence, the proposed research article focuses on the integration of stock prediction with the portfolio optimization model (SPPO). Initially, the stock prices for the next period are predicted using the hybrid deep reinforcement learning (DRL) model. Within this prediction model, the gated recurrent unit network (GRUN) model is utilized to simulate the interactions of the agent with the environment. The best actions in the prediction model are determined throughout the prediction process using the quantum differential evolution algorithm (Q-DEA). After the prediction of best assets, the optimal portfolio with the best assets is selected using the cumulative prospect theory (CPT) model. The work will be implemented in python and evaluated using the NIFTY-50 Stock Market Data (2000 -2021) dataset. Minimal error rates of 0.130, 0.114, 0.148 and 0.153 is obtained by the proposed model in case of MSE, MAE, RMSE and MAPE.",IEEE
Z. Qin; R. Tong; X. Wu; G. Bai; L. Wu; L. Su,A Compact Full Hardware Implementation of PQC Algorithm NTRU,2021,10.1109/CISCE52179.2021.9446042,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9446042,Conference Paper,"2021 International Conference on Communications, Information System and Computer Engineering (CISCE)","With the emergence and development of quantum computers, the traditional public-key cryptography (PKC) is facing the risk of being cracked. In order to resist quantum attacks and ensure long-term communication security, NIST launched a global collection of Post Quantum Cryptography (PQC) standards in 2016, and it is currently in the third round of selection. There are three Lattice-based PKC algorithms that stand out, and NTRU is one of them. In this article, we proposed the first complete and compact full hardware implementation of NTRU algorithm submitted in the third round. By using one structure to complete the design of the three types of complex polynomial multiplications in the algorithm, we achieved better performance while reducing area costs.",IEEE
L. Madden; A. Akhriev; A. Simonetto,Sketching the Best Approximate Quantum Compiling Problem,2022,10.1109/QCE53715.2022.00071,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9951173,Conference Paper,2022 IEEE International Conference on Quantum Computing and Engineering (QCE),"This paper considers the problem of quantum compilation from an optimization perspective by fixing a circuit structure of CNOTs and rotation gates then optimizing over the rotation angles. We solve the optimization problem classically and consider algorithmic tools to scale it to higher numbers of qubits. We investigate stochastic gradient descent and two sketchand-solve algorithms. For all three algorithms, we compute the gradient efficiently using matrix-vector instead of matrix-matrix computations. Allowing for a runtime on the order of one hour, our implementation using either sketch-and-solve algorithm is able to compile 9 qubit, 27 CNOT circuits; 12 qubit, 24 CNOT circuits; and 15 qubit, 15 CNOT circuits. Without our algorithmic tools, standard optimization does not scale beyond 9 qubit, 9 CNOT circuits, and, beyond that, is theoretically dominated by barren plateaus.",IEEE
K. Jia; Z. Ge; H. Wang; H. Liu; J. Xu; Q. Wu,Research on High-integrated Low-latency Superconducting Quantum Readout System,2023,10.1109/ITOEC57671.2023.10291440,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10291440,Conference Paper,2023 IEEE 7th Information Technology and Mechatronics Engineering Conference (ITOEC),"Superconducting quantum computing has gained significant attention for its ability to prepare a large number of qubits easily. However, the superconducting quantum readout systems, which serve as the foundation of superconducting quantum computing, still face several challenges including low integration, high computing delay, and reduced flexibility. In this paper, a highly integrated and low-latency superconducting readout system is introduced. This system, built on RFSoC chip, comprises multiple analog-to-digital and digital-to-analog conversion channels, as well as demodulation calculation units, to improve the degree of integration. The system employs a time-optimized single-channel matching filter demodulation algorithm to address the problem of high delay associated with readout systems, achieving a demodulation calculation delay of 19.2ns. Additionally, the system supports multiple quantum measurement and control experiments through the parameterization and modular design of functional modules. The actual test reveals that the qubit fidelity F00 and F11 obtained with this system can reach 99.5% and 98.6%, respectively, while the readout speed is significantly enhanced compared to software-based calculation. This system effectively improves the accuracy of quantum state readout.",IEEE
J. -Y. Park; Y. -H. Moon; W. Lee; S. -H. Kim; K. Sakurai,A Survey of Polynomial Multiplication With RSA-ECC Coprocessors and Implementations of NIST PQC Round3 KEM Algorithms in Exynos2100,2022,10.1109/ACCESS.2021.3138807,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9663274,Journal,IEEE Access,"Polynomial multiplication is one of the heaviest operations for a lattice-based public key algorithm in Post-Quantum Cryptography (PQC). Many studies have been done to accelerate polynomial multiplication with newly developed hardware accelerators or special CPU instructions. However, another method utilizes previously implemented and commercial hardware accelerators for RSA/elliptic curve cryptography (ECC). Reusing an existing hardware accelerator is advantageous, not only for the cost benefit but also for the improvement in performance. In this case, the developer should adopt the most efficient implementation method for the functions provided by a given legacy hardware accelerator. It is difficult to find an optimized implementation for a given hardware accelerator because there are a variety of methods, and each method depends on the functions provided by the given accelerator. In order to solve the problem, we survey methods for polynomial multiplication using RSA/ECC coprocessors and their application for Learning With Error (LWE)-based KEM algorithms of National Institute of Standards and Technology (NIST) PQC round 3 candidates. We implement all known methods for polynomial multiplication with RSA/ECC coprocessors in a platform, commercial mobile system-on-chip (SoC), the Exynos2100 Smart Secure Platform (SSP). We present and analyze the simulation results for various legacy hardware accelerators and give guidance for optimized implementation.","IEEE, Web of Science"
M. A. Sayed; M. Taha,A High Speed Post-Quantum Digital Signature At 180 Sig/Sec On ARM Cortex-M4,2023,10.1109/ICMCT60483.2023.00015,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10357743,Conference Paper,2023 8th International Conference on Multimedia Communication Technologies (ICMCT),"This paper presents a high speed implementation of a recently developed quantum-safe multivariate polynomial digital signature algorithm on the ARM Cortex-M4 processor. The structure of the algorithm and its different security levels are demonstrated, with a focus on its layered implementation architecture and optimization techniques. The results demonstrate the superior performance of the new algorithm on resources-constrained devices compared to the three standardized NIST PQC digital signature algorithms in terms of processing speed, key and signature size, flash and RAM memory usage. Overall, the performance metrics presented in this study demonstrate the promising potential of that algorithm for securing digital communications in a post-quantum era.",IEEE
Q. Zhang; M. Saligane; H. -S. Kim; D. Blaauw; G. Tzimpragos; D. Sylvester,Quantum Circuit Simulation with Fast Tensor Decision Diagram,2024,10.1109/ISQED60706.2024.10528748,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10528748,Conference Paper,2024 25th International Symposium on Quality Electronic Design (ISQED),"Quantum circuit simulation is a challenging computational problem crucial for quantum computing research and development. The predominant approaches in this area center on tensor networks, prized for their better concurrency and less computation than methods using full quantum vectors and matrices. However, even with the advantages, array-based tensors can have significant redundancy. We present a novel open-source framework that harnesses tensor decision diagrams to eliminate overheads and achieve significant speedups over prior approaches. On average, it delivers a speedup of 37 ¡Á over Google¡¯s TensorNetwork library on redundancy-rich circuits, and 25 ¡Á and 144 ¡Á over quantum multi-valued decision diagram and prior tensor decision diagram implementation, respectively, on Google random quantum circuits. To achieve this, we introduce a new linear-complexity rank simplification algorithm, Tetris, and edge-centric data structures for recursive tensor decision diagram operations. Additionally, we explore the efficacy of tensor network contraction ordering and optimizations from binary decision diagrams.",IEEE
L. Lu; W. Tian; X. Jia; Z. Song; S. Tan; J. Yin,SmartQCache: Fast and Precise Pulse Control With Near-Quantum Cache Design on FPGA,2024,10.1109/TCAD.2024.3497839,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10752670,Article,IEEE Transactions on Computer-Aided Design of Integrated Circuits and Systems,"Quantum pulse serves as the machine language of superconducting quantum devices, which needs to be synthesized and calibrated for precise control of quantum operations. However, existing pulse control systems suffer from the dilemma between long synthesis latency and inaccuracy of quantum control systems. compute-in-CPU synthesis frameworks, like IBM Qiskit Pulse alexander2020qiskit, involve massive redundant computation during pulse calculation, suffering from a high computational cost when handling large-scale circuits. On the other hand, FPGA-based synthesis frameworks, like QuMA fu2017experimental, faces inaccurate pulse control problem. In this paper, we propose both compute-in-CPU and all-in-FPGA solutions to collaboratively solve the latency and inaccuracy problem. First, we propose QPulseLib, a novel compute-in-CPU library with reusable pulses that can directly provide the pulse of a circuit pattern. To establish this library, we transform the circuit and apply convolutional operators to extract reusable patterns and pre-calculate their resultant pulses. Then, we develop a matching algorithm to identify such patterns shared by the target circuit. Experiments show that QPulseLib achieves 158.46¡Á and 16.03¡Á speedup for pulse calculation, compared to Qiskit Pulse and AccQOC cheng2020accqoc. Moreover, we extend the design as a fast and precise all-in-FPGA pulse control approach using near-quantum cache design, SmartQCache. To be specific, we employ a two-level cache to hold reusable pulses of frequently-used circuit patterns. Such a design enables pulse pre-fetching in near-quantum peripherals, dramatically reducing the end-to-end synthesis latency. To achieve precise pulse control, SmartQCache incorporates duration optimization and pulse sequence calibration to mitigate the execution errors from imperfect hardware, crosstalk, and time shift. Experimental results demonstrate that SmartQCache achieves 294.37¡Á and 145.43¡Á speedup in pulse synthesis compared to Qiskit Pulse alexander2020qiskit and AccQOC cheng2020accqoc. It also reduces the pulse inaccuracy by 1.27¡Á compared to QuMA [2].",IEEE
Y. Cao; Y. Wu; W. Wang; X. Lu; S. Chen; J. Ye; C. -H. Chang,An Efficient Full Hardware Implementation of Extended Merkle Signature Scheme,2022,10.1109/TCSI.2021.3115786,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9559627,Journal,IEEE Transactions on Circuits and Systems I: Regular Papers,"This paper presents a full hardware implementation of the eXtended Merkle Signature Scheme (XMSS), a NIST approved and IETF RFC specified post-quantum cryptography (PQC) algorithm. An optimized node traversal is proposed to enable efficient memory utilization without compromising the computational latency of the L-tree and Merkle tree construction, which are two key components used for the compression of the Winternitz One-Time Signature (WOTS) public key in XMSS. The computation of the authentication path during signature generation has also been significantly sped up by our proposed hardware implementation of the Buchmann, Dahmen, and Schneider (BDS) algorithm. Our implementation has completely avoided the use of block random-access memory, which is known to be vulnerable to side-channel attacks. The memory requirement has been highly optimized for implementation with small flip-flop chains and register counters as pointers for fast data access. To the best of our knowledge, this is the first full hardware implementation of all three key generation, signing and verification operations of XMSS. The design has been prototyped and evaluated on a 28 nm FPGA platform to demonstrate its performance improvements over the most efficient software and hardware/software co-design methods reported to date. Specifically, it increases the computational efficiency of the best reported XMSS implementation for key generation and signature generation by about 20% and 50%, respectively. It can also run at 10% higher clock speed than the fastest hardware implementation of signature verification in FPGA with 8% lower hardware resource utilization.","IEEE, Web of Science"
S. Shen; H. Yang; W. Dai; H. Zhang; Z. Liu; Y. Zhao,High-Throughput GPU Implementation of Dilithium Post-Quantum Digital Signature,2024,10.1109/TPDS.2024.3453289,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10663956,Journal,IEEE Transactions on Parallel and Distributed Systems,"Digital signatures are fundamental building blocks in various protocols to provide integrity and authenticity. The development of the quantum computing has raised concerns about the security guarantees afforded by classical signature schemes. CRYSTALS-Dilithium is an efficient post-quantum digital signature scheme based on lattice cryptography and has been selected as the primary algorithm for standardization by the National Institute of Standards and Technology. In this work, we present a high-throughput GPU implementation of Dilithium. For individual operations, we employ a range of computational and memory optimizations to overcome sequential constraints, reduce memory usage and IO latency, address bank conflicts, and mitigate pipeline stalls. This results in high and balanced compute throughput and memory throughput for each operation. In terms of concurrent task processing, we leverage task-level batching to fully utilize parallelism and implement a memory pool mechanism for rapid memory access. We propose a dynamic task scheduling mechanism to improve multiprocessor occupancy and significantly reduce execution time. Furthermore, we apply asynchronous computing and launch multiple streams to hide data transfer latencies and maximize the computing capabilities of both CPU and GPU. Across all three security levels, our GPU implementation achieves over 160¡Á speedups for signing and over 80¡Á speedups for verification on both commercial and server-grade GPUs. This achieves microsecond-level amortized execution times for each task, offering a high-throughput and quantum-resistant solution suitable for a wide array of applications in real systems.",IEEE
A. Waris; A. Aziz; B. Muhammad Khan,Unified Butterfly for NTT in Post-Quantum Cryptography Algorithm CRYSTALs-Kyber,2024,10.1109/ICONICS64289.2024.10824499,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10824499,Conference Paper,2024 4th International Conference on Innovations in Computer Science (ICONICS),"Quantum computing is a fast developing technology that puts the presently implemented cryptosystems at risk. National Institute of Standards and Technology announced CRSYTALs-Kyber as a standard after Post Quantum Cryptography competition. Kyber is a Lattice-based Cryptography algorithm that uses Number Theoretic transform technique to perform polynomial multiplication. To make NTT efficient, a compact and high-performance butterfly unit is required. In this work we have presented an FPGA based pipelined butterfly structure by incorporating a multiplier-free and low-complex Barrett reduction algorithm. Consequently, our design achieves an 18.2% increase in maximum operating frequency and 32.9% improvement in hardware efficiency.",IEEE
Y. Zhu; M. Zhu; B. Yang; W. Zhu; C. Deng; C. Chen; S. Wei; L. Liu,LWRpro: An Energy-Efficient Configurable Crypto-Processor for Module-LWR,2021,10.1109/TCSI.2020.3048395,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9321216,Journal,IEEE Transactions on Circuits and Systems I: Regular Papers,"Saber, the only module-learning with rounding-based algorithm in NIST's third round of post-quantum cryptography (PQC) standardization process, is characterized by simplicity and flexibility. However, energy-efficient implementation of Saber is still under investigation since the commonly used number theoretic transform can not be utilized directly. In this manuscript, an energy-efficient configurable crypto-processor supporting multi-security-level key encapsulation mechanism of Saber, is proposed. First, an 8-level hierarchical Karatsuba framework is utilized to reduce degree-256 polynomial multiplication to the coefficient-wise multiplication. Second, a hardware-efficient Karatsuba scheduling strategy and an optimized pre-/post-processing structure is designed to reduce the area overheads of scheduling strategy. Third, a task-rescheduling-based pipeline strategy and truncated multipliers are proposed to enable fine-grained processing. Moreover, multiple parameter sets are supported in LWRpro to enable configurability among various security scenarios. Enabled by these optimizations, LWRpro requires 1066, 1456 and 1701 clock cycles for key generation, encapsulation, and decapsulation of Saber768. The post-layout version of LWRpro is implemented with TSMC 40 nm CMOS process within 0.38 mm2. The throughput for Saber768 is up to 275k encapsulation operations per second and the energy efficiency is 0.15 uJ/encapsulation while operating at 400 MHz, achieving nearly 50¡Á improvement and 31¡Á improvement, respectively compared with current PQC hardware solutions.",IEEE
A. C. Ramos; M. Vellasco,Chaotic Quantum-inspired Evolutionary Algorithm: enhancing feature selection in BCI,2020,10.1109/CEC48606.2020.9185608,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9185608,Conference Paper,2020 IEEE Congress on Evolutionary Computation (CEC),"Quantum-inspired Evolutionary Algorithms (QiEAs) have demonstrated to be very effective in several applications. In particular, employing this algorithm for feature selection as a wrapper technique in Brain-Computer Interfaces applications was recently proposed with great results. Moreover, the training time of the model was decreased while maintaining a high classification accuracy, both essential conditions for a successful BCI. The drawback of this model was the sensitiveness to changes in the direction and magnitude of the rotation angle, which can produce adverse effects in both performance and convergence time. Chaotic systems and Evolutionary algorithms, when combined, can enhance the convergence rate and speed of the evolutionary process, incrementing the capacity of reaching the global optima. In this paper we explore the effects of adding ergodicity to a QiEA by the employment of chaotic maps in two operators: chaotic uniform crossover and chaotic quantum update gate. To validate the proposed approach, six commonly used chaotic maps are tested with data of Motor Imagery (MI) Electroencephalography (EEG) of right and left hand movement. The results of these experiments are compared with the ones of a QiEA and a classical Genetic Algorithm (GA). In the proposed model, Wavelet Packet Decomposition is employed as the time-frequency analysis to characterize the signal, whereas a Multilayer Perceptron Neural Network is used as a classifier. The results demonstrated that Chaotic QiEAs can significantly improve the convergence time of the model with only a small loss in the final accuracy.",IEEE
Y. Zhu; W. Zhu; C. Li; M. Zhu; C. Deng; C. Chen; S. Yin; S. Yin; S. Wei; L. Liu,RePQC: A 3.4-uJ/Op 48-kOPS Post-Quantum Crypto-Processor for Multiple-Mathematical Problems,2023,10.1109/JSSC.2022.3216758,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9977406,Journal,IEEE Journal of Solid-State Circuits,"Post-quantum cryptography (PQC) is investigated to replace the classical public cryptography algorithms, which would be completely broken by large-scale quantum computers. However, current PQC schemes have completely different mathematical foundations and parameter sets, which makes the implementation of unified PQC processor extremely challenging. To address this issue, an agile PQC processor, RePQC, is proposed in this work to support schemes on multiple mathematical problems. First, the hierarchical calculation framework, ranging from algorithm level, task level, and coefficient level, is proposed to achieve desirable flexibility and energy efficiency. Second, a hybrid processing element array is built to support arithmetic and logical operations simultaneously, while algorithm-hardware co-design is utilized in task-level schedulers to further improve the algorithm-oriented energy efficiency. Finally, parallelism exploration and algorithm-level computation transformation is further utilized to optimize the configuration on RePQC for higher throughput. Fabricated in a 28-nm process, RePQC achieves the energy efficiency of 3.4 uJ/Op and the throughput of 48 kOPS, which is  $2\times $  and  $23\times $  higher than the state-of-the-art work, respectively. To the best of our knowledge, RePQC is the first silicon-proven PQC processor for different mathematical problems.",IEEE
S. ?zeren; O. Yayla,Methods for Masking CRYSTALS-Kyber Against Side-Channel Attacks,2023,10.1109/ISCTrkiye61151.2023.10336068,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10336068,Conference Paper,2023 16th International Conference on Information Security and Cryptology (ISCT¨¹rkiye),"In the context of post-quantum secure algorithms like CRYSTALS-Kyber, the importance of protecting sensitive polynomial coefficients from side-channel attacks is increasingly recognized. Our research introduces two alternative masking methods to enhance the security of the compression function in Kyber through masking. Prior to this, the topic had been addressed by only one other research study. The ""Double and Check"" method integrates arithmetic sharing and symmetry adjustments, introducing a layer of obfuscation by determining coefficient values based on modular overflows. In contrast, the Look-Up-Table (LUT) integration method employs arithmetic-to-Boolean conversions, augmented by a pre-computed table for efficient value verifications. Furthermore, by leveraging the alternative prime 7681, we propose a novel masked compression function. This prime, 7681, is also notable as the smallest prime suitable for fast NTT multiplication. While both algorithms prioritize data protection and streamlined processing, they also underscore the inherent challenges of balancing computational speed with the potential vulnerabilities to side-channel attacks.",IEEE
D. Iliadis-Apostolidis; K. Manaa; M. Kadosh; I. Ioannou; V. Vassiliou; S. Kosta; J. J. Vegas Olmos,Towards Accelerating the Network Performance on DPUs by optimising the P4 runtime,2024,10.1109/PDP62718.2024.00040,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10495559,Conference Paper,"2024 32nd Euromicro International Conference on Parallel, Distributed and Network-Based Processing (PDP)","Data Processing Units (DPUs) are becoming increasingly popular, especially for use in conjunction with Warehouse-Scale Computers (WSCs) due to their ability to handle networking functions and data-centric workloads. Cost-performance, energy efficiency, network 1/0, and batch processing workloads are important design factors for WSCs. Recent developments in AI and the never-ending increase in demand for data processing, cloud computing, and HPC set the optimisation of all those design factors as a high priority. DPUs can be utilised to achieve significant improvements in all those areas. This includes in-line network processing and upcoming enhanced security paradigms such as post-quantum cryptography (PQC) for quantum re-silient communications or software-defined perimeters (SDP) for confidential computing implementations. Being P4-enabled and dRMT-based, DPUs allow for the reconfigurability of the network traffic without the need to change the hardware. However, the network performance on such devices is only sometimes deter-ministic since the actual traffic and the rules, both of which have to do with packet processing, are not known during compile time. In this paper, we envision how the network performance on DPUs can be accelerated. We describe the challenges that negatively impact the bandwidth and latency: the complex steering pipeline and the massive runtime needed to optimise. These challenges arise from the lack of information during compile time that is only known during runtime. Thus, we envision optimising during runtime by leveraging DPUs' reconfigurability on the network 110. For this, we discuss the significant factors that must be considered to accelerate the network performance on such devices and we propose a solution for them.",IEEE
M. S. Abdul Hameed; G. S. Chadha; A. Schwung; S. X. Ding,Gradient Monitored Reinforcement Learning,2023,10.1109/TNNLS.2021.3119853,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9585302,Journal,IEEE Transactions on Neural Networks and Learning Systems,"This article presents a novel neural network training approach for faster convergence and better generalization abilities in deep reinforcement learning (RL). Particularly, we focus on the enhancement of training and evaluation performance in RL algorithms by systematically reducing gradient¡¯s variance and, thereby, providing a more targeted learning process. The proposed method, which we term gradient monitoring (GM), is a method to steer the learning in the weight parameters of a neural network based on the dynamic development and feedback from the training process itself. We propose different variants of the GM method that we prove to increase the underlying performance of the model. One of the proposed variants, momentum with GM (M-WGM), allows for a continuous adjustment of the quantum of backpropagated gradients in the network based on certain learning parameters. We further enhance the method with the adaptive M-WGM (AM-WGM) method, which allows for automatic adjustment between focused learning of certain weights versus more dispersed learning depending on the feedback from the rewards collected. As a by-product, it also allows for automatic derivation of the required deep network sizes during training as the method automatically freezes trained weights. The method is applied to two discrete (real-world multirobot coordination problems and Atari games) and one continuous control task (MuJoCo) using advantage actor¨Ccritic (A2C) and proximal policy optimization (PPO), respectively. The results obtained particularly underline the applicability and performance improvements of the methods in terms of generalization capability.",IEEE
L. Shi; Y. He; B. Li; Y. Wu; Y. Huang; T. Cheng,On-Line Measurement of Dynamic Tilt Angle by Compensating Gyroscope Drift Error,2019,10.1109/TIM.2018.2878073,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8536473,Journal,IEEE Transactions on Instrumentation and Measurement,"In real-time movement controlling systems, it is essential to deploy a suitable sensor to measure tilt angle on-line. When the tilt angle is bigger than the preset threshold, the remedial operation should be made timely. This paper proposes an on-line dynamic tilt angle measurement method by compensating gyroscope drift error. First, gyroscope is selected as a measuring unit because it can overcome the interference of external forces to measure dynamic angular speed. Second, an improved least squares support vector machine (LSSVM) is proposed for gyroscope drift-error compensation. The vector base learning method is used to reduce those less important support vectors, and the sparsity of LSSVM can be changed by adjusting the value of ¦È. Third, the quantum-behaved particle swarm optimization algorithm is introduced as the optimization method to optimize regularization parameter C and kernel parameter ¦Ã of LSSVM model because it has good optimization result and fast convergence speed. Fourth, the experiment platform and implementation process are illustrated in detail. Finally, the corresponding experimental results demonstrate that the proposed methodology could measure the dynamic tilt angle accurately.",IEEE
D. Kim; H. Choi; S. C. Seo,Parallel Implementation of SPHINCS+ With GPUs,2024,10.1109/TCSI.2024.3370802,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10461494,Journal,IEEE Transactions on Circuits and Systems I: Regular Papers,"SPHINCS+ was selected as one of NIST Post-Quantum Cryptography Digital Signature Algorithms (PQC-DSA). However, SPHINCS+ processes are slower compared to other PQC-DSA. When integrating it into protocols ( $e.g.$ , TLS and IPSec), optimization research from the server perspective becomes crucial. Therefore, we present highly parallel and optimized implementations of SPHINCS+ on various NVIDIA GPU architectures (Pascal, Turing, and Ampere). We discovered parts within the internal processes of SPHINCS+ that could be parallelized and optimized them ( $e.g.$ , leaf node generation and node merging process in MSS, subtree constructions in FORS, signature generation in WOTS+ and hypertree layer construction), leveraging the characteristics of GPU architecture ( $e.g.$ , warp-based execution and efficient memory access). As far as we know, this is the first SPHINCS+ implementations on GPUs. Our implementations achieve 44,391(resp. 24,997 and 11,401) signature generations, 725,118(resp. 354,309 and 100,168) key generations, and 285,680(resp. 155,800 and 106,280) verifications per second at security level 1(resp. 3 and 5) on RTX3090. Furthermore, on GTX1070, our SPHINCS+ shows an enhanced throughput of  $\times 2.10$  for signature generation,  $\times 1.03$  for key generation, and  $\times 9.86$  for verification at security level 1, surpassing the study conducted by Sun  $et ~al.$  (IEEE TPDS 2020) on the GTX1080 having 640 more cores than GTX1070.",IEEE
H. -b. Qiu; X. -y. Zhang; F. Deng; X. Gao,A camera self-calibration method based on parallel QPSO,2017,10.23919/ChiCC.2017.8029074,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8029074,Conference Paper,2017 36th Chinese Control Conference (CCC),"In the field of machine vision, camera calibration is a key technology. The self-calibration, one of camera calibration methods, is only based on the images to calculate the camera's intrinsic parameters. It has simple calibration process and strong applicability. Traditional self-calibration algorithm needs to calculate the epipole and fundamental matrix by solving the Kruppa equation, but the uncertainty of the epipole always leads to large error and long operation time. To improve the precision of camera calibration and reduce the time consumption, the parallel quantum particle swarm algorithm (QPSO) is introduced to solve the improved Kruppa equation. It can figure out the camera intrinsic parameters and transform the calculation of epipole into the adaptive value of the cost function. Compared with the ordinary particle swarm optimization algorithm (PSO), QPSO has less parameters, better robustness and faster convergence rate. By using a multi-core computer platform, its parallel processing has also combined with the characteristics of parallel computing which improves the calculation efficiency. Experimental results show that the proposed method is more accurate than ordinary PSO, and the program time consuming is significantly reduced.",IEEE
C. Wang; Q. Hu; H. Yao; S. Wang; Z. Pei,Deciphering a Million-Plus RSA Integer with Ultralow Local Field Coefficient h and Coupling Coefficient J of the Ising Model by D-Wave 2000Q,2024,10.26599/TST.2023.9010059,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10339820,Journal,Tsinghua Science and Technology,"This work is the first to determine that a real quantum computer (including generalized and specialized) can decipher million-scale RSA relying solely on quantum algorithms, showing the real attack potential of D-Wave machines. The influence of different column widths on RSA factorization results is studied on the basis of a multiplication table, and the optimal column method is determined by traversal experiments. The traversal experiment of integer factorization within 10 000 shows that the local field and coupling coefficients are 75%-93% lower than the research of Shanghai University in 2020 and more than 85% lower than that of Purdue University in 2018. Extremely low Ising model parameters are crucial to reducing the hardware requirements, prompting factoring 1 245 407 on the D-Wave 2000Q real machine. D-Wave advantage already has more than 5000 qubits and will be expanded to 7000 qubits during 2023¨C2024, with remarkable improvements in decoherence and topology. This machine is expected to promote the solution of large-scale combinatorial optimization problems. One of the contributions of this paper is the discussion of the long-term impact of D-Wave on the development of post-quantum cryptography standards.",IEEE
L. Mu; Z. Li; W. Xiao; R. Zhang; P. Wang; T. Liu; G. Min; K. Li,A Fine-Grained End-to-End Latency Optimization Framework for Wireless Collaborative Inference,2024,10.1109/JIOT.2023.3307820,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10227294,Journal,IEEE Internet of Things Journal,"Mobile devices are becoming increasingly capable of delivering intelligent services by leveraging deep learning architectures such as deep neural networks (DNNs). However, due to the compute-intensive nature of these tasks, mobile devices often struggle to handle them independently, leading to the exploration of collaborative inference as a promising solution for achieving low-latency mobile intelligence. Despite its potential benefits, many challenges need to be addressed in realizing the full potential of inference acceleration. This article presents a collaborative device-edge inference optimization framework as a promising solution to inference acceleration. The framework comprises fundamental modules, including the parameters generator (PG), accuracy predictor (AP), delay calculator (DC), and optimizer (OP), which are specifically designed to identify the optimal set of parameters for model compression, DNN partition, and feature compression. To illustrate its implementation, an example of a deep CNN network is introduced, and the collaborative inference latency optimization is formulated as a mixed-integer programming problem. The implementation of a specific algorithm instance using a quantum-inspired OP within the optimization framework is then presented. A multiple regression-based inference accuracy prediction model is proposed to maintain inference accuracy close to that of the original network while significantly reducing the time consumption during the offline phase. Through various simulation scenarios involving inference tasks of AlexNet and RegNet on CIFAR-10, incorporating diverse hardware computation specifications and wireless communication link conditions, the proposed framework demonstrates superior performance in terms of inference acceleration compared to the compared methods.",IEEE
A. D'Elia; A. Rettaroli; S. Tocci; D. Babusci; C. Barone; M. Beretta; B. Buonomo; F. Chiarello; N. Chikhi; D. Di Gioacchino; G. Felici; G. Filatrella; M. Fistul; L. Foggetta; C. Gatti; E. Il'ichev; C. Ligi; M. Lisitskiy; G. Maccarrone; F. Mattioli; G. Oelsner; S. Pagano; L. Piersanti; B. Ruggiero; G. Torrioli; A. Zagoskin,Stepping Closer to Pulsed Single Microwave Photon Detectors for Axions Search,2023,10.1109/TASC.2022.3218072,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9932667,Journal,IEEE Transactions on Applied Superconductivity,"Axions detection requires the ultimate sensitivity down to the single-photon limit. In the microwave region, this corresponds to energies in the yJ range. This extreme sensitivity has to be combined with an extremely low dark-count rate since the probability of axions conversion into microwave photons is supposed to be very low. To face this complicated task, we followed two promising approaches that both rely on the use of superconducting devices based on the Josephson effect. The first one is to use a single Josephson junction (JJ) as a switching detector (i.e., exploiting the superconducting to normal state transition in the presence of microwave photons). We designed a device composed of a coplanar waveguide terminated on a current-biased JJ. We tested its efficiency to pulsed (pulse duration 10 ns) microwave signals since this configuration is closer to an actual axions search experiment. We show how our device is able to reach detection capability of the order of ten photons with the frequency of 8 GHz. The second approach is based on an intrinsically quantum device formed by two resonators coupled only via a superconducting qubit network. This approach relies on quantum nondemolition measurements of the resonator photons. We show that by injecting radiofrequency power into the resonator, the frequency position of the resonant drop in the transmission coefficient (S21) can be modulated up to 4 MHz. We anticipate that, once optimized, both the devices have the potential to reach single-photon sensitivity.",IEEE
H. Lin; C. Tang,Intelligent Bus Operation Optimization by Integrating Cases and Data Driven Based on Business Chain and Enhanced Quantum Genetic Algorithm,2022,10.1109/TITS.2021.3121289,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9611161,Journal,IEEE Transactions on Intelligent Transportation Systems,"Intelligent public transport systems are a key direction for the study of intelligent transportation systems (ITSs), and they perform the following functions: location and tracking, aided navigation, dispatch and command, and dynamic information release; these systems also help travelers determine optimal routes. This paper mainly studies intelligent bus operation optimization by integrating cases and data from business chains, including the optimization of public transport vehicle scheduling according to the characteristics of vehicle scheduling, considers the interests of passengers and public transport companies, and adopts a true-value encoding method with the departure time as the variable goal optimization. In addition, this paper builds a model for the intelligent scheduling problem in public transport based on an enhanced quantum genetic algorithm (EQGA) to find the optimal timetable. This model sets the minimum waiting time cost of passengers and the maximum interests of public transport companies as the goals, restricts the departure interval and two adjacent intervals, and constrains the load factor of passengers. Moreover, based on the analysis of public transport travel characteristics and passenger flow data, this paper evaluates the efficiency of public transport operation, reasonably analyzes the utilization of public transport resources and the travel time of public transport passengers, and thoroughly studies the public transport operation system. This paper selects actual bus line data for empirical analysis, and the empirical results show that the proposed algorithm and model can meet the requirements of many aspects and provides good intelligence, applicability, and optimization.",IEEE
D. Virmani; M. Atheeq Sultan Ghori; N. Tyagi; R. P. Ambilwade; P. Rajesh Patil; M. K. Sharma,Machine Learning: The Driving Force Behind Intelligent Systems and Predictive Analytics,2024,10.1109/TQCEBT59414.2024.10545166,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10545166,Conference Paper,2024 International Conference on Trends in Quantum Computing and Emerging Business Technologies,"This technical analysis explores the profound impact of machine learning on intelligent systems and predictive analytics. It examines algorithmic fundamentals and explores models such as linear regression, support vector machines and neural networks, which are the pillars of supervised learning. The research explores practical applications in natural language processing, where advanced neural network architectures such as Transformers redefine, language understanding and computer vision using convolutional neural networks for image recognition and object recognition. In addition, the analysis covers the basic steps of data processing, including data cleaning, transformation and refinement, as well as feature design and model optimization. In addition, the research addresses the challenges of machine learning, emphasizing the importance of reducing bias and ethical considerations. The study concludes with a look into the future of machine learning, envisioning advances in quantum computing to solve complex problems, combinatorial learning for distributed data problems, and synthetic data generation as a solution to data protection problems. This comprehensive study provides an overview of the current state of machine learning, challenges and promising developments in intelligent system innovation and predictive analytics.",IEEE
M. Fortes; E. Comesa?a; G. Indalecio; J. Rodr¨ªguez; P. Otero; A. Garcia-Loureiro; M. Vetter,Design and Monte Carlo Simulation of a LED-Based Optic Coupler,2015,10.1109/UKSim.2015.44,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7576604,Conference Paper,2015 17th UKSim-AMSS International Conference on Modelling and Simulation (UKSim),"The design of a multi-wavelength light source used to measure the external quantum efficiency of solar cells is presented. This low-cost optic coupler is based on the concept of integrating sphere and on the use of LEDs pulsing at different frequencies followed by a Fourier transformation of the current generated in the device under test. To obtain an accurate simulation model of the optic coupler experimental measurements were employed. Two algorithms based on Monte Carlo raytracing were tested. The first one uses a uniform random selection of the director angle and, depending on it, assigns a power to simulated rays. The second approach samples this angle randomly from a given distribution and uses an equal power for all rays. Both methods were compared in terms of their repeatability and dispersion.",IEEE
P. Gao; X. Duan; B. Schmidt; W. Wan; J. Guo; W. Zhang; L. Gan; H. Fu; W. Xue; W. Liu; G. Yang,Redesign and Accelerate the AIREBO Bond-Order Potential on the New Sunway Supercomputer,2023,10.1109/TPDS.2023.3321927,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10271720,Journal,IEEE Transactions on Parallel and Distributed Systems,"Molecular dynamics (MD) is one of the most crucial computer simulation methods for understanding real-world processes at the atomic level. Reactive potentials based on the bond order concept have the ability to model dynamic bond breaking and formation with close to quantum mechanical (QM) precision without actually requiring expensive QM calculations. In this article, we focus on the adaptive intermolecular reactive empirical bond-order (AIREBO) potential in LAMMPS for the simulation of carbon and hydrocarbon systems on the new Sunway supercomputer. To achieve scalable performance, we propose a parallel two-level building scheme and periodic buffering strategy for the tailored data design to explore data locality and data reuse. Furthermore, we design two optimized nearest-neighbor access algorithms: the redistribution of accumulated coefficients algorithm and the double-end search connectivity algorithm. Finally, we implement parallel force computation with an AoS data layout and hardware/software co-cache. In addition, we have designed a low-overhead atomic operation-based load balancing method and vectorization. The overall performance of AIREBO achieves a speedup of nearly $20\times$20¡Á on a single core group (CG), and more than $5\times$5¡Á and $4\times$4¡Á over an Intel Xeon E5 2680 v3 core and an Intel Xeon Gold 6138 core, respectively. Compared with the Intel accelerator package in LAMMPS, our performance further achieves $3.0\times$3.0¡Á of an Intel Xeon E5 2680 v3 core and is better than that of an Intel Xeon Gold 6138 core. We complete the validation of the results in no more than 20.5 hours on a single node with 2,000,000 running steps (i.e., 1 ns). Our experiments show that the simulation of 2,139,095,040 atoms on 798,720 ((1MPE+64CPEs) ¡Á 12,288 processes) cores exhibits a parallel efficiency of 88% under weak scaling.","IEEE, Web of Science"
Z. Wei; H. Wang; Y. Chen; S. Huang; Z. Zhang; Z. Yu; Q. Chang,Electromagnetic transient simulation of induction machine based on QSS algorithm,2015,10.1109/APPEEC.2015.7380954,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7380954,Conference Paper,2015 IEEE PES Asia-Pacific Power and Energy Engineering Conference (APPEEC),"This paper explores the feasibility of transient simulations power system based on discrete event system (DEVS), where the Quantized State System (QSS) algorithm is used for numerical integrations. An induction machine model based on DEVS formalism is built up. Moreover, to guarantee the efficiency and accuracy of transient simulations based on QSS, an algorithm for optimal selection of quantum is derived. Test results with comparisons with traditional EMTP simulations are presented, which also validate the proposed simulation method.",IEEE
L. C. M¨¹ller; C. J. Fourie,Automated State Machine and Timing Characteristic Extraction for RSFQ Circuits,2014,10.1109/TASC.2013.2284834,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6651715,Journal,IEEE Transactions on Applied Superconductivity,"We present a heuristic for the automated extraction of state machine representations of rapid single-flux-quantum (RSFQ) digital logic circuits given a circuit SPICE representation. Furthermore, this heuristic uses the SPICE netlist to extract timing characteristics for the creation of a hardware description language (HDL) implementation of the circuit. This facilitates RSFQ logic design at an HDL level rather than a Josephson junction level. The state machine extraction method can be also used for the automatic creation of test benches for circuit yield analysis, as well as optimization algorithms. An example of the automatic extraction of the state machine representation, timing characterization, and HDL implementation is demonstrated for a complex RSFQ cell.",IEEE
Q. Luo; X. Fang; Y. Sun; J. Ai; C. Yang,Self-Learning Hot Data Prediction: Where Echo State Network Meets NAND Flash Memories,2020,10.1109/TCSI.2019.2960015,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8949460,Journal,IEEE Transactions on Circuits and Systems I: Regular Papers,"Well understanding the access behavior of hot data is significant for NAND flash memory due to its crucial impact on the efficiency of garbage collection (GC) and wear leveling (WL), which respectively dominate the performance and life span of SSD. Generally, both GC and WL rely greatly on the recognition accuracy of hot data identification (HDI). However, in this paper, the first time we propose a novel concept of hot data prediction (HDP), where the conventional HDI becomes unnecessary. First, we develop a hybrid optimized echo state network (HOESN), where sufficiently unbiased and continuously shrunk output weights are learnt by a sparse regression based on L2 and L1/2 regularization. Second, quantum-behaved particle swarm optimization (QPSO) is employed to compute reservoir parameters (i.e., global scaling factor, reservoir size, scaling coefficient and sparsity degree) for further improving prediction accuracy and reliability. Third, in the test on a chaotic benchmark (Rossler), the HOESN performs better than those of six recent state-of-the-art methods. Finally, simulation results about six typical metrics tested on five real disk workloads and on-chip experiment outcomes verified from an actual SSD prototype indicate that our HOESN-based HDP can reliably promote the access performance and endurance of NAND flash memories.",IEEE
P. Chiavassa; A. Marchesin; I. Pedone; M. F. Dacrema; P. Cremonesi,Virtual Network Function Embedding with Quantum Annealing,2022,10.1109/QCE53715.2022.00048,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9951291,Conference Paper,2022 IEEE International Conference on Quantum Computing and Engineering (QCE),"In recent years, the growing number of devices connected to the internet led network operators to continuously expand their own infrastructures. In order to simplify this scaling process, the research community is currently investigating the opportunity to move the complexity from a hardware to a software domain, through the introduction of a new paradigm, called Network Functions Virtualisation (NFV). It considers standard hardware platforms where many virtual instances are allocated to implement specific network services. However, despite the theoretical benefits, the mapping of the different virtual instances to the available physical resources represents a complex problem, difficult to be solved classically. The present work proposes a Quadratic Unconstrained Binary Optimisation (QUBO) formulation of this embedding process, exploring the implementation possibilities on D-Wave¡¯s Quantum Annealers. Many test cases, with realistic constraints, have been considered to validate and characterise the potential of the model, and the promising results achieved are discussed throughout the document. The technical discussion is enriched with comparisons of the results obtained through heuristic algorithms, highlighting the strengths and the limitations in the resolution of the QUBO formulation proposed on current quantum machines.",IEEE
K. Mayes,Performance Evaluation and Optimisation for Kyber on the MULTOS IoT Trust-Anchor,2020,10.1109/SmartIoT49966.2020.00010,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9191980,Conference Paper,2020 IEEE International Conference on Smart Internet of Things (SmartIoT),"The Internet of Things (IoT) may be considered as a distributed, critical infrastructure, consisting of billions of devices, many of which having limited processing capability. However, the security of IoT must not be compromised by these limitations, and defenses need to protect against today's threats, and those predicted for the future. This requires protection against implementation attacks, as well as the ability to load, replace and run, best-practice cryptographic algorithms. Post-Quantum cryptographic algorithms are attracting great interest, and NIST standardization has a competition to find the best. Prior research demonstrated that a Learning With Errors candidate algorithm could be implemented on a smart card chip, however this was a low-level implementation, and not representative of loading the algorithm onto a secured IoT chip platform. In this paper we present analysis from a practical implementation of the Kyber768 CPAPKE public key encryption component on a MULTOS IoT Trust-Anchor chip. The investigation considered memory and speed requirements, and optimizations, and compared the NTT transform version of Kyber, presented in Round 1 of the NIST competition, with the Kroenecker multiplier technique that exploits a hardware crypto-coprocessor. The work began with a generic multi-round multiplier approach, which was then improved using a novel modification of the input data, allowing a built-in modular multiply function to be used, significantly increasing the speed of a multiplication round, and doubling the useable size of the hardware multiplier.",IEEE
P. Acevedo-Rueda; C. Camacho-Parra; G. Osma-Pinto; R. Rodr¨ªguez-Vel¨¢squez,Localization of Energy Sources and Distribution System Sizing in a Low Voltage Isolated Microgrid,2019,10.1109/SEST.2019.8848993,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8848993,Conference Paper,2019 International Conference on Smart Energy Systems and Technologies (SEST),"In this paper, a methodology that allows the location of sources and energy storage together with the sizing of the distribution network is presented. This methodology uses a Mixed integer nonlinear programming (MINLP), which is solved using algorithms: Quantum behaved Particle Swarm Optimization (QPSO) and genetic algorithms (GA) with Matlab, and with the solvers BARON, BONMIN, and LINDO of GAMS, in order to find the best possible solution and with the least computation time. And the proposed methodology is applied in a non-interconnected area, located in the rural area of the municipality of Cimitarra Colombia.",IEEE
L. Zhang; Z. Xing; W. Wang; Z. Zhang,Fiber coupled system design for quantum secure measurement and control communication,2023,10.1109/ICOIM60566.2023.10491561,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10491561,Conference Paper,2023 2nd International Conference on Optical Imaging and Measurement (ICOIM),"A large field of view coupling optical system was designed and optimized using PW algorithm to address the high fidelity space single mode fiber coupling problem in quantum secure communication with large field of view angle reception. A coupling system consisting of four spherical mirrors was designed using Zemax optical design software. After aberration test, the coupling system can realize important roles in the fields of unmanned system quantum communication, optical information processing and fiber optic imaging.",IEEE
M. Beyki; J. Pawlak; R. Patzke; F. Renz,Advanced Approaches in M?ssbauer Drive Modelling and Controller Design Reducing System Order and Increasing Robustness,2024,10.1109/CoDIT62066.2024.10708439,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10708439,Conference Paper,"2024 10th International Conference on Control, Decision and Information Technologies (CoDIT)","The M?ssbauer spectroscopy or also known as Gamma ray resonance spectroscopy based on the M?ssbauer effect has not only proven itself in the form of the MIMOS II (miniaturised M?ssbauer spectrometer) as a reliable measuring instrument for planetary exploration with a service life of several years on Mars, but also offers a wide range of popular applications on Earth with many applications in industry, science, art and much more. An important component of the M?ssbauer spectrometer is the M?ssbauer drive, which allows, utilizing the Doppler effect, to vary the amount of energy of the emitted gamma quanta so that it corresponds to the resonance energy and energetically excites the irradiated nuclei. This paper deals with drive modelling and control in M?ssbauer spectroscopy. For the first time, a single-mass model is used instead of the previously common three-mass model, as in this context only the momentum mass of the drive is the focus of the regulation. After modeling and determining important characteristics such as natural frequency and damping behavior of the unregulated system, three control algorithms are developed and compared. First, there is a PID controller design. Second, there is a feasible heuristic filtering method with subsequent normalization. Third, there is a simulated state-space model with the associated state feedback. All approaches yield good results and can be further evaluated in a practical environment. The heuristic control concept fundamentally revises common design approaches and opens up a broad spectrum of research. The controller design provides for a combination of signal-smoothing and signal-amplifying low-pass filtering in combination with dynamic input vector normalisation. This achieves the desired frequency and amplitude response of and 0.3 mm and optimises the dynamics for real laboratory use.",IEEE
R. Paludo; L. Sousa,Number Theoretic Transform Architecture suitable to Lattice-based Fully-Homomorphic Encryption,2021,10.1109/ASAP52443.2021.00031,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9516650,Conference Paper,"2021 IEEE 32nd International Conference on Application-specific Systems, Architectures and Processors (ASAP)","The Number Theoretic Transform (NTT) plays a central role for supporting high-performance polynomial multiplication on Post-Quantum Cryptography (PQC) and Fully-Homomorphic Encryption (FHE). This paper proposes a novel Montgomery-based butterfly to efficiently implement NTTs on FPGAs. This proposal is supported on prime moduli suitable for FHE, which minimizes the requirements to allow the speedup of the computation of the butterfly. A search algorithm is presented to select these moduli, while flexibility is a target in all parameters making the proposed architectures well-suited for FHE and PQC schemes. We experimentally evaluate the effectiveness of the novel butterfly-core on a Xilinx Virtex-7 device. The results show reductions up to 19%, 41%, 37%, and 67% in the number of lookup tables, slices, flip-flops, and Digital Signal Processors (DSPs), respectively, in comparison to the related state of the art. By integrating the proposed butterflies in a complete NTT accelerator, a speedup of up to 1.42 is achieved, while less than half of the number of DSPs are required, when compared to the other proposals. Moreover, the integration of the proposed accelerators to design FHE-based processors is discussed.",IEEE
Y. Zhao; V. C. M. Leung; C. Zhu; H. Gao; Z. Chen; H. Ji,Energy-Efficient Sub-Carrier and Power Allocation in Cloud-Based Cellular Network With Ambient RF Energy Harvesting,2017,10.1109/ACCESS.2017.2667678,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7850971,Journal,IEEE Access,"Due to the limited battery energy of mobile devices, the issue of energy-efficient resource allocation has drawn significant interest in the mobile cloud computing area. Simultaneous wireless information and power transfer (SWIPT) is an innovative way to provide electrical energy for mobile devices. Extensive research on the resource allocation problem is conducted in SWIPT systems. However, most previous works mainly focus on energy harvesting over a relatively narrow frequency range. Due to small amounts of energy harvested by the users, the practical implementations are usually limited to low power devices. In this paper, an energy-efficient uplink resource allocation problem is investigated in a cloud-based cellular network with ambient radio frequency (RF) energy harvesting. In order to obtain sufficient energy, a broadband rectenna is equipped at the user device to harvest ambient RF energy over six frequency bands at the same time. From the viewpoint of service arrival in the ambient transmitter, a new energy arrival model is presented. The joint problem of sub-carrier and power allocation is formulated as a mixed-integer nonlinear programming problem. The objective is to maximize the energy efficiency while satisfying the energy consumption constraint and the total data rate requirement. In order to reduce the computational complexity, a suboptimal solution to the optimization problem is derived by employing a quantum-behaved particle swarm optimization (QPSO) algorithm. Simulation results show that more energy can be harvested by the user devices compared with narrow band SWIFT systems, and the QPSO method achieves higher energy efficiency than a conventional particle swarm optimization approach.",IEEE
N. Gupta; A. Jati; A. Chattopadhyay,CRYSTALS-Dilithium on RISC-V Processor: Lightweight Secure Boot Using Post-Quantum Digital Signature,2023,10.1109/ICCAD57390.2023.10323688,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10323688,Conference Paper,2023 IEEE/ACM International Conference on Computer Aided Design (ICCAD),"With the ongoing efforts for transitioning towards post-quantum security, NIST has recently selected the digital signature algorithm CRYSTALS-Dilithium for standardization. In this work, we demonstrate the first Dilithium based hardware accelerated secure boot architecture developed around Ariane, an open-source RISC- V core. By utilizing a compact design with novel verification engine, a secure boot flow is implemented with only 3.48ms runtime overhead compared to normal boot, while requiring 10.4K LUTs and 5.7K FFs on an FPGA. Compared to the state-of-the-art we achieve a reduction of 3.42¡Á and 7.88 ¡Á for LUTs and FFs respectively. Also, the design when realized in 65nm ASIC requires only 125 kGE and 6.3 mW power at 100 MHz. Further, as secure boot is one of the critical processes and the security of the whole system depends on it, we implemented hardware fault countermeasures and evaluated their effectiveness in preventing secure boot bypass.",IEEE
S. Yang; D. Liu; A. Hu; A. Li; J. Zhang; X. Li; J. Lu; C. Mo,An Instruction-configurable Post-quantum Cryptographic Processor towards NTRU,2022,10.1109/AsianHOST56390.2022.10022178,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10022178,Conference Paper,2022 Asian Hardware Oriented Security and Trust Symposium (AsianHOST),"Post-quantum cryptography (PQC) is proposed to resist the attack of quantum computer. Among various PQC schemes, lattice-based cryptography depended on learning with errors (LWE) problem has attracted much attention. As one of the lattice-based PQC schemes, number theory research unit (NTRU) algorithm is flexible, simple and fast. In this paper, we propose a high-performance cryptographic processor towards NTRU. In the processor, we optimize instruction set architecture, which also saves memories. Three-level Karatsuba method is utilized to accelerate polynomial multiplication, and the computing time is reduced by 10x. Fixed and custom instructions are used to control the whole data path, with flexibility and high efficiency. Compared to other FPGA implementations, the results show this design performs the highest operating frequency of 200MHz, only consumes 28k look-up tables (LUTs). Besides, it has the shortest time of encryption, decryption and the best area-time product (ATP), which is 1.4x better than state-of-the-art work.",IEEE
S. Mondal; S. Patkar; T. K. Pal,A configurable and efficient implementation of Number Theoretic Transform (NTT) for lattice based Post-Quantum-Cryptography,2022,10.1109/I2CT54291.2022.9824426,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9824426,Conference Paper,2022 IEEE 7th International conference for Convergence in Technology (I2CT),"Advancement in the quantum computer has imposed huge threat to modern cryptography techniques. Post quantum cryptography (PQC) based on lattice structure provides quantum-resistance and facilitates efficient hardware implementation compared to other solutions. Ring learning with errors (RLWE) is a basic primitive of lattice-based cryptosystem, defined on a polynomial quotient ring with time and resource consuming multiplication operations. Number Theoretic Transform (NTT) is an extensively used polynomial multiplier to achieve AreaX-Time trade-off. In this paper, we proposed a fully configurable NTT which supports different RLWE and design parameters to produce highly optimized hardware. Our design can be customized for higher throughput or lightweight applications. The proposed high performance design achieves 9X improvement in execution time compared to High-Level synthesis, pure software and various hardware implementations. The result shows that our lightweight architecture consumes 16X lesser resource than other FPGA solutions targeted for deeply embedded systems. The proposed design is experimented in the NewHope PQC key exchange application and the execution time is enhanced by 37% at 133 MHz clock frequency compared to recent implementations.",IEEE
A. Borovik; A. Kuleshov; T. T. Trung,Verification of device model parameters for nanoscale MOSFETs,2015,10.1109/ATC.2015.7388382,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7388382,Conference Paper,2015 International Conference on Advanced Technologies for Communications (ATC),"A new approach to nanoscale MOSFETs electrical characteristics calculating, the essence of which is the use of adjustment factors, as well as parameter values of classic driftdiffusion models, which would effectively take into account the quantum-mechanical transport mechanisms is proposed. A modified direct search method of drift-diffusion model optimization for MOSFET with a 90 nm channel length is developed and used.",IEEE
M. J. Kannwischer; P. Schwabe; D. Stebila; T. Wiggers,Improving Software Quality in Cryptography Standardization Projects,2022,10.1109/EuroSPW55150.2022.00010,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9799340,Conference Paper,2022 IEEE European Symposium on Security and Privacy Workshops (EuroS&PW),"The NIST post-quantum cryptography (PQC) standardization project is probably the largest and most ambitious cryptography standardization effort to date, and as such it makes an excellent case study of cryptography standardization projects. It is expected that with the end of round 3 in early 2022, NIST will announce the first set of primitives to advance to standardization, so it seems like a good time to look back and see what lessons can be learned from this effort. In this paper, we take a look at one specific aspect of the NIST PQC project: software implementations. We observe that many implementations included as a mandatory part of the submission packages were of poor quality and ignored decades-old standard techniques from software engineering to guarantee a certain baseline quality level. As a consequence, it was not possible to readily use those implementations in experiments for post-quantum protocol migration and software optimization efforts without first spending a significant amount of time to clean up the submitted reference implementations. We do not mean to criticize cryptographers who submitted proposals, including software implementations, to NIST PQC: after all, it cannot reasonably be expected from every cryptographer to also have expertise in software engineering. Instead, we suggest how standardization bodies like NIST can improve the software-submission process in future efforts to avoid such issues with submitted software. More specifically, we present PQClean, an extensive (continuous-integration) testing framework for PQC software, which now also contains ¡°clean¡± implementations of the NIST round 3 candidate schemes. We argue that the availability of such a framework-either in an online continuous-integration setup, or just as an offline testing system-long before the submission deadline would have resulted in much better implementations included in NIST PQC submissions and overall would have saved the community and probably also NIST a lot of time and effort.",IEEE
Y. Zhu; W. Zhu; C. Chen; M. Zhu; Z. Li; S. Wei; L. Liu,Mckeycutter: A High-throughput Key Generator of Classic McEliece on Hardware,2023,10.1109/DAC56929.2023.10247918,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10247918,Conference Paper,2023 60th ACM/IEEE Design Automation Conference (DAC),"Classic McEliece is a code-based quantum-resistant public-key scheme characterized with relative high encapsulation/decapsulation speed and small ciphertexts, with an in-depth analysis on its security. However, slow key generation with large public key size make it hard for wider applications. Based on this observation, Mckeycutter, a high-throughput key generator in hardware, is proposed to accelerate the key generation in Classic McEliece based on algorithm-hardware co-design. Meanwhile the storage overhead caused by large-size keys is also minimized. First, compact large-size GF(2) Gauss elimination method is presented by adopting naive processing array and memory-friendly scheduling strategy. Second, an optimized constant-time hardware sorter is proposed to support regular memory accesses with less comparators and storage. Third, algorithmlevel pipeline is enabled for high-throughput processing, allowing for concurrent key generations. Our FPGA implementation results achieve around 4¡Á improvements in throughput with 9~14¡Á less memory-time product compared with the existing FPGA solutions.",IEEE
Z. Lin; M. Li; C. Fang; W. Wu; C. Wang; Y. Tang,Parameter Identification Method for Composite Load Based on Enhanced Quantum Particle Swarm Optimization Algorithm,2023,10.1109/CEECT59667.2023.10420772,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10420772,Conference Paper,2023 5th International Conference on Electrical Engineering and Control Technologies (CEECT),"Traditional load model is not able to reflect the actual transient characteristics of loads since distributed energy resources (DER) are gradually penetrated into the networks. Composite load model with DER is developed for simulation, but it is difficult for the existing methods to identify the model parameters accurately because the algorithms easily plunge into the local optimum in the expansive model parameter space. To overcome the issue, a parameter identification method based on the enhanced quantum particle swarm optimization (EQPSO) algorithm is developed. Firstly, a memory label that evaluates the quality of particle is introduced into the iteration of algorithm to control the mutation probability of particles. Then an EQPSO based identification strategy is presented and investigated by the PSASP-MATLAB joint simulation. Simulation results show the iterations are prevented from plunging into local optimum by the proposed method, which improves the global exploration ability of algorithm and further increases the accuracy of parameter identification for composite load model.",IEEE
E. Enrico; C. Bonavolont¨¤; G. Brida; G. Coda; E. Il'ichev; L. Fasolo; M. Fistoul; A. Meda; L. Oberto; G. Oelsner; M. Rajteri; B. Ruggiero; P. Silvestrini; M. Valentino; P. Vanacore; M. Lisitskiy,Superconducting Qubit Network as a Single Microwave Photon Detector for Galactic Axion Search,2024,10.1109/TASC.2023.3340640,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10349924,Journal,IEEE Transactions on Applied Superconductivity,"Experimental search of galactic axions requires detection of single photons in the microwave range. We work on a novel approach to detect single microwave photons based on a coherent collective response of quantum states occurring in a superconducting qubit network (SQN) embedded in a low-dissipative superconducting resonator. We propose a two resonators detector configuration with two parallel resonators without common part and with separated input and output terminals. The device consists of a low-dissipative resonator with embedded SQN in which microwave photons arrive (¡°signal resonator¡±), and a transmission line for measuring the frequency dependent transmission coefficient demonstrating resonant drops at the qubit frequencies (¡°readout resonator¡±). In comparison with T-type three terminal device recently proposed and investigated by us, the device with two resonators with separated input and output terminals doesn't contain common part of both resonators and exclude an unwanted noise from measurement readout circuits to the signal resonator. A layout of two resonators four terminal SQN detectors containing 5 flux qubits weakly coupled to a low-dissipative signal and readout resonator was developed and optimized. The samples were fabricated by Manhattan Al-based technology with Nb resonator circuits. The SQN detector was experimentally tested in terms of microwave measurements of scattering parameters of both resonators and crosstalk properties. Comparison of experimental data with results of the simulations permits one to conclude that the electromagnetic conditions of the fundamental resonant peak of 8.5 GHz of both resonators aren't affected by the crosstalk phenomenon and their performances provided by the design remain not altered for correct device operation.",IEEE
W. Ling; D. Wanlin; W. Jinfeng; Z. Yuanzhe; Y. Kai; L. Ning,Optimal configuration method of distribution network harmonic estimation based on quantum genetic algorithm,2024,10.1109/AEEES61147.2024.10544857,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10544857,Conference Paper,2024 6th Asia Energy and Electrical Engineering Symposium (AEEES),"With the continuous development of the ""double-high"" power system, a large number of power electronic devices are continuously connected to the distribution network. The harmonic pollution of the distribution network presents the characteristics of high density, decentralization and whole network. Since the distribution network has a radial weak topology, if the traditional method is used to estimate the harmonic state of the distribution network, the number and cost of power quality monitoring devices required will be huge. In order to ensure the accurate estimation of the harmonic state of the whole network and reduce the number of harmonic monitoring devices, this paper proposes an optimal distribution method for harmonic estimation of distribution network based on quantum genetic algorithm. Firstly, the probabilistic harmonic power flow calculation model is established and the probability distribution of each harmonic state is obtained, and the probability of distribution network harmonics is evaluated. Secondly, the calculation results of probabilistic harmonic power flow are corrected according to the data of a small number of harmonic monitoring points to ensure the accuracy of harmonic estimation. Thirdly, based on the quantum genetic algorithm, the optimal distribution results of harmonic monitoring are obtained with the goal of minimizing the average error of harmonic voltage estimation at all nodes of the distribution network. Finally, the MATLAB software is used to simulate the actual distribution network, and the effectiveness and superiority of the proposed method are verified.",IEEE
M. Zhou; Y. Nam; X. Wang; Y. Lee; C. Wilkerson; R. Kumar; S. Taneja; S. Mathew; R. Cammarota; T. Rosing,UFC: A Unified Accelerator for Fully Homomorphic Encryption,2024,10.1109/MICRO61859.2024.00034,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10764649,Conference Paper,2024 57th IEEE/ACM International Symposium on Microarchitecture (MICRO),"Fully homomorphic encryption (FHE) is crucial for post-quantum privacy-preserving computing. Researchers have proposed various FHE schemes that excel at different encrypted computations, such as single-instruction multiple-data (SIMD) arithmetic or arbitrary single-data functions. Hybrid-scheme FHE, which exploits appropriate schemes for specific tasks, is essential for real-world applications requiring optimal performance and accuracy. However, existing FHE accelerators only adopt scheme-specific custom designs, leading to inefficiency or lack of capability to support applications in hybrid FHE settings. In this work, we propose a Unified FHE aCcelerator (UFC) that provides better performance and cost-efficiency than prior scheme-specific accelerators on hybrid FHE applications. Our design process involves a comprehensive analysis of processing flows to abstract the primitives covering all operations in hybrid FHE applications. The UFC architecture primarily comprises hardware function units for these primitives, diverging from the deeply pipelined units in previous designs. This approach enables high hardware utilization across different FHE schemes. Further-more, we propose several algorithm-hardware co-optimizations to minimize the hardware cost of supporting various data shuffling patterns in FHE. This enables high-throughput implementation of function units that provide good cost efficiency. We also propose several compiler-level optimizations to achieve high hardware utilization of the unified architecture for computing FHE data in various algorithmic parameter settings. We evaluate the performance of UFC on different FHE programs, including scheme-specific and hybrid-scheme workloads. Our experiments show that UFC provides up to 6.0 ¡Á speedup and 1.6 ¡Á delay-energy-area efficiency improvement over state-of-the-art FHE accelerators.",IEEE
N. F. R. Annafianto; M. V. Jabir; I. A. Burenkov; H. F. Ugurdag; A. Battou; S. V. Polyakov,FPGA Implementation of a Low Latency and High SFDR Direct Digital Synthesizer for Resource-Efficient Quantum-Enhanced Communication,2020,10.1109/EWDTS50664.2020.9225029,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9225029,Conference Paper,2020 IEEE East-West Design & Test Symposium (EWDTS),"A Direct Digital Synthesizer (DDS) generates a sinusoidal signal, which is a significant component of many communication systems using modulation schemes. A CORDIC algorithm offers minimum memory requirements compared to look-up-based methods and low latency. The latency depends on the number of iterations, which is determined by the number of angles in the rotation set. However, it is necessary to maintain high spectral purity to optimize the overall system performance. To optimize the opportunity of quantum measurement, low latency and a high spectral purity sine wave generator is essential. The implementation of this design generates output with 64% latency reduction compared to that of the conventional CORDIC design and 72.2 dB SFDR value.",IEEE
D. B. Tan; S. Ping; J. Cong,Depth-Optimal Addressing of 2D Qubit Array with 1D Controls Based on Exact Binary Matrix Factorization,2024,10.23919/DATE58400.2024.10546763,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10546763,Conference Paper,"2024 Design, Automation & Test in Europe Conference & Exhibition (DATE)","Reducing control complexity is essential for achieving large-scale quantum computing, particularly on platforms operating in cryogenic environments. Wiring each qubit to a room-temperature control poses a challenge, as this approach would surpass the thermal budget in the foreseeable future. An essential tradeoff becomes evident: reducing control knobs compromises the ability to independently address each qubit. Recent progress in neutral atom-based platforms suggests that rectangular addressing may strike a balance between control granularity and flexibility for $2\mathrm{D}$ qubit arrays. This scheme allows addressing qubits on the intersections of a set of rows and columns each time. While quadratically reducing controls, it may necessitate more depth. We formulate the depth-optimal rectangular addressing problem as exact binary matrix factorization, an NP-hard problem also appearing in communication complexity and combinatorial optimization. We introduce a satisfiability modulo theories-based solver for this problem, and a heuristic, row packing, performing close to the optimal solver on various benchmarks. Furthermore, we discuss rectangular addressing in the context of fault-tolerant quantum computing, leveraging a natural two-level structure.",IEEE
E. Karabulut; A. Aysu,RANTT: A RISC-V Architecture Extension for the Number Theoretic Transform,2020,10.1109/FPL50879.2020.00016,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9221619,Conference Paper,2020 30th International Conference on Field-Programmable Logic and Applications (FPL),"Lattice-based cryptography has been growing in demand due to their quantum attack resiliency. Polynomial multiplication is a major computational bottleneck of lattice cryptosystems. To address the challenge, lattice-based cryptosystems use the Number Theoretic Transform (NTT). Although NTT reduces complexity, it is still a well-known computational bottleneck. At the same time, NTT arithmetic needs vary for different algorithms, motivating flexible solutions. Although there are prior hardware and software NTT designs, they do not simultaneously offer flexibility and efficiency. This work provides an efficient and flexible NTT solution through domain-specific architectural support on RISC-V. Rather than using instruction-set extensions with compiler modifications or loosely coupling a RISC-V core with an NTT co-processor, our proposal uses application-specific dynamic instruction scheduling, memory dependence prediction, and datapath optimizations. This allows achieving a direct translation of C code to optimized NTT executions. We demonstrate the flexibility of our approach by implementing the NTT used in several lattice-based cryptography protocols: NewHope, qTESLA, CRYSTALS-Kyber, CRYSTALS-Dilithium, and Falcon. The results on the FPGA technology show that the proposed design is respectively 6x, 40x, and 3x more efficient than the baseline solution, Berkeley Out-of-Order Machine, and a prior HW/SW co-design, while providing the needed flexibility.",IEEE
Y. Kim; S. Yoon; S. C. Seo,Vectorized Implementation of Kyber and Dilithium on 32-bit Cortex-A Series,2024,10.1109/ACCESS.2024.3435451,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10614163,Journal,IEEE Access,"In the field of Post-Quantum Cryptography (PQC), which typically demands more memory and relatively lower performance compared to Elliptic-Curve Cryptography (ECC), recent studies have been actively focused on neon-based parallel implementations for the 64-bit ARMv8-based Cortex-A series. However, research into implementing PQC on the widely adopted 32-bit ARMv7-based Cortex-A series remains insufficient. In this paper, we present the first instance of optimized implementation of Crystals-Kyber and Crystals-Dilithium, a Key Encapsulation Mechanism (KEM) and a Digital Signature Algorithm (DSA) selected by National Institute of Standards and Technology (NIST) for standardization, on a 32-bit ARMv7-based Cortex-A device. For computational efficiency, we finely tune widely used signed Montgomery multiplication and Barrett multiplication methods to take full advantage of the computational capabilities of NEON engine, a kind of Single-Instruction-Multiple-Data (SIMD) extension, available on the target device. Particularly, we propose improvements to internal parameters and operational techniques in Montgomery and Barrett arithmetic to preserve parallel processing logic. Moreover, we present an optimized merging technique tailored for the NEON engine of ARMv7, aimed at accelerating Number Theoretic Transform (NTT)-based polynomial multiplication. Compared to the state-of-the-art codes of PQM4, our approach achieves significant performance enhancements in Kyber and Dilithium: 62% (54%) for NTT, 50% (62%) for Point multiplication, and 56% (55%) for inverse NTT (NTT-1). Regarding the complete schemes, our implementations outperform the vectorized reference implementations, showing improvements of 50% (14%) in Key Generation, 43% (41%) in Encapsulation (Signing), and 52% (21%) in Decapsulation (Verifying) processes for Kyber768 (Dilithium3), respectively.","IEEE, Web of Science"
C. A. Roma; C. -E. A. Tai; M. A. Hasan,Energy Efficiency Analysis of Post-Quantum Cryptographic Algorithms,2021,10.1109/ACCESS.2021.3077843,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9424003,Journal,IEEE Access,"Classical cryptographic schemes in use today are based on the difficulty of certain number theoretic problems. Security is guaranteed by the fact that the computational work required to break the core mechanisms of these schemes on a conventional computer is infeasible; however, the difficulty of these problems would not withstand the computational power of a large-scale quantum computer. To this end, the post-quantum cryptography (PQC) standardization process initiated by the National Institute of Standards and Technology (NIST) is well underway. In addition to the evaluation criteria provided by NIST, the energy consumption of these candidate algorithms is also an important criterion to consider due to the use of battery-operated devices, high-performance computing environments where energy costs are critical, as well as in the interest of green computing. In this paper, the energy consumption of PQC candidates is evaluated on an Intel Core i7-6700 CPU using PAPI, the Performance API. The energy measurements are categorized based on their proposed security level and cryptographic functionality. The results are then further subdivided based on the underlying mechanism used in order to identify the most energy-efficient schemes. Lastly, IgProf is used to identify the most energy-consuming subroutines within a select number of submissions to highlight potential areas for optimization.","IEEE, Web of Science"
R. Behnia; M. O. Ozmen; A. A. Yavuz,Lattice-Based Public Key Searchable Encryption from Experimental Perspectives,2020,10.1109/TDSC.2018.2867462,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8450619,Journal,IEEE Transactions on Dependable and Secure Computing,"Public key Encryption with Keyword Search (PEKS) aims in mitigating the impacts of data privacy versus utilization dilemma by allowing any user in the system to send encrypted files to the server to be searched by a receiver. The receiver can retrieve the encrypted files containing specific keywords by providing the corresponding trapdoors of these keywords to the server. Despite their merits, the existing PEKS schemes introduce a high end-to-end delay that may hinder their adoption in practice. Moreover, they do not scale well for large security parameters and provide no post-quantum security promises. In this paper, we propose two novel lattice-based PEKS schemes that offer a high computational efficiency along with better security assurances than that of the existing alternatives. Specifically, our NTRU-PEKS scheme achieves 18 times lower end-to-end delay than the most efficient pairing-based alternatives. Our LWE-PEKS offers provable security in the standard model with a reduction to the worst-case lattice problems. We fully implemented our NTRU-PEKS scheme and benchmarked its performance as deployed on Amazon Web Services cloud infrastructures.",IEEE
Y. Zuo; W. Zheng; X. Zhang; J. Wei; Y. Zhang,Research on Power Grid Investment Decision-Making Model Based on Quantum Genetic Algorithm,2024,10.1109/EEPS63402.2024.10804533,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10804533,Conference Paper,2024 4th International Conference on Energy Engineering and Power Systems (EEPS),"In the context of green, clean, low-carbon and environmentally friendly power systems, the planning of new power systems is an important lever for future development and transformation. This paper comprehensively considers the development of new energy, and determines the scale of power grid investment based on investment capacity, investment demand, nuclear price investment and electricity efficiency. Considering the investment demand level, financial efficiency indicators, and core business efficiency indicators of each unit, investment allocation is determined to determine the investment scale of each region. Then, an objective function and constraint conditions for project portfolio optimization are constructed, and solved based on quantum genetic algorithm to optimize the power grid investment strategy and improve the efficiency and efficiency of power grid investment. According to calculations, X Company's investment scale is 17.078 billion yuan, and the difference between the investment structure model and the investment reported by various places is small, and the total investment amount of the investment project portfolio with the largest investment benefit of the optimized power grid is 350 million yuan.",IEEE
N. Tateiwa; Y. Shinano; K. Yamamura; A. Yoshida; S. Kaji; M. Yasuda; K. Fujisawa,CMAP-LAP: Configurable Massively Parallel Solver for Lattice Problems,2021,10.1109/HiPC53243.2021.00018,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9680420,Conference Paper,"2021 IEEE 28th International Conference on High Performance Computing, Data, and Analytics (HiPC)","Lattice problems are a class of optimization problems that are notably hard. There are no classical or quantum algorithms known to solve these problems efficiently. Their hardness has made lattices a major cryptographic primitive for post-quantum cryptography. Several different approaches have been used for lattice problems with different computational profiles; some suffer from super-exponential time, and others require exponential space. This motivated us to develop a novel lattice problem solver, CMAP-LAP, based on the clever coordination of different algorithms that run massively in parallel. With our flexible framework, heterogeneous modules run asynchronously in parallel on a large-scale distributed system while exchanging information, which drastically boosts the overall performance. We also implement full checkpoint-and-restart functionality, which is vital to high-dimensional lattice problems. CMAP-LAP facilitates the implementation of large-scale parallel strategies for lattice problems since all the functions are designed to be customizable and abstract. Through numerical experiments with up to 103,680 cores, we evaluated the performance and stability of our system and demonstrated its high capability for future massive-scale experiments.",IEEE
Z. -Y. Wong; D. C. . -K. Wong; W. -K. Lee; K. -M. Mok; W. -S. Yap; A. Khalid,KaratSaber: New Speed Records for Saber Polynomial Multiplication Using Efficient Karatsuba FPGA Architecture,2023,10.1109/TC.2023.3238129,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10021831,Journal,IEEE Transactions on Computers,"SABER is a round 3 candidate in the NIST Post-Quantum Cryptography Standardization process. Polynomial convolution is one of the most computationally intensive operation in Saber Key Encapsulation Mechanism, that can be performed through widely explored algorithms like the schoolbook polynomial multiplication algorithm (SPMA) and Number Theoretic Transform (NTT). While SPMA multiplier has a slow latency performance, the NTT-based multiplier usually requires large hardware. In this work, we propose KaratSaber, an optimized Karatsuba polynomial multiplier architecture with a balanced hardware efficiency (throughput-per-slice, TPS) compared to NTT and SPMA based designs. KaratSaber employs several techniques for an efficient design: a parallel grid input technique for efficient pre-processing stage in Karatsuba-based polynomial multiplier, a novel instruction code result-mapping technique catering the negacyclic operations improves the post-processing stage efficiency, a double multiplicand shifter-based multiplier doubles the throughput at the multiplication stage. Combining these three techniques, the proposed KaratSaber architecture is 7.47¡Á faster compared to the state-of-the-art SPMA Saber architecture at the expense of 4.96¡Á additional hardware resources; making KaratSaber 46.04% more area-time efficient. When compared to LWRPro, a recent Karatsuba Saber architecture, KaratSaber architecture achieves a 2.11¡Á higher throughput by only utilizing 1.92¡Á additional hardware; thus gaining a 10.44% improvement in area-time efficiency",IEEE
A. Stanco; F. B. L. Santagiustina; L. Calderaro; M. Avesani; T. Bertapelle; D. Dequal; G. Vallone; P. Villoresi,Versatile and Concurrent FPGA-Based Architecture for Practical Quantum Communication Systems,2022,10.1109/TQE.2022.3143997,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9695406,Journal,IEEE Transactions on Quantum Engineering,"This article presents a hardware and software architecture, which can be used in those systems that implement practical quantum key distribution (QKD) and quantum random-number generation (QRNG) schemes. This architecture fully exploits the capability of a System on a Chip (SoC), which comprehends both a field-programmable gate array (FPGA) and a dual-core CPU unit. By assigning the time-related tasks to the FPGA and the management to the CPU, we built a flexible system with optimized resource sharing on a commercial off-the-shelf (COTS) evaluation board, which includes an SoC. Furthermore, by changing the dataflow direction, the versatile system architecture can be exploited as a QKD transmitter, QKD receiver, and QRNG control-acquiring unit. Finally, we exploited the dual-core functionality and realized a concurrent stream device to implement a practical QKD transmitter, where one core continuously receives fresh data at a sustained rate from an external QRNG source, while the other operates with the FPGA to drive the qubit transmission to the QKD receiver. The system was successfully tested on a long-term run proving its stability and security. This demonstration paves the way toward a more secure QKD implementation, with fully unconditional security as the QKD states are entirely generated by a true random process and not by deterministic expansion algorithms. Eventually, this enables the realization of a standalone quantum transmitter, including both the random numbers and the qubit generation.","IEEE, Web of Science"
M. V. Petrenko; S. P. Dmitriev; A. S. Pazgalev; A. E. Ossadtchi; A. K. Vershovskii,Towards the Non-Zero Field Cesium Magnetic Sensor Array for Magnetoencephalography,2021,10.1109/JSEN.2021.3089455,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9455403,Journal,IEEE Sensors Journal,"Magnetic sensors developed for application in magnetoencephalography must meet a number of requirements; the main ones are compactness, sensitivity and response speed. We present a quantum optically pumped atomic sensor with cell volume of 0.5 cm3 that meets these requirements and is operable in nonzero magnetic fields. The ultimate sensitivity of the sensor was estimated as (using the criteria of the ratio of the slope of the magnetic resonance signal to the shot noise spectral density) to be better than 5 fT/ ¡ÌHz. The actual sensitivity, measured in a gradiometric scheme, reaches 13 fT/ ¡ÌHz per sensor. We also present a novel and fast algorithm for optimization of the geometric properties of non-zero field sensor array with respect to maximization of the information transfer rate for cortical sources.",IEEE
A. Sarker; M. M. Kermani; R. Azarderakhsh,Error Detection Architectures for Ring Polynomial Multiplication and Modular Reduction of Ring-LWE in $\boldsymbol{\frac{\mathbb{Z}/p\mathbb{Z}[x]}{x^{n}+1}}$ Benchmarked on ASIC,2021,10.1109/TR.2020.2991671,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9097279,Journal,IEEE Transactions on Reliability,"Ring learning with error (ring-LWE) within lattice-based cryptography is a promising cryptographic scheme for the post-quantum era. In this article, we explore efficient error detection approaches for implementing ring-LWE encryption. For achieving accurate operation of the ring-LWE problem and thwarting active side-channel attacks, error detection schemes need to be devised so that the induced overhead is not a burden to deeply embedded and constrained applications. This article, for the first time, investigates error detection schemes for both stages of the ring-LWE encryption operation, i.e., ring polynomial multiplication and modular reduction. Our schemes exploit recomputing with encoded operands, which successfully counter both natural faults (for the stuck-at model). We implement our schemes on an application-specific integrated circuit. As performance metrics show hardware overhead, our schemes prove to be low complexity with high error coverage. The proposed efficient architectures can be tailored and utilized for post-quantum cryptographic schemes in different usage models with diverse constraints.",IEEE
J. Zhang; Z. Liu; H. Yang; J. Huang; W. Wu,An Efficient and Scalable Sparse Polynomial Multiplication Accelerator for LAC on FPGA,2020,10.1109/ICPADS51040.2020.00059,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9359143,Conference Paper,2020 IEEE 26th International Conference on Parallel and Distributed Systems (ICPADS),"LAC, a Ring-LWE based scheme, has shortlisted for the second round evaluation of the National Institute of Standards and Technology Post-Quantum Cryptography (NIST-PQC) Standardization. FPGAs are widely used to design accelerators for cryptographic schemes, especially in resource-constrained scenarios, such as IoT. Sparse Polynomial Multiplication (SPM) is the most compute-intensive routine in LAC. Designing an accelerator for SPM on FPGA can significantly improve the performance of LAC. However, as far as we know, there are currently no works related to the hardware implementation of SPM for LAC. In this paper, the proposed efficient and scalable SPM accelerator fills this gap. More concretely, we firstly develop the Dual-For-Loop-Parallel (DFLP) technique to optimize the accelerator's parallel design. This technique can achieve 2x performance improvement compared with the previous works. Secondly, we design a hardware-friendly modular reduction algorithm for the modulus 251. Our method not only saves hardware resources but also improves performance. Then, we launch a detailed analysis and optimization of the pipeline design, achieving a frequency improvement of up to 34%. Finally, our design is scalable, and we can achieve various performance-area trade-offs through parameter $p$. Our results demonstrate that the proposed design can achieve a very considerable performance improvement with moderate hardware area costs. For example, our medium-scale architecture for LAC-128 takes only 783 LUTs, 432 FFs, 5BRAMs, and no DSP on an Artix-7 FPGA and can complete LAC's polynomial multiplication in 8512 cycles at a frequency of 202MHz.",IEEE
F. Sheldon; P. Cicotti; F. L. Traversa; M. Di Ventra,Stress-Testing Memcomputing on Hard Combinatorial Optimization Problems,2020,10.1109/TNNLS.2019.2927480,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8786927,Journal,IEEE Transactions on Neural Networks and Learning Systems,"Memcomputing is a novel computing paradigm that employs time non-local dynamical systems to compute with and in memory. The digital version of these machines [digital memcomputing machines or (DMMs)] is scalable, and is particularly suited to solve combinatorial optimization problems. One of its possible realizations is by means of standard electronic circuits, with and without memory. Since these elements are non-quantum, they can be described by ordinary differential equations. Therefore, the circuit representation of DMMs can also be simulated efficiently on our traditional computers. We have indeed previously shown that these simulations only require time and memory resources that scale linearly with the problem size when applied to finding a good approximation to the optimum of hard instances of the maximum-satisfiability problem. The state-of-the-art algorithms, instead, require exponential resources for the same instances. However, in that work, we did not push the simulations to the limit of the processor used. Since linear scalability at smaller problem sizes cannot guarantee linear scalability at much larger sizes, we have extended these results in a stress-test up to $64\times 10^{6}$ variables (corresponding to about 1 billion literals), namely the largest case that we could fit on a single core of an Intel Xeon E5-2860 with 128 GB of dynamic random-access memory (DRAM). For this test, we have employed a commercial simulator, Falcon of MemComputing, Inc. We find that the simulations of DMMs still scale linearly in both time and memory up to these very large problem sizes versus the exponential requirements of the state-of-the-art solvers. These results further reinforce the advantages of the physics-based memcomputing approach compared with traditional ones.",IEEE
A. A. A. El-Latif; B. Abd-El-Atty,Adaptive Particle Swarm Optimization With Quantum-Inspired Quantum Walks for Robust Image Security,2023,10.1109/ACCESS.2023.3286347,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10151885,Journal,IEEE Access,"In this paper, we propose a novel image cryptosystem that combines the adapted Particle Swarm Optimization (PSO) algorithm with a quantum-inspired Discrete-time Quantum Walk (DTQW). The proposed approach leverages the strengths of both PSO and DTQW, integrating them to achieve high security and efficiency in image encryption. The main contribution of this work lies in the development of this unique cryptosystem. While previous approaches have separately explored PSO or DTQW, our integration of these two techniques offers a novel and innovative approach. By employing chaotic sequences generated by a 3-D chaotic system and a controlled DTQW model, our cryptosystem demonstrates a high sensitivity to even slight changes in the original image. This sensitivity ensures that minor modifications in the plaintext lead to significant changes in the ciphertext, enhancing the system¡¯s resistance against attacks. Simulation outcomes prove that the proposed encryption mechanism has high security as well as high effectiveness.This makes it well-suited for practical implementation in a post-quantum computing era.",IEEE
J. . -R. L¨¦quepeys; M. Duranton; S. Bonnetier; S. Catrou; R. Fournel; T. Ernst; L. H¨¦rault; D. Louis; A. Jerraya; A. Valentian; F. Perruchot; T. Signamarcheix; E. Vianello; C. Reita,Overcoming the Data Deluge Challenges with Greener Electronics,2021,10.1109/ESSCIRC53450.2021.9567836,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9567836,Conference Paper,ESSCIRC 2021 - IEEE 47th European Solid State Circuits Conference (ESSCIRC),"The complete ecosystem of electronic device manufacturers, from microelectronics, software and hardware designers to developers, producers, and integrators, is facing an immense new environmental challenge: to cope with the data deluge and to reduce the energy consumption of digital technologies. The purpose of this paper is to propose scientific and technical directions to reach global data and power sobriety while preserving computational efficiency. We present nine opportunities to lower the power consumption of computing units. A growth factor of 100 to 1000 in energy efficiency is achievable in the next 10 years if we take full advantage of all the potential improvements, working simultaneously at all five levels of the technological ecosystem (process steps, circuits, architecture, software and algorithms). We will indeed need to exploit all the possible technological advances to achieve this goal, including resistive memories, 3D stacking and new computing paradigms such as in-memory-computing, neuromorphic computing and quantum computing. Additionally, in order to maximize efficiency and performance, the research and development communities must work closer together and embrace a real culture of co-design to optimize applications and algorithms, algorithms and architectures, architectures and technologies jointly. We also propose to perform data processing operations as closely as possible to the source, in order to curtail the energy consumption that comes with data transport. Finally, we believe it is essential to accept the constraints for sustainable electronics now, and to change our mindsets quite radically by carrying out product life-cycle assessments in the very early phases of any new research.",IEEE
S. Nassiri; M. Labbadi; C. Chatri; M. Cherkaoui,Optimal Recursive Terminal Sliding-Mode Control Using Super-Twisting Algorithm for Improving High Efficiency and Reliability of Pump Systems,2023,10.1109/LCSYS.2023.3330748,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10310222,Journal,IEEE Control Systems Letters,"In this letter, we propose an optimal recursive terminal sliding-mode control (ORTSMC) combined with super-twisting algorithm (STA) for a pump system under uncertainties. The main objective of the approach developed is to ensure rapid convergence of the pumping system with minimal power losses. To calculate the optimal input parameters of the pump system, a quantum particle swarm optimization algorithm (QPSO) is used. Next, we introduce a non-linear sliding variable into the cost function of the linear quadratic regulator (LQR). This proposal, along with the ORTSM manifold, aims to achieve fast convergence, dynamic stability, and minimize energy consumption. Additionally, the STA is employed to enhance performance during the reaching phase and reduce the chattering problem. The stability of the closed-loop control system is guaranteed using the Lyapunov theory. Finally, we conduct a comparative simulation analysis with two existing control schemes to demonstrate the superiority and effectiveness of our proposed control strategy.",IEEE
R. Hua; D. Di Lorenzo; F. Chinesta; P. Codognet,Quantum Annealing Solutions for Drone Route Planning Problems,2024,10.1109/QCE60285.2024.00076,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10821321,Conference Paper,2024 IEEE International Conference on Quantum Computing and Engineering (QCE),"We present annealing solutions for route optimization problems for unmanned aerial vehicles (UAVs), The route planning problem is a generalised version of the Travelling Salesman Problem which has many applications in logistics planning. Our annealing solutions combine classical algorithms with quantum/digital annealers specifically designed for quadratic optimization problems and shows improvements over generic traditional solvers such as Gurobi. We empirically test the solvability of our annealing solutions on both hand-crafted hard test cases as well as simulated ¡®real-world¡¯ examples of urban environments where the operations of the UAVs can be affected by the direction and intensity of wind, which is conditioned by the presence of buildings.",IEEE
Y. Murai; C. L. Ayala; N. Takeuchi; Y. Yamanashi; N. Yoshikawa,Development and Demonstration of Routing and Placement EDA Tools for Large-Scale Adiabatic Quantum-Flux-Parametron Circuits,2017,10.1109/TASC.2017.2721965,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7964776,Journal,IEEE Transactions on Applied Superconductivity,"Adiabatic quantum-flux-parametron (AQFP) logic is a very energy-efficient superconductor logic due to zero static power dissipation and adiabatic switching operation. However, there is a shortage of electronic design automation (EDA) software tools adaptable to AQFP logic. Such tools are essential for designing large-scale-integration circuits efficiently. Therefore, we have developed a first set of EDA tools that handle cell placement and wiring, written in SKILL, the Cadence scripting language. Our tools also consider the maximum wire length constraint that exists in AQFP logic. First, AQFP logic cells are repositioned via the genetic algorithm to minimize the number of wires that violate the wiring length constraint. Buffers are then automatically inserted as signal repeaters for logic rows where the violations still exist. We then complete the logic wiring of the circuit using the channel routing algorithm. We demonstrate the usability of the EDA tools by designing a 16-bit adder as well as a randomly generated test circuit.","IEEE, Web of Science"
N. Majlesinasab; F. Yousefian; M. J. Feizollahi,A First-order Method for Monotone Stochastic Variational Inequalities on Semidefinite Matrix Spaces,2019,10.23919/ACC.2019.8814737,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8814737,Conference Paper,2019 American Control Conference (ACC),"Motivated by multi-user optimization problems and non-cooperative Nash games in stochastic regimes, we consider stochastic variational inequality (SVI) problems on matrix spaces where the variables are positive semidefinite matrices and the mapping is merely monotone. Much of the interest in the theory of variational inequality (VI) has focused on addressing VIs on vector spaces. Yet, most existing methods addressing VIs on matrix spaces either rely on strong assumptions, or require a two-loop framework where at each iteration, a projection problem, i.e., a semidefinite optimization problem needs to be solved. Motivated by this gap, we develop a stochastic mirror descent method where we choose the distance generating function to be defined as the quantum entropy. This method is a single-loop first-order method in the sense that it only requires a gradient-type of update at each iteration. The novelty of this work lies in the convergence analysis that is carried out through employing an auxiliary sequence of stochastic matrices. Our contribution is three-fold: (i) under this setting and employing averaging techniques, we show that the iterate generated by the algorithm converges to a weak solution of the SVI; (ii) moreover, we derive a convergence rate in terms of the expected value of a suitably defined gap function; (iii) we implement the developed method for solving a multiple-input multiple-output multi-cell cellular wireless network composed of seven hexagonal cells and present the numerical experiments supporting the convergence of the proposed method.",IEEE
M. Beyki; J. Pawlak; M. Mutz; R. Patzke; F. Renz,Drive Modeling and Dynamic Control in M?ssbauer Spectroscopy for Space & Terrestrial Applications,2024,10.1109/MMAR62187.2024.10680771,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10680771,Conference Paper,2024 28th International Conference on Methods and Models in Automation and Robotics (MMAR),"An important component of the M?ssbauer spectrometer is the M?ssbauer drive, which allows, utilizing the Doppler effect, to vary the amount of energy of the emitted gamma quanta so that it corresponds to the resonance energy and energetically excites the irradiated nuclei. This paper deals with drive modelling and control in M?ssbauer spectroscopy. The equations of motion of the linear drive are derived and compared in different versions. In this context, the single-mass representation proves to be a sufficiently accurate model, which shows almost identical results compared to multibody models. This leads to a reduction of the system order from n=6 to n=2, which greatly simplifies the evaluation steps in this context and the further controller design modalities. Based on this, a heuristic control concept is developed that fundamentally revises common design approaches and opens up a broad spectrum of research. The controller design provides for a combination of signal-smoothing and signal amplifying low-pass filtering in combination with dynamic input vector normalisation. This achieves the desired frequency and amplitude response of $1.1485 \cdot 10^{3} \frac{\mathrm{rad}}{\mathrm{s}}$ and 0.3 mm and optimises the dynamics for real laboratory use.",IEEE
S. J. Nawaz; S. K. Sharma; B. Mansoor; M. N. Patwary; N. M. Khan,Non-Coherent and Backscatter Communications: Enabling Ultra-Massive Connectivity in 6G Wireless Networks,2021,10.1109/ACCESS.2021.3061499,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9360811,Journal,IEEE Access,"With the commencement of the 5th generation (5G) of wireless networks, researchers around the globe have started paying their attention to the imminent challenges that may emerge in the beyond 5G (B5G) era. Various revolutionary technologies and innovative services are offered in 5G networks, which, along with many principal advantages, are anticipated to bring a boom in the number of connected wireless devices and the types of use-cases that may cause the scarcity of network resources. These challenges partly emerged with the advent of massive machine-type communications (mMTC) services, require extensive research innovations to sustain the evolution towards enhanced-mMTC (e-mMTC) with the scalable network cost in 6th generation (6G) wireless networks. Towards delivering the anticipated massive connectivity requirements with optimal energy and spectral efficiency besides low hardware cost, this paper presents an enabling framework for 6G networks, which utilizes two emerging technologies, namely, non-coherent communications and backscatter communications (BsC). Recognizing the coherence between these technologies for their joint potential of delivering e-mMTC services in the B5G era, a comprehensive review of their state-of-the-art is conducted. The joint scope of non-coherent and BsC with other emerging 6G technologies is also identified, where the reviewed technologies include unmanned aerial vehicles (UAVs)-assisted communications, visible light communications (VLC), quantum-assisted communications, reconfigurable large intelligent surfaces (RLIS), non-orthogonal multiple access (NOMA), and machine learning (ML)-aided intelligent networks. Subsequently, the scope of these enabling technologies for different device types (e.g., UAVs, body implants, etc), service types (e.g., e-mMTC), and optimization parameters (e.g., spectrum, energy, cost) is analyzed. Finally, in the context of the proposed non-coherent and BsCs based framework for e-mMTCs, some promising future research directions and open research challenges are highlighted.",IEEE
M. Castro; J. Straub,Nanosatellite scheduling using a dictionary module and a ¡®useful trick¡¯ with coded unsigned integers,2015,10.1109/AERO.2015.7119266,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7119266,Conference Paper,2015 IEEE Aerospace Conference,"Schedulers for small spacecraft must satisfy the dual requirement of generating very efficient schedules while concurrently minimizing the resources required to create the schedule. This paper proposes a technique for searching for tasks that can be utilized to fill particular schedule locations. This approach is based on a modular system for storing important variables. This modular system has three important variables: t0, x0 and y0. The variable y is latitude and x is longitude. Time variable t is an integer and each unit represents a time quantum. They are related to each other by three functions Ft, Fx, and Fy. These functions are derived from a space time function where x0 and y0 are the normalized ground trace. These three variables can define a prospective instance of any task on an Earth-orbiting spacecraft. Similarly, this same approach could be used for planetary missions by making the ground trace references in relation to the local body. This approach is based on a 'useful trick' that can be performed with integers that facilitates the encoding of conditional statements using these three variables. This trick helps define the life cycle of a task. This approach can also, if needed, be expanded to allow the incorporation of other variables. This paper considers the limits of using integers in this way. It presents and considers several example problems and demonstrates the efficacy of using this algorithm to generate a solution.",IEEE
M. M. Shabir; K. Zhang,Qwallet: A Hybrid Cryptocurrency Wallet using Quantum RNG,2023,10.1109/BCCA58897.2023.10338857,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10338857,Conference Paper,2023 Fifth International Conference on Blockchain Computing and Applications (BCCA),"Blockchain wallets use two primary key generation schemes: non-deterministic (ND) and hierarchical deterministic (HD). ND key generation scheme provides better fund distribution but have issues with backup complexity and memory utilization. HD key generation scheme simplifies the backup process but is vulnerable to privilege escalation and brute-force attacks. In addition, deterministic pseudo-random algorithms used in these key generation schemes are predictable, which makes Quantum Random Number Generators (QRNGs) a promising alternative. This paper proposes Qwallet: a hybrid wallet based on the user's behavior that utilizes both HD and ND key generation architecture while leveraging QRNG to generate the keys. The wallet is optimized through deep learning, which trains on user behavior to select the optimal key generation scheme for maximum efficiency in blockchain wallet usage. We implemented and evaluated our proposed solution to support Ethereum transactions. Our results show that Qwallet reduces risk by up to 98% compared to traditional HD wallets, while consuming similar memory resources.",IEEE
M. Pfefferkorn; M. Maiworm; C. Wagner; F. S. Tautz; R. Findeisen,Fusing Online Gaussian Process-Based Learning and Control for Scanning Quantum Dot Microscopy,2020,10.1109/CDC42340.2020.9304053,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9304053,Conference Paper,2020 59th IEEE Conference on Decision and Control (CDC),"Elucidating electrostatic surface potentials contributes to a deeper understanding of the nature of matter and its physicochemical properties, which is the basis for a wide field of applications. Scanning quantum dot microscopy, a recently developed technique allows to measure such potentials with atomic resolution. For an efficient deployment in scientific practice, however, it is essential to speed up the scanning process. To this end we employ a two-degree-of-freedom control paradigm, in which a Gaussian process is used as the feed-forward part. We present a tailored online learning scheme of the Gaussian process, adapted to scanning quantum dot microscopy, that includes hyperparameter optimization during operation to enable fast and precise scanning of arbitrary surface structures. For the potential application in practice, the accompanying computational cost is reduced evaluating different sparse approximation approaches. The fully independent training conditional approximation, used on a reduced set of active training data, is found to be the most promising approach.",IEEE
A. Okada; K. Otaki; T. Matsumori; H. Yoshida; K. Terada; N. Togawa,QUBO Formulation Using Sequence Pair With Search Space Restriction for Rectangle Packing Problem,2024,10.1109/ACCESS.2024.3485675,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10734100,Journal,IEEE Access,"The development of quantum annealing has stimulated interest in solving NP-hard problems, including various industrial problems, such as quadratic unconstrained binary optimization (QUBO), with specialized solvers. This study focuses on the rectangle packing problem (RPP), which is an NP-hard problem applicable to industrial applications. The objective of this problem is to place given items in a minimum area without overlap. Naive QUBO representations, such as a direct binary encoding of locations, could require a large number of bits, which limits the problem size, hindering the acquisition of the optimal solution. To circumvent this difficulty, we employ the concept of sequence pairs to efficiently represent the locations of items. We also propose a strategy that uses multiple sampling solutions obtained with a QUBO solver, where we employ new constraints on the number of the rectangles contributing to the placement area for restricting the search space to smoothly bridge the QUBO formulation of the sequence pair and the minimization of area of rectangle placement. We estimate an approximate curve for the optimum number of rectangles contributing to the placement area. Then, we add the penalty term concerning the deviation from the estimated optimal value on the objective function. In numerical experiments with instances with 4 to 10 rectangles, we demonstrate that the proposed sampling-based strategy can efficiently find feasible solutions. This strategy would be useful for dealing with more complex problems, such as rectangle orientation and three-dimensional problems, with a relatively small number of bits using sequence pairs.",IEEE
K. Liu; J. Feng; S. Guo; L. Xiao; Z. -Q. Zhu,Identification of Flux Linkage Map of Permanent Magnet Synchronous Machines Under Uncertain Circuit Resistance and Inverter Nonlinearity,2018,10.1109/TII.2017.2722470,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7967682,Journal,IEEE Transactions on Industrial Informatics,"This paper proposes a novel scheme for the identification of the whole flux linkage map of permanent magnet synchronous machines, by which the map of dq-axis flux linkages at different load or saturation conditions can be identified by the minimization of a proposed estimation model. The proposed method works on a conventional three-phase inverter based vector control system and the immune clonal based quantum genetic algorithm is employed for the global searching of minimal point. Besides, it is also noteworthy that the influence of uncertain inverter nonlinearity and circuit resistance are cancelled during the modeling process. The proposed method is subsequently tested on two PMSMs and shows quite good performance compared with the finite element prediction results.",IEEE
B. Alhazmi; F. Gebali,Fast Large Integer Modular Addition in GF(p) Using Novel Attribute-Based Representation,2019,10.1109/ACCESS.2019.2914641,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8705212,Journal,IEEE Access,"Addition is an essential operation in all cryptographic algorithms. Higher levels of security require larger key sizes and this becomes a limiting factor in GF(p) using large integers because of the carry propagation problem. We propose a novel and efficient attribute-based large integer representation scheme suitable for large integers commonly used in cryptography such as the five NIST primes and the Pierpont primes used in supersingular isogeny Diffie-Hellman (SIDH) for post-quantum cryptography. Algorithms are proposed for this new representation to implement arithmetic operations such as two's complement, addition/subtraction, comparison, sign detection, and modular reduction. Algorithms are also developed for converting binary numbers to attribute representation and vice versa. The extensive numerical simulations were done to verify the performance of the new number representation. Results show that addition is done faster in our proposed representation when compared with binary and residue number system (RNS)-based additions. Attribute addition outperformed RNS addition for all values of m where 128 ¡Ü m ¡Ü 32768 bits for all machine word sizes w where 4 ¡Ü w ¡Ü 128 bits. Attribute-based addition outperforms Kogge-Stone binary adders for a wide range of m when w is small. For increasing values of w, the speed advantages are evident only for large values of m. This makes the proposed number representation suitable for implementing cryptographic applications in embedded processors for IoT and consumer electronic devices where w is small.",IEEE
J. Schupp; P. Karl; J. N?pel; A. Hepp; T. Music; G. Sigl,RISC-V Triplet: Tapeouts for Security Applications,2024,10.1109/NorCAS64408.2024.10752453,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10752453,Conference Paper,2024 IEEE Nordic Circuits and Systems Conference (NorCAS),"In 2019 we started to design RISC-V based ASICs including security IP with a focus on Post Quantum Cryptography (PQC) at our institute. The primary goal were small, resource efficient implementations with high flexibility through HW/SW-codesign. In a first ASIC we included tightly coupled PQC accelerators directly integrated in a 32 bit RISC-V processor. We achieved speedups and power savings of a factor 10 for many lattice based PQC algorithms. Furthermore, this design included HW-Trojans to demonstrate the risk of such attacks and to perform research on Trojan detection techniques. In a second ASIC we went for loosely coupled accelerators optimizing bus integration. We also included accelerators for isogeny based PQC and code based cryptography. Furthermore higher frequency and a smaller technology was used. The underlying idea was to get experience for chip design with the first tapeout on a 65 nm technology and use this for the second tapeout in a 22 nm technology with a more challenging design flow. The third step remained in the same technology but went from a simple RISCV platform to a complex security platform provided by the OpenTitan open-source project. The target here was to modify this platform in such a way that key storage can be achieved with Physical Unclonable Functions (PUFs) and PQC enhancements are included in the big number processor. With these ASICs we enable deeper security analysis of implementations in our hardware lab. The first chip was, e.g., given to a reverse engineering lab to reconstruct the netlist from the silicon and to find the Trojans. Additionally, the chip design activities educate students and PhD candidates addressing the needs of the industry in more skilled people.",IEEE
F. Yan; H. Huang; X. Yu,A Multiwatermarking Scheme for Verifying Medical Image Integrity and Authenticity in the Internet of Medical Things,2022,10.1109/TII.2022.3159863,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9736617,Journal,IEEE Transactions on Industrial Informatics,"With the advent of a fifth-generation mobile network and developments in technologies such as the Internet of Medical Things, smart healthcare systems are becoming ubiquitous in our daily lives. Patients, doctors, and other medical personnel rely on the safe and efficient storage, transmission, and analysis of electronic health records, particularly medical images, for successful diagnosis, treatment, and management of different ailments. In this study, a multiwatermarking scheme is proposed for medical images based on quantum random walk and the brain storm optimization algorithm. A logo image used to verify medical image integrity is embedded in regions of interest, and text data are embedded in regions of non-interest to conceal private hospital and patient information. This process improves the accuracy of medical image verification and helps to ensure authenticity. A series of experiments were conducted to validate the capacity, security, robustness, and imperceptibility of the proposed multiwatermarking scheme.",IEEE
J. -P. D¡¯Anvers; M. Van Beirendonck; I. Verbauwhede,Revisiting Higher-Order Masked Comparison for Lattice-Based Cryptography: Algorithms and Bit-Sliced Implementations,2023,10.1109/TC.2022.3197074,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9852472,Journal,IEEE Transactions on Computers,"Masked comparison is one of the most expensive operations in side-channel secure implementations of lattice-based post-quantum cryptography, especially for higher masking orders. First, we introduce two new masked comparison algorithms, which improve the arithmetic comparison of D¡¯Anvers et al. (2021) and the hybrid comparison method of Coron et al. (2021) respectively. We then look into implementation-specific optimizations, and show that small specific adaptations can have a significant impact on the overall performance. Finally, we implement various state-of-the-art comparison algorithms and benchmark them on the same platform (ARM-Cortex M4) to allow a fair comparison between them. We improve on the arithmetic comparison of D¡¯Anvers et al. with a factor $\approx 20\%$¡Ö20% by using Galois Field multiplications and the hybrid comparison of Coron et al. with a factor $\approx 25\%$¡Ö25% by streamlining the design. Our implementation-specific improvements allow a speedup of a straightforward comparison implementation of $\approx 33\%$¡Ö33%. We discuss the differences between the various algorithms and provide the implementations and a testing framework to ease future research.",IEEE
C. Li; Y. Zhang; J. Wu; Y. Luo; S. Yu,Smart Contract-Based Decentralized Data Sharing and Content Delivery for Intelligent Connected Vehicles in Edge Computing,2024,10.1109/TITS.2024.3388422,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10508747,Journal,IEEE Transactions on Intelligent Transportation Systems,"Intelligent Connected Vehicles (ICVs) need to obtain real-time traffic data from nearby ICVs or remote content providers to ensure safe driving. However, providers are hesitant to share their data due to privacy and benefits concerns. To ensure privacy while improving efficiency of obtaining data, we proposed smart contract-based data sharing among ICVs, and content delivery between ICVs and remote content provider. To solve low willingness to vehicles due to untrustworthy third-party platforms, we use smart contracts to implement access control during data upload and transaction. Then, we propose a one-to-many sharing model based on Stackelberg game to model the interaction between consumers and owners. Consumers adjust their reward strategies with the owners¡¯ optimal strategies to maximize its utility, thus obtaining the nash equilibrium solution. To provide reliable quality of service (QoS) and security guarantee for content delivery, smart contracts regulate the delivery process, facilitating automatic execution under specific conditions. Transaction records audited and stored on blockchain enhance transparency and trustworthiness. Utilizing a delivery utility model that considers benefits, costs, and mining profits, proposed quantum particle swarm optimization (QPSO) algorithm is used to find the optimal solution. We built an EdgeChain testbed, and used BDD-100K dataset to evaluate the performance in utility, access delay, etc. Compared to CTM and MFPA, proposed data sharing algorithm achieves maximum consumer utility. Compared to LRU, PCCM and MARL, when content is 400, proposed content delivery algorithm reduces average access delay by 30.88%, 18.92% and 4.86%, and reduce backhaul load by 50.04%, 47.23% and 3.16%.","IEEE, Web of Science"
S. Sun; R. Zhang; H. Ma,Efficient Parallelism of Post-Quantum Signature Scheme SPHINCS,2020,10.1109/TPDS.2020.2995562,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9095410,Journal,IEEE Transactions on Parallel and Distributed Systems,"SPHINCS was recently proposed as a stateless, quantum-resilient hash-based signature scheme. However, one possible limitation of SPHINCS is its signing speed, namely, the best known implementation merely produces a few hundred of signatures per second, which is not good enough, e.g., for a social website with a huge amount of users. Aiming at improving the singing throughput, we present highly parallel and optimized implementations of SPHINCS, which can be deployed on various multi-core platforms. As a first step, we give an elementary implementation on ¡Á86/64 processors, which proves the effectiveness and correctness of our implementations. To obtain a significantly higherthroughput, we implement SPHINCS on Graphics Processing Units (GPUs). Furthermore, we develop a few general and hardware-specific techniques to take full advantage of the computing power of targeted platforms. We instantiate the underlying hash functions with three primitives. Our comprehensive benchmark shows that our work outperforms all the state-of-the-art implementations of SPHINCS regarding throughput with reasonable latency, and has scalability on multiple cores and multiple GPU cards. For instance, forthe key generation algorithm instantiated with ChaCha running on a GeForce GTX 1080, we obtain 5152 signatures per second which is 7.88x speedup fasterthan a recent FPGA implementation. When upgrade to TITAN Xp, 6,651 signatures are generated in one second. With four TITAN Xp GPUs, the obtained throughput satisfies vast majority scenarios.",IEEE
J. Sun; X. Bai,A High-Speed Hardware Architecture of an NTT Accelerator for CRYSTALS-Kyber,2024,10.23919/ICS.2024.3419562,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10572273,Journal,Integrated Circuits and Systems,"CRYSTALS-Kyber has emerged as a notable lattice-based post-quantum cryptography (PQC) scheme. As one of the four finalists in NIST's PQC standardization round three, CRYSTALS-Kyber is the only encryption algorithm demonstrating superior performance compared to other algorithms. The number theoretic transform (NTT) is employed to optimize polynomial multiplication, which constitutes the most complex operation within CRYSTALS-Kyber. This study introduces a high-speed NTT accelerator architecture, featuring a novel butterfly unit and an efficient modular polynomial multiplier. The proposed accelerator utilizes a radix-4-based configurable NTT design, which is capable of executing both forward and inverse NTT operations on a unified architecture. When implemented on the Xilinx Virtex-7 FPGA platform, the proposed architecture achieves an acceleration of 1.02¨C2.30 times in terms of latency, a throughput improvement of 1.02¨C2.30 times, and an area throughput improvement of up to 3.30 times, relative to the prior works.",IEEE
R. El Khatib; R. Azarderakhsh; M. Mozaffari-Kermani,High-Performance FPGA Accelerator for SIKE,2022,10.1109/TC.2021.3078691,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9427238,Journal,IEEE Transactions on Computers,"In this article, we provide improvements for the architecture of Supersingular Isogeny Key Encapsulation (SIKE), a post-quantum cryptography candidate. We develop a new highly optimized Montgomery multiplication algorithm and architecture for prime fields. The multiplier occupies less area and provide better timing results than the state-of-the-art. We also provide improvements to the scheduling of SIKE in our program ROM. We implement SIKE for all Round 3 NIST security levels (SIKEp434 for NIST security level 1, SIKEp503 for NIST security level 2, SIKEp610 for NIST security level 3, and SIKEp751 for NIST security level 5) on Xilinx Artix 7 and Xilinx Virtex 7 FPGAs. Our best implementation (NIST security level 1) runs 38 percent faster and occupies 30 percent less hardware resources in comparison to the leading counterpart available in the literature and implementations for other security levels achieved similar improvement.",IEEE
L. Ling; C. W. Tan; S. -W. Ho; R. W. Yeung,Scalable Automated Proving of Information Theoretic Inequalities with Proximal Algorithms,2019,10.1109/ISIT.2019.8849799,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8849799,Conference Paper,2019 IEEE International Symposium on Information Theory (ISIT),"Proving or disproving linear information theoretic inequalities is a fundamental task in information theory, and it has also been proved to be important in fields like cryptography and quantum communication theory. Manually proving information inequalities involving more than a few random variables can often be tedious or even intractable. In 1997, Yeung proposed a linear programming framework for verifying information inequalities, which was later extended to construct analytical proofs and disproofs. However, in practice this framework can be very slow for inequalities involving more than ten random variables, thus it is impossible to be applied to a wide range of practical problems. In this paper, we further extend this optimization-theoretic framework by reformulating the LPs and applying the Alternating Direction Method of Multipliers (ADMM) technique, where all the subproblems have closed-form solutions and thus can be solved efficiently. The proposed algorithm is also parallelizable so the performance can be further improved by running it on a GPU. An online web service is developed to allow users to prove or disprove their problem-specific inequalities without installing any software package or dependency.",IEEE
H. Zhao; C. Zhao; W. Zhu; B. Yang; S. Wei; L. Liu,Sparse Polynomial Multiplication-Based High-Performance Hardware Implementation for CRYSTALS-Dilithium,2024,10.1109/HOST55342.2024.10545379,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10545379,Conference Paper,2024 IEEE International Symposium on Hardware Oriented Security and Trust (HOST),"CRYSTALS-Dilithium has been declared as the first recommended digital signature algorithm in NIST Post-Quantum Cryptography Standardization. The advancement of high-speed hardware research for Dilithium is propelled by the need for real-time processing of extensive data in numerous digital signature applications. To address the slow signature generation speed issue, a two-stage pipeline structure was developed to accelerate the underlying rejection loop, at a cost of substantial resource consumption. In this paper, we present the first analysis on the possibility of leveraging sparse multiplication in the second stage, which can reduce the bit complexity of corresponding multiplications by over 85% and lower the storage requirements for the secret key by over 68%. Building on this, we propose a sparse computing core and a high-speed hybrid architecture for Dilithium, with an efficient scheduling mechanism and optimized modules. Compared to state-of-the-art high-speed implementations on similar platforms, the signature generation speed is at least 2x faster. Meanwhile, the area-time-products of signature generation achieve 3.6x/4.3x/2.0x/2.1x improvement in terms of LUT/FF/DSP/BRAM, respectively.",IEEE
R. R. Irshad; S. Hussain; I. Hussain; J. A. Nasir; A. Zeb; K. M. Alalayah; A. A. Alattab; A. Yousif; I. M. Alwayle,IoT-Enabled Secure and Scalable Cloud Architecture for Multi-User Systems: A Hybrid Post-Quantum Cryptographic and Blockchain-Based Approach Toward a Trustworthy Cloud Computing,2023,10.1109/ACCESS.2023.3318755,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10261941,Journal,IEEE Access,"Cloud computing has revolutionized organizational operations by providing convenient, on-demand access to resources. The emergence of the Internet of Things (IoT) has introduced a new paradigm for collaborative computing, leveraging sensors and devices that generate and process vast amounts of data, thereby resulting in challenges related to scalability and security, making the significance of conventional security methods even more pronounced. Consequently, in this paper, we propose a novel Scalable and Secure Cloud Architecture (SSCA) that integrates IoT and cryptographic techniques, aiming to develop scalable and trustworthy cloud systems, thus enabling multi-user systems and facilitating simultaneous access to cloud resources by multiple users. The design adopts a decentralized approach, utilizing multiple cloud nodes to handle user requests efficiently and incorporates Multicast and Broadcast Rekeying Algorithm (MBRA) to ensure the privacy and confidentiality of user information, utilizing a hybrid cryptosystem that combines MBRA, Post Quantum Cryptography (PQC) and blockchain technology. Leveraging IoT devices, the architecture gathers data from distributed sensing resources and ensures the security of collected information through robust MBRA-PQC encryption algorithms, while the blockchain ensures that the confidential data is stored in distributed and immutable records. The proposed approach is applied to several datasets and the effectiveness is validated through various performance metrics, including response time, throughput, scalability, security, and reliability. The results highlight the effectiveness of the proposed SSCA, showcasing a notable reduction in response time by 1.67 seconds and 0.97 seconds for 250 and 1000 devices, respectively, in comparison to the MHE-IS-CPMT. Likewise, SSCA demonstrated significant improvements in the AUC values, exhibiting enhancements of 6.30%, 6.90%, 7.60%, and 7.30% at the 25-user level, and impressive gains of 5.20%, 9.30%, 11.50%, and 15.40% at the 50-user level when compared to the MHE-IS-CPMT, EAM, SCSS, and SHCEF models, respectively.",IEEE
A. Menon; A. Srivastava; S. Kundu; K. Basu,Application Profiling Using Register-Instruction Hardware Performance Counters,2023,10.1109/ISVLSI59464.2023.10238603,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10238603,Conference Paper,2023 IEEE Computer Society Annual Symposium on VLSI (ISVLSI),"Kleptographic attacks are a type of security threat that involve weakening a cryptographic implementation in order to extract sensitive information from a computer system. These attacks can be particularly harmful when they target cryptographic keys or other security-critical information. Since software-based defenses are not robust, to address these threats, prior studies have explored the use of trusted hardware-based solutions, involving tailor-made Hardware Performance Counters (HPCs). However, these tailor-made HPCs lack the fine-grained characterization necessary to correctly differentiate between individual applications. As a result, a large number of HPCs are required to monitor the application, which incurs high overhead on the system. To this end, we propose the development of Register-Instruction Hardware Performance Counters (RIHPCs), a bespoke set of special-purpose registers designed to characterize applications, and thus detect Kleptographic attacks, with low granularity and low performance overhead. To assess the performance of RIHPCs against Kleptographic attacks, we profile NIST¡¯s Post Quantum Cryptographic Key Encapsulation Mechanism (PQC-KEM) algorithms. Our results show that RIHPC traces can distinguish between PQC algorithms with an accuracy of over 99%, while furnishing up to 67% reduction in performance overhead in comparison to tailor-made HPCs.",IEEE
S. Dou; X. Liu; S. Shangguan; T. Wen; S. Zheng; B. Han,Design of Biplane Coils Based on Funnel Algorithm for Generating a Near-Zero Magnetic Environment in MSR,2023,10.1109/TIM.2023.3267370,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10102498,Journal,IEEE Transactions on Instrumentation and Measurement,"The biplane coils (BCs) based on the inverse design method are crucial for creating the near-zero magnetic environment in magnetic shielding room (MSR), but multiparameter optimization remains a key factor that limits the performance of the BCs. This study proposes a funnel algorithm (FA) to solve the issue of multiparameter optimization in the design. The upper and lower limits of the parameters are dynamically adjusted based on the previous calculating step. By gradually reducing the upper and lower limits, we achieve the BCs with optimal performance. This method has been verified by both the theoretical analysis and experimental test. Compared with other methods, the designed coils show a higher space utilization ratio (SUR) and smaller relative errors, with the SUR improved from 1.6% to 3.75% and the relative errors all less than 2%. Based on the designed BCs, the total residual magnetic field is stabilized below 40.4 pT at the central point of the MSR, with the noise reaching the intrinsic noise of the flux-gate magnetometer in the frequency range of interest. The proposed method can significantly improve the performance of the BCs, thus reducing the space and construct cost of the MSR and promoting the magnetoencephalogram (MEG) measurement based on the quantum technology.",IEEE
J. W. Bos; S. J. Friedberger,Arithmetic Considerations for Isogeny-Based Cryptography,2019,10.1109/TC.2018.2851238,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8400486,Journal,IEEE Transactions on Computers,"In this paper we investigate various arithmetic techniques which can be used to potentially enhance the performance in the supersingular isogeny Diffie-Hellman (SIDH) key-exchange protocol which is one of the more recent contenders in the post-quantum public-key arena. First, we give a systematic overview of techniques to compute efficient arithmetic modulo 2xpy ¡À 1. Our overview shows that in the SIDH setting, where arithmetic over a quadratic extension field is required, the approaches based on the Montgomery reduction for such primes of a special shape are to be preferred. Moreover, the outcome of our investigation reveals that there exist moduli which allow even faster implementations. Second, we investigate if it is beneficial to use other curve models to speed up the elliptic curve scalar multiplication. The use of twisted Edwards curves allows one to search for efficient addition-subtraction chains for fixed scalars while this is not possible with the differential addition law when using Montgomery curves. Our preliminary results show that despite the fact that we found such efficient chains, using twisted Edwards curves does not result in faster scalar multiplication arithmetic in the setting of SIDH.",IEEE
G. Acampora; R. Schiattarella; A. Vitiello,Using Quantum Fuzzy Inference Engines in Smart Cities,2024,10.1109/FUZZ-IEEE60900.2024.10611863,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10611863,Conference Paper,2024 IEEE International Conference on Fuzzy Systems (FUZZ-IEEE),"This paper addresses the escalating complexity of smart city environments by proposing the use of Quantum Fuzzy Inference Engine (QFIE) for enhanced control. Smart cities play a pivotal role in optimizing resource utilization and improving overall urban living. However, their intricate and interconnected nature demands advanced control algorithms. QFIE emerges as a promising solution due to its computational power and capability to handle uncertainty. In this research, the suitability of QFIE for the control of smart city environments is assessed for the very first time by the design and test of three different QFIE-based fuzzy rule base systems aiming to solve the problem of computing the average localization error in wireless sensor networks, the prediction of heating demands in buildings, and the control of traffic lights in a junction. In these scenarios, the experimental evaluation of QFIE shows improved control capability compared with classical algorithms.",IEEE
V. S. Dhaka; V. Lamba; Anubhav; D. Pathania,"Application layer proxy detection, prevention with predicted load optimization",2016,10.1109/ICRAIE.2016.7939513,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7939513,Conference Paper,2016 International Conference on Recent Advances and Innovations in Engineering (ICRAIE),"In this paper, we have formulated a solution for proxy usages in a network. We all are surrounded with digital signatures around us, we just need to filter those to make our network clean, secure, efficient. Is what we did in this research work. There is also a great need of load optimization at different points in the network. We have proposed a way to use machine learning and neural networks to apply it on a network. Our basic approach to do this work is a time quantum analysis for load prediction over a network and digital signature validation for proxy detection at the application layer. There are many methods to detect network statistics and security at different layers, but we need real-time analysis in the network and prevention measure right before it happens.",IEEE
S. D. Matteo; I. Sarno; S. Saponara,CRYPHTOR: A Memory-Unified NTT-Based Hardware Accelerator for Post-Quantum CRYSTALS Algorithms,2024,10.1109/ACCESS.2024.3367109,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10439161,Journal,IEEE Access,"This paper presents the design and FPGA implementation of a hardware accelerator for the Post-Quantum CRYSTALS-Kyber and CRYSTALS-Dilithium algorithms, named CRYPHTOR (CRYstals Polynomial HW acceleraTOR). The proposed architecture includes a unified memory arrangement and dedicated ALUs for Kyber and Dilithium, capable of accelerating several polynomial operations such as Number Theoretic Transform (NTT), Inverse NTT, Coefficient-Wise Multiplication (CWM), modular addition and subtraction, modular reduction, and the multiply-accumulate operation. CRYPHTOR has been integrated into two SoCs: one based on a 64-bit RISC-V processor and the other on a 32-bit RISC-V microcontroller. In these configurations, up to 26x and 300x of speedup has been obtained for the NTT, and up to 30x and 140x of speedup for the matrix-vector multiplication compared to the software implementation running on the RISC-V processors.","IEEE, Web of Science"
Y. Cao; Y. Wu; L. Qin; S. Chen; C. -H. Chang,"Area, Time and Energy Efficient Multicore Hardware Accelerators for Extended Merkle Signature Scheme",2022,10.1109/TCSI.2022.3200987,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9869764,Journal,IEEE Transactions on Circuits and Systems I: Regular Papers,"This paper addresses a barrier that prevents the timely adoption of post-quantum signature algorithms, such as the eXtended Merkle Signature Scheme (XMSS), due to its lack of fast, cost-effective and energy-efficient hardware accelerators. Two new architectures that use more than one hash core are proposed for the first time to significantly reduce the latency of two bottleneck XMSS operations, namely key generation and signature generation, for which the speed of existing hardware accelerators is still apparently inadequate. The first proposed multi-core design uses block RAM and a simplified data flow to maximize the use of  $p$  hash cores concurrently in three major sequential stages of computation, i. e., Winternitz One-time Signature (WOTS), L-tree and Merkle tree. The second proposed multi-core design adds a dedicated hash core for tree hashing in the L-tree and Merkle tree while keeping the  $p$  hash cores solely for chain hashing in WOTS. The dedicated hash core leapfrogs between the L-tree and Merkle tree and computes concurrently with the  $p$  hash cores to keep the  $p+1$  hash cores active most of the time while minimizing the storage requirement and energy consumption. Both designs are implemented on a 28 nm ATRIX-7 FPGA chip. Experimental results show that both proposed accelerators with  $p=8$  operate at a much faster speed and consume significantly less hardware resources and energy than all existing XMSS accelerators. Specifically, they are  $\sim 8\times $  and  $\sim 6\times $  faster than the fastest reported design in key generation and signature generation operations, respectively.",IEEE
Y. Zhao; W. Yang; Y. Wang; L. Yang,Communicate and Control System for Planar Single-Axis Photovoltaic Array Clusters in Complex Terrain,2024,10.1109/ICSPCC62635.2024.10770446,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10770446,Conference Paper,"2024 IEEE International Conference on Signal Processing, Communications and Computing (ICSPCC)","In the current discourse on renewable energy, photovoltaic (PV) technology surfaces as a keystone in the sustainable energy portfolio. However, the efficiency of PV systems is often compromised by geographical and temporal challenges, specifically in undulating terrains where shadowing can markedly degrade output. Addressing this, we introduce the Dynamic Adaptive Posture Adjustment Control for Photovoltaic Cluster Systems (DAPAC-PVCS), a novel system engineered to dynamically modulate the orientation of PV panels in real-time. Through an adept fusion of hardware innovation and evolutionary computation algorithms, DAPAC-PVCS transcends traditional fixed installations by counteracting shadowing effects and optimizing energy capture. Computational analyses authenticate that this avant-garde control system significantly surmounts the efficiency benchmarks of extant models, heralding a 1.5 % amplification in annual power generation. Our contribution marks a quantum leap in PV technology, poised to enhance the viability of solar farms in topographically complex regions and bolster the shift towards renewable energy paradigms.",IEEE
Z. Wang; X. Dong; H. Chen; Y. Kang,Efficient GPU Implementations of Post-Quantum Signature XMSS,2023,10.1109/TPDS.2022.3233348,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10004747,Journal,IEEE Transactions on Parallel and Distributed Systems,"The National Institute of Standards and Technology (NIST) approved XMSS as part of the post-quantum cryptography (PQC) development effort in 2018. XMSS is currently one of only two standardized PQC algorithms, but its performance limits its use. For example, the fastest record for some standardized parameters still takes more than a minute to generate a keypair. In this article, we present the first GPU implementation for XMSS and its variant XMSS$^{\mathsf {MT}}$MT. The high parallelism of GPUs is especially effective for reducing latency in key generation and improving throughput for signing and verifying. In order to meet various application scenarios, we provide three parallel XMSS schemes: algorithmic parallelism, multi-keypair data parallelism, and single-keypair data parallelism. For these schemes, we design custom parallel strategies that use more than 10,000 cores for all parameters provided by NIST. In addition, we analyze the availability of most previous serial optimizations and explore numerous techniques to fully exploit GPU performance. Our evaluations are made with the XMSSMT-SHA2_20/2_256 parameter set on a GeForce RTX 3090. The result shows the key generation latency is 3.20 ms, a speedup of 21,899¡Á compared to the GPU ported version, which is also 54¡Á speedup faster than the fastest work (174 ms). When 16384 tasks are executed, the throughput (task/s) for signing/verifying in the single-key and multi-key cases is 311,424/415,100 and 145,100/419,887, respectively. Compared to the throughput for signing/verifying (1695/4000) of the fastest work, we obtain a speedup of 184¡Á/104¡Á and 86¡Á/105¡Á in single-key and multi-key cases, respectively.",IEEE
R. Loredo; F. Saeed,Q-CASA Invited Speakers Quantum-Centric Supercomputing Strategies for Neuroscience problems: Challenges and Progress,2023,10.1109/IPDPSW59300.2023.00087,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10196599,Conference Paper,2023 IEEE International Parallel and Distributed Processing Symposium Workshops (IPDPSW),"For decades high-performance computing systems have allowed researchers, scientists and engineers to solve complex data- and compute-intensive problems. These parallel and distributed computing systems provided researchers to develop state of the art solutions in areas such as machine learning, health, and life science. While successful for a large number of problems, these systems face limitations when handling intractable problems which require either an enormous number of resources (i.e. number of bits, or power) or time to solve a problem (i.e. factoring integers). In this work we describe how quantum computers can enhance these systems by incorporating quantum computational principles to create a quantum-centric supercomputer. Recent developments include quantum middleware, error mitigation, and error suppression techniques to curtail these issues in near-term quantum devices and enable researchers to create quantum useful applications without having to wait for full fault-tolerant quantum computers. We also give an overview of dynamic circuits, circuit knitting, and various error suppression techniques recently developed to help minimize noise and execute quantum circuits on multiple quantum systems. Our preliminary work shows recent challenges and advancements in quantum-centric supercomputing when trying to solve neuroscience problems. We focus on functional MRI (fMRI) and diffusion MRI problems related to mental health and the potential areas where quantum computers can alleviate some of these challenges. We also present preliminary solutions to connectomics, tractography, and brain network analysis that can be used to help researchers identify neurodegenerative diseases or injuries.",IEEE
Wang Y.; Li K.; Han Y.; Yan X.,Distributed multi-UAV cooperation for dynamic target tracking optimized by an SAQPSO algorithm,2022,10.1016/j.isatra.2021.12.014,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85122086191&doi=10.1016%2fj.isatra.2021.12.014&partnerID=40&md5=53e7d5599abb0a6cdd6f85b5a9347063,Article,ISA Transactions,"Real-time tracking of the dynamic intrusion targets consists of two crucial factors: the path forecast of the target and real-time path optimization of multi-UAV target tracking. For the first one, the uncertainty of the target trajectory is an obstacle to realizing real-time tracking. Thus a trajectory prediction method is proposed in this paper to ensure the sampling period of the target. Owing to the poor prediction accuracy of the single-step trajectory, a multi-step Unscented Kalman Filter (MUKF) is proposed to forecast its multi-step trajectory further in different regions. For the second one, there are two problems: poor optimization accuracy of the tracking trajectory and larger local optimization deviation, which will cause failure of the regional tracking. Under this circumstance, a hybrid algorithm called SAQPSO is proposed, combining the specific mechanism of two intelligence algorithms. The annealing mechanism in the Simulated Annealing (SA) algorithm is used to modify the Quantum Particle Swarm Optimization (QPSO) algorithm. Then the characteristic of quantum particles is used to update the population and enhance global searchability. Furthermore, to testify the effectiveness of the trajectory optimization algorithm and related target prediction method, a specific simulation environment is given as an example, in which the tracking trajectories of eight different algorithms are compared. Simulation results show the effectiveness of the proposed algorithm. ? 2021 ISA",Scopus
Soh Y.S.; Varvitsiotis A.,A Non-commutative Extension of Lee-Seung's Algorithm for Positive Semidefinite Factorizations,2021,10.48550/arXiv.2106.00293,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85131856186&partnerID=40&md5=8782cd27d1c3b4da2a50546a2148462c,Conference Paper,Advances in Neural Information Processing Systems,"Given a data matrix X ¡Ê Rm+¡Án with non-negative entries, a Positive Semidefinite (PSD) factorization of X is a collection of r ¡Á r-dimensional PSD matrices {Ai} and {Bj} satisfying the condition Xij = tr(AiBj) for all i ¡Ê [m], j ¡Ê [n]. PSD factorizations are fundamentally linked to understanding the expressiveness of semidefinite programs as well as the power and limitations of quantum resources in information theory. The PSD factorization task generalizes the Nonnegative Matrix Factorization (NMF) problem in which we seek a collection of r-dimensional non-negative vectors {ai} and {bj} satisfying Xij = aTi bj, for all i ¡Ê [m], j ¡Ê [n] - one can recover the latter problem by choosing matrices in the PSD factorization to be diagonal. The most widely used algorithm for computing NMFs of a matrix is the Multiplicative Update algorithm developed by Lee and Seung, in which non-negativity of the updates is preserved by scaling with positive diagonal matrices. In this paper, we describe a non-commutative extension of Lee-Seung's algorithm, which we call the Matrix Multiplicative Update (MMU) algorithm, for computing PSD factorizations. The MMU algorithm ensures that updates remain PSD by congruence scaling with the matrix geometric mean of appropriate PSD matrices, and it retains the simplicity of implementation that the multiplicative update algorithm for NMF enjoys. Building on the Majorization-Minimization framework, we show that under our update scheme the squared loss objective is non-increasing and fixed points correspond to critical points. The analysis relies on Lieb's Concavity Theorem. Beyond PSD factorizations, we show that the MMU algorithm can be also used as a primitive to calculate block-diagonal PSD factorizations and tensor PSD factorizations. We demonstrate the utility of our method with experiments on real and synthetic data. ? 2021 Neural information processing systems foundation. All rights reserved.",Scopus
Sasdelli M.; Chin T.-J.,Quantum Annealing Formulation for Binary Neural Networks,2021,10.1109/DICTA52665.2021.9647321,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85123682283&doi=10.1109%2fDICTA52665.2021.9647321&partnerID=40&md5=17d3813177cdfc94e75f6bd85286c21e,Conference Paper,DICTA 2021 - 2021 International Conference on Digital Image Computing: Techniques and Applications,"Quantum annealing is a promising paradigm for building practical quantum computers. Compared to other approaches, quantum annealing technology has been scaled up to a larger number of qubits. On the other hand, deep learning has been profoundly successful in pushing the boundaries of AI. It is thus natural to investigate potentially game changing technologies such as quantum annealers to augment the capabilities of deep learning. In this work, we explore binary neural networks, which are lightweight yet powerful models typically intended for resource constrained devices. Departing from current training regimes for binary networks that smooth/approximate the activation functions to make the network differentiable, we devise a quadratic unconstrained binary optimization formulation for the training problem. While the problem is intractable, i.e., the cost to estimate the binary weights scales exponentially with network size, we show how the problem can be optimized directly on a quantum annealer, thereby opening up to the potential gains of quantum computing. We experimentally validated our formulation via simulation and testing on an actual quantum annealer (D-Wave Advantage), the latter to the extent allowable by the capacity of current technology. ? 2021 IEEE.",Scopus
Stein S.A.; Baheri B.; Chen D.; Mao Y.; Guan Q.; Li A.; Fang B.; Xu S.,QuGAN: A Quantum State Fidelity based Generative Adversarial Network,2021,10.1109/QCE52317.2021.00023,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85121590635&doi=10.1109%2fQCE52317.2021.00023&partnerID=40&md5=c50959c4aa7314db94e5283af45393b9,Conference Paper,"Proceedings - 2021 IEEE International Conference on Quantum Computing and Engineering, QCE 2021","Tremendous progress has been witnessed in artificial intelligence where neural network backed deep learning systems have been used, with applications in almost every domain. As a representative deep learning framework, Generative Adversarial Network (GAN) has been widely used for generating artificial images, text-to-image or image augmentation across areas of science, arts and video games. However, GANs are computationally expensive, sometimes computationally prohibitive. Furthermore, training GANs may suffer from convergence failure and modal collapse. Aiming at the acceleration of use cases for practical quantum computers, we propose QuGAN, a quantum GAN architecture that provides stable convergence, quantum-states based gradients and significantly reduced parameter sets. The QuGAN architecture runs both the discriminator and the generator purely on quantum state fidelity and utilizes the swap test on qubits to calculate the values of quantum-based loss functions. Built on quantum layers, QuGAN achieves similar performance with a 94.98% reduction on the parameter set when compared to classical GANs. With the same number of parameters, additionally, QuGAN outperforms state-of-the-art quantum based GANs in the literature providing a 48.33% improvement in system performance compared to others attaining less than 0.5% in terms of similarity between generated distributions and original data sets. QuGAN code is released at https://github.com/yingmao/Quantum-Generative-Adversarial-Network  ? 2021 IEEE.",Scopus
Anitha C.; Balakiruthiga B.; Angayarkanni S.A.; Pandi selvi P.; Sathish Kumar L.,"Recent developments, application cases, and lingering issues on the path to a 6G IoT",2023,10.1109/RMKMATE59243.2023.10368882,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85183570773&doi=10.1109%2fRMKMATE59243.2023.10368882&partnerID=40&md5=a26c86686f7ba7753f834018e0896760,Conference Paper,"2023 IEEE International Conference on Research Methodologies in Knowledge Management, Artificial Intelligence and Telecommunication Engineering, RMKMATE 2023","The growing demand for wireless communication networks (WSN) has resulted in a rise in the importance of intelligent services that depend on the Internet of Everything (IoE). An assessment of Wireless Sensor Networks (WSN) that incorporates enhanced capabilities and state-of-the-art communication technologies is necessary. Although 5G connections show potential for facilitating various IoE-based assistance applications, they may not be adequate to fulfil all the requirements of emerging intelligent applications. The current limitations of 5G connections have resulted in an increased demand for the conceptualization of Sixth Generation (6G) Wireless Sensor Networks (WSN) as a potential solution. The integration of artificial intelligence (AI) into the 6G network will provide resolutions for complex issues related to network optimisation. Furthermore, researchers are currently investigating novel techniques such as terahertz and quantum networks to augment the capabilities of forthcoming 6G networks. The forthcoming 6G wireless network is required to fulfil the requirements of accommodating a vast number of users and data-centric applications. This article stands out from prior works by presenting a comprehensive review of the most recent advancements in 6G networking, encompassing network prerequisites and significant enabling technologies. Furthermore, the article provides a thorough analysis of use cases, comparing the functionalities of 5G and 6G systems. The objective of these solutions is to address the requirements of intelligent communities. This article presents an overview of potential research directions for the development of IoT networks using 6G technology. ? 2023 IEEE.",Scopus
Sirra K.K.; Mogalla S.; Madhuri K.B.,CSSLnO: Cat Swarm Sea Lion Optimization-based deep learning for fake news detection from social media,2024,10.1007/s41870-024-01943-6,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85197676253&doi=10.1007%2fs41870-024-01943-6&partnerID=40&md5=d4790e3c4053ed7601f1be9d86891e5d,Article,International Journal of Information Technology (Singapore),"Social media has effectively shortened the time for the distribution of information, which sometimes carry news when compared to traditional methods. The convenience and affordable instant access to data with revolution in mobile technology have directed the production of false news. Fake news has the potential to mobilize public opinion, causing social unrest. Therefore, it is essential to check the authenticity and credibility of news articles being shared on social media. Moreover, versions of fake news are very similar to the actual ones, so it is problematic for humans to recognize them. Therefore, Fake news identification from social media become an Artificial Intelligence (AI) problem. A Cat Swarm Sea Lion Optimization (CSSLnO)-based Deep Quantum Neural Network (DQNN) is developed in this research for detecting fake news. The input is effectively acquired from different websites, such as Twitter and Facebook. Various unique features are extracted from FakeNewsNet and BuzzFeed-Webis Fake News Corpus for the effective fake news detection process. DQNN is applied for identifying fake news using the extracted features. The authors developed an optimization algorithm named CSSLnO and employed it to further train the DQNN model to increase the detection performance. The developed model outperformed the other existing fake news detection techniques with improved accuracy, sensitivity, specificity, and F-measure of 90.65, 91.90, 89.09, and 91.46%. ? Bharati Vidyapeeth's Institute of Computer Applications and Management 2024.",Scopus
Li Z.; Xiao T.; Deng X.; Zeng G.; Li W.,Optimizing Variational Quantum Neural Networks Based on Collective Intelligence,2024,10.3390/math12111627,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85195784974&doi=10.3390%2fmath12111627&partnerID=40&md5=aa04bc3c75187a8cd9647d641465f8e0,Article,Mathematics,"Quantum machine learning stands out as one of the most promising applications of quantum computing, widely believed to possess potential quantum advantages. In the era of noisy intermediate-scale quantum, the scale and quality of quantum computers are limited, and quantum algorithms based on fault-tolerant quantum computing paradigms cannot be experimentally verified in the short term. The variational quantum algorithm design paradigm can better adapt to the practical characteristics of noisy quantum hardware and is currently one of the most promising solutions. However, variational quantum algorithms, due to their highly entangled nature, encounter the phenomenon known as the ¡°barren plateau¡± during the optimization and training processes, making effective optimization challenging. This paper addresses this challenging issue by researching a variational quantum neural network optimization method based on collective intelligence algorithms. The aim is to overcome optimization difficulties encountered by traditional methods such as gradient descent. We study two typical applications of using quantum neural networks: random 2D Hamiltonian ground state solving and quantum phase recognition. We find that the collective intelligence algorithm shows a better optimization compared to gradient descent. The solution accuracy of ground energy and phase classification is enhanced, and the optimization iterations are also reduced. We highlight that the collective intelligence algorithm has great potential in tackling the optimization of variational quantum algorithms. ? 2024 by the authors.",Scopus
Zhang J.; Xia K.; He Z.; Fan S.,Dynamic Multi-Swarm Differential Learning Quantum Bird Swarm Algorithm and Its Application in Random Forest Classification Model,2020,10.1155/2020/6858541,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85089771121&doi=10.1155%2f2020%2f6858541&partnerID=40&md5=be24440bec5a49e6f80cc8df77b6ce6d,Article,Computational Intelligence and Neuroscience,"Bird swarm algorithm is one of the swarm intelligence algorithms proposed recently. However, the original bird swarm algorithm has some drawbacks, such as easy to fall into local optimum and slow convergence speed. To overcome these short-comings, a dynamic multi-swarm differential learning quantum bird swarm algorithm which combines three hybrid strategies was established. First, establishing a dynamic multi-swarm bird swarm algorithm and the differential evolution strategy was adopted to enhance the randomness of the foraging behavior's movement, which can make the bird swarm algorithm have a stronger global exploration capability. Next, quantum behavior was introduced into the bird swarm algorithm for more efficient search solution space. Then, the improved bird swarm algorithm is used to optimize the number of decision trees and the number of predictor variables on the random forest classification model. In the experiment, the 18 benchmark functions, 30 CEC2014 functions, and the 8 UCI datasets are tested to show that the improved algorithm and model are very competitive and outperform the other algorithms and models. Finally, the effective random forest classification model was applied to actual oil logging prediction. As the experimental results show, the three strategies can significantly boost the performance of the bird swarm algorithm and the proposed learning scheme can guarantee a more stable random forest classification model with higher accuracy and efficiency compared to others.  ? 2020 Jiangnan Zhang et al.",Scopus
Ullah A.; Dral P.O.,MLQD: A package for machine learning-based quantum dissipative dynamics,2024,10.1016/j.cpc.2023.108940,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85173508593&doi=10.1016%2fj.cpc.2023.108940&partnerID=40&md5=f0cc0f1418407b82e6468651d60b09ee,Article,Computer Physics Communications,"Machine learning has emerged as a promising paradigm to study the quantum dissipative dynamics of open quantum systems. To facilitate the use of our recently published ML-based approaches for quantum dissipative dynamics, here we present an open-source Python package MLQD (https://github.com/Arif-PhyChem/MLQD), which currently supports the three ML-based quantum dynamics approaches: (1) the recursive dynamics with kernel ridge regression (KRR) method, (2) the non-recursive artificial-intelligence-based quantum dynamics (AIQD) approach and (3) the blazingly fast one-shot trajectory learning (OSTL) approach, where both AIQD and OSTL use the convolutional neural networks (CNN). This paper describes the features of the MLQD package, the technical details, optimization of hyperparameters, visualization of results, and the demonstration of the MLQD's applicability for two widely studied systems, namely the spin-boson model and the Fenna¨CMatthews¨COlson (FMO) complex. To make MLQD more user-friendly and accessible, we have made it available on the Python Package Index (PyPi) platform and it can be installed via [Formula presented]. In addition, it is also available on the XACS cloud computing platform (https://XACScloud.com) via the interface to the MLATOM package (http://MLatom.com). Program summary: Program Title: MLQD CPC Library link to program files: https://doi.org/10.17632/yxp37csy5x.1 Developer's repository link: https://github.com/Arif-PhyChem/MLQD Code Ocean capsule: https://codeocean.com/capsule/5563143/tree Licensing provisions: Apache Software License 2.0 Programming language: Python 3.0 Supplementary material: Jupyter Notebook-based tutorials External routines/libraries: Tensorflow, Scikit-learn, Hyperopt, Matplotlib, MLatom Nature of problem: Fast propagation of quantum dissipative dynamics with machine learning approaches. Solution method: We have developed MLQD as a comprehensive framework that streamlines and supports the implementation of our recently published machine learning-based approaches for efficient propagation of quantum dissipative dynamics. This framework encompasses: (1) the recursive dynamics with kernel ridge regression (KRR) method, as well as the non-recursive approaches utilizing convolutional neural networks (CNN), namely (2) artificial intelligence-based quantum dynamics (AIQD), and (3) one-shot trajectory learning (OSTL). Additional comments including restrictions and unusual features: 1. Users can train a machine learning (ML) model following one of the ML-based approaches: KRR, AIQD and OSTL. 2. Users have the option to propagate dynamics with the existing trained ML models. 3. MLQD also provides the transformation of trajectories into the training data. 4. MLQD also supports hyperparameter optimization using MLATOM's grid search functionality for KRR and Bayesian methods with Tree-structured Parzen Estimator (TPE) for CNN models via the HYPEROPT package. 5. MLQD also facilitates the visualization of results via auto-plotting. 6. MLQD is designed to be user-friendly and easily accessible, with availability on the XACS cloud computing platform (https://XACScloud.com) via the interface to the MLATOM package (http://MLatom.com). In addition, it is also available as a pip package which makes it easy to install. Future outlook: MLQD will be extended to more realistic systems along with the incorporation of other machine learning-based approaches as well as the traditional quantum dynamics methods. ? 2023 Elsevier B.V.","Scopus, Web of Science"
Zhang Q.; Liu S.; Gong D.; Zhang H.; Tu Q.,An Improved Multi-Objective Quantum-Behaved Particle Swarm Optimization for Railway Freight Transportation Routing Design,2019,10.1109/ACCESS.2019.2948197,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85078001273&doi=10.1109%2fACCESS.2019.2948197&partnerID=40&md5=28792dbb8f6238828deb76235d4c23de,Article,IEEE Access,"With the development of railway transportation, the railway transportation enterprises expand their freight transportation from station-to-station transportation to door-to-door transportation, which makes the routing design more complicated. The existing classical optimization algorithms are difficult to meet the needs of practical applications. Therefore, the paper introduces an Improved Multi-objective Quantum-behaved Particle Swarm Optimization algorithm (IMOQPSO). Then based on the continuous coding for the Railway Freight Transportation Routing Design, the proposed improved algorithm was applied to solve the problem to verify the performance of algorithm. Finally, the paper compared the performance of Improved Multi-objective Quantum-behaved Particle Swarm Optimization algorithm with other four continuous multi-objective swarm intelligence algorithms. The results shown that the proposed algorithm obtained the best Pareto front which is closer to the real Pareto front of Railway Freight Transportation Routing Design. Hence, the proposed Improved Multi-objective Quantum-behaved Particle Swarm Optimization algorithm can provide support for the railway transport enterprises routing design decisions to some extent. ? 2013 IEEE.",Scopus
Wan J.; Ruan G.; Guo Q.; Gong X.,A new radar signal recognition method based on optimal classification atom and IDCQGA,2018,10.3390/sym10110659,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85057770922&doi=10.3390%2fsym10110659&partnerID=40&md5=629a343ef5d2f23a223be43736dae8b2,Article,Symmetry,"Radar electronic reconnaissance is an important part of modern and future electronic warfare systems and is the primary method to obtain non-cooperative intelligence information. As the task requirement of radar electronic reconnaissance, it is necessary to identify the non-cooperative signals from the mixed signals. However, with the complexity of battlefield electromagnetic environment, the performance of traditional recognition system is seriously affected. In this paper, a new recognition method based on optimal classification atom and improved double chains quantum genetic algorithm (IDCQGA) is researched, optimal classification atom is a new feature for radar signal recognition, IDCQGA with symmetric coding performance can be applied to the global optimization algorithm. The main contributions of this paper are as follows: Firstly, in order to measure the difference of multi-class signals, signal separation degree based on distance criterion is proposed and established according to the inter-class separability and intra-class aggregation of the signals. Then, an IDCQGA is proposed to select the best atom for classification under the constraint of distance criterion, and the inner product of the signal and the best atom for classification is taken as the eigenvector. Finally, the extreme learning machine (ELM) is introduced as classifier to complete the recognition of signals. Simulation results show that the proposed method can improve the recognition rate of multi-class signals and has better processing ability for overlapping eigenvector parameters. ? 2018 by the authors.",Scopus
Chen J.; Qi X.; Chen L.; Chen F.; Cheng G.,Quantum-inspired ant lion optimized hybrid k-means for cluster analysis and intrusion detection,2020,10.1016/j.knosys.2020.106167,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85086822458&doi=10.1016%2fj.knosys.2020.106167&partnerID=40&md5=425797a220391253ce02bb3871e82212,Article,Knowledge-Based Systems,"Intrusion detection maintains network security by detecting intrusion behaviors. There are many clustering algorithms that can be used directly for intrusion detection. K-means is a simple and efficient method used in data clustering. However, k-means has a tendency to converge to local optima and depends on the initial value of cluster centers. Therefore, we present an efficient hybrid clustering algorithm referred to as QALO-K, whereby, we combine k-means with quantum-inspired ant lion optimized. This algorithm combines the advantages of quantum computing and swarm intelligence algorithms to improve the k-means algorithm and make the k-means algorithm converge towards the global optimal direction. Our proposed algorithm is tested on several standard datasets from UCI Machine Learning Repository for cluster analysis and its performance is compared with other well-known algorithms. The proposed method was applied on KDD Cup 99 large datasets for intrusion detection. The simulation results infer that the proposed algorithms can be efficiently used for data clustering and intrusion detection. ? 2020 Elsevier B.V.",Scopus
Fahad S.; Khan S.A.; Yang S.; Khan S.U.; Tahir M.; Salman M.,Optimizing Multi-Modal Electromagnetic Design Problems Using Quantum Particle Swarm Optimization With Differential Evolution,2023,10.1109/ACCESS.2023.3312567,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85171554418&doi=10.1109%2fACCESS.2023.3312567&partnerID=40&md5=78a96e7ce30b29b48b735d175112515d,Article,IEEE Access,"Many versatile and promising swarm intelligence evolutionary algorithms are being developed to solve engineering optimization problems. Although evolutionary algorithms have been implemented in various optimization fields, there is still potential for enhancement in the domain of complex, electromagnetic, and multimodal objective problems. To effectively address the shortcomings and slow convergence speed observed in both smart quantum particle swarm optimization (QPSO) and differential evolution (DE), a hybrid strategy is proposed. In the proposed QPSODE, apart from the smart strategy of QPSO for improving the exploration as a whole, more additional features such as non-linear adaptive control parameter, the partition of the swarm to apply smart and gaussian mutation mechanism, crossover and selection of best particle using Boltzmann strategy to avoid premature convergence are introduced. Consequently, applying the new design algorithm to several benchmark-constrained, mostly non-convex, and superconducting magnetic energy storage (SMES) electromagnetic problems shows a marked performance improvement. The performances of the QPSODE is compared with those of many other widely recognized population-based swarm intelligence optimizers. Experimental results and statistical analysis using Friedman test show that the search accuracy and the convergence of the hybrid QPSODE strategy are advantageous over other optimization approaches. ? 2013 IEEE.",Scopus
Navaux P.O.A.; Lorenzon A.F.; Serpa M.S.,Challenges in High-Performance Computing,2023,10.5753/jbcs.2023.2219,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85169415730&doi=10.5753%2fjbcs.2023.2219&partnerID=40&md5=38e937138d633847483d190047f0e28c,Article,Journal of the Brazilian Computer Society,"High-Performance Computing, HPC, has become one of the most active computer science fields. Driven mainly by the need for high processing capabilities required by algorithms from many areas, such as Big Data, Artificial Intelligence, Data Science, and subjects related to chemistry, physics, and biology, the state-of-art algorithms from these fields are notoriously demanding computer resources. Therefore, choosing the right computer system to optimize their performance is paramount. This article presents the main challenges of future supercomputer sys-tems, highlighting the areas that demand the most of HPC servers; the new architectures, including heterogeneous processors composed of artificial intelligence chips, quantum processors, the adoption of HPC on cloud servers; and the challenges of software developers when facing parallelizing applications. We also discuss challenges regarding non-functional requirements, such as energy consumption and resilience. ? 2023, Brazilian Computing Society. All rights reserved.",Scopus
Zhu J.; Shao Z.H.; Chen C.,An improved whale optimization algorithm for job-shop scheduling based on quantum computing,2019,10.2507/IJSIMM18(3)CO13,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85076557926&doi=10.2507%2fIJSIMM18%283%29CO13&partnerID=40&md5=6cf5448e1c8717470f6f37280ba94fd3,Article,International Journal of Simulation Modelling,"The traditional swarm intelligence algorithms are inefficient and difficult to converge to the optimal solution of the job-shop scheduling problem (JSP). In this paper, an improved whale optimization algorithm (IWOA) is proposed based on quantum computing to solve the discrete JSP. The algorithm was subjected to the analysis on computing complexity, the demonstration of global convergence, and simulation verification on a benchmark example of the JSP. Through the simulation, our algorithm achieved better minimum value, mean value and optimization success rate than traditional swarm intelligence algorithms. The results prove the convergence accuracy and global search ability of the IWOA. ? 2019, DAAAM International Vienna. All rights reserved.","Scopus, Web of Science"
Tandel P.; Nasriwala J.,Secure authentication framework for IoT applications using a hash-based post-quantum signature scheme,2024,10.1007/s11761-024-00414-x,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85195885127&doi=10.1007%2fs11761-024-00414-x&partnerID=40&md5=786c5e8641a4d252b39f04800005bb72,Article,Service Oriented Computing and Applications,"In today¡¯s era, numerous applications are evolving into smart applications by leveraging technologies like the Internet of Things (IoT), Artificial Intelligence (AI), and Big Data. The incorporation of advanced sensors, AI-driven embedded devices, and cloud-based remote control has significantly enhanced the efficiency and profitability of IoT applications in numerous eras. Ensuring the security of IoT applications is crucial, with authentication emerging as a top priority. Lack of proper authentication may lead to unauthorized and risky activities, potentially causing hazardous situations within IoT applications. The current cryptographic methods employed in IoT devices rely on public-key cryptographic primitives, which, unfortunately, are susceptible to future quantum attacks. Therefore, there is a need to develop an effective signature scheme that can authenticate IoT devices resiliently against potential quantum threats. Hash-based post-quantum signature scheme stood as the best candidate to design quantum-safe authentication mechanisms. This paper presents a practical client¨Cserver implementation scenario tailored for IoT applications, showcasing the utilization of hash-based post-quantum digital signatures. Highlighting the complexity and computational demands of these signatures, the model architecture is illustrated using Raspberry Pi 3 and Pi 0 as servers, complemented by the widely used ESP32 as client devices in IoT applications achieving 32.83% optimized memory usage. ? The Author(s), under exclusive licence to Springer-Verlag London Ltd., part of Springer Nature 2024.","Scopus, Springer"
Shi Y.; Wong W.K.; Goldin J.G.; Brown M.S.; Kim G.H.J.,Prediction of progression in idiopathic pulmonary fibrosis using CT scans at baseline: A quantum particle swarm optimization - Random forest approach,2019,10.1016/j.artmed.2019.101709,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85072554565&doi=10.1016%2fj.artmed.2019.101709&partnerID=40&md5=b527a2794359f2ed9234551372477307,Article,Artificial Intelligence in Medicine,"Idiopathic pulmonary fibrosis (IPF) is a fatal lung disease characterized by an unpredictable progressive decline in lung function. Natural history of IPF is unknown and the prediction of disease progression at the time of diagnosis is notoriously difficult. High resolution computed tomography (HRCT) has been used for the diagnosis of IPF, but not generally for monitoring purpose. The objective of this work is to develop a novel predictive model for the radiological progression pattern at voxel-wise level using only baseline HRCT scans. Mainly, there are two challenges: (a) obtaining a data set of features for region of interest (ROI) on baseline HRCT scans and their follow-up status; and (b) simultaneously selecting important features from high-dimensional space, and optimizing the prediction performance. We resolved the first challenge by implementing a study design and having an expert radiologist contour ROIs at baseline scans, depending on its progression status in follow-up visits. For the second challenge, we integrated the feature selection with prediction by developing an algorithm using a wrapper method that combines quantum particle swarm optimization to select a small number of features with random forest to classify early patterns of progression. We applied our proposed algorithm to analyze anonymized HRCT images from 50 IPF subjects from a multi-center clinical trial. We showed that it yields a parsimonious model with 81.8% sensitivity, 82.2% specificity and an overall accuracy rate of 82.1% at the ROI level. These results are superior to other popular feature selections and classification methods, in that our method produces higher accuracy in prediction of progression and more balanced sensitivity and specificity with a smaller number of selected features. Our work is the first approach to show that it is possible to use only baseline HRCT scans to predict progressive ROIs at 6 months to 1year follow-ups using artificial intelligence. ? 2019 Elsevier B.V.",Scopus
Al-Jumaili S.; Al-Jumaili A.; Alyassri S.; Duru A.D.; Ucan O.N.,Recent Advances on Convolutional Architectures in Medical Applications: Classical or Quantum,2022,10.1109/ISMSIT56059.2022.9932857,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85142832734&doi=10.1109%2fISMSIT56059.2022.9932857&partnerID=40&md5=fe777145e498badb74c0ea79c7543c57,Conference Paper,"ISMSIT 2022 - 6th International Symposium on Multidisciplinary Studies and Innovative Technologies, Proceedings","Deep learning is one of the most significant advances in AI (AI). It is used in a variety of fields due to it has the ability to solve problems that cannot be handled by traditional technologies. The optimization of deep learning relevant to medical images is one of the most important recent advances in image analysis. Several developments have been done on Convolutional Neural Networks to achieve optimal accuracy and increase the learning speed. However, in this paper, we discuss the most recent innovations in convolutional neural networks within Classical method and Quantum method. We briefly provide a snapshot about the architecture, improvements, and principles of both (Classical and Quantum).  ? 2022 IEEE.",Scopus
Liu P.; Y¨¹ksel S.; Din?er H.; Olaru G.O.,Artificial Intelligence-Based Expert Prioritizing and Hybrid Quantum Picture Fuzzy Rough Sets for Investment Decisions of Virtual Energy Market in the Metaverse,2024,10.1007/s40815-024-01716-0,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85190765671&doi=10.1007%2fs40815-024-01716-0&partnerID=40&md5=2663c5a183145dd3927b6984c3ab6cdf,Article,International Journal of Fuzzy Systems,"Improvements are necessary for the performance improvements of the digital twin technology developed for the virtual energy market on the Metaverse platform. However, more important factors need to be improved first to avoid excessive increases in costs. Thus, a priority analysis needs to be carried out to determine the variables that most affect the performance of technology investments. Accordingly, the purpose of this study is to evaluate the investments of digital twin technologies for virtual energy market in the Metaverse. A novel artificial intelligence-based fuzzy decision-making model is constructed to reach this objective. Firstly, the expert choices are prioritized with artificial intelligence-based decision-making method. Secondly, the investment priorities are analyzed for digital twin technologies with quantum picture fuzzy rough sets (QPFRS)-based Multi Stepwise Weight Assessment Ratio Analysis (M-SWARA). Finally, the alternatives for virtual energy market in the metaverse are ranked by VIKOR (VIsekriterijumska optimizacija i KOmpromisno Resenje). There are limited studies in the literature that computes the weights of the experts while generating a decision-making model. Therefore, the main contribution of this study is integrating the artificial intelligence approach and fuzzy multi-criteria decision-making methodology. Within this scope, an artificial intelligence-based application is performed when creating the decision matrix. Owing to this issue, the importance weights of experts are determined according to the qualifications of these people. This situation contributes to the results obtained being more realistic. The findings demonstrate that operational performance is the most important indicator for the improvements of the digital twin technology investments for virtual energy markets in metaverse platform because it has the greatest weight (0.267). Furthermore, integrated data production is another critical factor for the performance increase of these projects with the weight of 0.257. It is also concluded that optimization of energy consumption with smart grids has the best ranking performance among the alternatives. ? The Author(s) under exclusive licence to Taiwan Fuzzy Systems Association 2024.",Scopus
Andr¨¦s E.; Cu¨¦llar M.P.; Navarro G.,Brain-Inspired Agents for Quantum Reinforcement Learning,2024,10.3390/math12081230,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85191413543&doi=10.3390%2fmath12081230&partnerID=40&md5=6d33d8b910a82688608a99594ed5fb05,Article,Mathematics,"In recent years, advancements in brain science and neuroscience have significantly influenced the field of computer science, particularly in the domain of reinforcement learning (RL). Drawing insights from neurobiology and neuropsychology, researchers have leveraged these findings to develop novel mechanisms for understanding intelligent decision-making processes in the brain. Concurrently, the emergence of quantum computing has opened new frontiers in artificial intelligence, leading to the development of quantum machine learning (QML). This study introduces a novel model that integrates quantum spiking neural networks (QSNN) and quantum long short-term memory (QLSTM) architectures, inspired by the complex workings of the human brain. Specifically designed for reinforcement learning tasks in energy-efficient environments, our approach progresses through two distinct stages mirroring sensory and memory systems. In the initial stage, analogous to the brain¡¯s hypothalamus, low-level information is extracted to emulate sensory data processing patterns. Subsequently, resembling the hippocampus, this information is processed at a higher level, capturing and memorizing correlated patterns. We conducted a comparative analysis of our model against existing quantum models, including quantum neural networks (QNNs), QLSTM, QSNN and their classical counterparts, elucidating its unique contributions. Through empirical results, we demonstrated the effectiveness of utilizing quantum models inspired by the brain, which outperform the classical approaches and other quantum models in optimizing energy use case. Specifically, in terms of average, best and worst total reward, test reward, robustness, and learning curve. ? 2024 by the authors.",Scopus
Rani S.; Babbar H.; Kaur P.; Ali Khan A.,A novel approach of localization with single mobile anchor using quantum-based Salp swarm algorithm in wireless sensor networks,2023,10.1007/s00500-023-09261-y,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85173045071&doi=10.1007%2fs00500-023-09261-y&partnerID=40&md5=5e8f11b9f285bd96427203acad0f72fb,Article,Soft Computing,"Quantum software engineering is a field of study that combines principles from quantum computing and classical software engineering. One potential application of quantum software engineering is in the area of wireless sensor networks (WSNs), specifically in the localization of nodes. WSNs are equipped to gather information by detecting the surroundings around smart cities. Numerous applications related to Mobility in Smart Cities (MSC) struggle with routing, security, deployment, extended lifetime, data computation, and localization. Many academics have developed various Computational Intelligence-based techniques for the aforementioned problems to attain high-level performance of MSCs. Quantum software engineering can potentially enhance the accuracy and efficiency of node localization in WSNs. Node localization refers to the process used to locate the target node. Accurately determining the coordinates of static nodes is simple, but locating mobile nodes is more difficult. The performance of the MSC is directly impacted by localization accuracy. In this article, the Quantum-based Salp Swarm Algorithm (QBSSA) is implemented for a range-based and range-free framework. The performance of already existing techniques is evaluated and compared with QBSSA, such as Particle Swarm Optimization (PSO) and H-best Particle Swarm Optimization (HPSO). The mobile anchor node moves in the whole network in a Hilbert path topology and localizes the mobile targets in the network by their random deployment in the area of communication. To minimize the effect of Line of Sight propagation, the Hilbert trajectory is used. The results of the simulation demonstrate that the proposed approach can localize the mobile target with a two-fold reduction in error as opposed to PSO and a 1.5-fold reduction in error as opposed to HPSO, at the same time as the computational time is significantly reduced. ? 2023, The Author(s), under exclusive licence to Springer-Verlag GmbH Germany, part of Springer Nature.","Scopus, Web of Science,Springer"
Raikov A.N.; Pirani M.,Human-Machine Duality: What's Next in Cognitive Aspects of Artificial Intelligence?,2022,10.1109/ACCESS.2022.3177657,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85130771274&doi=10.1109%2fACCESS.2022.3177657&partnerID=40&md5=a7763452bc893a3a7657609804a20ecf,Article,IEEE Access,"The goal of the paper is to find means for the unification of human-machine duality in collective behavior of people and machines, by conciliating approaches that proceed in opposite directions. The first approach proceeds top-down from non-formalizable, cognitive, uncaused, and chaotic human consciousness towards purposeful and sustainable human-machine interaction. The second approach proceeds bottom-up from intelligent machines towards high-end computing and is based on formalizable models leveraging multi-agent architectures. The resulting work reviews the extent, the merging points, and the potential of hybrid artificial intelligence frameworks that accept the idea of strong artificial intelligence. These models concern the pairing of connectionist and cognitive architectures, conscious and unconscious actions, symbolic and conceptual realizations, emergent and brain-based computing, and automata and subjects. The special authors' convergent methodology is considered, which is based on the integration of inverse problem-solving on topological spaces, cognitive modelling, quantum field theory, category theory methods, and holonic approaches. It aims to a more purposeful and sustainable human-machine interaction in form of algorithms or requirements, rules of strategic conversations or network brainstorming, and cognitive semantics. The paper addresses the reduction of the impact of AI development on ethics violation. The findings delivered are used to provide perspectives on the shaping of societal, ethical, and normative aspects in the symbiosis between humans and machines. Implementations in real practice are represented.  ? 2013 IEEE.",Scopus
Delgado F.; Cardoso-Isidoro C.,Non-Local Parallel Processing and Database Settlement Using Multiple Teleportation Followed by Grover Post-Selection,2023,10.3390/e25020376,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85148959391&doi=10.3390%2fe25020376&partnerID=40&md5=60b53049b01efd93d0fb0a2e82f3c4d5,Article,Entropy,"Quantum information applications emerged decades ago, initially introducing a parallel development that mimicked the approach and development of classical computer science. However, in the current decade, novel computer-science concepts were rapidly extended to the fields of quantum processing, computation, and communication. Thus, areas such as artificial intelligence, machine learning, and neural networks have their quantum versions; furthermore, the quantum brain properties of learning, analyzing, and gaining knowledge are discussed. Quantum properties of matter conglomerates have been superficially explored in such terrain; however, the settlement of organized quantum systems able to perform processing can open a new pathway in the aforementioned domains. In fact, quantum processing involves certain requisites as the settlement of copies of input information to perform differentiated processing developed far away or in situ to diversify the information stored there. Both tasks at the end provide a database of outcomes with which to perform either information matching or final global processing with at least a subset of those outcomes. When the number of processing operations and input information copies is large, parallel processing (a natural feature in quantum computation due to the superposition) becomes the most convenient approach to accelerate the database settlement of outcomes, thus affording a time advantage. In the current study, we explored certain quantum features to realize a speed-up model for the entire task of processing based on a common information input to be processed, diversified, and finally summarized to gain knowledge, either in pattern matching or global information availability. By using superposition and non-local properties, the most valuable features of quantum systems, we realized parallel local processing to set a large database of outcomes and subsequently used post-selection to perform an ending global processing or a matching of information incoming from outside. We finally analyzed the details of the entire procedure, including its affordability and performance. The quantum circuit implementation, along with tentative applications, were also discussed. Such a model could be operated between large processing technological systems using communication procedures and also on a moderately controlled quantum matter conglomerate. Certain interesting technical aspects involving the non-local control of processing via entanglement were also analyzed in detail as an associated but notable premise. ? 2023 by the authors.",Scopus
Bhutoria A.,"Personalized education and Artificial Intelligence in the United States, China, and India: A systematic review using a Human-In-The-Loop model",2022,10.1016/j.caeai.2022.100068,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85129965168&doi=10.1016%2fj.caeai.2022.100068&partnerID=40&md5=2a4c7ce3bd94218ff3b4a469d6943cb7,Article,Computers and Education: Artificial Intelligence,"The traditional ¡°one size fits all¡± education system has been largely criticized in recent years on the ground of its lacking the capacity to meet individual student needs. Global education systems are leaning towards a more personalized, student-centered approach. Innovations like Big Data, Machine Learning, and Artificial Intelligence (AI) have given the modern-day technology to accommodate the distinctive features of human beings - smart machines and computers have been built to understand individual-specific needs. This opens an avenue for ¡°personalization¡± in the education sector. From, mushrooming of Education Technology (EdTech) start-ups to government funding in AI research, it is evident that the next generation educational reforms would take a quantum leap forward piloted by Big Data analysis and AI. The objective of this paper is to organize the vast literature on the use of AI for personalization of education and to shed light on the key themes by which an AI-driven approach makes structural modifications to the existing education system. To this effect, the paper employed a systematic review using a Human-In-The-Loop natural language processing model of past two years' literature (2019¨C2021) in English language from IEEE Xplore on countries China, India and the USA. This process yielded more than 2000 search results at first and these were eventually shortlisted to 353 relevant papers for in-depth analysis. Being the pioneers in EdTech innovations, insights from research done in these three countries provides valuable input for the development of global education systems and research. The findings bring forward AI's success in catering to specific learning requirements, learning habits, and learning abilities of students and guiding them into optimized learning paths across all three countries. Not just that, it is also evident from the literature that AI augments educational content, customizes it for any individual according to their needs, and raises the flag of caution for anticipated learning difficulties. This recalibrates the role of instructors as well as optimizes the teaching-learning environment for a better learning experience. The upward trajectory of educational development with AI opens a new horizon of personalized education for the future generation, but also comes with its challenges. Data privacy issues, availability of digital resources, and affordability constraints have been reported in the recent literature as impediments in the way of promoting such technologies for day-to-day practice. ? 2022 The Author",Scopus
Thakur A.S.; Biswas T.; Kuila P.,Binary quantum-inspired gravitational search algorithm-based multi-criteria scheduling for multi-processor computing systems,2021,10.1007/s11227-020-03292-0,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85083971856&doi=10.1007%2fs11227-020-03292-0&partnerID=40&md5=5b52a1ebe5057a4740b73a3652dc775a,Article,Journal of Supercomputing,"A quantum-inspired hybrid scheduling technique is proposed for multi-processor computing systems. The proposed algorithm is a hybridization of principles of quantum mechanics (QM) and a nature-inspired intelligence, gravitational search algorithm (GSA). The principles of QM such as quantum bit, superposition and rotation gate help to design an efficient agent representation as well as intense exploration capability of GSA enhances toward better converging rate. The fitness function is designed with the aim to minimize makespan, adequate balancing of loads and proper utilization of the deployed resources during the evaluation of agents. Several standard benchmarks as well as synthetic data sets are used to analyze and validate the work. The performance improvement of the proposed algorithm is compared with recently designed algorithms like quantum genetic algorithm, particle swarm optimization-based multi-criteria scheduling, Improved-GA, GSA and Cloudy-GSA. The significance of the algorithm is tested using a hypothesis analysis of variance. ? 2020, Springer Science+Business Media, LLC, part of Springer Nature.",Scopus
Beck T.; Baroni A.; Bennink R.; Buchs G.; P¨¦rez E.A.C.; Eisenbach M.; da Silva R.F.; Meena M.G.; Gottiparthi K.; Groszkowski P.; Humble T.S.; Landfield R.; Maheshwari K.; Oral S.; Sandoval M.A.; Shehata A.; Suh I.-S.; Zimmer C.,Integrating quantum computing resources into scientific HPC ecosystems,2024,10.1016/j.future.2024.06.058,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85197515662&doi=10.1016%2fj.future.2024.06.058&partnerID=40&md5=83ae4468b7cbf08892fe28d9a00e7716,Article,Future Generation Computer Systems,"Quantum Computing (QC) offers significant potential to enhance scientific discovery in fields such as quantum chemistry, optimization, and artificial intelligence. Yet QC faces challenges due to the noisy intermediate-scale quantum era's inherent external noise issues. This paper discusses the integration of QC as a computational accelerator within classical scientific high-performance computing (HPC) systems. By leveraging a broad spectrum of simulators and hardware technologies, we propose a hardware-agnostic framework for augmenting classical HPC with QC capabilities. Drawing on the HPC expertise of the Oak Ridge National Laboratory (ORNL) and the HPC lifecycle management of the Department of Energy (DOE), our approach focuses on the strategic incorporation of QC capabilities and acceleration into existing scientific HPC workflows. This includes detailed analyses, benchmarks, and code optimization driven by the needs of the DOE and ORNL missions. Our comprehensive framework integrates hardware, software, workflows, and user interfaces to foster a synergistic environment for quantum and classical computing research. This paper outlines plans to unlock new computational possibilities, driving forward scientific inquiry and innovation in a wide array of research domains. ? 2024 Elsevier B.V.","Scopus, Web of Science"
Akpan I.J.; Kobara Y.M.; Owolabi J.; Akpan A.A.; Offodile O.F.,Conversational and generative artificial intelligence and human¨Cchatbot interaction in education and research,2025,10.1111/itor.13522,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85200045149&doi=10.1111%2fitor.13522&partnerID=40&md5=1f9a2f05492e53b0b629495b5be716ad,Article,International Transactions in Operational Research,"Artificial intelligence (AI) as a disruptive technology is not new. However, its recent evolution, engineered by technological transformation, big data analytics, and quantum computing, produces conversational and generative AI (CGAI/GenAI) and human-like chatbots that disrupt conventional operations and methods in different fields. This study investigates the scientific landscape of CGAI and human¨Cchatbot interaction/collaboration and evaluates use cases, benefits, challenges, and policy implications for multidisciplinary education and allied industry operations. The publications trend showed that just 4% (n = 75) occurred during 2006¨C2018, while 2019¨C2023 experienced astronomical growth (n = 1763 or 96%). The prominent use cases of CGAI (e.g., ChatGPT) for teaching, learning, and research activities occurred in computer science (multidisciplinary and AI; 32%), medical/healthcare (17%), engineering (7%), and business fields (6%). The intellectual structure shows strong collaboration among eminent multidisciplinary sources in business, information systems, and other areas. The thematic structure highlights prominent CGAI use cases, including improved user experience in human¨Ccomputer interaction, computer programs/code generation, and systems creation. Widespread CGAI usefulness for teachers, researchers, and learners includes syllabi/course content generation, testing aids, and academic writing. The concerns about abuse and misuse (plagiarism, academic integrity, privacy violations) and issues about misinformation, danger of self-diagnoses, and patient privacy in medical/healthcare applications are prominent. Formulating strategies and policies to address potential CGAI challenges in teaching/learning and practice are priorities. Developing discipline-based automatic detection of GenAI contents to check abuse is proposed. In operational/operations research areas, proper CGAI/GenAI integration with modeling and decision support systems requires further studies. ? 2024 The Author(s). International Transactions in Operational Research published by John Wiley & Sons Ltd on behalf of International Federation of Operational Research Societies.","Scopus, Wiley"
Khan S.; Jiangbin Z.; Ullah F.; Akhter M.P.; Khan S.; Awwad F.A.; Ismail E.A.A.,Hybrid computing framework security in dynamic offloading for IoT-enabled smart home system,2024,10.7717/PEERJ-CS.2211,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85204307656&doi=10.7717%2fPEERJ-CS.2211&partnerID=40&md5=d083a395a641da41267f5c6fa02950ca,Article,PeerJ Computer Science,"In the distributed computing era, cloud computing has completely changed organizational operations by facilitating simple access to resources. However, the rapid development of the IoT has led to collaborative computing, which raises scalability and security challenges. To fully realize the potential of the Internet of Things (IoT) in smart home technologies, there is still a need for strong data security solutions, which are essential in dynamic offloading in conjunction with edge, fog, and cloud computing. This research on smart home challenges covers in-depth examinations of data security, privacy, processing speed, storage capacity restrictions, and analytics inside networked IoT devices. We introduce the Trusted IoT Big Data Analytics (TIBDA) framework as a comprehensive solution to reshape smart living. Our primary focus is mitigating pervasive data security and privacy issues. TIBDA incorporates robust trust mechanisms, prioritizing data privacy and reliability for secure processing and user information confidentiality within the smart home environment. We achieve this by employing a hybrid cryptosystem that combines Elliptic Curve Cryptography (ECC), Post Quantum Cryptography (PQC), and Blockchain technology (BCT) to protect user privacy and confidentiality. Additionally, we comprehensively compared four prominent Artificial Intelligence anomaly detection algorithms (Isolation Forest, Local Outlier Factor, One-Class SVM, and Elliptic Envelope). We utilized machine learning classification algorithms (random forest, k-nearest neighbors, support vector machines, linear discriminant analysis, and quadratic discriminant analysis) for detecting malicious and non-malicious activities in smart home systems. Furthermore, the main part of the research is with the help of an artificial neural network (ANN) dynamic algorithm; the TIBDA framework designs a hybrid computing system that integrates edge, fog, and cloud architecture and efficiently supports numerous users while processing data from IoT devices in real-time. The analysis shows that TIBDA outperforms these systems significantly across various metrics. In terms of response time, TIBDA demonstrated a reduction of 10¨C20% compared to the other systems under varying user loads, device counts, and transaction volumes. Regarding security, TIBDA¡¯s AUC values were consistently higher by 5¨C15%, indicating superior protection against threats. Additionally, TIBDA exhibited the highest trustworthiness with an uptime percentage 10¨C12% greater than its competitors. TIBDA¡¯s Isolation Forest algorithm achieved an accuracy of 99.30%, and the random forest algorithm achieved an accuracy of 94.70%, outperforming other methods by 8¨C11%. Furthermore, our ANN-based offloading decision-making model achieved a validation accuracy of 99% and reduced loss to 0.11, demonstrating significant improvements in resource utilization and system performance. Copyright 2024 Khan et al.","Scopus, Web of Science"
Zhao X.; Jiang Y.,Synchronously Improving Multi-user English Translation Ability by Using AI,2022,10.1142/S0218213022400073,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85133133667&doi=10.1142%2fS0218213022400073&partnerID=40&md5=c224646e16b704aeb0a9533b8bf25d14,Article,International Journal on Artificial Intelligence Tools,"English has become the most widely used language in the world. Everything we do in study, life and work is closely linked with English. With the continuous development of computer technology, machine translation is becoming more and more mature. The convergence of Artificial Intelligence (AI) and language learning is getting increasingly close, which brings great impact and challenge to the language education industry, but also provides an opportunity for the synchronous promotion of the development of the language education industry. With the further development of AI, machine translation can better meet the needs of most general translation, but in the face of professional, diversified, detailed and complex communication translation tasks containing human emotion, machine translation is still difficult to replace human translation. In order to improve the English translation ability of university students, this paper uses AI to propose the innovative factor based Quantum Particle Swarm Optimization-Convolutional Neural Network (QPSO-CNN) algorithm. Through the experiment, at first, the obtained dataset can ensure the accuracy and diversity of the collected results of English translation feature samples to the maximum extent, and the trained QPSO-CNN can be used to analyze the accuracy of the English translation ability of university students. Then, by comparing the convergence curve of QPSO-CNN and back propagation-CNN (BP-CNN), it is concluded that the proposed QPSO-CNN in this paper has been greatly improved in terms of model accuracy and convergence speed. ? 2022 World Scientific Publishing Company.",Scopus
Zhu F.; Li G.; Tang H.; Li Y.; Lv X.; Wang X.,Dung beetle optimization algorithm based on quantum computing and multi-strategy fusion for solving engineering problems,2024,10.1016/j.eswa.2023.121219,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85169566201&doi=10.1016%2fj.eswa.2023.121219&partnerID=40&md5=a924857e430ea621f7e613211fec66b9,Article,Expert Systems with Applications,"The Dung beetle optimization algorithm is a kind of group intelligence optimization algorithm proposed by Jiankai Xue in 2022, which has the characteristics of strong optimization-seeking ability and fast convergence but suffers from the defect of easily falling into local optimum at the late stage of optimization-seeking as other group intelligence optimization algorithms. To address this problem, this paper proposes a dung beetle search algorithm (QHDBO) based on quantum computing and a multi-strategy hybrid. The good point set strategy is used to initialize the initial population of dung beetles. That makes the initial population more evenly distributed, and reduces the likelihood of the algorithm falling into a local optimum solution. The convergence factor and dynamic balance between the number of Spawning and foraging dung beetles is proposed. That allows the algorithm to focus on the global search in the early stages and local exploration in the later stages. The quantum computing based t-distribution variation strategy is used to variate the optimal global solution, that prevents the algorithm from falling into a local optimum. To verify the performance of the QHDBO algorithm, this paper compares QHDBO with six other swarm intelligence algorithms through 37 test functions and practical engineering application problems. The experimental results show that the improved dung beetle optimization algorithm significantly improves convergence speed and optimization accuracy and has good robustness. ? 2023 Elsevier Ltd",Scopus
"Sengupta S.; Basak S.; Peters R.A., II","Chaotic quantum double delta swarm algorithm using Chebyshev maps: Theoretical foundations, performance analyses and convergence issues",2019,10.3390/jsan8010009,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85060517987&doi=10.3390%2fjsan8010009&partnerID=40&md5=b6eb9324f2691ec22e3acb64ab1ff842,Article,Journal of Sensor and Actuator Networks,"The Quantum Double Delta Swarm (QDDS) Algorithm is a networked, fully-connected novel metaheuristic optimization algorithm inspired by the convergence mechanism to the center of potential generated within a single well of a spatially colocated double¨Cdelta well setup. It mimics the wave nature of candidate positions in solution spaces and draws upon quantum mechanical interpretations much like other quantum-inspired computational intelligence paradigms. In this work, we introduce a Chebyshev map driven chaotic perturbation in the optimization phase of the algorithm to diversify weights placed on contemporary and historical, socially-optimal agents¡¯ solutions. We follow this up with a characterization of solution quality on a suite of 23 single¨Cobjective functions and carry out a comparative analysis with eight other related nature¨Cinspired approaches. By comparing solution quality and successful runs over dynamic solution ranges, insights about the nature of convergence are obtained. A two-tailed t-test establishes the statistical significance of the solution data whereas Cohen¡¯s d and Hedge¡¯s g values provide a measure of effect sizes. We trace the trajectory of the fittest pseudo-agent over all iterations to comment on the dynamics of the system and prove that the proposed algorithm is theoretically globally convergent under the assumptions adopted for proofs of other closely-related random search algorithms. ? 2019 by the authors",Scopus
Li F.; Wu J.; Ge W.; Ji W.,Quantum bacterial foraging optimization for cognitive radio spectrum allocation,2015,10.3837/tiis.2015.02.005,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84924099108&doi=10.3837%2ftiis.2015.02.005&partnerID=40&md5=5c241b1ce35254a215f83f5024aed5a0,Article,KSII Transactions on Internet and Information Systems,"This paper proposes a novel swarm intelligence optimization method which integrates bacterial foraging optimization (BFO) with quantum computing, called quantum bacterial foraging optimization (QBFO) algorithm. In QBFO, a multi-qubit which can represent a linear superposition of states in search space probabilistically is used to represent a bacterium, so that the quantum bacteria representation has a better characteristic of population diversity. A quantum rotation gate is designed to simulate the chemotactic step for the sake of driving the bacteria toward better solutions. Several tests are conducted based on benchmark functions including multi-peak function to evaluate optimization performance of the proposed algorithm. Numerical results show that the proposed QBFO has more powerful properties in terms of convergence rate, stability and the ability of searching for the global optimal solution than the original BFO and quantum genetic algorithm. Furthermore, we examine the employment of our proposed QBFO for cognitive radio spectrum allocation. The results indicate that the proposed QBFO based spectrum allocation scheme achieves high efficiency of spectrum usage and improves the transmission performance of secondary users, as compared to color sensitive graph coloring algorithm and quantum genetic algorithm. ? 2015 KSII.",Scopus
Sayed G.I.,A novel multilevel thresholding algorithm based on quantum computing for abdominal CT liver images,2023,10.1007/s12065-021-00669-9,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85116461020&doi=10.1007%2fs12065-021-00669-9&partnerID=40&md5=60d34e34e481630b7ec5df50a567d59d,Article,Evolutionary Intelligence,"Image segmentation is considered one of the important tasks for extracting useful information from an image. Multilevel thresholding image segmentation is one of the effective techniques for image segmentation. The computation time grows exponentially of traditional multilevel thresholding methods such as Kapur with the number of thresholds. Meta-heuristic algorithms based on swarm intelligence have proved their efficiency in solving the multilevel thresholding optimization problem. In this paper, a new hybrid algorithm based on quantum computing (QC) and optimal foraging algorithm (OFA) for multilevel image segmentation is presented. The main characteristic of the proposed quantum optimal foraging algorithm (QOFA) is the integration of quantum operators such as interference with the optimization process of OFA to get a proper balance between exploration and exploitation phases. The feasibility of the proposed multilevel image segmentation algorithm has been evaluated and tested on real abdominal CT liver images. All the results are analyzed qualitatively and quantitatively to evaluate the effectiveness and the robustness of the proposed algorithm. The experimental results revealed that the proposed algorithm is a very promising algorithm and it can provide better segmentation results compared with the standard OFA. ? 2021, The Author(s), under exclusive licence to Springer-Verlag GmbH Germany, part of Springer Nature.",Scopus
Shankar V.; Chang S.,Performance of Caffe on QCT Deep Learning Reference Architecture-A Preliminary Case Study,2017,10.1109/CSCloud.2017.49,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85028660426&doi=10.1109%2fCSCloud.2017.49&partnerID=40&md5=ae4e770165c76438cd825376223d6163,Conference Paper,"Proceedings - 4th IEEE International Conference on Cyber Security and Cloud Computing, CSCloud 2017 and 3rd IEEE International Conference of Scalable and Smart Cloud, SSC 2017","Deep learning is a sub-set of machine learning practice employing models based on various learning network architectures and algorithms in the field of artificial intelligence. Businesses planning to adopt a deep learning solution should comprehend a set of complex choices in hardware, software, configuration and optimizations to setup a functional deep learning solution. This paper will describe the reference architecture built on Intel Knights Landing processor and omni-path interconnection. We provide a simplified guide to deploy, configure and optimize deep learning solutions based on an array of compute, storage, networking and software components offered by Quanta Cloud Technology. The performance data is presented and it shows good scaling and accuracy on processing the data from IMAGENET. ? 2017 IEEE.",Scopus
Zhu L.; Lin S.; Richard Yu F.; Li Y.,Collaborative Computing Optimization in Train-Edge-Cloud-Based Smart Train Systems Using Risk-Sensitive Reinforcement Learning,2023,10.1109/TVT.2023.3325674,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85174837526&doi=10.1109%2fTVT.2023.3325674&partnerID=40&md5=f318ff81b9c9b2d977fd7a54cc4ff257,Article,IEEE Transactions on Vehicular Technology,"With the advent of the intelligent and digital era, intelligent urban rail transit systems have been a research focus. As the core part of intelligent urban rail transit systems, smart trains are empowered by various intelligent applications. While improving system performance and reducing system risk, intelligent applications demand a large amount of computing power. However, it is challenging to provide simultaneously all intelligent applications for smart trains due to limited on-board computing resources. In this article, we design a train-edge-cloud (TEC) collaborative computing framework for train intelligent computing tasks. We aim to develop a TEC-based collaborative computing scheme to minimize the task processing delay with edge computing resource constraints. Considering the unique environment of smart train systems, we design a risk-sensitive reinforcement learning (RL) algorithm to realize collaborative computing optimization. We design a novel risk function in the system by jointly considering the computing load of edge intelligence (EI) servers and the characteristics of the urban rail transit systems. Moreover, we optimize the proposed risk-sensitive RL algorithm by using quantum representation and functions to accelerate its convergence speed. We design the TEC-based collaborative computing framework and design the quantum-inspired risk-sensitive RL algorithm to formulate the strategies for task scheduling. Comprehensive simulation results indicate that the algorithm adopted in this article can significantly reduce the task processing delay while satisfying EI servers¡¯ computing resource constraints. The quantum-inspired-optimized risk-sensitive RL model dramatically improves the model convergence speed. ? 2023 IEEE.",Scopus
Barletta V.S.; Caivano D.; De Vincentiis M.; Pal A.; Scalera M.,Hybrid quantum architecture for smart city security,2024,10.1016/j.jss.2024.112161,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85199449984&doi=10.1016%2fj.jss.2024.112161&partnerID=40&md5=a32e77922f826d849310ca69069170e2,Article,Journal of Systems and Software,"Currently and in the near future, Smart Cities are vital to enhance urban living, address resource challenges, optimize infrastructure, and harness technology for sustainability, efficiency, and improved quality of life in rapidly urbanizing environments. Owing to the high usage of networks, sensors, and connected devices, Smart Cities generate a massive amount of data. Therefore, Smart City security concerns encompass data privacy, Internet-of-Things (IoT) vulnerabilities, cyber threats, and urban infrastructure risks, requiring robust solutions to safeguard digital assets, citizens, and critical services. Some solutions include robust cybersecurity measures, data encryption, Artificial Intelligence (AI)-driven threat detection, public¨Cprivate partnerships, standardized security protocols, and community engagement to foster a resilient and secure smart city ecosystem. For example, Security Information and Event Management (SIEM) helps in real-time monitoring, threat detection, and incident response by aggregating and analyzing security data. To this end, no integrated systems are operating in this context. In this paper, we propose a Hybrid Quantum-Classical Architecture for bolstering Smart City security that exploits Quantum Machine Learning (QML) and SIEM to provide security based on Quantum Artificial Intelligence and patterns/rules. The validity of the hybrid quantum-classical architecture was proven by conducting experiments and a comparison of the QML algorithms with state-of-the-art AI algorithms. We also provide a proof of concept dashboard for the proposed architecture. ? 2024 The Author(s)","Scopus, Web of Science"
Musia?ek F.; Szabra D.; Wojtas J.,Time-Efficient SNR Optimization of WMS-Based Gas Sensor Using a Genetic Algorithm,2024,10.3390/s24061842,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85189020004&doi=10.3390%2fs24061842&partnerID=40&md5=41dd9c96ba9546ef049bbcaf27173375,Article,Sensors,"This paper presents the description of the wavelength modulation spectroscopy (WMS) experiment, the parameters of which were established by use of the Artificial Intelligence (AI) algorithm. As a result, a significant improvement in the signal power to noise power ratio (SNR) was achieved, ranging from 1.6 to 6.5 times, depending on the harmonic. Typically, optimizing the operation conditions of WMS-based gas sensors is based on long-term simulations, complex mathematical model analysis, and iterative experimental trials. An innovative approach based on a biological-inspired genetic algorithm (GA) and custom-made electronics for laser control is proposed. The experimental setup was equipped with a 31.23 m Heriott multipass cell, software lock-in, and algorithms to control the modulation process of the quantum cascade laser (QCL) operating in the long-wavelength-infrared (LWIR) spectral range. The research results show that the applied evolutionary approach can efficiently and precisely explore a wide range of WMS parameter combinations, enabling researchers to dramatically reduce the time needed to identify optimal settings. It took only 300 s to test approximately 1.39 ¡Á 1032 combinations of parameters for key system components. Moreover, because the system is able to check all possible component settings, it is possible to unquestionably determine the operating conditions of WMS-based gas sensors for which the limit of detection (LOD) is the most favorable. ? 2024 by the authors.","Scopus, Web of Science"
Li P.; Li Y.; Hsieh C.-Y.; Zhang S.; Liu X.; Liu H.; Song S.; Yao X.,TrimNet: Learning molecular representation from triplet messages for biomedicine,2021,10.1093/bib/bbaa266,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85108260509&doi=10.1093%2fbib%2fbbaa266&partnerID=40&md5=bd512c4ac9c998407ac28a306d2860e4,Article,Briefings in Bioinformatics,"Motivation: Computational methods accelerate drug discovery and play an important role in biomedicine, such as molecular property prediction and compound-protein interaction (CPI) identification. A key challenge is to learn useful molecular representation. In the early years, molecular properties are mainly calculated by quantum mechanics or predicted by traditional machine learning methods, which requires expert knowledge and is often labor-intensive. Nowadays, graph neural networks have received significant attention because of the powerful ability to learn representation from graph data. Nevertheless, current graph-based methods have some limitations that need to be addressed, such as large-scale parameters and insufficient bond information extraction. Results: In this study, we proposed a graph-based approach and employed a novel triplet message mechanism to learn molecular representation efficiently, named triplet message networks (TrimNet). We show that TrimNet can accurately complete multiple molecular representation learning tasks with significant parameter reduction, including the quantum properties, bioactivity, physiology and CPI prediction. In the experiments, TrimNet outperforms the previous state-of-the-art method by a significant margin on various datasets. Besides the few parameters and high prediction accuracy, TrimNet could focus on the atoms essential to the target properties, providing a clear interpretation of the prediction tasks. These advantages have established TrimNet as a powerful and useful computational tool in solving the challenging problem of molecular representation learning. Availability: The quantum and drug datasets are available on the website of MoleculeNet: http://moleculenet.ai. The source code is available in GitHub: https://github.com/yvquanli/trimnet. Contact: xjyao@lzu.edu.cn, songsen@tsinghua.edu.cn  ? 2020 The Author(s) 2020. Published by Oxford University Press. All rights reserved. For Permissions, please email: journals.permissions@oup.com.",Scopus
Ghosh M.; Sen S.; Sarkar R.; Maulik U.,Quantum squirrel inspired algorithm for gene selection in methylation and expression data of prostate cancer,2021,10.1016/j.asoc.2021.107221,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85102063324&doi=10.1016%2fj.asoc.2021.107221&partnerID=40&md5=e968f5104003011953d661cda80c42e1,Article,Applied Soft Computing,"Prostate cancer is the second most common type of cancer among men after skin cancer In this work, we present a comprehensive view on genomic and epigenomic changes following the incremental biological functionality. For gene selection, a new Feature Selection algorithm called Quantum Squirrel inspired Feature Selection is proposed here. While exploring the feature space, the proposed algorithm exploits the benefits of Squirrel Search Algorithm (a recently proposed swarm intelligence algorithm) along with Quantum mechanics. Moreover, a modified version of the end of winter concept is used to achieve effective dimension reduction capacity. Quantum Squirrel inspired Feature Selection is executed on both expression and methylation data of prostate cancer. The major challenge in gene selection is to bring down the number of selected features without compromising on accuracy. The proposed algorithm consistently achieves this goal and outperforms other state-of-the-art algorithms. The proposed algorithm has steadily attained 100% accuracy while selecting a much lower number of features (around 4), which is a major improvement over others. The top selected genes are biologically validated in terms of Kyoto Encyclopedia of Genes and Genomes (KEGG) pathway and Gene Ontologies (GO), which further demonstrates the usefulness of the proposed method. The genes selected by Quantum Squirrel inspired Feature Selection show an association with prostate carcinoma and most are known biomarkers. A few novel biomarkers selected by proposed algorithm have also been detailed in this work. Source code of this work is available at: Quantum Squirrel inspired Feature Selection. ? 2021 Elsevier B.V.",Scopus
Garc¨ªa C.R.; Bouchmal O.; Stan C.; Giannakopoulos P.; Cimoli B.; Olmos J.J.V.; Rommel S.; Monroy I.T.,Secure and Agile 6G Networking - Quantum and AI Enabling Technologies,2023,10.1109/ICTON59386.2023.10207418,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85169426065&doi=10.1109%2fICTON59386.2023.10207418&partnerID=40&md5=ae75ffb1d01b37d53f813124bb6d7cf5,Conference Paper,International Conference on Transparent Optical Networks,"This paper proposes a novel architecture for enabling ultra-fast and ultra-safe 6G networks that can support complex and challenging real-time applications based on four key enabling technologies: 1) performance prediction, 2) AI-enabled task offloading, 3) quantum machine learning, and 4) quantum-resistant communication. With the emergence of 6G applications where the real-time quality of experience is prioritized, AI-enabled task offloading leverages the benefits of edge computing. Moreover, the execution time of complex applications can be reduced by using quantum computers at the edge or in the cloud. In addition, by incorporating quantum key distribution and post-quantum cryptography, we can ensure the safety of mobile networks in the quantum computing era. Collectively, these technologies will provide ultra-fast and ultra-safe 6G networks, meeting the requirements of challenging real-time applications that were not supported in the previous generations, thus advancing the state of the art of mobile communication networks.  ? 2023 IEEE.",Scopus
Tellez F.; Ort¨ªz J.,Comparing AI Algorithms for Optimizing Elliptic Curve Cryptography Parameters in e-Commerce Integrations: A Pre-Quantum Analysis,2024,10.14569/IJACSA.2024.01506153,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85199688239&doi=10.14569%2fIJACSA.2024.01506153&partnerID=40&md5=551b66585096568a22d9808de50018da,Article,International Journal of Advanced Computer Science and Applications,"This paper presents a comparative analysis between the Genetic Algorithm (GA) and Particle Swarm Optimization (PSO), two vital artificial intelligence algorithms, focusing on optimizing Elliptic Curve Cryptography (ECC) parameters. These encompass the elliptic curve coefficients, prime number, generator point, group order, and cofactor. The study provides insights into which of the bio-inspired algorithms yields better optimization results for ECC configurations, examining performances under the same fitness function. This function incorporates methods to ensure robust ECC parameters, including assessing for singular or anomalous curves and applying Pollard¡¯s rho attack and Hasse¡¯s theorem for optimization precision. The optimized parameters generated by GA and PSO are tested in a simulated e-commerce environment, contrasting with well-known curves like secp256k1 during the transmission of order messages using Elliptic Curve-Diffie Hellman (ECDH) and Hash-based Message Authentication Code (HMAC). Focusing on traditional computing in the pre-quantum era, this research highlights the efficacy of GA and PSO in ECC optimization, with implications for enhancing cybersecurity in third-party e-commerce integrations. We recommend the immediate consideration of these findings before quantum computing¡¯s widespread adoption. ? (2024), (Science and Information Organization). All rights reserved.",Scopus
Rugveth V.S.; Khatter K.,Sensitivity analysis on Gaussian quantum-behaved particle swarm optimization control parameters,2023,10.1007/s00500-023-08011-4,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85150629367&doi=10.1007%2fs00500-023-08011-4&partnerID=40&md5=60c4d72c421e1484c690f8c33725d4d1,Article,Soft Computing,"Particle swarm optimization (PSO) is a population-based swarm intelligence algorithm that falls under the category of nature-inspired algorithms and is similar to evolutionary computing in various ways. Rather than the survival of the fittest, the PSO is driven by a representation of a social psychological model inspired by the group behaviors of birds and other social species. The particle's position is modified in PSO based on its position as well as velocity, while in quantum mechanics, the trajectory idea is absurd; however, the uncertainty principle suggests that a particle's position, as well as velocity, cannot be determined simultaneously. As a result, an advanced version of the quantum mechanics-based PSO method is proposed. The study in this paper is focused on an investigation of a new quantum-behaved PSO (QPSO) method called Gaussian quantum-behaved particle swarm optimization (GQPSO), which uses a mutation operator with a Gaussian distribution and is inspired by classical PSO methods and quantum mechanics concepts. In GQPSO, inadequate control parameter tuning results in poor solutions. To better understand the effect of different control parameters and their implications on GQPSO results, this paper used a full parametric sensitivity analysis on five different problems (the Design of a pressure vessel, Tension/Spring Compression, Rastrigin function, Ackley function, and Constrained Box Volume Problem). By adjusting each parameter one at a time, different optimization problems were used to investigate GQPSO. As a result, to allow particles to change their earliest best solution based on viability, a constraint-handling mechanism was developed. The optimal parameter set for GQPSO is provided based on the analysis of the results. With the help of the proposed optimal parameter set (contraction¨Cexpansion coefficient values as (1 = 1.6,2 = 1.3), swarm size as ¡®350¡¯, and number of Iterations as ¡®500¡¯), GQPSO returned an optimized solution for Rastrigin and Ackley functions. It also performed better in the case of the design of a pressure vessel and tension/spring compression problems in comparison to the existing solution available in related literature. As per the findings of the sensitivity analysis, GQPSO is the most sensitive to the contraction-expansion coefficient in comparison to the maximum number of iterations (itermax) and swarm size (¡®n¡¯). ? 2023, The Author(s), under exclusive licence to Springer-Verlag GmbH Germany, part of Springer Nature.",Scopus
Perkowski M.,"Inverse problems, constraint satisfaction, reversible logic, invertible logic and Grover quantum oracles for practical problems",2022,10.1016/j.scico.2022.102775,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85126312089&doi=10.1016%2fj.scico.2022.102775&partnerID=40&md5=5797989bc7c608a211c776170319e147,Article,Science of Computer Programming,"It is well-known that the ¡°Unsorted Database¡± quantum algorithm by Grover gives quadratic speedup to several practically important combinatorial and enumerative problems, such as: SAT, Graph Coloring, Maximum Cliques, Traveling Salesman and many others. Recently, quantum programming languages such as QISKIT, QSHARP or Quipper start to be used to design, verify and simulate practical quantum algorithms for important problems in Quantum Machine Learning or optimization. So far, however, no methodologies have been created to program Grover's Oracles for particular classes of problems. In contrast, such methodologies have been already created for classical Constraint Satisfaction Problems (CSP). Invertible Logic was recently introduced by Supriyo Datta and his team. The goal of this paper is to present results of our research towards creating a systematic methodology to solve search problems in Artificial Intelligence, Logic Design and Machine Learning by repeated applications of modified hardware oracles. These oracles can use: (1) classical Boolean logic, (2) quantum logic, or (3) invertible logic. Our methodology to design and exercise all types of general oracles is based on bottom-up synthesis and technology transformations. For CSP problems we apply unified blocks which use various data representations and encodings. ? 2022",Scopus
Zaman F.; Farooq A.; Ullah M.A.; Jung H.; Shin H.; Win M.Z.,Quantum Machine Intelligence for 6G URLLC,2023,10.1109/MWC.003.2200382,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85156146285&doi=10.1109%2fMWC.003.2200382&partnerID=40&md5=4c169e26921c32f0ae5ab73934d19948,Article,IEEE Wireless Communications,"Immersive and mission-critical data-driven applications, such as virtual or augmented reality, tactile Internet, industrial automation, and autonomous mobility, are creating unprecedented challenges for ultra-reliable and low-latency communication (URLLC) in the sixth generation (6G) networks. Machine intelligence approaches deep learning, reinforcement learning, and federated learning (FL), to provide new paradigms to ensure 6G URLLC on the stream of big data training. However, classical limitations of machine learning capabilities make it challenging to achieve stringent 6G URLLC requirements. In this article, we investigate the potential of variational quantum computing and quantum machine learning (QML) for 6G URLLC by utilizing the advantage of quantum resources, such as superposition, entanglement, and quantum parallelism. The underlying idea is to integrate quantum machine intelligence with 6G networks to ensure stringent 6G URLLC requirements. As an example, we demonstrate the quantum approximate optimization algorithm for NP-hard URLLC task offloading optimization problems. The variational quantum computation for QML is also adopted in wireless networks to enhance the learning rate of machine intelligence and ensure the learning optimality for mission-critical applications. Considering the security and privacy issues, as well as computational-resource overheads in FL, distributed quantum computation in blind and remote fashions is further investigated for quantum-assisted FL.  ? 2002-2012 IEEE.",Scopus
Winker T.; Groppe S.; Uotila V.; Yan Z.; Lu J.; Franz M.; Mauerer W.,"Quantum Machine Learning: Foundation, New Techniques, and Opportunities for Database Research",2023,10.1145/3555041.3589404,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85162896901&doi=10.1145%2f3555041.3589404&partnerID=40&md5=8b9ee512808ba1315d83af1c0553702c,Conference Paper,Proceedings of the ACM SIGMOD International Conference on Management of Data,"In the last few years, the field of quantum computing has experienced remarkable progress. The prototypes of quantum computers already exist and have been made available to users through cloud services (e.g., IBM Q experience, Google quantum AI, or Xanadu quantum cloud). While fault-tolerant and large-scale quantum computers are not available yet (and may not be for a long time, if ever), the potential of this new technology is undeniable. Quantum algorithms have the proven ability to either outperform classical approaches for several tasks, or are impossible to be efficiently simulated by classical means under reasonable complexity-theoretic assumptions. Even imperfect current-day technology is speculated to exhibit computational advantages over classical systems. Recent research is using quantum computers to solve machine learning tasks. Meanwhile, the database community has already successfully applied various machine learning algorithms for data management tasks, so combining the fields seems to be a promising endeavour. However, quantum machine learning is a new research field for most database researchers. In this tutorial, we provide a fundamental introduction to quantum computing and quantum machine learning and show the potential benefits and applications for database research. In addition, we demonstrate how to apply quantum machine learning to the join order optimization problem in databases.  ? 2023 ACM.",Scopus
Sha M.; Rahamathulla M.P.,Quantum deep learning in Parkinson¡¯s disease prediction using hybrid quantum¨Cclassical convolution neural network,2024,10.1007/s11128-024-04588-3,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85210078953&doi=10.1007%2fs11128-024-04588-3&partnerID=40&md5=c07a378abd378e2964bf592b2f75b796,Article,Quantum Information Processing,"Deep learning, also known as DL, holds great potential within the field of artificial intelligence. Fast problem-solving approaches are widely used in quantum computing. Large multidimensional space is utilized to categorize and address intricate problems. The different algorithms have the ability to interact in a space with multiple dimensions and find solutions to the problems. Quantum deep learning facilitates different mining procedures by incorporating precise advancements in quantum computing. Prompt and accurate identification during the early stages of progression is crucial for various severe and life-threatening illnesses like cancer, hepatotoxicity, cardio toxicity, nephrotoxicity, and others. Currently, there is a critical need to create rapid, precise, and highly effective approaches for predicting different diseases. These methods should also be feasible and nonintrusive. Dementia, a highly hazardous condition, has a significant impact on the human nervous system. Dementia often includes Parkinson¡¯s as one of its prominent symptoms. The patient¡¯s entire operational behavior will be impacted. The proposed system is utilizing machine learning and quantum computing to develop a method for predicting Parkinson¡¯s disease based on speech signals. Quantum computers can be used to assist in identifying cancer by using a hybrid quantum¨Cclassical convolution neural network (QCCNN). This network is inspired by convolution neural networks (CNNs) but has been modified for quantum computing in order to improve the process of mapping features. Dimensionality reduction algorithms, principal component analysis (PCA) are applied to the preprocessed dataset to make predictions about diseases. The standard dataset from UCI machine learning repository will be used to determine the performance of the model. Ensemble models exceed the precision of highly accurate techniques such as neural networks. To demonstrate the superior detection capability of our model, we have compared its performance with several advanced machine learning and deep learning-based methods for Parkinson¡¯s disease detection. ? The Author(s), under exclusive licence to Springer Science+Business Media, LLC, part of Springer Nature 2024.",Scopus
Campos R.; Casares P.A.M.; Martin-Delgado M.A.,Quantum Metropolis Solver: a quantum walks approach to optimization problems,2023,10.1007/s42484-023-00119-y,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85165232094&doi=10.1007%2fs42484-023-00119-y&partnerID=40&md5=8d10064e2d88c2d91620b205a160307b,Article,Quantum Machine Intelligence,"The efficient resolution of optimization problems is one of the key issues in today¡¯s industry. This task relies mainly on classical algorithms that present scalability problems and processing limitations. Quantum computing has emerged to challenge these types of problems. In this paper, we focus on the Metropolis-Hastings quantum algorithm, which is based on quantum walks. We use this algorithm to build a quantum software tool called Quantum Metropolis Solver (QMS). We validate QMS with the N-Queen problem to show a potential quantum advantage in an example that can be easily extrapolated to an Artificial Intelligence domain. We carry out different simulations to validate the performance of QMS and its configuration. ? 2023, The Author(s).","Scopus, Web of Science"
Mangala N.; Reddy B.E.; Venugopal K.R.,Light Weight Circular Error Learning Algorithm (CELA) for Secure Data Communication Protocol in IoT-Cloud Systems,2023,10.14569/IJACSA.2023.0140792,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85168806198&doi=10.14569%2fIJACSA.2023.0140792&partnerID=40&md5=30bf187e8d435fdedb950cc36def8f10,Article,International Journal of Advanced Computer Science and Applications,"The data driven smart applications, utilize the IoT, Cloud Computing, AI and other digital technologies to create, curate and operate on large amounts of data to provide intelligent solutions for day-to-day problems. Security of Data in the IoTCloud systems has become very crucial as there are several attacks such as ransomware, data thieving, and data corruption, causing huge loss to the application users. The basic impediment in providing strong security solutions for the IoT systems, is due the resource limitations of IoT devices. Recently, there is an additional threat of quantum computing being able to break the traditional cryptographic techniques. The objective of this research is to address the bifold challenge and design a light weight quantum secure communication protocol for the IoT Cloud ecosystem. The Ring Learning With Errors (RLWE) lattice based cryptography has emerged as the most popular in the NIST PQC Standardization Program. A light weight Circular Learning Error Algorithm (CELA) has been proposed by optimizing RLWE to make it suitable for IoT-Cloud environment. The CELA inherits the advantages of quantum security and homomorphic encryption from RLWE. It is observed that CELA is light weight in terms of execution time and a slightly bigger cipher text size provides higher security as compared to RLWE. The paper also offers plausible solutions for future quantum secure cryptographic protocols. ? 2023, Science and Information Organization. All Rights Reserved.",Scopus
Nanda T.; Dhanalakshmi B.K.; Lakshmi B.N.,An Explorative Cross Sectional Comprehensive Survey on Quantum Computing,2024,10.1007/s42979-024-03505-w,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85211173147&doi=10.1007%2fs42979-024-03505-w&partnerID=40&md5=878300dd534eeff70d4aa783666cb8be,Article,SN Computer Science,"Quantum computers have been called the Ultimate Computer a decisive leap in technology with profound implications for the entire world. Quantum computers might usher in an entirely new age for the economy, society, and our way of life. It is an emerging field that leverages the principles of quantum mechanics to perform computations that are infeasible for classical computers. As quantum systems advance beyond early prototypes, it is critical to assess their capabilities compared to classical computers and artificial intelligence. This survey aims to provide a comprehensive, cross-sectional analysis of the current state of quantum computing, exploring its advantages over traditional computing paradigms and its potential societal impacts. It also goes through the various algorithms used in this paradigm and how they can aid in our needs. We conducted an extensive literature review of peer-reviewed articles and industry reports to gather data on quantum computing advancements, applications, and challenges. The survey examines quantum hardware platforms, algorithms, use cases across industries, and comparisons to classical and AI systems. Our findings indicate that quantum computers excel at specific tasks like optimization and simulation, offering exponential speedups over classical methods for certain problems. While not universally superior to AI or traditional computers, quantum systems enable new approaches to longstanding challenges in fields such as materials science, finance, and machine learning. However, significant technical hurdles remain before realizing large-scale, fault-tolerant quantum computers. Quantum computing represents a paradigm shift in computational power, with far-reaching implications across science, industry, and society. While challenges persist, continued advances in quantum technologies promise to unlock new realms of problem-solving capability beyond the reach of classical computers and AI systems. Strategic investment and interdisciplinary collaboration will be crucial to fully harness quantum computing¡¯s transformative potential. ? The Author(s), under exclusive licence to Springer Nature Singapore Pte Ltd. 2024.","Scopus, Springer"
Louren?o M.P.; Herrera L.B.; Hosta? J.; Calaminici P.; K?ster A.M.; Tchagang A.; Salahub D.R.,A new active learning approach for adsorbate¨Csubstrate structural elucidation in silico,2022,10.1007/s00894-022-05173-0,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85131170905&doi=10.1007%2fs00894-022-05173-0&partnerID=40&md5=e58b8e39b0c9b6aedc91243eafeb92c3,Article,Journal of Molecular Modeling,"Adsorbate interactions with substrates (e.g. surfaces and nanoparticles) are fundamental for several technologies, such as functional materials, supramolecular chemistry, and solvent interactions. However, modeling these kinds of systems in silico, such as finding the optimum adsorption geometry and energy, is challenging, due to the huge number of possibilities of assembling the adsorbate on the surface. In the current work, we have developed an artificial intelligence (AI) approach based on an active learning (AL) method for adsorption optimization on the surface of materials. AL uses machine learning (ML) regression algorithms and their uncertainties to make a decision (based on a policy) for the next unexplored structures to be computed, increasing, though, the probability of finding the global minimum with a small number of calculations. The methodology allows an accurate and automated structural elucidation of the adsorbate on the surface, based on the minimization of the total electronic energy. The new AL method for adsorption optimization was developed and implemented in the quantum machine learning software/agent for material design and discovery (QMLMaterial) program and was applied for C60@TiO2 anatase (101). It marks another software extension with a new feature in addition to the automatic structural elucidation of defects in materials and of nanoparticles as well. SCC-DFTB calculations were used to build the complex search surfaces with a reasonably low computational cost. An artificial neural network (NN) was employed in the AL framework evaluated together with two uncertainty quantification methods: K-fold cross-validation and non-parametric bootstrap (BS) resampling. Also, two different acquisition functions for decision-making were used: expected improvement (EI) and the lower confidence bound (LCB). Graphical abstract: [Figure not available: see fulltext.] ? 2022, The Author(s), under exclusive licence to Springer-Verlag GmbH Germany, part of Springer Nature.",Scopus
Kiruthiga G.; Mary Vennila S.,An enriched chaotic quantum whale optimization algorithm based job scheduling in cloud computing environment,2019,10.30534/ijatcse/2019/105842019,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85073322724&doi=10.30534%2fijatcse%2f2019%2f105842019&partnerID=40&md5=869ab00a79e15b23fafdb8e9ea1ec7b5,Article,International Journal of Advanced Trends in Computer Science and Engineering,"In recent years, cloud has become a metaphor for voluminous data storage and utilization of virtual resources by cloud user. This study focuses on independent job scheduling in cloud computing paradigm. This paper devised a new enriched approach of chaotic quantum whale optimization algorithm (CQWOA), whose ultimate objective is to overwhelm degree of imbalance, increasing makespan and overheads in cost, energy consumption, resource utilization. With the intelligence of chaotic mapping and the quantum mechanism based optimal virtual machine selection, the global optima is achieved more significantly by CQWOA. This algorithm discovers best location and the direction to detect appropriate virtual machine in terms of reduced resource utilization, increasing makespan and evenly distributing the work load, makes the presented model to be more superior than Particle swarm optimization, Ant colony Optimization and standard Whale optimization. The existing models fails to handle the inconsistencies and vagueness in discovering potential virtual machine¡¯s which qualifies their requirements and standard whale optimization easily meets earlier converge of local optima and it is very complex for them to reach global best virtual machines in cloud computing Paradigm. The proposed CQWOA model has saved the total execution cost in job scheduling more successfully and it is proved by its simulation results. ? 2019, World Academy of Research in Science and Engineering. All rights reserved.",Scopus
Davies E.; Kalidindi P.,Quantum Algorithms for Drone Mission Planning,2024,10.1117/12.3036340,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85212212009&doi=10.1117%2f12.3036340&partnerID=40&md5=5b660da33622fbd162e40b75c1571c01,Conference Paper,Proceedings of SPIE - The International Society for Optical Engineering,"Mission planning often involves optimising the use of ISR (Intelligence, Surveillance and Reconnaissance) assets in order to achieve a set of mission objectives within allowed parameters subject to constraints. The missions of interest here, involve routing multiple UAVs visiting multiple targets, utilising sensors to capture data relating to each target. Finding such solutions is often an NP-Hard problem and cannot be solved efficiently on classical computers. Furthermore, during the mission new constraints and objectives may arise, requiring a new solution to be computed within a short time period. To achieve this we investigate near term quantum algorithms that have the potential to offer speed-ups against current classical methods. We demonstrate how a large family of these problems can be formulated as a Mixed Integer Linear Program (MILP) and then converted to a Quadratic Unconstrained Binary Optimisation (QUBO). The formulation provided is versatile and can be adapted for many different constraints with clear qubit scaling provided. We discuss the results of solving the QUBO formulation using commercial quantum annealers and compare the solutions to current edge classical solvers. We also analyse the results from solving the QUBO using Quantum Approximate Optimisation Algorithms (QAOA) and discuss their results. Finally, we also provide efficient methods to encode to the problem into the Variational Quantum Eigensolver (VQE) formalism, where we have tailored the ansatz to the problem making efficient use of the qubits available. ? 2024 SPIE.",Scopus
Ye H.; Dong J.,A Hybrid Algorithm of Quantum-Behaved Particle Swarm Optimization and Adam for ANN Training and Application for Classification Prediction,2023,10.1109/NTCI60157.2023.10403715,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85185220986&doi=10.1109%2fNTCI60157.2023.10403715&partnerID=40&md5=bb8b9b1348ba52c9588cfd43f9d9a35f,Conference Paper,"Proceedings of 2023 International Conference on New Trends in Computational Intelligence, NTCI 2023","The study of neural networks has become increasingly popular as artificial intelligence has advanced. In addition to several new types of networks and their applications in various fields, neural network optimization has also drawn a lot of attention. Traditional techniques for optimizing the parameters of neural networks are gradient descent algorithms. The drawback of gradient descent algorithms is that they may easily fall into local optima because of the characteristics of local optimization. Meanwhile, several meta-heuristic algorithms have been attempted to optimize neural networks, but the performance is also limited due to insufficient fine search capability. This work proposes the hybrid algorithm HAQPSO to improve the draw-back of gradient descent algorithms, which not only combines Adam with the Quantum-behaved Particle Swarm Optimization (QPSO) but also introduces the hybrid strategy to facilitate information transfer between the algorithms and enhances the efficiency. The proposed algorithm was tested on the Iris dataset and compared with classical gradient descent algorithms and Particle Swarm Optimization (PSO). The experimental results prove that HAQPSO can improve the searching capability while enhancing stability and achieving fast convergence, which is a competitive algorithm.  ? 2023 IEEE.",Scopus
Zamani H.; Nadimi-Shahraki M.H.; Gandomi A.H.,QANA: Quantum-based avian navigation optimizer algorithm,2021,10.1016/j.engappai.2021.104314,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85108253446&doi=10.1016%2fj.engappai.2021.104314&partnerID=40&md5=70bc94cdc0447e88cdbe1ce4b7721e78,Article,Engineering Applications of Artificial Intelligence,"Differential evolution is an effective and practical approach that is widely applied for solving global optimization problems. Nevertheless, its effectiveness and scalability are decreased when the problems¡¯ dimension is increased. Hence, this paper is devoted to proposing a novel DE algorithm named quantum-based avian navigation optimizer algorithm (QANA) inspired by the extraordinary precision navigation of migratory birds during long-distance aerial paths. In the QANA, the population is distributed by partitioning into multi flocks to explore the search space effectively using proposed self-adaptive quantum orientation and quantum-based navigation consisted of two mutation strategies, DE/quantum/I and DE/quantum/II. Except for the first iteration, each flock is assigned using an introduced success-based population distribution (SPD) policy to one of the quantum mutation strategies. Meanwhile, the information flow is shared through the population using a new communication topology named V-echelon. Furthermore, we introduce two long-term and short-term memories to provide meaningful knowledge for partial landscape analysis and a qubit-crossover operator to generate the next search agents. The effectiveness and scalability of the proposed QANA were extensively evaluated using benchmark functions CEC 2018 and CEC 2013 as LSGO problems. The results were statistically analyzed by the Wilcoxon signed-rank sum test, ANOVA, and mean absolute error tests. Finally, the applicability of the QANA to solve real-world problems was evaluated by four engineering problems. The experimental results and statistical analysis prove that the QANA is superior to the competitor DE and swarm intelligence algorithms in test functions CEC 2018 and CEC 2013, with overall effectiveness of 80.46% and 73.33%, respectively. ? 2021 Elsevier Ltd",Scopus
Kou G.; Din?er H.; Pamucar D.; Y¨¹ksel S.; Deveci M.; Eti S.,Artificial intelligence-based expert weighted quantum picture fuzzy rough sets and recommendation system for metaverse investment decision-making priorities,2024,10.1007/s10462-024-10905-0,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85203271337&doi=10.1007%2fs10462-024-10905-0&partnerID=40&md5=d2e28ed84172e365f286fa66c73c564f,Article,Artificial Intelligence Review,"There should be some improvements to increase the performance of Metaverse investments. However, businesses need to focus on the most important actions to provide cost effectiveness in this process. In summary, a new study is needed in which a priority analysis is made for the performance indicators of Metaverse investments. Accordingly, this study aims to evaluate the main determinants of the performance of the metaverse investments. Within this context, a novel model is created that has four different stages. The first stage is related to the prioritizing the experts with artificial intelligence-based decision-making method. Secondly, missing evaluations are estimated by expert recommendation system. Thirdly, the criteria are weighted with Quantum picture fuzzy rough sets-based (QPFR) M-Step-wise Weight Assessment Ratio Analysis (SWARA). Finally, investment decision-making priorities are ranked by QPFR VIKOR (Vlse Kriterijumska Optimizacija Kompromisno Resenje). The main contribution of this study is the integration of the artificial intelligence methodology to the fuzzy decision-making approach for the purpose of computing the weights of the decision makers. Owing to this condition, the evaluations of these people are examined according to their qualifications. This situation has a positive contribution to make more effective evaluations. Organizational effectiveness is found to be the most important factor in improving the performance of metaverse investments. Similarly, it is also identified that it is important for businesses to ensure technological improvements in the development of Metaverse investments. On the other side, the ranking results indicate that regulatory framework is the most critical alternative in this regard. ? The Author(s) 2024.",Scopus
Chen B.; Cao L.; Chen C.; Chen Y.; Yue Y.,A comprehensive survey on the chicken swarm optimization algorithm and its applications: state-of-the-art and research challenges,2024,10.1007/s10462-024-10786-3,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85195801676&doi=10.1007%2fs10462-024-10786-3&partnerID=40&md5=085139d3c711cc7527c9d58dff7adf1f,Article,Artificial Intelligence Review,"The application of optimization theory and the algorithms that are generated from it has increased along with science and technology's continued advancement. Numerous issues in daily life can be categorized as combinatorial optimization issues. Swarm intelligence optimization algorithms have been successful in machine learning, process control, and engineering prediction throughout the years and have been shown to be efficient in handling combinatorial optimization issues. An intelligent optimization system called the chicken swarm optimization algorithm (CSO) mimics the organic behavior of flocks of chickens. In the benchmark problem's optimization process as the objective function, it outperforms several popular intelligent optimization methods like PSO. The concept and advancement of the flock optimization algorithm, the comparison with other meta-heuristic algorithms, and the development trend are reviewed in order to further enhance the search performance of the algorithm and quicken the research and application process of the algorithm. The fundamental algorithm model is first described, and the enhanced chicken swarm optimization algorithm based on algorithm parameters, chaos and quantum optimization, learning strategy, and population diversity is then categorized and summarized using both domestic and international literature. The use of group optimization algorithms in the areas of feature extraction, image processing, robotic engineering, wireless sensor networks, and power. Second, it is evaluated in terms of benefits, drawbacks, and application in comparison to other meta-heuristic algorithms. Finally, the direction of flock optimization algorithm research and development is anticipated. ? The Author(s) 2024.",Scopus
G?lc¨¹k ?.; Ozsoydan F.B.,Quantum particles-enhanced multiple Harris Hawks swarms for dynamic optimization problems,2021,10.1016/j.eswa.2020.114202,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85098162303&doi=10.1016%2fj.eswa.2020.114202&partnerID=40&md5=99ebde4374c6de22179e6fb1b254c51c,Article,Expert Systems with Applications,"Dynamic optimization problems (DOPs) have been a subject of considerable research interest mainly due to their widespread application potential. In the literature, various mechanisms have been reported to cope with the challenges of DOPs. The proposed mechanisms have usually been adopted by well-known population-based optimization algorithms, such as genetic algorithms or particle swarm optimization. Although new generation swarm-intelligence algorithms are continuously being developed and have much to offer in DOPs, their performance is usually tested on stationary optimization problems. In this study, a recently introduced optimization algorithm, Harris Hawk Optimizer, is redesigned as a multi-population based algorithm to deal with possible multiple optima. Thus, the proposed modification is allowed to search diverse parts of the search space more efficiently, particularly in multimodal environments. Next, it is further enhanced by using quantum particles to tackle with diversification and intensification challenges in DOPs. As shown in the present work, this mechanism can maintain population diversity and intensification depending on a user-supplied parameter. Finally, based on different algorithmic components, four different variants of HHO are proposed. The performances of the developed algorithms are tested on both stationary and dynamic test problems. Dynamic test functions introduced in the IEEE Congress on Evolutionary Computation 2009 (CEC 2009) are used and further extended to test the proposed algorithms' performances. Finally, appropriate statistical analysis is conducted to demonstrate significant improvements over the existing algorithms. ? 2020 Elsevier Ltd",Scopus
Maity R.; Srivastava A.; Sarkar S.; Khan M.I.,Revolutionizing the future of hydrological science: Impact of machine learning and deep learning amidst emerging explainable AI and transfer learning,2024,10.1016/j.acags.2024.100206,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85208726382&doi=10.1016%2fj.acags.2024.100206&partnerID=40&md5=ee6cd95589c7161ad3a6bcd9d193113c,Article,Applied Computing and Geosciences,"Artificial Intelligence (AI), Machine Learning (ML), and Deep Learning (DL) are revolutionizing hydrology, driving significant advancements in water resource management, modeling, and prediction. This review synthesizes cutting-edge developments, methodologies, and applications of AI-ML-DL across key hydrological processes. By critically evaluating these techniques against traditional models, we highlight their superior ability to capture complex, nonlinear relationships and adapt to diverse environments. We further explore AI applications in precipitation forecasting, evapotranspiration estimation, groundwater dynamics, and extreme event prediction (floods, droughts, and compound events), showcasing their timely potential in addressing critical water-related challenges. A particular emphasis is placed on Explainable AI (XAI) and transfer learning as essential tools for improving model transparency and applicability, enabling broader stakeholder trust and cross-regional adaptability. The review also addresses persistent challenges, including data limitations, computational demands, and model interpretability, proposing solutions that integrate emerging technologies like quantum computing, the Internet of Things (IoT), and interdisciplinary collaboration. This review charts a strategic course for future research and practice by bridging AI advancements with practical hydrological applications. Our findings highlight the importance of embracing AI-driven approaches for next-generation hydrological modeling and provide actionable understandings for researchers, practitioners, and policymakers. As hydrology faces escalating challenges due to human-induced climate change and growing water demands, the continued evolution of AI-integrated models and innovations in data handling and stakeholder engagement will be imperative. In conclusion, the findings emphasize the critical role of AI-driven hydrological modeling in addressing global water challenges, including climate change adaptation, sustainable water resource management, and disaster risk reduction. ? 2024 The Authors",Scopus
Wang D.; Song B.; Lin P.; Yu F.R.; Du X.; Guizani M.,Resource Management for Edge Intelligence (EI)-Assisted IoV Using Quantum-Inspired Reinforcement Learning,2022,10.1109/JIOT.2021.3137984,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85122077843&doi=10.1109%2fJIOT.2021.3137984&partnerID=40&md5=a355ccbebd48e6b95feb6ddf9e1efbab,Article,IEEE Internet of Things Journal,"Recent developments in the Internet of Vehicles (IoV) enable interconnected vehicles to support ubiquitous services. Various emerging service applications are promising to increase the Quality of Experience (QoE) of users. On-board computation tasks generated by these applications have heavily overloaded the resource-constrained vehicles, forcing it to offload on-board tasks to other edge intelligence (EI)-assisted servers. However, excessive task offloading can lead to severe competition for communication and computation resources among vehicles, thereby increasing the processing latency, energy consumption, and system cost. To address these problems, we investigate the transmission-awareness and computing-sense uplink resource management problem and formulate it as a time-varying Markov decision process. Considering the total delay, energy consumption, and cost, quantum-inspired reinforcement learning (QRL) is proposed to develop an intelligence-oriented edge offloading strategy. Specifically, the vehicle can flexibly choose the network access mode and offloading strategy through two different radio interfaces to offload tasks to multiaccess edge computing (MEC) servers through WiFi and cloud servers through 5G. The objective of this joint optimization is to maintain a self-adaptive balance between these two aspects. Simulation results show that the proposed algorithm can significantly reduce the transmission latency and computation delay.  ? 2014 IEEE.",Scopus
Habib A.; Finkelstein J.; Niklasson A.M.N.,Efficient Mixed-Precision Matrix Factorization of the Inverse Overlap Matrix in Electronic Structure Calculations with AI-Hardware and GPUs,2024,10.1021/acs.jctc.4c00584,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85201148634&doi=10.1021%2facs.jctc.4c00584&partnerID=40&md5=1eeda5c246f1bef7daa80f273d0b0192,Article,Journal of Chemical Theory and Computation,"In recent years, a new kind of accelerated hardware has gained popularity in the artificial intelligence (AI) community which enables extremely high-performance tensor contractions in reduced precision for deep neural network calculations. In this article, we exploit Nvidia Tensor cores, a prototypical example of such AI-hardware, to develop a mixed precision approach for computing a dense matrix factorization of the inverse overlap matrix in electronic structure theory, S-1. This factorization of S-1, written as ZZT = S-1, is used to transform the general matrix eigenvalue problem into a standard matrix eigenvalue problem. Here we present a mixed precision iterative refinement algorithm where Z is given recursively using matrix-matrix multiplications and can be computed with high performance on Tensor cores. To understand the performance and accuracy of Tensor cores, comparisons are made to GPU-only implementations in single and double precision. Additionally, we propose a nonparametric stopping criteria which is robust in the face of lower precision floating point operations. The algorithm is particularly useful when we have a good initial guess to Z, for example, from previous time steps in quantum-mechanical molecular dynamics simulations or from a previous iteration in a geometry optimization. ? 2024 American Chemical Society",Scopus
"Li, Hongwei and Xu, Qiyuan and Wang, Qilin and Tang, Bin",A Review of Intelligent Verification System for Distribution Automation Terminal based on Artificial Intelligence Algorithms,2023,10.1186/s13677-023-00527-2,https://doi.org/10.1186/s13677-023-00527-2,Journal,Journal of Cloud Computing,"Artificial intelligence (AI) plays a key role in the distribution automation system (DAS). By using artificial intelligence technology, it is possible to intelligently verify and monitor distribution automation terminals, improve their safety and reliability, and reduce power system operating and maintenance costs. At present, researchers are exploring a variety of application methods and algorithms of the distribution automation terminal intelligent acceptance system based on artificial intelligence, such as machine learning, deep learning and expert systems, and have made significant progress. This paper comprehensively reviews the existing research on the application of artificial intelligence technology in distribution automation systems, including fault detection, network reconfiguration, load forecasting, and network security. It undertakes a thorough examination and summarization of the major research achievements in the field of distribution automation systems over the past few years, while also analyzing the challenges that this field confronts. Moreover, this study elaborates extensively on the diverse applications of AI technology within distribution automation systems, providing a detailed comparative analysis of various algorithms and methodologies from multiple classification perspectives. The primary aim of this endeavor is to furnish valuable insights for researchers and practitioners in this domain, thereby fostering the advancement and innovation of distribution automation systems.",Springer
"Alamin, Md Abdullah Al and Uddin, Gias and Malakar, Sanjay and Afroz, Sadia and Haider, Tameem and Iqbal, Anindya",Developer discussion topics on the adoption and barriers of low code software development platforms,2022,10.1007/s10664-022-10244-0,https://doi.org/10.1007/s10664-022-10244-0,Journal,Empirical Software Engineering,"Low-code software development (LCSD) is an emerging approach to democratize application development for software practitioners from diverse backgrounds. LCSD platforms promote rapid application development with a drag-and-drop interface and minimal programming by hand. As it is a relatively new paradigm, it is vital to study developers' difficulties when adopting LCSD platforms. Software engineers frequently use the online developer forum Stack Overflow (SO) to seek assistance with technical issues. We observe a growing body of LCSD-related posts in SO. This paper presents an empirical study of around 33K SO posts (questions + accepted answers) containing discussions of 38 popular LCSD platforms. We use Topic Modeling to determine the topics discussed in those posts. Additionally, we examine how these topics are spread across the various phases of the agile software development life cycle (SDLC) and which part of LCSD is the most popular and challenging. Our study offers several interesting findings. First, we find 40 LCSD topics that we group into five categories: Application Customization, Database and File Management, Platform Adoption, Platform Maintenance, and Third-party API Integration. Second, while the Application Customization (30{\%}) and Data Storage (25{\%}) topic categories are the most common, inquiries relating to several other categories (e.g., the Platform Adoption topic category) have gained considerable attention in recent years. Third, all topic categories are evolving rapidly, especially during the Covid-19 pandemic. Fourth, the How-type questions are prevalent in all topics, but the What-type and Why-type (i.e., detail information for clarification) questions are more prevalent in the Platform Adoption and Platform Maintenance category. Fifth, LCSD practitioners find topics related to Platform Query the most popular, while topics related to Message Queue and Library Dependency Management as the most difficult to get accepted answers to. Sixth, the Why-type and What-type questions and Agile Maintenance and Deployment phase are the most challenging among practitioners. The findings of this study have implications for all three LCSD stakeholders: LCSD platform vendors, LCSD developers/practitioners, Researchers, and Educators. Researchers and LCSD platform vendors can collaborate to improve different aspects of LCSD, such as better tutorial-based documentation, testing, and DevOps support.",Springer
"Fu, Michael and Tantithamthavorn, Chakkrit and Le, Trung and Kume, Yuki and Nguyen, Van and Phung, Dinh and Grundy, John","AIBugHunter: A Practical tool for predicting, classifying and repairing software vulnerabilities",2023,10.1007/s10664-023-10346-3,https://doi.org/10.1007/s10664-023-10346-3,Journal,Empirical Software Engineering,"Many Machine Learning(ML)-based approaches have been proposed to automatically detect, localize, and repair software vulnerabilities. While ML-based methods are more effective than program analysis-based vulnerability analysis tools, few have been integrated into modern Integrated Development Environments (IDEs), hindering practical adoption. To bridge this critical gap, we propose in this article AIBugHunter, a novel Machine Learning-based software vulnerability analysis tool for C/C++ languages that is integrated into the Visual Studio Code (VS Code) IDE. AIBugHunter helps software developers to achieve real-time vulnerability detection, explanation, and repairs during programming. In particular, AIBugHunter scans through developers' source code to (1) locate vulnerabilities, (2) identify vulnerability types, (3) estimate vulnerability severity, and (4) suggest vulnerability repairs. We integrate our previous works (i.e., LineVul and VulRepair) to achieve vulnerability localization and repairs. In this article, we propose a novel multi-objective optimization (MOO)-based vulnerability classification approach and a transformer-based estimation approach to help AIBugHunter accurately identify vulnerability types and estimate severity. Our empirical experiments on a large dataset consisting of 188K+ C/C++ functions confirm that our proposed approaches are more accurate than other state-of-the-art baseline methods for vulnerability classification and estimation. Furthermore, we conduct qualitative evaluations including a survey study and a user study to obtain software practitioners' perceptions of our AIBugHunter tool and assess the impact that AIBugHunter may have on developers' productivity in security aspects. Our survey study shows that our AIBugHunter is perceived as useful where 90{\%} of the participants consider adopting our AIBugHunter during their software development. Last but not least, our user study shows that our AIBugHunter can enhance developers' productivity in combating cybersecurity issues during software development. AIBugHunter is now publicly available in the Visual Studio Code marketplace.",Springer
"Ju{\'a}rez-Ram{\'i}rez, R. and Navarro, C. X. and Jim{\'e}nez, Samantha and Ram{\'i}rez, Alan and Tapia-Ibarra, Ver{\'o}nica and Guerra-Garc{\'i}a, C{\'e}sar and Perez-Gonzalez, Hector G. and Fern{\'a}ndez-y-Fern{\'a}ndez, Carlos",A Taxonomic View of the Fundamental Concepts of Quantum Computing--A Software Engineering Perspective,2023,10.1134/S0361768823080108,https://doi.org/10.1134/S0361768823080108,Journal,Programming and Computer Software,"Quantum computing is based on the principles of quantum mechanics, such as superposition, entanglement, measurement, and decoherence. The basic units of computation are qubits, which are abstract objects with a mathematical expression to implement the quantum mechanics principles. Alongside quantum hardware, software is a principal element for conducting quantum computing. The software consists of logic gates and quantum circuits that implement algorithms for the execution of quantum programs. Due to those characteristics, quantum computing is a paradigm that non-physics experts cannot understand. Under this new scheme for developing software, it is important to integrate a conceptual framework of the fundamentals on which quantum computing is based. In this paper, we present a kind of taxonomical view of the fundamental concepts of quantum computing and the derived concepts that integrate the emerging discipline of quantum software engineering. We performed a quasi-systematic mapping for conducting the systematic review because the objective of the review only intends to detect the fundamental concepts of quantum computing and quantum software. The results can help computer science students and professors as a starting point to address the study of this discipline.",Springer
"Ju{\'a}rez-Ram{\'i}rez, Reyes and Jim{\'e}nez, Samantha and Navarro, Christian X. and Guerra-Garc{\'i}a, C{\'e}sar and Perez-Gonzalez, Hector G. and Fern{\'a}ndez-y-Fern{\'a}ndez, Carlos and Ortiz-Hern{\'a}ndez, Javier and Cancino, Karina",Skills Required for Quantum Computing: A Comprehensive Review of Recent Studies,2024,10.1134/S0361768824700804,https://doi.org/10.1134/S0361768824700804,Journal,Programming and Computer Software,"Quantum mechanics as the basis of quantum computing imposes an inherent complexity for practitioners not formed on quantum physics, for understanding such new paradigm of computation and getting involved in the prominent quantum world. Strong technical skills on quantum topics, mathematics and related disciplines are required to attend job positions in the labor market. Furthermore, the multidisciplinary environment where quantum computing is immersed requires soft skills to work in integrative teams. This paper presents a literature review, supported by the systematic mapping methodology, to gather the core knowledge and technical skills, as well as soft skills required to prepare students and practitioners to work on quantum computing. The results allow us to have a wide spectrum of the competences involved, enabling academic institutions and educational bodies to design individual courses or curricula blocks to prepare the workforce.",Springer
"Alzoubi, Yehia Ibrahim and Gill, Asif and Mishra, Alok",A systematic review of the purposes of Blockchain and fog computing integration: classification and open issues,2022,10.1186/s13677-022-00353-y,https://doi.org/10.1186/s13677-022-00353-y,Journal,Journal of Cloud Computing,"The fog computing concept was proposed to help cloud computing for the data processing of Internet of Things (IoT) applications. However, fog computing faces several challenges such as security, privacy, and storage. One way to address these challenges is to integrate blockchain with fog computing. There are several applications of blockchain-fog computing integration that have been proposed, recently, due to their lucrative benefits such as enhancing security and privacy. There is a need to systematically review and synthesize the literature on this topic of blockchain-fog computing integration. The purposes of integrating blockchain and fog computing were determined using a systematic literature review approach and tailored search criteria established from the research questions. In this research, 181 relevant papers were found and reviewed. The results showed that the authors proposed the combination of blockchain and fog computing for several purposes such as security, privacy, access control, and trust management. A lack of standards and laws may make it difficult for blockchain and fog computing to be integrated in the future, particularly in light of newly developed technologies like quantum computing and artificial intelligence. The findings of this paper serve as a resource for researchers and practitioners of blockchain-fog computing integration for future research and designs.",Springer
"Eisenberg, Martin and Wimmer, Manuel",From single-objective to multi-objective reinforcement learning-based model transformation,2024,10.1007/s10270-024-01233-6,https://doi.org/10.1007/s10270-024-01233-6,Journal,Software and Systems Modeling,"Model-driven optimization allows to directly apply domain-specific modeling languages to define models which are subsequently optimized by applying a predefined set of model transformation rules. Objectives guide the optimization processes which can range from one single objective formulation resulting in one single solution to a set of objectives that necessitates the identification of a Pareto-optimal set of solutions. In recent years, a multitude of reinforcement learning approaches has been proposed that support both optimization cases and competitive results for various problem instances have been reported. However, their application to the field of model-driven optimization has not gained much attention yet, especially when compared to the extensive application of meta-heuristic search approaches such as genetic algorithms. Thus, there is a lack of knowledge about the applicability and performance of reinforcement learning for model-driven optimization. We therefore present in this paper a general framework for applying reinforcement learning to model-driven optimization problems. In particular, we show how a catalog of different reinforcement learning algorithms can be integrated with existing model-driven optimization approaches that use a transformation rule application encoding. We exemplify this integration by presenting a dedicated reinforcement learning extension for MOMoT. We build on this tool support and investigate several case studies for validating the applicability of reinforcement learning for model-driven optimization and compare the performance against a genetic algorithm. The results show clear advantages of using RL for single-objective problems, especially for cases where the transformation steps are highly dependent on each other. For multi-objective problems, the results are more diverse and case-specific, which further motivates the usage of model-driven optimization to utilize different approaches to find the best solutions.",Springer
"Sakhrawi, Zaineb and Labidi, Taher",Test case selection and prioritization approach for automated regression testing using ontology and COSMIC measurement,2024,10.1007/s10515-024-00447-8,https://doi.org/10.1007/s10515-024-00447-8,Journal,Automated Software Engineering,"Regression testing is an important activity that aims to provide information about the quality of the software product under test when changes occur. The two primary techniques for optimizing regression testing are test case selection and prioritization. To identify features affected by a change and determine the best test cases for selection and prioritization, techniques allowing the semantic representation and the quantification of testing concepts are required. The goal of this paper is threefold. Firstly, we proposed an ontology-based test case selection model that enables automated regression testing by dynamically selecting appropriate test cases. The selection of test cases is based on a semantic mapping between change requests and their associated test suites and test cases. Secondly, the selected test cases are prioritized based on their functional size. The functional size is determined using the COmmon Software Measurement International Consortium (COSMIC) Functional Size Measurement (FSM) method. The test case prioritization attempts to reorganize test case execution in accordance with its goal. One common goal is fault detection, in which test cases with a higher functional size (i.e., with a higher chance of detecting a fault) are run first, followed by the remaining test cases. Thirdly, we built an automated testing tool using the output of the aforementioned processes to validate the robustness of our proposed research methodology. Results from a case study in the automotive industry domain show that semantically presenting change requests and using standardized FSM methods to quantify their related test cases are the most interesting metrics. Obviously, they assist in the automation of regression testing and, therefore, in all the software testing processes.",Springer
"Klusch, Matthias and L{\""a}ssig, J{\""o}rg and M{\""u}ssig, Daniel and Macaluso, Antonio and Wilhelm, Frank K.",Quantum Artificial Intelligence: A Brief Survey,2024,10.1007/s13218-024-00871-8,https://doi.org/10.1007/s13218-024-00871-8,Journal,"KI - K{\""u}nstliche Intelligenz","Quantum Artificial Intelligence (QAI) is the intersection of quantum computing and AI, a technological synergy with expected significant benefits for both. In this paper, we provide a brief overview of what has been achieved in QAI so far and point to some open questions for future research. In particular, we summarize some major key findings on the feasability and the potential of using quantum computing for solving computationally hard problems in various subfields of AI, and vice versa, the leveraging of AI methods for building and operating quantum computing devices.",Springer
"Paul, Suman",A Comprehensive Review on Machine Learning-based Approaches for Next Generation Wireless Network,2024,10.1007/s42979-024-02831-3,https://doi.org/10.1007/s42979-024-02831-3,Journal,SN Computer Science,"Rapid progress of wireless communication and networks plays a critical role in different applications related to carrying out heterogeneous ever-increasing traffic in multimedia communication, remote health, and commercial applications. The fastest developments and uninterrupted upgradations in recent telecommunication networks regarding the deployment of the advanced 5G, which is being rolled out, draw attention to various research challenges and demanding transition requirements from existing 4G to 5G, beyond (B5G) and toward the 6G. These network upgradations strongly stipulate the need for system flexibility along with intelligent decisions at run-time with the integration of Artificial Intelligence (AI) and Machine Learning (ML)-based techniques. In this paper, various research challenges regarding the rolling out of advanced 5G network, the need for artificial intelligence in the rapidly emerging next generation wireless network (NGWN) along with various state-of-the-art approaches of the Artificial Intelligence and Machine learning, target applications, challenges regarding the incorporation of intelligence in the network have been investigated in a unified way. The paper highlights the contemporary cutting-edge developments of the telecom industry, research trends of network edge intelligence including the integration of federated learning (FL), allied challenges and open research issues in promising 6G networks.",Springer
"Sarkar, Aritra",Automated quantum software engineering,2024,10.1007/s10515-024-00436-x,https://doi.org/10.1007/s10515-024-00436-x,Journal,Automated Software Engineering,"As bigger quantum processors with hundreds of qubits become increasingly available, the potential for quantum computing to solve problems intractable for classical computers is becoming more tangible. Designing efficient quantum algorithms and software in tandem is key to achieving quantum advantage. Quantum software engineering is challenging due to the unique counterintuitive nature of quantum logic. Moreover, with larger quantum systems, traditional programming using quantum assembly language and qubit-level reasoning is becoming infeasible. Automated Quantum Software Engineering (AQSE) can help to reduce the barrier to entry, speed up development, reduce errors, and improve the efficiency of quantum software. This article elucidates the motivation to research AQSE (why), a precise description of such a framework (what), and reflections on components that are required for implementing it (how).",Springer
"Moslehi, Parisa and Adams, Bram and Rilling, Juergen",A feature location approach for mapping application features extracted from crowd-based screencasts to source code,2020,10.1007/s10664-020-09874-z,https://doi.org/10.1007/s10664-020-09874-z,Journal,Empirical Software Engineering,"Crowd-based multimedia documents such as screencasts have emerged as a source for documenting requirements, the workflow and implementation issues of open source and agile software projects. For example, users can show and narrate how they manipulate an application's GUI to perform a certain functionality, or a bug reporter could visually explain how to trigger a bug or a security vulnerability. Unfortunately, the streaming nature of programming screencasts and their binary format limit how developers can interact with a screencast's content. In this research, we present an automated approach for mining and linking the multimedia content found in screencasts to their relevant software artifacts and, more specifically, to source code. We apply LDA-based mining approaches that take as input a set of screencast artifacts, such as GUI text and spoken word, to make the screencast content accessible and searchable to users and to link it to their relevant source code artifacts. To evaluate the applicability of our approach, we report on results from case studies that we conducted on existing WordPress and Mozilla Firefox screencasts. We found that our automated approach can significantly speed up the feature location process. For WordPress, we find that our approach using screencast speech and GUI text can successfully link relevant source code files within the top 10 hits of the result set with median Reciprocal Rank (RR) of 50{\%} (rank 2) and 100{\%} (rank 1). In the case of Firefox, our approach can identify relevant source code directories within the top 100 hits using screencast speech and GUI text with the median RR{\thinspace}={\thinspace}20{\%}, meaning that the first true positive is ranked 5 or higher in more than 50{\%} of the cases. Also, source code related to the frontend implementation that handles high-level or GUI-related aspects of an application is located with higher accuracy. We also found that term frequency rebalancing can further improve the linking results when using less noisy scenarios or locating less technical implementation of scenarios. Investigating the results of using original and weighted screencast data sources (speech, GUI, speech and GUI) that can result in having the highest median RR values in both case studies shows that speech data is an important information source that can result in having RR of 100{\%}.",Springer
"Akbar, Muhammad Azeem and Khan, Arif Ali and Rafi, Saima",A systematic decision-making framework for tackling quantum software engineering challenges,2023,10.1007/s10515-023-00389-7,https://doi.org/10.1007/s10515-023-00389-7,Journal,Automated Software Engineering,"Quantum computing systems harness the power of quantum mechanics to execute computationally demanding tasks more effectively than their classical counterparts. This has led to the emergence of Quantum Software Engineering (QSE), which focuses on unlocking the full potential of quantum computing systems. As QSE gains prominence, it seeks to address the evolving challenges of quantum software development by offering comprehensive concepts, principles, and guidelines. This paper aims to identify, prioritize, and develop a systematic decision-making framework of the challenging factors associated with QSE process execution. We conducted a literature survey to identify the challenging factors associated with QSE process and mapped them into 7 core categories. Additionally, we used a questionnaire survey to collect insights from practitioners regarding these challenges. To examine the relationships between core categories of challenging factors, we applied Interpretive Structure Modeling (ISM). Lastly, we applied fuzzy TOPSIS to rank the identified challenging factors concerning to their criticality for QSE process. We have identified 22 challenging factors of QSE process and mapped them to 7 core categories. The ISM results indicate that the `resources' category has the most decisive influence on the other six core categories of the identified challenging factors. Moreover, the fuzzy TOPSIS indicates that `complex programming', `limited software libraries', `maintenance complexity', `lack of training and workshops', and `data encoding issues' are the highest priority challenging factor for QSE process execution. Organizations using QSE could consider the identified challenging factors and their prioritization to improve their QSE process.",Springer
"Ikegwu, Anayo Chukwu and Nweke, Henry Friday and Anikwe, Chioma Virginia",Recent trends in computational intelligence for educational big data analysis,2024,10.1007/s42044-023-00158-5,https://doi.org/10.1007/s42044-023-00158-5,Journal,Iran Journal of Computer Science,"Educational big data analytics and computational intelligence have transformed our understanding of learning ability and computing power, catalyzing the emergence of Education 4.0. However, educators and researchers still struggle to identify appropriate methods to analyze the diverse data generated within educational environments. The complexity and uncertainty inherent in heterogeneous and homogeneous data often compound these challenges. This study aims to explore the potential applications of computational intelligence methods to support educational big data analysis. We begin by discussing the processes involved in educational big data analytics (EDA), including data collection, data preprocessing, feature extraction, modeling, and evaluation. We then provided an extensive review of computational intelligence and its methods, including artificial intelligence approaches, machine learning methods, deep learning methods, meta-heuristic optimization approaches, ensemble techniques, and the Markov model, as applied to educational big data analysis. Furthermore, we discussed novel application areas for computational intelligence in education, including predicting academic performance, social network analysis, detecting undesirable student behaviors, adaptive curriculum sequencing and personalization, courseware development, and decision support systems. We also mapped various computational intelligence methods to these novel application areas. Despite the progress made in educational big data analytics implementation, challenging research areas still require further investigation. These research areas include enhanced academic performance prediction, data-driven intelligent tutoring systems, adversarial machine learning, student engagement, personalized learning, and more. In this paper, we briefly discussed these ten important research directions.",Springer
"Alvarado-Valiente, Jaime and Romero-{\'A}lvarez, Javier and Moguel, Enrique and Garc{\'i}a-Alonso, Jos{\'e} and Murillo, Juan M.",Technological diversity of quantum computing providers: a comparative study and a proposal for API Gateway integration,2024,10.1007/s11219-023-09633-5,https://doi.org/10.1007/s11219-023-09633-5,Journal,Software Quality Journal,"After decades of advances, mainly theoretical, in recent years quantum computing has begun to show its first practical applications. This new and revolutionary technology aims to enhance essential areas such as cybersecurity, financial services, or medicine. The growth of this technology has encouraged different research centers and big companies such as IBM, Amazon, and Google to dedicate considerable efforts to developing new technologies that bring quantum computing to the market. However, these technologies are not yet mature and create a significant vendor lock-in problem. Therefore, new tools are needed that facilitate access to this technology and that allow developers to increase the abstraction level at which they work. Given that the integration of quantum software should not be very different from that of classical services, we can take advantage of the knowledge acquired and use current techniques of service-oriented computing. In this work, we have carried out a technical comparison between different quantum computing service providers using a case study, by performing empirical tests based on the Travelling Salesman Problem. This study highlights the differences between the main providers. To address these differences and reduce the vendor lock-in effect, we propose an extension of the Quantum API Gateway to support the different providers and the casuistry that each one presents. This would allow programmers to deploy quantum code without vendor-specific knowledge of the major providers, which would facilitate access and simplify the development of quantum applications.",Springer
"Stollenwerk, Tobias and Bhattacharya, Somtapa and Cattelan, Michele and Ciani, Alessandro and Compostella, Gabriele and Headley, David and Klepsch, Johannes and Klusch, Matthias and Leder, Markus and Macaluso, Antonio and Michielsen, Kristel and Nabok, Dmytro and Papanikolaou, Anestis and Rausch, Alexander and Schumann, Marco and Skolik, Andrea and Yarkoni, Sheir and Wilhelm, Frank K.",{\$}{\$}{\backslash}mathrm{\{}Q(AI){\}}^2{\$}{\$}: Quantum Artificial Intelligence for the Automotive Industry,2024,10.1007/s13218-024-00862-9,https://doi.org/10.1007/s13218-024-00862-9,Journal,"KI - K{\""u}nstliche Intelligenz",,Springer
"Dhiman, Shalini and Mahato, Ganesh Kumar and Chakraborty, Swarnendu Kumar","Homomorphic Encryption Library, Framework, Toolkit and Accelerator: A Review",2023,10.1007/s42979-023-02316-9,https://doi.org/10.1007/s42979-023-02316-9,Journal,SN Computer Science,"Homomorphic encryption ensures secure computation on encrypted data without the need for decryption beforehand. It enables the secure offloading of computations to untrusted servers. This paper provides a comprehensive description of multiple methods for conducting secure computations, along with the appropriate approaches and tools needed for successful implementation. Various strategies are outlined for selecting a suitable homomorphic encryption (HE) library, assisting developers and researchers in determining the most suitable library for their projects. To begin with, the paper presents a comparison of homomorphic encryption libraries based on different parameters. Additionally, it outlines the steps involved in choosing the right framework for effective implementation, comparing them based on various parameters. The Framework discussed in the paper supports a range of homomorphic encryption libraries and provides detailed information about them. Furthermore, the paper surveys three different homomorphic encryption accelerators and compares them to determine which one would maximize bootstrapping throughput when implemented. Lastly, the Fully Homomorphic Encryption-IBM toolkit is discussed. This toolkit supports the development of resources, primarily involved in the flow of messages. The paper concludes that secure computation is achievable by implementing the appropriate tools, considering their performance and implementation limitations. Moreover, the selection of the appropriate library, framework, and accelerator depends on the specific demands and requirements of the implementation chosen by the developer.",Springer
"Khan, Arif Ali and Akbar, Muhammad Azeem and Lahtinen, Valtteri and Paavola, Marko and Niazi, Mahmood and Alatawi, Mohammed Naif and Alotaibi, Shoayee Dlaim",Agile meets quantum: a novel genetic algorithm model for predicting the success of quantum software development project,2024,10.1007/s10515-024-00434-z,https://doi.org/10.1007/s10515-024-00434-z,Journal,Automated Software Engineering,"Quantum software systems represent a new realm in software engineering, utilizing quantum bits (Qubits) and quantum gates (Qgates) to solve the complex problems more efficiently than classical counterparts. Agile software development approaches are considered to address many inherent challenges in quantum software development, but their effective integration remains unexplored. This study investigates key causes of challenges that could hinders the adoption of traditional agile approaches in quantum software projects and develop an Agile-Quantum Software Project Success Prediction Model (AQSSPM). Firstly, we identified 19 causes of challenging factors discussed in our previous study, which are potentially impacting agile-quantum project success. Secondly, a survey was conducted to collect expert opinions on these causes and applied Genetic Algorithm (GA) with Naive Bayes Classifier (NBC) and Logistic Regression (LR) to develop the AQSSPM. Utilizing GA with NBC, project success probability improved from 53.17 to 99.68{\%}, with cost reductions from 0.463 to 0.403{\%}. Similarly, GA with LR increased success rates from 55.52 to 98.99{\%}, and costs decreased from 0.496 to 0.409{\%} after 100 iterations. Both methods result showed a strong positive correlation (rs{\thinspace}={\thinspace}0.955) in causes ranking, with no significant difference between them (t{\thinspace}={\thinspace}1.195, p{\thinspace}={\thinspace}0.240{\thinspace}>{\thinspace}0.05). The AQSSPM highlights critical focus areas for efficiently and successfully implementing agile-quantum projects considering the cost factor of a particular project.","Springer, Web of Science"
"Prity, Farida Siddiqi and Uddin, K. M. Aslam and Nath, Nishu","Exploring swarm intelligence optimization techniques for task scheduling in cloud computing: algorithms, performance analysis, and future prospects",2024,10.1007/s42044-023-00163-8,https://doi.org/10.1007/s42044-023-00163-8,Journal,Iran Journal of Computer Science,"The advent of the cloud computing paradigm has enabled innumerable organizations to seamlessly migrate, compute, and host their applications within the cloud environment, affording them facile access to a broad spectrum of services with minimal exertion. A proficient and adaptable task scheduler is essential to manage simultaneous user requests for diverse cloud services using various heterogeneous and varied resources. Inadequate scheduling may result in issues related to either under-utilization or over-utilization of resources, potentially causing a waste of cloud resources or a decline in service performance. Swarm intelligence meta-heuristics optimization technique has evinced conspicuous efficacy in tackling the intricacies of scheduling difficulties. Thus, the present manuscript seeks to undertake an exhaustive review of swarm intelligence optimization techniques deployed in the task-scheduling domain within cloud computing. This paper examines various swarm-based algorithms, investigates their application to task scheduling in cloud environments, and provides a comparative analysis of the discussed algorithms based on various performance metrics. This study also compares different simulation tools for these algorithms, highlighting challenges and proposing potential future research directions in this field. This review paper aims to shed light on the state-of-the-art swarm-based algorithms for task scheduling in cloud computing, showing their potential to improve resource allocation, enhance system performance, and efficiently utilize cloud resources.",Springer
"Punia, Aarti and Gulia, Preeti and Gill, Nasib Singh and Ibeke, Ebuka and Iwendi, Celestine and Shukla, Piyush Kumar",A systematic review on blockchain-based access control systems in cloud environment,2024,10.1186/s13677-024-00697-7,https://doi.org/10.1186/s13677-024-00697-7,Journal,Journal of Cloud Computing,"The widespread adoption of cloud computing has dramatically altered how data is stored, processed, and accessed in an era. The rapid development of digital technologies characterizes all this. The widespread adoption of cloud services has introduced new obstacles to guaranteeing secure and expeditious access to sensitive data. Organizations of all types find user-friendly and cost-effective solutions crucial, which is why they consider cloud services essential. The availability of the cloud hampers access control security in systems that are constantly and remotely changing. Conventional methods of access control are efficient, but the advanced world of technology exposes them to more threats. Applying blockchain technology to cloud access control systems, which are decentralized, transparent, and tamper-proof, has overcome these challenges. This paper aims to discuss the potential of blockchain in enhancing access management, security and trust in cloud computing. Besides, this scholarly article reviews the evolving area of blockchain-based access control systems and synthesizes the findings of 118 selected papers from various academic repositories. Based on this systematic review of the studies, twelve different types of blockchain-based access control paradigms can be identified. This work provides a critical analysis of the research on blockchain technology in access control systems, with a focus on scalability, compatibility, and security challenges. It also highlights areas that require further research and proposes directions for future research to advance this rapidly growing area of scholarship.",Springer
"Khan, Arif Ali and Khan, Javed Ali and Akbar, Muhammad Azeem and Zhou, Peng and Fahmideh, Mahdi",Insights into software development approaches: mining Q {\&}A repositories,2023,10.1007/s10664-023-10417-5,https://doi.org/10.1007/s10664-023-10417-5,Journal,Empirical Software Engineering,"Software practitioners adopt approaches like DevOps, Scrum, and Waterfall for high-quality software development. However, limited research has been conducted on exploring software development approaches concerning practitioners' discussions on Q {\&}A forums.",Springer
"Kumar, Preethika Ajay and Manoj, Nandana and Sudheer, Neeraj and Bhat, Pranamya P. and Arya, Arti and Sharma, Richa",UAV Swarm Objectives: A Critical Analysis and Comprehensive Review,2024,10.1007/s42979-024-03156-x,https://doi.org/10.1007/s42979-024-03156-x,Journal,SN Computer Science,"Unmanned Aerial Vehicles (UAVs) are now used in multiple sectors for a vast array of purposes. These vehicles working in swarms can be used for reconnaissance, search and rescue, photography, and crop monitoring. In addition, the versatility of UAVs is highly utilized by several governments to play an integral role in the defense of a country. This survey paper provides a comprehensive study of the various advancements in the field of UAV swarms, such as Maximal Area Coverage, Path Planning, Intra-swarm collision avoidance, Obstacle avoidance, Formation of Swarms, Target tracking and Optimal resource allocation. An extensive study has been performed on each of these objectives, and an overview of the same has been consolidated from the year 2005--2024 in this survey. This study thoroughly examines the unique approaches used to accomplish the endeavors assigned to the UAV swarms. Moreover, the challenges and potential for future advancements in all the studies above have been highlighted. The research areas in the cutting-edge field of generative artificial intelligence have been clearly defined. This survey highlights significant advancements in UAV swarm technology over nearly two decades, focusing on key areas like coverage, path planning, and collision avoidance. It also outlines the challenges and future potential in integrating generative AI for further development.",Springer
"Curty, Simon and H{\""a}rer, Felix and Fill, Hans-Georg",Design of blockchain-based applications using model-driven engineering and low-code/no-code platforms: a structured literature review,2023,10.1007/s10270-023-01109-1,https://doi.org/10.1007/s10270-023-01109-1,Journal,Software and Systems Modeling,"The creation of blockchain-based software applications requires today considerable technical knowledge, particularly in software design and programming. This is regarded as a major barrier in adopting this technology in business and making it accessible to a wider audience. As a solution, low-code and no-code approaches have been proposed that require only little or no programming knowledge for creating full-fledged software applications. In this paper we extend a review of academic approaches from the discipline of model-driven engineering as well as industrial low-code and no-code development platforms for blockchains. This includes a content-based, computational analysis of relevant academic papers and the derivation of major topics. In addition, the topics were manually evaluated and refined. Based on these analyses we discuss the spectrum of approaches in this field and derive opportunities for further research.",Springer
"Yakubu, Jimoh and Abdulhamid, Shafi'i Muhammad and Christopher, Haruna Atabo and Chiroma, Haruna and Abdullahi, Mohammed",Security challenges in fog-computing environment: a systematic appraisal of current developments,2019,10.1007/s40860-019-00081-2,https://doi.org/10.1007/s40860-019-00081-2,Journal,Journal of Reliable Intelligent Environments,"Fog computing is a new paradigm of computing that extends cloud-computing operations to the edges of the network. The fog-computing services provide location sensitivity, reduced latency, geographical accessibility, wireless connectivity, and enhanced improved data streaming. However, this computing paradigm is not an alternative for cloud computing and it comes with numerous security and privacy challenges. This paper provides a systematic literature review on the security challenges in fog-computing system. It reviews several architectures that are vital to support the security of fog environment and then created a taxonomy based on the different security techniques used. These include machine learning, cryptographic techniques, computational intelligence, and other techniques that differentiate this paper from the previous reviews in this area of research. Nonetheless, most of the proposed techniques used to solve security issues in fog computing could not completely addressed the security challenges due to the limitation of the various techniques. This review is intended to guide experts and novice researchers to identify certain areas of security challenges in fog computing for future improvements.",Springer
"Fortz, Sophie and Temple, Paul and Devroey, Xavier and Heymans, Patrick and Perrouin, Gilles",VaryMinions: leveraging RNNs to identify variants in variability-intensive systems' logs,2024,10.1007/s10664-024-10473-5,https://doi.org/10.1007/s10664-024-10473-5,Journal,Empirical Software Engineering,"From business processes to course management, variability-intensive software systems (VIS) are now ubiquitous. One can configure these systems' behaviour by activating options, e.g., to derive variants handling building permits across municipalities or implementing different functionalities (quizzes, forums) for a given course. These customisation facilities allow VIS to support distinct relevant customer requirements while taking advantage of reuse for common parts. Customisation thus allows realising both scope and scale economies. Behavioural differences amongst variants manifest themselves in event logs. To re-engineer this kind of system, one must know which variant(s) have produced which behaviour. Since variant information is barely present in logs, this paper supports this task by employing machine learning techniques to classify behaviours (event sequences) among variants. Specifically, we train Long Short Term Memory (LSTMs) and Gated Recurrent Units (GRUs) recurrent neural networks to relate event sequences with the variants they belong to on six different datasets issued from the configurable process and VIS domains. After having evaluated 20 different architectures of LSTM/GRU, our results demonstrate that it is possible to effectively learn the trace-to-variant mapping with high accuracy (at least {\$}{\$}80{\backslash}{\%}{\$}{\$}and up to {\$}{\$}99{\backslash}{\%}{\$}{\$}) and at scale, i.e., identifying 50 variants using 5000+ traces for each variant.",Springer
"Saini, Himani and Singh, Gopal and Dalal, Sandeep and Moorthi, Iyyappan and Aldossary, Sultan Mesfer and Nuristani, Nasratullah and Hashmi, Arshad",A hybrid machine learning model with self-improved optimization algorithm for trust and privacy preservation in cloud environment,2024,10.1186/s13677-024-00717-6,https://doi.org/10.1186/s13677-024-00717-6,Journal,Journal of Cloud Computing,"The rapid adoption of cloud-based data sharing is transforming collaboration across various sectors, yet ensuring trust and privacy in sensitive data remains a critical challenge. This paper presents a hybrid model aimed at enhancing data privacy and trust in cloud environments, specifically addressing concerns in healthcare and finance. The model combines k-anonymity for user privacy, an optimized Firefly algorithm for trust generation, and a Time-aware Modified Best Fit Decreasing (T-MBFD) algorithm to improve resource allocation efficiency. Key contributions include a comprehensive methodology that encompasses dataset selection, preprocessing, model training, and evaluation across multiple datasets, including healthcare, financial, and pandemic-related data. Experimental results demonstrate that the hybrid model achieves a precision score of approximately 90{\%} and an accuracy of around 93{\%} in financial datasets, significantly outperforming existing methods in both privacy preservation and computational efficiency. These findings emphasize the model's effectiveness in securely facilitating data-driven collaboration in highly regulated domains, thus paving the way for practical applications that uphold individual privacy and data integrity in cloud-based environments.",Springer
"Bucaioni, Alessio and Cicchetti, Antonio and Ciccozzi, Federico",Modelling in low-code development: a multi-vocal systematic review,2022,10.1007/s10270-021-00964-0,https://doi.org/10.1007/s10270-021-00964-0,Journal,Software and Systems Modeling,"In 2014, a new software development approach started to get a foothold: low-code development. Already from its early days, practitioners in software engineering have been showing a rapidly growing interest in low-code development. In 2021 only, the revenue of low-code development technologies reached 13.8 billion USD. Moreover, the business success of low-code development has been sided by a growing interest from the software engineering research community. The model-driven engineering community has shown a particular interest in low-code development due to certain similarities between the two. In this article, we report on the planning, execution, and results of a multi-vocal systematic review on low-code development, with special focus to its relation to model-driven engineering. The review is intended to provide a structured and comprehensive snapshot of low-code development in its peak of inflated expectations technology adoption phase. From an initial set of potentially relevant 720 peer-reviewed publications and 199 grey literature sources, we selected 58 primary studies, which we analysed according to a meticulous data extraction, analysis, and synthesis process. Based on our results, we tend to frame low-code development as a set of methods and/or tools in the context of a broader methodology, often being identified as model-driven engineering.",Springer
"Ferrara, Pietro and Arceri, Vincenzo and Cortesi, Agostino","Challenges of software verification: the past, the present, the future",2024,10.1007/s10009-024-00765-y,https://doi.org/10.1007/s10009-024-00765-y,Journal,International Journal on Software Tools for Technology Transfer,"Software verification aims to prove that a program satisfies some given properties for all its possible executions. Software evolved incredibly fast during the last century, exposing several challenges to this scientific discipline. The goal of the ``Challenges of Software Verification Symposium'' is to monitor the state-of-the-art in this field. In this article, we will present the evolution of software from its inception in the 1940s to today's applications, how this exposed new challenges to software verification, and what this discipline achieved. We will then discuss how this chapter covers most of the current open challenges, the possible future software developments, and what challenges this will raise in software verification.",Springer
"Abdollahi, Jafar and Aref, Solmaz",Early Prediction of Diabetes Using Feature Selection and Machine Learning Algorithms,2024,10.1007/s42979-023-02545-y,https://doi.org/10.1007/s42979-023-02545-y,Journal,SN Computer Science,"Diabetes has become one of the most common diseases in middle- and low-income countries. Machine learning (ML) and data mining techniques have recently been used to predict diabetes with a high success rate. As a result, medical professionals seek a dependable method for predicting diagnosis. Of course, the feature selection process may be considered a global combinatorial optimization problem in machine learning. The number of features is reduced, irrelevant, noisy, redundant data are removed, and classification accuracy is acceptable. This work uses particle swarm optimization (PSO) to implement feature selection, followed by performance comparison. After that, three medical datasets are used to compare the performance of several machine learning methods. Standard approaches are used to determine the optimum technique for the three datasets. The best results for three datasets are reported for each scheme. The primary goal is to assess the validity of each algorithm's data classification in terms of efficiency and effectiveness in terms of accuracy, sensitivity, and specificity. Decision Tree, Random Forest, and Na{\""i}ve Bayes deliver the highest accuracy with the lowest mistake rate, according to the findings of the experiments. Machine learning may classify and determine which instances should be sent to medical for further evaluation and treatment with high accuracy. Using such an algorithm on a global scale could help minimize the number of people diagnosed with diabetes.",Springer
"Sas, Darius and Avgeriou, Paris",Quality attribute trade-offs in the embedded systems industry: an exploratory case study,2020,10.1007/s11219-019-09478-x,https://doi.org/10.1007/s11219-019-09478-x,Journal,Software Quality Journal,"The embedded systems domain has grown exponentially over the past years. The industry is forced by the market to rapidly improve and release new products to beat the competition. Frenetic development rhythms thus shape this domain and give rise to several new challenges for software design and development. One of them is dealing with trade-offs between run-time and design-time quality attributes. To study practices, processes and tools concerning the management of run-time and design-time quality attributes as well as the trade-offs among them from the perspective of embedded systems software engineers. An exploratory case study with two qualitative data collection steps, namely interviews and a focus group, involving six different companies from the embedded systems domain with a total of twenty participants. The interviewed subjects showed a preference for run-time over design-time qualities. Trade-offs between design-time and run-time qualities are very common, but they are often implicit, due to the lack of adequate monitoring tools and practices. Practitioners prefer to deal with trade-offs in the most lightweight way possible, by applying ad-hoc practices, thus avoiding any overhead incurred. Finally, practitioners have elaborated on how they envision the ideal tool support for dealing with trade-offs. Although it is notoriously difficult to deal with trade-offs, constantly monitoring the quality attributes of interest with automated tools is key in making explicit and prudent trade-offs and mitigating the risk of incurring technical debt.",Springer
"Serrano, Manuel A. and S{\'a}nchez, Luis E. and Santos-Olmo, Antonio and Garc{\'i}a-Rosado, David and Blanco, Carlos and Barletta, Vita Santa and Caivano, Danilo and Fern{\'a}ndez-Medina, Eduardo",Minimizing incident response time in real-world scenarios using quantum computing,2024,10.1007/s11219-023-09632-6,https://doi.org/10.1007/s11219-023-09632-6,Journal,Software Quality Journal,"The Information Security Management Systems (ISMS) are global and risk-driven processes that allow companies to develop their cybersecurity strategy by defining security policies, valuable assets, controls, and technologies for protecting their systems and information from threats and vulnerabilities. Despite the implementation of such management infrastructures, incidents or security breaches happen. Each incident has associated a level of severity and a set of mitigation controls, so in order to restore the ISMS, the appropriate set of controls to mitigate their damage must be selected. The time in which the ISMS is restored is a critical aspect. In this sense, classic solutions are efficient in resolving scenarios with a moderate number of incidents in a reasonable time, but the response time increases exponentially as the number of incidents increases. This makes classical solutions unsuitable for real scenarios in which a large number of incidents are handled and even less appropriate for scenarios in which security management is offered as a service to several companies. This paper proposes a solution to the incident response problem that acts in a minimal amount of time for real scenarios in which a large number of incidents are handled. It applies quantum computing, as a novel approach that is being successfully applied to real problems, which allows us to obtain solutions in a constant time regardless of the number of incidents handled. To validate the applicability and efficiency of our proposal, it has been applied to real cases using our framework (MARISMA).",Springer
"Langdon, W. B.",Jaws 30,2023,10.1007/s10710-023-09467-x,https://doi.org/10.1007/s10710-023-09467-x,Journal,Genetic Programming and Evolvable Machines,"It is 30 years since John R. Koza published ``Jaws'', the first book on genetic programming [Genetic Programming: On the Programming of Computers by Means of Natural Selection. MIT Press (1992)]. I recount and expand the celebration at GECCO 2022, very briefly summarise some of what the rest of us have done and make suggestions for the next thirty years of GP research.",Springer
"Jurcut, Anca and Niculcea, Tiberiu and Ranaweera, Pasika and Le-Khac, Nhien-An",Security Considerations for Internet of Things: A Survey,2020,10.1007/s42979-020-00201-3,https://doi.org/10.1007/s42979-020-00201-3,Journal,SN Computer Science,"Interconnecting ``things'' and devices that takes the form of wearables, sensors, actuators, mobiles, computers, meters, or even vehicles is a critical requirement for the current era. These inter-networked connections are serving the emerging applications home and building automation, smart cities and infrastructure, smart industries, and smart-everything. However, the security of these connected Internet of things (IoT) plays a centric role with no margin for error. After a review of the relevant, online literature on the topic and after looking at the market trends and developments, one can notice that there are still concerns with regard to security in IoT products and services. This paper is focusing on a survey on IoT security and aims to highlight the most significant problems related to safety and security in the IoT ecosystems. This survey identifies the general threat and attack vectors against IoT devices while highlighting the flaws and weak points that can lead to breaching the security. Furthermore, this paper presents solutions for remediation of the compromised security, as well as methods for risk mitigation, with prevention and improvement suggestions.",Springer
"Hussain, Sajid and Songhua, Xu and Aslam, Muhammad Usman and Hussain, Fida and Ali, Iftikhar",Optimal Prognostic Accuracy: Machine Learning Approaches for COVID-19 Prognosis with Biomarkers and Demographic Information,2024,10.1007/s00354-024-00261-6,https://doi.org/10.1007/s00354-024-00261-6,Journal,New Generation Computing,"The global emergence of the unprecedented COVID-19 pandemic in late 2019 has led to millions of infections and thousands of fatalities, profoundly affecting various aspects of life. The continual genetic evolution of the virus highlights the critical need for accurate prognostic tools. In response, this study introduces a machine learning-based approach that leverages the capabilities of Quantum Neural Networks (QNN) to predict the lethal risk of COVID-19 patients, aiming to support physicians and healthcare administrators with insightful data for informed decision-making. Leveraging demographic information and biomarker-based dataset, the Relief method and Matrix factorization feature selection approaches were employed for the feature engineering. In addition, our in-depth descriptive analysis revealed specific demographic factors and comorbidities that intricately contribute to an elevated risk of mortality among COVID-19 patients, emphasizing the nuanced dynamics influencing fatal outcomes. A comprehensive comparative analysis compared QNN with a range of machine learning and deep learning algorithms. The findings demonstrate the potential of our prototype prognostic model in stratifying the mortality risk among COVID-19 patients, offering valuable insights for healthcare professionals to make informed decisions in clinical practice.",Springer
"Acharya, Biswaranjan and Panda, Sucheta and Sivakumar, Eashwar",An Analytical Study of Multiprocessor Scheduling Using Metaheuristic Approach,2022,10.1007/s42979-022-01398-1,https://doi.org/10.1007/s42979-022-01398-1,Journal,SN Computer Science,"The process scheduling in the distributed and heterogeneous environment is the principal concern which can influence the execution performance of the application. The multiprocessor scheduling concept in grid environment incepts from 1980. After a decade in 1992 heuristic and evolutionary approaches started to solve these issues followed by nature inspired metaheuristic algorithms which started in the twentieth century. This paper provides a taxonomy of scheduling techniques which defines characteristics of each technique and gives some prominent algorithms as an example. Many research works have been done for minimizing execution cost and makespan as the influencing parameters for the scheduling of the dependent processes but few researchers have considered energy utilization, memory utilization and miss rate. This paper describes different types of algorithms starting from traditional algorithms from the year 1984 and consequently, metaheuristic algorithms including nature-inspired, bio-inspired, swarm intelligence-based techniques used for multiprocessor scheduling optimization purposes in different real-time applications up to 2019. It also defines available simulation tool for simulating scheduling algorithms. This paper will empower the beginners to select appropriate techniques according to their requirements and especially it will be a great help for getting a road map for different scheduling techniques and its applications.",Springer
"Geng, Tongsheng and Amaris, Marcos and Zuckerman, St{\'e}phane and Goldman, Alfredo and Gao, Guang R. and Gaudiot, Jean-Luc",A Profile-Based AI-Assisted Dynamic Scheduling Approach for Heterogeneous Architectures,2022,10.1007/s10766-021-00721-2,https://doi.org/10.1007/s10766-021-00721-2,Journal,International Journal of Parallel Programming,"While heterogeneous architectures are increasing popular with High Performance Computing systems, their effectiveness depends on how efficient the scheduler is at allocating workloads onto appropriate computing devices and how communication and computation can be overlapped. With different types of resources integrated into one system, the complexity of the scheduler correspondingly increases. Moreover, for applications with varying problem sizes on different heterogeneous resources, the optimal scheduling approach may vary accordingly. Thus, we introduce a Profile-based AI-assisted Dynamic Scheduling approach to dynamically and adaptively adjust workloads and efficiently utilize heterogeneous resources. It combines online scheduling, application profile information, hardware mathematical modeling and offline machine learning estimation modeling to implement automatic application-device-specific scheduling for heterogeneous architectures. A hardware mathematical model provides coarse-grain computing resource selection while the profile information and offline machine learning model estimates the performance of a fine-grain workload, and an online scheduling approach dynamically and adaptively distributes the workload. Our scheduling approach is tested on control-regular applications, 2D and 3D Stencil kernels (based on a Jacobi Algorithm), and a data-irregular application, Sparse Matrix-Vector Multiplication, in an event-driven runtime system. Experimental results show that PDAWL is either on-par or far outperforms whichever yields the best results (CPU or GPU).",Springer
"Kumar, B. P. Pradeep and Manoj, H. M.",Comparative Assessment of Machine Learning Models for Predicting Glucose Intolerance Risk,2024,10.1007/s42979-024-03259-5,https://doi.org/10.1007/s42979-024-03259-5,Journal,SN Computer Science,"This study focuses on predictive analytics and healthcare, specifically the prediction of Glucose Intolerance, a chronic metabolic disease with significant global health implications. The research aims to develop efficient tools for risk assessment and early identification, offering medical practitioners reliable instruments for identifying high-risk patients and implementing preventive measures in a timely manner. A significant challenge in managing Glucose Intolerance is the absence of effective and precise prediction models. Traditional risk assessment techniques often fail to capture the multifaceted nature of Glucose Intolerance development, leading to delayed treatments and suboptimal patient outcomes. To address this issue, we conducted a comprehensive study utilizing various machine learning algorithms, including Decision Trees, Random Forest, Gradient Boosting, CatBoost, K-Nearest Neighbors (KNN), Support Vector Classifier (SVC), Logistic Regression, and a Voting Classifier, to predict Glucose Intolerance. The primary objective was to identify the most effective combination of features and models for accurate predictions. Key factors considered included patient demographics, lifestyle characteristics, medical history, and genetic susceptibility, which were used to build robust and personalized prediction models. We conducted a comparative analysis of the machine learning models' performance based on cross-validated accuracy with test-train splits and folds: 0.2, 6; 0.05, 4; 0.1, 2; 0.2, 6; and 0.05, 2. The results showed that Random Forest achieved test accuracies of 74{\%}, 76{\%}, 82{\%}, 75{\%}, and 79{\%}; KNN achieved 70{\%}, 72{\%}, 74{\%}, 75{\%}, and 72{\%}; SVC achieved 74{\%}, 72{\%}, 77{\%}, 77{\%}, and 72{\%}; Logistic Regression achieved 73{\%}, 76{\%}, 79{\%}, 73{\%}, and 76{\%}; Gradient Boosting achieved 72{\%}, 79{\%}, 75{\%}, 73{\%}, and 79{\%}; XGBoost achieved 72{\%}, 79{\%}, 77{\%}, 74{\%}, and 79{\%}; CatBoost achieved 74{\%}, 76{\%}, 79{\%}, 75{\%}, and 76{\%}; Decision Tree achieved 60{\%}, 83{\%}, 74{\%}, 70{\%}, and 79{\%}; and Voting Classifier achieved 74{\%}, 72{\%}, 77{\%}, 74{\%}, and 72{\%}. These results highlight the strengths and limitations of each model, providing insights into their suitability for Glucose Intolerance prediction. The findings have significant implications for the prevention and early detection of Glucose Intolerance. By accurately identifying high-risk patients, healthcare practitioners can implement targeted interventions and lifestyle modifications, thereby improving patient outcomes and reducing the overall burden of Glucose Intolerance-related complications. The proposed models hold promise for enhancing Glucose Intolerance management through personalized therapy.",Springer
"Prity, Farida Siddiqi and Hossain, Md. Maruf","A comprehensive examination of load balancing algorithms in cloud environments: a systematic literature review, comparative analysis, taxonomy, open challenges, and future trends",2024,10.1007/s42044-024-00183-y,https://doi.org/10.1007/s42044-024-00183-y,Journal,Iran Journal of Computer Science,"Cloud computing is a robust paradigm that empowers users and organizations to procure services tailored to their needs. This model encompasses many offerings, including storage solutions, platforms for seamless deployment, and convenient access to web services. Load balancing, a fundamental pillar in cloud computing, is crucial in distributing requests across multiple servers to optimize resource utilization and reduce response times. However, load balancing presents a common challenge in the cloud environment, as it hampers the ability to maintain optimal application performance while adhering to the stringent requirements of Quality of Service (QoS) measurements and Service Level Agreement (SLA) compliance mandated by cloud providers to enterprises. The equitable workload distribution across servers poses a significant challenge for cloud providers. Hence, an efficient load-balancing technique should optimize resource utilization in Virtual Machines (VMs) to ensure maximum user satisfaction and overall system efficiency. However, existing review papers on load balancing in cloud environments often exhibit limitations, lacking in-depth analyses, graphical representations, and comprehensive evaluations of performance metrics. This review paper aims to fill these gaps by providing a novel taxonomy of load balancing algorithms divided into four categories (types of algorithms, nature of problem, metrics, and simulation tools) and thoroughly examining their objectives, parameters, and operational flows. It evaluates the strengths and weaknesses of these algorithms, considering their nature and type, and employs qualitative QoS parameter-based criteria for effectiveness evaluation. The paper also includes a comparative analysis of simulation tools, visual representations, and experimental results. By offering valuable insights, open issues, recommendations, and future directions, this review paper equips researchers, practitioners, and cloud service providers with the knowledge to make informed decisions in selecting and optimizing load-balancing strategies for diverse cloud environments.",Springer
"Godhrawala, Husain and Sridaran, R.",Apriori Algorithm Based Approach for Improving QoS and SLA Guarantee in IaaS Clouds Using Pattern-Based Service-Oriented Architecture,2023,10.1007/s42979-023-02079-3,https://doi.org/10.1007/s42979-023-02079-3,Journal,SN Computer Science,"Cloud computing is a modern computing technology. The integration of fog computing, edge computing, mist computing, IoT, 5G, etc. with cloud computing adds immense power to cloud computing. However, this integration leads to two problems. The first problem is to define an interoperable cloud architecture and the second problem is resource allocation to optimize performance. To address both problems, we propose a SOA for cloud. We implement a machine learning based Apriori algorithm, to find association rules between QoS to define a stronger SLA. This approach also helps in defining better and simpler resource management policies and for developer it becomes easier to develop and deploy cloud applications. When cloud manages resources in a well-defined manner, revenue is optimized easily with maintaining required QoS levels. Experiments and detailed discussion show that this approach successfully helps in defining better SLA and implement a simpler resource management policy, makes easier to handle QoS, reduces costs and optimizes revenues.",Springer
"Akbar, Muhammad Azeem and Khan, Arif Ali and Hyrynsalmi, Sami and Khan, Javed Ali",6G secure quantum communication: a success probability prediction model,2024,10.1007/s10515-024-00427-y,https://doi.org/10.1007/s10515-024-00427-y,Journal,Automated Software Engineering,"The emergence of 6G networks initiates significant transformations in the communication technology landscape. Yet, the melding of quantum computing (QC) with 6G networks although promising an array of benefits, particularly in secure communication. Adapting QC into 6G requires a rigorous focus on numerous critical variables. This study aims to identify key variables in secure quantum communication (SQC) in 6G and develop a model for predicting the success probability of 6G-SQC projects. We identified key 6G-SQC variables from existing literature to achieve these objectives and collected training data by conducting a questionnaire survey. We then analyzed these variables using an optimization model, i.e., Genetic Algorithm (GA), with two different prediction methods the Na{\""i}ve Bayes Classifier (NBC) and Logistic Regression (LR). The results of success probability prediction models indicate that as the 6G-SQC matures, project success probability significantly increases, and costs are notably reduced. Furthermore, the best fitness rankings for each 6G-SQC project variable determined using NBC and LR indicated a strong positive correlation (rs{\thinspace}={\thinspace}0.895). The t-test results (t{\thinspace}={\thinspace}0.752, p{\thinspace}={\thinspace}0.502{\thinspace}>{\thinspace}0.05) show no significant differences between the rankings calculated using both prediction models (NBC and LR). The results reveal that the developed success probability prediction model, based on 15 identified 6G-SQC project variables, highlights the areas where practitioners need to focus more to facilitate the cost-effective and successful implementation of 6G-SQC projects.","Springer, Web of Science"
"Tarvo, Alexander and Reiss, Steven P.",Automatic performance prediction of multithreaded programs: a simulation approach,2018,10.1007/s10515-017-0214-5,https://doi.org/10.1007/s10515-017-0214-5,Journal,Automated Software Engineering,"The performance of multithreaded programs is often difficult to understand and predict. Multiple threads engage in synchronization operations and use hardware simultaneously. This results in a complex non-linear dependency between the configuration of a program and its performance. To better understand this dependency a performance prediction model is used. Such a model predicts the performance of a system for different configurations. Configurations reflect variations in the workload, different program options such as the number of threads, and characteristics of the hardware. Performance models are complex and require a solid understanding of the program's behavior. As a result, building models of large applications manually is extremely time-consuming and error-prone. In this paper we present an approach for building performance models of multithreaded programs automatically. We employ hierarchical discrete-event models. Different tiers of the model simulate different factors that affect performance of the program, while interaction between the model tiers simulates mutual influence of these factors on performance. Our framework uses a combination of static and dynamic analyses of a single representative run of a system to collect information required for building the performance model. This includes information about the structure of the program, the semantics of interaction between the program's threads, and resource demands of individual program's components. In our experiments we demonstrate that models accurately predict the performance of various multithreaded programs, including complex industrial applications.",Springer
"Zhou, Jincheng and Lilhore, Umesh Kumar and M, Poongodi and Hai, Tao and Simaiya, Sarita and Jawawi, Dayang Norhayati Abang and Alsekait, Deemamohammed and Ahuja, Sachin and Biamba, Cresantus and Hamdi, Mounir",Comparative analysis of metaheuristic load balancing algorithms for efficient load balancing in cloud computing,2023,10.1186/s13677-023-00453-3,https://doi.org/10.1186/s13677-023-00453-3,Journal,Journal of Cloud Computing,"Load balancing is a serious problem in cloud computing that makes it challenging to ensure the proper functioning of services contiguous to the Quality of Service, performance assessment, and compliance to the service contract as demanded from cloud service providers (CSP) to organizations. The primary objective of load balancing is to map workloads to use computing resources that significantly improve performance. Load balancing in cloud computing falls under the class of concerns defined as ``NP-hard'' issues due to vast solution space. Therefore it requires more time to predict the best possible solution. Few techniques can perhaps generate an ideal solution under a polynomial period to fix these issues. In previous research, Metaheuristic based strategies have been confirmed to accomplish accurate solutions under a decent period for those kinds of issues. This paper provides a comparative analysis of various metaheuristic load balancing algorithms for cloud computing based on performance factors i.e., Makespan time, degree of imbalance, response time, data center processing time, flow time, and resource utilization. The simulation results show the performance of various Meta-heuristic Load balancing methods, based on performance factors. The Particle swarm optimization method performs better in improving makespan, flow time, throughput time, response time, and degree of imbalance.",Springer
"P, Geetha and Nanda, Satyasai Jagannath and Yadav, Rajendra Prasad",DOA Estimation in the Presence of Doppler Shifts Using Quantum-Inspired Swarm Intelligence Algorithms,2024,10.1007/s42979-024-02639-1,https://doi.org/10.1007/s42979-024-02639-1,Journal,SN Computer Science,"Direction of arrival (DOA) estimation is an important problem of wireless sensor network (WSN) where the objective is to calculate the angle of incidence of the source signal at the sensor array. The estimation performance degrades due to the presence of Doppler shifts, which are caused by the mobility of sources. To determine the effective solution, here new models based on quantum-inspired swarm intelligence algorithms are proposed for DOA estimation: quantum-inspired sailfish optimization (QSFO), quantum-inspired gray wolf optimization (QGWO), quantum-inspired whale optimization (QWoA), and quantum-inspired particle swarm optimization (QPSO). The beauty of these algorithms is that they provide high-speed convergence on large-scale optimization problems. The quantum entanglement principle is embodied in the swarm intelligence algorithms to improve the exploration capability of the population in the hunting phase. The DOA estimation is carried out using a maximum likelihood estimator (MLE) with quantum-inspired swarm intelligence algorithms in these scenarios: (1) variation of Doppler frequencies, (2) variation of a number of sources, (3) different noise conditions (SNR variation), (4) different noise environments (stationary and non-stationary), and (5) different types of sources (uncorrelated and correlated). Superior DOA estimation results are reported for the proposed algorithm for different Doppler frequencies. The performance of the proposed quantum-inspired algorithms is also compared with two state-of-the-art classical algorithms: MUSIC and ESPIRIT. Proposed QSFO offers better results for 4 CEC, 12 uni-modal, and 12 multi-modal benchmark functions. A practical application of the proposed approach is demonstrated to solve DOA estimation with Doppler shift in automotive radar.",Springer
"Panda, Arnapurna",Digital Channel Equalizer Using Functional Link Artificial Neural Network Trained with Quantum Aquila Optimizer,2024,10.1007/s42979-024-02632-8,https://doi.org/10.1007/s42979-024-02632-8,Journal,SN Computer Science,"In digital communication, channel equalization plays an important role in mitigating the effects of inter-symbol interference, non-linearity and noise. In case of wireless channels, it also reduces the co-channel and adjacent channel interference. The channel equalizer is placed at the receiver which inherently perform an inverse modeling operation. In this manuscript, equalizers are proposed based on Functional Link Artificial Neural Network (FLANN) for nonlinear communication channel. Three types of FLANN architecture are explored based on: Trigonometric, Chebyshev and Legendre polynomial-based expansions. The weight of these FLANN architectures are trained by a quantum Aquila optimization algorithm (QAOA). In this manuscript the quantum entanglement principle is embodied to improve the performance of original Aquila optimizer. The Aquila optimizer is reported in 2021 by Abualigah et. al. is a popular algorithm and based on the inherent behavior of Aquila to catch the pray. Simulation studies are reported for two nonlinear finite impulse response (FIR) channels performance under noisy environment. The performance is reported in the form of MSE and normalized MSE (dB) value, run time required during training; final bit error rate (BER) value obtained and BER plot during testing. Simulation results reveal superior performance of Chebyshev FLANN architecture with QAOA learning, compared to the other FLANN models as well as a FIR filter-based equalizer trained with original Aquila optimizer, Grey Wolf optimizer, particle swarm optimizer and least mean square algorithm.",Springer
"Nandhini, S. and Rajeswari, A. and Shanker, N. R.",Cyber attack detection in IOT-WSN devices with threat intelligence using hidden and connected layer based architectures,2024,10.1186/s13677-024-00722-9,https://doi.org/10.1186/s13677-024-00722-9,Journal,Journal of Cloud Computing,"In this paper, cyber-attacks in IOT-WSN are detected through proposed optimized-Neural Network algorithms such as (i) Equilibrium Optimizer Neural Network (EO-NN), (ii) Particle Swarm Optimization (PSO-NN), (iii) Single Candidate Optimizer Neural Network (SCO-NN) and (iv) Single Candidate Optimizer Long Short-Term Memory (SCO-LSTM) with different connecting, hidden neural network layers and threat intelligence data. The proposed algorithms detect the attacker node, which frequently changes the behaviour such as attacker node/ normal node. Existing IDS system detects the attacks in WSN and unable to detect the changing behavior attacker nodes in IOT-WSN. The behaviour of attacker node changes from normal behaviour to attacker behaviour due to nodes connected to internet continuously. The classification accuracy rates of proposed SCO-LSTM algorithm without and with threat intelligence are about 99.7{\%} and 99.89{\%}, respectively.",Springer
"Kumar, Sandeep and Shaw, Dilip Kumar",An API Security Framework for IoT-Enabled Healthcare System with the Application Blockchain-Based Smart Contract,2024,10.1007/s42979-024-03430-y,https://doi.org/10.1007/s42979-024-03430-y,Journal,SN Computer Science,"Healthcare (HC) systems must address the security, privacy, and trust issues due to the rapid advancements in technological innovations.For visualizing these concepts, there are different approaches. However, they are inefficient owing to unsecured Application Programming Interfaces (APIs), unauthorized data access, cryptanalysis attacks, etc. To tackle these security issues, a scheme that enables API security and data filtering mechanisms to prevent illegitimate actions in the HC system is proposed in this paper. Primarily, in the registration phase, a nominee is elected by each patient for data access in an emergency situation. Afterward, by utilizing the Empirical Resampling based Elliptic Curve Cryptography(ER-ECC) technique, the patient data collected from data sensing are securely stored. In the meantime, a Halving Grid Search-based Argon2 (HGS-A2)-based hashed smart contract is created between doctor and patient. Then, the hashed contract isshared with the nominee and stored in the Blockchain (BC). Authorization is done by matching hashed smart contract while accessing the data. After that, by utilizing the Elliot Symmetric Activation-based Long Short Term Memory (ESA-LSTM), the data filtering layer returns filtered data under the access request. After data downloading, the key update instruction was received for updating new keys for data encryption. During the whole process, by using the Xored-Hills Cipher(XHC) technique, the API security for each step is established. Lastly, the experimental outcomes exhibited that the proposed system attains a higher level of security when contrasted with the existing approaches.",Springer
"Klusch, Matthias and L{\""a}ssig, J{\""o}rg and Wilhelm, Frank K.",Quantum Computing and AI,2024,10.1007/s13218-024-00872-7,https://doi.org/10.1007/s13218-024-00872-7,Journal,"KI - K{\""u}nstliche Intelligenz",,Springer
"Tan, Chao and Wang, Tiexin and Zhang, Man and Yue, Tao",Safety behavior abstraction and model evolution in autonomous driving,2025,10.1007/s10270-024-01261-2,https://doi.org/10.1007/s10270-024-01261-2,Journal,Software and Systems Modeling,"In the autonomous driving systems (ADSs) literature, most existing approaches primarily focus on identifying driving scenarios, which is challenged by the reality that real-world driving scenarios are countless and unpredictable, and it is impossible to have a comprehensive set of driving scenarios to demonstrate the test efficiency in covering all possible situations ADSs might face. To address these challenges, one fundamental step is to abstract complex ADS behaviors, e.g., (semi-)automatically derive a holistic view of how an ADS behaves under its driving environment with high-level representations, such as prior-knowledge-based models. Therefore, in this paper, we propose a novel Risk-basEd Model comprehension and Evolution approach for autonomous Driving sYstems, named REMEDY, which facilitates the development of such models and enables automated model evolution (i.e., discovering and extracting ADS behaviors and their interactions with the environment) via model execution and simulation with the autonomous driving simulator CARLA. To enable efficient model evolution, we also equipped REMEDY with a risk-based strategy using Q-Learning, which is empirically evaluated by comparing it with three baselines (i.e., a random strategy, a coverage-based greedy strategy, and DeepCollision---a state-of-the-art approach). Results show that REMEDY is capable of discovering new and diverse behaviors, and the risk-based strategy is efficient in discovering risky ADS behaviors.",Springer
"Parashar, Gaurav and Chaudhary, Alka and Pandey, Dilkeshwar",Machine Learning for Prediction of Cardiovascular Disease and Respiratory Disease: A Review,2024,10.1007/s42979-023-02529-y,https://doi.org/10.1007/s42979-023-02529-y,Journal,SN Computer Science,"Cardiovascular (CVD) and respiratory diseases (RD) have been in the active domain for machine learning (ML) researchers as these diseases significantly contribute to mortality in humans. Some studies suggest that CVD problems such as cerebrovascular problems, dysrhythmia, inflammatory heart disease, ischemic heart disease (IHD), and RD related problems remain high even after COVID-19 infection clears up. To the best of our knowledge, this is the only study that surveyed these two diseases. This paper's goal is to explore the existing state of the art in the application of ML in the detection, categorization, and prediction of disorders related to CVD and RD. The review highlights ML algorithms used in prediction of CVD and RD related diseases, datasets used by the articles, technique used for feature selection, features selected for the study, dataset used in the article was unimodal or multimodal, and performance of the algorithm. In CVD category, it was observed that about 15 studies had their performance metrics range between 91{\%} and 100{\%}, 7 studies had between 81{\%} and 90{\%} and about 2 studies had their performance between 70{\%} and 80{\%}. CNN is the most used Feature Selection technique. Only three studies were found in our set that worked on the multimodal dataset and others used the unimodal dataset. In case of RDs, it was observed that about 15 studies had their performance metrics range between 91{\%} and 100{\%}, 7 studies had between 81{\%} and 90{\%} and about 2 studies had their performance between 70{\%} and 80{\%}. CNN is the most used feature selection technique. Only three studies were found in our set that worked on the multimodal dataset and others used the unimodal dataset. The intent of this review is to stimulate the interest of scientists in this challenging field and to acquaint them with current advances in the field. To design a system that predict CVD or RD in a patient using uni or multi modal datasets, approaches such as data cleaning, feature selection, region of interest (ROI) identification, and classification are applied. This article provided details related to publicly available datasets, most used classification algorithm with performance metric.",Springer
"Bhushan, Megha and Negi, Arun and Samant, Piyush and Goel, Shivani and Kumar, Ajay",A classification and systematic review of product line feature model defects,2020,10.1007/s11219-020-09522-1,https://doi.org/10.1007/s11219-020-09522-1,Journal,Software Quality Journal,"Product line (PL)-based development is a thriving research area to develop software-intensive systems. Feature models (FMs) facilitate derivation of valid products from a PL by managing commonalities and variabilities among software products. However, the researchers in academia as well as in the industries experience difficulties in quality assessment of FMs. The increasing complexity and size of FMs may lead to defects, which outweigh the benefits of PL. This paper provides a systematic literature review and key research issues related to the FM defects in PL. We derive a typology of FM defects according to their level of importance. The information on defects' identification and explanations are provided with formalization. Further, corrective explanations are presented which incorporates various techniques used to fix defects with their implementation. This information would help software engineering community by enabling developers or modelers to find the types of defects and their causes and to choose an appropriate technique to fix defects in order to produce defect-free products from FMs, thereby enhancing the overall quality of PL-based development.",Springer
"Macaluso, Antonio",Quantum Supervised Learning,2024,10.1007/s13218-024-00856-7,https://doi.org/10.1007/s13218-024-00856-7,Journal,"KI - K{\""u}nstliche Intelligenz","Recent advancements in quantum computing have positioned it as a prospective solution for tackling intricate computational challenges, with supervised learning emerging as a particularly promising domain for its application. Despite this potential, the field of quantum machine learning is still in its early stages, and there persists a level of skepticism regarding a possible near-term quantum advantage. This paper aims to provide a classical perspective on current quantum algorithms for supervised learning, effectively bridging traditional machine learning principles with advancements in quantum machine learning. Specifically, this study charts a research trajectory that diverges from the predominant focus of quantum machine learning literature, originating from the prerequisites of classical methodologies and elucidating the potential impact of quantum approaches. Through this exploration, our objective is to deepen the understanding of the convergence between classical and quantum methods, thereby laying the groundwork for future advancements in both domains and fostering the involvement of classical practitioners in the field of quantum machine learning.",Springer
"Maigida, Abdullahi Mohammed and Abdulhamid, Shafi'i Muhammad and Olalere, Morufu and Alhassan, John K. and Chiroma, Haruna and Dada, Emmanuel Gbenga",Systematic literature review and metadata analysis of ransomware attacks and detection mechanisms,2019,10.1007/s40860-019-00080-3,https://doi.org/10.1007/s40860-019-00080-3,Journal,Journal of Reliable Intelligent Environments,"Ransomware is advanced and upgraded malicious software which comes in the forms of Crypto or Locker, with the intention to attack and take control of basic infrastructures and computer systems. The vast majority of these threats are aimed at directly or indirectly making money from the victims by asking for a ransom in exchange for decryption keys. This systematic literature analysed the anatomy of ransomware, including its trends and mode of attacks to find the possible solutions by querying various academic literature. In contrast to previous reviews, sources of ransomware dataset are revealed in this review paper to ease the challenges of researchers in getting access to ransomware datasets. In addition, a taxonomy of ransomware current trends is presented in the paper. We discussed the articles in detail, the evolution and trend in ransomware researches. Most of the techniques deployed could not completely prevent ransomware attacks because of its obfuscation techniques, but rather recommend proper and regular backup of important files. This review can serve as a benchmark for researchers in proposing a novel ransomware detection methodology and starting point for novice researchers.",Springer
"Nag, Sayan",Vector quantization using the improved differential evolution algorithm for image compression,2019,10.1007/s10710-019-09342-8,https://doi.org/10.1007/s10710-019-09342-8,Journal,Genetic Programming and Evolvable Machines,"Vector quantization (VQ) is a popular image compression technique with a simple decoding architecture and high compression ratio. Codebook designing is the most essential part in vector quantization. Linde--Buzo--Gray (LBG) is a traditional method of generation of VQ codebook which results in lower PSNR value. A codebook affects the quality of image compression, so the choice of an appropriate codebook is a must. Several optimization techniques have been proposed for global codebook generation to enhance the quality of image compression. In this paper, a novel algorithm called IDE-LBG is proposed which uses improved differential evolution algorithm coupled with LBG for generating optimum VQ codebooks. The proposed IDE works better than the traditional DE with modifications in the scaling factor and the boundary control mechanism. The IDE generates better solutions by efficient exploration and exploitation of the search space. Then the best optimal solution obtained by the IDE is provided as the initial codebook for the LBG. This approach produces an efficient codebook with less computational time and the consequences include excellent PSNR values and superior quality reconstructed images. It is observed that the proposed IDE-LBG find better VQ Codebooks as compared to IPSO-LBG, BA-LBG and FA-LBG.",Springer
"Haeri Boroujeni, Sayed Pedram and Pashaei, Elnaz",A hybrid chimp optimization algorithm and generalized normal distribution algorithm with opposition-based learning strategy for solving data clustering problems,2024,10.1007/s42044-023-00160-x,https://doi.org/10.1007/s42044-023-00160-x,Journal,Iran Journal of Computer Science,"This paper focuses on connectivity-based data clustering for categorizing similar and dissimilar data into distinct groups. Although classical clustering algorithms such as K-means are efficient techniques, they often trap in local optima and have a slow convergence rate in solving high-dimensional problems. To address these issues, many successful meta-heuristic optimization algorithms and intelligence-based methods have been introduced to attain the optimal solution in a reasonable time. In this study, we attempt to conceptualize a powerful approach using the three main components: Chimp Optimization Algorithm (ChOA), Generalized Normal Distribution Algorithm (GNDA), and Opposition-Based Learning (OBL) method. First, two versions of ChOA with two different dynamic coefficients and seven chaotic maps, entitled ChOA(I) and ChOA(II), are presented to achieve the best possible result for data clustering purposes. Second, a novel combination of ChOA and GNDA algorithms with the OBL strategy is devised to solve the major shortcomings of the original algorithms. Lastly, the proposed ChOAGNDA method is a Selective Opposition (SO) algorithm based on ChOA and GNDA, which can be used to tackle large and complex real-world optimization problems, particularly data clustering applications. In this study, eight benchmark datasets, including five datasets of the UCI machine learning repository and three challenging shape datasets, are used to investigate the general performance of the proposed method. The results are evaluated against several popular and recent state-of-the-art clustering techniques. Experimental results illustrate that the proposed work significantly outperforms other existing methods in terms of the Sum of Intra-Cluster Distances (SICD), Error Rate (ER), and convergence rate.",Springer
"Widdows, Dominic and Aboumrad, Willie and Kim, Dohun and Ray, Sayonee and Mei, Jonathan",Quantum Natural Language Processing,2024,10.1007/s13218-024-00861-w,https://doi.org/10.1007/s13218-024-00861-w,Journal,"KI - K{\""u}nstliche Intelligenz","Language processing is at the heart of current developments in artificial intelligence, and quantum computers are becoming available at the same time. This has led to great interest in quantum natural language processing, and several early proposals and experiments. This paper surveys the state of this area, showing how NLP-related techniques have been used in quantum language processing. We examine the art of word embeddings and sequential models, proposing some avenues for future investigation and discussing the tradeoffs present in these directions. We also highlight some recent methods to compute attention in transformer models, and perform grammatical parsing. We also introduce a new quantum design for the basic task of text encoding (representing a string of characters in memory), which has not been addressed in detail before. Quantum theory has contributed toward quantifying uncertainty and explaining ``What is intelligence?'' In this context, we argue that ``hallucinations'' in modern artificial intelligence systems are a misunderstanding of the way facts are conceptualized: language can express many plausible hypotheses, of which only a few become actual.",Springer
"Mautner, Julian and Makmal, Adi and Manzano, Daniel and Tiersch, Markus and Briegel, Hans J.",Projective Simulation for Classical Learning Agents: A Comprehensive Investigation,2015,10.1007/s00354-015-0102-0,https://doi.org/10.1007/s00354-015-0102-0,Journal,New Generation Computing,"We study the model of projective simulation (PS), a novel approach to artificial intelligence based on stochastic processing of episodic memory which was recently introduced. 2) Here we provide a detailed analysis of the model and examine its performance, including its achievable efficiency, its learning times and the way both properties scale with the problems' dimension. In addition, we situate the PS agent in different learning scenarios, and study its learning abilities. A variety of new scenarios are being considered, thereby demonstrating the model's flexibility. Furthermore, to put the PS scheme in context, we compare its performance with those of Q-learning and learning classifier systems, two popular models in the field of reinforcement learning. It is shown that PS is a competitive artificial intelligence model of unique properties and strengths.",Springer
"Devarajan, Mohanarangan Veerappermal and Yallamelli, Akhil Raj Gaius and Mamidala, Vijaykumar and Yalla, Rama Krishna Mani Kanta and Ganesan, Thirusubramanian and Sambas, Aceng",IoT-based enterprise information management system for cost control and enterprise job-shop scheduling problem,2024,10.1007/s11761-024-00438-3,https://doi.org/10.1007/s11761-024-00438-3,Journal,Service Oriented Computing and Applications,"The Internet of Things (IoT) transforms modern industries, particularly enterprise information management and supply chain optimization. However, integrating IoT technologies into manufacturing systems introduces challenges, especially in inventory cost control and job-shop scheduling (JSP), which involves optimizing production under complex, dynamic constraints. This research proposes a novel approach to solving JSP by leveraging a Heterogeneous Genetic Algorithm (HGA) and a Hybrid Particle Swarm Optimization (HPSO). HGA addresses traditional Genetic Algorithms (GA) limitations by incorporating immune mechanisms, such as memory and mutation strategies, to prevent premature convergence and enhance exploration capabilities. HPSO is specifically designed to improve job sequencing and minimize production time by combining the strengths of PSO with genetic operators. This hybridization enables HPSOs to balance global and local search efficiency, making it more effective than traditional PSOs in handling the complexities of JSP. In addition to improving HPSO's cost optimization and schedule efficiency performance, this research made significant contributions to the field by hybridizing genetic algorithms with HPSO and introducing a double-chain encoding method for machine selection and job sequencing. The proposed approach is validated through empirical studies, demonstrating that HGA and HPSO significantly outperform conventional scheduling techniques.",Springer
"Manimuthu, Arunmozhi and Dharshini, Venugopal and Zografopoulos, Ioannis and Priyan, M. K. and Konstantinou, Charalambos","Contactless Technologies for Smart Cities: Big Data, IoT, and Cloud Infrastructures",2021,10.1007/s42979-021-00719-0,https://doi.org/10.1007/s42979-021-00719-0,Journal,SN Computer Science,"Intelligent systems are enhancing city environments and improving their overall performance in all possible aspects. Innovations in the field of information and communication technologies (ICT) and the proliferation of big data, internet-of-things (IoT), and cloud (BIC) infrastructures revolutionize the existing agile city ecosystems while effectively addressing customers and citizens needs. In this paper, we address the technology-driven applications that are capable of influencing the existing city infrastructures during their transformation towards smart cities with contactless technologies. We present applications, design principles, technology standards, and cost-effective techniques that leverage BIC for contactless applications and discuss user interfaces deployed in smart city environments. We further discuss state-of-the-art sensing methods and smart applications that support cities with smart contactless features. Finally, a case study is reported on how BIC can assist in efficiently handling and managing emergency situations such as the COVID-19 pandemic.",Springer
"Bakhtin, V. A. and Krukov, V. A.",DVM-Approach to the Automation of the Development of Parallel Programs for Clusters,2019,10.1134/S0361768819030034,https://doi.org/10.1134/S0361768819030034,Journal,Programming and Computer Software,"The DVM-approach to the development of parallel programs for heterogeneous computer clusters with accelerators. The basic capabilities of DVM and SAPFOR , which automate the parallelization of applications, are discussed.",Springer
"Nath, Rajdeep Kumar and Thapliyal, Himanshu and Humble, Travis S.",A Review of Machine Learning Classification Using Quantum Annealing for Real-World Applications,2021,10.1007/s42979-021-00751-0,https://doi.org/10.1007/s42979-021-00751-0,Journal,SN Computer Science,"Optimizing the training of a machine learning pipeline helps in reducing training costs and improving model performance. One such optimizing strategy is quantum annealing, which is an emerging computing paradigm that has shown potential in optimizing the training of a machine learning model. The implementation of a physical quantum annealer has been realized by D-wave systems and is available to the research community for experiments. Recent experimental results on a variety of machine learning applications using quantum annealing have shown interesting results where the performance of classical machine learning techniques is limited by limited training data and high dimensional features. This article explores the application of D-wave's quantum annealer for optimizing machine learning pipelines for real-world classification problems. We review the application domains on which a physical quantum annealer has been used to train machine learning classifiers. We discuss and analyze the experiments performed on the D-Wave quantum annealer for applications such as image recognition, remote sensing imagery, computational biology, and particle physics. We discuss the possible advantages and the problems for which quantum annealing is likely to be advantageous over classical computation.",Springer
"K, Karan Kumar and Nutakki, Mounica and Koduru, Suprabhath and Mandava, Srihari",Quantum support vector machine for forecasting house energy consumption: a comparative study with deep learning models,2024,10.1186/s13677-024-00669-x,https://doi.org/10.1186/s13677-024-00669-x,Journal,Journal of Cloud Computing,"The Smart Grid operates autonomously, facilitating the smooth integration of diverse power generation sources into the grid, thereby ensuring a continuous, reliable, and high-quality supply of electricity to end users. One key focus within the realm of smart grid applications is the Home Energy Management System (HEMS), which holds significant importance given the fluctuating availability of generation and the dynamic nature of loading conditions. This paper presents an overview of HEMS and the methodologies utilized for load forecasting. It introduces a novel approach employing Quantum Support Vector Machine (QSVM) for predicting periodic power consumption, leveraging the AMPD2 dataset. In the establishment of a microgrid, various factors such as energy consumption patterns of household appliances, solar irradiance, and overall load are taken into account in dataset creation. In the realm of load forecasting in Home Energy Management Systems (HEMS), the Quantum Support Vector Machine (QSVM) stands out from other methods due to its unique approach and capabilities. Unlike traditional forecasting methods, QSVM leverages quantum computing principles to handle complex and nonlinear electricity consumption patterns. QSVM demonstrates superior accuracy by effectively capturing intricate relationships within the data, leading to more precise predictions. Its ability to adapt to diverse datasets and produce significantly low error values, such as RMSE and MAE, showcases its efficiency in forecasting electricity load consumption in smart grids. Moreover, the QSVM model's exceptional flexibility and performance, as evidenced by achieving an accuracy of 97.3{\%} on challenging datasets like AMpds2, highlight its distinctive edge over conventional forecasting techniques, making it a promising solution for enhancing forecasting accuracy in HEMS.The article provides a brief summary of HEMS and load forecasting techniques, demonstrating and comparing them with deep learning models to showcase the efficacy of the proposed algorithms.",Springer
"Kishor, Kaushal and Agrawal, Krishna Kant and Yadav, Satya Prakash and Thakur, Hardeo Kumar and Naruka, Mahaveer Singh",SPAM: An Enhanced Performance of Security and Privacy-Aware Model over Split Learning in Consumer Electronics,2024,10.1134/S0361768824700816,https://doi.org/10.1134/S0361768824700816,Journal,Programming and Computer Software,"The use of consumer electronics has grown drastically in recent times due to advancements in technology. It has resulted in users expecting privacy and security from data shared over these devices. Split learning has become a widespread technique in providing these assurances. It is necessary to extend it further. That resulted in a model where the traditional approach has more performance resources and a more security-aware/privacy-aware alternative. This superior performance is explained by the fact that It has a more detailed implementation than the split learning approach. Provides data leak prevention to meet different use cases, including (but not limited to) the ability to protect data at rest, in motion, and while in use. Therefore, it can enhance transaction speed and latency over split learning. The security and privacy-aware view helps the user by providing options to secure his data while the prevention relationship improves usability. It can also lead to greater data type flexibility in networks. SPAM crawled results in proposed 0.05135 FDR, where Pth: 1 results with fdr > This caused the programmable security and privacy-aware model to far outstrip Split learning in terms of performance, making it a good candidate for encrypting consumer electronics-transmitted data. It provides a secure, responsive means for users to exchange information while at the same time promising that user privacy is well considered.",Springer
"Murugesh, V. and Godla, Sanjiv Rao and Meganathan, R. and Kumar, G. V. Sam and Murugesan, Pandiyanathan and Priyadharshini, M.",Application of Artificial Bee Colony Algorithm in Solving Second-Order Differential Equations,2024,10.1007/s42979-024-03418-8,https://doi.org/10.1007/s42979-024-03418-8,Journal,SN Computer Science,"This paper presents the use of the Artificial Bee Colony (ABC) algorithm to solve second order initial value problems (IVPs). The numerical methods like RK4 and RK-Gill are not very efficient in terms of accuracy, versatility and computational time especially with large step sizes. Based on the foraging behavior of honey bees the ABC approach is capable of enhancing the search for solutions in the search space to achieve the best solution. In this paper we use the second order IVPs to test the performance of the ABC algorithm and compare it with the exact solution, RK4, and RK-Gill methods. The efficacy of the proposed ABC algorithm in terms of accuracy and comparison to other methods is shown in tables and heat maps with zero visible error on several datasets. This shows that the proposed method is accurate and consistent in providing numerical solutions free from rounding off errors. Furthermore, we investigate the combination of the ABC algorithm with conventional numerical techniques and state-of-the-art computing approaches including adaptive step size methods and parallel computing in order to enhance the solution quality and accuracy. The paper also examines how integrating the proposed ABC algorithm with intelligent and machine learning approaches can be useful in extending the possibilities of numerical methods for solving differential equations and demonstrates its versatility as a computational intelligence method for different applications.",Springer
"Kumar, Ajay and Bhatt, Dheeraj and Singh, Yashwant and Kumar, Neerendra",Blockchain-Empowered Secure Data Communication for UAV,2024,10.1007/s42979-024-03496-8,https://doi.org/10.1007/s42979-024-03496-8,Journal,SN Computer Science,"Unmanned Aerial Vehicles (UAVs), originally used for agriculture, military and typical videography applications, now expanded into many exciting areas but also carries potential security risks. Blockchain, widely renowned for its decentralized and secure properties will materialize the cure for these security threats faced by UAV networks. In this research, we introduced a blockchain based UAV communication algorithm in which both are jointly used to ensure a secure data exchange between drones. This algorithm makes sure that only validated data blocks are added to the Blockchain and ensures integrity {\&} security during communication. By conducting an in-depth literature review, we have addressed some of the issues and challenges propagated by UAV systems. To summarize, the findings lay out that a combination of blockchain and UAV communication can enhance data integrity mechanisms as well as security layers; hence proving to be an optimal design for shaping even trustable solutions in wider domains dealing with professional aerial systems operation.",Springer
"Arora, Ritu and Sondhi, Sukrit","Towards Developing an Open-Infrastructure for Assessing the Progress, Success, and Impacts of CyberInfrastructure Projects",2024,10.1007/s42979-024-02961-8,https://doi.org/10.1007/s42979-024-02961-8,Journal,SN Computer Science,"Metrics for objectively assessing the CyberInfrastructure (CI) projects are important for not only obtaining the required resources for the long-term sustainability of the projects and community engagement but also for identifying issues and prioritizing the areas of improvement. This paper presents an overview of a model named MICI for assessing the progress, success, and impacts of a diverse range of CI projects. As an initial step, we developed a taxonomy of the CI projects and defined a set of standard metrics for the assessment of the projects belonging to the different categories in the taxonomy. If all the projects in the same category adopt a standard set of metrics for their assessment in addition to their project-specific and general metrics for assessment, it can help in focusing on gathering the assessment related data uniformly and understanding the short-term and long-term impacts created by the investments and the projects. We also introduce the MICI model for measuring the impacts of CI projects. Models like MICI along with the periodic peer-review can be useful in standardizing the process of assessing the impacts of the CI projects while ensuring accountability and transparency. With community engagement, the taxonomy of the CI projects, the associated metrics, and the impacts model should be refined further for ensuring their continued relevance and usefulness. Additionally, quantitative metrics should be used to supplement human judgment in the evaluation process and not to replace it.",Springer
"Swetha, P. and Rao, D. S.",Effective Feature Selection-Based Meta-heuristics Optimization Approach for Spam Detection,2023,10.1007/s42979-023-02126-z,https://doi.org/10.1007/s42979-023-02126-z,Journal,SN Computer Science,"According to studies of international monetary data, the sum of money lost due to fraud in all transactions around the world keeps rising. In particular, the adoption of the Bank-as-a-Service model by financial institutions will place additional strain on payment processing infrastructure and exacerbate the already serious problem of payment fraud. These communications carried more than just beneficial information: contain bogus content, phishing mails, viruses, annoying reviews, and more. Spammers, or spam users, are driving this growth every year. These scammers frequently make attractive-looking bogus accounts. Spam detection has become an essential demand currently, considered that spam has become a significant problem. Online reviews about product quality influence bank, particularly when it comes to merchandise. Some people use this as an attempt to spam the transaction, upgrading or degrading the user account. For this reason, the identification of these evaluations is crucial to ensure the interests of customers are preserved. Research on spam reviews and their detection has been undertaken by several researchers in order to help both customers and bank. In addition, the limited number of spam detection results in a data imbalance problem. Further, comparing reviews requires expensive computing. Studying how to identify spam detection and spam activity is a hot topic, and while numerous experiments have been done in this area, so far, there is no way that can recognize spam feedback or show the worth of the derived function types. To better detect spam in social media text, in this research, an effective feature selection-based meta-heuristics optimization (FS-MHO) using machine learning is proposed for accurate feature extraction and selection for further processing of online payment fraud detection. The proposed model achieves 97{\%} accuracy in detecting relevant features to train the model for accurate online fraud prediction.",Springer
"Waters, Max and Padgham, Lin and Sardina, Sebastian",Improving domain-independent intention selection in BDI systems,2015,10.1007/s10458-015-9293-5,https://doi.org/10.1007/s10458-015-9293-5,Journal,Autonomous Agents and Multi-Agent Systems,"The Belief Desire Intention (BDI) agent paradigm provides a powerful basis for developing complex systems based on autonomous intelligent agents. These agents have, at any point in time, a set of intentions encoding the various tasks the agent is working on. Despite its importance, the problem of selecting which intention to progress at any point in time has received almost no attention and has been mostly left to the programmer to resolve in an application-dependent manner. In this paper, we implement and evaluate two domain-independent intention selection mechanisms based on the ideas of enablement checking and low coverage prioritisation. Through a battery of automatically generated synthetic tests and one real program, we compare these with the commonly used intention selection mechanisms of First-In-First-Out (FIFO) and Round Robin (RR). We found that enablement checking, which is incorporated into low coverage prioritisation, is never detrimental and provides substantial benefits when running vulnerable programs in dynamic environments. This is a significant finding as such a check can be readily applied to FIFO and RR, giving an extremely simple and effective mechanism to be added to existing BDI frameworks. In turn, low coverage prioritisation provides a significant further benefit.",Springer
"Mondal, Anindita Sarkar and Mukhopadhyay, Somnath and Mondal, Kartick Chandra and Chattopadhyay, Samiran",A Double Threshold-Based Power-Aware Honey Bee Cloud Load Balancing Algorithm,2021,10.1007/s42979-021-00771-w,https://doi.org/10.1007/s42979-021-00771-w,Journal,SN Computer Science,"Present-day advancement in cloud computing provides ICT infrastructure as a service on a pay per use. Cloud computing provides this infrastructure as a service and as service demand increases, service providers organize large-scale data centers with a lot of resources, and cause of huge greenhouse gases' emission. This data center's huge power demand necessitates the balancing of cloud load. To attain the optimum resource utilization, least processing time of CPU, minimal average response time, and avoiding over-load, cloud load balancing algorithms distributes workload across virtual machines. The key challenge here is to develop such a load balancing algorithm which consumes the least resources to fulfill the service demands. In this paper, a double threshold-based power-aware honey bee load balancing algorithm is proposed for the fair and even distribution of the incoming task requests to all the virtual machines. This paper compares the proposed algorithm with five widely used existing load balancing algorithms. Moreover, we have done the performance analysis using the popular CloudAnalyst simulation toolkit. Results of simulation showed that the proposed algorithm gives a note-worthy outcome for average response time, CPU cost, storage cost, memory cost, and energy consumption in cloud computing to show the resource utilization.",Springer
"Rong, Chunming and Geng, Jiahui and Hacker, Thomas J. and Bryhni, Haakon and Jaatun, Martin G.",OpenIaC: open infrastructure as code - the network is my computer,2022,10.1186/s13677-022-00285-7,https://doi.org/10.1186/s13677-022-00285-7,Journal,Journal of Cloud Computing,"Modern information systems are built fron a complex composition of networks, infrastructure, devices, services, and applications, interconnected by data flows that are often private and financially sensitive. The 5G networks, which can create hyperlocalized services, have highlighted many of the deficiencies of current practices in use today to create and operate information systems. Emerging cloud computing techniques, such as Infrastructure-as-Code (IaC) and elastic computing, offer a path for a future re-imagining of how we create, deploy, secure, operate, and retire information systems. In this paper, we articulate the position that a comprehensive new approach is needed for all OSI layers from layer 2 up to applications that are built on underlying principles that include reproducibility, continuous integration/continuous delivery, auditability, and versioning. There are obvious needs to redesign and optimize the protocols from the network layer to the application layer. Our vision seeks to augment existing Cloud Computing and Networking solutions with support for multiple cloud infrastructures and seamless integration of cloud-based microservices. To address these issues, we propose an approach named Open Infrastructure as Code (OpenIaC), which is an attempt to provide a common open forum to integrate and build on advances in cloud computing and blockchain to address the needs of modern information architectures. The main mission of our OpenIaC approach is to provide services based on the principles of Zero Trust Architecture (ZTA) among the federation of connected resources based on Decentralized Identity (DID). Our objectives include the creation of an open-source hub with fine-grained access control for an open and connected infrastructure of shared resources (sensing, storage, computing, 3D printing, etc.) managed by blockchains and federations. Our proposed approach has the potential to provide a path for developing new platforms, business models, and a modernized information ecosystem necessary for 5G networks.",Springer
"Wang, Tao and Yu, Xiao and Qiu, Zhengyi and Jin, Guoliang and Mueller, Frank",BarrierFinder: recognizing ad hoc barriers,2020,10.1007/s10664-020-09862-3,https://doi.org/10.1007/s10664-020-09862-3,Journal,Empirical Software Engineering,"Ad hoc synchronizations are pervasive in multi-threaded programs. Due to their diversity and complexity, understanding the enforced synchronization relationships of ad hoc synchronizations is challenging but crucial to multi-threaded program development and maintenance. Existing techniques can partially detect primitive ad hoc synchronizations, but they cannot recognize complete implementations or infer the enforced synchronization relationships. In this paper, we propose a framework to automatically identify complex ad hoc synchronizations in full and infer their synchronization relationships. We instantiate the framework with a tool called BarrierFinder, which features various techniques, including program slicing and bounded symbolic execution, to efficiently explore the interleaving space of ad hoc synchronizations within multi-threaded programs and collect execution traces. BarrierFinder then uses these traces to characterize ad hoc synchronizations into different types with a focus on recognizing barriers. Our evaluation shows that BarrierFinder is both effective and efficient in doing this, and BarrierFinder is also helpful for programmers to understand the correctness of their implemented ad hoc synchronizations.",Springer
"Maass, Wolfgang and Agrawal, Ankit and Ciani, Alessandro and Danz, Sven and Delgadillo, Alejandro and Ganser, Philipp and Kienast, Pascal and Kulig, Marco and K{\""o}nig, Valentina and Rodellas-Gr{\`a}cia, Nil and Rughubar, Rivan and Schr{\""o}der, Stefan and Stautner, Marc and Stein, Hannah and Stollenwerk, Tobias and Zeuch, Daniel and Wilhelm, Frank K.",QUASIM: Quantum Computing Enhanced Service Ecosystem for Simulation in Manufacturing,2024,10.1007/s13218-024-00860-x,https://doi.org/10.1007/s13218-024-00860-x,Journal,"KI - K{\""u}nstliche Intelligenz","Quantum computing (QC) and machine learning (ML), taken individually or combined into quantum-assisted ML (QML), are ascending computing paradigms whose calculations come with huge potential for speedup, increase in precision, and resource reductions. Likely improvements for numerical simulations in engineering imply the possibility of a strong economic impact on the manufacturing industry. In this project report, we propose a framework for a quantum computing-enhanced service ecosystem for simulation in manufacturing, consisting of various layers ranging from hardware to algorithms to service and organizational layers. In addition, we give insight into the current state of the art of applications research based on QC and QML, both from a scientific and an industrial point of view. We further analyze two high-value use cases with the aim of a quantitative evaluation of these new computing paradigms for industrially relevant settings.",Springer
"Nikpour, Bahareh and Nezamabadi-pour, Hossein",HTSS: a hyper-heuristic training set selection method for imbalanced data sets,2018,10.1007/s42044-018-0009-2,https://doi.org/10.1007/s42044-018-0009-2,Journal,Iran Journal of Computer Science,"Imbalanced data sets are those in which data samples have uneven distribution amongst the classes. When classifying such data, classical classifiers encounter problem; hence, this problem has become a challenging issue in the field of machine learning. To weaken this problem, we propose a novel hyper-heuristic algorithm, called HTSS, to select the best training samples in this paper. In other words, the best training sample subset is chosen with the goal of enhancing the performance of classifier when confronting imbalanced data. To do so, some local search algorithms and a choice function are incorporated with a global search algorithm to improve its effectiveness. The global search used in this paper is binary quantum inspired gravitational search algorithm (BQIGSA) which is a recently proposed meta-heuristic search for optimization of binary encoded problems. Experiments are performed on 75 imbalanced data sets, and G-mean and AUC measures are employed for evaluation. The results of comparing the proposed method with other state of the art algorithms show the superiority of the proposed HTSS method.",Springer
"Costa, Daniel Alencar da and McIntosh, Shane and Treude, Christoph and Kulesza, Uir{\'a} and Hassan, Ahmed E.",The impact of rapid release cycles on the integration delay of fixed issues,2018,10.1007/s10664-017-9548-7,https://doi.org/10.1007/s10664-017-9548-7,Journal,Empirical Software Engineering,"The release frequency of software projects has increased in recent years. Adopters of so-called rapid releases---short release cycles, often on the order of weeks, days, or even hours---claim that they can deliver fixed issues (i.e., implemented bug fixes and new features) to users more quickly. However, there is little empirical evidence to support these claims. In fact, our prior work shows that code integration phases may introduce delays for rapidly releasing projects---98{\%} of the fixed issues in the rapidly releasing Firefox project had their integration delayed by at least one release. To better understand the impact that rapid release cycles have on the integration delay of fixed issues, we perform a comparative study of traditional and rapid release cycles. Our comparative study has two parts: (i) a quantitative empirical analysis of 72,114 issue reports from the Firefox project, and a (ii) qualitative study involving 37 participants, who are contributors of the Firefox, Eclipse, and ArgoUML projects. Our study is divided into quantitative and qualitative analyses. Quantitative analyses reveal that, surprisingly, fixed issues take a median of 54{\%} (57 days) longer to be integrated in rapid Firefox releases than the traditional ones. To investigate the factors that are related to integration delay in traditional and rapid release cycles, we train regression models that model whether a fixed issue will have its integration delayed or not. Our explanatory models achieve good discrimination (ROC areas of 0.80--0.84) and calibration scores (Brier scores of 0.05--0.16) for rapid and traditional releases. Our explanatory models indicate that (i) traditional releases prioritize the integration of backlog issues, while (ii) rapid releases prioritize issues that were fixed in the current release cycle. Complementary qualitative analyses reveal that participants' perception about integration delay is tightly related to activities that involve decision making, risk management, and team collaboration. Moreover, the allure of shipping fixed issues faster is a main motivator for adopting rapid release cycles among participants (although this motivation is not supported by our quantitative analysis). Furthermore, to explain why traditional releases deliver fixed issues more quickly, our participants point out the rush for integration in traditional releases and the increased time that is invested on polishing issues in rapid releases. Our results suggest that rapid release cycles may not be a silver bullet for the rapid delivery of new content to users. Instead, our results suggest that the benefits of rapid releases are increased software stability and user feedback.",Springer
"Bajpai, Prathu and Anicho, Ogbonnaya and Nagar, Atulya K. and Bansal, Jagdish Chand",Dynamic Mutation Strategy Selection in Differential Evolution Using Perturbed Adaptive Pursuit,2024,10.1007/s42979-024-03062-2,https://doi.org/10.1007/s42979-024-03062-2,Journal,SN Computer Science,"Diverse mutant vectors play a significant role in the performance of the Differential Evolution (DE). A mutant vector is generated using a stochastic mathematical equation, known as mutation strategy. Many mutation strategies have been proposed in the literature. Utilizing multiple mutation strategies with the help of an adaptive operator selection (AOS) technique can improve the quality of the mutant vector. In this research, one popular AOS technique known as perturbation adaptive pursuit (PAP) is integrated with the DE algorithm for managing a pool of mutation strategies. A community-based reward criterion is proposed that rewards the cumulative performance of the whole population. The proposed approach is called `Dynamic Mutation Strategy Selection in Differential Evolution using Perturbed Adaptive Pursuit (dmss-DE-pap)'. The performance of dmss-DE-pap is evaluated over the 30D and 50D optimization problems of the CEC 2014 benchmark test suite. Results are competitive when compared with other state-of-the-art evolutionary algorithms and some recent DE variants.",Springer
"Klusch, Matthias and L{\""a}ssig, J{\""o}rg and Wilhelm, Frank K.",Quantum Technologies and AI,2024,10.1007/s13218-024-00873-6,https://doi.org/10.1007/s13218-024-00873-6,Journal,"KI - K{\""u}nstliche Intelligenz",,Springer
"Ju{\'a}rez-Smith, Perla and Trujillo, Leonardo and Garc{\'i}a-Valdez, Mario and Fern{\'a}ndez de Vega, Francisco and Ch{\'a}vez, Francisco",Local search in speciation-based bloat control for genetic programming,2019,10.1007/s10710-019-09351-7,https://doi.org/10.1007/s10710-019-09351-7,Journal,Genetic Programming and Evolvable Machines,"This work presents a unique genetic programming (GP) approach that integrates a numerical local search method and a bloat-control mechanism to address some of the main issues with traditional GP. The former provides a directed search operator to work in conjunction with standard syntax operators that perform more exploration in design space, while the latter controls code growth by maintaining program diversity through speciation. The system can produce highly parsimonious solutions, thus reducing the cost of performing the local optimization process. The proposal is extensively evaluated using real-world problems from diverse domains, and the behavior of the search is analyzed from several different perspectives, including how species evolve, the effect of the local search process and the interpretability of the results. Results show that the proposed approach compares favorably with a standard approach, and that the hybrid algorithm can be used as a viable alternative for solving real-world symbolic regression problems.",Springer
"Avinash, N. and Sinha, Sitesh Kumar and Shivamurthaiah, M.",An Improved Gannet Optimization Algorithm Based on Opposition-Based Schemes for Feature Selection Problems in High-Dimensional Datasets,2024,10.1007/s42979-023-02487-5,https://doi.org/10.1007/s42979-023-02487-5,Journal,SN Computer Science,"In the ever-evolving landscape of optimization algorithms for healthcare datasets, this study introduces an innovative fusion of the gannet optimization algorithm (GOA) with advanced opposition-based learning (OBL) techniques, including quasi-OBL, generalized OBL, and partial OBL. The primary novelty of our approach lies in the hybridization of GOA with OBL schemes. While GOA itself draws inspiration from the hunting behavior of gannets, OBL techniques introduce a layer of opposition-based learning that mimics the dialectical nature of opposing forces. By integrating these two distinct paradigms, we create a symbiotic relationship between exploration and exploitation. This synergy empowers our optimization framework to dynamically adapt to the complex landscape of high-dimensional healthcare datasets, underlining its prowess in classification tasks, particularly when employed with support vector machine (SVM) and k-nearest neighbor (KNN) classifiers. Statistical validation further underscores the significance of our results. The p value analysis reveals that our GOBL--GOA approach stands as a statistically superior alternative, making substantial strides in feature selection and classification accuracy. Beyond statistics, our approach excels in practicality, effectively identifying and selecting relevant features to provide accurate insights from complex healthcare data, as demonstrated by precision, recall, and F1-score metrics. In conclusion, our study not only introduces a paradigm shift in feature selection and optimization but also advances the cause of precise disease detection and prognosis, holding immense potential to enhance healthcare outcomes globally.",Springer
"Langdon, W. B.",Response to comments on ``Jaws 30'',2023,10.1007/s10710-023-09474-y,https://doi.org/10.1007/s10710-023-09474-y,Journal,Genetic Programming and Evolvable Machines,,Springer
"Azizi, Mehdi and Sajedi, Hedieh",Satellite Broadcast Scheduling Based on a Boosted Binary Differential Evolution,2017,10.1007/s00354-017-0017-z,https://doi.org/10.1007/s00354-017-0017-z,Journal,New Generation Computing,"The satellite broadcasts scheduling (SBS) optimization problem is knownto be an NP-complete problem which like all scheduling, is the problem of mapping tasks to resources. The aim of this problem is to find a valid broadcasting pattern to earth-stationed terminals which maximizes the number of timeslots utilized for broadcasting under certain constraints. In this paper, we proposed Boosted Binary Differential Evolution (BBDE) to solve SBS and propose some various methods for every stage of the algorithm. Our proposed algorithm employs the best method in different stages of DE. The result of our algorithm is tested against published works toward solving SBS problem. A set of benchmark instances that reported in the literature for SBS problem are used to evaluate the performance of the proposed algorithm. The experimental results show that the BBDE algorithm has achieved good improvement on the optimization of SBS.",Springer
"Abdulkadir, Umar and Waziri, Victor Onomza and Alhassan, John Kolo and Ismaila, Idris","Electronic Medical Records Management and Administration: Current Trends, Issues, Solutions, and Future Directions",2024,10.1007/s42979-024-02803-7,https://doi.org/10.1007/s42979-024-02803-7,Journal,SN Computer Science,"Electronic Medical Records (EMR) is often used to refer to as electronic personal health (EPH) records or electronic healthcare records (EHR). These are considered vivacious assets of health facilities and patients. The relevance of the EMRs has motivated diverse innovations in the collecting, organizing, managing and administering for purpose of treatment primarily and other reasons. There are various concerns raised about legitimate usages, reproducibility, accuracy, and privacy breaches of EMRs across majority of health and medical facilities globally. This phenomenon became popular due to its support of electronic devices, wireless links, transmission and storage of data in the cloud, and communication across a gateway (or central-point). Therefore, physicians and medical facilities were empowered to undertake virtual consultations to patients through telemedicine applications for the remote treatment and diagnosis. Internet of Things (IoT) systems, medical wearable objects, and sensors were the basic components that collect and transmit patient data on real-time basis to a base station or centralized servers managed by hospitals. However, there is the need to improve creation and adoption of EMRs not without understanding their roles and shortfalls as well possible means of improvement. Consequently, this study conducts a systematic literature review on electronic medical records management and administration under current trends, issues, solutions and future directions. To this end, eighty-one (81) peer-reviewed articles including conferences and journals papers were included in the final stage of the study after applying Preferred Reporting Items for Systematic Review and Meta-analysis Protocols (PRIMA-P) methodology of records selection. The contributions of this study include: the recognition of the informed consent strategy as the best solution to illegitimate access to patient electronic records; the use of permissioned access strategies provided by blockchain technology as most recent attempt for privacy preservations; the use of lightweight cryptosystems with greater emphasis on Lattice systems; and the need to scale beyond theoretical frameworks to real-life implementations.",Springer
"Khan, Arif Ali and Akbar, Muhammad Azeem and Lahtinen, Valtteri and Paavola, Marko and Niazi, Mahmood and Alatawi, Mohammed Naif and Alotaibi, Shoayee Dlaim",Correction: Agile meets quantum: a novel genetic algorithm model for predicting the success of quantum software development project,2024,10.1007/s10515-024-00474-5,https://doi.org/10.1007/s10515-024-00474-5,Journal,Automated Software Engineering,,Springer
"Ferrari, Alessio and Esuli, Andrea",An NLP approach for cross-domain ambiguity detection in requirements engineering,2019,10.1007/s10515-019-00261-7,https://doi.org/10.1007/s10515-019-00261-7,Journal,Automated Software Engineering,"During requirements elicitation, different stakeholders with diverse backgrounds and skills need to effectively communicate to reach a shared understanding of the problem at hand. Linguistic ambiguity due to terminological discrepancies may occur between stakeholders that belong to different technical domains. If not properly addressed, ambiguity can create frustration and distrust during requirements elicitation meetings, and lead to problems at later stages of development. This paper presents a natural language processing approach to identify ambiguous terms between different domains, and rank them by ambiguity score. The approach is based on building domain-specific language models, one for each stakeholders' domain. Word embeddings from each language model are compared in order to measure the differences of use of a term, thus estimating its potential ambiguity across the domains of interest. We evaluate the approach on seven potential elicitation scenarios involving five domains. In the evaluation, we compare the ambiguity rankings automatically produced with the ones manually obtained by the authors as well as by multiple annotators recruited through Amazon Mechanical Turk. The rankings produced by the approach lead to a maximum Kendall's Tau of 88{\%}. However, for several elicitation scenarios, the application of the approach was unsuccessful in terms of performance. Analysis of the agreement among annotators and of the observed inaccuracies offer hints for further research on the relationship between domain knowledge and natural language ambiguity.",Springer
"Slezkin, A. O. and Hodashinsky, I. A. and Shelupanov, A. A.",Binarization of the Swallow Swarm Optimization for Feature Selection,2021,10.1134/S0361768821050066,https://doi.org/10.1134/S0361768821050066,Journal,Programming and Computer Software,"In this paper, we propose six methods for binarization of the swallow swarm optimization (SSO) algorithm to solve the feature selection problem. The relevance of the selected feature subsets is estimated by two classifiers: a fuzzy rule-based classifier and a classifier based on k-nearest neighbors. To find an optimal subset of features, we take into account the number of features and classification accuracy. The developed algorithms are tested on datasets from the KEEL repository. For the statistical evaluation of the binarization methods, we use Friedman's two-way analysis of variance by ranks for related samples. The best feature selection result is shown by a hybrid method based on modified algebraic operations and MERGE operation introduced by the authors of this paper. The best classification accuracy is achieved with a V-shaped transfer function.",Springer
"Sengupta, Kinshuk and Srivastava, Praveen Ranjan",HRNET: AI-on-Edge for Mask Detection and Social Distancing Calculation,2022,10.1007/s42979-022-01023-1,https://doi.org/10.1007/s42979-022-01023-1,Journal,SN Computer Science,"The purpose of the paper is to provide innovative emerging technology framework for community to combat epidemic situations. The paper proposes a unique outbreak response system framework based on artificial intelligence and edge computing for citizen centric services to help track and trace people eluding safety policies like mask detection and social distancing measure in public or workplace setup. The framework further provides implementation guideline in industrial setup as well for governance and contact tracing tasks. The adoption will thus lead in smart city planning and development focusing on citizen health systems contributing to improved quality of life. The conceptual framework presented is validated through quantitative data analysis via secondary data collection from researcher's public websites, GitHub repositories and renowned journals and further benchmarking were conducted for experimental results in Microsoft Azure cloud environment. The study includes selective AI models for benchmark analysis and were assessed on performance and accuracy in edge computing environment for large-scale societal setup. Overall YOLO model outperforms in object detection task and is faster enough for mask detection and HRNetV2 outperform semantic segmentation problem applied to solve social distancing task in AI-Edge inferencing environmental setup. The paper proposes new Edge-AI algorithm for building technology-oriented solutions for detecting mask in human movement and social distance. The paper enriches the technological advancement in artificial intelligence and edge computing applied to problems in society and healthcare systems. The framework further equips government agency, system providers to design and construct technology-oriented models in community setup to increase the quality of life using emerging technologies into smart urban environments.",Springer
"Kumar, Mandeep and Mondal, Bhaskar",Study on Implementation of Shor's Factorization Algorithm on Quantum Computer,2024,10.1007/s42979-024-02771-y,https://doi.org/10.1007/s42979-024-02771-y,Journal,SN Computer Science,"The fundamental security aspect of the classical crypto-system depends on integer factorization and discrete logarithm problems. The quantum factorization problem is a crucial problem in quantum computing as it has significant implications for cryptography and security. Shos's paper on ``Polynomial-time algorithms for discrete logarithms and factoring on a quantum compute'' has become a threat to the classical crypto-system, influencing many researchers to work on factorization problems using quantum computing. Quantum Computers (QC) can be essential in running different factorization algorithms in polynomial time. However, practical implementation on larger numbers is still a major challenge due to the requirement for error correction and massive quantum devices. Although the quantum factorization issue puts traditional cryptographic systems at risk, it also opens up new possibilities for quantum communication and encryption. The challenge of factorization opens up an entirely new field for research into quantum communication protocol security, including quantum key distribution and the development of quantum-resistant cryptographic systems. This paper surveys the various quantum algorithms for factoring a number into prime integers. We present a simulation study of the Quantum factorization algorithm to determine the period of a process. Turning the factoring problem into the challenge of determining a function's period is the essential strategy of practical implementation using the quantum circuit.",Springer
"Alfa, Abraham Ayegba and Alhassan, John Kolo and Olaniyi, Olayemi Mikail and Olalere, Morufu","Blockchain technology in IoT systems: current trends, methodology, problems, applications, and future directions",2021,10.1007/s40860-020-00116-z,https://doi.org/10.1007/s40860-020-00116-z,Journal,Journal of Reliable Intelligent Environments,"The growth of Internet of Things (IoT) took center stage universally due their capability to advance the course of human lives. Consequent upon this, several challenges were thrown up such as security of huge data stored and transmitted through network communication channels. IoT insecurity is partly due to centralization architecture, low computational strength, resource-constrained devices, variation in standards and protocols of communication. From this Systematic Literature Review (SLR), the 85 articles reviewed showed that privacy and security solutions are still being proposed or at conceptual levels, though a number of researchers favored the integration of Blockchain technology, cryptographic and hashing schemes into IoT. The Blockchain technology in IoT systems remains an open area of interest for top researchers especially in evolving frameworks to fit into the centralized architecture, functionality, and scalability demands of conventional IoT systems. In this article, we investigate security and privacy concerns of IoT from the lens of current trends, pertinent challenges, security methodologies, applications, and gaps for future research directions. Most specifically, there is prospect of utilizing cryptographic and hashing schemes offered by Blockchain technology in IoT. Then, high performance and scalable cryptographic schemes (that is, those in the class of lightweight appraoch) are suggested to deal with privacy and security of data in Blockchain-based IoT system. More importantly, this study provides basis for evolving secure and decentralized applications and systems in several domains such as smart farming.",Springer
"Falkenthal, Michael and Krieger, Christoph and Paul, Felix and Wagner, Sebastian and Wurster, Michael",PlanQK---Platform and Ecosystem for Quantum Applications,2024,10.1007/s13218-024-00865-6,https://doi.org/10.1007/s13218-024-00865-6,Journal,"KI - K{\""u}nstliche Intelligenz","The rapid progress made in recent years in the field of quantum computers has led to new research programs focusing more and more on the systematic development and utilization of quantum software in addition to hardware-related research projects. The initial lighthouse project on this topic in Germany was PlanQK-Platform and Ecosystem for Quantum Applications. In this work, we present the key results of this project and outline how the developed PlanQK Platform lays a nucleus and supports an open and community-driven approach for the development, provisioning, and sovereign utilization of quantum solutions for the German and European economic area.",Springer
"Rathinaeswari, S. P. and Santhi, V.",An Intelligent Lightweight Signing Signature and Secured Jellyfish Data Aggregation (LS3JDA) Based Privacy Preserving Model in Cloud,2024,10.1007/s00354-024-00263-4,https://doi.org/10.1007/s00354-024-00263-4,Journal,New Generation Computing,"Developing a secured and accurate disease diagnosis framework in the healthcare cloud systems are still remains one of the crucial problems in recent times. Due to the rapid growth of information and technology, it is highly essential to protect the patient health information against the unauthenticated users for ensuring the privacy and security. For this purpose, the different types of security approaches are developed in the conventional works, which are mainly focused on increasing the privacy of medical data stored in the cloud systems. However, it lacks with the major issues of increased computational overhead, communication cost, lack of security, complex mathematical modeling, and increased time consumption. Therefore, the proposed work objects to implement an intelligent and advanced privacy preserving framework, named as, lightweight signing signature based secured jellyfish data aggregation (LS3JDA) for ensuring the privacy of medical data in the healthcare cloud systems. The main contribution of this research work is to develop a new and lightweight privacy preservation model by incorporating the functions of both AI and signing signature algorithms for assuring data security in cloud systems. Moreover, it simplified the process of entire privacy preservation system with low computational burden and high data security. It also objects to accurately predict the type of disease based on the patients' medical history by using an advanced random forest (RF) machine learning methodology. The novel contributions of this work are, a message signing signature generation algorithm is used to strengthen the security of patients' medical data, and a jelly fish optimization (JFO) methodology is used to improve the process of data aggregation. The primary advantages of the proposed system are reduced processing time, low computational burden, and simple to deploy. For validating the results of the proposed model, several parameters include level of security, time, throughput, latency, signature cost, and communication overhead are assessed during evaluation. Moreover, the results are contrasted with some of the recent privacy preservation models for assuring the superiority of the proposed framework. Here, the overall processing time is reduced up to 1.5 ms, and communication overhead is reduced up to 100 bytes with the use of optimization integrated data aggregation model.",Springer
"Slavin, O. A.",Software Performance Optimization for Classification and Linking of Administrative Documents,2024,10.1134/S0361768824700324,https://doi.org/10.1134/S0361768824700324,Journal,Programming and Computer Software,"This paper discusses technologies for software performance optimization. Optimization methods are divided into high-level and low-level, as well as parallelization. The described optimization methods are applied to programs and software systems for processing large volumes of information, which have hot spots. An algorithm for classifying and linking fields in a recognized image of an administrative document is described. The implementation features of the classification and linking tasks, which consist in using constellations of text key points and a modified Levenshtein distance, are considered. For optical character recognition (OCR), Smart Document Engine and Tesseract are employed. Several methods used to optimize the performance of functions for document classification and linking are described. The performance optimization of the system for sorting administrative document image streams is considered. The proposed methods for software performance optimization are suitable not only for image processing algorithms but also for computational algorithms with cyclic information processing. The approach can also be used in modern CAD systems to analyze the content of recognized text files.",Springer
"Lin, Yujia and Chen, Liming and Ali, Aftab and Nugent, Christopher and Cleland, Ian and Li, Rongyang and Ding, Jianguo and Ning, Huansheng",Human digital twin: a survey,2024,10.1186/s13677-024-00691-z,https://doi.org/10.1186/s13677-024-00691-z,Journal,Journal of Cloud Computing,"The concept of the Human Digital Twin (HDT) has recently emerged as a new research area within the domain of digital twin technology. HDT refers to the replica of a physical-world human in the digital world. Currently, research on HDT is still in its early stages, with a lack of comprehensive and in-depth analysis from the perspectives of universal frameworks, core technologies, and applications. Therefore, this paper conducts an extensive literature review on HDT research, analyzing the underlying technologies and establishing typical frameworks in which the core HDT functions or components are organized. Based on the findings from the aforementioned work, the paper proposes a generic architecture for the HDT system and describes the core function blocks and corresponding technologies. Subsequently, the paper presents the state of the art of HDT technologies and their applications in the healthcare, industry, and daily life domains. Finally, the paper discusses various issues related to the development of HDT and points out the trends and challenges of future HDT research and development.",Springer
"Luc, Nhu-Quynh and Nguyen, Tat-Thang and Vu, Chi-Hung and Quach, Duc-Huy and Dao, Thanh-Toan","Secure Messaging Application Development: Based on Post-Quantum Algorithms CSIDH, Falcon, and AES Symmetric Key Cryptosystem",2024,10.1134/S0361768824700130,https://doi.org/10.1134/S0361768824700130,Journal,Programming and Computer Software,"In this paper, the authors present a technique for developing a secure messaging service called ``CryptoMess'' which utilizes the Commutative Supersingular Isogeny Diffie-Hellman (CSIDH) algorithm for secure key exchange and the Advanced Encryption Standard (AES) to protect message content in communication. In addition, the authors have incorporated the Falcon post-quantum digital signature technology to ensure the integrity and authenticity of communications between the sender and the recipient. The novel post-quantum cryptographic algorithms utilized by the authors are still under consideration in the competition to select cryptosystems for use in quantum computing systems organized by the NIST Standards Institute. As a result, the messaging program ``CryptoMess'' is able to exchange messages between users, providing safety, security, integrity, and authenticity. The authors have included modern post-quantum cryptography techniques, such as the Falcon digital signature system, to guarantee that the product operates safely. The program has a transmitting rate of approximately 209--261 ms and a receiving rate of approximately 168--206 ms. The message signing time is about 260 ms, and the message verification speed is approximately 185 ms. Key generation time is about 741 ms, key encapsulation time is about 1.454 ms, and key decapsulation time is about 1.921 ms. The source code of the ``CryptoMess'' communications program has been analyzed and tested by the authors using the Fortify Static Code Analyzer tool to ensure that the product has been created safely and securely.",Springer
"Khattab, Rana and Abdelmaksoud, Islam R. and Abdelrazek, Samir",Deep Convolutional Neural Networks for Detecting COVID-19 Using Medical Images: A Survey,2023,10.1007/s00354-023-00213-6,https://doi.org/10.1007/s00354-023-00213-6,Journal,New Generation Computing,"Coronavirus Disease 2019 (COVID-19), which is caused by Severe Acute Respiratory Syndrome Coronavirus 2 (SARS-COV-2), surprised the world in December 2019 and has threatened the lives of millions of people. Countries all over the world closed worship places and shops, prevented gatherings, and implemented curfews to stand against the spread of COVID-19. Deep Learning (DL) and Artificial Intelligence (AI) can have a great role in detecting and fighting this disease. Deep learning can be used to detect COVID-19 symptoms and signs from different imaging modalities, such as X-Ray, Computed Tomography (CT), and Ultrasound Images (US). This could help in identifying COVID-19 cases as a first step to curing them. In this paper, we reviewed the research studies conducted from January 2020 to September 2022 about deep learning models that were used in COVID-19 detection. This paper clarified the three most common imaging modalities (X-Ray, CT, and US) in addition to the DL approaches that are used in this detection and compared these approaches. This paper also provided the future directions of this field to fight COVID-19 disease.",Springer
"Bouchene, Mohammed Mehdi and Boukharouba, Abdelhak",Features extraction and reduction techniques with optimized SVM for Persian/Arabic handwritten digits recognition,2022,10.1007/s42044-022-00106-9,https://doi.org/10.1007/s42044-022-00106-9,Journal,Iran Journal of Computer Science,"Recognizing handwritten digits is one of the most active research areas in computer vision, as there are a variety of applications, such as automatic identification of digits in bank checks and vehicle numbers. In the last 3 decades, much effort has been devoted to recognizing handwritten Latin digits, while much less attention has been paid to the recognition of Persian and Arabic handwritten digits. For this reason, we will focus on the problem of recognizing Persian and Arabic handwritten numerals. We present an efficient and robust low-dimensional representation of the digit image based on an improved version of the histogram of oriented gradient (HOG) as a feature descriptor. A principal component analysis (PCA)-based dimensionality reduction strategy is also proposed to obtain a subset of features that optimizes classification accuracy. The selected sets of features were fed into a radial basis function (RBF)-based support vector machine (SVM) algorithm that performs classification, and the hyperparameters C and {\$}{\$}{\backslash}gamma {\$}{\$}were optimized using a Bayesian optimization (BO) algorithm. Extensive experimental results with 80,000 handwritten samples of Persian/Arabic numerals show that our method outperforms the current state-of-the-art classification accuracy and computational efficiency. This trade-off between accuracy and time complexity is highly beneficial for the real-time performance of handwritten digit recognition applications.",Springer
"Adel, Amr","Future of industry 5.0 in society: human-centric solutions, challenges and prospective research areas",2022,10.1186/s13677-022-00314-5,https://doi.org/10.1186/s13677-022-00314-5,Journal,Journal of Cloud Computing,"Industry 4.0 has been provided for the last 10 years to benefit the industry and the shortcomings; finally, the time for industry 5.0 has arrived. Smart factories are increasing the business productivity; therefore, industry 4.0 has limitations. In this paper, there is a discussion of the industry 5.0 opportunities as well as limitations and the future research prospects. Industry 5.0 is changing paradigm and brings the resolution since it will decrease emphasis on the technology and assume that the potential for progress is based on collaboration among the humans and machines. The industrial revolution is improving customer satisfaction by utilizing personalized products. In modern business with the paid technological developments, industry 5.0 is required for gaining competitive advantages as well as economic growth for the factory. The paper is aimed to analyze the potential applications of industry 5.0. At first, there is a discussion of the definitions of industry 5.0 and advanced technologies required in this industry revolution. There is also discussion of the applications enabled in industry 5.0 like healthcare, supply chain, production in manufacturing, cloud manufacturing, etc. The technologies discussed in this paper are big data analytics, Internet of Things, collaborative robots, Blockchain, digital twins and future 6G systems. The study also included difficulties and issues examined in this paper head to comprehend the issues caused by organizations among the robots and people in the assembly line.",Springer
"Garg, Divya and Verma, Gyanendra Kumar and Singh, Awadhesh Kumar",EEG-Based Emotion Recognition Using Quantum Machine Learning,2023,10.1007/s42979-023-01943-6,https://doi.org/10.1007/s42979-023-01943-6,Journal,SN Computer Science,"Recognizing emotions is crucial for the development of artificial intelligence in various fields. This study explores the application of quantum support vector machines (SVMs) on emotion recognition from electroencephalogram (EEG) signals and compares its performance to traditional SVMs. SVMs are a popular machine-learning algorithm for this task due to their ability to handle high-dimensional data and non-linear relationships between input features. This study uses a quantum SVM to generate distinct solutions based on quantum principles. We applied this method to the DEAP benchmark dataset for binary class classification and gained new insights into the quantum nature of emotions. The algorithm has trained on D-Wave quantum annealer using various samples, achieving accuracies of 65.6{\%} and 75.0{\%} for valence and arousal dimensions, respectively, with 22{\thinspace}{\texttimes}{\thinspace}40{\thinspace}{\texttimes}{\thinspace}32 (subjects{\thinspace}{\texttimes}{\thinspace}trials{\thinspace}{\texttimes}{\thinspace}channels) data points, demonstrating the potential of quantum machine learning for EEG-based emotion recognition. However, there are methodological challenges due to the quantum arbitrariness of current annealers and the sensitivity of quantum-based machines to initial values. To address this, we conducted multiple investigations under similar circumstances and successfully recognized emotions using our proposed method.",Springer
"Bahache, Anwar Noureddine and Chikouche, Noureddine and Mezrag, Fares",Authentication Schemes for Healthcare Applications Using Wireless Medical Sensor Networks: A Survey,2022,10.1007/s42979-022-01300-z,https://doi.org/10.1007/s42979-022-01300-z,Journal,SN Computer Science,"Many applications are developed with the quick emergence of the Internet of things (IoT) and wireless sensor networks (WSNs) in the health sector. Healthcare applications that use wireless medical sensor networks (WMSNs) provide competent communication solutions for enhancing people life. WMSNs rely on highly sensitive and resource-constrained devices, so-called sensors, that sense patients' vital signs then send them through open channels via gateways to specialists. However, these transmitted data from WMSNs can be manipulated by adversaries without data security, resulting in crucial consequences. In light of this, efficient security solutions and authentication schemes are needed. Lately, researchers have focussed highly on authentication for WMSNs, and many schemes have been proposed to preserve privacy and security requirements. These schemes face a lot of security and performance issues due to the constrained devices used. This paper presents a new classification of authentication schemes in WMSNs based on its architecture; as far as we know, it is the first of its kind. It also provides a comprehensive study of the existing authentication schemes in terms of security and performance. The performance evaluation is based on experimental results. Moreover, it identifies some future research directions and recommendations for designing authentication schemes in WMSNs.",Springer
"Vesala, G. T. and Ghali, V. S. and Subhani, S. and Vijaya Lakshmi, A. and Naik, R. B.",Convolution Neural Networks Based Automatic Subsurface Anomaly Detection and Characterization in Quadratic Frequency Modulated Thermal Wave Imaging,2022,10.1007/s42979-022-01055-7,https://doi.org/10.1007/s42979-022-01055-7,Journal,SN Computer Science,"Recent trends in thermal non-destructive testing focusing on artificial intelligence and various deep learning architectures have been investigated for quality assessment of different materials. The present work introduces three famous computer vision models (AlexNet, GoogleNet and VggNet) with one-dimensional convolution layers for defect detection for material inspected by quadratic frequency modulated thermal wave imaging. These models employ sequential convolution operations and pooling on temporal thermal profiles and extract deep features further to classify defect and sound regions in the test sample. The three deep learning models are trained from scratch with the experimental thermographic data of a carbon fiber reinforced polymer (CFRP) specimen with artificially simulated flat bottom hole defects of different sizes at varying depths. The performance metrics conclude that AlexNet presents high testing accuracy and F-score of 98.92{\%} and 0.954 resulting in less deviation to the actual labels favoring enhanced defect signal-to-noise ratio with less computation time in CPU-based hardware. Further, the depth of the detected defect was quantified using a recently introduced quantification model using the chirp-z transform-based phase analysis. The estimated depths are rearranged in the respective locations and visualized the depth map.",Springer
"Divakaran, Aswathy and Mohan, Anuraj",Temporal Link Prediction: A Survey,2020,10.1007/s00354-019-00065-z,https://doi.org/10.1007/s00354-019-00065-z,Journal,New Generation Computing,"The evolutionary behavior of temporal networks has gained the attention of researchers with its ubiquitous applications in a variety of real-world scenarios. Learning evolutionary behavior of networks is directly related to link prediction problem, as the addition or removal of new links or edges over time leads to the network evolution. With the rise of large-scale temporal networks such as social networks, temporal link prediction has become an interesting field of study. In this work, we provide a detailed survey of various researches carried out in the direction of temporal link prediction. We build a taxonomy of temporal link prediction methods based on various approaches used and discuss the works which come under each category. Further, we present the challenges and directions for future works.",Springer
"Nurjahan and Mahbub-Or-Rashid, Md. and Satu, Md. Shahriare and Tammim, Sanjana Ruhani and Sunny, Farhana Akter and Moni, Mohammad Ali",Machine learning and deep learning algorithms in detecting COVID-19 utilizing medical images: a comprehensive review,2024,10.1007/s42044-024-00190-z,https://doi.org/10.1007/s42044-024-00190-z,Journal,Iran Journal of Computer Science,"The public's health is seriously at risk from the coronavirus pandemic. Millions of people have already died as a result of this devastating illness, which affects countless people daily worldwide. Unfortunately, no specific therapeutic drugs or vaccines are available to cure patients completely. Therefore, early identification of infected individuals and their isolation can help reduce community transmission of COVID-19. Despite being commonly used, the reverse transcription polymerase chain reaction (RT-PCR) test is costly, time-consuming, and requires suitable kits, which are not always readily available. An alternative solution for the traditional RT-PCR test is machine learning and deep learning-based COVID-19 detection that utilizes clinical features of chest X-rays and computed tomography (CT) images. In this study, we conducted a detailed review of more than 100 recently published works to detect COVID-19-infected patients. Thus, different data preprocessing, data augmentation, image enhancement, feature extraction, machine learning, deep learning, Explainable Artificial Intelligence (AI) methods, etc. were explored to understand how these techniques were used to process images for identifying COVID-19. Additionally, we identified the current challenges in this field and suggested further research directions.",Springer
"Saborido, Rub{\'e}n and Morales, Rodrigo and Khomh, Foutse and Gu{\'e}h{\'e}neuc, Yann-Ga{\""e}l and Antoniol, Giuliano",Getting the most from map data structures in Android,2018,10.1007/s10664-018-9607-8,https://doi.org/10.1007/s10664-018-9607-8,Journal,Empirical Software Engineering,"A map is a data structure that is commonly used to store data as key--value pairs and retrieve data as keys, values, or key--value pairs. Although Java offers different map implementation classes, Android SDK offers other implementations supposed to be more efficient than HashMap: ArrayMap and SparseArray variants (SparseArray, LongSparseArray, SparseIntArray, SparseLongArray, and SparseBooleanArray). Yet, the performance of these implementations in terms of CPU time, memory usage, and energy consumption is lacking in the official Android documentation; although saving CPU, memory, and energy is a major concern of users wanting to increase battery life. Consequently, we study the use of map implementations by Android developers in two ways. First, we perform an observational study of 5713 Android apps in GitHub. Second, we conduct a survey to assess developers' perspective on Java and Android map implementations. Then, we perform an experimental study comparing HashMap, ArrayMap, and SparseArray variants map implementations in terms of CPU time, memory usage, and energy consumption. We conclude with guidelines for choosing among the map implementations: HashMap is preferable over ArrayMap to improve energy efficiency of apps, and SparseArray variants should be used instead of HashMap and ArrayMap when keys are primitive types.",Springer
"Shi, Ruohan and Fan, Qilin and Fu, Shu and Zhang, Xu and Li, Xiuhua and Chen, Meng",COCAM: a cooperative video edge caching and multicasting approach based on multi-agent deep reinforcement learning in multi-clouds environment,2023,10.1186/s13677-023-00510-x,https://doi.org/10.1186/s13677-023-00510-x,Journal,Journal of Cloud Computing,"The evolution of the Internet of Things technology (IoT) has boosted the drastic increase in network traffic demand. Caching and multicasting in the multi-clouds scenario are effective approaches to alleviate the backhaul burden of networks and reduce service latency. However, existing works do not jointly exploit the advantages of these two approaches. In this paper, we propose COCAM, a cooperative video edge caching and multicasting approach based on multi-agent deep reinforcement learning to minimize the transmission number in the multi-clouds scenario with limited storage capacity in each edge cloud. Specifically, by integrating a cooperative transmission model with the caching model, we provide a concrete formulation of the joint problem. Then, we cast this decision-making problem as a multi-agent extension of the Markov decision process and propose a multi-agent actor-critic algorithm in which each agent learns a local caching strategy and further encompasses the observations of neighboring agents as constituents of the overall state. Finally, to validate the COCAM algorithm, we conduct extensive experiments on a real-world dataset. The results show that our proposed algorithm outperforms other baseline algorithms in terms of the number of video transmissions.",Springer
"Samala, Agariadne Dwinggo and Rawas, Soha and Criollo-C, Santiago and Bojic, Ljubisa and Prasetya, Febri and Ranuharja, Fadhli and Marta, Rizkayeni","Emerging Technologies for Global Education: A Comprehensive Exploration of Trends, Innovations, Challenges, and Future Horizons",2024,10.1007/s42979-024-03538-1,https://doi.org/10.1007/s42979-024-03538-1,Journal,SN Computer Science,"Emerging technologies (ETs), including artificial intelligence (AI), blockchain, non-fungible tokens (NFTs), the Internet of Things (IoT), augmented reality (AR), virtual reality (VR), mixed reality (MR), extended reality (XR), robotics, and 3D printing, have greatly impacted education. While these technologies are commonly used in informal learning, their application in formal education remains under explored. This systematic review addresses this gap by analyzing the effective use of these technologies in formal education. Following Preferred Reporting Items for Systematic reviews and Meta-Analyses (PRISMA) guidelines and using bibliometric analysis, this research reviewed experimental studies from the Scopus database (2008--2022). Data visualization tools, including RStudio, VOSviewer, Python, and Microsoft Excel, facilitated robust analysis. The study identifies gaps in technology adoption arising from economic status, infrastructure, and digital literacy challenges. It highlights the benefits of mobile apps and Learning Management Systems (LMS) in enhancing information retrieval, communication, and learning support. Challenges include the need for pedagogical skills, ICT competencies, and information literacy. Additionally, the study explores the potential of adaptive learning technologies and personalized learning environments to transform education by tailoring experiences to individual needs. Effective technology integration in education provides valuable insights for educators, policymakers, and researchers, highlighting strategies to overcome existing challenges and improve educational outcomes.",Springer
"Gao, Shujun and de Silva, Clarence W.",A univariate marginal distribution algorithm based on extreme elitism and its application to the robotic inverse displacement problem,2017,10.1007/s10710-017-9298-8,https://doi.org/10.1007/s10710-017-9298-8,Journal,Genetic Programming and Evolvable Machines,"In this paper, a univariate marginal distribution algorithm in continuous domain (UMDAC) based on extreme elitism (EEUMDAC) is proposed for solving the inverse displacement problem (IDP) of robotic manipulators. This algorithm highlights the effect of a few top best solutions to form a primary evolution direction and obtains a fast convergence rate. Then it is implemented to determine the IDP of a 4-degree-of-freedom (DOF) Barrett WAM robotic arm. After that, the algorithm is combined with differential evolution (EEUMDAC-DE) to solve the IDP of a 7-DOF Barrett WAM robotic arm. In addition, three other heuristic optimization algorithms (enhanced leader particle swarm optimization, intersect mutation differential evolution, and evolution strategies) are applied to find the IDP solution of the 7-DOF arm and their performance is compared with that of EEUMDAC-DE.",Springer
"Talia, Domenico",A view of programming scalable data analysis: from clouds to exascale,2019,10.1186/s13677-019-0127-x,https://doi.org/10.1186/s13677-019-0127-x,Journal,Journal of Cloud Computing,"Scalability is a key feature for big data analysis and machine learning frameworks and for applications that need to analyze very large and real-time data available from data repositories, social media, sensor networks, smartphones, and the Web. Scalable big data analysis today can be achieved by parallel implementations that are able to exploit the computing and storage facilities of high performance computing (HPC) systems and clouds, whereas in the near future Exascale systems will be used to implement extreme-scale data analysis. Here is discussed how clouds currently support the development of scalable data mining solutions and are outlined and examined the main challenges to be addressed and solved for implementing innovative data analysis applications on Exascale systems.",Springer
"Ogala, Justin Onyarin and Ahmad, Shahnawaz and Shakeel, Iman and Ahmad, Javed and Mehfuz, Shabana","Strengthening KMS Security with Advanced Cryptography, Machine Learning, Deep Learning, and IoT Technologies",2023,10.1007/s42979-023-02073-9,https://doi.org/10.1007/s42979-023-02073-9,Journal,SN Computer Science,"This paper presents an innovative approach to strengthening Key Management Systems (KMS) against the escalating landscape of cyber threats by integrating advanced cryptographic technologies, machine learning, deep learning, and the Internet of Things (IoT). As digital reliance and cyber-attacks surge, strengthening KMS security becomes paramount. Our research provides a comprehensive overview of the state-of-the-art in cloud data security, identifying key vulnerabilities in existing KMS. The paper also outlines a distinctive framework based on the combined application of advanced cryptography, machine learning, deep learning, and IoT, which represents a novel approach in the quest for robust KMS security. Our experimental results substantiate the efficacy of this unique blend of technologies, providing solid empirical evidence that such a fusion can successfully strengthen KMS against potential threats. As technologies and threat landscapes continue to evolve, our framework can serve as a benchmark for future research and practical implementations. It highlights the potential of integrated technological solutions to counter complex cybersecurity issues. Moreover, the approach we've developed can be adapted and expanded to cater to the specific needs of different sectors, such as finance, healthcare, and e-commerce, which are particularly vulnerable to cyber threats. The novelty of our work lies in the amalgamation of the four technologies and the creation of an empirically backed, robust framework, marking a significant stride in KMS security.",Springer
"Altahat, Mohammad A. and Daradkeh, Tariq and Agarwal, Anjali",Virtual machine scheduling and migration management across multi-cloud data centers: blockchain-based versus centralized frameworks,2025,10.1186/s13677-024-00724-7,https://doi.org/10.1186/s13677-024-00724-7,Journal,Journal of Cloud Computing,"Efficiently managing virtual resources in the cloud is crucial for successful recourse utilization. Scheduling is a vital technique used to manage Virtual Machines (VMs), enabling placement and migration between hosts located in the same or different data centers. Effective scheduling not only ensures better server consolidation but also enhances hardware utilization and reduces power consumption in data centers. However, scheduling VMs across a Wide Area Network (WAN) poses considerable challenges due to connectivity issues, slower communication speeds, and concerns around data integrity and confidentiality. To enable informed scheduling decisions, it is critical to facilitate the exchange of real-time and accurate status information between cloud data centers, ensuring optimal resource allocation and minimizing latency. To address this, we propose a novel distributed cloud management solution that utilizes blockchain technology to facilitate efficient sharing of VM characteristics across multiple data centers. BigchainDB platform has been used as a blockchain-based ledger database to effectively share information required for VM scheduling and migration across different data centers. The proposed framework has been validated and compared with a Virtual Private Network (VPN)-based centralized management solution. The proposed model utilizing blockchain-based solution achieves 41.79{\%} to 49.85{\%} reduction in number of communication messages and 2{\%} to 12{\%} decrease in total communication delay comparing to the centralized model.",Springer
"Ding, Yongcheng and Chen, Xi and Lamata, Lucas and Solano, Enrique and Sanz, Mikel",Implementation of a Hybrid Classical-Quantum Annealing Algorithm for Logistic Network Design,2021,10.1007/s42979-021-00466-2,https://doi.org/10.1007/s42979-021-00466-2,Journal,SN Computer Science,"The logistic network design is an abstract optimization problem that, under the assumption of minimal cost, seeks the optimal configuration of the supply chain's infrastructures and facilities based on customer demand. Key economic decisions are taken about the location, number, and size of manufacturing facilities and warehouses based on the optimal solution. Therefore, improvements in the methods to address this question, which is known to be in the NP-hard complexity class, would have relevant financial consequences. Here, we implement in the D-Wave quantum annealer a hybrid classical-quantum annealing algorithm. The cost function with constraints is translated to a spin Hamiltonian, whose ground state encodes the searched result. As a benchmark, we measure the accuracy of results for a set of paradigmatic problems against the optimal published solutions (the error is on average below {\$}{\$}1{\backslash}{\%}{\$}{\$}), and the performance is compared against the classical algorithm, showing a remarkable reduction in the number of iterations. This work shows that state-of-the-art quantum annealers may codify and solve relevant supply-chain problems even still far from useful quantum supremacy.",Springer
"Gleirscher, Mario and van de Pol, Jaco and Woodcock, Jim",A manifesto for applicable formal methods,2023,10.1007/s10270-023-01124-2,https://doi.org/10.1007/s10270-023-01124-2,Journal,Software and Systems Modeling,"Recently, formal methods have been used in large industrial organisations (including AWS, Facebook/Meta, and Microsoft) and have proved to be an effective part of a software engineering process finding important bugs. Perhaps because of that, practitioners are interested in using them more often. Nevertheless, formal methods are far less applied than expected, particularly for safety-critical systems where they are strongly recommended and have the most significant potential. We hypothesise that formal methods still seem not applicable enough or ready for their intended use in such areas. In critical software engineering, what do we mean when we speak of a formal method? And what does it mean for such a method to be applicable both from a scientific and practical viewpoint? Based on what the literature tells about the first question, with this manifesto, we identify key challenges and lay out a set of guiding principles that, when followed by a formal method, give rise to its mature applicability in a given scope. Rather than exercising criticism of past developments, this manifesto strives to foster increased use of formal methods in any appropriate context to the maximum benefit.",Springer
"Godunov, A. N. and Soldatov, V. A.","Baget real-time operating system family (features, comparison, and future development)",2014,10.1134/S036176881405003X,https://doi.org/10.1134/S036176881405003X,Journal,Programming and Computer Software,Main features of Baget 2.0 and Baget 3.0 Russian real-time operating systems (RTOSs) are discussed. Their similarities and differences are examined. Ways of further development of RTOS Baget are considered.,Springer
"Bahi, Mouad and Eisenbeis, Christine",Impact of Reverse Computing on Information Locality in Register Allocation for High Performance Computing,2014,10.1007/s10766-012-0212-y,https://doi.org/10.1007/s10766-012-0212-y,Journal,International Journal of Parallel Programming,"Reversible computing aims at keeping all information on input and intermediate values available at any step of the computation, making information virtually present everywhere. Rematerialization in register allocation amounts to recomputing values instead of spilling them in memory when registers run out. In this paper we detail a heuristic algorithm for exploiting reverse computing for register materialization. This improves information locality as it provides more opportunities for retrieving data. Rematerialization adds instructions and we show on one specifically designed example that reverse computing may alleviate the impact of these additional instructions on performance. We also show how thread parallelism may be optimized on GPUs by performing register allocation with reverse recomputing that increases the number of threads per Streaming Multiprocessor. This is done on the main kernel of Lattice Quantum Chromo Dynamics simulation program where we gain a 11 {\%} speedup.",Springer
"Blenninger, Jonas and Bucher, David and Cortiana, Giorgio and Ghosh, Kumar and Mohseni, Naeimeh and N{\""u}{\ss}lein, Jonas and O'Meara, Corey and Porawski, Daniel and Wimmer, Benedikt",Q-GRID: Quantum Optimization for the Future Energy Grid,2024,10.1007/s13218-024-00866-5,https://doi.org/10.1007/s13218-024-00866-5,Journal,"KI - K{\""u}nstliche Intelligenz","In this project summary paper, we summarize the key results and use-cases explored in the German Federal Ministry of Education and Research (BMBF) funded project ``Q-GRID'' which aims to assess potential quantum utility optimization applications in the electrical grid. The project focuses on two layers of optimization problems relevant to decentralized energy generation and transmission as well as novel energy transportation/exchange methods such as Peer-2-Peer energy trading and microgrid formation. For select energy grid optimization problems, we demonstrate exponential classical optimizer runtime scaling even for small problem instances, and present initial findings that variational quantum algorithms such as QAOA and hybrid quantum annealing solvers may provide more favourable runtime scaling to obtain similar solution quality. These initial results suggest that quantum computing may be a key enabling technology in the future energy transition insofar that they may be able to solve business problems which are already challenging at small problem instance sizes.",Springer
"Yi, Haibo",Improving cloud storage and privacy security for digital twin based medical records,2023,10.1186/s13677-023-00523-6,https://doi.org/10.1186/s13677-023-00523-6,Journal,Journal of Cloud Computing,"As digital transformation progresses across industries, digital twins have emerged as an important technology. In healthcare, digital twins are created by digitizing patient parameters, medical records, and treatment plans to enable personalized care, assist diagnosis, and improve planning. Data is core to digital twins, originating from physical and virtual entities as well as services. Once processed and integrated, data drives various components. Medical records are critical healthcare data but present unique challenges for digital twins. However, directly storing or encrypting medical records has issues. Plaintext risks privacy leaks while encryption hinders retrieval. To address this, we present a cloud-based solution combining post-quantum searchable encryption. Our system includes key generation using Physical Unable Functions (PUF). It encrypts medical records in cloud storage, verifies records using blockchain, and retrieves records via cloud. By integrating cloud encryption, blockchain verification and cloud retrieval, we propose a secure and efficient cloud-based medical records system for digital twins. Our implementation demonstrates the system provides users efficient and secure medical record services, compared to related designs. This highlights digital twins' potential to transform healthcare through secure data-driven personalized care, diagnosis and planning.",Springer
"Liu, Zhi and Qiao, Bo and Fang, Kui",Joint optimization strategy for QoE-aware encrypted video caching and content distributing in multi-edge collaborative computing environment,2020,10.1186/s13677-020-00204-8,https://doi.org/10.1186/s13677-020-00204-8,Journal,Journal of Cloud Computing,"The video request service of users in 5G network will explode, and adaptive bit rate technology can provide users with reliable video response. Placing video resources on edge servers close to users can overcome the problem of excessive network load similar to traditional centralized cloud platform solutions. Moreover, multiple edge servers can provide caching and transcoding support by collaboration mechanisms, which further improves users' Quality of Experience (QoE). However, the design difficulty of video caching and content distribution strategies is increased due to the diversity of collaboration mechanisms and the competition between local and collaborative services of edge servers for computing and storage resources. In order to solve this problem, video cache and content distribution problem is modeled as random integer programming problem in the multi-edge server at most two-hop collaboration scenario. In order to improve the security of video data transmission, the video stream is encrypted using an encryption algorithm based on Logistic chaotic-Quantum-dot Cellular Automata (QCA). For improving the efficiency of solving integer programming problems, this paper uses a pyramid intelligent evolution algorithm based on optimal cooperation strategy to solve this problem. Simulation experiments show that our proposed method can obtain higher QoE value compared with several newer methods. In addition, the average access delay of proposed method is shortened by more than 27.98{\%}, which verifies its reliability.",Springer
"Gomes, Cl{\'a}udio and Falcao, Gabriel and Paquete, Lu{\'i}s and Fernandes, Jo{\~a}o Paulo",An Empirical Study on the Use of Quantum Computing for Financial Portfolio Optimization,2022,10.1007/s42979-022-01215-9,https://doi.org/10.1007/s42979-022-01215-9,Journal,SN Computer Science,"Quantum Computing (QC) is regarded with a mix of amazement, excitement, and skepticism. While quantum computers have been shown to outperform classical ones in particular computational tasks, their effective applicability to general-purpose problems remains under-studied. We shed light on the practical use of QC to tackle a combinatorial optimization problem in Finance, the Portfolio Optimization Problem (POP). We present an in-depth empirical study on the influence that configurable parameters of both a state-of-the-art adiabatic quantum computer and POP itself can have on the overall quality of the solutions we obtain. Our results show that some of these parameters, such as chain strength and a number of reads, have a significant statistical effect, while others, such as anneal schedule and embedding, do not. Our results also show that the quality of the solutions returned by a quantum computer, given a quadratic unconstrained binary optimization formulation of POP from the literature, is still far from the quality of the solutions produced by a classical computer using an exact algorithm. We believe the conclusions drawn from our study are valuable contributions to the utilization of adiabatic quantum computers in practice, not only in the context of POP but also for other application domains.",Springer
"Affum, Eric and Enchill, Marian",Data Confidentiality in Machine Learning: Exploring Multivariate Regression and Its Application on Encrypted Medical Data,2024,10.1007/s42979-024-02657-z,https://doi.org/10.1007/s42979-024-02657-z,Journal,SN Computer Science,"In this work, we present a concise literature review on the application of multivariate regression using gradient descent. We employed gradient descent, which provides an optimal approach for minimizing the cost function in a regression model for error estimation, and further modelled a multivariate regression algorithm to perform regression analysis over encrypted data. To encrypt the dataset, we modified the original integer homomorphic encryption scheme into a new scheme for dataset encryption to achieve an efficient and secure data encryption and decryption operation. Since homomorphic operations do not support division, we devised a division-free gradient descent multivariate regression over cost-effective VHE encrypted training samples with high regression accuracy. We conducted simulations to compare least-squares and gradient descent with and without division. We also proved the applicability of machine learning for modeling encrypted datasets based on breast cancer datasets, with the focus on determining breast cancer potential patients. In our system, encrypted datasets should not interrupt the learning task, nor should the learning task reveal sensitive information to unauthorized users.",Springer
"Chhangte, Lalengmawia and Chakrabarty, Alok",Mapping Quantum Circuits in IBM Q Devices Using Progressive Qubit Assignment for Global Ordering,2022,10.1007/s00354-022-00163-5,https://doi.org/10.1007/s00354-022-00163-5,Journal,New Generation Computing,"One major challenge in executing a quantum circuit is the restriction on physical qubit interaction. The elementary gates in a quantum circuit must strictly conform to the hardware's qubit coupling constraints before they are executed. This requires doing an initial mapping of input circuit qubits to physical qubits alongside satisfying qubit couplings specified by a qubit coupling map. Currently, quantum computing architectures possess the restrictions of limited qubit interaction distance and the inability of multi-qubit interaction. Two qubits of a quantum gate can interact if they locate adjacent to each other. During the execution of a quantum circuit, it is essential to re-arrange qubits for adjacency. As a result, the number of gates increases. We can address these issues by mapping the qubits of the input circuit to hardware and performing qubit re-ordering with minimal additional gates. In the proposed work, we efficiently generate a good initial qubit mapping that attempts to keep frequently interacting qubits together and use a multi-window look-ahead technique for qubit re-ordering. The proposed work is evaluated on the most recent IBM Q 16 Melbourne device. The experimental evaluation confirms the effectiveness of our work for minimizing the circuit cost and depth.",Springer
"Sarin, K. S.",Discrete Optimization Algorithm Based on Probability Distribution with Transformation of Target Values,2024,10.1134/S0361768824700312,https://doi.org/10.1134/S0361768824700312,Journal,Programming and Computer Software,"Problems of search optimization in a discrete space, particularly, in a binary space where a variable can take only two values, are of great practical importance. This paper proposes a new population-based discrete optimization algorithm that uses probability distributions of variables. The distributions determine the probability of taking one or another discrete value and are generated by transforming target values of solutions into their weight coefficients. The performance of the algorithm is evaluated using unimodal and multimodal test functions with binary variables. The experimental results demonstrate the high efficiency of the proposed algorithm in terms of convergence rate and stability.",Springer
"Rebentrost, Patrick and Lloyd, Seth",Quantum Computational Finance: Quantum Algorithm for Portfolio Optimization,2024,10.1007/s13218-024-00870-9,https://doi.org/10.1007/s13218-024-00870-9,Journal,"KI - K{\""u}nstliche Intelligenz","We present a quantum algorithm for portfolio optimization. We discuss the market data input of asset prices, the processing of such data via quantum operations, and the output of financially relevant results. Given quantum access to a historical record of asset returns, the algorithm determines the optimal risk-return tradeoff curve and allows one to sample from the optimal portfolio. The algorithm can in principle attain a run time of {\$}{\$}{\backslash}textrm{\{}poly{\}}({\backslash}log (N)){\$}{\$}, where N is the number of assets. Direct classical algorithms for determining the risk-return curve and other properties of the optimal portfolio take time {\$}{\$}{\backslash}textrm{\{}poly{\}}(N){\$}{\$}and we discuss potential quantum speedups in light of efficient classical sampling approaches.",Springer
"Angeline, Peter J.",The Revolution Continues,2021,10.1007/s42979-021-00798-z,https://doi.org/10.1007/s42979-021-00798-z,Journal,SN Computer Science,Evolutionary Computations have risen from rather humble beginnings to a well-regarded and flexible technique that is imperative to the needs of modern intelligent computations. This introduction to this special issue provides both a historical perspective and a current characterization of the context in which Evolutionary Computations have evolved.,Springer
"Ait Oulahyane, Hafsa and Bahnasse, Ayoub and Bakali, Assia and Broumi, Said and El-Hasnony, Ibrahim M. and Talea, Mohamed",Secure Model for Dynamic Access Control and Unreliable Access Point Detection: Enhancing QoS Through SDN in Wireless Networks,2023,10.1007/s42979-023-02407-7,https://doi.org/10.1007/s42979-023-02407-7,Journal,SN Computer Science,"Over the past few years, we have seen the spread of wireless networks in institutions, businesses, and private homes. Their wide variety, market availability, and ease of implementation have made this wireless technology more popular than wired networks. Nevertheless, enterprises are still demanding better quality of service to meet the needs of sensitive applications and avoid data loss. The SDN approach provides the ability to manage QoS dynamically via a controller. In this paper, we developed a secure model based on dynamic access control and the detection of unreliable access points. We also proposed QoS management in a wireless network by adopting the SDN approach to address connection problems and efficiently utilize resources. By employing these tools and techniques, we can narrow down all possible options to one single best choice. By comparing the results, our model validates its effectiveness in minimizing latency, jitter, packet loss, and transaction delay and offers a good opinion score.",Springer
"Ghorbani, Mohsen and Bahaghighat, Mahdi and Xin, Qin and {\""O}zen, Figen",ConvLSTMConv network: a deep learning approach for sentiment analysis in cloud computing,2020,10.1186/s13677-020-00162-1,https://doi.org/10.1186/s13677-020-00162-1,Journal,Journal of Cloud Computing,"The rapid development of social media, and special websites with critical reviews of products have created a huge collection of resources for customers all over the world. These data may contain a lot of information including product reviews, predicting market changes, and the polarity of opinions. Machine learning and deep learning algorithms provide the necessary tools for intelligence analysis in these challenges. In current competitive markets, it is essential to understand opinions, and sentiments of reviewers by extracting and analyzing their features. Besides, processing and analyzing this volume of data in the cloud can increase the cost of the system, strongly. Fewer dependencies on expensive hardware, storage space, and related software can be provided through cloud computing and Natural Language Processing (NLP). In our work, we propose an integrated architecture of Convolutional Neural Network (CNN) and Long Short-Term Memory (LSTM) network to identify the polarity of words on the Google cloud and performing computations on Google Colaboratory. Our proposed model based on deep learning algorithms with word embedding technique learns features through a CNN layer, and these features are fed directly into a bidirectional LSTM layer to capture long-term feature dependencies. Then, they can be reused from a CNN layer to provide abstract features before final dense layers. The main goal for this work is to provide an appropriate solution for analyzing sentiments and classification of the opinions into positive and negative classes. Our implementations show that found on the proposed model, the accuracy of more than 89.02{\%} is achievable.",Springer
"Gong, Chi and Bryan, Jordan and Furcoiu, Alex and Su, Qichang and Grobe, Rainer",Evolutionary Symbolic Regression from a Probabilistic Perspective,2022,10.1007/s42979-022-01094-0,https://doi.org/10.1007/s42979-022-01094-0,Journal,SN Computer Science,"We examine the genetic evolution-based algorithm for symbolic regression from a probabilistic dynamical perspective. This approach permits us to follow the evolution of the search candidate functions from generation to generation as they improve their fitness and finally converge to the best function that matches a given data set. In particular, we use this statistical framework to explore the optimal external parameters that govern a special mutation operator, which can systematically improve the numerical value of constants contained in each candidate formula of the search space. We then apply symbolic regression to the chaotic logistic map and the Lorenz system.",Springer
"Alkhodair, Ahmad J. and Mohanty, Saraju P. and Kougianos, Elias",FlexiChain: A Minerless Scalable Next Generation Blockchain for Rapid Data and Device Security in Large Scale Complex Cyber-Physical Systems,2022,10.1007/s42979-022-01139-4,https://doi.org/10.1007/s42979-022-01139-4,Journal,SN Computer Science,"The advancement of technology in several fields has given the opportunity to change the conventional ways of the daily services and activities to a better, easier, efficient, and fully or partially automated manner. Cyber-physical system (CPS) application interactions using distributed ledger technology (DLT) will enrich the conventional ways. We propose a DLT designed based on CPS application requirements to transform the traditional paradigm to a decentralized version. The proposed technology ensures the security of the process and the integrity of the participant in a flexible ledger that includes a virtual version of the actual nodes that are part of the network. The whole technology comprises of two essential algorithms: the registration and the authentication, each of which has been experimented with and analyzed. The experiment conducted for three different cases of 10, 20, and 30 nodes, respectively, and the average registration time was 0.48, 0.54, and 0.7 ms. The average authentication time for the three cases was 3, 2.42, 1.23 ms/tx.",Springer
"Najaran, Mohammad Hassan Tayarani",A probabilistic meta-heuristic optimisation algorithm for image multi-level thresholding,2023,10.1007/s10710-023-09460-4,https://doi.org/10.1007/s10710-023-09460-4,Journal,Genetic Programming and Evolvable Machines,"The spread of the Severe Acute Respiratory Syndrome CoronaVirus 2 (SARS-CoV-2) which causes CoronaVirus Disease 2019 (COVID-19) has challenged many countries. To curb the effect of the pandemic requires the development of low-cost and rapid tools for detecting and diagnosing the patients. In this regard, chest X-ray scan images provide a reliable way of detecting the patients. One limitation, however, is the need for experts to analyse the images and identify the cases which can be a burden, when a large number of images are to be processed. The aim of this paper is to propose a method to extract rapidly, from the X-ray images, the regions in which there exist indications of COVID-19 infection. To identify the regions, image segmentation is required which is performed in this paper with a novel optimization algorithm. The proposed optimization algorithm uses probabilistic representation for the solutions. To improve the optimization process, we propose a diversity preserving operator. For multi-level image thresholding via optimization algorithms, different fitness functions have been proposed in the literature. In the proposed method in this paper, we use three fitness functions to benefit from the advantages of all. A fitness swapping scheme is proposed which swaps between the fitness functions in the optimization process. Also, a diversity preserving operator is proposed in this paper which compares the individuals and reinitializes the similar ones to inject diversity in the population. The proposed algorithm is tested on a number of COVID-19 benchmark images and experimental analysis suggest better performance for the proposed algorithm.",Springer
"Saha, Amit and Saha, Debasri and Chakrabarti, Amlan",Circuit Design for k-Coloring Problem and Its Implementation in Any Dimensional Quantum System,2021,10.1007/s42979-021-00813-3,https://doi.org/10.1007/s42979-021-00813-3,Journal,SN Computer Science,"With the evolution of quantum computing, researchers nowadays tend to incline to find solutions to NP-complete problems using quantum algorithms to gain asymptotic advantage. In this paper, we solve k-coloring problem (NP-complete problem) using Grover's algorithm in any dimensional quantum system or any d-ary quantum system for the first time to the best of our knowledge, where {\$}{\$}d {\backslash}ge 2{\$}{\$}. Till date, k-coloring problem has been implemented only in binary and ternary quantum systems, hence, we abide to {\$}{\$}d=2{\$}{\$}or {\$}{\$}d=3{\$}{\$}, that is for binary and ternary quantum systems for comparing our proposed work with the state-of-the-art techniques. Our comparator-based approach has reduced the qubit cost, compared to the state-of-the-art binary quantum systems (Saha et al. in IEEE Int Symp Smart Electron Syst 1:17--22, 2020). Further in this paper, with the help of newly proposed ternary comparator, a substantial reduction in quantum gate count for the ternary oracle circuit of the k-coloring problem than the previous approaches has been obtained. Later, this proposed comparator-based approach helps to generalize the implementation of the k-coloring problem in any dimensional quantum system. An end-to-end automated framework has been put forward for implementing the k-coloring problem for any undirected and unweighted graph on any available near-term quantum devices or Noisy Intermediate-Scale Quantum (NISQ) devices or multi-valued quantum simulator, which helps in generalizing our approach.",Springer
"Thirumahal, R. and Sudha Sadasivam, G. and Shruti, P.",Semantic Integration of Heterogeneous Data Sources Using Ontology-Based Domain Knowledge Modeling for Early Detection of COVID-19,2022,10.1007/s42979-022-01298-4,https://doi.org/10.1007/s42979-022-01298-4,Journal,SN Computer Science,"The enormous outbreak of biomedical knowledge, the aim of reducing computation and processing costs and the widespread availability of internet connection have created a profuse amount of electronic data. Such data are stored across the globe in various data sources that are semantically, structurally and syntactically different. This decentralized nature of biomedical data has made it difficult to obtain a unified view of the data. Data integration plays a crucial role in enhancing access to heterogeneous data making the retrieval easier and faster. A variety of ontology, machine learning, deep learning and fuzzy logic-based solutions are being developed for heterogeneous data integration. The proposed model concentrates on the automatic ontology-based data integration method that can be effectively deployed and used in the healthcare domain. The proposed model is divided into three phases. The first phase includes the automatic mapping of data and generation of local ontology across heterogeneous data sources, the second phase combines the local ontology models developed in the first phase to create a root global schema mapping and the third phase queries diverse databases to retrieve semantically analogous records. The model is created based on the medical records, chest X-ray details and COVID-19 symptom questionnaire data of various patients distributed across three data sources (SQL, mongodb and excel). Based on the data, the patients who have moderate/higher risk of developing serious illness from COVID-19 are retrieved.",Springer
"Menaouer, Brahami and Dermane, Zoulikha and El Houda Kebir, Nour and Matta, Nada",Diabetic Retinopathy Classification Using Hybrid Deep Learning Approach,2022,10.1007/s42979-022-01240-8,https://doi.org/10.1007/s42979-022-01240-8,Journal,SN Computer Science,"During the recent years, diabetic retinopathy (DR) has been one of the most threatening complications of diabetes that leads to permanent blindness. Further, DR mutilates the retinal blood vessels of a patient having diabetes. Accordingly, various artificial intelligence techniques and deep learning have been proposed to automatically detect abnormalities in DR and its different stages from retina images. In this paper, we propose a hybrid deep learning approach using deep convolutional neural network (CNN) method and two VGG network models (VGG16 and VGG19) to diabetic retinopathy detection and classification according to the visual risk linked to the severity of retinal ischemia. Indeed, the classification of DR deals with understanding the images and their context with respect to the categories. The experimental results, performed on 5584 images, which are an ensemble of online datasets, yielded an accuracy of 90.60{\%}, recall of 95{\%} and F1 score of 94{\%}. The main aim of this work is to develop a robust system for detecting and classifying DR automatically.",Springer
"Drozdov, A. Yu. and Novikov, S. V. and Vladislavlev, V. E. and Kochetkov, E. L. and Il'in, P. V.",Program auto parallelizer and vectorizer implemented on the basis of the universal translation library and LLVM technology,2014,10.1134/S0361768814030037,https://doi.org/10.1134/S0361768814030037,Journal,Programming and Computer Software,"The paper is devoted to the integration of the compiler based on the LLVM library with the tools created using the Universal Translation Library (UTL)---automatic parallelizer and vectorizer. The intermediate representations used in the libraries to be integrated are analyzed and compared. Mechanisms which had to be implemented for integration are described. The most important UTL components are also presented. Finally we present comparative performance tests of the compilation system obtained as a result of this integration, and available compilers. These tests were run on multi-core systems based on ARM and x86 architectures using SPEC/CPU2006 and NAS Parallel Benchmarks packages.",Springer
"Biswas, Rounak and Roy Talukdar, Dhruv and Roy, Utpal",Verifying the Reliability of Quantum Random Number Generator: A Comprehensive Testing Approach,2024,10.1007/s42979-023-02323-w,https://doi.org/10.1007/s42979-023-02323-w,Journal,SN Computer Science,"Computers typically use pseudo-random numbers generated by algorithms that produce a deterministic sequence of numbers that appear random but are predictable if the entropy of the seed is disclosed. On the other hand advantage of quantum random numbers is that they are generated based on the inherent uncertainty of quantum mechanics, which means they are truly random and unpredictable. This makes them ideal for cryptographic purposes, as attackers cannot easily guess or reproduce them. We proposed a test verifying the randomness of classical and quantum random number generators by running the National Institute of Science and Technology (NIST) test suite. Tests intend to draw attention to whether quantum random numbers match or surpass today's classical random numbers.",Springer
"Ihueze, Christopher Chukwutoo and Okafor, Christian Emeka and Omeiza, Obende Ezekiel",Robust Design and Intelligent Modelling of Organic-Based Composites for Armoury Applications,2024,10.1007/s42979-024-03199-0,https://doi.org/10.1007/s42979-024-03199-0,Journal,SN Computer Science,"The study focused on assessing selected organic fillers' impact (periwinkle and clam shells) on the physicochemical and mechanical properties of polyester composites. The tensile, compressive, flexural and Brinell hardness tests were respectively carried out in accordance to ASTM standards. The methods involved grinding and sieve analysis of the shells, material preparation, and Taguchi robust design aided by Plackett--Burman screening. Signal-to-noise ratio analysis guided composite fabrication. The process control variables were grouped in terms of particles sizes: 75, 150, 425 {\textmu}m, weight fraction: 5{\%}, 20{\%}, 40{\%} and material thickness: 5, 15, 25 mm. The Artificial Neural Network (ANN) training was carried out using MATLAB R2013a and the cascade-forward back-propagation architecture while Adaptive network-based fuzzy system (ANFIS) which is a well-known hybrid artificial intelligence model was subsequently applied. The geometrical model of 9 mm FMJ armour piercing ammunition projectile and the armour plate was modeled using a commercial finite element software package (ANSYS v14) suitable for high velocity impact. The Finite Element Analysis (FEA) further investigates the deformation, elastic strain, and stress response of clam and periwinkle reinforced composites under ballistic impact. Scanning Electron Microscopy (SEM), Fourier transform infrared (FTIR), Differential scanning calorimetry (DSC) and Thermogravimetric analysis (TGA)/Differential thermal analysis (DTA) were deployed to further study the morphology, chemical composition, phase transitions and thermal stability of the optimal material. The results revealed that the clam shell reinforced composite have mechanical responses of 11.038 MPa, 17.07 MPa, 40.2 MPa, and 69.62 N/mm for tensile, compressive, flexural, and hardness strength respectively. While the periwinkle shell reinforced composite has mechanical responses of 16.111 MPa, 17.173 MPa, 39.7 MPa, and 63.57 N/mm for tensile, compressive, flexural, and hardness strength respectively. FEA results indicate decreasing deformation, elastic strain, and stress with increasing material thickness. The investigation carried out indicated the impact of the organic fillers and showed that the new material properties depend on the reinforcement combinations of control parameters.",Springer
"Nazeer, Rubaina and Ali, Sajid and Hu, Zhihua and Ansari, Ghulam Jillani and Al-Razgan, Muna and Awwad, Emad Mahrous and Ghadi, Yazeed Yasin",Detection of cotton leaf curl disease's susceptibility scale level based on deep learning,2024,10.1186/s13677-023-00582-9,https://doi.org/10.1186/s13677-023-00582-9,Journal,Journal of Cloud Computing,"Cotton, a crucial cash crop in Pakistan, faces persistent threats from diseases, notably the Cotton Leaf Curl Virus (CLCuV). Detecting these diseases accurately and early is vital for effective management. This paper offers a comprehensive account of the process involved in collecting, preprocessing, and analyzing an extensive dataset of cotton leaf images. The primary aim of this dataset is to support automated disease detection systems. We delve into the data collection procedure, distribution of the dataset, preprocessing stages, feature extraction methods, and potential applications. Furthermore, we present the preliminary findings of our analyses and emphasize the significance of such datasets in advancing agricultural technology. The impact of these factors on plant growth is significant, but the intrusion of plant diseases, such as Cotton Leaf Curl Disease (CLCuD) caused by the Cotton Leaf Curl Gemini Virus (CLCuV), poses a substantial threat to cotton yield. Identifying CLCuD promptly, especially in areas lacking critical infrastructure, remains a formidable challenge. Despite the substantial research dedicated to cotton leaf diseases in agriculture, deep learning technology continues to play a vital role across various sectors. In this study, we harness the power of two deep learning models, specifically the Convolutional Neural Network (CNN). We evaluate these models using two distinct datasets: one from the publicly available Kaggle dataset and the other from our proprietary collection, encompassing a total of 1349 images capturing both healthy and disease-affected cotton leaves. Our meticulously curated dataset is categorized into five groups: Healthy, Fully Susceptible, Partially Susceptible, Fully Resistant, and Partially Resistant. Agricultural experts annotated our dataset based on their expertise in identifying abnormal growth patterns and appearances. Data augmentation enhances the precision of model performance, with deep features extracted to support both training and testing efforts. Notably, the CNN model outperforms other models, achieving an impressive accuracy rate of 99{\%} when tested against our proprietary dataset.",Springer
"Simos, Dimitris E. and Bozic, Josip and Garn, Bernhard and Leithner, Manuel and Duan, Feng and Kleine, Kristoffer and Lei, Yu and Wotawa, Franz",Testing TLS using planning-based combinatorial methods and execution framework,2019,10.1007/s11219-018-9412-z,https://doi.org/10.1007/s11219-018-9412-z,Journal,Software Quality Journal,"The TLS protocol is the standard for secure Internet communication between two parties. Unfortunately, there have been recently successful attacks like DROWN, ROBOT, or BREACH that indicate the necessity for thoroughly testing TLS implementations. In our research work, we focus on automated test case generation and execution for the TLS security protocol, where the aim is to combine planning with combinatorial methods for providing test cases that ideally also reveal previously unknown attacks. This is made feasible by creating appropriate input parameter models for different messages that can appear in a TLS message sequence. In this paper, we present the resulting test case generation and execution framework together with the corresponding test oracle. Furthermore, we discuss in detail empirical results obtained via testing different TLS implementations.",Springer
"Devezas, Jos{\'e} and Nunes, S{\'e}rgio",A Review of Graph-Based Models for Entity-Oriented Search,2021,10.1007/s42979-021-00828-w,https://doi.org/10.1007/s42979-021-00828-w,Journal,SN Computer Science,"Entity-oriented search tasks heavily rely on exploiting unstructured and structured collections. Moreover, it is frequent for text corpora and knowledge bases to provide complementary views on a common topic. While, traditionally, the retrieval unit was the document, modern search engines have evolved to also retrieve entities and to provide direct answers to the information needs of the users. Cross-referencing information from heterogeneous sources has become fundamental, however a mismatch still exists between text-based and knowledge-based retrieval approaches. The former does not account for complex relations, while the latter does not properly support keyword-based queries and ranked retrieval. Graphs are a good solution to this problem, since they can be used to represent text, entities and their relations. In this survey, we examine text-based approaches and how they evolved to leverage entities and their relations in the retrieval process. We also cover multiple aspects of graph-based models for entity-oriented search, providing an overview on link analysis and exploring graph-based text representation and retrieval, leveraging knowledge graphs for document or entity retrieval, building entity graphs from text, using graph matching for querying with subgraphs, exploiting hypergraph-based representations, and ranking based on random walks on graphs. We close with a discussion on the topic and a view of the future to motivate the research of graph-based models for entity-oriented search, particularly as joint representation models for the generalization of retrieval tasks.",Springer
"Yu, Zheng and Wu, Songyu and Jiang, Jielin and Liu, Dongqing",A knowledge-graph based text summarization scheme for mobile edge computing,2024,10.1186/s13677-023-00585-6,https://doi.org/10.1186/s13677-023-00585-6,Journal,Journal of Cloud Computing,"As the demand for edge services intensifies, text, being the most common type of data, has seen a significant expansion in data volume and an escalation in processing complexity. Furthermore, mobile edge computing (MEC) service systems often faces challenges such as limited computational capabilities and difficulties in data integration, requiring the development and implementation of more efficient and lightweight methodologies for text data processing. To swiftly extract and analysis vital information from MEC text data, an automatic generation scheme of multi-document text summarization based on knowledge graph is proposed in this paper, named KGCPN. For the text data from MEC devices and applications, the natural language processing technology is used to execute the data pre-processing steps, which transforms the MEC text data into a computationally tractable and semantically comprehensible format. Then, the knowledge graph of multi-document text is constructed by integrating the relationship paths and entity descriptions. The nodes and edges of the knowledge graph serve to symbolize the semantic relationships within the text, and the Graph Convolution Neural network (GCN) is used to understand the text and learn the semantic representation. Finally, a pointer-generator network model accepts the encoding information from GCN and automatically generate a general text summarization. The experimental results indicate that our scheme can effectively facilitate the smart pre-processing and integration of MEC data.",Springer
"De Falco, Francesca and Ceschini, Andrea and Sebastianelli, Alessandro and Le Saux, Bertrand and Panella, Massimo",Quantum Hybrid Diffusion Models for Image Synthesis,2024,10.1007/s13218-024-00858-5,https://doi.org/10.1007/s13218-024-00858-5,Journal,"KI - K{\""u}nstliche Intelligenz","In this paper, we propose a new methodology to design quantum hybrid diffusion models, derived from classical U-Nets with ResNet and Attention layers. Specifically, we propose two possible different hybridization schemes combining quantum computing's superior generalization with classical networks' modularity. In the first one, we acted at the vertex: ResNet convolutional layers are gradually replaced with variational circuits to create Quantum ResNet blocks. In the second proposed architecture, we extend the hybridization to the intermediate level of the encoder, due to its higher sensitivity in the feature extraction process. In order to conduct an in-depth analysis of the potential advantages stemming from the integration of quantum layers, images generated by quantum hybrid diffusion models are compared to those generated by classical models, and evaluated in terms of several quantitative metrics. The results demonstrate an advantage in using hybrid quantum diffusion models, as they generally synthesize better-quality images and converges faster. Moreover, they show the additional advantage of having a lower number of parameters to train compared to the classical one, with a reduction that depends on the extent to which the vertex is hybridized.",Springer
"Mogalapalli, Harshit and Abburi, Mahesh and Nithya, B. and Bandreddi, Surya Kiran Vamsi",Classical--Quantum Transfer Learning for Image Classification,2021,10.1007/s42979-021-00888-y,https://doi.org/10.1007/s42979-021-00888-y,Journal,SN Computer Science,"Classical--quantum transfer learning is a recent development in the field of quantum computing, which involves the modification of a pre-trained classical network and compounding it with a variational quantum circuit. This paper puts forward a quantum transfer learning-based approach for three different image classification tasks---classifying organic and recyclable from Trash, TB detection from chest X-ray images and detecting the presence of cracks from concrete crack images. The model used in this paper is a concatenation of pre-trained classical feature extractor with a quantum circuit as classifier. This paper compares the classification results obtained using various pre-trained networks such as VGG19, DenseNet169 and AlexNet, as feature extractors. From the obtained results, it is inferred that, DenseNet, Alexnet and VGG19 performs better in trash, TB and crack datasets, respectively. No model is the best for all the classification tasks, it is purely based on parameters such as dataset size, test-train split and learning rate.",Springer
"Zhang, Boyu and Wang, Shuo and Gao, Fuchang",Contrastive Metric Learning for Lithium Super-ionic Conductor Screening,2022,10.1007/s42979-022-01370-z,https://doi.org/10.1007/s42979-022-01370-z,Journal,SN Computer Science,"High-performance Li-ion battery significantly impacts modern society, and materials with high conductivity play critical roles in battery development. Machine learning (ML) technologies have rapidly changed the field in recent years. However, it is still challenging to predict the high conductors directly due to the lack of validated conductor samples. This paper presents a succinct but effective metric-learning framework for high conductor screening. The material structures are mapped to an optimized feature space using a Siamese network, and an instance-based method is used to classify the input sample. The experiments demonstrate that the proposed method could effectively extract knowledge from imbalanced data and has good performance and generalization ability.",Springer
"Aldeia, Guilherme Seidyo Imai and de Fran{\c{c}}a, Fabr{\'i}cio Olivetti",Interpretability in symbolic regression: a benchmark of explanatory methods using the Feynman data set,2022,10.1007/s10710-022-09435-x,https://doi.org/10.1007/s10710-022-09435-x,Journal,Genetic Programming and Evolvable Machines,"In some situations, the interpretability of the machine learning models plays a role as important as the model accuracy. Interpretability comes from the need to trust the prediction model, verify some of its properties, or even enforce them to improve fairness. Many model-agnostic explanatory methods exists to provide explanations for black-box models. In the regression task, the practitioner can use white-boxes or gray-boxes models to achieve more interpretable results, which is the case of symbolic regression. When using an explanatory method, and since interpretability lacks a rigorous definition, there is a need to evaluate and compare the quality and different explainers. This paper proposes a benchmark scheme to evaluate explanatory methods to explain regression models, mainly symbolic regression models. Experiments were performed using 100 physics equations with different interpretable and non-interpretable regression methods and popular explanation methods, evaluating the performance of the explainers performance with several explanation measures. In addition, we further analyzed four benchmarks from the GP community. The results have shown that Symbolic Regression models can be an interesting alternative to white-box and black-box models that is capable of returning accurate models with appropriate explanations. Regarding the explainers, we observed that Partial Effects and SHAP were the most robust explanation models, with Integrated Gradients being unstable only with tree-based models. This benchmark is publicly available for further experiments.",Springer
"Acharya, Biswaranjan and Panda, Sucheta and Ray, Niranjan K.",Multiprocessor Task Scheduling Optimization for Cyber-Physical System Using an Improved Salp Swarm Optimization Algorithm,2024,10.1007/s42979-023-02517-2,https://doi.org/10.1007/s42979-023-02517-2,Journal,SN Computer Science,"Salp Swarm Algorithm (SSA) is a bio-inspired optimization algorithm used in this paper to optimize the multiprocessor scheduling process in the current cyber-physical system. Although SSA is mainly utilized in terms of local search, in our case, an improved version has been introduced with the use of a Local Search Algorithm (LSA) and binary SSA, namely Improved SSA (ISSA). More to the point, eight optimization algorithms are compared with this proposed ISSA namely SSA, Particle Swarm Optimization (PSO), Genetic Algorithm (GA), Grey Wolf Optimizer (GWO), Jaya Algorithm (JAYA), Chaotic Squirrel Search Algorithm (CSSA), Quantum-inspired Binary Chaotic Salp Swarm Algorithm (QBCSSA) and Space Transformation Search (STS) with SSA is termed as STS-SSA. The performance of ISSA along with the other 6 meta-heuristic and 2 improved versions of SSA algorithms are compared with 12 traditional benchmark functions and evaluated for 100 and 300 dimensions. Convergent curves have also been demonstrated and the proposed ISSA has been shown to find a global optimum within the very initial phase of iterations. For calculating the efficiency of the proposed algorithm, the gear train design problem has been employed. The proposed algorithm has demonstrated higher accuracy rates and better convergent values than the other applied algorithms.",Springer
"Ramanathan, Shalini and Ramasundaram, Mohan",Low Dose CT Image Reconstruction Using Deep Convolutional Residual Learning Network,2023,10.1007/s42979-023-02210-4,https://doi.org/10.1007/s42979-023-02210-4,Journal,SN Computer Science,"Image reconstruction from computed tomography measurement is formulated as a thought-provoking statistical inverse problem. Deep learning algorithms are best for ill-posed statistical inverse problems that presently achieve state-of-art reconstruction results. The challenging task is to lower the potentially harmful radiation a patient is exposed to during the CT scan. In recently available CT Scanners, Low-Dose CT (LDCT) reconstruction is presented with a post-processing approach, which uses deep learning-based medical image reconstruction methods to reduce the dose level without compromising the image quality. Therefore, this paper proposes a deep learning-based post-processing method called Deep Convolutional Neural Network with Residual Learning (DCNN-RL). The method trains the network on a newly available low-dose CT benchmark dataset (LoDoPaB-CT). It also enables to compare with other benchmark CT datasets such as AAPM LDCT and COVIDx-CT. The proposed architecture optimizes the filtering part to minimize the error function. It learns the parameters of the residual network via numerous training to maximize the efficiency of production. This paper compares noise methods on DCNN-RL using various LDCT datasets of the same domain (human being's chest CT scan) to analyze the image quality. The experiment findings suggest that the Adagrad optimizer is the best for LDCT images. Gaussian noise with a minor variance outperforms the medical image reconstruction task. Here, it has been demonstrated that this approach with these benchmark datasets drastically improves the medical CT image quality, shown through qualitative and quantitative outcomes.",Springer
"Fuchs, Franz G. and Kolden, Herman {\O}ie and Aase, Niels Henrik and Sartor, Giorgio",Efficient Encoding of the Weighted MAX {\$}{\$}k{\$}{\$}-CUT on a Quantum Computer Using QAOA,2021,10.1007/s42979-020-00437-z,https://doi.org/10.1007/s42979-020-00437-z,Journal,SN Computer Science,"The weighted MAX {\$}{\$}k{\$}{\$}-CUT problem consists of finding a k-partition of a given weighted undirected graph G(V, E), such that the sum of the weights of the crossing edges is maximized. The problem is of particular interest as it has a multitude of practical applications. We present a formulation of the weighted MAX {\$}{\$}k{\$}{\$}-CUT suitable for running the quantum approximate optimization algorithm (QAOA) on noisy intermediate scale quantum (NISQ) devices to get approximate solutions. The new formulation uses a binary encoding that requires only {\$}{\$}|V|{\backslash}log {\_}2k{\$}{\$}qubits. The contributions of this paper are as follows: (i) a novel decomposition of the phase-separation operator based on the binary encoding into basis gates is provided for the MAX {\$}{\$}k{\$}{\$}-CUT problem for {\$}{\$}k>2{\$}{\$}. (ii) Numerical simulations on a suite of test cases comparing different encodings are performed. (iii) An analysis of the resources (number of qubits, CX gates) of the different encodings is presented. (iv) Formulations and simulations are extended to the case of weighted graphs. For small k and with further improvements when k is not a power of two, our algorithm is a possible candidate to show quantum advantage on NISQ devices.",Springer
"Amaithi Rajan, Arun and V, Vetriselvi and Raikwar, Mayank and Balaraman, Reshma",SMedIR: secure medical image retrieval framework with ConvNeXt-based indexing and searchable encryption in the cloud,2024,10.1186/s13677-024-00702-z,https://doi.org/10.1186/s13677-024-00702-z,Journal,Journal of Cloud Computing,"The security and privacy of medical images are crucial due to their sensitive nature and the potential for severe consequences from unauthorized modifications, including data breaches and inaccurate diagnoses. This paper introduces a method for lossless medical image retrieval from encrypted images stored on third-party clouds. The proposed approach employs a symmetric integrity-centric image encryption scheme, leveraging multiple chaotic maps and cryptographic hash techniques, to ensure lossless image reconstruction. Medical images are first encrypted by the image owners and converted into hashcodes encapsulating essential features using a deep hashing technique with the ConvNeXt network as the backbone in parallel. To ensure index privacy, these hashcodes are encrypted in a searchable manner. The encrypted medical images, along with a secure index, are subsequently uploaded to cloud storage. Authorized medical image users can request similar medical images for diagnostic purposes by submitting a query image, from which a search trapdoor is generated and sent to the cloud. The retrieval process involves a secure similar image search over the encrypted indexes, followed by decryption along with integrity verification of the retrieved images. The proposed method has been rigorously tested on three standard medical datasets, demonstrating an improvement of 5-20{\%} in retrieval accuracy compared to standard baselines. Formal security analysis and experimental results indicate that the proposed scheme offers enhanced security and retrieval accuracy, making it an effective solution for the encrypted storage and secure retrieval of medical image data.",Springer
"Ben Ammar, Boulbaba and Salem, Ali and Ben Said, Mouna and Ben Aouicha, Mohamed",Machine Learning Models for Early Prediction of COVID-19 Infections Based on Clinical Signs,2024,10.1007/s42979-023-02489-3,https://doi.org/10.1007/s42979-023-02489-3,Journal,SN Computer Science,"Nowadays, the appearance of common symptoms, such as cough, fever, and loss of smell and taste, is the starting point of a battle against the coronavirus. The first standard method of COVID-19 infection assertion has become the RT-PCR test, which is however an uncomfortable solution for both patients and medical staff due to its high cost, timeliness, and false-negative result issue. This has raised the need for reliable automatic detection systems that aid in the early prediction of the COVID-19 infections with a lower cost. In this work, we aim at profiting from the Machine Learning (ML) advances to provide a reliable and low-cost COVID-19 prediction system. This system is based on the disease starting point, which is the patients' clinical symptoms, that are still under-explored. We developed seven predictive models using traditional ML classification algorithms using a public dataset of obvious high-risk factors from patients' clinical signs. The dataset has first undergone a pre-processing phase consisting of feature engineering and dataset resampling to deal with imbalanced dataset issue. Our best classification model is able to detect true positives and true negatives and weed out false positive and false negatives with an accuracy of 93{\%}.",Springer
"Sartaj, Hassan and Ali, Shaukat and Marie Gj{\o}by, Julie",Uncertainty-aware environment simulation of medical devices digital twins,2024,10.1007/s10270-024-01223-8,https://doi.org/10.1007/s10270-024-01223-8,Journal,Software and Systems Modeling,"Smart medical devices are an integral component of the healthcare Internet of Things (IoT), providing patients with various healthcare services through an IoT-based application. Ensuring the dependability of such applications through system and integration-level testing mandates the physical integration of numerous medical devices, which is costly and impractical. In this context, digital twins of medical devices play an essential role in facilitating testing automation. Testing with digital twins without accounting for uncertain environmental factors of medical devices leaves many functionalities of IoT-based healthcare applications untested. In addition, digital twins operating without environmental factors remain out of sync and uncalibrated with their corresponding devices functioning in the real environment. To deal with these challenges, in this paper, we propose a model-based approach (EnvDT) for modeling and simulating the environment of medical devices' digital twins under uncertainties. We empirically evaluate the EnvDT using three medicine dispensers, Karie, Medido, and Pilly connected to a real-world IoT-based healthcare application. Our evaluation targets analyzing the coverage of environment models and the diversity of uncertain scenarios generated for digital twins. Results show that EnvDT achieves approximately 61{\%} coverage of environment models and generates diverse uncertain scenarios (with a near-maximum diversity value of 0.62) during multiple environmental simulations.",Springer
"Tamilselvi, P.",Blockchain Chain Based Cloud Security Using Provable Partitioned Folding Encryption for Integrity Proofing in Cloud Environment,2024,10.1007/s42979-024-03487-9,https://doi.org/10.1007/s42979-024-03487-9,Journal,SN Computer Science,"In current existences there has been an increase in concentration in the potential of blockchain (BC) technology to transform multiple industries, including cloud security. This study delves into the combination of BC technology and cloud security to improve data protection, authentication, and access control. The unchangeable and decentralized nature of BC suggestions a strong foundation for safeguarding cloud-based systems, reducing the vulnerabilities linked to centralized storage and single points of failure. This research investigates the fundamental principles and mechanisms of blockchain-based cloud security, such as encryption, access control, smart contracts, and disseminated mechanism. The employment of BC technology to safeguard data and transactions in cloud-based environments is referred to as blockchain security in cloud computing (CC). To defend the veracity and security of data stored in the cloud, encryption and decentralised consensus processes are used.The cloud provides decentralized service and communication all over the world through internet services. By increasing open service accessibility and sharing, the personalized information and sensitive data get unauthorized access leads security breaches, data leakage due to improves security concerns. So the security in the sense, the privacy preservation based security is an important concern to protect the sensitive data from unauthorized access. Most existing security failed in cryptographic approaches doe to key leakages and authenticity failures. To resolve this problem we provide a consensus proof of work based block chain principle (CPoW-BCP) based on provable partitioned encryption is implemented to secure the cloud environment in this research demystifying cryptographic hash function (DCHF) is applied to create portioned data block to make encryption using provable partitioned folding encryption (PPFE). With the support of post quantum chain links (PQCL) the block are stamped with randomized key policy and the hash key is updated to master node. Then master integrity proofing authentication (MIPA) verifies the user accessibility to securely handover the data. Finally the integrity proofing verification is carried out by lattice key role verification policy (LKRVP) to ensure the security to handover the data at peer end. Such the system prove the higher security to make verification and authentication to enrich the integrity on security in cloud environment. By comparing the existing system, the proposed proves higher security standard in cloud Computing and privacy standard levels. The findings suggest that block chain-based cloud security offers a promising solution for addressing the evolving threats and vulnerabilities in cloud environments, tiling the path for a further secure and resilient infrastructure.",Springer
"F{\""a}hndrich, Johannes and Povalej, Roman and Rittelmeier, Heiko and Berner, Silvio","Interview: AI Expert Prof. M{\""u}ller on XAI",2022,10.1007/s13218-022-00776-4,https://doi.org/10.1007/s13218-022-00776-4,Journal,"KI - K{\""u}nstliche Intelligenz",,Springer
"Kiwit, Florian J. and Wolf, Maximilian A. and Marso, Marwa and Ross, Philipp and Lorenz, Jeanette M. and Riofr{\'i}o, Carlos A. and Luckow, Andre",Benchmarking Quantum Generative Learning: A Study on Scalability and Noise Resilience using QUARK,2024,10.1007/s13218-024-00864-7,https://doi.org/10.1007/s13218-024-00864-7,Journal,"KI - K{\""u}nstliche Intelligenz","Quantum computing promises a disruptive impact on machine learning algorithms, taking advantage of the exponentially large Hilbert space available. However, it is not clear how to scale quantum machine learning (QML) to industrial-level applications. This paper investigates the scalability and noise resilience of quantum generative learning applications. We consider the training performance in the presence of statistical noise due to finite-shot noise statistics and quantum noise due to decoherence to analyze the scalability of QML methods. We employ rigorous benchmarking techniques to track progress and identify challenges in scaling QML algorithms, and show how characterization of QML systems can be accelerated, simplified, and made reproducible when the QUARK framework is used. We show that QGANs are not as affected by the curse of dimensionality as QCBMs and to which extent QCBMs are resilient to noise.",Springer
"Gallego, {\'A}ngel J. and Or{\'u}s, Rom{\'a}n",Language Design as Information Renormalization,2022,10.1007/s42979-021-01002-y,https://doi.org/10.1007/s42979-021-01002-y,Journal,SN Computer Science,"Here we consider some well-known facts in syntax from a physics perspective, allowing us to establish analogies between both fields with many consequences. Mainly, we observe that the operation MERGE, put forward by Chomsky (in: Evolution and Revolution in Linguistic Theory, Essays in honor of Carlos Otero., eds. Hector Campos and Paula Kempchinsky, 1995), can be interpreted as a physical information coarse-graining. Thus, MERGE in linguistics entails information renormalization in physics, according to different time scales. We make this point mathematically formal in terms of statistical language models. In this setting, MERGE amounts to a probability tensor implementing a coarse-graining, akin to a probabilistic context-free grammar. The probability vectors of meaningful sentences are given by stochastic tensor networks (TN) built from diagonal tensors and which are mostly loop-free, such as Tree Tensor Networks and Matrix Product States, thus being computationally very efficient to manipulate. We show that this implies the polynomially-decaying (long-range) correlations experimentally observed in language, and also provides arguments in favour of certain types of neural networks for language processing. Moreover, we show how to obtain such language models from quantum states that can be efficiently prepared on a quantum computer, and use this to find bounds on the perplexity of the probability distribution of words in a sentence. Implications of our results are discussed across several ambits.",Springer
{Editorial Board},Guest Editorial Special Issue: ``Emerging Trends in Advanced Computing and Next-Generation Technologies'',2024,10.1134/S0361768824700610,https://doi.org/10.1134/S0361768824700610,Journal,Programming and Computer Software,,Springer
"Mukesh, K. and Jayaprakash, S. L. and Kumar, R. Prasanna",QViLa: Quantum Infused Vision-Language Model for Enhanced Multimodal Understanding,2024,10.1007/s42979-024-03398-9,https://doi.org/10.1007/s42979-024-03398-9,Journal,SN Computer Science,"Vision-language models have emerged as transformative tools, revolutionizing the integration of visual and textual information, forging pathways for nuanced interpretations across various applications. The evolution of these models underscores the challenge of achieving seamless modality fusion, particularly in aligning raw pixel values of images with high-level semantics of text, a bottleneck that often hinders optimal cross-modal representations. Addressing this, our research introduces a quantum-enhanced multimodal framework. The main objective of our proposed work is the integration of classical vision-language transformers with quantum-augmented layer, aimed at enhancing the fusion of extracted feature embeddings, thereby bridging the modality gap. The quantum computing techniques, offers an innovative approach to information processing, which paves the way for richer and more intricate visual-textual representations. Furthermore, the shared self-attention mechanism accentuates the model's ability to detect complex modality interactions. The quantum-enhanced framework is empirically evaluated on the VQA v2 dataset. This evaluation not only considers accuracy across diverse question categories but also the model's computational efficiency, emphasizing the pivotal contributions of quantum computations in achieving heightened accuracy levels. Further exploration into the influence of different quantum feature maps aided in identifying the most optimal model variant. Our findings highlight the quantum layer's pivotal role in improving the efficacy of classical vision language models.",Springer
"Yifeng, Chen and Sanders, J. W.",A modal approach to conscious social agents,2023,10.1007/s10009-023-00732-z,https://doi.org/10.1007/s10009-023-00732-z,Journal,International Journal on Software Tools for Technology Transfer,"An agent's awareness has previously been modelled as a modal operator in such a way that awareness can be iterated, and consciousness formalised as awareness of awareness. Agents are not necessarily human and may a priori be other animals, organisations or software. In that generality awareness is presumed to exist in degrees, and so the expected Boolean model of agent awareness has been augmented with a numerical one. The context is an adaptive multi-agent system in which agents, individually and in groups, control actions and adapt. So far the approach has been developed for individual agents only.",Springer
"Kaveri, Parag Ravikant and Lahande, Prathamesh",Reinforcement Learning to Improve Resource Scheduling and Load Balancing in Cloud Computing,2023,10.1007/s42979-022-01609-9,https://doi.org/10.1007/s42979-022-01609-9,Journal,SN Computer Science,"Cloud computing provides various services to the end-user by processing a high number of tasks using the Internet. The end-user submits this high number of tasks to the cloud for execution. The cloud processes and executes these tasks on the cloud Virtual Machines (VM) using resource scheduling algorithms and performing load-balancing mechanisms. The cloud performance is directly proportional to how the resources are scheduled and how the load is managed. With proper resource scheduling and load balancing, the cloud performance is enhanced, and it can execute a more significant number of tasks. Similarly, the cloud performance is hampered by poor resource scheduling as well as load misbalancing. Therefore, it becomes essential for the cloud to schedule its resources and manage its load in an appropriate way to provide proper Quality of Service (QoS) without any infractions in the Service Level Agreements (SLA). With static resource scheduling, managing the resources and balancing the load becomes challenging while executing tasks, especially when the cloud system has been given no intelligence. Resource scheduling and load balancing become complex without any intelligence to keep a smooth flow of task execution, irrespective of the task load. The main objective of this research paper is to study and compare the behavior of resource scheduling algorithms by executing tasks of different loads under different scenarios and circumstances. This research paper is broadly divided into three phases: the first phase includes a simulation experiment conducted on the WorkflowSim environment where tasks are processed and executed on VMs in four different scenarios and circumstances; the second phase includes a detailed empirical analysis of the results obtained from the experiment conducted in the first phase using the mathematical model of Linear Regression and R2 analysis; the last part proposes reinforcement learning (RL) to provide intelligence and improve the resource scheduling and load-balancing mechanisms in the cloud computing environment.",Springer
"Venkataraman, Ramanathan and Yerchuru, Srinivasa Kumar",Future of financial technology---a perspective,2021,10.1007/s40012-021-00341-8,https://doi.org/10.1007/s40012-021-00341-8,Journal,CSI Transactions on ICT,"We live in 'Exponential Times' powered by Technology. Banking, Financial Services {\&} Insurance are at the epicenter of all the activities and have an unique place to witness as well as shape the Growth and Transformation of all industries. This paper analyses and provides a perspective of the changing context in which the Financial Industry is being shaped by the convergence of ecosystems, technology, evolving customer preferences and ongoing new age competition from Fintechs.",Springer
"Kryukov, A. P. and Demichev, A. P. and Polyakov, S. P.",Web platforms for scientific research,2016,10.1134/S036176881603004X,https://doi.org/10.1134/S036176881603004X,Journal,Programming and Computer Software,"This paper considers current trends in creating systems for convenient and secure remote submission (by authorized users) of jobs to computing resources of different types, including supercomputers, clusters, cloud resources, storages, databases, and grid infrastructures. Presently, large computing and storage resources are capable of solving, on their own, the majority of practical problems in the field of science and technology. Therefore, the focus in developing next-generation middleware shifts from global grid systems towards creating convenient and efficient means of access to large individual resources. A web platform for remote access to computing resources is a set of special web services and application-oriented web interfaces. Such web platforms, on a centralized basis, provide users with a number of services interrelated by a specific application area, principle of access, and interface. In this paper, general principles of creating such platforms are considered and some particular implementations of web platforms are briefly described.",Springer
"Haque, Md Alimul and Ahmad, Sultan and John, Alok and Mishra, Khushboo and Mishra, Binay Kumar and Kumar, Kailash and Nazeer, Jabeen",Cybersecurity in Universities: An Evaluation Model,2023,10.1007/s42979-023-01984-x,https://doi.org/10.1007/s42979-023-01984-x,Journal,SN Computer Science,"Cybercriminals have been increasingly targeting higher education institutions during the COVID-19 pandemic. The shift to online learning and remote work has created new opportunities for cybercriminals to exploit vulnerabilities in university networks and systems. This paper highlights the challenges faced by universities in ensuring the security of their information systems and employee data and the potential consequences of cyberattacks. The objective of this study is to conduct a comprehensive assessment of the cybersecurity situation in university facilities by identifying, quantifying, and modeling it. The resulting model will enable educational institutions to recognize potential operational risks and determine which measures to implement or improve to mitigate those risks. Consequently, we will create a novel assessment tool in this study to offer universities a precise representation of their current status, aiding university designers in incorporating the recommended cyber risk mitigation measures into the system design before deployment.",Springer
"Nramban Kannan, Senthil Kumar and Kolla, Bhanu Prakash and Sengan, Sudhakar and Muthusamy, Rajendiran  and Manikandan, Raja and Patel, Kanubhai K. and Dadheech, Pankaj",Analysis of COVID-19 Datasets Using Statistical Modelling and Machine Learning Techniques to Predict the Disease,2024,10.1007/s42979-023-02464-y,https://doi.org/10.1007/s42979-023-02464-y,Journal,SN Computer Science,"Sustainable development is crucial for a prosperous future, but epidemic diseases like Coronavirus Disease 2019 (COVID-19) pose real and complex challenges. The global pandemic, declared by the WHO on March 11, 2020, has led to significant loss of life and challenges in public health, economy, food systems, and social life. This research article aims to develop a Machine Learning (ML) model to predict a patient's COVID-19 diagnosis, as early diagnosis is fundamental for controlling the spread of COVID-19. An investigation of the literature and a research study is conducted to find suitable mathematical methods and measure how they impact prediction models. This paper analyses COVID-19 pandemic deaths, confirmed cases, and recovered individuals using Time Series Analysis (TSA) to study the disease's impacts and understand the TAS. A forecasting model can predict future COVID cases by analyzing trends in time-series and connecting global changes with government restrictions. Since higher predictive accuracy is the limitation of ensemble learning algorithms, better ML approaches are proposed here. Autocorrelation plots clearly showed the results executed for the considered objectives. The hybrid ARIMA algorithm proposed in this work proved adequate results.",Springer
"Voevodin, Vl. V. and Popova, N. N.",Infrastructure of Supercomputing Technologies,2019,10.1134/S0361768819030071,https://doi.org/10.1134/S0361768819030071,Journal,Programming and Computer Software,"Supercomputing technologies have a lot of aspects, and, speaking of their serious support at the state level, it is necessary to create and develop all elements of a supercomputing infrastructure, not focusing only on its individual components. In this paper, we discuss all basic elements of this infrastructure and illustrate the extreme demand for it in Russia, where only the list of tasks published by the Ministry of Education and Science of the Russian Federation contains more than 700 problems that require supercomputing resources for their solution. Many researchers have worked in this field; however, in this paper, we overview only the results achieved by some prominent Russian scientists from the Moscow State University, to which M.R. Shura-Bura devoted a significant part of his life.",Springer
"Aikawa, Yuri and Ueda, Naonori and Tanaka, Toshiyuki",Improving the Efficiency of Training Physics-Informed Neural Networks Using Active Learning,2024,10.1007/s00354-024-00253-6,https://doi.org/10.1007/s00354-024-00253-6,Journal,New Generation Computing,"PINN, or physics-informed neural network, is a partial differential equation (PDE) solver realized as a neural network by incorporating the target PDE into the network as physical constraints. In this study, our focus lies in optimizing collocation point selection. We propose an active learning method to enhance the efficiency of PINN learning. The proposed method leverages variational inference based on dropout learning to assess the uncertainty inherent in the solution estimates provided by the PINN. Subsequently, it formulates an acquisition function for active learning grounded in this uncertainty assessment. By employing this acquisition function to probabilistically select collocation points, we can achieve a more expedited convergence to a reasonable solution, as opposed to relying on random sampling. The efficacy of our approach is empirically demonstrated using both Burgers' equation and the convection equation. We also show experimentally that the choice of the collocation points can affect the loss function, the fitting of initial and boundary conditions, and the sensible balance of PDE constraints.",Springer
"Kumar, Ravin",A Generalized Quantum Algorithm for Assuring Fairness in Random Selection Among 2N Participants,2020,10.1007/s42979-020-0091-z,https://doi.org/10.1007/s42979-020-0091-z,Journal,SN Computer Science,"Quantum computing promises to provide a tremendous boost to the computational power of our machines by utilizing superposition and entanglement phenomenon of quantum mechanics. Few quantum algorithms are known which are taking advantage of these quantum phenomena and are providing solutions to problems having significant importance. In this paper, we have proposed a generalized method for designing 2N qubits circuit such that during measurement only one qubit will be in state-1, while remaining other qubits will hold state-0. Apart from adding fair randomness to the selection process in distributed quantum computing, these generalized quantum circuits can be found very useful in commercial domains requiring transparency and trust in systems requiring fair randomness in decision-making such as in a lottery system. The critical advantage of using our proposed method is that it allows individual's results to be teleported to them, hence making an end-to-end system whose fairness is quantum assured.",Springer
"Jiang, Hui and Fu, Jianling and Deng, Yuxin and Wu, Jun",A binary integer programming-based method for qubit mapping in sparse architectures,2024,10.1007/s00236-024-00471-x,https://doi.org/10.1007/s00236-024-00471-x,Journal,Acta Informatica,"It is a current trend of sparse architectures employed for superconducting quantum chips, which have the advantage of low coupling and crosstalk properties. Existing qubit mapping algorithms do not take the sparsity of quantum architectures into account. To this end, we propose a qubit mapping method based on binary integer programming, called QMBIP. First, we slice a given quantum circuit by taking into account the sparsity of target architectures. Then, the constraints and the objective function are formulated and rendered to the binary integer programming problem by matrix transformation. The behavior of a {\$}{\$}{\backslash}textbf{\{}SWAP{\}}{\$}{\$}gate is characterized by an elementary row transformation on the mapping matrix between the physical and logical qubits. To reduce the search space, we introduce path variables and isomorphic pruning, as well as a look-ahead mechanism. Finally, we compare with typical qubit mapping algorithms such as SABRE and SATMAP on the sparse architectures ibmq{\_}sydney, ibmq{\_}manhattan, ibmq{\_}singapore, and a dense architecture ibmq{\_}tokyo. Experiments show that QMBIP effectively maintains the fidelity of the compiled quantum circuits. For example, on ibmq{\_}sydney, the fidelity of the quantum circuits compiled by our approach outperforms SABRE and SATMAP by 53.9{\%} and 46.8{\%}, respectively.",Springer
"Ottaviano, Alessandro and Balas, Robert and Bambini, Giovanni and Del Vecchio, Antonio and Ciani, Maicol and Rossi, Davide and Benini, Luca and Bartolini, Andrea",ControlPULP: A RISC-V On-Chip Parallel Power Controller for Many-Core HPC Processors with FPGA-Based Hardware-In-The-Loop Power and Thermal Emulation,2024,10.1007/s10766-024-00761-4,https://doi.org/10.1007/s10766-024-00761-4,Journal,International Journal of Parallel Programming,"High-performance computing (HPC) processors are nowadays integrated cyber-physical systems demanding complex and high-bandwidth closed-loop power and thermal control strategies. To efficiently satisfy real-time multi-input multi-output (MIMO) optimal power requirements, high-end processors integrate an on-die power controller system (PCS). While traditional PCSs are based on a simple microcontroller (MCU)-class core, more scalable and flexible PCS architectures are required to support advanced MIMO control algorithms for managing the ever-increasing number of cores, power states, and process, voltage, and temperature variability. This paper presents ControlPULP, an open-source, HW/SW RISC-V parallel PCS platform consisting of a single-core MCU with fast interrupt handling coupled with a scalable multi-core programmable cluster accelerator and a specialized DMA engine for the parallel acceleration of real-time power management policies. ControlPULP relies on FreeRTOS to schedule a reactive power control firmware (PCF) application layer. We demonstrate ControlPULP in a power management use-case targeting a next-generation 72-core HPC processor. We first show that the multi-core cluster accelerates the PCF, achieving 4.9x speedup compared to single-core execution, enabling more advanced power management algorithms within the control hyper-period at a shallow area overhead, about 0.1{\%} the area of a modern HPC CPU die. We then assess the PCS and PCF by designing an FPGA-based, closed-loop emulation framework that leverages the heterogeneous SoCs paradigm, achieving DVFS tracking with a mean deviation within 3{\%} the plant's thermal design power (TDP) against a software-equivalent model-in-the-loop approach. Finally, we show that the proposed PCF compares favorably with an industry-grade control algorithm under computational-intensive workloads.",Springer
"Yue, Tao and Abrah{\~a}o, Silvia and Zhang, Man",Guest editorial to the special section of models 2019,2021,10.1007/s10270-021-00939-1,https://doi.org/10.1007/s10270-021-00939-1,Journal,Software and Systems Modeling,,Springer
"Lin, Bing and Lin, Kai and Lin, Changhang and Lu, Yu and Huang, Ziqing and Chen, Xinwei",Computation offloading strategy based on deep reinforcement learning for connected and autonomous vehicle in vehicular edge computing,2021,10.1186/s13677-021-00246-6,https://doi.org/10.1186/s13677-021-00246-6,Journal,Journal of Cloud Computing,"Connected and Automated Vehicle (CAV) is a transformative technology that has great potential to improve urban traffic and driving safety. Electric Vehicle (EV) is becoming the key subject of next-generation CAVs by virtue of its advantages in energy saving. Due to the limited endurance and computing capacity of EVs, it is challenging to meet the surging demand for computing-intensive and delay-sensitive in-vehicle intelligent applications. Therefore, computation offloading has been employed to extend a single vehicle's computing capacity. Although various offloading strategies have been proposed to achieve good computing performace in the Vehicular Edge Computing (VEC) environment, it remains challenging to jointly optimize the offloading failure rate and the total energy consumption of the offloading process. To address this challenge, in this paper, we establish a computation offloading model based on Markov Decision Process (MDP), taking into consideration task dependencies, vehicle mobility, and different computing resources for task offloading. We then design a computation offloading strategy based on deep reinforcement learning, and leverage the Deep Q-Network based on Simulated Annealing (SA-DQN) algorithm to optimize the joint objectives. Experimental results show that the proposed strategy effectively reduces the offloading failure rate and the total energy consumption for application offloading.",Springer
"Shabanov, B. M. and Samovarov, O. I.",Building the Software-Defined Data Center,2019,10.1134/S0361768819080048,https://doi.org/10.1134/S0361768819080048,Journal,Programming and Computer Software,"Data center is the most effective way of providing computational resources to a large number of users. The software-defined model is a modern approach to the creation of the computing infrastructure for the data center, which allows user tasks to be processed in acceptable time and at acceptable cost. This paper formulates the general design requirements for the interagency data center and describes some problems and methods of planning and building software-defined data centers (deployment of computing systems optimized for maximum hardware utilization, software support for different classes of tasks, etc.).",Springer
"Kanadath, Anusree and Jothi, J. Angel Arul and Urolagin, Siddhaling",Multilevel Colonoscopy Histopathology Image Segmentation Using Particle Swarm Optimization Techniques,2023,10.1007/s42979-023-01915-w,https://doi.org/10.1007/s42979-023-01915-w,Journal,SN Computer Science,"Histopathology image segmentation is a challenging task in medical image processing. This work aims to segment lesion regions from colonoscopy histopathology images. Initially, the images are preprocessed and then segmented using the multilevel image thresholding technique. Multilevel thresholding is considered an optimization problem. Particle swarm optimization (PSO) and its variants, darwinian particle swarm optimization (DPSO), and fractional order darwinian particle swarm optimization (FODPSO) are used to solve the optimization problem and they generate the threshold values. The threshold values obtained are used to segment the lesion regions from the images of the colonoscopy tissue data set. Segmented images containing the lesion regions are then postprocessed to remove unnecessary regions. Experimental results reveal that the FODPSO algorithm with Otsu's discriminant criterion as the objective function achieves the best accuracy, Dice and Jaccard values of 0.89, 0.68 and 0.52, respectively, for the colonoscopy data set. The FODPSO algorithm also outperforms other optimization methods such as artificial bee colony and the firefly algorithms in terms of the accuracy, Dice and Jaccard values.",Springer
"Geetha, J. Sai",Adaptive Artificial Bee Colony Algorithm-Based Enhancement of Data Security in Cloud Computing,2023,10.1007/s42979-023-02419-3,https://doi.org/10.1007/s42979-023-02419-3,Journal,SN Computer Science,"Nowadays, the usage of network has been increased due to cloud computing. It is used in many applications because of its salient features such as reduced cost, hassle-free usage without the requirement of client--server model. The networked resources of cloud computing environment support the data storage in remote server. It has been used in more applications particularly in resource utilization and data sharing. The fundamental functions of security and user authentication must be improved for cloud computing to operate more efficiently. The above tasks should be achieved through the Artificial Bee Colony with split encryption process and biometric authentication. The biometric authentication is utilized to improve the user authentication in public cloud environment. In addition, the method of split encryption process in Artificial Bee Colony algorithm helps to improve the data security. The proposed methodology, namely biometric-based split encryption (BSE) accomplishes two main goals: (i) enhancement of security and (ii) user authentication. The split encryption process with ABC algorithm is applied to the sensitive data and also combined with the finger impression of the authenticated user. To prevent unwanted access to encrypted data, the resulting data and the biometric authentication should be kept distinct in the cloud storage area and verified before decrypting the original data. The execution time, which includes encryption and decryption, as well as memory usage, are used to gauge the effectiveness of the biometric-based split encryption (BSE). The results of BSE algorithm are compared with the emperor penguin optimization (EPO) with Elliptic curve cryptography.",Springer
"Kornyak, V. V.",Complementarity in Finite Quantum Mechanics and Computer-Aided Computations of Complementary Observables,2023,10.1134/S036176882302010X,https://doi.org/10.1134/S036176882302010X,Journal,Programming and Computer Software,"Mathematical formulation of Bohr's complementarity principle leads to the concepts of mutually unbiased bases in Hilbert spaces and complementary quantum observables. In this paper, we consider algebraic structures associated with these concepts and their applications to constructive quantum mechanics. We also briefly discuss some computer-algebraic approaches to the problems under consideration and propose an algorithm for solving one of them.",Springer
"Pandey, Anuj Kumar and Singh, Satya Prakash and Chakraborty, Chinmay",Residual attention UNet GAN Model for enhancing the intelligent agents in retinal image analysis,2024,10.1007/s11761-024-00415-w,https://doi.org/10.1007/s11761-024-00415-w,Journal,Service Oriented Computing and Applications,"A unique method for improving the intelligent agents in retinal image processing is the proposed RAUGAN (Residual Attention UNet GAN) model. Reliability, accuracy, and delineation of retinal vessels are improved by RAUGAN, which incorporates residual attention mechanisms into the model through the use of Generative Adversarial Networks (GANs) and UNet architecture ideas. The model successfully segments retinal arteries from complicated backgrounds with a mean Intersection over Union (IOU) score of 0.915, which is impressive. Traditional approaches to segmenting the retinal images were not fully automated and hence required hours of labor of domain experts in annotation tasks. Yet other challenges were the accuracy in the previous studies. Incorporating residual attention modules allows the network to focus on salient regions while preserving contextual information, contributing to the model's superior performance. A semantic web is to offer a formalism that supports it and offers a consensus for defining structure and semantics. The Semantic Web, which gives information a clear meaning and improves human--computer collaboration, is an extension of the existing Web rather than a separate one. The experimental findings show that RAUGAN has the potential to be a reliable and accurate tool for segmenting retinal vessels in medical picture analysis.",Springer
"Tang, Yehui and Yan, Junchi and Hu, Guoqiang and Zhang, Baohua and Zhou, Jinzan",Recent progress and perspectives on quantum computing for finance,2022,10.1007/s11761-022-00351-7,https://doi.org/10.1007/s11761-022-00351-7,Journal,Service Oriented Computing and Applications,,Springer
"Sargsyan, R. and Sahakyan, R. and Gazazyan, E. and Sargsyan, Sh. and Sargsyan, S. and Astsatryan, H.",Evaluation of Differential Equation Solutions through Traditional Techniques and Neural Networks in Quantum Simulations,2024,10.1134/S0361768824700452,https://doi.org/10.1134/S0361768824700452,Journal,Programming and Computer Software,"The study presents a comparative analysis of algorithms of traditional numerical methods and methods using neural networks for solving ordinary differential equations. The evaluation includes both mathematical aspects and aspects of machine learning. Using the Julia programming language, neural networks and the necessary algorithms for conducting practical experiments are implemented. These experiments demonstrate outstanding achievements in the field of quantum computing. Moreover, comparing the efficiency metrics of solving differential equations using numerical methods and neural networks reveals interesting results, depending on the chosen architecture and network parameters.",Springer
"Harper, Robin","Introducing Design Automation for Quantum Computing, Alwin Zulehner and Robert Wille. ISBN 978-3-030-41753-6, 2020, Springer International Publishing. 222 Pages, 51 b/w illustrations, 14 illustrations in colour",2021,10.1007/s10710-021-09407-7,https://doi.org/10.1007/s10710-021-09407-7,Journal,Genetic Programming and Evolvable Machines,,Springer
"Langdon, W. B.",Genetic programming and evolvable machines at 20,2020,10.1007/s10710-019-09344-6,https://doi.org/10.1007/s10710-019-09344-6,Journal,Genetic Programming and Evolvable Machines,"The journal and in particular the resource reviews have been running for 20 years. We summarise the GP literature, including top papers and authors, as seen by users of the genetic programming bibliography. Then revisit our original goals for GPEM book reviews and compare them with what has achieved.",Springer
"Minin, P. V.",Unified Processing of Events and Co-routines in Embedded Program,2024,10.1134/S0361768824700154,https://doi.org/10.1134/S0361768824700154,Journal,Programming and Computer Software,"A new architectural approach to real-time embedded programming is described. A bare-metal program is written in C/C++ and combines event-driven technique with concurrency based on co-routines. Events are processed by soft real-time core at the priority level of software generated interrupts. Event is first posted to input queue of the core and then processed by invocation of its event handler. A special case of event is co-routine, its resumable function being a co-routine event handler. The co-routine that either yielded or needs to be resumed is queued for event processing once again. As a result, it is processed multiple times until execution of resumable function comes to the end of its operator sequence. Different levels of processing priority may be assigned to an event. Soft real-time core could be further expanded to run on symmetrical multiprocessor hardware. A combination of co-routines and basic events could easily be used in fork/join model. Concurrency constructs resemble those of Go and occam languages. Virtually all classic types of synchronization primitives could be implemented. The new approach was implemented for various ARM and Blackfin processors in C++ language as portable DORSECC library. This library was further used to program real-time embedded systems for mass-produced banknote sorting machines. One type of systems was used to recognize and validate banknote images by the method of cascade of one-class classifiers. The other system worked as a motion controller and used finite automata to control sensors and actuators. The total number of systems in operation is currently over 20000. The event and co-routine core in these systems provides average event processing time in the range of dozens of microseconds with sub-microsecond overhead time per each event.",Springer
"Cho, Kenta",Semantics for a Quantum Programming Language by Operator Algebras,2016,10.1007/s00354-016-0204-3,https://doi.org/10.1007/s00354-016-0204-3,Journal,New Generation Computing,"This paper presents a novel semantics for a quantum programming language by operator algebras, which are known to give a formulation for quantum theory that is alternative to the one by Hilbert spaces. We show that the opposite of the category of W*-algebras and normal completely positive subunital maps is an elementary quantum flow chart category in the sense of Selinger. As a consequence, it gives a denotational semantics for Selinger's first-order functional quantum programming language. The use of operator algebras allows us to accommodate infinite structures and to handle classical and quantum computations in a unified way.",Springer
"Piattini, Mario and Garc{\'i}a-Rodr{\'i}guez de Guzm{\'a}n, Ignacio and P{\'e}rez-Castillo, Ricardo",Special issue on quality management for information systems,2020,10.1007/s11219-020-09516-z,https://doi.org/10.1007/s11219-020-09516-z,Journal,Software Quality Journal,,Springer
"Malviya, Anjali and Dixit, Rahul and Shukla, Anupam and Kushwaha, Nagendra",Long Short-Term Memory-based Deep Learning Model for COVID-19 Detection using Coughing Sound,2023,10.1007/s42979-023-01934-7,https://doi.org/10.1007/s42979-023-01934-7,Journal,SN Computer Science,"The sudden spike in Coronavirus disease 2019 (COVID-19) cases reported by China recently suggests the possible threat of the pandemic's resurgence. Due to the extremely contagious nature of the virus COVID-19 has already made its presence felt in countries all over the world, since it was reported first in 2019. The delay in detection of the infection resulted in daunting figures of infected patients and over six million fatal casualties have been reported to date. Necessitated by the urgent need for early detection of the disease to contain its spread, and the cost and time implication of the existing testing options, researchers have tried to provide AI-based systems which majorly exploit chest X-ray and Computed Tomography (CT) scan images. Our work explores the possibility of a real-time non-invasive screening tool for early detection of the disease through audio data like cough, resulting from respiratory tract infection which is an early symptom of COVID-19. In this paper, we have proposed a Long Short-Term Memory (LSTM)-based Deep Learning approach for the detection of COVID-19, using the Pfizer Digital Medicine Challenge dataset which contains audio signals of sneezing, coughing, and breath, classified as sick or not sick. Our proposed model obtained a training accuracy of 96.74{\%} with a binary cross-entropy loss of 8.04{\%}. The experimental results show an accuracy of 96.24{\%} which is significantly higher than the previous study on the same dataset which resulted in an accuracy of 80.26{\%}, suggesting that the proposed model is better in terms of classification efficiency.",Springer
"Ludwig, Simone A.","Anthony Brabazon, Michael O'Neill, Sean McGarraghy: Natural computing algorithms",2016,10.1007/s10710-016-9266-8,https://doi.org/10.1007/s10710-016-9266-8,Journal,Genetic Programming and Evolvable Machines,,Springer
"Alornyo, Seth",Quantum-secure plaintext checkable signcryption,2023,10.1007/s42044-022-00119-4,https://doi.org/10.1007/s42044-022-00119-4,Journal,Iran Journal of Computer Science,"A public plaintext query on a ciphertext using plaintext checkable encryption is a cryptographic primitive studied extensively to promote the search on ciphertext using a plaintext keywords or phrase. Most existing schemes are vulnerable to an adversary with quantum computers. In this paper, we propose quantum-secure plaintext checkable signcryption in a lattice environment. Our scheme is post-quantum secure and achieves the dual benefits of digital signature and public key encryption. Learning with errors cryptographic primitive ensures the attainment of this goal. We achieve a desirable security feature of existential unforgeable chosen message attack using the random oracle model.",Springer
"Ramezani, Fahimeh and Lu, Jie and Hussain, Farookh Khadeer",Task-Based System Load Balancing in Cloud Computing Using Particle Swarm Optimization,2014,10.1007/s10766-013-0275-4,https://doi.org/10.1007/s10766-013-0275-4,Journal,International Journal of Parallel Programming,"Live virtual machine (VM) migration is a technique for achieving system load balancing in a cloud environment by transferring an active VM from one physical host to another. This technique has been proposed to reduce the downtime for migrating overloaded VMs, but it is still time- and cost-consuming, and a large amount of memory is involved in the migration process. To overcome these drawbacks, we propose a Task-based System Load Balancing method using Particle Swarm Optimization (TBSLB-PSO) that achieves system load balancing by only transferring extra tasks from an overloaded VM instead of migrating the entire overloaded VM. We also design an optimization model to migrate these extra tasks to the new host VMs by applying Particle Swarm Optimization (PSO). To evaluate the proposed method, we extend the cloud simulator (Cloudsim) package and use PSO as its task scheduling model. The simulation results show that the proposed TBSLB-PSO method significantly reduces the time taken for the load balancing process compared to traditional load balancing approaches. Furthermore, in our proposed approach the overloaded VMs will not be paused during the migration process, and there is no need to use the VM pre-copy process. Therefore, the TBSLB-PSO method will eliminate VM downtime and the risk of losing the last activity performed by a customer, and will increase the Quality of Service experienced by cloud customers.",Springer
"Tchernykh, Andrei and Ju{\'a}rez Ram{\'i}rez, Reyes and Mocskos, Esteban and Nesmachnow, Sergio",Guest Editorial Special Issue ``Recent Trends on Advanced Computing: The Converging Technologies'',2023,10.1134/S0361768823080285,https://doi.org/10.1134/S0361768823080285,Journal,Programming and Computer Software,,Springer
"Peper, Ferdinand",The End of Moore's Law: Opportunities for Natural Computing?,2017,10.1007/s00354-017-0020-4,https://doi.org/10.1007/s00354-017-0020-4,Journal,New Generation Computing,"The impending end of Moore's Law has started a rethinking of the way computers are built and computation is done. This paper discusses two directions that are currently attracting much attention as future computation paradigms: the merging of logic and memory, and brain-inspired computing. Natural computing has been known for its innovative methods to conduct computation, and as such may play an important role in the shaping of the post-Moore era.",Springer
"Monica, Stefania and Bergenti, Federico and Zambonelli, Franco",A kinetic approach to investigate the collective dynamics of multi-agent systems,2023,10.1007/s10009-023-00724-z,https://doi.org/10.1007/s10009-023-00724-z,Journal,International Journal on Software Tools for Technology Transfer,"When the number of interacting agents in a multi-agent system is large, the detailed study of the dynamics of each agent tends to obfuscate the collective and possibly emergent dynamics of the multi-agent system as a whole. When the interest is on the collective properties of the multi-agent system, a statistical study of the dynamics of the states of the agents can provide a more effective perspective on the system. In particular, a statistical approach can better focus on the long-term asymptotic properties of the studied multi-agent system. The initial part of this paper outlines a framework to approach the study of the collective properties of multi-agent systems. The framework targets large and decentralized multi-agent systems in which the relevant collective properties emerge from interactions. Then, the paper exemplifies the use of the framework to study the long-term asymptotic properties of multi-agent systems in which agents interact using the symmetric gossip algorithm. The state of each agent is represented as a real number, and the use of the framework shows that all agents exponentially converge to the average of their initial states. The analytic results provided by the framework are confirmed by independent multi-agent simulations. Finally, the paper is concluded with a brief discussion of related work and an overview of future extensions.",Springer
"Khan, Naveed and Jianbiao, Zhang and Lim, Huhnkuk and Ali, Jehad and Ullah, Intikhab and Salman Pathan, Muhammad and Chaudhry, Shehzad Ashraf",An ECC-based mutual data access control protocol for next-generation public cloud,2023,10.1186/s13677-023-00464-0,https://doi.org/10.1186/s13677-023-00464-0,Journal,Journal of Cloud Computing,"Through the broad usage of cloud computing and the extensive utilization of next-generation public clouds, people can share valuable information worldwide via a wireless medium. Public cloud computing is used in various domains where thousands of applications are connected and generate numerous amounts of data stored on the cloud servers via an open network channel. However, open transmission is vulnerable to several threats, and its security and privacy are still a big challenge. Some proposed security solutions for protecting next-generation public cloud environments are in the literature. However, these methods may not be suitable for a wide range of applications in a next-generation public cloud environment due to their high computing and communication overheads because if security protocol is strengthened, it inversely impacts performance and vice versa. Furthermore, these security frameworks are vulnerable to several attacks, such as replay, denial-of-service (DoS), insider, server spoofing, and masquerade, and also lack strong user anonymity and privacy protection for the end user. Therefore, this study aims to design an elliptic curve cryptographic (ECC) based data access control protocol for a public cloud environment. The security mechanism of the proposed protocol can be verified using BAN (Burrows-Abadi-Needham) logic and ProVerif 2.03, as well as informally using assumptions and pragmatic illustration. In contrast, in the performance analysis section, we have considered the parameters such as the complexity of storage overheads, communication, and computation time. As per the numerical results obtained in the performance analysis section, the proposed protocol is lightweight, robust, and easily implemented in a practical next-generation cloud computing environment.",Springer
,News,2022,10.1007/s13218-022-00757-7,https://doi.org/10.1007/s13218-022-00757-7,Journal,"KI - K{\""u}nstliche Intelligenz",,Springer
"Prokopenya, A. N.",Simulation of a quantum algorithm for phase estimation,2015,10.1134/S0361768815020061,https://doi.org/10.1134/S0361768815020061,Journal,Programming and Computer Software,"A quantum algorithm for estimating the phase, which determines the eigenvalue of a unitary operator, is discussed. It is assumed that the eigenvector of this operator and the corresponding quantum circuit are given. The memory register where the approximate phase value is stored consists of n qubits, which makes it possible to determine the phase accurate to 2éä½¹åéè¥æ¨éçµ¯ith the probability greater than 8/$\pi$2. By way of example, computations for the case of the quantum phase shift operator are performed. The simulation of the quantum algorithm and the computation of the eigenvalue are performed using the QuantumCircuit package written in the Wolfram Mathematica computer algebra system. This system is also used to perform all the computations and visualize the results.",Springer
"Barzen, Johanna and Leymann, Frank",Quantum humanities: a vision for quantum computing in digital humanities,2020,10.1007/s00450-019-00419-4,https://doi.org/10.1007/s00450-019-00419-4,Journal,SICS Software-Intensive Cyber-Physical Systems,"The establishment of digital humanities as a research field has shown that the use of computers as tools, but also the use of methods and techniques from computer science, can contribute enormously to research done in the humanities. Since quantum computers are expected to become generally available in the next few years, it is promising to use the advantages of this new technology for addressing existing as well as completely new questions in the humanities. The use of quantum computers offers a great deal of potential: (i) they are much faster than classical computers in solving certain complex problems, (ii) solutions may be much more precise, (iii) they allow the solution of problem classes that can hardly been solved on classical computers, and (iv) their usage promises to be much cheaper than that of supercomputers. Parts of this potential are already used in different domains but are also particular promising for digital humanities research. This paper outlines the vision of such quantum humanities.",Springer
"Luo, Yun and Chen, Yuling and Li, Tao and Tan, Chaoyue and Dou, Hui",Cloud-SMPC: two-round multilinear maps secure multiparty computation based on LWE assumption,2024,10.1186/s13677-023-00586-5,https://doi.org/10.1186/s13677-023-00586-5,Journal,Journal of Cloud Computing,"Cloud computing has data leakage from all parties, security protection of private data, and existing solutions do not provide a trade-off between security and overhead. With distributed data communication due to data barriers, information interaction security and data computation security have become challenges for secure computing. Combining cloud computing with secure multiparty computation can provide a higher level of data protection while maintaining the benefits of cloud computing. In this case, data can be stored in the cloud and computed through SMPC protocols, thus protecting the privacy and security of the data. However, multiple rounds of information interaction are often required, increasing the communication overhead, and the security strength is limited by the hardness assumption. In this paper, we work to achieve an optimal setting of the number of rounds in secure multi-party computation on the cloud to achieve a sublinear communication overhead and improve the security concept. A 2-round SMPC protocol is constructed in the framework of Universally Composable (UC). A 2-round SMPC protocol is constructed that uses multilinear maps based on the Learning from Errors (LWE) assumption. The participant encodes the input and sends it via broadcast to reduce the interaction, homomorphic computational encoding information for secure access to computational data and secure the SMPC protocol through UC security. This paper extends the participants to multiple parties, reduces the communication rounds to 2, the protocol achieves sublinear communication overhead in poly polynomial time, smaller setup size to poly(k), and static security is achieved.",Springer
"Houshmand, Mahboobeh and Saheb Zamani, Morteza and Sedighi, Mehdi and Houshmand, Monireh",GA-based approach to find the stabilizers of a given sub-space,2015,10.1007/s10710-014-9219-z,https://doi.org/10.1007/s10710-014-9219-z,Journal,Genetic Programming and Evolvable Machines,"Stabilizer formalism is a powerful framework for understanding a wide class of operations in quantum information. This formalism is a framework where multiple qubit states and sub-spaces are described in a compact way in terms of operators under which they are invariant. In stabilizer formalism, one focuses the members of Pauli groups which have the stabilizing property of a given sub-space. Therefore, finding the Pauli stabilizers of a given sub-space in an efficient way is of great interest. In this paper, this problem is addressed in the field of quantum information theory. We present a two-phase algorithm to solve the problem whose order of complexity is considerably smaller than the common solution. In the first phase, a genetic algorithm is run. The results obtained by this algorithm are the matrices that can potentially be the Pauli stabilizers of the given sub-space. Then an analytical approach is applied to find the correct answers among the results of the first phase. Experimental results show that speed-ups are remarkable as compared to the common solution.",Springer
"Uijlen, Sander and Westerbaan, Bas",A Kochen-Specker System Has at Least 22 Vectors,2016,10.1007/s00354-016-0202-5,https://doi.org/10.1007/s00354-016-0202-5,Journal,New Generation Computing,"At the heart of the Conway-Kochen Free Will Theorem and Kochen and Specker's argument against non-contextual hidden variable theories is the existence of a Kochen-Specker (KS) system: a set of points on the sphere that has no {\{}0,1{\}}-coloring such that at most one of two orthogonal points are colored 1 and of three pairwise orthogonal points exactly one is colored 1. In public lectures, Conway encouraged the search for small KS systems. At the time of writing, the smallest known KS system has 31 vectors.",Springer
"Weber, Brian J. and Kalantre, Sandesh S. and McJunkin, Thomas and Taylor, Jacob M. and Zwolak, Justyna P.",Theoretical Bounds on Data Requirements for the Ray-Based Classification,2021,10.1007/s42979-021-00921-0,https://doi.org/10.1007/s42979-021-00921-0,Journal,SN Computer Science,"The problem of classifying high-dimensional shapes in real-world data grows in complexity as the dimension of the space increases. For the case of identifying convex shapes of different geometries, a new classification framework has recently been proposed in which the intersections of a set of one-dimensional representations, called rays, with the boundaries of the shape are used to identify the specific geometry. This ray-based classification (RBC) has been empirically verified using a synthetic dataset of two- and three-dimensional shapes (Zwolak et al. in Proceedings of Third Workshop on Machine Learning and the Physical Sciences (NeurIPS 2020), Vancouver, Canada [December 11, 2020], arXiv:2010.00500, 2020) and, more recently, has also been validated experimentally (Zwolak et al., PRX Quantum 2:020335, 2021). Here, we establish a bound on the number of rays necessary for shape classification, defined by key angular metrics, for arbitrary convex shapes. For two dimensions, we derive a lower bound on the number of rays in terms of the shape's length, diameter, and exterior angles. For convex polytopes in {\$}{\$}{\backslash}mathbb {\{}R{\}}^N{\$}{\$}, we generalize this result to a similar bound given as a function of the dihedral angle and the geometrical parameters of polygonal faces. This result enables a different approach for estimating high-dimensional shapes using substantially fewer data elements than volumetric or surface-based approaches.",Springer
"Ruiz, Alejandra and Martin, Yod-Samuel and Martinez, Jabier and Quintans, Jacobo and Mockly, Guillaume and Gyrard, Amelie and Crepax, Tommaso",Modeling ecosystems of reference frameworks for assurance: a case on privacy impact assessment regulation and guidelines,2023,10.1007/s10270-022-01061-6,https://doi.org/10.1007/s10270-022-01061-6,Journal,Software and Systems Modeling,"To assure certain critical quality properties (e.g., safety, security, or privacy), supervisory authorities and industrial associations provide reference frameworks such as standards or guidelines that in some cases are enforced (e.g., regulations). Given the pace at which both technical advancements and risks appear, there is an increase in the number of reference frameworks. As several frameworks might apply for same systems, certain overlaps appear (e.g., regulations for different countries where the system will operate, or generic standards in conjunction with more concrete standards for a given industrial sector or system type). We propose the use of modelling for alleviating the complexity of these reference frameworks ecosystems, and we provide a tool-supported method to create them for the benefit of different stakeholders. The case study is based on privacy data protection, and more concretely on privacy impact assessment processes. The European GDPR regulates the movement and processing of personal data, and, contrary to available software engineering privacy guidelines, articles in legal texts are usually difficult to translate to the underlying processes, artefacts and roles that they refer to. To facilitate the mutual comprehension of legal experts and engineers, in this work we investigate how mappings can be created between these two domains of expertise. Notably, we rely on modelling as a central point. We modelled the legal requirements of the GDPR on data protection impact assessments, and then, we selected the ISO/IEC 29134, a mainstream engineering guideline for privacy impact assessment, and, taking a concrete sector as example, the EU Smart Grid Data Protection Impact Assessment template. The OpenCert tool was used for providing technical support to both the modelling and the creation of the mapping models in a systematic way. We provide a qualitative evaluation from legal experts and privacy engineering practitioners to report on the benefits and limitations of this approach.",Springer
"Jain, Amith K. and Naveen Kumar, H. N.",Integration of Discriminative Information from Expressive and Neutral Face Image for Effective Modelling of Facial Expression Classification Problem,2024,10.1007/s42979-024-03469-x,https://doi.org/10.1007/s42979-024-03469-x,Journal,SN Computer Science,"The contribution of appearance feature variations between expressive and neutral face image towards facial expression classification problem has received limited attention in the literature. The prime focus of the proposed work is to investigate the abstract, robust and discriminative feature space to effectively model expression classification problem. The significant contributions of the work are, hybrid feature space developed by the integration of discriminative features derived from histogram of oriented gradients (HOG) and local gabor binary pattern histogram sequence (LGBPHS) feature descriptor; computing the shape and texture feature variations between expressive and neutral face image (feature difference); novel feature space developed by combining the hybrid feature space acquired from the expressive face image with the feature difference; stacked deep convolutional autoencoder is employed as an efficient feature selection algorithm for dimensionality reduction and multiclass support vector machine (MSVM) for classification. The combination of HOG and LGBPHS has improved the recognition accuracy, robustness, and generalization capability of the model. The work is carried out on three benchmark datasets (CK+, KDEF, and JAFFE) and the model has shown remarkable recognition rates on all the three benchmark datasets (96.43{\%} on CK+{\thinspace}, 96.03{\%} on KDEF, and 88.53{\%} on JAFFE).",Springer
"Mondal, Avijit and Chatterjee, Pinaki Sankar",CloudSec: A Lightweight and Agile Approach to Secure Medical Image Transmission in the Cloud Computing Environment,2024,10.1007/s42979-023-02539-w,https://doi.org/10.1007/s42979-023-02539-w,Journal,SN Computer Science,"In this paper, we have proposed a novel method CloudSec. It is a lightweight and agile image encryption method that combines a hashing function, multi-wing chaotic mapping system, and genetics algorithm. The proposed method offers significant benefits in terms of efficiency in data authentication. Additionally, our proposed method does complementary and internal scrambling in order to increase security of the image. Secret key with features is used as a seeding value to generate a key DNA image from a hyper-chaotic system to eliminate the correlation between adjacent pixels by chaotic sequence. The complex dynamic behavior of the chaotic map generates random sequences for image diffusion. The propagation of information between a permuted DNA image and a key DNA image can be achieved through the use of DNA operations. Simulation results show that the proposed method used to authenticate and secure medical images in health care information systems. Our results demonstrated that it is very effective and reliable to fully recover medical image in case of any attack. The proposed approach executes faster, generates a large key space, and provides better encryption than available state-of-the-art techniques. It also resists various attacks, such as differential and statistical attack. The proposed crypto system is suitable for real-time applications in cloud computing and can be integrated into an IoHT framework for secure medical image transmission.",Springer
"Van Dyke Parunak, H.",How to turn an MAS into a graphical causal model,2022,10.1007/s10458-022-09560-y,https://doi.org/10.1007/s10458-022-09560-y,Journal,Autonomous Agents and Multi-Agent Systems,"This paper proposes that an appropriately configured multi-agent system (MAS) is formally equivalent to a graphical causal model (GCM, a broad category that includes many formalisms expressed as directed graphs), and offers benefits over other GCMs in modeling a social scenario. MASs often use GCMs to support their operation, but are not usually viewed as tools for enhancing their execution. We argue that the definition of a GCM should include its update mechanism, an often-overlooked component. We review a wide range of GCMs to validate this definition and point out limitations that they face when applied to the social and psychological dimensions of causality. Then we describe Social Causality using Agents with Multiple Perspectives (SCAMP), a causal language and multi-agent simulator that satisfies our definition and overcomes the limitations of other GCMs for social simulation.",Springer
"Sai Phaneendra, P. and Vudadha, Chetan and Srinivas, M. B.",Optimization of Reversible Circuits Using Gate Pair Classification,2021,10.1007/s42979-021-00900-5,https://doi.org/10.1007/s42979-021-00900-5,Journal,SN Computer Science,"Research on reversible logic gained momentum in the past decade owing to its utility in emerging areas such as quantum computing, optical computing and low power circuit implementation, etc. Reversible circuits synthesized using existing techniques often tend to be sub-optimal; thus, post-synthesis optimization techniques are usually employed to reduce the `circuit cost', a metric used to compare the reversible circuits. In this paper, a set of optimization techniques is proposed to minimize the circuit cost. These techniques rely on classifying a pair of reversible gates in a given circuit based on their structural similarity. An algorithm that maps the classifications with the optimization techniques to improve the cost of a circuit is also proposed. Results obtained for a set of benchmark reversible circuits confirm that the proposed methodology performs better in terms of circuit cost when compared to those available in the literature.",Springer
"Rehman, Zia ur and Hussain, Omar Khadeer and Hussain, Farookh Khadeer",Parallel Cloud Service Selection and Ranking Based on QoS History,2014,10.1007/s10766-013-0276-3,https://doi.org/10.1007/s10766-013-0276-3,Journal,International Journal of Parallel Programming,"The growing number of cloud services has made service selection a challenging decision-making problem by offering wide ranging choices for cloud service consumers. This necessitates the use of formal decision making methodologies to assist a decision maker in selecting the service that best fulfills the user's requirements. In this paper, we present a cloud service selection methodology that utilizes quality of service history of cloud services over different time periods and performs parallel multi-criteria decision analysis to rank all cloud services in each time period in accordance with user preferences before aggregating the results to determine the overall rank of all the available options for cloud service selection. This methodology assists the cloud service user to select the best possible available service according to the requirements. The multi-criteria decision making processes used for each time period are independent of the other time periods and are executed in parallel.",Springer
"Singh, Shaurya Pratap and Chaurasia, Brijesh Kumar and Tripathi, Tanmay and Pal, Ayush and Gupta, Siddharth",Attack on lattice shortest vector problem using K-Nearest Neighbour,2024,10.1007/s42044-024-00184-x,https://doi.org/10.1007/s42044-024-00184-x,Journal,Iran Journal of Computer Science,"Lattice-based cryptography is now the most effective and adaptable branch of post-quantum cryptography. The prime number factoring assumption or the presumption that the discrete logarithm problem is intractable are the two assumptions that underlie nearly all cryptographic security systems. Lattice-based cryptography has recently gained popularity to improve security as the world prepares for quantum computing. Lattices are used to secure the systems; however, one of the problems is the Shortest vector problem. In this work, we addressed the attack on lattice problems, especially two-dimensional, four-dimensional, and ten-dimensional, with the help of the machine learning algorithm K-Nearest Neighbour (KNN). Results and analysis findings demonstrate that the suggested approach can achieve accuracy of upto 78{\%} and 58{\%} on self-prepared datasets over two-dimensional and ten- dimensional, respectively.",Springer
"Saggio, Giovanni",The Human Digi-real Duality,2024,10.1007/s42979-023-02582-7,https://doi.org/10.1007/s42979-023-02582-7,Journal,SN Computer Science,"Current technologies allow acquiring whatever amount of data (even big data), from whatever system (object, component, mechanism, network, implant, machinery, structure, asset, etc.), during whatever time lapse (secs, hours, weeks, years). Therefore, potentially it is possible to fully characterize any system for any time we need, with the possible consequence of creating a virtual copy, namely the digital twin (DT) of the system. When technology of DT meets an augmented reality scenario, the augmented digital twin (ADT) arises, when DT meets an artificial intelligence environment, the intelligent digital twin (IDT) arises. DTs, ADTs and IDTs are successfully adopted in electronics, mechanics, chemistry, manufacturing, science, sport, and more, but when adopted for the human body it comes out the human digital twin (HDT) or alternatively named virtual human simulator (VHS). When the VHS incorporates information from surroundings (other VHSs and environment), taking a cue from the particle-wave duality (the mix of matter and energy), we can name this super-VHS as the human digi-real duality (HDRD). This work is focused on defining the aforementioned acronyms, on evidencing their differences, advantages and successful case adoptions, but highlighting technology limits too, and on foreseeing new and intriguing possibilities.",Springer
"Song, Kang and Shang, Wenqian and Zhang, Yong and Yi, Tong and Wang, Xuan",Security issues of news data dissemination in internet environment,2024,10.1186/s13677-024-00632-w,https://doi.org/10.1186/s13677-024-00632-w,Journal,Journal of Cloud Computing,"With the rise of artificial intelligence and the development of social media, people's communication is more convenient and convenient. However, in the Internet environment, the untrue dissemination of news data leads to a large number of problems. Efficient and automatic detection of rumors in social platforms hence has become an important research direction in recent years. This paper leverages deep learning methods to mine the changing trend of user features related to rumor events, and designs a rumor detection model called Time Based User Feature Capture Model(TBUFCM). To obtain a new feature vector representing the user's comprehensive features under the current event, the proposed model first recomputes the user feature vector by using feature enhancement function. Then it utilizes GRU(Gate Recurrent Unit, GRU) and CNN(Convolutional Neural Networks, CNN) models to learn the global and local changes of user features, respectively. Finally, the hidden rumor features in the process of rumor propagation can be discovered by user and time information. The experimental results show that TBUFCM outperforms the baseline model, and when there are only 20 forwarded posts, it can also reach an accuracy of 92{\%}. The proposed method can effectively solve the security problem of news data dissemination in the Internet environment.",Springer
"Zhang, Jinli and Wang, Zhenbo and Jiang, Zongli and Wu, Man and Li, Chen and Yamanishi, Yoshihiro",Quantitative evaluation of molecular generation performance of graph-based GANs,2024,10.1007/s11219-024-09671-7,https://doi.org/10.1007/s11219-024-09671-7,Journal,Software Quality Journal,"Deep generative models have been widely used in molecular generation tasks because they can save time and cost in drug development compared with traditional methods. Previous studies based on generative adversarial network (GAN) models typically employ reinforcement learning (RL) to constrain chemical properties, resulting in efficient and novel molecules. However, such models have poor performance in generating molecules due to instability in training. Therefore, quantitative evaluation of existing molecular generation models, especially GAN models, is necessary. This study aims to evaluate the performance of discrete GAN models using RL in molecular generation tasks and explore the impact of different factors on model performance. Through evaluation experiments on QM9 and ZINC datasets, the results show that noise sampling distributions, training epochs, and training data volumes can affect the performance of molecular generation. Finally, we provide strategies for stable training and improved performance for GAN models.",Springer
"Thalheim, Bernhard",Models: the fourth dimension of computer science,2022,10.1007/s10270-021-00954-2,https://doi.org/10.1007/s10270-021-00954-2,Journal,Software and Systems Modeling,"Models are a universal instrument in science, technology, and daily life. They function as instruments in almost every scenario. Any human activity can be (and is) supported by models, e.g. reason, explain, design, act, predict, explore, communicate, collaborate, interact, orient, direct, guide, socialises, perceive, reflect, develop, making sense, teach, learn, imagine, etc. This universal suitability is also the basis for a wide use of models and modelling in Computer Science and Engineering. We claim that models form the fourth dimension in Computer Science. This paper sketches and systematises the main ingredients of the study model and modelling.",Springer
"Kumar, Aman and Rizvi, Danish Raza","(S2M {\$}{\$}-IQ):{\$}{\$}Semiotics Similarity Measurement and Information Quantification, Lecture Information Weightage Calculation",2024,10.1007/s42979-024-03541-6,https://doi.org/10.1007/s42979-024-03541-6,Journal,SN Computer Science,"AI and ML-based smart applications will be the next best way towards essential services, like basic education, and quality optimization. In the educational delivery context, not only summarization but advanced stages of NLP require capabilities to extract information and quantify the delivered knowledge. Summarizing and evaluating summary quality alone is insufficient as it ignores whether the original lecture adequately covered relevant information about the topic---testing a summary against a perfect reference is meaningless if the lecture itself was incomplete. Hence, the perfect summarisation of educational delivery is insufficient, but information quantification is imperative, particularly for enhancing educational quality of service (E-QoS). This paper meticulously analyses the existing quality assessment metrics used in recent benchmark works and proposes/supports the need for information quantification by thoroughly examining some known metrics for generated summary quality assessment and their limitations concerning educational deliveries and respective summaries. The paper contributes in four key areas: first, a comprehensive study and evaluation of the sufficiency of available metrics for assessing the quality of candidate summaries in the context of educational deliveries; second, a proposal of the need for information/knowledge quantification (not only summary quality) in educational delivery summaries; third, mathematical modeling based on known metrics; and finally, experimentation and analysis of proposed mathematics on both benchmark and real-time novel datasets.",Springer
"Danso, Juliana Mantebea and Missah, Yaw Marfo and Gyamfi, Enoch Opanin and Dankwa, Stephen and Kwabena, Sarpong",Reseed Skipping of Linear Congruential Generator for Multi-level Image Steganography Security of Financial Data,2022,10.1007/s42979-022-01540-z,https://doi.org/10.1007/s42979-022-01540-z,Journal,SN Computer Science,"This paper proposed a multi-level image steganography model that integrates with image and plaintext encryption schemes. The model starts by partitioning the cover-image pixel positions into two regions of respective purposes, one is reserved to hold the data, and through the implementation of the dynamic difference expansion principle, the other sloughs some parts to the reserved region in responsive to the size of the data to embed. Continuously reseeding and initializing the parameter values of a Linear Congruential Generator (LCG), generate a set of random pixel positions as members of the reserved region. Before data embedding, the region reserved to hold the data as well as the data bits to embed, are then encrypted using AES with respective keys. Encryption keys are randomly generated using a Cryptographically Secure Pseudo-Random Number Generator (CSPRNG), the Fortuna algorithm. Multiplex security nature of using a randomization generator to reserve image region for encryption and encrypting plaintext data before performing steganography still ensures stability in computational complexities better than a logarithmic O(n log n). A visual inspection by evaluators who made 3000 choices to correctly differentiate stego images from its cover-images shows that only 47 choices were correct, 1884 choices were wrong, while 1069 choices were uncertain. An experiment shows an average Embedding Rates (ERs) of 0.00109 bpp and an average PSNR of 72. This concludes, as our integrated steganography and image encryption which implements the dynamic difference expansion principle, outputs encrypted stego mages that can deceive the naked human eyes into identifying them as rather cover-images, its embedding rate is faster (i.e. {\$}{\$}{\backslash}mathrm{\{}ER{\}}<0.1{\$}{\$}), suitably good, and ensures better imperceptibility of cover-image alterations. When comparing these experimental results with existing methods, our proposed model shows significant competitiveness. We even show real-life scenarios on how this idea is just not a proof-of-concept but typically applicable in protecting sensitive financial data.",Springer
"Banzhaf, Wolfgang",Genetic Programming and Emergence,2014,10.1007/s10710-013-9196-7,https://doi.org/10.1007/s10710-013-9196-7,Journal,Genetic Programming and Evolvable Machines,"Emergence and its accompanying phenomena are a widespread process in nature. Despite its prominence, there is no agreement in the sciences about the concept and how to define or measure emergence. One of the most contentious issues discussed is that of top-down (or downward) causation as a defining characteristic of systems with emergence. In this contribution we shall argue that emergence happens in Genetic Programming, for all the world to see.",Springer
"Coronado, Estefan{\'i}a and Valero, Valent{\'i}n and Orozco-Barbosa, Luis and Cambronero, Mar{\'i}a-Emilia and Pelayo, Fernando L.",Modeling and simulation of the IEEE 802.11e wireless protocol with hidden nodes using Colored Petri Nets,2021,10.1007/s10270-020-00817-2,https://doi.org/10.1007/s10270-020-00817-2,Journal,Software and Systems Modeling,"Wireless technologies are continuously evolving, including features such as the extension to mid- and long-range communications and the support of an increasing number of devices. However, longer ranges increase the probability of suffering from hidden terminal issues. In the particular case of Wireless Local Area Networks (WLANs), the use of Quality of Service (QoS) mechanisms introduced in IEEE 802.11e compromises scalability, exacerbates the hidden node problem, and creates congestion as the number of users and the variety of services in the network grow. In this context, this paper presents a configurable Colored Petri Net (CPN) model for the IEEE 802.11e protocol with the aim of analyzing the QoS support in mid- and long-range WLANs The CPN model covers the behavior of the protocol in the presence of hidden nodes to examine the performance of the RTS/CTS exchange in scenarios where the QoS differentiation may involve massive collision chains and high delays. Our CPN model sets the basis for further exploring the performance of the various mechanisms defined by the IEEE 802.11 standard. We then use this CPN model to provide a comprehensive study of the effectiveness of this protocol by using the simulation and monitoring capabilities of CPN Tools.",Springer
"Surana, Shraddha and Arora, Pooja and Singh, Divye and Sahasrabuddhe, Deepti and Valadi, Jayaraman",PandoraGAN: Generating Antiviral Peptides Using Generative Adversarial Network,2023,10.1007/s42979-023-02203-3,https://doi.org/10.1007/s42979-023-02203-3,Journal,SN Computer Science,"The continuous increase in pathogenic viruses and the intensive laboratory research emphasizes the need for cost- and time-efficient drug development. This accelerates research for alternate drug candidates like antiviral peptides (AVP) that have therapeutic and prophylactic potential and gaining attention in recent times. However, diversity in their sequences, limited and non-uniform characterization often limit their applications. Isolating newer peptide backbones with required characteristics is a cumbersome process with many design--test--build cycles. Advanced deep learning approaches such as generative adversarial networks (GAN) can be helpful to expedite the initial stage of developing novel peptide drugs. In this study, we developed PandoraGAN that uses a manually curated training dataset of 130 highly active peptides that include peptides from known databases (such as AVPdb) and literature to generate novel antiviral peptides. The underlying architecture in PandoraGAN is able to learn a good representation of the implicit properties of antiviral peptides. The generated sequences from PandoraGAN are validated based on physico-chemical properties. They are also compared with the training dataset statistically using Pearson's correlation and Mann--Whitney U-test. We, therefore, confirm that PandoraGAN is capable of generating a novel antiviral peptide backbone showing similar properties to that of the known highly active antiviral peptides. This approach exhibits a potential to discover novel patterns of AVP which may have not been seen earlier with traditional methods. To our knowledge, this is the first ever use of GAN models for antiviral peptides across the viral spectrum.",Springer
"Raychaudhuri, Amlan and Maity, Satyabrata and Chakrabarti, Amlan and Bhattacharjee, Debotosh",SMDF: Spatial Mass Distribution Features and Deep Learning-Based Technique for Human Activity Recognition,2023,10.1007/s42979-023-02452-2,https://doi.org/10.1007/s42979-023-02452-2,Journal,SN Computer Science,"Automatic detection of human activity is one of the growing research areas due to the wide range of applications like elderly and patient monitoring for ambient assistive living, visual surveillance, etc. This paper presents a novel bi-channel deep learning model to recognize several human daily living activities. One channel includes activity classification using key poses, based on the spatial mass distribution feature (SMDF). The key poses of all the training classes are estimated using the K-means algorithm on the SMDF of the corresponding silhouette images. Similarly, the key poses of a testing video are extracted, and the k-nearest neighbor (KNN) technique is used thereafter to determine the activity classes. The other channel utilizes VGG-16 to classify human activity on preprocessed frame sequence of a video. Ultimately, the results of the two channels are combined to determine the final activity classification. The bi-channel procedure provides better accuracy over any of the individual channels. The proposed technique is verified using the single-view Weizmann and multi-view MuHAVi datasets. For the Weizmann dataset, the accuracy is 98.8{\%}, and for MuHAVi-14 and MuHAVi-8 both, the accuracy is 98.5{\%}. The accuracy rate for the proposed technique is better than the other state-of-the-art methods concerning different parameters that establish the effectiveness of our proposed method.",Springer
"Sleegers, Joeri and van den Berg, Daan",The Hardest Hamiltonian Cycle Problem Instances: The Plateau of Yes and the Cliff of No,2022,10.1007/s42979-022-01256-0,https://doi.org/10.1007/s42979-022-01256-0,Journal,SN Computer Science,"We use two evolutionary algorithms to make hard instances of the Hamiltonian cycle problem. Hardness (or `fitness'), is defined as the number of recursions required by Vandegriend--Culberson, the best known exact backtracking algorithm for the problem. The hardest instances, all non-Hamiltonian, display a high degree of regularity and scalability across graph sizes. These graphs are found multiple times through independent runs, and by both evolutionary algorithms, suggesting the search space might contain monotonic paths towards the global maximum. For Hamiltonian-bound evolution, some hard graphs were found, but convergence is much less consistent. In this extended paper, we survey the neighbourhoods of both the hardest yes- and no-instances produced by the evolutionary algorithms. Results show that the hardest no-instance resides on top of a steep cliff, while the hardest yes-instance turns out to be part of a plateau of 27 equally hard instances. While definitive answers are far away, the results provide a lot of insight in the Hamiltonian cycle problem's state space.",Springer
"Mendel, Jerry M.",Type-2 Fuzzy Sets and Systems: a Retrospective,2015,10.1007/s00287-015-0927-4,https://doi.org/10.1007/s00287-015-0927-4,Journal,Informatik-Spektrum,"This article provides a high-level retrospective of type-2 fuzzy sets and fuzzy logic systems. It explains how type-2 fuzzy sets can be used to model membership function uncertainties, and how by doing this smoother performance can be obtained than by using type-1 fuzzy sets. It also summarizes the notation that should be used for type-2 fuzzy sets, describes four important mathematical representations for these fuzzy sets, explains the differences between type-1 and type-2 fuzzy logic systems and which of the four representations is most useful when designing an optimal type-2 fuzzy logic system, provides a very useful strategy for optimal designs of fuzzy logic systems -- one that guarantees performance improvement as one goes from a type-1 fuzzy logic system to a type-2 fuzzy logic system design -- , and describes four methods for simplifying the designs of type-2 fuzzy logic systems. Finally, it explains why type-2 fuzzy sets can capture two kinds of linguistic uncertainties simultaneously (the uncertainty of an individual and the uncertainties of a group about a word), whereas type-1 fuzzy sets cannot, and that such type-2 fuzzy set word models are what should be used to implement Zadeh's Computing With Words paradigm.",Springer
"P{\'e}rez-Castillo, Ricardo and Delgado, Andrea and Ruiz, Francisco and Bacigalupe, Virginia and Piattini, Mario",A method for transforming knowledge discovery metamodel to ArchiMate models,2022,10.1007/s10270-021-00912-y,https://doi.org/10.1007/s10270-021-00912-y,Journal,Software and Systems Modeling,"Enterprise architecture has become an important driver to facilitate digital transformation in companies, since it allows to manage IT and business in a holistic and integrated manner by establishing connections among technology concerns and strategical/motivational ones. Enterprise architecture modelling is critical to accurately represent business and their IT assets in combination. This modelling is important when companies start to manage their enterprise architecture, but also when it is remodelled so that the enterprise architecture is realigned in a changing world. Enterprise architecture is commonly modelled by few experts in a manual way, which is error-prone and time-consuming and makes continuous realignment difficult. In contrast, other enterprise architecture modelling proposal automatically analyses some artefacts like source code, databases, services, etc. Previous automated modelling proposals focus on the analysis of individual artefacts with isolated transformations toward ArchiMate or other enterprise architecture notations and/or frameworks. We propose the usage of Knowledge Discovery Metamodel (KDM) to represent all the intermediate information retrieved from information systems' artefacts, which is then transformed into ArchiMate models. Thus, the core contribution of this paper is the model transformation between KDM and ArchiMate metamodels. The main implication of this proposal is that ArchiMate models are automatically generated from a common knowledge repository. Thereby, the relationships between different-nature artefacts can be exploited to get more complete and accurate enterprise architecture representations.",Springer
"Nalavade, Jagannath E. and Patil, Akshta and Buchade, Amar and Jadhav, Nagesh",Deep Neural Network and GAN-Based Reversible Data Hiding in Encrypted Images: A Privacy-Preserving Approach,2023,10.1007/s42979-023-02347-2,https://doi.org/10.1007/s42979-023-02347-2,Journal,SN Computer Science,"In light of recent incidents involving the leakage of private photographs of Hollywood celebrities from iCloud, the need for robust methods to safeguard image content has gained paramount importance. This paper addresses this concern by introducing a novel framework for reversible image editing (RIT) supported by reversible data hiding with encrypted images (RDH-EI) techniques. Unlike traditional approaches vulnerable to hacking, this framework ensures both efficient and secure data embedding while maintaining the original image's privacy. The framework leverages two established methods: secret writing and knowledge activity. While secret writing is susceptible to hacking due to the complex nature of cipher languages, RDH-EI-supported RIT adopts a more secure approach. It replaces the linguistic content of the original image with the semantics of a different image, rendering the encrypted image visually indistinguishable from a plaintext image. This novel substitution prevents cloud servers from detecting encrypted data, enabling the adoption of reversible data hiding (RDH) methods designed for plaintext images. The proposed framework offers several distinct advantages. Firstly, it ensures the confidentiality of sensitive information by concealing the linguistic content of the original image. Secondly, it supports reversible image editing, enabling the restoration of the original image from the encrypted version without any loss of data. Lastly, the integration of RDH techniques designed for plaintext images empowers the cloud server to embed supplementary data while preserving image quality. Incorporating convolutional neural network (CNN) and generative adversarial network (GAN) models, the framework ensures accurate data extraction and high-quality image restoration. The applications of this concealed knowledge are vast, spanning law enforcement, medical data privacy, and military communication. By addressing limitations of previous methods, it opens new avenues for image manipulation and secure data transmission. This research not only contributes a practical solution but also sets a benchmark for advancing the security and privacy paradigms in image-related technologies.",Springer
"Pavone, Arianna and Viola, Caterina",The Quantum Cyclic Rotation Gate,2024,10.1007/s42979-024-03141-4,https://doi.org/10.1007/s42979-024-03141-4,Journal,SN Computer Science,"A circular shift operator (or cyclic rotation gate) {\$}{\$}{\{}{\{}{\backslash},{\backslash}mathrm{\{}{\backslash}texttt {\{}ROT{\}}{\}}{\backslash},{\}}{\}}{\_}k{\$}{\$}applies a rightward (or leftward) shift to an input register of n qubits o by as many positions as encoded by an additional input {\$}{\$}k {\backslash}in {\backslash}mathbb N{\$}{\$}. Specifically, the qubit at position x is moved to position {\$}{\$}(x+k) {\backslash}mod n{\$}{\$}. While it is known that there exists a quantum rotation operator that can be implemented in {\$}{\$}{\{}{\{}{\backslash},{\backslash}mathrm{\{}{\backslash}mathcal {\{}O{\}}{\}}{\backslash},{\}}{\}}({\backslash}log (n)){\$}{\$}-time, through the repeated parallel application of the elementary {\$}{\$}{\{}{\{}{\backslash},{\backslash}mathrm{\{}{\backslash}texttt {\{}Swap{\}}{\}}{\backslash},{\}}{\}}{\$}{\$}operators, there is no systematic procedure that concretely constructs the quantum operator {\$}{\$}{\{}{\{}{\backslash},{\backslash}mathrm{\{}{\backslash}texttt {\{}ROT{\}}{\}}{\backslash},{\}}{\}}{\$}{\$}for variable size n of the quantum register and a variable parameter k. We fill the gap, providing a systematic implementation of the cyclic rotation operator (denoted {\$}{\$}{\{}{\{}{\backslash},{\backslash}mathrm{\{}{\backslash}texttt {\{}ROT{\}}{\}}{\backslash},{\}}{\}}{\$}{\$}) in a quantum circuit model of computation whose depth is {\$}{\$}{\{}{\{}{\backslash},{\backslash}mathrm{\{}{\backslash}mathcal {\{}O{\}}{\}}{\backslash},{\}}{\}}({\backslash}log (n)){\$}{\$}. We show how the circular shift operator can be utilized in quantum approaches to text processing, focusing on the problem of getting all possible cyclic rotations of a string in {\$}{\$}{\{}{\{}{\backslash},{\backslash}mathrm{\{}{\backslash}mathcal {\{}O{\}}{\}}{\backslash},{\}}{\}}({\backslash}log ^2(n)){\$}{\$}depth.",Springer
"Barash, L. Yu. and Guskova, M. S. and Shchur, L. N.",Employing AVX vectorization to improve the performance of random number generators,2017,10.1134/S0361768817030033,https://doi.org/10.1134/S0361768817030033,Journal,Programming and Computer Software,"By the example of the RNGAVXLIB random number generator library, this paper considers some approaches to employing AVX vectorization for calculation speedup. The RNGAVXLIB library contains AVX implementations of modern generators and the routines allowing one to initialize up to 1019 independent random number streams. The AVX implementations yield exactly the same pseudorandom sequences as the original algorithms do, while being up to 40 times faster than the ANSI C implementations.",Springer
"Vallecillo, Antonio and Perez-Castillo, Ricardo and Visser, Joost",Guest editorial: special issue on ``IT quality challenges in a digital society'',2024,10.1007/s11219-023-09644-2,https://doi.org/10.1007/s11219-023-09644-2,Journal,Software Quality Journal,,Springer
"Bose, S. Rubin and Kumar, V. Sathiesh",Precise Hand Gesture Recognition under Hard Visual Environments using Deep Architecture,2024,10.1007/s42979-023-02474-w,https://doi.org/10.1007/s42979-023-02474-w,Journal,SN Computer Science,"Hand gesture recognition is a way of capturing and translating the human signs into commands utilizing a visual interface. In this paper, You Only Look Once (Yolo) based deep single-stage convolutional neural network (CNN) is proposed for real-time multi-hand sign recognition under hard visual environments. The Yolo-v2 and Yolo-v3 models are utilized for real-time hand sign recognition. The DarkNet-19 and DarkNet-53 CNN architectures are used as a backbone networks in Yolo-v2 and Yolo-v3 respectively. Three distinct datasets (NUSHP-II, SENZ-3D, and MITI-HD) are used to train and validate the models. The models are evaluated using a test dataset with an IoU range of 0.5 to 0.95. The Yolo-v2 CNN model achieved an average precision value of 99.10{\%} for AP0.5, 93.00{\%} for AP0.75, and 78.30{\%} for AP0.5:0.95 on the MITI-Hand dataset. The Yolo-v3 CNN model achieved an average precision value of 99.18{\%} for AP0.5. The Yolo model with Adam Optimizer performs better com- pared to other optimization approaches. The prediction time obtained by using the Yolo-v2 and Yolo-v3 CNN models is 20 ms and 25 ms, respectively. The proposed Yolo-v3 CNN model efficiently recognizes the multi-hand signs under hard visual environments.",Springer
"Chaitanya, S. N. V. S. K. and Bakkiyaraj, R. Ashok and Rao, B. Venkateswara and Jayanthi, K.",Scenario-Based Approach to Solve Optimal Reactive Power Dispatch Problem with Integration of Solar Energy Using Modified Ant Line Optimizer,2023,10.1007/s42979-023-02315-w,https://doi.org/10.1007/s42979-023-02315-w,Journal,SN Computer Science,"This paper considers a scenario-based approach, a stochastic ORPD formulation and solution that accommodates uncertain load demand, and solar power. The optimization tasks are based on the Modified Ant Line Optimizer (MALO) algorithm. PV system was used in place of the conventional thermal generator at bus 8, then the IEEE 30-bus system is modified. In addition, calculate the available solar power, and use the lognormal probability density function. In this paper, minimization of active power losses and voltage deviation are considered as objectives. This is delineated as an optimization problem by considering solar energy uncertainties and load uncertainties. Introducing solar energy sources to the power system along with the existing conventional sources to improve the performance of the system. An analysis was carried out using MALO to examine the proposed approach for IEEE 30-bus test system. The proposed method has been compared to other approaches and found to be effective.",Springer
"Li, Shichao and Zhang, Ning and Jiang, Ruihong and Zhou, Zou and Zheng, Fei and Yang, Guiqin",Joint task offloading and resource allocation in mobile edge computing with energy harvesting,2022,10.1186/s13677-022-00290-w,https://doi.org/10.1186/s13677-022-00290-w,Journal,Journal of Cloud Computing,"Mobile edge computing (MEC) is considered to be a promising technique to enhance the computation capability and reduce the energy consumption of smart mobile devices (SMDs) in the sixth-generation (6G) networks. With the huge increase of SMDs, many applications of SMDs can be interrupted due to the limited energy supply. Combining MEC and energy harvesting (EH) can help solve this issue, where computation-intensive tasks can be offloaded to edge servers and the SMDs can also be charged during the offloading. In this work, we aim to minimize the total energy consumption subject to the service latency requirement by jointly optimizing the task offloading ratio and resource allocation (including time switching (TS) factor, uplink transmission power of SMDs, downlink transmission power of eNodeB, computation resources of SMDs and MEC server). Compared with the previous studies, the task uplink transmission time, MEC computation time and the computation results downloading time are all considered in this problem. Since the problem is non-convex, we first reformulate it, and then decompose it into two subproblems, i.e., joint uplink and downlink transmission time optimization subproblem (JUDTT-OP) and joint task offloading ratio and TS factor optimization subproblem (JTORTSF-OP). By solving the two subproblems, a joint task offloading and resource allocation with EH (JTORAEH) algorithm is proposed to solve the considered problem. Simulation results show that compared with other benchmark methods, the proposed JTORAEH algorithm can achieve a better performance in terms of the total energy consumption.",Springer
"Samima, Shabnam and Sarma, Monalisa",PSPHERE: person specific human error estimation,2022,10.1007/s40860-021-00146-1,https://doi.org/10.1007/s40860-021-00146-1,Journal,Journal of Reliable Intelligent Environments,"Human error has always been a source of threat for any human--machine interaction system. Incidents like Bhopal gas tragedy, Three Mile Island and Chernobyl are examples of havoc caused due to human errors. With an aim to understand human error, human reliability analysis methods have been introduced. These methods use performance shaping factors (PSFs) to model human behavior. In-depth analyses of PSFs reveal that human factor is one of the important influencing factors affecting human behavior. However, most of the existing approaches depend on fixed or expert opinion values for estimating human error probability thus paying less attention to dynamic nature of human behavior. Every human is different and also their behavior changes along the course of time. Based on this philosophy, the work proposes a Person-Specific Human Error Estimation methodology called P-SPHERE to estimate human error probability. The architectural framework of the proposed method consists of environment, human, task, and organization factors. Using these factors, the framework evaluates human error probability by exploiting the advances of the dynamic human behavior using real values and the existing human reliability analysis methods. Considering the effect of type of task performed, time spent on task, work environment, time of work, work context, and the cognitive aspect of behavior, human error probability is evaluated. A case study has been taken to demonstrate the evaluation process with respect to railway industry. By incorporating human specific factor values, the proposed approach transforms the HEP estimation procedure into a person-specific approach, thereby overcoming the shortcomings of traditional HRA methods in addressing the uncertainty of the complex working environment.",Springer
"Abramov, S. A. and Ryabenko, A. A. and Khmelnov, D. E.","Laurent, Rational, and Hypergeometric Solutions of Linear q-Difference Systems of Arbitrary Order with Polynomial Coefficients",2018,10.1134/S0361768818020020,https://doi.org/10.1134/S0361768818020020,Journal,Programming and Computer Software,"Systems of linear q-difference equations with polynomial coefficients are considered. Equations in the system may have arbitrary orders. For such systems, algorithms for searching polynomial, rational, and hypergeometric solutions, as well as solutions in the form of Laurent series, are suggested. Implementations of these algorithms are discussed.",Springer
"Lodato, Ivano and Shekatkar, Snehal M. and Wong, Tian An",On partial information retrieval: the unconstrained 100 prisoner problem,2023,10.1007/s00236-022-00436-y,https://doi.org/10.1007/s00236-022-00436-y,Journal,Acta Informatica,"We consider a generalization of the classical 100 prisoner problem and its variant, involving empty boxes, whereby winning probabilities for a team depend on the number of attempts, as well as on the number of winners. We call this the unconstrained 100 prisoner problem. After introducing the 3 main classes of strategies, we define a variety of `hybrid' strategies and quantify their winning-efficiency. Whenever analytic results are not available, we make use of Monte Carlo simulations to estimate with high accuracy the winning probabilities. Based on the results obtained, we conjecture that all strategies, except for the strategy maximizing the winning probability of the classical (constrained) problem, converge to the random strategy under weak conditions on the number of players or empty boxes. We conclude by commenting on the possible applications of our results in understanding processes of information retrieval, such as ``memory'' in living organisms.",Springer
"Pecharrom{\'a}n-Gallego, Ra{\'u}l",A Fully Physics-Based CMOS Camera Model Within a 3-D Virtual World Ray Trace Simulation Engine,2023,10.1007/s42979-023-02372-1,https://doi.org/10.1007/s42979-023-02372-1,Journal,SN Computer Science,"CMOS based cameras are present nowadays for many imaging applications, ranging from any consumer, industrial or artistic use, they will also be introduced into the simulation engines applied to any raytracing technology, like electro optical, radar or LiDAR sensors simulation in the automotive industry, which is the scope of this work, that introduces a holistic model of CMOS camera that can be customized for different applications from input specifications. Starting with a ray trace simulation environment of the surrounding scene to its light reaching the lens, to photon conversion into electron--hole pairs within the image sensor photodiodes, to final image rendering and shown in display. Both the camera model and the ray tracing engine are fully physics-based. The whole system is validated within a simulated environmental illumination system including the camera sensor pipeline for final image processing. We also use industrial standard color and resolution targets and methodologies for image quality validation. Furthermore, a HDR image fusion by using fusion of images captured at different exposure values is also introduced. Moreover, validation against real photographs on color targets and the resolution methodologies introduced here leads to feasibility of the whole process presented. In summary, this work presents a number of well proven methodologies on CMOS camera simulation valid within both a ray trace environment and real world, and its automotive application feasibility supported with full real measurements validation.",Springer
"Sergiyenko, O. and Zhirabok, A.",Fault Identification in Mobile Robot Groups Using Sliding Mode Observers,2020,10.1134/S0361768820080216,https://doi.org/10.1134/S0361768820080216,Journal,Programming and Computer Software,"The paper studies the emerging trends in advanced computing and information technology for efficient solutions of fault identification problem for mobile robot groups under the unmatched disturbances. The sliding mode observers are considered for mentioned problem solution. It facilitates the concept of Smart everything inside the considered robotic group during its generalized control: smart surrounding sensing, communication, processing, and scanned data storing. The suggested novel approach to sliding mode observer design is based on obtaining the reduced order model of the initial system. This allows reduce the complexity of sliding mode observer and relax restrictions imposed on the initial system.",Springer
"Moharana, Meena and Pandey, Manjusha and Rautaray, Siddharth Swarup",Clustering Based BMI Indexing for Child Disease Prone-Probability Prediction,2023,10.1007/s42979-023-01823-z,https://doi.org/10.1007/s42979-023-01823-z,Journal,SN Computer Science,"Early age obesity has a significant impact on the world's public health. Obesity can be identified in children using body mass indexing based on age-specific vitals of a child. An increase in BMI due to excess deposit of body fats has an association with early age obesity. Analyses the impact of parental factors along with child obesity using data analytic techniques decision tree, random forest, OLS Regression technique, k-means algorithm, and suggest how fatal it can be along with requirements to overcome it. The ongoing research finds the possibility of generating predictive models from existing/logged data and using them for imputation. With higher model accuracy decision tree, Random forest, k-Means algorithm followed by two major hypothesis z-test and OLS regression has been done. The current model adopted for finding PtD (prone to disease) clusters on dataset. PtD cluster has been defined as one with k{\thinspace}={\thinspace}3. Clusters of EAO has been defined as the one with k{\thinspace}={\thinspace}5. The accuracy level of model with DT{\thinspace}+{\thinspace}k-means (a1{\thinspace}={\thinspace}0.987{\%}, a2{\thinspace}={\thinspace}0.989{\%}, m1{\thinspace}={\thinspace}83{\%}) and RF{\thinspace}+{\thinspace}k-means (a1{\thinspace}={\thinspace}0.976{\%}, a2{\thinspace}={\thinspace}0.988{\%}, m1{\thinspace}={\thinspace}79{\%}) has been generated by our proposed model. Our model rejects null hypothesis translated as (mean{\thinspace}={\thinspace}20.31, std{\thinspace}={\thinspace}7.91, p{\thinspace}={\thinspace}0.05). Clusters of both CBMI and CorrBMI found out (E, D, C, B, A), which gives EAO clusters and PtD (C, B, A) clusters with k{\thinspace}={\thinspace}3. Out of 1102 instances 562 no. of child of PtD and 857 no. of child have been deduced to be suffering from EAO in the sample data. The result of the performance evaluation of our models proposed results into the deduction of fact that the random forest algorithm of data analysis has the highest accuracy of 0.993 while the decision tree has the accuracy of 0.997.",Springer
"Mehla, Rajan and Garg, Ritu",Anonymous Attribute-Based Searchable Encryption for Smart Health System,2024,10.1007/s42979-024-03206-4,https://doi.org/10.1007/s42979-024-03206-4,Journal,SN Computer Science,"The quality of healthcare is predicted to rise dramatically with the advent of smart health. The key role in making smart health a success is played by the rise of cloud computing and the Internet of Things (IoT). However, issues with user privacy and the security of sensitive data in the healthcare domain make users vulnerable and reluctant to adopt these advanced solutions for promoting better healthcare. Attribute-based searchable encryption (ABSE) is a popular method for achieving fine-grained search control and has the ability to guarantee data security. However, two problems exist with directly implementing the conventional ABSE in the smart health sector. First, the encrypted health records contain sensitive health information that is visible as the access policy is sent in plaintext to the third-party cloud server. Additionally, it typically supports limited attribute universes, which unnecessarily restricts the deployments of such systems because the number of its public parameters increases in a linear fashion with the size of the attribute universe. This paper addresses these two key issues by adding an extra step for matching the attributes with an access policy, and the number of public parameters is invariable to the number of attributes which are present in the attribute universe.",Springer
"Hung, Benson K. H. and To, Catter C. N. and Fung, Ryan K. H. and Chan, Calvert C. S.",Addressing Proficiency Gaps in Future Skills Between Employers and Learners Through Data Visualization,2023,10.1007/s42979-023-01722-3,https://doi.org/10.1007/s42979-023-01722-3,Journal,SN Computer Science,"The pandemic has principally changed the way the construction industry operates. It has caused a profound shift in how we conduct our work, with a large-scale take-up of remote working and changes in our digital approach. The way we work is changing. All these impacts challenge the traditional supply chain and working practices of the construction industry negatively, resulting in price escalations, additional costs, loss of revenue, payment delays and increase in disputes and claims. This study aimed to assess the skill proficiency of learners and narrow the employers' and young engineers' perspectives on what are the future skills requirements in the construction industry in the world of digitalization. This study, which comprised two surveys entitled ``Future Skills---What does the future look like for young engineers?'' (for employers) and ``WLA Survey in ``Future Skills''---The Proficiency Analyses of Young Engineers-to-be'' (for learners), was a part of the Workplace Learning and Assessment (WLA) Engagement Series for students. This research attempts to map skill proficiency of learners (or young engineers-to-be) with the future skill requirements of the employers and to make recommendations on the construction-related institutional arrangements. A quantitative approach by using online surveys as the main data collection tool was adopted. A sample of 20 WLA-participating employers and 23 WLA-participating students in construction companies was generated. In December 2021, the project team initiated two surveys to explore the expectation for the future workforce in the construction industry. Interview results covering various construction-related disciplines, including civil engineering, building studies, surveying and building technology, were analysed and illustrated using Microsoft Power BI. Content analysis with data visualizations was used to identify major themes. This study has shown that employers and students have different perceptions of skills and attributes as critical competencies for a successful workforce. On a positive note, there was a high level of satisfaction for both employers and learners in ``Training Structure'' and ``Training and Development''. This study highlighted that students did not have the appropriate level of knowledge as expected by their employers in key subject areas of the construction industry. Employers expressed a clear expectation for the roles and responsibilities of young engineers in their organizations. Areas of practice such as building information modelling (BIM), ``Problem Solving'', and ``Presentation Skills'' were highlighted as critical for the future. The competency of youngsters in achieving targeted vision and goals as well as the competency in striving for continual improvement was identified as highly relevant for the future. There was potential for young engineers to play a more active role in their organizations and to repackage their technical skill and interpersonal skill sets for anticipated future roles. The choice of the quantitative research design approach was guided by the need to capture numerical data in the construction industry of Hong Kong for the purpose of illuminating differences in perspectives among participants about future skills for WLA implementation in vocational and professional education and training (VPET). This study can help to investigate the skill proficiency gaps that employers will be looking for and how WLA can bring maximized benefits to students and companies. Based on the results, the students can be better informed about the workplace settings and be prepared for the upcoming industrial attachment or apprenticeship programme with WLA. Feedback provided by the companies can help support students' transition into the world of work. On the other hand, by understanding learners' self-perception, this adaptation made by the companies could result in what looks to be part of a longer-term change in how we work, particularly with a move to increased use of hybrid working. The statistical models with data visualization based on Power BI can also lead to the experimentation and inference that inform the institution's strategy.",Springer
"Hasuo, Ichiro and Panangaden, Prakash",Special Issue on Quantum Physics and Logic,2016,10.1007/s00354-016-0200-7,https://doi.org/10.1007/s00354-016-0200-7,Journal,New Generation Computing,,Springer
"Das, Monidipa and Ghosh, Akash and Ghosh, Soumya K.",Does Climate Variability Impact COVID-19 Outbreak? An Enhanced Semantics-Driven Theory-Guided Model,2021,10.1007/s42979-021-00845-9,https://doi.org/10.1007/s42979-021-00845-9,Journal,SN Computer Science,"COVID-19, a life-threatening infection by novel coronavirus, has broken out as a pandemic since December 2019. Eventually, with the aim of helping the World Health Organization and other health regulators to combat COVID-19, significant research effort has been exerted during last several months to analyze how the various factors, especially the climatic aspects, impact on the spread of this infection. However, due to insufficient test and lack of data transparency, these research findings, at times, are found to be inconsistent as well as conflicting. In our work, we aim to employ a semantics-driven probabilistic framework for analyzing the causal influence as well as the impact of climate variability on the COVID-19 outbreak. The idea here is to tackle the data inadequacy and uncertainty issues using probabilistic graphical analysis along with embedded technology of incorporating semantics from climatological domain. Furthermore, the theoretical guidance from epidemiological model additionally helps the framework to better capture the pandemic characteristics. More significantly, we further enhance the impact analysis framework with an auxiliary module of measuring semantic relatedness on regional basis, so as to realistically account for the existence of multiple climate types within a single spatial region. This added notion of regional semantic relatedness further helps us to attain improved probabilistic analysis for modeling the climatological impact on this disease outbreak. Experimentation with COVID-19 datasets over 15 states (or provinces) belonging to varying climate regions in India, demonstrates the effectiveness of our semantically-enhanced theory-guided data-driven approach. It is worth noting that our proposed framework and the relevant semantic analyses are generic enough for intelligent as well as explainable impact analysis in many other application domains, by introducing minimal augmentation.",Springer
"Alghamdi, Yousef and Munir, Arslan",An Image Encryption Algorithm Based on Trivium Cipher and Random Substitution,2023,10.1007/s42979-023-02172-7,https://doi.org/10.1007/s42979-023-02172-7,Journal,SN Computer Science,"Traditional encryption algorithms are not suitable and computationally efficient for encrypting multimedia data due to the large size and high redundancy inherent in multimedia data. In this paper, a new image encryption algorithm based on nonlinear-feedback shift registers is proposed. The proposed algorithm is based on the Trivium cipher and has multiple encryption rounds. A key schedule produces the round keys from the initial secret key, and the Trivium cipher generates the key-streams for the bit-level substitution for each round utilizing the round key and an initialization vector (IV). Each round of the proposed algorithm consists of three steps, pixel-based row permutation, pixel-based column permutation, and bit-level substitution. Experimental results show that the proposed algorithm is reliably secure and outperforms the contemporary image encryption algorithms in terms of quality, efficiency, and security on most of the image encryption metrics. Furthermore, the low complexity of the proposed Trivium-based image encryption algorithm demonstrates high potential for deployment in real-time applications.",Springer
"Gyongyosi, Laszlo and Imre, Sandor",Secret Key Rate Adaption for Multicarrier Continuous-Variable Quantum Key Distribution,2019,10.1007/s42979-019-0027-7,https://doi.org/10.1007/s42979-019-0027-7,Journal,SN Computer Science,"A multicarrier continuous-variable quantum key distribution (CVQKD) protocol  uses Gaussian subcarrier quantum continuous variables (CVs) for the transmission. Here, we define an iterative error-minimizing secret key adaption method for multicarrier CVQKD. The proposed method allows for the parties to reach a given target secret key rate with minimized error rate through the Gaussian sub-channels by a sub-channel adaption procedure. The adaption algorithm iteratively determines the optimal transmit conditions to achieve the target secret key rate and the minimal error rate over the sub-channels. The solution requires no complex calculations or computational tools, allowing for easy implementation for experimental scenarios.",Springer
"Bruno, Gerwin and Devaraj, Sujitha Juliet",A Group-Centric Intelligence Recommendation System for Twitter,2020,10.1007/s42979-020-00139-6,https://doi.org/10.1007/s42979-020-00139-6,Journal,SN Computer Science,"The group-centric recommendation system develops logical collective results from the information given by Twitter users. Even though different input data formats have been used to represent user preferences, the input information mode is static. To avoid this shortcoming, this paper proposes a system which enables clients to give halfway or deficient inclination information at various occasions. Since this is an entangled issue, this paper explicitly centers around specific perspective (recommending movies) as the main endeavor. Accordingly, the re-analysis of variant input datasets, the maximum consensus mining problem, with the help of sentiment analysis, review analysis and rating analysis has merged singular proposals into clusters of suggestions under dynamic information mode suspicion. The outcome demonstrates that the proposed strategy is computationally productive and can adequately distinguish a general understanding among all clients.",Springer
"Miyazoe, Terumi and Sato, Shinichi",The Authenticity of Digital News Coverage in the Mainstream Media in Japan,2022,10.1007/s42979-022-01237-3,https://doi.org/10.1007/s42979-022-01237-3,Journal,SN Computer Science,"This research examines the authenticity of digital news coverage in the mainstream media in Japan via a specific case study, namely `Doctoral Students Have Decreased by Half'. In research, `fake news' comprises two elements, facticity and intentionality; this study focuses on facticity or misinformation. Studies regarding `fake news' are abundant, but those focussing on the mainstream digital media and Japan are highly scarce. This study applied a gap analysis, a comparison between the expected original information and the actual news coverage in a reversed direction. The study first detected and examined the original governmental data and announcements on which a series of news reports were based. Next, it drew a compare and contrast between the news on selective mainstream media and the original information. The reported drop in the number of doctoral students could be a `false alarm' for prospective target audiences, implying that digital news portals may disseminate misinformation. The analysis also revealed that the current structure of digital news making, segmented into multiformat comprising headlines, texts, videos, captions, and others, may make the information verification process more complex and obstructed for individuals. The study also points at the risk of spread of misinformation and of memory retention, amplified by the use of culture-specific symbolic numbers, which weakens our reasoning ability. The findings emphasise the importance of updating our digital media literacy and making collaborative efforts to make local research internationally sharable to advance the understanding of `fake news' research in this multimedia era.",Springer
"Dutta, Toshika and Gupta, Manish",An Intelligent Image Encryption Scheme Based on Hyperchaotic Map and Dynamic DNA Encoding,2024,10.1007/s42979-024-03224-2,https://doi.org/10.1007/s42979-024-03224-2,Journal,SN Computer Science,"With the increasing use of multimedia data over social networking websites, the use of multimedia security has become popular nowadays. This work proposed an intelligent 4D discrete hyperchaotic map based image encryption scheme along with dynamic DNA encoding. In comparison to other hyperchaotic maps, the adopted 4D hyperchaotic map is more complicated and has a greater chaotic range. In this approach, nearly every encryption phase utilizes the created hyperchaotic sequence. Using the modified Runge--Kutta method based on the trapezoid approach, a 4D hyperchaotic sequence is produced in this work. The modified Runge--Kutta method involves calculating intermediate values at various stages to obtain a more accurate approximation. Here, the input image is first transformed into binary image sequences, and the employed 4D hyperchaotic map then scrambles these sequences globally. This approach employs a 4D discrete hyperchaotic map and a two-point crossover operator to produce a unique session key for every image encryption. Additionally, the suggested system dynamically adds together DNA encoding rules along with a two-point crossover operator to improve diffusion in the system. DNA complementation and algebraic operations (DNA subtraction and DNA addition) are used in the hyperchaotic sequence in order to improve encryption performance and enhance diffusion in the suggested technique. The proposed scheme provides more confusion and diffusion in comparison to the existing similar schemes. The analysis of the proposed scheme's results demonstrates that it outperforms existing schemes, exhibiting superior average NPCR (99.6{\%}) and Entropy (7.99) values, while also exhibiting resistance against various types of attacks.",Springer
"Malaschonok, G. I.",MathPartner computer algebra,2017,10.1134/S0361768817020086,https://doi.org/10.1134/S0361768817020086,Journal,Programming and Computer Software,"In this paper, we describe general characteristics of the MathPartner computer algebra system (CAS) and Mathpar programming language thereof. MathPartner can be used for scientific and engineering calculations, as well as in high schools and universities. It allows one to carry out both simple calculations (acting as a scientific calculator) and complex calculations with large-scale mathematical objects. Mathpar is a procedural language; it supports a large number of elementary and special functions, as well as matrix and polynomial operators. This service allows one to build function images and animate them. MathPartner also makes it possible to solve some symbolic computation problems on supercomputers with distributed memory. We highlight main differences of MathPartner from other CASs and describe the Mathpar language along with the user service provided.",Springer
"Dandime, Gopal M. and Sawale, Manish D.",Enhancing the Efficiency of Solar Energy Harvesting System for Wireless Sensor Network Nodes,2023,10.1007/s42979-023-02162-9,https://doi.org/10.1007/s42979-023-02162-9,Journal,SN Computer Science,"To solve the problem of wireless sensor network (WSN) nodes' limited battery energy, this study's goal is to provide an effective solar energy harvesting method. Due to their short battery life, WSN nodes have a significant design limitation, so it's critical to look into solutions to supply a dependable and sustainable energy source for their continuous operation. The research's major contribution is to increase the efficiency of solar photovoltaic (PV) cells, a crucial form of renewable energy that can provide an efficient energy solution for WSN nodes. The research focused on the nonlinear characteristics of solar PV cells, which can result in low efficiency, and highlighted the importance of using Maximum Power Point Tracking (MPPT) to extract the maximum power. To enhance the traditional MPPT controller's performance, the research proposes incorporating a Proportional-Integral-Derivative (PID) controller and using optimization techniques to predict optimal tuning parameters. The research integrates the mutated fire-fly algorithm (MFA) for tuning the PID controller, which showed superior performance over comparative techniques. Simulation results demonstrated that our proposed solar energy harvesting system (SEHS) achieved an efficiency of 97.3{\%}, indicating a significant improvement over existing methods. This system can provide a sustainable and reliable energy source for WSN nodes, which are limited by their battery life and require efficient energy solutions for long-term operation.",Springer
"Fernau, Henning",Editorial 2023: changes and invariants,2023,10.1007/s00236-023-00447-3,https://doi.org/10.1007/s00236-023-00447-3,Journal,Acta Informatica,,Springer
"Mailler, Roger and Zheng, Huimin and Ridgway, Anton","Dynamic, distributed constraint solving and thermodynamic theory",2018,10.1007/s10458-017-9377-5,https://doi.org/10.1007/s10458-017-9377-5,Journal,Autonomous Agents and Multi-Agent Systems,"There has been an increasing recognition that a number of key computational problems require distributed solution techniques. To facilitate the creation and advancement of these techniques, researchers have developed the distributed constraint satisfaction and optimization (DCSP/DCOP) formalisms with the understanding that many critical real-world problems can be represented using them. Subsequently, these formalisms have led to the creation of numerous protocols where most ignore a critical feature of the problems they are designed to solve: the problems change over time. Dynamic variations of the DCSP and DCOP formalisms were invented to address this deficiency, but these models have received inadequate attention from the research community. A key impediment to advancing this research area is the lack of a compelling theoretical underpinning to the analysis of these problems and the evaluation of the protocols used to solve them. This work creates a mapping of the DynDCSP and DynDCOP formalisms onto thermodynamic systems. Under this mapping, it shows that these problems obey the three laws of thermodynamics. Utilizing these laws, this work develops, for the first time, a method for characterizing the impact that dynamics has on a distributed problem as well as a technique for predicting the expected performance of distributed protocols under various levels of dynamics.",Springer
"Mehdipour, S. Hamid and Machado, J. A. Tenreiro",Multidimensional analysis of particles,2022,10.1007/s42044-022-00111-y,https://doi.org/10.1007/s42044-022-00111-y,Journal,Iran Journal of Computer Science,"This paper analyses several features of fundamental and composite particles using a computational approach. Different distances are used to unravel the connections among particles emerging from their characteristics. Two clustering and visualization techniques are adopted, namely hierarchical clustering (HC) and multidimensional scaling (MDS), for comparing the particles' attributes and portraying the results in a smaller number of dimensions. In the first phase, 31 fundamental particles are assessed under the light of 6 characteristics. The Canberra and Lorentzian distances adapt well to the data set producing graphical representations consistent with the present-day knowledge. In the second phase, 88 composite particles including 21 tetraquark and 7 pentaquark candidates, described by 10 characteristics, are considered. The different cases are represented and visualized using maps created by the HC and MDS techniques. The MDS exhibits superior performance for representing the pentaquark states. Additionally, the two computational tools are tested when representing (1) normalized numerical real-valued data, and (2) categorical data. The MDS reveals that the categories' strategy captures better the main characteristics of the data set. The numerical measures allow assessing a few unmeasured spin-parity quantum numbers {\$}{\$}J^P{\$}{\$}for 5 tetraquark candidates, namely the X(4020), X(4050), X(4055), X(4100), and X(4250). Therefore, algorithmic modeling proves to be a powerful tool for exploring numerical data sets with complex information.",Springer
"Shirokov, I. E.",Computer Algebra Calculations in Supersymmetric Electrodynamics,2023,10.1134/S0361768823020147,https://doi.org/10.1134/S0361768823020147,Journal,Programming and Computer Software,"We propose a new symbolic algorithm and a C++ program for generating and calculating supersymmetric Feynman diagrams for {\$}{\$}{\backslash}mathcal{\{}N{\}} = 1{\$}{\$}supersymmetric electrodynamics regularized by higher derivatives in four dimensions. According to standard rules, the program generates all diagrams that are necessary to calculate a specific contribution to the two-point Green function of matter superfields in the needed order, and then reduces the answer to the sum of Euclidean momentum integrals. At the moment, the program was used to calculate the anomalous dimension in {\$}{\$}{\backslash}mathcal{\{}N{\}} = 1{\$}{\$}supersymmetric quantum electrodynamics, regularized by higher derivatives, in the three-loop approximation.",Springer
"Ozawa, Masanao",Quantum Set Theory Extending the Standard Probabilistic Interpretation of Quantum Theory,2016,10.1007/s00354-016-0205-2,https://doi.org/10.1007/s00354-016-0205-2,Journal,New Generation Computing,"The notion of equality between two observables will play many important roles in foundations of quantum theory. However, the standard probabilistic interpretation based on the conventional Born formula does not give the probability of equality between two arbitrary observables, since the Born formula gives the probability distribution only for a commuting family of observables. In this paper, quantum set theory developed by Takeuti and the present author is used to systematically extend the standard probabilistic interpretation of quantum theory to define the probability of equality between two arbitrary observables in an arbitrary state. We apply this new interpretation to quantum measurement theory, and establish a logical basis for the difference between simultaneous measurability and simultaneous determinateness.",Springer
"Nanduri, Sambamurthy and Kamaraju, Maddu",Energy-Efficient Median Filter Core Architecture for Impulse Noise Removal in Smart Measurement Systems,2024,10.1007/s42979-023-02530-5,https://doi.org/10.1007/s42979-023-02530-5,Journal,SN Computer Science,"In modern measurement systems, preserving accurate data integrity is essential for reliable and precise measurements. The presence of impulse noise in real-world image data can severely degrade the performance of vision algorithms. Median filtering has proven effective in attenuating impulse noise while retaining edge details. Nevertheless, traditional Median Filter architectures often exhibit high power consumption and hardware resource utilization, limiting their practical applicability in resource-constrained applications. Median filtering has proven effective for impulse noise removal while retaining critical measurement features. Nonetheless, existing architectures for Median Filters may suffer from high power consumption and hardware resource utilization, limiting their suitability for smart measurement systems.",Springer
"Sharma, Geeta and Kalra, Sheetal",A secure remote user authentication scheme for smart cities e-governance applications,2017,10.1007/s40860-017-0046-x,https://doi.org/10.1007/s40860-017-0046-x,Journal,Journal of Reliable Intelligent Environments,"Smart cities are rapidly gaining momentum and aims at improving the quality of life of citizens by adopting Information and Communication Technology. E-governance have become the smarter way of deployment of administration by the authority under its jurisdiction. The citizens can access the services of government anywhere at any time. Since this technique requires the transmission of sensitive information between the government and the citizen through the Internet, information security is of utmost importance. This paper proposes a lightweight, robust remote user authentication and key agreement protocol for e-governance applications in the smart cities. The proposed protocol is based on XOR and hash operations, and includes (1) a password and smart card, (2) user anonymity, (3) mutual authentication, (4) shared session key, and (5) key freshness. It satisfies desirable security attributes and is resistant against all well-known security attacks. Further, the formal security verification using AVISPA and informal security proves the security strength of the proposed protocol and its robustness against all possible security threats.",Springer
"Paolini, Luca and Piccolo, Mauro and Roversi, Luca",On a Class of Reversible Primitive Recursive Functions and Its Turing-Complete Extensions,2018,10.1007/s00354-018-0039-1,https://doi.org/10.1007/s00354-018-0039-1,Journal,New Generation Computing,"Reversible computing is both forward and backward deterministic. This means that a uniquely determined step exists from the previous computational configuration (backward determinism) to the next one (forward determinism) and vice versa. We present the reversible primitive recursive functions (RPRF), a class of reversible (endo-)functions over natural numbers which allows to capture interesting extensional aspects of reversible computation in a formalism quite close to that of classical primitive recursive functions. The class RPRF can express bijections over integers (not only natural numbers), is expressive enough to admit an embedding of the primitive recursive functions and, of course, its evaluation is effective. We also extend RPRF to obtain a new class of functions which are effective and Turing complete, and represent all Kleene's {\$}{\$}{\backslash}upmu {\$}{\$}-recursive functions. Finally, we consider reversible recursion schemes that lead outside the reversible endo-functions.",Springer
"Augusto, Juan Carlos and Coronato, Antonio",Editorial,2022,10.1007/s40860-022-00193-2,https://doi.org/10.1007/s40860-022-00193-2,Journal,Journal of Reliable Intelligent Environments,,Springer
"Batkhin, A. B.",Parameterization of a Set Determined by the Generalized Discriminant of a Polynomial,2018,10.1134/S0361768818020032,https://doi.org/10.1134/S0361768818020032,Journal,Programming and Computer Software,"A generalization of the classical discriminant of the real polynomial defined using the linear Hahn operator that decreases the degree of the polynomial by one is studied. The structure of the generalized discriminant set of the real polynomial, i.e., the set of values of the polynomial coefficients at which the polynomial and its Hahn operator image have a common root, is investigated. The structure of the generalized discriminant of the polynomial of degree n is described in terms of the partitions of n Algorithms for the construction of a polynomial parameterization of the generalized discriminant set in the space of the polynomial coefficients are proposed. The main steps of these algorithms are implemented in a Maple library. Examples of calculating the discriminant set are discussed.",Springer
"Shemyakova, Ekaterina",Darboux transformations for factorable Laplace operators,2014,10.1134/S0361768814030062,https://doi.org/10.1134/S0361768814030062,Journal,Programming and Computer Software,"Factorable Laplace operators of the form L = ? x ? y + a? x + b? y + c, where the coefficients a, b, c are not necessarily constants, are considered. For these operators, the Darboux transformations, M ¡Ê K[? x ], defined by the intertwining relation NL = L 1 M are considered. It is shown that only the following cases are possible: either (1) M ¡É ker? x + b = {0} and L 1 is also factorable or (2) M ¡É ker? x + b contains a nonzero element. We prove that, in both cases, the Darboux transformation can be represented as a product of first-order Darboux transformations. For case (2), the proof is based on the fact that the Darboux transformation of operator L can be reduced to Darboux transformations of first-order operators.",Springer
"Singh, Hukum and Yadav, Poonam",An optical vortex-based asymmetric cryptosystem using QZ modulation for the double image encryption in the gyrator transform,2024,10.1007/s42044-024-00196-7,https://doi.org/10.1007/s42044-024-00196-7,Journal,Iran Journal of Computer Science,"The current study proposes a new nonlinear cryptosystem that employs complex phase masks named as optical vortices (OVs) which are obtained from the phases of the radial Hilbert mask (RHM) and Toroidal Fresnel lens (TFL). The security keys used in classical optical cryptosystems are often random phase masks (RPMs), which are vulnerable to various forms of attacks including brute force attacks. To create complex images in the frequency domain with the current encryption, the amplitude images are first phase encoded, after which the OV phase mask is used to modulate them. The complex images are further processed with QZ decomposition resulting in two upper quasi-triangular matrices, two unitary matrices, and decryption keys in the gyrator transform (GT). The use of OVs, QZ decomposition and gyrator transform settings provides additional keys to expand the key space. The proposed method is asymmetric, and the decryption process requires the private keys generated during encryption. The performance of the scheme has been evaluated in terms of mean-squared-error (MSE), peak signal-to-noise ratio (PSNR), SSIM, histograms, entropy analysis, correlation analysis, noise and occlusion attacks. Numerical simulations are presented to validate the proposed encryption method in terms of its strength and reliability.",Springer
"Spector, Lee",Editorial introduction,2015,10.1007/s10710-014-9240-2,https://doi.org/10.1007/s10710-014-9240-2,Journal,Genetic Programming and Evolvable Machines,,Springer
"Bertl, Markus and Piho, Gunnar and Draheim, Dirk and Ross, Peeter and Pechmann, Ludwig and Bucciarelli, Nicholas and Sharma, Rahul",Future Opportunities for Systematic AI Support in Healthcare,2025,10.1007/978-3-031-73741-1_13,https://doi.org/10.1007/978-3-031-73741-1_13,Conference Paper,Bridging the Gap Between AI and Reality,"Artificial Intelligence (AI) holds transformative potential to revolutionize healthcare delivery and outcomes. However, the literature suggests that focusing solely on AI algorithms leads to low adoption rates. AI needs to be introduced systematically into healthcare. This paper builds on this approach and synthesizes existing literature and authors' insights to critically examine the current landscape and future opportunities for systematic AI support in healthcare. The multifaceted applications of AI, ranging from disease prediction to personalized medicine, are explored with a focus on AI's potential to optimize employee performance, alleviate healthcare staff burdens, and enhance patient care. However, challenges such as limited access to unbiased data sets, connectivity issues, and ethical concerns pose significant barriers to AI adoption in healthcare.",Springer
"Wang, Xinyi and Arcaini, Paolo and Yue, Tao and Ali, Shaukat",Generating Failing Test Suites for Quantum Programs With Search,2021,10.1007/978-3-030-88106-1_2,https://doi.org/10.1007/978-3-030-88106-1_2,Conference Paper,Search-Based Software Engineering,"Testing quantum programs requires systematic, automated, and intelligent methods due to their inherent complexity, such as their superposition and entanglement. To this end, we present a search-based approach, called Quantum Search-Based Testing (QuSBT), for automatically generating test suites of a given size depending on available testing budget, with the aim of maximizing the number of failing test cases in the test suite. QuSBT consists of definitions of the problem encoding, failure types, test assessment with statistical tests, fitness function, and test case generation with a Genetic Algorithm (GA). To empirically evaluate QuSBT, we compared it with Random Search (RS) by testing six quantum programs. We assessed the effectiveness of QuSBT and RS with 30 carefully designed faulty versions of the six quantum programs. Results show that QuSBT provides a viable solution for testing quantum programs, and achieved a significant improvement over RS in 87{\%} of the faulty programs, and no significant difference in the rest of 13{\%} of the faulty programs.",Springer
"Maruyama, Yoshihiro",Symbolic and Statistical Theories of Cognition: Towards Integrated Artificial Intelligence,2021,10.1007/978-3-030-67220-1_11,https://doi.org/10.1007/978-3-030-67220-1_11,Conference Paper,Software Engineering and Formal Methods. SEFM 2020 Collocated Workshops,"There are two types of approaches to Artificial Intelligence, namely Symbolic AI and Statistical AI. The symbolic and statistical paradigms of cognition may be considered to be in conflict with each other; the recent debate between Chomsky and Norvig exemplifies a fundamental tension between the two paradigms (esp. on language), which is arguably in parallel with a conflict on interpretations of quantum theory as seen between Bohr and Einstein, one side arguing for the probabilist or empiricist view and the other for the universalist or rationalist view. In the present paper we explicate and articulate the fundamental discrepancy between them, and explore how a unifying theory could be developed to integrate them, and what sort of cognitive r{\^o}les Integrated AI could play in comparison with present-day AI. We give, inter alia, a classification of Integrated AI, and argue that Integrated AI serves the purpose of humanising AI in terms of making AI more verifiable, more explainable, more causally accountable, more ethical, and thus closer to general intelligence. We especially emphasise the ethical advantage of Integrated AI. We also briefly touch upon the Turing Test for Ethical AI, and the pluralistic nature of Turing-type Tests for Integrated AI. Overall, we believe that the integrated approach to cognition gives the key to the next generation paradigm for AI and Cognitive Science in general, and that Categorical Integrated AI or Categorical Integrative AI Robotics would be arguably the most promising approach to it.",Springer
"Guan, Ji and Fang, Wang and Ying, Mingsheng",Robustness Verification of Quantum Classifiers,2021,10.1007/978-3-030-81685-8_7,https://doi.org/10.1007/978-3-030-81685-8_7,Conference Paper,Computer Aided Verification,"Several important models of machine learning algorithms have been successfully generalized to the quantum world, with potential speedup to training classical classifiers and applications to data analytics in quantum physics that can be implemented on the near future quantum computers. However, quantum noise is a major obstacle to the practical implementation of quantum machine learning. In this work, we define a formal framework for the robustness verification and analysis of quantum machine learning algorithms against noises. A robust bound is derived and an algorithm is developed to check whether or not a quantum machine learning algorithm is robust with respect to quantum training data. In particular, this algorithm can find adversarial examples during checking. Our approach is implemented on Google's TensorFlow Quantum and can verify the robustness of quantum machine learning algorithms with respect to a small disturbance of noises, derived from the surrounding environment. The effectiveness of our robust bound and algorithm is confirmed by the experimental results, including quantum bits classification as the ``Hello World'' example, quantum phase recognition and cluster excitation detection from real world intractable physical problems, and the classification of MNIST from the classical world.",Springer
"Maruyama, Yoshihiro","Categorical Artificial Intelligence: The Integration of Symbolic and Statistical AI for Verifiable, Ethical, and Trustworthy AI",2022,10.1007/978-3-030-93758-4_14,https://doi.org/10.1007/978-3-030-93758-4_14,Conference Paper,Artificial General Intelligence,"Statistical artificial intelligence based upon machine learning is facing major challenges such as machine bias, explainability, and verifiability problems. Resolving them would be of the utmost importance for ethical, safe, and responsible AI for social good. In this paper we propose to address these problems with the (recently rapidly developing) methodology of category theory, a powerful integrative scientific language from pure mathematics, and discuss, in particular, the possibility of the categorical integration of statistical (inductive) with symbolic (deductive) artificial intelligence. Categorical artificial intelligence arguably has the potential to resolve the aforementioned urgent problems, thus being beneficial to make artificial intelligence more ethical, verifiable, responsible, and so more human, which would be crucial for AI-pervasive society.",Springer
"Lin, Yanling and Guan, Ji and Fang, Wang and Ying, Mingsheng and Su, Zhaofeng",A obustness fication Tool for uantum Machine Learning Models,2025,10.1007/978-3-031-71162-6_21,https://doi.org/10.1007/978-3-031-71162-6_21,Conference Paper,Formal Methods,"Adversarial noise attacks present a significant threat to quantum machine learning (QML) models, similar to their classical counterparts. This is especially true in the current Noisy Intermediate-Scale Quantum era, where noise is unavoidable. Therefore, it is essential to ensure the robustness of QML models before their deployment. To address this challenge, we introduce VeriQR, the first tool designed specifically for formally verifying and improving the robustness of QML models, to the best of our knowledge. This tool mimics real-world quantum hardware's noisy impacts by incorporating random noise to formally validate a QML model's robustness. VeriQR supports exact (sound and complete) algorithms for both local and global robustness verification. For enhanced efficiency, it implements an under-approximate (complete) algorithm and a tensor network-based algorithm to verify local and global robustness, respectively. As a formal verification tool, VeriQR can detect adversarial examples and utilize them for further analysis and to enhance the local robustness through adversarial training, as demonstrated by experiments on real-world quantum machine learning models. Moreover, it permits users to incorporate customized noise. Based on this feature, we assess VeriQR using various real-world examples, and experimental outcomes confirm that the addition of specific quantum noise can enhance the global robustness of QML models. These processes are made accessible through a user-friendly graphical interface provided by VeriQR, catering to general users without requiring a deep understanding of the counter-intuitive probabilistic nature of quantum computing.",Springer
"Fornaciari, William and Reghenzani, Federico and Agosta, Giovanni and Zoni, Davide and Galimberti, Andrea and Conti, Francesco and Tortorella, Yvan and Parisi, Emanuele and Barchi, Francesco and Bartolini, Andrea and Acquaviva, Andrea and Gregori, Daniele and Cognetta, Salvatore and Ciancarelli, Carlo and Leboffe, Antonio and Serri, Paolo and Burrello, Alessio and Pagliari, Daniele Jahier and Urgese, Gianvito and Martina, Maurizio and Masera, Guido and Di Carlo, Rosario and Sciarappa, Antonio",RISC-V Processor Technologies for Aerospace Applications in the ISOLDE Project,2023,10.1007/978-3-031-46077-7_24,https://doi.org/10.1007/978-3-031-46077-7_24,Conference Paper,"Embedded Computer Systems: Architectures, Modeling, and Simulation","Modern space applications impose significant challenges to the design of hardware and software platforms. Beyond traditional applications such as avionics, Attitude Orbit Control, and signal/telemetry processing, new developments increasingly leverage Machine Learning models to enhance the autonomy of spacecraft. Such AI-based functionalities promise significant advantages, but require computing power beyond what can be provided by current on-board platforms. At the same time, the challenge of technological sovereignty requires a move towards open hardware and software. To achieve these objectives, within the KDT ISOLDE project started in 2023, we propose the development of a new family of processors for AI-based applications to be deployed on board of satellites. In this paper, we showcase some examples of space applications with their requirements, and highlight the possible solutions as well as the corresponding work that will be carried out in ISOLDE, and the expected results.",Springer
"Salm, Marie and Barzen, Johanna and Leymann, Frank and Wundrack, Philipp",Optimizing the Prioritization of Compiled Quantum Circuits by Machine Learning Approaches,2022,10.1007/978-3-031-18304-1_9,https://doi.org/10.1007/978-3-031-18304-1_9,Conference Paper,Service-Oriented Computing,"The performance of current quantum computers is limited by high error rates and few qubits. Nevertheless, more and more quantum computers are available in the cloud. Selecting a suitable quantum computer to execute a specific quantum circuit and receive precise results can be difficult. At the same time, it is crucial to choose an available quantum computer that offers the hardware characteristics required by the circuit to retrieve precise results, depending on the quantum computer's last re-calibration and the quantum compiler that maps the circuit to the hardware. Furthermore, cloud providers regulate hardware access, so waiting times must be considered. To support the choice of a quantum computer, we introduced an automated framework in previous work. It enables the user to analyze and prioritize the compiled circuits of a given input circuit for different quantum computers based on their requirements. In this work, we extend the framework by automating the prioritization of compiled circuits targeting short waiting times and precise executions based on previous results. We present our framework's prototype and case study to demonstrate and evaluate the practical feasibility.",Springer
"Stoelinga, Mari{\""e}lle","No Risk, No Fun",2025,10.1007/978-3-031-71177-0_26,https://doi.org/10.1007/978-3-031-71177-0_26,Conference Paper,Formal Methods,"The aim of this tutorial is to explain to the formal methods community the area of risk management and its most prominent concepts: the definition of risk, strategies for managing risk, the risk management cycle, and the role of ISO standards.",Springer
"Coppola, Riccardo and Ardito, Luca and Torchiano, Marco","Multi-device, Robust, and Integrated Android GUI Testing: A Conceptual Framework",2023,10.1007/978-3-031-43240-8_8,https://doi.org/10.1007/978-3-031-43240-8_8,Conference Paper,Testing Software and Systems,"Android GUI (Graphical User Interface) testing is often overlooked by developers, even if it holds the potential to guarantee sufficient quality for the apps. It is typically regarded as a burdensome activity. High maintenance costs, fragmentation, fragility, and flakiness of the test artifacts are the main hurdles for wider adoption in practice. This article identifies the main modules that could enable efficient and robust mobile testing in continuous development environments. On top of them, we sketch the infrastructure of a conceptual framework for the generation, execution, and maintenance of mobile test suites. We also present a call to action for software testers, developers, and researchers towards the framework realization in practice.",Springer
"Apak, Boran and Bandic, Medina and Sarkar, Aritra and Feld, Sebastian",KetGPT -- Dataset Augmentation of Quantum Circuits Using Transformers,2024,10.1007/978-3-031-63778-0_17,https://doi.org/10.1007/978-3-031-63778-0_17,Conference Paper,Computational Science -- ICCS 2024,"Quantum algorithms, represented as quantum circuits, can be used as benchmarks for assessing the performance of quantum systems. Existing datasets, widely utilized in the field, suffer from limitations in size and versatility, leading researchers to employ randomly generated circuits. Random circuits are, however, not representative benchmarks as they lack the inherent properties of real quantum algorithms for which the quantum systems are manufactured. This shortage of `useful' quantum benchmarks poses a challenge to advancing the development and comparison of quantum compilers and hardware.",Springer
"Vishwanathan, Harishankar and Shachnai, Matan and Narayana, Srinivas and Nagarakatte, Santosh",Verifying the Verifier: eBPF Range Analysis Verification,2023,10.1007/978-3-031-37709-9_12,https://doi.org/10.1007/978-3-031-37709-9_12,Conference Paper,Computer Aided Verification,"This paper proposes an automated method to check the correctness of range analysis used in the Linux kernel 's eBPF verifier. We provide the specification of soundness for range analysis performed by the eBPF verifier. We automatically generate verification conditions that encode the operation of the eBPF verifier directly from the Linux kernel 's C source code and check it against our specification. When we discover instances where the eBPF verifier is unsound, we propose a method to generate an eBPF program that demonstrates the mismatch between the abstract and the concrete semantics. Our prototype automatically checks the soundness of 16 versions of the eBPF verifier in the Linux kernel versions ranging from 4.14 to 5.19. In this process, we have discovered new bugs in older versions and proved the soundness of range analysis in the latest version of the Linux kernel.",Springer
"Alvarado-Valiente, Jaime and Romero-{\'A}lvarez, Javier and D{\'i}az, Ana and Rodr{\'i}guez, Mois{\'e}s and Garc{\'i}a-Rodr{\'i}guez, Ignacio and Moguel, Enrique and Garcia-Alonso, Jose and Murillo, Juan M.",Quantum Services Generation and Deployment Process: A Quality-Oriented Approach,2023,10.1007/978-3-031-43703-8_15,https://doi.org/10.1007/978-3-031-43703-8_15,Conference Paper,Quality of Information and Communications Technology,"Quantum computing technology is revolutionizing the current world and is enabling the creation of advanced applications in various fields, such as healthcare and economics. However, for the industry to carry out mass production of quantum software, it is crucial to ensure an adequate level of quality. However, as quantum technologies move towards practical applications, they face significant challenges. Depending heavily on specific platforms, developers have difficulty creating quantum applications that can run on different quantum providers. Additionally, the lack of mature tools makes the creation of quantum applications a slow and complex process that requires specialized knowledge of quantum mechanics and computer science, where the quality of quantum services can be compromised. This article addresses the need to ensure an adequate level of quality in quantum software, and proposes a process that allows for the improvement of the current generation and deployment of quantum services while evaluating the quality of the created quantum services, using an extension of the OpenAPI Specification and the SonarQube tool.",Springer
"Kuang, Fangjun and Zhang, Siyang",A Novel Multiple Sequence Alignment Algorithm Based on Artificial Bee Colony and Particle Swarm Optimization,2020,10.1007/978-981-15-8760-3_11,https://doi.org/10.1007/978-981-15-8760-3_11,Conference Paper,Recent Advances in Data Science,"Multiple sequence alignment (MSA), known as an NP-complete combinatorial optimization problem, is one of the most important and challenging tasks in bioinformatics. A novel hybrid algorithm of artificial bee colony and particle swarm optimization (HABC-PSO) for MSA is proposed in this paper to tackle this problem. The proposed method innovatively integrates Tent chaos search, opposition-based learning and recombination operator techniques. The best solutions obtained by the recombination operator are further set as the neighbor food source for onlooker bees and the global best of particle swarm, respectively. In addition, a new method of HABC-PSO algorithm for determining a food source or particle swarm in the neighborhood is proposed by exploiting the discreteness of the MSA problem. The experiment results strongly demonstrate its robustness and effectiveness, as well as achieve better performance and biological quality in comparison with its peers.",Springer
"Tomar, Veerender Singh and Ranga, Virender","An Experimental Study on Estimation of Reliability of a Computer Network for the Network of Delhi Development Authority: A Study on Challenges, Experiment and Its Results, Potential Future Avenues and Significance of Ongoing Research",2024,10.1007/978-3-031-64076-6_16,https://doi.org/10.1007/978-3-031-64076-6_16,Conference Paper,Advanced Network Technologies and Intelligent Computing,"The digitally intra networked organizations and inter-netted with world rely significantly on their networks for their performance and overall throughput including communication, data transfer and running their business. This paper presents the in-depth research study carried out on the 4000 plus nodes network of Delhi Development Authority on reliability of computer networks which can be predicted or estimated in different scenarios. Beginning with a definition, an explanation of its significance and a discussion on elements that affect it, this paper provides a broad overview of network dependability and precisely on reliability. It then delves into several methods for gauging a network's reliability, including simulation-based techniques like Monte Carlo simulation and analytical methods like Markov models and fault trees etc. This study delves deeper into methods for analysing network reliability, such as failure analysis, redundancy methods, and failure recovery plans. In addition, case studies show how network reliability can be used in practical scenario across different sectors. Challenges, potential future study avenues, and the significance of ongoing research are discussed in the last section of the paper.",Springer
"Chochliouros, Ioannis P. and Kourtis, Michail -Alexandros and Xilouris, George and Tavernier, Wouter and Sanchez, Enrique Areizaga and Anastassova, Margarita and Bolzmacher, Christian and Tcholtchev, Nikolay and Corsi, Antonello and Trakadas, Panagiotis and Millet, Marta and Xenakis, Christos and Imeri, Adnan and Bellesini, Francesco and D'Ostilio, Paride and Markakis, Albertos and Engin, Ihsan Bal and Litke, Antonis and Quarato, Lucrezia Maria and Cugat, Diego and Gardikis, Georgios and Zarakovitis, Charilaos and Bouilland, Stephane and Zaharis, Zaharias and Lessi, Christina and Arvanitozisis, Dimitrios and Spiliopoulou, Anastasia S.","OASEES: An Innovative Scope for a DAO-Based Programmable Swarm Solution, for Decentralizing AI Applications Close to Data Generation Locations",2023,10.1007/978-3-031-34171-7_7,https://doi.org/10.1007/978-3-031-34171-7_7,Conference Paper,Artificial Intelligence  Applications  and Innovations. AIAI 2023 IFIP WG 12.5 International Workshops,"As traditional linear models have proved to be ineffective in perspective of the stagnant decision-making and inefficient data federation, the pathway onwards a European data sovereignty dictates for a sustainable and circular economy across diverse market sectors. In this scope, the EU-funded OASEES project has identified the need for a novel, inclusive and disruptive approach regarding the cloud to edge continuum and swarm programmability and also supporting multi-tenant, interoperable, secure and trustworthy deployments. In the present paper we discuss actual challenges for the management and orchestration of edge infrastructure and services to exploit the potential of edge processing. Then we discuss the concept and fundamental features of the OASEES approach together with technology challenges that are to be covered by the intended system development. We also discuss, in brief, a set of several vertical edge applications with significant market impact.",Springer
"Sallinger, Sarah and Weissenbacher, Georg and Zuleger, Florian",A Formalization of Heisenbugs and Their Causes,2023,10.1007/978-3-031-47115-5_16,https://doi.org/10.1007/978-3-031-47115-5_16,Conference Paper,Software Engineering and Formal Methods,"The already challenging task of identifying the cause of a bug becomes even more cumbersome if those bugs disappear or change their behavior under observation. Such bugs occur in a range of contexts including elusive concurrency bugs as well as unintended system alterations during debugging and---as a pun on the name of Werner Heisenberg---are often referred to as Heisenbugs. Heisenbugs can be caused by various sources of nondeterminism on different system levels, many of which developers and testers might not even be aware of. This paper provides formal foundations for rigorously reasoning about causes of Heisenbugs. It provides a formal definition of Heisenbugs in terms of a hyperproperty and introduces a framework for determining the causality of Heisenbugs in presence of multiple candidate causes based on said hyperproperty. We analyze the properties of causes and the implications on practical causal analyses.",Springer
"Alonso, Juncal and Orue-Echevarria, Leire and Nedeltcheva, Galia and Di Nitto, Elisabetta",Using a Multi-sourced Methodology to Identify Challenges in Software Technologies Research,2022,10.1007/978-3-031-23298-5_10,https://doi.org/10.1007/978-3-031-23298-5_10,Conference Paper,Advances in Service-Oriented and Cloud Computing,"The software industry has a great impact in the European Union's economy as reported in a study by the European Commission [1]. However, in spite of the importance that software has in Europe, there exist several barriers that could hamper its growth. An important one is related to research and development of software technologies, and more specifically the topics that should be funded by the public programmes and policies. The current paper presents a methodology designed with the aim of providing policy-makers with recommendations on the research challenges that should be prioritized. It is a three step methodology, out of which the first one is currently implemented, namely the identification of research topics, taking as input information coming from various sources such as landscape reports, analysis of academic venues, workshops and existing funded-projects. The paper briefly details the main six challenges currently identified in the field of Software Technologies.",Springer
"Takagi, Tsubasa and Do, Canh Minh and Ogata, Kazuhiro",Automated Quantum Program Verification in Dynamic Quantum Logic,2024,10.1007/978-3-031-51777-8_5,https://doi.org/10.1007/978-3-031-51777-8_5,Conference Paper,Dynamic Logic. New Trends and Applications,"Dynamic Quantum Logic (DQL) has been used as a logical framework for manually proving the correctness of quantum programs. This paper presents an automated approach to quantum program verification at the cost of simplifying DQL to Basic Dynamic Quantum Logic (BDQL). We first formalize quantum states, quantum gates, and projections in bra-ket notation and use a set of laws from quantum mechanics and matrix operations to reason on quantum computation. We then formalize the semantics of BQDL and specify the behavior and desired properties of quantum programs in the scope of BDQL. Formal verification of whether a quantum program satisfies desired properties is conducted automatically through an equational simplification process. We use Maude, a rewriting logic-based specification/programming language, to implement our approach. To demonstrate the effectiveness of our automated approach, we successfully verified the correctness of five quantum protocols: Superdense Coding, Quantum Teleportation, Quantum Secret Sharing, Entanglement Swapping, and Quantum Gate Teleportation, using our support tool.",Springer
"Cirstea, Horatiu and Kuppe, Markus A. and Loillier, Benjamin and Merz, Stephan",Validating Traces of Distributed Programs Against TLA+ Specifications,2025,10.1007/978-3-031-77382-2_8,https://doi.org/10.1007/978-3-031-77382-2_8,Conference Paper,Software Engineering and Formal Methods,"TLA+ is a formal language for specifying systems, including distributed algorithms, that is supported by powerful verification tools. In this work we present a framework for checking if traces of distributed programs are compatible with high-level specifications written in TLA+. The problem is reduced to a constrained model checking problem, realized using the TLC model checker. Our framework consists of an API for instrumenting Java programs in order to record traces of executions, of a collection of TLA+ operators that are used for relating those traces to specifications, and of scripts for running the model checker. Crucially, traces only contain updates to specification variables rather than full values, and developers may choose to trace only certain variables. We have applied our approach to several distributed programs, detecting discrepancies between the specifications and the implementations in all cases. We discuss reasons for these discrepancies, best practices for instrumenting programs, and how to interpret the verdict produced by TLC.",Springer
"Agrawal, Pulin and Yagnik, Arpan and Dong, Daqi",Generative AI Can Be Creative Too,2024,10.1007/978-3-031-65572-2_1,https://doi.org/10.1007/978-3-031-65572-2_1,Conference Paper,Artificial General Intelligence,"Large Language Models (LLMs) have significantly influenced everyday computational tasks and the pursuit of Artificial General Intelligence (AGI). However, their creativity is limited by the conventional data they learn from, particularly lacking in novelty. To enhance creativity in LLMs, this paper introduces an innovative approach using the Learning Intelligent Decision Agent (LIDA) cognitive architecture. We describe and implement a multimodal vector embeddings-based LIDA in this paper. A LIDA agent from this implementation is used to demonstrate our proposition to make generative AI more creative, specifically making it more novel. By leveraging episodic memory and attention, the LIDA-based agent can relate memories of recent unrelated events to solve current problems with novelty. Our approach incorporates a neuro-symbolic implementation of a LIDA agent that assists in generating creative ideas while illuminating a prompting technique for LLMs to make them more creative. Comparing responses from a baseline LLM and our LIDA-enhanced agent indicates an improvement in the novelty of the ideas generated.",Springer
"Lee, Edward A.",Certainty vs. Intelligence,2025,10.1007/978-3-031-75434-0_2,https://doi.org/10.1007/978-3-031-75434-0_2,Conference Paper,Bridging the Gap Between AI and Reality,"Mathematical models can yield certainty, as can probabilistic models where the probabilities degenerate. The field of formal methods emphasizes developing such certainty about engineering designs. In safety-critical systems, such certainty is highly valued and, in some cases, even required by regulatory bodies. But achieving reasonable performance for sufficiently complex environments appears to require the use of AI technologies, which resist such certainty. This paper suggests that certainty and intelligence may be fundamentally incompatible. First, Bayes Theorem shows, rather trivially, that certainty implies an inability to learn when presented with new data. A more subtle issue, however, is that logic and mathematics, necessary for certainty, may be a result of intelligence rather than the foundations of intelligence. This paper makes the case that intelligence is an evolved form of prediction, that logic and mathematics were not discovered but rather were invented because of their predictive value, and that the certainty they can give us cannot be about systems that exhibit intelligence.",Springer
"Jain, Neetu and Porwal, Rabins",Automated Test Data Generation Applying Heuristic Approaches---A Survey,2019,10.1007/978-981-10-8848-3_68,https://doi.org/10.1007/978-981-10-8848-3_68,Conference Paper,Software Engineering,"Software testing is a systematic approach to identify the presence of errors in the developed software Pressman (Software Engineering A Practitioners Approach, Mc Graw Hill International Edition, 2010) [1], Beizer, Software Testing Techniques, Van Nostrand Reinhold Co, New York, 1990) [2], Beizer (Black Box Testing: Techniques for Functional Testing of Software and Systems, Wiley 1995) [3]. In this paper, we explore and present the challenges in software testing and how software testing techniques evolved over the period of time. Further software testing is tedious, time-consuming, cost-ineffective and does not guarantee reliability. Automation of software testing has been an area of most research in the field. Test cases play a vital role in achieving effective testing target, but generating effective test cases is equally challenging task. Heuristic approaches have gained the attention in different fields of computer science. In this paper, we discuss the need of automation of test data generation and heuristic algorithms or techniques to implement the same. We present an extensive survey of the work done in the related field by researchers and their results.",Springer
"Balicki, Jerzy",Multi-objective Quantum-Inspired Genetic Algorithm for Supervised Learning of Deep Classification Models,2023,10.1007/978-3-031-36030-5_20,https://doi.org/10.1007/978-3-031-36030-5_20,Conference Paper,Computational Science -- ICCS 2023,"Quantum decision making is an emerging field that explores how quantum computing can be used to make decisions more efficiently and effectively than classical computing. The main advantage of quantum decision making is the ability to explore multiple possible solutions to a problem simultaneously, using the principles of superposition and entanglement. A quantum-inspired genetic algorithm can improve a quality of a multi-criteria supervised learning of deep classification models. Designed classifiers can be trained by a quantum simulator with Hadamard, CNOT and rotation gates. To demonstrate advantages of the new algorithm, we analyze the Pareto-optimal classifiers for an efficient diagnosis of SARS-CoV-2 infection based on remote analysis of X-rays images with the quantum computing platform QI.",Springer
"Wu, Maochuan and Lin, Junyu and Shi, Shouchuang and Ren, Long and Wang, Zhiwen",Hybrid Optimization-Based GRU Neural Network for Software Reliability Prediction,2020,10.1007/978-981-15-7984-4_27,https://doi.org/10.1007/978-981-15-7984-4_27,Conference Paper,Data Science -- ICPCSEE 2020,"Aiming at the problems of low prediction accuracy and weak generalization ability of current reliability prediction models, this paper proposes a hybrid multi-layer heterogeneous particle swarm optimization algorithm (HMHPSO) that can simultaneously optimize the structure and parameters of the GRU neural network. It first introduced a multi-layer heteromass particle swarm optimization (MHPSO) algorithm, which sets the population topology as a hierarchical structure and introduces the concept of attractors, so as to improve the update formula of particle speed, and enhance the information interaction ability between particles, increase the diversity of the groups, thereby improving the optimization ability of the algorithm. Then the HMHPSO used the quantum particle swarm optimization (QPSO) algorithm to determine the structure of the GRU, that is, the number of hidden nodes. Experimental results show that the algorithm can generate GRU neural networks with high generalization performance and low architecture complexity, and has better prediction accuracy in software reliability prediction.",Springer
"Abbott, Vincent and Xu, Tom and Maruyama, Yoshihiro",Category Theory for Artificial General Intelligence,2024,10.1007/978-3-031-65572-2_13,https://doi.org/10.1007/978-3-031-65572-2_13,Conference Paper,Artificial General Intelligence,"Category theory has been successfully applied beyond pure mathematics and applications to artificial intelligence (AI) and machine learning (ML) have been developed. Here we first give an overview of the current development of category theory for AI and ML, and we then compare and elucidate the essential features of various category-theoretical approaches to AI and ML. Broadly, there are three types of category theory for AI and ML, namely category theory for data representation learning, category theory for learning (optimisation) algorithms and category theory for compositional architecture design and analysis. There are various approaches even within each type of category theory for AI and ML; among other things, we shed new light on the relationships between the two types of category theory for neural network architectures as have been developed by the authors recently (i.e., neural string diagrams and neural circuit diagrams). The three types of category theory can be integrated together and to that end we focus upon a categorical deep learning framework, which integrates categorical structures with a universal probabilistic programming language. We also discuss the significance of categorical approaches in relation with the ultimate goal of development of artificial general intelligence.",Springer
"Cappello, Franck and Di, Sheng and Gok, Ali Murat",Fulfilling the Promises of Lossy Compression for Scientific Applications,2020,10.1007/978-3-030-63393-6_7,https://doi.org/10.1007/978-3-030-63393-6_7,Conference Paper,"Driving Scientific and Engineering Discoveries Through the Convergence of HPC, Big Data and AI","Many scientific simulations, machine/deep learning applications and instruments are in need of significant data reduction. Error-bounded lossy compression has been identified as one solution and has been tested for many use-cases: reducing streaming intensity (instruments), reducing storage and memory footprints, accelerating computation and accelerating data access and transfer. Ultimately, users' trust in lossy compression relies on the preservation of science: same conclusions should be drawn from computations or analysis done from lossy compressed data. Experience from scientific simulations, Artificial Intelligence (AI) and instruments reveals several points: (i) there are important gaps in the understanding of the effects of lossy compressed data on computations, AI and analysis, (ii) each use-case, application and user has its own requirements in terms of compression ratio, speed and accuracy, and current generic monolithic compressors are not responding well to this need for specialization. This situation calls for more research and development on the lossy compression technologies. This paper addresses the most pressing research needs regarding the application of lossy compression in the scientific context.",Springer
"Kumara, Indika and Van Den Heuvel, Willem-Jan and Tamburri, Damian A.",QSOC: Quantum Service-Oriented Computing,2021,10.1007/978-3-030-87568-8_3,https://doi.org/10.1007/978-3-030-87568-8_3,Conference Paper,Service-Oriented Computing,"Quantum computing is quickly turning from a promise to reality, witnessing the launch of several cloud-based services that provide access to quantum resources, simulators, runtimes, and programming tools, all through the cloud. Unfortunately, however, existing solutions typically implicitly assume intimate knowledge about quantum computing concepts and operators. This vision paper introduces Quantum Service-Oriented Computing (QSOC), a model for building applications using a well-balanced mix of classical and quantum (hybrid) computing approaches. We propose a model-driven methodology that allows application developers, classical service developers, and quantum programmers to build hybrid enterprise applications collaboratively. As a result, quantum programmers and service developers can develop and publish quantum and classical components. At the same time, the application developers can discover, compose, configure and compose pre-built components to build and operate enterprise applications without intimate knowledge on the underlying quantum infrastructure, advocating knowledge reuse and separation of concerns.",Springer
"Timonen, Salla and Sroor, Maha and Mohanani, Rahul and Mikkonen, Tommi",Anomaly Detection Through Container Testing: A Survey of Company Practices,2024,10.1007/978-3-031-49266-2_25,https://doi.org/10.1007/978-3-031-49266-2_25,Conference Paper,Product-Focused Software Process Improvement,"Background: Containers are a commonly used solution for deploying software applications. Therefore, container functionality and security is a concern of practitioners and researchers. Testing is essential to ensure the quality of the container environment component and the software product and plays a crucial role in using containers.",Springer
"Sarkar, Aritra and Al-Ars, Zaid and Bertels, Koen",QKSA: Quantum Knowledge Seeking Agent,2023,10.1007/978-3-031-19907-3_37,https://doi.org/10.1007/978-3-031-19907-3_37,Conference Paper,Artificial General Intelligence,"In this research, we extend the universal reinforcement learning agent models of artificial general intelligence to quantum environments. The utility function of a classical exploratory stochastic Knowledge Seeking Agent, KL-KSA, is generalized to distance measures from quantum information theory on density matrices. Quantum process tomography (QPT) algorithms form a tractable subset of programs for modeling environmental dynamics. The optimal QPT policy is selected based on a mutable cost function based on algorithmic complexity as well as computational resource complexity. The entire agent design is encapsulated in a self-replicating quine which mutates the cost function based on the predictive value of the optimal policy choosing scheme. Thus, multiple agents with pareto-optimal QPT policies evolve using genetic programming, mimicking the development of physical theories each with different resource trade-offs. This formal framework, termed Quantum Knowledge Seeking Agent (QKSA), is a resource-bounded participatory observer modification to the recently proposed algorithmic information-based reconstruction of quantum mechanics. A proof-of-concept is implemented and available as open-sourced software.",Springer
"Huisman, Marieke and Merz, Stephan and Seceleanu, Cristina",Scalable Verification and Validation of Concurrent and Distributed Systems (ScaVeri) (Track Summary),2025,10.1007/978-3-031-75380-0_15,https://doi.org/10.1007/978-3-031-75380-0_15,Conference Paper,"Leveraging Applications of Formal Methods, Verification and Validation. Specification and Verification","Given the inherent reliance of distributed systems on concurrent programming, coupled with increased hardware concurrency and diversity, ensuring their reliability, safety, and security without compromising performance has become exceedingly challenging. This necessitates scalable verification methods that can accurately capture the behavior of concurrent and distributed systems while providing robust guarantees of compliance with specific requirements. The Scalable Verification and Validation of Concurrent and Distributed Systems (ScaVeri) track is dedicated to presenting and discussing advancements in formal methods tailored to these systems. Emphasizing scalable techniques and models that have been validated through real-world case studies, the track covers subtopics such as generating correct parallel code, compositional verification with assume-guarantee contracts, enhanced analysis for large-scale systems, and combinations of various analysis techniques, collectively aiming to improve the assurance of diverse and complex distributed computing environments.",Springer
"Chen, Yu-Fang and Chung, Kai-Min and Leng{\'a}l, Ond{\v{r}}ej and Lin, Jyun-Ao and Tsai, Wei-Lun",AutoQ: An Automata-Based Quantum Circuit Verifier,2023,10.1007/978-3-031-37709-9_7,https://doi.org/10.1007/978-3-031-37709-9_7,Conference Paper,Computer Aided Verification,"We present a specification language and a fully automated tool named AutoQ for verifying quantum circuits symbolically. The tool implements the automata-based algorithm from [14] and extends it with the capabilities for symbolic reasoning. The extension allows to specify relational properties, i.e., relationships between states before and after executing a circuit. We present a number of use cases where we used AutoQ to fully automatically verify crucial properties of several quantum circuits, which have, to the best of our knowledge, so far been proved only with human help.",Springer
"Masuda, Masahiro and Kameyama, Yukiyoshi",Unified Program Generation and Verification: A Case Study on Number-Theoretic Transform,2022,10.1007/978-3-030-99461-7_8,https://doi.org/10.1007/978-3-030-99461-7_8,Conference Paper,Functional and Logic Programming,"Giving correctness assurance to the generated code in the context of generative programming is a poorly explored problem. Such assurance is particularly desired for applications where correctness of the optimized code is far from obvious, such as cryptography.",Springer
"Limas Sierra, Robert and Guerrero-Balaguera, Juan-David and Rodriguez Condia, Josie E. and Sonza Reorda, Matteo",Analyzing the Reliability of TCUs Through Micro-architecture and Structural Evaluations for Two Real Number Formats,2024,10.1007/978-3-031-70947-0_8,https://doi.org/10.1007/978-3-031-70947-0_8,Conference Paper,VLSI-SoC 2023: Innovations for Trustworthy Artificial Intelligence,"Modern Graphics Processing Units (GPUs) include in-chip hardware accelerators (Tensor Core Units, or TCUs) to increase the performance of machine learning applications. Unfortunately, cutting-edge semiconductor technologies are increasingly prone to suffer from faults and affect devices during their operation. Moreover, the execution of safety-critical and High-Performance Computing (HPC) applications in GPUs strongly stresses crucial resources, such as TCUs, which increases the likelihood of different kinds of failures. Thus, the resilience analysis of GPUs and their critical units (TCUs) are vital in safety-critical domains, e.g., in automotive, space, and autonomous robotics, to develop effective countermeasures or improve designs. Recently, new arithmetic formats have been proposed, particularly suited to neural network processing. However, an effective reliability characterization of TCUs supporting different arithmetic formats was still missed.",Springer
"Barletta, Vita Santa and Caivano, Danilo and Lako, Alfred and Pal, Anibrata",Quantum as a Service Architecture for Security in a Smart City,2023,10.1007/978-3-031-43703-8_6,https://doi.org/10.1007/978-3-031-43703-8_6,Conference Paper,Quality of Information and Communications Technology,"Smart Cities are becoming a reality now with ample interest and investment from both government and private entities. As the number of Smart Cities increases, so does the sheer size and variety of data, the major part of which comes from Internet of Things (IoT) sensors embedded in devices. Millions of intelligent devices may be vulnerable to cyberattacks or threats, potentially harming one or more connected devices or exposing sensitive data. Therefore, Smart Cities have Intelligent Operations Centers (IOC), using different machine learning (ML) algorithms to monitor the data and take necessary actions to protect or contain any security incident. The advent of Quantum Computing (QC) has led to many initiatives for using QC in various applications of a Smart City but using Quantum Computing as a service is not yet fully contemplated in this context. In this work, we propose an architecture for Smart City security using Quantum as a Service (QaaS) for analyzing and classifying Smart City data. The proposed architecture uses two different Quantum Classifiers, implemented in the D-Wave Leap Quantum Cloud (QBoost) and IBM Quantum Services (Variational Quantum Classifier), for real-time classification of data and displays security incidents on a conveniently designed dashboard for further actions by the Security Operations Center (SOC) specialist. Further experiments have shown that D-Wave Leap Quantum Cloud-based QBoost performed the best among the quantum classifiers both regarding quality and time.",Springer
"Karn, Rupesh Raj and Gebremichael, Mizan and Nawaz, Kashif and Elfadel, Ibrahim M.",Confidential Inference in Decision Trees,2024,10.1007/978-3-031-70947-0_14,https://doi.org/10.1007/978-3-031-70947-0_14,Conference Paper,VLSI-SoC 2023: Innovations for Trustworthy Artificial Intelligence,"In confidential computing, arithmetic algorithms operate on encrypted inputs to produce encrypted outputs. Specifically, in confidential inference, Alice has the parameters of the machine-learning model but does not want to reveal them to Bob, who has the data. Bob wants to use Alice's model for inference, but does not want to reveal his data. Alice and Bob agree to use confidential computing to run the inference engine without revealing either the model or the data. However, they find that fully homomorphic and order-preserving encryptions are very time-consuming and very challenging to accelerate on hardware. When the machine learning model is a decision tree, these encryptions can be made computationally efficient and can even be readily accelerated on hardware. In this paper, we reveal how Alice and Bob run the inference engine of a decision tree in full confidence and show FPGA implementations of additively homomorphic, order-preserving, and post-quantum order-preserving encryption on constrained hardware platforms. We further evaluate the resources needed to implement the ciphertext decision tree and compare them with those of a plaintext decision tree. Confidential inference tests are run on the encrypted FPGA design using the MNIST data set.",Springer
"Ihde, Nina and Marten, Paula and Eleliemy, Ahmed and Poerwawinata, Gabrielle and Silva, Pedro and Tolovski, Ilin and Ciorba, Florina M. and Rabl, Tilmann","A Survey of Big Data, High Performance Computing, and Machine Learning Benchmarks",2022,10.1007/978-3-030-94437-7_7,https://doi.org/10.1007/978-3-030-94437-7_7,Conference Paper,Performance Evaluation and Benchmarking,"In recent years, there has been a convergence of Big Data (BD), High Performance Computing (HPC), and Machine Learning (ML) systems. This convergence is due to the increasing complexity of long data analysis pipelines on separated software stacks. With the increasing complexity of data analytics pipelines comes a need to evaluate their systems, in order to make informed decisions about technology selection, sizing and scoping of hardware. While there are many benchmarks for each of these domains, there is no convergence of these efforts. As a first step, it is also necessary to understand how the individual benchmark domains relate.",Springer
"Blackwell, Daniel and Petke, Justyna and Cao, Yazhuo and Bensoussan, Avner",Fuzzing-Based Differential Testing for Quantum Simulators,2024,10.1007/978-3-031-64573-0_6,https://doi.org/10.1007/978-3-031-64573-0_6,Conference Paper,Search-Based Software Engineering,"Quantum programs are hard to develop and test due to their probabilistic nature and the restricted availability of quantum computers. Quantum simulators have thus been introduced to help software developers. There are, however, no formal proofs that these simulators behave in exactly the way that real quantum hardware does, which could lead to errors in their implementation. Here we propose to use a search-based technique, grammar-based fuzzing, to generate syntactically valid quantum programs, and use differential testing to search for inconsistent behaviour between selected quantum simulators. We tested our approach on three simulators: Braket, Quantastica, and Qiskit. Overall, we generated and ran over 400k testcases, 2,327 of which found new coverage, and 292 of which caused crashes, hangs or divergent behaviour. Our analysis revealed 4 classes of bugs, including a bug in the OpenQASM 3 stdgates.inc standard gates library, affecting all the simulators. All but one of the bugs reported to the developers have been already fixed by them, while the remaining bug has been acknowledged as a true bug.",Springer
"Fornaciari, William and Reghenzani, Federico and Terraneo, Federico and Baroffio, Davide and Metra, Cecilia and Omana, Martin and Condia, Josie E. Rodriguez and Reorda, Matteo Sonza and Birke, Robert and Colonnelli, Iacopo and Mittone, Gianluca and Aldinucci, Marco and Mencagli, Gabriele and Iannone, Francesco and Palombi, Filippo and Zummo, Giuseppe and Cesarini, Daniele and Tesser, Federico",RISC-V-Based Platforms for HPC: Analyzing Non-functional Properties for Future HPC and Big-Data Clusters,2023,10.1007/978-3-031-46077-7_26,https://doi.org/10.1007/978-3-031-46077-7_26,Conference Paper,"Embedded Computer Systems: Architectures, Modeling, and Simulation","High-Performance Computing (HPC) have evolved to be used to perform simulations of systems where physical experimentation is prohibitively impractical, expensive, or dangerous. This paper provides a general overview and showcases the analysis of non-functional properties in RISC-V-based platforms for HPCs. In particular, our analyses target the evaluation of power and energy control, thermal management, and reliability assessment of promising systems, structures, and technologies devised for current and future generation of HPC machines. The main set of design methodologies and technologies developed within the activities of the Future and HPC {\&} Big Data spoke of the National Centre of HPC, Big Data and Quantum Computing project are described along with the description of the testbed for experimenting two-phase cooling approaches.",Springer
"Tsai, Ming-Hsien and Fu, Yu-Fu and Liu, Jiaxiang and Shi, Xiaomu and Wang, Bow-Yaw and Yang, Bo-Yin",Certified Verification for Algebraic Abstraction,2023,10.1007/978-3-031-37709-9_16,https://doi.org/10.1007/978-3-031-37709-9_16,Conference Paper,Computer Aided Verification,"We present a certified algebraic abstraction technique for verifying bit-accurate non-linear integer computations. In algebraic abstraction, programs are lifted to polynomial equations in the abstract domain. Algebraic techniques are employed to analyze abstract polynomial programs; SMT QF{\_}BV solvers are adopted for bit-accurate analysis of soundness conditions. We explain how to verify our abstraction algorithm and certify verification results. Our hybrid technique has verified non-linear computations in various security libraries such as Bitcoin and OpenSSL. We also report the certified verification of Number-Theoretic Transform programs from the post-quantum cryptosystem Kyber.",Springer
"Ozdemir, Alex and Wahby, Riad S. and Brown, Fraser and Barrett, Clark",Bounded Verification for Finite-Field-Blasting,2023,10.1007/978-3-031-37709-9_8,https://doi.org/10.1007/978-3-031-37709-9_8,Conference Paper,Computer Aided Verification,"Zero Knowledge Proofs (ZKPs) are cryptographic protocols by which a prover convinces a verifier of the truth of a statement without revealing any other information. Typically, statements are expressed in a high-level language and then compiled to a low-level representation on which the ZKP operates. Thus, a bug in a ZKP compiler can compromise the statement that the ZK proof is supposed to establish. This paper takes a step towards ZKP compiler correctness by partially verifying a field-blasting compiler pass, a pass that translates Boolean and bit-vector logic into equivalent operations in a finite field. First, we define correctness for field-blasters and ZKP compilers more generally. Next, we describe the specific field-blaster using a set of encoding rules and define verification conditions for individual rules. Finally, we connect the rules and the correctness definition by showing that if our verification conditions hold, the field-blaster is correct. We have implemented our approach in the CirC ZKP compiler and have proved bounded versions of the corresponding verification conditions. We show that our partially verified field-blaster does not hurt the performance of the compiler or its output; we also report on four bugs uncovered during verification.",Springer
"Guan, Ji and Fang, Wang and Ying, Mingsheng",Verifying Fairness in Quantum Machine Learning,2022,10.1007/978-3-031-13188-2_20,https://doi.org/10.1007/978-3-031-13188-2_20,Conference Paper,Computer Aided Verification,"Due to the beyond-classical capability of quantum computing, quantum machine learning is applied independently or embedded in classical models for decision making, especially in the field of finance. Fairness and other ethical issues are often one of the main concerns in decision making. In this work, we define a formal framework for the fairness verification and analysis of quantum machine learning decision models, where we adopt one of the most popular notions of fairness in the literature based on the intuition---any two similar individuals must be treated similarly and are thus unbiased. We show that quantum noise can improve fairness and develop an algorithm to check whether a (noisy) quantum machine learning model is fair. In particular, this algorithm can find bias kernels of quantum data (encoding individuals) during checking. These bias kernels generate infinitely many bias pairs for investigating the unfairness of the model. Our algorithm is designed based on a highly efficient data structure---Tensor Networks---and implemented on Google's TensorFlow Quantum. The utility and effectiveness of our algorithm are confirmed by the experimental results, including income prediction and credit scoring on real-world data, for a class of random (noisy) quantum decision models with 27 qubits ({\$}{\$}2^{\{}27{\}}{\$}{\$}227-dimensional state space) tripling ({\$}{\$}2^{\{}18{\}}{\$}{\$}218times more than) that of the state-of-the-art algorithms for verifying quantum machine learning models.",Springer
"Ahmed, Ibrahim H. and Hanna, Josiah P. and Fosong, Elliot and Albrecht, Stefano V.",Towards Quantum-Secure Authentication and Key Agreement via Abstract Multi-Agent Interaction,2021,10.1007/978-3-030-85739-4_2,https://doi.org/10.1007/978-3-030-85739-4_2,Conference Paper,"Advances in Practical Applications of Agents, Multi-Agent Systems, and Social Good. The PAAMS Collection","Current methods for authentication and key agreement based on public-key cryptography are vulnerable to quantum computing. We propose a novel approach based on artificial intelligence research in which communicating parties are viewed as autonomous agents which interact repeatedly using their private decision models. Authentication and key agreement are decided based on the agents' observed behaviors during the interaction. The security of this approach rests upon the difficulty of modeling the decisions of interacting agents from limited observations, a problem which we conjecture is also hard for quantum computing. We release PyAMI, a prototype authentication and key agreement system based on the proposed method. We empirically validate our method for authenticating legitimate users while detecting different types of adversarial attacks. Finally, we show how reinforcement learning techniques can be used to train server models which effectively probe a client's decisions to achieve more sample-efficient authentication.",Springer
"Azarderakhsh, Reza and Jao, David and Leonardi, Christopher",Post-Quantum Static-Static Key Agreement Using Multiple Protocol Instances,2018,10.1007/978-3-319-72565-9_3,https://doi.org/10.1007/978-3-319-72565-9_3,Conference Paper,Selected Areas in Cryptography -- SAC 2017,"Some key agreement protocols leak information about secret keys if dishonest participants use specialized public keys. We formalize these protocols and attacks, and present a generic transformation that can be made to such key agreement protocols to resist such attacks. Simply put, each party generates k different keys, and two parties perform key agreement using all {\$}{\$}k^2{\$}{\$}k2combinations of their individual keys. We consider this transformation in the context of various post-quantum key agreement schemes and analyze the attacker's success probabilities (which depend on the details of the underlying key agreement protocol) to determine the necessary parameter sizes for 128-bit security. Our transformation increases key sizes by a factor of k and computation times by {\$}{\$}k^2{\$}{\$}k2, which represents a significant cost---but nevertheless still feasible. Our transformation is particularly well-suited to supersingular isogeny Diffie-Hellman, in which one can take {\$}{\$}k=113{\$}{\$}k=113instead of the usual {\$}{\$}k=256{\$}{\$}k=256at the 128-bit quantum security level. These results represent a potential path forward towards solving the open problem of securing long-term static-static key exchange against quantum adversaries.",Springer
"Bisicchia, Giuseppe and Garc{\'i}a-Alonso, Jose and Murillo, Juan M. and Brogi, Antonio","Distributing Quantum Computations, by Shots",2023,10.1007/978-3-031-48421-6_25,https://doi.org/10.1007/978-3-031-48421-6_25,Conference Paper,Service-Oriented Computing,"Quantum Process Units (QPUs) are becoming more widely accessible to the public. Nonetheless, they still are very susceptible to noise and feature only a small amount of qubits, making it possible to only execute short quantum computations. Facing this problem, several approaches were proposed to make the most of the present situation, either by distributing the Quantum load, sending different Quantum programs to different QPUs or by distributing Quantum program fragments, by cutting a Quantum program into multiple smaller chunks. Here, we propose a change of perspective. Due to the probabilistic nature of Quantum Mechanics, it is usually required to iterate the execution of a Quantum program numerous times or shots. We suggest considering the shots dimension while determining how to distribute quantum computations. In this paper, we design and develop a methodology to distribute the shots of a Quantum program among many QPUs. Exploiting multiple QPUs improves the resilience to potential QPUs failures. Our solution also enables users to directly encode, through a proposed DSL, their own distribution strategies according to their needs and considered scenarios, offering an expressive and customisable approach. Finally, we showcase a prototype implementation and discuss a life-like use case that can only be addressed by relying on our approach.",Springer
"Anselmo, Mart{\'i}n and Vitali, Monica",A Data-Centric Approach for Reducing Carbon Emissions in Deep Learning,2023,10.1007/978-3-031-34560-9_8,https://doi.org/10.1007/978-3-031-34560-9_8,Conference Paper,Advanced Information Systems Engineering,"The growing popularity of Deep Learning (DL) in recent years has had a large environmental impact. Training models require a lot of processing and computation and therefore require a lot of energy. The size of these models and the amount of data required for training them have grown exponentially, not comparable to the performance improvements. Recently, some model-centric approaches have been proposed to limit the environmental impact of AI. This paper complements them by proposing a data-centric ``Green AI'' approach, focusing on the data preparation phase of the DL pipeline. A general methodology, valid for any DL task, is proposed. This methodology is based on analyzing data characteristics, mainly the data quality and volume dimensions, and observing how these affect carbon emissions and performance on different models. With this information, a human-in-the-loop (HITL) approach is provided to support researchers in obtaining a modified and reduced version of a dataset that can decrease the environmental impact of training while achieving a specified performance goal. To demonstrate its validity, the proposed methodology is applied to the time series classification task and a prototype has been developed which demonstrates the possibility of reducing the carbon emissions of DL training by up to 50{\%}.",Springer
"Alexander, Samuel Allen",Can Reinforcement Learning Learn Itself? A Reply to `Reward is Enough',2022,10.1007/978-3-031-12429-7_9,https://doi.org/10.1007/978-3-031-12429-7_9,Conference Paper,Software Engineering and Formal Methods. SEFM 2021 Collocated Workshops,"In their paper `Reward is enough', Silver et al. conjecture that the creation of sufficiently good reinforcement learning (RL) agents is a path to artificial general intelligence (AGI). We consider one aspect of intelligence Silver et al. did not consider in their paper, namely, that aspect of intelligence involved in designing RL agents. If that is within human reach, then it should also be within AGI's reach. This raises the question: is there an RL environment which incentivises RL agents to design RL agents?",Springer
"{\""O}zkural, Eray","Measures of Intelligence, Perception and Intelligent Agents",2022,10.1007/978-3-030-93758-4_18,https://doi.org/10.1007/978-3-030-93758-4_18,Conference Paper,Artificial General Intelligence,We explain the relevance of operator and set induction to machine learning theory as universal models of supervised and unsupervised learning. We propose a new informal definition of general intelligence based on prediction. We propose that operator induction serves as an adequate model of perception. We discuss the application of operator induction in AGI and analyze potential objections to it. We show how to construct a discrete-time reinforcement learning agent model with operator induction serving as a perception module. We propose a universal measure of intelligence based on operator induction goodness-of-fit. We discuss the close relevance of our intelligence measure to intelligent agent theory suggesting that our proposal may contribute to AI unification.,Springer
"Yadav, Harsh",Advancing Sustainable Development: Harnessing AI for Efficient and Eco-Friendly Customer Support in IoT Solutions,2025,10.1007/978-3-031-71729-1_14,https://doi.org/10.1007/978-3-031-71729-1_14,Conference Paper,"Sustainable Development through Machine Learning, AI and IoT","This research paper explores the intersection of Artificial Intelligence (AI) and Internet of Things (IoT) solutions in the context of sustainable development. Focused on enhancing customer support mechanisms, our study investigates the application of AI-driven technologies to optimize efficiency and contribute to eco-friendly practices within the IoT landscape. By analyzing the symbiotic relationship between AI and IoT in customer support, we aim to uncover innovative approaches that not only streamline user interactions but also align with sustainable development goals. The paper delves into case studies, methodologies, and key findings to provide actionable insights for businesses seeking to integrate AI-driven customer support in their IoT solutions while fostering environmental sustainability. Through this exploration, we contribute to the discourse on responsible and eco-conscious technology adoption, paving the way for a more sustainable and resilient future.",Springer
"Sicilia, Miguel-Angel and S{\'a}nchez-Alonso, Salvador and Mora-Cantallops, Mar{\c{c}}al and Garc{\'i}a-Barriocanal, Elena",On the Source Code Structure of Quantum Code: Insights from Q{\#} and QDK,2020,10.1007/978-3-030-58793-2_24,https://doi.org/10.1007/978-3-030-58793-2_24,Conference Paper,Quality of Information and Communications Technology,"A considerable number of high-level quantum programming languages have been proposed and implemented in the last years. This fact opens the possibility to study the structure of the source code of quantum software, using initially the same metrics typically used in classical software. Here we report a preliminary study in module structure and use of quantum gates in the libraries of Microsoft's quantum development platform QDK (Quantum Developer Kit) that uses a specific language, Q{\#}. The structure of dependencies and the use of primitives is analyzed across all the source code available in the Github repositories related to the platform to date.",Springer
"D'Urbano, Andrea and Catalano, Christian and Corallo, Angelo",A Perspective on the Interplay Between 5G and Quantum Computing for Secure Algorithm and Software Engineering,2024,10.1007/978-3-031-49269-3_9,https://doi.org/10.1007/978-3-031-49269-3_9,Conference Paper,Product-Focused Software Process Improvement,"With the advancement of quantum computing technology, a pressing need arises to assess its potential implications on existing systems and infrastructures. In this paper, we delve into the interplay between quantum computing and 5G technology, with a specific focus on its profound impact on cryptography and the emergence of post-quantum techniques. We analyse the potential vulnerabilities quantum computers pose to conventional cryptographic algorithms employed in 5G networks. Our research investigates the challenges and opportunities that arise at the intersection of quantum computing and 5G, ultimately aiming to contribute to the development of secure and future-proof communication systems.",Springer
"Guarda, Teresa and Torres, Washington and Augusto, Maria Fernanda",The Impact of Quantum Computing on Businesses,2022,10.1007/978-3-031-10542-5_1,https://doi.org/10.1007/978-3-031-10542-5_1,Conference Paper,Computational Science and Its Applications -- ICCSA 2022 Workshops,"Despite the fact that data science continues in a constant evolution, there are still many problems that are still impossible to solve due to processing issues, either due to the exorbitant amount of data collected, or related to the different types of data to be processed. Quantum computing in the last decade has experienced a significant boom which has allowed researchers to pose problems that until now were impossible to solve in the classical paradigm. Quantum computing promises gains by solving how we solve these challenging computational problems. Currently, creating added value and achieving new experiences for the consumer, enhanced with it combination with artificial intelligence and machine learning, being a determining factor to promote business competitive advantage. This article aims to assess the impact of quantum computing on businesses competitive advantage, through a qualitative bibliographic analysis. In this context, an extensive research was carried out in this area on Web of Science and Scopus for the period 2016--2021. The survey covers 162 papers selected for this study, 92 from Scopus and 70 from Web of Science.",Springer
"Schalkers, Merel A. and M{\""o}ller, Matthias",Learning Based Hardware-Centric Quantum Circuit Generation,2022,10.1007/978-3-031-06668-9_22,https://doi.org/10.1007/978-3-031-06668-9_22,Conference Paper,Innovations for Community Services,"In this paper we present an approach to find quantum circuits suitable to mimic probabilistic and search operations on a physical NISQ device. We present both a gradient based and a non-gradient based machine learning approach to optimize the created quantum circuits. In our optimization procedure we make use of a cost function that differentiates between the vector representing the probabilities of measurement of each basis state after applying our learned circuit and the desired probability vector. As such our quantum circuit generation (QCG) approach leads to thinner quantum circuits which behave better when executed on physical quantum computers. Our approach moreover ensures that the created quantum circuit obeys the restrictions of the chosen hardware. By catering to specific quantum hardware we can avoid unforeseen and potentially unnecessary circuit depth, and we return circuits that need no further transpilation. We present the results of running the created circuits on quantum computers by IBM, Rigetti and Quantum Inspire.",Springer
"Oddi, Angelo and Rasconi, Riccardo and Baioletti, Marco and Santucci, Vieri Giuliano and Beck, Hamish",Quantum Circuit Compilation for the Graph Coloring Problem,2023,10.1007/978-3-031-27181-6_26,https://doi.org/10.1007/978-3-031-27181-6_26,Conference Paper,AIxIA 2022 -- Advances in Artificial Intelligence,"In this work we investigate the performance of greedy randomised search (GRS) techniques to the problem of compiling quantum circuits that solve instances of the Graph Coloring problem. Quantum computing uses quantum gates that manipulate multi-valued bits (qubits). A quantum circuit is composed of a number of qubits and a series of quantum gates that operate on those qubits, and whose execution realises a specific quantum algorithm.",Springer
"Belesioti, Maria and Trevlakis, Stylianos and Sanchez-Iborra, Ramon and Asensio-Garriga, Rodrigo and Chochliouros, Ioannis P. and Arvanitozisis, Dimitris and Fortuna, Carolina and de Vicente Gutierrez, Francisco Javier and Soukaras, Sotiris and Kavallieros, Dimitris",Beyond 5G Networking: The Case of NANCY Project,2024,10.1007/978-3-031-63227-3_2,https://doi.org/10.1007/978-3-031-63227-3_2,Conference Paper,Artificial Intelligence Applications and Innovations. AIAI 2024 IFIP WG 12.5 International Workshops,"With the global deployment of the fifth-generation (5G) wireless networks, the exploration of Beyond 5G (B5G)/sixth-generation (6G) wireless communications has begun. It is foreseen that related technologies will exhibit superior characteristics compared to their predecessors, encompassing higher transfer speeds, expanded coverage, enhanced reliability, greater energy efficiency, reduced latency and, notably, an integrated ``human-centric'' network infrastructure driven by Artificial Intelligence (AI). This study underscores the imperative need for AI methodologies and security across various resources such as spectrum, computing and storage, provided by the advanced blockchain features in the forthcoming 6G era. Use cases posed by these B5G technologies aim to leverage its inherent features of decentralization, transparency, anonymity and resiliency, while blockchain can foster cooperative trust among disparate network entities. Furthermore, the paper elucidates insights into Blockchain Radio Access Networks (B-RANs) gleaned from the EU-funded research project NANCY [1], whose pillars and architecture are highlighted, providing an overview of the core advancements it can offer.",Springer
"Priya, Siddharth and Kahsai, Temesghen and Gurfinkel, Arie",Unlocking the Power of Environment Assumptions for Unit Proofs,2025,10.1007/978-3-031-77382-2_21,https://doi.org/10.1007/978-3-031-77382-2_21,Conference Paper,Software Engineering and Formal Methods,"Clearly articulating the assumptions of the execution environment is crucial for the successful application of code-level formal verification. The process of specifying a model for the environment can be both laborious and error-prone, often requiring domain experts. In contrast, when engineers write unit tests, they frequently employ mocks (tMocks) to define the expected behavior of the environment in which the function under test operates. These tMocks describe how the environment behaves, e.g., the return types of an external API call (stateless behaviour) or the correct sequence of function calls (stateful behaviour). Mocking frameworks have proven to be highly effective tools for crafting unit tests. In our work, we draw inspiration from tMocks and introduce their counterpart in the realm of formal verification, which we term vMocks. vMocks offer an intuitive framework for specifying a plausible environment when conducting code-level formal verification. We implement a vMock library for the verification of C programs called SeaMock. We investigate the practicality of vMocks by, first, comparing specifications styles in the communication layer of the Android Trusty Trusted Execution Environment (TEE) open source project, and second, in the verification of mbedTLS, a widely used open source C library that provides secure communication protocols and cryptography primitives for embedded systems. Based on our experience, we conclude that vMocks complement other forms of environment models. We believe that vMocks ease adoption of code-level formal verification among developers already familiar with tMocks.",Springer
"Bui, Duong and Halunen, Kimmo and Nguyen, Nhan and R{\""o}ning, Juha",Quantum Algorithms: Application and Feasibility,2025,10.1007/978-3-031-78392-0_10,https://doi.org/10.1007/978-3-031-78392-0_10,Conference Paper,"Product-Focused Software Process Improvement. Industry-, Workshop-, and Doctoral Symposium Papers","In this paper, we evaluate the feasibility of quantum algorithms for practical applications and categorize them into three types: green, yellow, and red. Green means the most feasible, while red means the least feasible. We select four quantum algorithms from the Algebraic and Number Theoretic fields, four from the Optimization field, six from the Machine Learning field, and four from the Oracular field to assess their feasibility. Our results show that some quantum algorithms can be applied to solve real-life problems in the near future, while other fields may take a long time to be practically applied. The feasibility assessment is obtained by considering whether there are requirements in the quantum algorithms that are hard to satisfy with current quantum technologies and predicting how much time it will require for those requirements to be satisfied in the future. We also provide a table summarizing the feasibility evaluation results of these quantum algorithms.",Springer
"Rezayat, Sarmad and Burmester, Gerrit and Ma, Hui and Hartmann, Sven",Conceptual Framework for Designing Hippocratic APIs,2025,10.1007/978-3-031-75872-0_19,https://doi.org/10.1007/978-3-031-75872-0_19,Conference Paper,Conceptual Modeling,"The rapid proliferation of Application Programming Interfaces (APIs) enhances data exchange. Still, it introduces significant privacy and security risks, especially in the Internet of Things (IoT), where APIs often lack mechanisms to manage privacy and security, leading to vulnerabilities. Hippocratic Databases (HDBs) provide mechanisms, e.g., purpose-based access, to control database use. However, to effectively manage data access to the HDB, proper API design is crucial. This paper proposes a conceptual framework for a Hippocratic API (HAPI), revising traditional API design aiming to protect data subjects' rights and enhance security. By embedding data protection and ethical standards into API operations, HAPIs rectify inadequacies in consent mechanisms and mitigate privacy risks. We identify non-functional requirements, design objectives, and techniques through extensive research of recent literature, informed by the ethical principles of the GDPR, ISO/IEC 27001, and HDBs. We present our findings by knowledge graphs, providing a comprehensive conceptual view of the relevant design knowledge.",Springer
"Piatrenka, Ilya and Rusek, Marian",Quantum Variational Multi-class Classifier for the Iris Data Set,2022,10.1007/978-3-031-08760-8_21,https://doi.org/10.1007/978-3-031-08760-8_21,Conference Paper,Computational Science -- ICCS 2022,Recent advances in machine learning on quantum computers have been made possible mainly by two discoveries. Mapping the features into exponentially large Hilbert spaces makes them linearly separable---quantum circuits perform linear operations only. The parameter-shift rule allows for easy computation of objective function gradients on quantum hardware---a classical optimizer can then be used to find its minimum. This allows us to build a binary variational quantum classifier that shows some advantages over the classical one. In this paper we extend this idea to building a multi-class classifier and apply it to real data. A systematic study involving several feature maps and classical optimizers as well as different repetitions of the parametrized circuits is presented. The accuracy of the model is compared both on a simulated environment and on a real IBM quantum computer.,Springer
"Alidoust, Mohammadreza","On VEI, AGI Pyramid, and Energy",2023,10.1007/978-3-031-33469-6_1,https://doi.org/10.1007/978-3-031-33469-6_1,Conference Paper,Artificial General Intelligence,"This paper is the extension of my recent paper which was presented at the AGI-22 conference. In this paper, I try to answer the comments I received during and after the conference and to clarify and explain in more details the points and results that were missed or omitted from my previous paper due to the page limitation of the proceedings.",Springer
"Sukhomlin, Vladimir and Zubareva, Elena",Analytical Review of the Current Curriculum Standards in Information Technologies,2020,10.1007/978-3-030-46895-8_1,https://doi.org/10.1007/978-3-030-46895-8_1,Conference Paper,Modern Information Technology and IT Education,"The article provides us with an analytical overview of the current state (the beginning of 2018) of the curriculum system for undergraduate and graduate programs in computing (computing is the academic name of the field of Information Technology or IT), inter alia it considers: definition of the concept of curriculum, modern architecture of the curriculum system, construction principles and content of relevant curricula of the last decade, including the following documents: CC2005, CS2013, CE2016, SE2014, GSwE2009, IS2010, MSIS2016, IT2017, CSEC2017. The article provides a comparative analysis of curricula in terms of methodological solutions in describing educational content and learning objectives, highlighting the minimum required part of the curriculum knowledge (core), composition and methods of using didactic parameters for describing pedagogical emphasis on curricula and learning outcomes. The article will be useful for methodologists-developers of curricula and educational standards, in particular for comparing the domestic educational regulatory and methodological base with international experience in standardizing curricula in the field of training IT personnel. The information presented in the article can also be useful to students and graduate students to understand the international structure of the methodological foundations of the modern IT education system.",Springer
"Lee, Chien-Sing",An Exploration Towards Sustainable Metaverse Systems for e-Learning by Student Designers: A Meta-analysis,2023,10.1007/978-3-031-37126-4_33,https://doi.org/10.1007/978-3-031-37126-4_33,Conference Paper,Computational Science and Its Applications -- ICCSA 2023 Workshops,"The metaverse has caught the imagination and investments of many. However, in developing countries, the metaverse may raise more questions, than answers. As such, this study aims to investigate first, student-designers' perceptions towards what and how they want the metaverse to be like, and whether students would prioritize information flow; second, the efficacy of triangulating 3 usability-HCI questionnaires; third, whether student-designers would be more interested, creative, and be more confident in designing and developing for interconnecting (non) metaverse (eco)systems. Findings from alpha-beta user testings of Figma prototypes indicate preference for balance between structure and freedom/creativity, enhanced by user feedback and open ecosystems. Mind maps, sequencing of chain of effects in descending order, and the derived hierarchical relationship reflect centralities in design, and continuums in notions of what sustainable interconnected systems in the metaverse may be like. They are influenced by how perspectives, objectives, utility functions, and evaluation criteria, dynamically affect shifts in these centrality of design (dy/dx) over time (dy/dt), based on demographics. Loosely coupled pointer-based systems, are thus viable complements to integration.",Springer
"Reuter, Julia and Martinek, Viktor and Herzog, Roland and Mostaghim, Sanaz",Unit-Aware Genetic Programming for the Development of Empirical Equations,2024,10.1007/978-3-031-70055-2_11,https://doi.org/10.1007/978-3-031-70055-2_11,Conference Paper,Parallel Problem Solving from Nature -- PPSN XVIII,"When developing empirical equations, domain experts require these to be accurate and adhere to physical laws. Often, constants with unknown units need to be discovered alongside the equations. Traditional unit-aware genetic programming (GP) approaches cannot be used when unknown constants with undetermined units are included. This paper presents a method for dimensional analysis that propagates unknown units as ``jokers'' and returns the magnitude of unit violations. We propose three methods, namely evolutive culling, a repair mechanism, and a multi-objective approach, to integrate the dimensional analysis in the GP algorithm. Experiments on datasets with ground truth demonstrate comparable performance of evolutive culling and the multi-objective approach to a baseline without dimensional analysis. Extensive analysis of the results on datasets without ground truth reveals that the unit-aware algorithms make only low sacrifices in accuracy, while producing unit-adherent solutions.",Springer
"Chen, Yu-Fang and R{\""u}mmer, Philipp and Tsai, Wei-Lun",A Theory of Cartesian Arrays (with Applications in Quantum Circuit Verification),2023,10.1007/978-3-031-38499-8_10,https://doi.org/10.1007/978-3-031-38499-8_10,Conference Paper,Automated Deduction -- CADE 29,"We present a theory of Cartesian arrays, which are multi-dimensional arrays with support for the projection of arrays to sub-arrays, as well as for updating sub-arrays. The resulting logic is an extension of Combinatorial Array Logic (CAL) and is motivated by the analysis of quantum circuits: using projection, we can succinctly encode the semantics of quantum gates as quantifier-free formulas and verify the end-to-end correctness of quantum circuits. Since the logic is expressive enough to represent quantum circuits succinctly, it necessarily has a high complexity; as we show, it suffices to encode the k-color problem of a graph under a succinct circuit representation, an NEXPTIME-complete problem. We present an NEXPTIME decision procedure for the logic and report on preliminary experiments with the analysis of quantum circuits using this decision procedure.",Springer
"Vietz, Daniel and Barzen, Johanna and Harzenetter, Lukas and Leymann, Frank and Weder, Benjamin",Integrating Artifact Translation Into Model Transformation Processes,2025,10.1007/978-3-031-72578-4_3,https://doi.org/10.1007/978-3-031-72578-4_3,Conference Paper,Service-Oriented Computing,"Model transformation is a critical aspect of modern software engineering, enabling the effective development, maintenance, and evolution of software systems while improving their quality, correctness, and interoperability. However, one issue arises when a model under transformation references artifacts such as source code files or binary executables: Model transformations typically do not consider the referenced artifacts, resulting in the possibility of them becoming incompatible with the final model after transformation. As a result, the referenced artifacts often require manual adaptations which can be complex, time-consuming, and error-prone. To address this issue, we present an approach that integrates artifact translation mechanisms into the model transformation process. In addition to the translation between different concrete artifacts during model transformation, our approach also enables the use of abstract artifacts in models in order to translate them into concrete artifacts during model refinement, which is a special type of model transformation. To validate the practical feasibility of our approach, we present a prototype and two case studies in the domain of quantum software engineering.",Springer
"Fonseca, Alcides and Santos, Paulo and Silva, Sara",The Usability Argument for Refinement Typed Genetic Programming,2020,10.1007/978-3-030-58115-2_2,https://doi.org/10.1007/978-3-030-58115-2_2,Conference Paper,Parallel Problem Solving from Nature -- PPSN XVI,"The performance of Evolutionary Algorithms is frequently hindered by arbitrarily large search spaces. In order to overcome this challenge, domain-specific knowledge is often used to restrict the representation or evaluation of candidate solutions to the problem at hand. Due to the diversity of problems and the unpredictable performance impact, the encoding of domain-specific knowledge is a frequent problem in the implementation of evolutionary algorithms.",Springer
"Tang, Weipeng and Pan, Yan and Xu, Haojie and Ge, Yisu",Quantum Genetic Algorithm with Fuzzy Control Based on Clustering Analysis,2023,10.1007/978-981-99-6483-3_28,https://doi.org/10.1007/978-981-99-6483-3_28,Conference Paper,Intelligent Robotics and Applications,"Finding the solution of NP hard problem is an interesting puzzle, and numerous evolutionary algorithms are proposed to accelerate the speed of searching. In recent decades, the quantum computer technology has gradually improved, which is a new tool to reduce the searching time. In order to extend the genetic algorithm in quantum computer for faster convergence, the quantum genetic algorithm with fuzzy control based on clustering analysis is proposed. The operations of genetic algorithm are replaced by the quantum gate circuit First, quantum genetic algorithm is put forward, and the quantum superposition is applied to replace the mutation operation in genetic algorithm. Second, clustering analysis is employed to depict the distribution of solutions. Third, fuzzy control is used to adjust the reproduction parameter adaptively based on the results of clustering analysis. The experiments are designed for proving the performance of the proposed method with different algorithms.",Springer
"Cybulski, Jacob L. and Zaj{\k{a}}c, Sebastian",Design Considerations for Denoising Quantum Time Series Autoencoder,2024,10.1007/978-3-031-63778-0_18,https://doi.org/10.1007/978-3-031-63778-0_18,Conference Paper,Computational Science -- ICCS 2024,"This paper explains the main design decisions in the development of variational quantum time series models and denoising quantum time series autoencoders. Although we cover a specific type of quantum model, the problems and solutions are generally applicable to many other methods of time series analysis. The paper highlights the benefits and weaknesses of alternative approaches to designing a model, its data encoding and decoding, ansatz and its parameters, measurements and their interpretation, and quantum model optimization. Practical issues in training and execution of quantum time series models on simulators, including those that are CPU and GPU based, as well as their deployment on quantum machines, are also explored. All experimental results are evaluated, and the final recommendations are provided for the developers of quantum models focused on time series analysis.",Springer
"Cruz-Lemus, Jos{\'e} A. and Marcelo, Luis A. and Piattini, Mario",Towards a Set of Metrics for Quantum Circuits Understandability,2021,10.1007/978-3-030-85347-1_18,https://doi.org/10.1007/978-3-030-85347-1_18,Conference Paper,Quality of Information and Communications Technology,"Quantum computing is the basis of a new revolution. Several quantum computers are already available and, with them, quantum programming languages, quantum software development kits and platforms, quantum error correction and optimization tools are proposed and presented continuously. In connection with this, disciplines such as the Quantum Software Engineering are appearing for applying the knowledge acquired through time in their corresponding classical relatives. Besides, measurement is well known as a key factor for assessing, and improving if needed, the quality of any model in terms of, for instance, its understandability. The easier to understand a model is, the easier to maintain, reuse, etc. In this work, we present the definition of a set of metrics for assessing the understandability of quantum circuits. Some examples of the calculation of the metrics are also presented. This is just the beginning of a more thorough process in which they will be empirically validated by the performance of empirical studies, especially experiments.",Springer
"Kiltz, Eike and Lyubashevsky, Vadim and Schaffner, Christian",A Concrete Treatment of Fiat-Shamir Signatures in the Quantum Random-Oracle Model,2018,10.1007/978-3-319-78372-7_18,https://doi.org/10.1007/978-3-319-78372-7_18,Conference Paper,Advances in Cryptology -- EUROCRYPT 2018,"The Fiat-Shamir transform is a technique for combining a hash function and an identification scheme to produce a digital signature scheme. The resulting scheme is known to be secure in the random oracle model (ROM), which does not, however, imply security in the scenario where the adversary also has quantum access to the oracle. The goal of this current paper is to create a generic framework for constructing tight reductions in the QROM from underlying hard problems to Fiat-Shamir signatures.",Springer
"Dai, Aochu and Ying, Mingsheng",QReach: A Reachability Analysis Tool for Quantum Markov Chains,2024,10.1007/978-3-031-65633-0_23,https://doi.org/10.1007/978-3-031-65633-0_23,Conference Paper,Computer Aided Verification,"We present QReach, the first reachability analysis tool for quantum Markov chains based on decision diagrams CFLOBDD (presented at CAV 2023). QReach provides a novel framework for finding reachable subspaces, as well as a series of model-checking subprocedures like image computation. Experiments indicate its practicality in verification of quantum circuits and algorithms. QReach is expected to play a central role in future quantum model checkers.",Springer
"Cinal, Adrian and Wechta, Gabriel and Wro{\'{n}}ski, Micha{\l}",Hybrid Approach to Public-Key Algorithms in the Near-Quantum Era,2024,10.1007/978-3-031-63778-0_27,https://doi.org/10.1007/978-3-031-63778-0_27,Conference Paper,Computational Science -- ICCS 2024,"Application of post-quantum algorithms in newly deployed cryptosystems is necessary nowadays. In the NIST Post-Quantum Competition several algorithms that seem to be resistant against attacks mounted using quantum computers have been chosen as finalists. However, it is worth noting that one of finalists---SIKE---was catastrophically broken by a classical attack of Castryck and Decru only a month after qualifying for the final round. This shows that absolute trust cannot yet be placed in the algorithms being standardized. And so a proposition was made to use the novel, post-quantum schemes alongside the well-studied classical ones with parameters chosen appropriately to remain secure against quantum attacks at least temporarily, i.e., until a large enough quantum computer is built.",Springer
"Kotagiri, Anudeep and Bammidi, Tirupathi Rao",Sustainable Safeguarding: Implementing Fraud Defense Systems for Authorized Push Payments Through Robotics Process Automation and AI Integration,2025,10.1007/978-3-031-71729-1_13,https://doi.org/10.1007/978-3-031-71729-1_13,Conference Paper,"Sustainable Development through Machine Learning, AI and IoT","This research paper investigates the development and implementation of a robust fraud defense system for Authorized Push Payments (APP) by seamlessly integrating Robotics Process Automation (RPA) and Artificial Intelligence (AI) technologies. Titled ``Sustainable Safeguarding'', the paper explores the synergy between RPA and AI in fortifying APP transactions against fraudulent activities. The research delves into the intricacies of creating a sophisticated defense mechanism while ensuring sustainability by minimizing environmental impact. Through a comprehensive analysis of real-world scenarios, the paper demonstrates the effectiveness of the proposed system in enhancing security and protecting financial transactions. The integration of sustainable practices underscores a forward-thinking approach, aligning technological advancements with environmental responsibility. This research contributes to the ongoing discourse on the intersection of financial technology, security, and sustainability, offering insights for both industry practitioners and researchers navigating the evolving landscape of digital finance.",Springer
"Martens, Julian and Kumara, Indika and Monsieur, Geert and Heuvel, Willem-Jan Van Den and Tamburri, Damian Andrew",QuantumShare: Towards an Ontology for Bridging the Quantum Divide,2023,10.1007/978-3-031-47262-6_22,https://doi.org/10.1007/978-3-031-47262-6_22,Conference Paper,Conceptual Modeling,"As quantum computing matures, organizations must engage early with the technology and eventually adopt it in their business operations to achieve a competitive edge. At the same time, quantum computing experts (e.g., researchers and technology providers) expect extensive input and collaboration with potential adopters to explore new application areas. However, the inherently counter-intuitive and complex theoretical principles of quantum theory discourage non-expert adopters of the technology from engaging in research and development. As a result, an increasing knowledge gap emerges. This paper proposes the QuantumShare ontology to capture and share quantum computing knowledge to support the collaboration between quantum experts and non-expert adopters, thereby bridging the present knowledge gap. We used the NeOn methodology to create QuantumShare systematically. We evaluated QuantumShare by applying it to the usage scenarios extracted from the literature and end-users.",Springer
"Munford, C. S.",Epistolution: How a Systems View of Biology May Explain General Intelligence,2022,10.1007/978-3-030-93758-4_17,https://doi.org/10.1007/978-3-030-93758-4_17,Conference Paper,Artificial General Intelligence,"The genes-first view of life provides a theory of traits interacting with ecological niches, and of genes as determinants of these traits, but fails to link the two with a logic of physiology. How are genes selected for expression? It is on this level of physiology that intelligence appears. In this paper, I propose a formula by which epistemology, the sources of knowledge, and evolution might be united---an ``epistolution'' that offers in principle a testable synthesis to predict organismic behavior. Perhaps organisms and their microbiota, through allostasis, mediate between their ecological niches and their DNA. Perhaps they form networks nested within networks that are sensitive enough to synchronize with their niches using the formula: if used, then reinforce; else mutate stochastically.",Springer
"Stirbu, Vlad and Mikkonen, Tommi","Quantum Software Ecosystem: Stakeholders, Interactions and Challenges",2024,10.1007/978-3-031-53227-6_33,https://doi.org/10.1007/978-3-031-53227-6_33,Conference Paper,Software Business,"The emergence of quantum computing proposes a revolutionary paradigm that can radically transform numerous scientific and industrial application domains. The ability of quantum computers to scale computations imply better performance and efficiency for certain algorithmic tasks than current computers provide. However, to gain benefit from such improvement, quantum computers must be integrated with existing software systems, a process that is not straightforward. In this paper, we investigate the quantum computing ecosystem and the stakeholders involved in building larger hybrid classical-quantum systems. In addition, we discuss the challenges that are emerging at the horizon as the field of quantum computing becomes more mature.",Springer
"Bonilla, Javier and Moguel, Enrique and Garc{\'i}a-Alonso, Jos{\'e} and Canal, Carlos",Integration of Classical and Quantum Services Using an Enterprise Service Bus,2024,10.1007/978-3-031-49269-3_11,https://doi.org/10.1007/978-3-031-49269-3_11,Conference Paper,Product-Focused Software Process Improvement,"Early advancements in quantum computing have opened up new possibilities to tackle complex problems across various fields, including mathematics, physics, and healthcare. However, the technology required to construct systems where different quantum and classical software components collaborate is currently lacking. To address this, substantial progress in service-oriented quantum computing is necessary, empowering developers to create and operate quantum services and microservices that are comparable to their classical counterparts. The main objective of this work is to establish the essential technological infrastructure for integrating an Enterprise Service Bus (ESB). This integration enables developers to implement quantum algorithms through independent and automatable services, thereby facilitating the collaboration of quantum and classical software components. Additionally, this work has been validated through a practical case using Zato, a platform that supports service-oriented architectures. By achieving this goal, developers can harness the power of quantum computing while benefiting from the flexibility, scalability, and efficiency of service-oriented computing. This integration opens up new possibilities for developing advanced quantum applications and tackling real-world challenges across various domains.",Springer
"Mantovani, Marco and Momigliano, Alberto",Towards Substructural Property-Based Testing,2022,10.1007/978-3-030-98869-2_6,https://doi.org/10.1007/978-3-030-98869-2_6,Conference Paper,Logic-Based Program Synthesis and Transformation,We propose to extend property-based testing to substructural logics to overcome the current lack of reasoning tools in the field. We take the first step by implementing a property-based testing system for specifications written in the linear logic programming language Lolli. We employ the foundational proof certificates architecture to model various data generation strategies. We validate our approach by encoding a model of a simple imperative programming language and its compilation and by testing its meta-theory via mutation analysis.,Springer
"Wang, Zihao and Zhang, Xiaofei",AI-Assisted Exploration of the Spirit of Place in Chinese Gardens from the Perspective of Spatial Sequences,2023,10.1007/978-3-031-37189-9_19,https://doi.org/10.1007/978-3-031-37189-9_19,Conference Paper,Computer-Aided Architectural Design. INTERCONNECTIONS: Co-computing Beyond Boundaries,"The Chinese garden style is not only a decorative aesthetic but also a composition of spaces. Chinese gardening is about creating narrative spatial sequences, and the composition of the views in each space is also important. We propose to simulate these approaches with AI. Firstly, we used the pix2pix algorithm to generate a plan layout and determine the paths that connect the spatial sequences. secondly, we will enter the first-person view. Whereas traditional architects design by plans and axonometric drawings, our work focuses on the `spirit of place'. We used Isovist to simulate the spatial elements that one sees as he or she moves through space over time and encoded these spatial elements, then we chose RNN (LSTM) to learn this spatial sequence composition of the `spirit of place', and to generate a practical project with the `spirit of place' in Chinese gardens. The RNN (LSTM) model can handle the information of the sequence well, that is, the input before and the input after are related, and in a spatial sequence, the spatial nodes before and the spatial nodes after will also jointly form a sense of spatial rhythm. Finally we tried to materialize the model with CycleGAN to refine the workflow of the auxiliary architectural design. We tested this methodology in a renovation program for a Chinese village to observe the `spirit of place' created by AI(Artificial Intelligence). This approach could potentially be applied to other user experience-oriented aided designs. Our objective is to establish a workflow that enables architects to collaborate better with AI.",Springer
"Lewis, Marco and Zuliani, Paolo and Soudjani, Sadegh",Verification of Quantum Systems Using Barrier Certificates,2023,10.1007/978-3-031-43835-6_24,https://doi.org/10.1007/978-3-031-43835-6_24,Conference Paper,Quantitative Evaluation of Systems,"Various techniques have been used in recent years for verifying quantum computers, that is, for determining whether a quantum computer/system satisfies a given formal specification of correctness. Barrier certificates are a recent novel concept developed for verifying properties of dynamical systems. In this article, we investigate the usage of barrier certificates as a means for verifying behaviours of quantum systems. To do this, we extend the notion of barrier certificates from real to complex variables. We then develop a computational technique based on linear programming to automatically generate polynomial barrier certificates with complex variables taking real values. Finally, we apply our technique to several simple quantum systems to demonstrate their usage.",Springer
"von Berg, Benjamin and Aichernig, Bernhard K. and Rindler, Maximilian and {\v{S}}tern, Darko and Tappler, Martin",Hierarchical Learning of Generative Automaton Models from Sequential Data,2025,10.1007/978-3-031-77382-2_13,https://doi.org/10.1007/978-3-031-77382-2_13,Conference Paper,Software Engineering and Formal Methods,"Passive automata learning is a method for inferring automaton models from a given collection of observations of system behavior (traces). It has been applied to reactive systems with probabilistic behavior. In particular, IOAlergia is a well known algorithm for inferring models in the form of deterministically labeled Markov decision processes from system traces. The quality of the resulting model depends heavily on the provided data set and suffers if data is scarce. However, in many cases additional knowledge about the system is available. This work aims to incorporate knowledge about system modes into the learning process in order to improve model quality for low-data scenarios. This is done by splitting the traces according to system modes, learning individual models for each mode and combining those models into one model with sub-regions corresponding to individual system modes. In our evaluation on artificial models, our method outperforms the baseline in at least 90 {\%} of cases for all considered metrics. This method was developed to learn generative models of human driving behavior. Data from recorded test drives on highways was used to learn a hierarchical stochastic model of typical acceleration behavior of human drivers. In the automotive industry, such models make the simulations of driving emissions more realistic.",Springer
"Salm, Marie and Barzen, Johanna and Leymann, Frank and Weder, Benjamin and Wild, Karoline",Automating the Comparison of Quantum Compilers for Quantum Circuits,2021,10.1007/978-3-030-87568-8_4,https://doi.org/10.1007/978-3-030-87568-8_4,Conference Paper,Service-Oriented Computing,"For very specific problems, quantum advantage has recently been demonstrated. However, current NISQ computers are error-prone and only support small numbers of qubits. This limits the executable circuit size of an implemented quantum algorithm. Due to this limitation, it is important that compiled quantum circuits for a specific quantum computer are as resource-efficient as possible. A variety of different quantum compilers exists supporting different programming languages, gate sets, and vendors of quantum computers. However, comparing the results of several quantum compilers requires (i) deep technical knowledge and (ii) large manual effort for translating a given circuit into different languages. To tackle these challenges, we present a framework to automate the translation, compilation, and comparison of a given quantum circuit with multiple quantum compilers to support the selection of the most suitable compiled quantum circuit. For demonstrating the practical feasibility of the framework, we present a prototypical implementation.",Springer
"Stirbu, Vlad and Haghparast, Majid",Quantum Algorithm Cards: Streamlining the Development of Hybrid Classical-Quantum Applications,2024,10.1007/978-3-031-49269-3_13,https://doi.org/10.1007/978-3-031-49269-3_13,Conference Paper,Product-Focused Software Process Improvement,"The emergence of quantum computing proposes a revolutionary paradigm that can radically transform numerous scientific and industrial application domains. The ability of quantum computers to scale computations implies better performance and efficiency for certain algorithmic tasks than current computers provide. However, to gain benefit from such improvement, quantum computers must be integrated with existing software systems, a process that is not straightforward. In this paper, we investigate challenges that emerge when building larger hybrid classical-quantum computers and introduce the Quantum Algorithm Card (QAC) concept, an approach that could be employed to facilitate the decision making process around quantum technology.",Springer
"Guo, Qian and Johansson, Thomas and Nilsson, Alexander",A Key-Recovery Timing Attack on Post-quantum Primitives Using the Fujisaki-Okamoto Transformation and Its Application on FrodoKEM,2020,10.1007/978-3-030-56880-1_13,https://doi.org/10.1007/978-3-030-56880-1_13,Conference Paper,Advances in Cryptology -- CRYPTO 2020,"In the implementation of post-quantum primitives, it is well known that all computations that handle secret information need to be implemented to run in constant time. Using the Fujisaki-Okamoto transformation or any of its different variants, a CPA-secure primitive can be converted into an IND-CCA secure KEM. In this paper we show that although the transformation does not handle secret information apart from calls to the CPA-secure primitive, it has to be implemented in constant time. Namely, if the ciphertext comparison step in the transformation is leaking side-channel information, we can launch a key-recovery attack.",Springer
"Marchesi, Lodovica and Marchesi, Michele and Tonelli, Roberto",Reviewing Crypto-Agility and Quantum Resistance in the Light of Agile Practices,2024,10.1007/978-3-031-48550-3_21,https://doi.org/10.1007/978-3-031-48550-3_21,Conference Paper,Agile Processes in Software Engineering and Extreme Programming -- Workshops,"The term crypto-agility means the ability to quickly and securely change cryptographic algorithms and related data, in the case of their compromise. In this context, the advent of quantum computing constitutes a new paradigm, which poses existential threats to current cryptographic algorithms. Even if these attacks are not an imminent danger, we must be prepared to change the cryptographic algorithms at risk with new, quantum resistant ones. This is by no means an easy task, because cryptographic algorithms are used everywhere and are often also implemented on the hardware. In this paper, we analyze the similarities and the differences between traditional agility and crypto-agility, and investigate the prospects of using agile and lean practices in the context of crypto-agility to introduce quantum resistant algorithms. In particular, for the main agile and lean practices we discuss if and how they can be useful for obtaining crypto-agility. We also investigate how the features key to crypto-agility can be helped by the agile and lean approach.",Springer
"Cardwell, Suma George and Vineyard, Craig and Severa, Willam and Chance, Frances S. and Rothganger, Frederick and Wang, Felix and Musuvathy, Srideep and Teeter, Corinne and Aimone, James B.",Truly Heterogeneous HPC: Co-design to Achieve What Science Needs from HPC,2020,10.1007/978-3-030-63393-6_23,https://doi.org/10.1007/978-3-030-63393-6_23,Conference Paper,"Driving Scientific and Engineering Discoveries Through the Convergence of HPC, Big Data and AI","Future high-performance computing (HPC) platforms increasingly depend on heterogeneous node architectures to meet power and performance requirements. While modern HPC design largely incorporates GPUs with CPU resources, there is potential to further integrate novel forms of computing. The ability to leverage efficient, non-conventional computing technologies would be a fundamentally disruptive development in advancing HPC. Neuromorphic computing is such an emerging technology, which would interest the HPC community, due to its potential for implementing large-scale calculations with an extremely low power footprint. We will explore the example of mapping the connectome of the brain to illustrate advantages of using a heterogeneous system that incorporates neuromorphic hardware.",Springer
"Herber, Paula and Adelt, Julius and Tasche, Philip",Formal Verification of Cyber-Physical Systems Using Domain-Specific Abstractions,2025,10.1007/978-3-031-77382-2_1,https://doi.org/10.1007/978-3-031-77382-2_1,Conference Paper,Software Engineering and Formal Methods,"Cyber-physical systems have become ubiquitous in our daily lives, and their complexity continually evolves to unprecedented levels. In addition to their heterogeneity and interaction with a physical environment, we see a tremendous increase in the use of learning to make autonomous decisions in dynamic environments. These developments pose significant challenges for ensuring safety and resilience of cyber-physical systems. Formal methods have the potential to guarantee such properties under all circumstances. However, they are expensive and severely suffer from scalability issues. To improve scalability and applicability of formal methods, it is highly desirable to exploit domain-specific knowledge. In this paper, we summarize some of our recent efforts towards reusable specification and more scalable verification of cyber-physical systems using domain-specific abstractions.  In particular, we present our ideas to use domain-specific abstractions to provide 1) reusable semantics encodings that enable us to automatically transform domain-specific system design languages such as SystemC or Simulink into a formal representation, and 2) reusable specification mechanisms for contracts and invariants that can be used for deductive verification of safety and resilience of reactive, hybrid, and learning systems. We discuss promising results and open problems, and identify challenges for future work.",Springer
"Jaques, Samuel and Schanck, John M.",Quantum Cryptanalysis in the RAM Model: Claw-Finding Attacks on SIKE,2019,10.1007/978-3-030-26948-7_2,https://doi.org/10.1007/978-3-030-26948-7_2,Conference Paper,Advances in Cryptology -- CRYPTO 2019,"We introduce models of computation that enable direct comparisons between classical and quantum algorithms. Incorporating previous work on quantum computation and error correction, we justify the use of the gate-count and depth-times-width cost metrics for quantum circuits. We demonstrate the relevance of these models to cryptanalysis by revisiting, and increasing, the security estimates for the Supersingular Isogeny Diffie--Hellman (SIDH) and Supersingular Isogeny Key Encapsulation (SIKE) schemes. Our models, analyses, and physical justifications have applications to a number of memory intensive quantum algorithms.",Springer
"Sharma, Rattan and Singhal, Mayank",Sustainable Transport Using AI and IoT,2025,10.1007/978-3-031-71729-1_25,https://doi.org/10.1007/978-3-031-71729-1_25,Conference Paper,"Sustainable Development through Machine Learning, AI and IoT","This paper provides a comprehensive analysis of the integration of AI and IoT into sustainable transportation, emphasizing the broad definition of sustainable transportation and its role in social, economic, and environmental well-being. It explores the challenges facing modern transportation systems, the importance of sustainable mobility, and the potential of AI and emerging technologies to revolutionize transportation. The paper delves into the application of AI and IoT in optimizing traffic flow, enhancing safety, and orchestrating real-time traffic intelligence. It also highlights the potential of AI and emerging technologies in transforming Indian Railways, addressing challenges related to efficiency, safety, passenger experience, and environmental sustainability.",Springer
"Tribastone, Mirco and J{\""a}hnichen, Stefan and Wirsing, Martin",Introduction to the REoCAS Colloquium in Honor of Rocco De Nicola's 70th Birthday,2025,10.1007/978-3-031-73709-1_1,https://doi.org/10.1007/978-3-031-73709-1_1,Conference Paper,"Leveraging Applications of Formal Methods, Verification and Validation. REoCAS Colloquium in Honor of Rocco De Nicola","This volume contains the proceedings of the Colloquium in honor of Rocco De Nicola's 70th birthday, held jointly with the ISOLA 2024's track on REoCAS (Rigorous Engineering of Collective Adaptive Systems). Rocco De Nicola has significantly contributed to collective adaptive systems through novel approaches for their formal specification, analysis, and verification. The Colloquium features one homage paper and 23 contributions from invited authors who reflected upon these developments within the context of Rocco's much broader legacy in concurrency theory, distributed systems, domain-specific languages, service-oriented computing, and formal methods, exploring his recent contributions to cybersecurity.",Springer
"Toirov, Sh. A. and Boynazarov, I. M. and Abatov, Sh. A. and Mirsaidov, B. M. and Ruziyeva, Z.",Optimization with Quantum Algorithm that is Based on Grover's Method,2023,10.1007/978-3-031-31353-0_7,https://doi.org/10.1007/978-3-031-31353-0_7,Conference Paper,Information Technologies and Intelligent Decision Making Systems,"This article reviews the processes of solving the global optimization problems by Grover's method of quantum algorithm, and presents all the solutions that are possible at the same time in solving global optimization problems by quantum algorithm and the methods of identifying the correct result. Searching for a solution to a global optimization task is typical for a systematic analysis. Adoption of optimal solutions and management of complex systems in information uncertainty and dangerous conditions have been developing for many years in various directions. In recent years, the solution to this problem is considered successful as a new form of intelligent computing. One of such intellectual computation is Grover's method of quantum algorithm. The software for solving the optimization problems based on the quantum algorithm is developed and the obtained results are analyzed.",Springer
"Simonetti, Marco and Perri, Damiano and Gervasi, Osvaldo",An Example of Use of Variational Methods in Quantum Machine Learning,2022,10.1007/978-3-031-10592-0_43,https://doi.org/10.1007/978-3-031-10592-0_43,Conference Paper,Computational Science and Its Applications -- ICCSA 2022 Workshops,This paper introduces a deep learning system based on a quantum neural network for the binary classification of points of a specific geometric pattern (Two-Moons Classification problem) on a plane.,Springer
"Hassan, Tayyabah and Khan, Wajiha Ajmal and Ahmad, Fahad and Rizwan, Muhammad and Rehman, Rabia",Edge Caching Framework in Fog Based Radio Access Networks Through AI in Quantum Regime,2020,10.1007/978-981-15-5232-8_61,https://doi.org/10.1007/978-981-15-5232-8_61,Conference Paper,Intelligent Technologies and Applications,"Fog Computing based Radio Access Networks are a promising paradigm for 5th Generation wireless communication technology (5G) having edge devices endowed with some caching and storage capacity, as a key component for reducing caching burden on the cloud server and providing fast access and retrieval at F-UEs in a scenario where IoT based devices requiring ultra-low latency will be used extensively. The amount of static as well as dynamic data requests generated by these real-time applications will be unpredictable and unmanageable shortly causing fronthaul congestion. In order to avoid performance degradation of F-RANs in near future, cache resource allocation strategies to increase cache hit ratio, must be redefined in a further better way. Quantum computing, on the other hand, seems to be the future for every kind of classical computing problem having non-linearity and exponential growth of computation and memory with a linear increase in Quantum bits due to its parallelism. In this paper, AI has been engaged in an attempt to enhance the caching capability in F-APs by updating caching content intelligently in quantum regime, accelerating computational speed and facilitating limited storage concerns. To validate our proposed framework, certain simulations are carried out in MATLAB. The results show an inevitable outcomes for F-RANs performance up gradation.",Springer
"Schmidt, Heinz W.",How to Bake Quantum into Your Pet Petri Nets and Have Your Net Theory Too,2021,10.1007/978-3-030-87568-8_1,https://doi.org/10.1007/978-3-030-87568-8_1,Conference Paper,Service-Oriented Computing,"Petri nets have found widespread use among many application domains, not least due to their human-friendly graphical syntax for the composition of interacting distributed and asynchronous processes and services, based in partial-order dependencies and concurrent executions. Petri nets also come with abstract semantics, and mathematical methods for compositional synthesis, structural checks and behavioural analysis. These have led to the use of various kinds of nets for real-time, distributed and parallel programming languages, software and services systems, with a view to their interfaces and interaction protocols. These affordances make Petri nets invaluable for distributed software architecture approaches focused on components, their mutual dependencies and environment-facing interactions. Quantum computing -- and in particular quantum software engineering -- is in its infancy and could benefit from the accumulated insights of software architecture research and of net theory, its methods, and its applications.",Springer
"van Dommelen, Melanie R. and Phillipson, Frank",QUBO Formulation for Sparse Sensor Placement for Classification,2024,10.1007/978-3-031-60433-1_2,https://doi.org/10.1007/978-3-031-60433-1_2,Conference Paper,Innovations for Community Services,"The demand for facial recognition technology has grown in various sectors over the past decade, but the need for efficient feature selection methods is crucial due to high-dimensional data complexity. This paper explores the potential of quantum computing for Sparse Sensor Placement optimisation (SSPO) in facial image classification. It studies a well known Filter Approach, based on statistical measures like Pearson correlation and Mutual Information, as it offers computational simplicity and speed. The proposed Quadratic Unconstrained Binary optimisation (QUBO) formulation for SSPO, inspired by the Quadratic Programming Feature Selection approach, aims to select a sparse set of relevant features while minimising redundancy. QUBO formulations can be solved by simulated annealing and by quantum annealing. Two experiments were conducted to compare the QUBO with a machine learning (ML) approach. The results showed that the QUBO approach, utilising simulated annealing, achieved an accuracy between random placed sensors and ML based sensors. The ML algorithm outperformed the QUBO approach, likely due to its ability to capture relevant features more effectively. The QUBO approach's advantage lies in its much shorter running time. The study suggests potential improvements by using Mutual Information instead of Pearson correlation as a measure of feature relevance. Additionally, it highlights the limitations of quantum annealers' current connectivity and the need for further advancements in quantum hardware.",Springer
"Zhandry, Mark",Quantum Lightning Never Strikes the Same State Twice,2019,10.1007/978-3-030-17659-4_14,https://doi.org/10.1007/978-3-030-17659-4_14,Conference Paper,Advances in Cryptology -- EUROCRYPT 2019,"Public key quantum money can be seen as a version of the quantum no-cloning theorem that holds even when the quantum states can be verified by the adversary. In this work, we investigate quantum lightning where no-cloning holds even when the adversary herself generates the quantum state to be cloned. We then study quantum money and quantum lightning, showing the following results:We demonstrate the usefulness of quantum lightning beyond quantum money by showing several potential applications, such as generating random strings with a proof of entropy, to completely decentralized cryptocurrency without a block-chain, where transactions is instant and local.We give Either/Or results for quantum money/lightning, showing that either signatures/hash functions/commitment schemes meet very strong recently proposed notions of security, or they yield quantum money or lightning. Given the difficulty in constructing public key quantum money, this suggests that natural schemes do attain strong security guarantees.We show that instantiating the quantum money scheme of Aaronson and Christiano [STOC'12] with indistinguishability obfuscation that is secure against quantum computers yields a secure quantum money scheme. This construction can be seen as an instance of our Either/Or result for signatures, giving the first separation between two security notions for signatures from the literature.Finally, we give a plausible construction for quantum lightning, which we prove secure under an assumption related to the multi-collision resistance of degree-2 hash functions. Our construction is inspired by our Either/Or result for hash functions, and yields the first plausible standard model instantiation of a non-collapsing collision resistant hash function. This improves on a result of Unruh [Eurocrypt'16] which is relative to a quantum oracle.",Springer
"Moussa, Charles and Wang, Hao and Calandra, Henri and B{\""a}ck, Thomas and Dunjko, Vedran",Tabu-Driven Quantum Neighborhood Samplers,2021,10.1007/978-3-030-72904-2_7,https://doi.org/10.1007/978-3-030-72904-2_7,Conference Paper,Evolutionary Computation in Combinatorial Optimization,"Combinatorial optimization is an important application targeted by quantum computing. However, near-term hardware constraints make quantum algorithms unlikely to be competitive when compared to high-performing classical heuristics on large practical problems. One option to achieve advantages with near-term devices is to use them in combination with classical heuristics. In particular, we propose using quantum methods to sample from classically intractable distributions -- which is the most probable approach to attain a true provable quantum separation in the near-term -- which are used to solve optimization problems faster. We numerically study this enhancement by an adaptation of Tabu Search using the Quantum Approximate Optimization Algorithm (QAOA) as a neighborhood sampler. We show that QAOA provides a flexible tool for exploration-exploitation in such hybrid settings and can provide evidence that it can help in solving problems faster by saving many tabu iterations and achieving better solutions.",Springer
"Bernstein, Daniel J. and Lange, Tanja and Martindale, Chloe and Panny, Lorenz",Quantum Circuits for the CSIDH: Optimizing Quantum Evaluation of Isogenies,2019,10.1007/978-3-030-17656-3_15,https://doi.org/10.1007/978-3-030-17656-3_15,Conference Paper,Advances in Cryptology -- EUROCRYPT 2019,"Choosing safe post-quantum parameters for the new CSIDH isogeny-based key-exchange system requires concrete analysis of the cost of quantum attacks. The two main contributions to attack cost are the number of queries in hidden-shift algorithms and the cost of each query. This paper analyzes algorithms for each query, introducing several new speedups while showing that some previous claims were too optimistic for the attacker. This paper includes a full computer-verified simulation of its main algorithm down to the bit-operation level.",Springer
"Atchade Adelomou, Parfait and Golobardes Rib{\'e}, Elisabet and Vilas{\'i}s Cardona, Xavier",Using the Variational-Quantum-Eigensolver (VQE) to Create an Intelligent Social Workers Schedule Problem Solver,2020,10.1007/978-3-030-61705-9_21,https://doi.org/10.1007/978-3-030-61705-9_21,Conference Paper,Hybrid Artificial Intelligent Systems,"The scheduling problem of social workers is a class of combinatorial optimization problems that can be solved in exponential time at best. Because is belongs to class of problems known as NP-Hard, which have huge impact huge impact on our society. Nowadays, the focus on the quantum computer should no longer be just for its enormous computing capacity but also for the use of its imperfection, (Noisy Intermediate-Scale Quantum (NISQ) era) to create a powerful machine learning device that uses the variational principle to solve the optimization problem by reducing their complexity's class. We propose a formulation of the Vehicle Rooting Problem (VRP) with time windows to solve efficiently the social workers schedule problem using Variational Quantum Eigensolver (VQE). The quantum feasibility of the algorithm will be modelled with docplex and tested on IBMQ computers.",Springer
"Lam{\.{z}}a, Tomasz and Zawalska, Justyna and Sterzel, Mariusz and Rycerz, Katarzyna",Software Aided Approach for Constrained Optimization Based on QAOA Modifications,2023,10.1007/978-3-031-36030-5_10,https://doi.org/10.1007/978-3-031-36030-5_10,Conference Paper,Computational Science -- ICCS 2023,"We present two variants of the QAOA modification for solving constrained combinatorial problems. The results presented in this paper were obtained using the QHyper framework, which we developed specifically for this purpose. More specifically, we use the created framework to compare the QAOA results with its two modifications, namely: Weight-Free QAOA (WF-QAOA) and Hyper QAOA (H-QAOA). Additionally, we compare the Basin-hopping global optimization method for subsequent sampling of the initial points for the proposed QAOA modifications with a simple Random Search. The results obtained for the Knapsack Problem indicate that the proposed solution outperforms the original QAOA algorithm and can be promising for QUBO, where adjusting the relative importance of the cost function and the constraints is a significant challenge.",Springer
"Shpigelman, Yuval and Shainer, Gilad and Graham, Richard and Qin, Yong and Cisneros-Stoianowski, Gerardo and Stunkel, Craig",NVIDIA's Quantum InfiniBand Network Congestion Control Technology and Its Impact on Application Performance,2022,10.1007/978-3-031-07312-0_2,https://doi.org/10.1007/978-3-031-07312-0_2,Conference Paper,High Performance Computing,"Applications running on large scale systems often suffer from degraded performance and lack of reproducible run-times due to network-level congestion, whether caused by the application network traffic itself, or by unrelated background network traffic (i.e. other applications). This paper describes the hardware-based congestion control algorithm implemented in NVIDIA's Quantum HDR 200 Gb/s InfiniBand generation and the AI-based training used to obtain algorithm parameters. The hardware leverages NVIDIA's Data Center Quantized Congestion Notification (DCQCN) algorithm and protocol and applies it to the InfiniBand network layer. Congestion patterns described in the literature are studied and enhanced to create greater congestion and are used to study the impact of such patterns on three applications: Incompact3D, LAMMPS and VASP. The study shows that network congestion increases individual measured application run time by up to a factor of ten or greater, while introduction of the implemented congestion control on the Quantum HDR InfiniBand technology recovers most of the lost time for the tested applications and congestion.",Springer
"Fehlmann, Thomas and Kranich, Eberhard",Requirements Engineering for Cyber-Physical Products,2023,10.1007/978-3-031-42307-9_23,https://doi.org/10.1007/978-3-031-42307-9_23,Conference Paper,"Systems, Software and Services Process Improvement","Today's cyber-physical products are software-intense. That means that the software process is decisive for the ability of these products to learn and adapt behavior, but in turn also to physically harm humans or the environment. Because such systems learn, change their behavior, unlearn, and adapt to their environment makes not only testing a challenge, but also requirements engineering.",Springer
"Piatkowski, Nico and M{\""u}cke, Sascha",Real-Part Quantum Support Vector Machines,2024,10.1007/978-3-031-70371-3_9,https://doi.org/10.1007/978-3-031-70371-3_9,Conference Paper,Machine Learning and Knowledge Discovery in Databases. Research Track and Demo Track,"In recent years, quantum computing has been slowly transitioning from a purely theoretical branch of computer science to a practical yet highly experimental discipline. Within quantum computing, quantum machine learning is becoming more and more popular. However, subtle differences between classical and quantum machine learning methods sometimes lead to incompatible formalizations of otherwise well aligned methods. Inspired by this observation, we investigate a classical machine learning method, namely support vector machines, and compare the model to state-of-the-art quantum support vector machines (QSVM). We show that the training procedure for QSVMs does not perform margin maximization, thus deviating from the strict definition of SVMs. Moreover, we propose a novel Real-Part QSVM formulation that overcomes this issue. We prove that our Real-Part QSVM converges to the classical SVM, while enjoying a logarithmic space complexity. Results obtained from quantum simulations as well as from a 27-qubit superconducting quantum processor confirm our theoretical findings. The source code is available at: https://github.com/np84/realqsvm.",Springer
"Zhao, Rui and Guan, Donghai and Jin, Yuanfeng and Xiao, Hui and Yuan, Weiwei and Tu, Yaofeng and Khattak, Asad Masood",Hard Disk Failure Prediction via Transfer Learning,2021,10.1007/978-981-16-3150-4_43,https://doi.org/10.1007/978-981-16-3150-4_43,Conference Paper,Big Data and Security,"Due to the large-scale growth of data, the storage scale of data centers is getting larger and larger. Hard disk is the main storage medium, once a failure occurs, it will bring huge losses to users and enterprises. In order to improve the reliability of storage systems, many machine learning methods have been widely employed to predict hard disk failure in the past few decades. However, due to the large number of different models of hard disks in the heterogeneous disk system, traditional machine learning methods cannot build a general model. Inspired by a DANN based unsupervised domain adaptation approach for image classification, in this paper, we propose the DFPTL (Disk Failure Prediction via Transfer Learning) approach, which introduce the DANN approach to predict failure in heterogeneous disk systems by reducing the distribution differences between different models of disk datasets. This approach only needs unlabeled data (the target domain) of a specific disk model and the labeled data (the source domain) collected from a different disk model from the same manufacturer. Experimental results on real-world datasets demonstrate that DFPTL can achieve adaptation effect in the presence of domain shifts and outperform traditional machine learning algorithms.",Springer
"Karimi, Leila and Little, Connor and Choudhury, Salimur",A Pattern Mining Heuristic for the Extension of Multi-trip Vehicle Routing,2024,10.1007/978-3-031-53025-8_6,https://doi.org/10.1007/978-3-031-53025-8_6,Conference Paper,"Optimization, Learning Algorithms and Applications","Multi-trip vehicle routing problem with a variable number of wagons significantly reduces the number of vehicles and drivers needed to service customers. It is often hard to solve these problems in acceptable CPU times using exact algorithms when the problem contains very big real-world data sets. We use meta-heuristic algorithms to get a solution close to the optimal solutions for vehicle routing problems with a dynamic capacity of a vehicle. First, local search heuristics applied with genetic algorithms are proposed. Then, a pattern-mining algorithm is developed to improve the solutions found from the genetic algorithm. We perform detailed experiments on Solomon instances for vehicle routing problem with time windows (VRPTW). Our experiments establish the effectiveness of the algorithms.",Springer
"Aydin, Furkan and Kashyap, Priyank and Potluri, Seetal and Franzon, Paul and Aysu, Aydin",DeePar-SCA: Breaking Parallel Architectures of Lattice Cryptography via Learning Based Side-Channel Attacks,2020,10.1007/978-3-030-60939-9_18,https://doi.org/10.1007/978-3-030-60939-9_18,Conference Paper,"Embedded Computer Systems: Architectures, Modeling, and Simulation","This paper proposes the first deep-learning based side-channel attacks on post-quantum key-exchange protocols. We target hardware implementations of two lattice-based key-exchange protocols---Frodo and NewHope---and analyze power side-channels of the security-critical arithmetic functions. The challenge in applying side-channel attacks stems from the single-trace nature of the protocols: each new execution will use a fresh and unique key, limiting the adversary to a single power measurement. Although such single-trace attacks are known, they have been so far constrained to sequentialized designs running on simple micro-controllers. By using deep-learning and data augmentation techniques, we extend those attacks to break parallelized hardware designs, and we quantify the attack's limitations. Specifically, we demonstrate single-trace deep-learning based attacks that outperform traditional attacks such as horizontal differential power analysis and template attacks by up to 900{\%} and 25{\%}, respectively. The developed attacks can therefore break implementations that are otherwise secure, motivating active countermeasures even on parallel architectures for key-exchange protocols.",Springer
"Pluck, Graham and Cerone, Antonio and Villagomez-Pacheco, David","Executive Function and Intelligent Goal-Directed Behavior: Perspectives from Psychology, Neurology, and Computer Science",2023,10.1007/978-3-031-26236-4_27,https://doi.org/10.1007/978-3-031-26236-4_27,Conference Paper,Software Engineering and Formal Methods. SEFM 2022 Collocated Workshops,"The concept of executive function, as top-down control of processes, originated in computer science in the 1950s. However, it has since become an important concept in a range of human sciences, particularly for its explanatory power in psychology, education, and clinical neurosciences. Nevertheless, its use has been limited by vague definitions and confusion between the related conceptualizations of executive process and intelligence. Here we explore the concept of executive control in detail, drawing on psychology, neurology, and computer science/human-machine interaction. We explore both computationalist and embodied cognition approaches. We describe the core goal-directed and resource-limited features of executive control, its fractionation into components, and partial overlap with psychometric conceptions of intelligence. We also examine its associations with neurological systems beyond those usually linked to executive function (i.e., the frontal lobes). We propose that executive functions are `intelligent', and can be defined by their goal-directedness. Furthermore, executive function tasks can be classified by their task goals into one of three types: Those that involve i) convergent, or ii) divergent thinking, or iii) not responding, such as in psychomotor response inhibition. Conventional intelligence tests measure only convergent thinking. The recognition of non-convergent executive functions allows the identification of executively controlled intelligent goal-directed behavior beyond that controlled by domain-general cognitive processes. This reconceptualization may benefit research in education, clinical and cognitive sciences, as well as the quest for artificial general intelligence.",Springer
"Xu, Guanghua and Dai, Zifeng and Liu, Zhihong and Zhang, Chen and Zhang, Bin and Zhang, Changsheng",Accelerating Method of Evolutionary Ensemble Learning Based on Gaussian Random Field,2021,10.1007/978-3-030-72792-5_23,https://doi.org/10.1007/978-3-030-72792-5_23,Conference Paper,Simulation Tools and Techniques,"In recent years, research on ensemble learning of neural networks is very popular. As a research hotspot in the field of machine learning, ensemble learning methods can effectively improve the accuracy and generalization of deep network models, but not all neural networks are suitable for participating in the construction of ensemble model. Deep network ensemble learning requires a single neural network participating in the ensemble to have a high accuracy rate, and there is a large difference between the networks. In the initial stage of deep network ensemble learning, the generation process of the candidate deep network set is first required. In this article, a multi-objective evolutionary ensemble model is improved, and an evolutionary ensemble learning acceleration method based on Gaussian random field is added before the evaluation of fitness function which can screen individuals with great potential for improvement in the evaluation of fitness function during the generation of candidate deep network sets, thereby effectively improving the quality of the solution and reduce the time spent training neural networks. This pre-screening strategy is applied to the solution of the multi-objective differential evolution algorithm, which can conveniently obtain a large number of neural network models with high accuracy and large network differences. And this strategy speeds up the solution process of multi-target algorithm.",Springer
"Murina, Ezequiel",Math and Physics Tools for Quality Quantum Programming,2020,10.1007/978-3-030-58793-2_21,https://doi.org/10.1007/978-3-030-58793-2_21,Conference Paper,Quality of Information and Communications Technology,"We are in presence of a quantum computing revolution that will be critical for the dominant global position of nations in near future. Some quantum lab devices have been developed and important milestones have been reached, mainly in the branch of communications. In this scenario, it is urgent to educate people in quantum computing and technology, like it happens with disciplines such as science, technology, engineering, and mathematics promoted by government in order to instruct science-aware citizens. A solid knowledge base in math and physics is essential for a workforce able to develop high quality quantum technology. This work addresses the necessity of quantum literacy for the creation of a new workforce, proposing the basic math tools, and physics background for entering into the field of quantum programming. It also addresses a certification about Science Foundation for Quantum Programming, as a means for assuring the quality of quantum software professionals.",Springer
"B{\u{a}}etu, Ciprian and Durak, F. Bet{\""u}l and Huguenin-Dumittan, Lo{\""i}s and Talayhan, Abdullah and Vaudenay, Serge",Misuse Attacks on Post-quantum Cryptosystems,2019,10.1007/978-3-030-17656-3_26,https://doi.org/10.1007/978-3-030-17656-3_26,Conference Paper,Advances in Cryptology -- EUROCRYPT 2019,"Many post-quantum cryptosystems which have been proposed in the National Institute of Standards and Technology (NIST) standardization process follow the same meta-algorithm, but in different algebras or different encoding methods. They usually propose two constructions, one being weaker and the other requiring a random oracle. We focus on the weak version of nine submissions to NIST. Submitters claim no security when the secret key is used several times. In this paper, we analyze how easy it is to run a key recovery under multiple key reuse. We mount a classical key recovery under plaintext checking attacks (i.e., with a plaintext checking oracle saying if a given ciphertext decrypts well to a given plaintext) and a quantum key recovery under chosen ciphertext attacks. In the latter case, we assume quantum access to the decryption oracle.",Springer
"Liu, Mingyang and Song, Fu and Chen, Taolue",Automated Verification of Correctness for Masked Arithmetic Programs,2023,10.1007/978-3-031-37709-9_13,https://doi.org/10.1007/978-3-031-37709-9_13,Conference Paper,Computer Aided Verification,"Masking is a widely-used effective countermeasure against power side-channel attacks for implementing cryptographic algorithms. Surprisingly, few formal verification techniques have addressed a fundamental question, i.e., whether the masked program and the original (unmasked) cryptographic algorithm are functional equivalent. In this paper, we study this problem for masked arithmetic programs over Galois fields of characteristic 2. We propose an automated approach based on term rewriting, aided by random testing and SMT solving. The overall approach is sound, and complete under certain conditions which do meet in practice. We implement the approach as a new tool FISCHER and carry out extensive experiments on various benchmarks. The results confirm the effectiveness, efficiency and scalability of our approach. Almost all the benchmarks can be proved for the first time by the term rewriting system solely. In particular, FISCHER detects a new flaw in a masked implementation published in EUROCRYPT 2017.",Springer
"Guan, Ji and Feng, Yuan and Turrini, Andrea and Ying, Mingsheng",Measurement-Based Verification of Quantum Markov Chains,2024,10.1007/978-3-031-65633-0_24,https://doi.org/10.1007/978-3-031-65633-0_24,Conference Paper,Computer Aided Verification,"Model-checking techniques have been extended to analyze quantum programs and communication protocols represented as quantum Markov chains, an extension of classical Markov chains. To specify qualitative temporal properties, a subspace-based quantum temporal logic is used, which is built on Birkhoff-von Neumann atomic propositions. These propositions determine whether a quantum state is within a subspace of the entire state space. In this paper, we propose the measurement-based linear-time temporal logic MLTL to check quantitative properties. MLTL builds upon classical linear-time temporal logic (LTL) but introduces quantum atomic propositions that reason about the probability distribution after measuring a quantum state. To facilitate verification, we extend the symbolic dynamics-based techniques for stochastic matrices described by Agrawal et al. (JACM 2015) to handle more general quantum linear operators (super-operators) through eigenvalue analysis. This extension enables the development of an efficient algorithm for approximately model checking a quantum Markov chain against an MLTL formula. To demonstrate the utility of our model-checking algorithm, we use it to simultaneously verify linear-time properties of both quantum and classical random walks. Through this verification, we confirm the previously established advantages discovered by Ambainis et al. (STOC 2001) of quantum walks over classical random walks and discover new phenomena unique to quantum walks.",Springer
"Muqeet, Asmar and Ali, Shaukat and Arcaini, Paolo",Approximating Stochastic Quantum Noise Through Genetic Programming,2024,10.1007/978-3-031-64573-0_5,https://doi.org/10.1007/978-3-031-64573-0_5,Conference Paper,Search-Based Software Engineering,"Quantum computing's potential for exponential speedups over classical computing has recently sparked considerable interest. However, quantum noise presents a significant obstacle to realizing this potential, compromising computational reliability. Accurate estimation and mitigation of noise are crucial for achieving fault-tolerant quantum computation. While current efforts focus on developing noise models tailored to specific quantum computers, these models often fail to fully capture the complexity of real quantum noise. To this end, we propose an approach that uses genetic programming (GP) to develop expression-based noise models for quantum computers. We represent the quantum noise model as a computational expression, with each function corresponding to a specific aspect of the noise behavior. By function nesting, we create a chain of operations that collectively capture the intricate nature of quantum noise. Through GP, we explore the search space of possible noise model expressions, gradually improving the quality of the solution. We evaluated the approach on five artificial noise models of varying complexity and a real quantum computer. Results show that our approach achieved an error difference of less than 2{\%} in approximating artificial noise models and 15{\%} for a real quantum computer.",Springer
"Stamatiou, George T. and Magoutis, Kostas",Investigating the Use of Machine Learning Techniques in a Random Physical System,2021,10.1007/978-3-030-87568-8_7,https://doi.org/10.1007/978-3-030-87568-8_7,Conference Paper,Service-Oriented Computing,"Machine learning (ML) techniques have seen increasing use in recent years in complementing traditional HPC solutions to physical systems problems. While the scientific community has been rapidly adopting such techniques, it is still unclear how different ML techniques compare in terms of accuracy. In this paper we address this question by designing and training a neural network and comparing its performance to traditional classification models using as a case study a non-interacting quantum system on a graph structure. We build a classifier with the ability to distinguish extended from localized quantum states based on their different structure and compare it with other commonly used ML classifiers. Our results show high accuracy for certain ML models in most cases, whereas others are less effective.",Springer
"Hong, Weijiang and Chen, Zhenbang and Li, Minglong and Li, Yuhan and Huang, Peishan and Wang, Ji",Formal Verification Based Synthesis for Behavior Trees,2024,10.1007/978-981-99-8664-4_5,https://doi.org/10.1007/978-981-99-8664-4_5,Conference Paper,"Dependable Software Engineering. Theories, Tools, and Applications","Behavior trees (BTs) have been extensively applied in the area of both computer games and robotics, as the control architectures. However, the construction of BTs is labor-expensive, time-consuming, and even impossible as the complexity of task increases. In this work, we propose a formal verification based synthesis method to automatically construct BTs whose behaviors satisfy the given Linear Temporal Logic (LTL) specifications. Our method first explores candidate BTs by a grammar-based Monte Carlo Tree Search (MCTS), then the explored BTs are transformed into Communicating Sequential Processes (CSP) models. After that, we invoke the verifier to check the models' correctness w.r.t. specifications, and provide feedback based on the verification result for guiding the search process. The application of our method on several representative robotic missions indicates its promising.",Springer
"Blauensteiner, Florian and Fahrnberger, G{\""u}nter",Route Optimization of an Unmanned Aerial Vehicle Beyond Visual Line of Sight,2024,10.1007/978-3-031-60433-1_12,https://doi.org/10.1007/978-3-031-60433-1_12,Conference Paper,Innovations for Community Services,"Undoubtedly, Unmanned Aerial Vehicles (UAVs), also known as drones, have experienced significant growth in recent decades and will continue their increase. Presently, drone operators view the endurance of their devices' flights as one of the most challenging obstacles. This challenge becomes even more pronounced when UAVs must remain airborne for extended periods without ground contact for recharging or refueling. This contribution further addresses autonomous Beyond Visual Line Of Sight (BVLOS) flight, hydrogen propulsion, and optimized joined wing design, considering both demands and constraints. However, as no recent scientific work adequately addresses all these challenges, this disquisition aims to provide mitigation strategies by proposing prudent routing for an already constructed drone prototype. Findings from an experimental test flight substantiate the intended improvements.",Springer
"Neves, Andr{\'e} and Meira, Silvio and Caleg{\'a}rio, Filipe and Belfort, Rui and Bressan, Marcello","squad.ai: A Multi-agent System Built on LLMs, Incorporating Specialized Embeddings and Sociocultural Diversity",2024,10.1007/978-3-031-61353-1_6,https://doi.org/10.1007/978-3-031-61353-1_6,Conference Paper,"Design, User Experience, and Usability","The squad.ai system emerges as an innovative proposition in the landscape of multi-agent systems, building upon the robustness of Large Language Models (LLMs). Recognizing the potentialities and limitations of LLMs, the system integrates specialized embeddings, allowing for a deepening and specialization of agent knowledge in specific domains. A distinctive feature of squad.ai is the incorporation of rich identity and educational attributes, reflecting sociocultural diversity. This diversity, coupled with behavioral archetypes, aims to facilitate more contextualized and humanized interactions, both among agents and between agents and humans. Squad.ai, therefore, represents a stride forward in the pursuit of multi-agent systems that combine vast knowledge, deep specialization, and meaningful sociocultural representation.",Springer
"Yu, Yang and Ducas, L{\'e}o",Learning Strikes Again: The Case of the DRS Signature Scheme,2018,10.1007/978-3-030-03329-3_18,https://doi.org/10.1007/978-3-030-03329-3_18,Conference Paper,Advances in Cryptology -- ASIACRYPT 2018,"Lattice signature schemes generally require particular care when it comes to preventing secret information from leaking through signature transcript. For example, the Goldreich-Goldwasser-Halevi (GGH) signature scheme and the NTRUSign scheme were completely broken by the parallelepiped-learning attack of Nguyen and Regev (Eurocrypt 2006). Several heuristic countermeasures were also shown vulnerable to similar statistical attacks.",Springer
"Nicolae, Bogdan",DataStates: Towards Lightweight Data Models for Deep Learning,2020,10.1007/978-3-030-63393-6_8,https://doi.org/10.1007/978-3-030-63393-6_8,Conference Paper,"Driving Scientific and Engineering Discoveries Through the Convergence of HPC, Big Data and AI","A key emerging pattern in deep learning applications is the need to capture intermediate DNN model snapshots and preserve or clone them in explore a large number of alternative training and/or inference paths. However, with increasing model complexity and new training approaches that mix data, model, pipeline and layer-wise parallelism, this pattern is challenging to address in a scalable and efficient manner. To this end, this position paper advocates for rethinking how to represent and manipulate DNN learning models. It relies on a broader notion of data states, a collection of annotated, potentially distributed data sets (tensors in the case of DNN models) that AI applications can capture at key moments during the runtime and revisit/reuse later. Instead explicitly interacting with the storage layer (e.g., write to a file), users can ``tag'' DNN models at key moments during runtime with metadata that expresses attributes and persistency/movement semantics. A high-performance runtime is the responsible to interpret the metadata and perform the necessary actions in the background, while offering a rich interface to find data states of interest. Using this approach has benefits at several levels: new capabilities, performance portability, high performance and scalability.",Springer
"Gilbert, Valentin and Louise, St{\'e}phane",Quantum Annealers Chain Strengths: A Simple Heuristic to Set Them All,2024,10.1007/978-3-031-63778-0_21,https://doi.org/10.1007/978-3-031-63778-0_21,Conference Paper,Computational Science -- ICCS 2024,"Quantum annealers (QA), such as D-Wave systems, become increasingly efficient and competitive at approximating combinatorial optimization problems. However, solving problems that do not directly map the chip topology remains challenging for this type of quantum computer. The creation of logical qubits as sets of interconnected physical qubits overcomes limitations imposed by the sparsity of the chip at the expense of increasing the problem size and adding new parameters to optimize. This paper explores the advantages and drawbacks provided by the structure of the logical qubits and the impact of the rescaling of coupler strengths on the minimum spectral gap of Ising models. We show that logical qubits encoded over densely connected physical qubits require a lower chain strength to maintain the ferromagnetic coupling. We also analyze the optimal chain strength variations considering different minor embeddings of the same instance. This experimental study suggests that the chain strength can be optimized for each instance. We design a heuristic that optimizes the chain strength using a very low number of shots during the preprocessing step. This heuristic outperforms the default method used to initialize the chain strength on D-Wave systems, increasing the quality of the best solution by up to {\$}{\$}17.2{\backslash}{\%}{\$}{\$}17.2{\%}for tested instances on the max-cut problem.",Springer
"Abate, Alessandro and Giacobbe, Mirco and Roy, Diptarko",Learning Probabilistic Termination Proofs,2021,10.1007/978-3-030-81688-9_1,https://doi.org/10.1007/978-3-030-81688-9_1,Conference Paper,Computer Aided Verification,"We present the first machine learning approach to the termination analysis of probabilistic programs. Ranking supermartingales (RSMs) prove that probabilistic programs halt, in expectation, within a finite number of steps. While previously RSMs were directly synthesised from source code, our method learns them from sampled execution traces. We introduce the neural ranking supermartingale: we let a neural network fit an RSM over execution traces and then we verify it over the source code using satisfiability modulo theories (SMT); if the latter step produces a counterexample, we generate from it new sample traces and repeat learning in a counterexample-guided inductive synthesis loop, until the SMT solver confirms the validity of the RSM. The result is thus a sound witness of probabilistic termination. Our learning strategy is agnostic to the source code and its verification counterpart supports the widest range of probabilistic single-loop programs that any existing tool can handle to date. We demonstrate the efficacy of our method over a range of benchmarks that include linear and polynomial programs with discrete, continuous, state-dependent, multi-variate, hierarchical distributions, and distributions with undefined moments.",Springer
"Katsumata, Shuichi and Yamada, Shota and Yamakawa, Takashi",Tighter Security Proofs for GPV-IBE in the Quantum Random Oracle Model,2018,10.1007/978-3-030-03329-3_9,https://doi.org/10.1007/978-3-030-03329-3_9,Conference Paper,Advances in Cryptology -- ASIACRYPT 2018,"In (STOC, 2008), Gentry, Peikert, and Vaikuntanathan proposed the first identity-based encryption (GPV-IBE) scheme based on a post-quantum assumption, namely, the learning with errors (LWE) assumption. Since their proof was only made in the random oracle model (ROM) instead of the quantum random oracle model (QROM), it remained unclear whether the scheme was truly post-quantum or not. In (CRYPTO, 2012), Zhandry developed new techniques to be used in the QROM and proved security of GPV-IBE in the QROM, hence answering in the affirmative that GPV-IBE is indeed post-quantum. However, since the general technique developed by Zhandry incurred a large reduction loss, there was a wide gap between the concrete efficiency and security level provided by GPV-IBE in the ROM and QROM. Furthermore, regardless of being in the ROM or QROM, GPV-IBE is not known to have a tight reduction in the multi-challenge setting. Considering that in the real-world an adversary can obtain many ciphertexts, it is desirable to have a security proof that does not degrade with the number of challenge ciphertext.",Springer
"De Feo, Luca and Galbraith, Steven D.",SeaSign: Compact Isogeny Signatures from Class Group Actions,2019,10.1007/978-3-030-17659-4_26,https://doi.org/10.1007/978-3-030-17659-4_26,Conference Paper,Advances in Cryptology -- EUROCRYPT 2019,"We give a new signature scheme for isogenies that combines the class group actions of CSIDH with the notion of Fiat-Shamir with aborts. Our techniques allow to have signatures of size less than one kilobyte at the 128-bit security level, even with tight security reduction (to a non-standard problem) in the quantum random oracle model. Hence our signatures are potentially shorter than lattice signatures, but signing and verification are currently very expensive.",Springer
"Baioletti, Marco and Rasconi, Riccardo and Oddi, Angelo",A Novel Ant Colony Optimization Strategy for the Quantum Circuit Compilation Problem,2021,10.1007/978-3-030-72904-2_1,https://doi.org/10.1007/978-3-030-72904-2_1,Conference Paper,Evolutionary Computation in Combinatorial Optimization,"Quantum Computing represents the most promising technology towards speed boost in computation, opening the possibility of major breakthroughs in several disciplines including Artificial Intelligence. This paper investigates the performance of a novel Ant Colony Optimization (ACO) algorithm for the realization (compilation) of nearest-neighbor compliant quantum circuits of minimum duration. In fact, current technological limitations (e.g., decoherence effect) impose that the overall duration (makespan) of the quantum circuit realization be minimized, and therefore the production of minimum-makespan compiled circuits for present and future quantum machines is of paramount importance. In our ACO algorithm (QCC-ACO), we introduce a novel pheromone model, and we leverage a heuristic-based Priority Rule to control the iterative selection of the quantum gates to be inserted in the solution.",Springer
"Ducas, L{\'e}o and Plan{\c{c}}on, Maxime and Wesolowski, Benjamin",On the Shortness of Vectors to Be Found by the Ideal-SVP Quantum Algorithm,2019,10.1007/978-3-030-26948-7_12,https://doi.org/10.1007/978-3-030-26948-7_12,Conference Paper,Advances in Cryptology -- CRYPTO 2019,"The hardness of finding short vectors in ideals of cyclotomic number fields (hereafter, Ideal-SVP) can serve as a worst-case assumption for numerous efficient cryptosystems, via the average-case problems Ring-SIS and Ring-LWE. For a while, it could be assumed the Ideal-SVP problem was as hard as the analog problem for general lattices (SVP), even when considering quantum algorithms.",Springer
"Ravishankar, Anand and Natarajan, Santhi and Bharathi Malakreddy, A.",SparseMAX: Accelerating Quantum Neural Networks on GPU Clusters Using Sparse-Matrix Kernels,2022,10.1007/978-3-031-04580-6_28,https://doi.org/10.1007/978-3-031-04580-6_28,Conference Paper,"Embedded Computer Systems: Architectures, Modeling, and Simulation","The growing popularity of Applied Quantum Mechanics and Artificial Intelligence drives the need for integrating the two fields. Quantum Neural Networks (QNNs) incorporate quantum aspects into classical deep learning networks which are capable of performing universal quantum computations. The dense representation of QNNs presents great challenges in terms of computational cost and noise susceptibility. In this paper, we present SparseMAX, a novel Sparse Quantum Neural Network (SQNN) that is robust to noise and interference for large volumes of network parameters. We also introduce Quantron ({\$}{\$}{\backslash}psi {\$}{\$}$\psi$), a generalized version of perceptron, which acts on qubits and performs the necessary quantum operations. Based on these insights, we develop 2 GPU kernels. The first kernel estimates the network architecture through a quantum training algorithm. The second kernel accelerates a sparsified version of the network matrices on a GPU cluster. We validate our kernel performance and training algorithm and present the results in terms of inference time, GPU efficiency and scalability. On an average, SparseMAX utilizes 54.83{\%} of our GPU cluster's compute resources, while offering a 41.51{\$}{\$}{\backslash}times {\$}{\$}{\texttimes}speedup in terms of serial inference timing measurements for network layer range [120, 1920] and neurons per layer range [1024,4096]",Springer
"Devadas, Srinivas and Ren, Ling and Xiao, Hanshen",On Iterative Collision Search for LPN and Subset Sum,2017,10.1007/978-3-319-70503-3_24,https://doi.org/10.1007/978-3-319-70503-3_24,Conference Paper,Theory of Cryptography,"Iterative collision search procedures play a key role in developing combinatorial algorithms for the subset sum and learning parity with noise (LPN) problems. In both scenarios, the single-list pair-wise iterative collision search finds the most solutions and offers the best efficiency. However, due to its complex probabilistic structure, no rigorous analysis for it appears to be available to the best of our knowledge. As a result, theoretical works often resort to overly constrained and sub-optimal iterative collision search variants in exchange for analytic simplicity. In this paper, we present rigorous analysis for the single-list pair-wise iterative collision search method and its applications in subset sum and LPN. In the LPN literature, the method is known as the LF2 heuristic. Besides LF2, we also present rigorous analysis of other LPN solving heuristics and show that they work well when combined with LF2. Putting it together, we significantly narrow the gap between theoretical and heuristic algorithms for LPN.",Springer
"Bonetti, Paolo and Metelli, Alberto Maria and Restelli, Marcello",Interpetable Target-Feature Aggregation for Multi-task Learning Based on Bias-Variance Analysis,2024,10.1007/978-3-031-70365-2_5,https://doi.org/10.1007/978-3-031-70365-2_5,Conference Paper,Machine Learning and Knowledge Discovery in Databases. Research Track,"Multi-task learning (MTL) is a powerful machine learning paradigm designed to leverage shared knowledge across tasks to improve generalization and performance. Previous works have proposed approaches to MTL that can be divided into feature learning, focused on the identification of a common feature representation, and task clustering, where similar tasks are grouped together. In this paper, we propose an MTL approach at the intersection between task clustering and feature transformation based on a two-phase iterative aggregation of targets and features. First, we propose a bias-variance analysis for regression models with additive Gaussian noise, where we provide a general expression of the asymptotic bias and variance of a task, considering a linear regression trained on aggregated input features and an aggregated target. Then, we exploit this analysis to provide a two-phase MTL algorithm (NonLinCTFA). Firstly, this method partitions the tasks into clusters and aggregates each obtained group of targets with their mean. Then, for each aggregated task, it aggregates subsets of features with their mean in a dimensionality reduction fashion. In both phases, a key aspect is to preserve the interpretability of the reduced targets and features through the aggregation with the mean, which is further motivated by applications to Earth science. Finally, we validate the algorithms on synthetic data, showing the effect of different parameters and real-world datasets, exploring the validity of the proposed methodology on classical datasets, recent baselines, and Earth science applications.",Springer
"Toncian, Vlad and Florea, Adrian and David, Alin and Morariu, Daniel and Cretulescu, Radu","Leveraging Collaboration for Industry 5.0: Needs, Strategies and Future Directions",2024,10.1007/978-3-031-71739-0_21,https://doi.org/10.1007/978-3-031-71739-0_21,Conference Paper,Navigating Unpredictability: Collaborative Networks in Non-linear Worlds,"This paper analyzes the identified key elements that are needed by the Industrial sector to ensure the seamless transition of enterprises from the ``4.0 paradigm'' -- based on digitalization and technologies, to the ``5.0 paradigm'' -- focused on resilience, ``green'' mindset and human-centric approach. The basis of this analysis is a research survey conducted within a century-old European technology company, focused on automotive products, with over 20 locations spread on more than 10 countries and on 4 continents. The goal of this paper is to identify both the needs of the Industrial sector concerning the ``5.0 Transition'' and the focus points for the CoDEMO 5.0 project, concerning what the Industry players expect from this Consortium. Moreover, this paper aims to define a process in which these two elements combine harmoniously so that a continuous positive feedback loop is established and, if implemented on a wider scale, could establish a new way of working among the EU Industrial actors, thanks to the collaborative network that shall be established. Concerning this study, such a collaborative network is composed of a ``triple-helix'' formed by the Customer (OEM manufacturer), the Supplier (automotive company), and the Academic Partner. Such partnership will enable the OEM to come out with new, and groundbreaking products that stand out from their competitors, thanks to the supplier that is creating these products which in turn, can develop them thanks to the academic partner that prepares highly skilled professionals for the current and future emerging technologies from Industrial sector like Artificial Intelligence, machine learning, blockchain, quantum computing, IIoTs, etc.",Springer
"Mittone, Gianluca and Riviera, Walter and Colonnelli, Iacopo and Birke, Robert and Aldinucci, Marco",Model-Agnostic Federated Learning,2023,10.1007/978-3-031-39698-4_26,https://doi.org/10.1007/978-3-031-39698-4_26,Conference Paper,Euro-Par 2023: Parallel Processing,"Since its debut in 2016, Federated Learning (FL) has been tied to the inner workings of Deep Neural Networks (DNNs); this allowed its development as DNNs proliferated but neglected those scenarios in which using DNNs is not possible or advantageous. The fact that most current FL frameworks only support DNNs reinforces this problem. To address the lack of non-DNN-based FL solutions, we propose MAFL (Model-Agnostic Federated Learning). MAFL merges a model-agnostic FL algorithm, AdaBoost.F, with an open industry-grade FL framework: Intelé¹è°æªé·ç¨¯penFL. MAFL is the first FL system not tied to any machine learning model, allowing exploration of FL beyond DNNs. We test MAFL from multiple points of view, assessing its correctness, flexibility, and scaling properties up to 64 nodes of an HPC cluster. We also show how we optimised OpenFL achieving a 5.5{\$}{\$}{\backslash}times {\$}{\$}{\texttimes}speedup over a standard FL scenario. MAFL is compatible with x86-64, ARM-v8, Power and RISC-V.",Springer
"D'Urbano, Andrea and Angelelli, Mario and Catalano, Christian",The Significance of Classical Simulations in the Adoption of Quantum Technologies for Software Development,2024,10.1007/978-3-031-49269-3_6,https://doi.org/10.1007/978-3-031-49269-3_6,Conference Paper,Product-Focused Software Process Improvement,"This paper addresses classical simulations in the assessment of quantum computing performance. It emphasises the significance of these simulations in understanding quantum systems and exploring the potential of quantum algorithms. The challenges posed by the exponential growth of quantum states and the limitations of full-state simulations are addressed. Various approximation techniques and encoding methods are pointed out to enable simulations of larger quantum systems, and advanced simulation strategies tailored to specific goals are also discussed. This work focuses on the feasibility of classical simulation in decision processes regarding the development of software solutions, extending the assessment beyond high-performance computing systems to include standard hardware. This opportunity can foster the adoption of classical simulations of quantum algorithms to a wider range of users.",Springer
"Barenghi, Alessandro and Cremonesi, Paolo and Pelosi, Gerardo",Quantum Computing Research Lines in the Italian Center for Supercomputing,2023,10.1007/978-3-031-46077-7_28,https://doi.org/10.1007/978-3-031-46077-7_28,Conference Paper,"Embedded Computer Systems: Architectures, Modeling, and Simulation","Quantum computing is widely seen as an evolution step in computer science, with the potential for disruptive changes in how we think about problem solvability. The significant perspective societal gains have pushed for the creation of nation-wide research efforts, gathering together a diverse set of competences, ranging from fundamental physics, to electronic and computer engineering, and to pure computer science. In this paper, we provide an overview of the perspectives and research directions of the Italian Center for Supercomputing, and in particular its efforts towards advancing research in all aspects of quantum computing. Besides a general overview of the center itself, and its components, we also provide a glance on some of the current research directions.",Springer
"Rehn, Erik M.",Free Will Belief as a Consequence of Model-Based Reinforcement Learning,2023,10.1007/978-3-031-19907-3_34,https://doi.org/10.1007/978-3-031-19907-3_34,Conference Paper,Artificial General Intelligence,"The debate on whether or not humans have free will has been raging for centuries. Although there are good arguments based on our current understanding of the laws of nature for the view that it is not possible for humans to have free will, most people believe they do. This discrepancy begs for an explanation. If we accept that we do not have free will, we are faced with two problems: (1) while freedom is a very commonly used concept that everyone intuitively understands, what are we actually referring to when we say that an action or choice is ``free'' or not? And, (2) why is the belief in free will so common? Where does this belief come from, and what is its purpose, if any? In this paper, we examine these questions from the perspective of reinforcement learning (RL). RL is a framework originally developed for training artificial intelligence agents. However, it can also be used as a computational model of human decision making and learning, and by doing so, we propose that the first problem can be answered by observing that people's common sense understanding of freedom is closely related to the information entropy of an RL agent's normalized action values, while the second can be explained by the necessity for agents to model themselves as if they could have taken decisions other than those they actually took, when dealing with the temporal credit assignment problem. Put simply, we suggest that by applying the RL framework as a model for human learning it becomes evident that in order for us to learn efficiently and be intelligent we need to view ourselves as if we have free will.",Springer
"Kiselyova, Nadezhda and Dudarev, Victor and Stolyarenko, Andrey",Machine Learning Application to Predict New Inorganic Compounds -- Results and Perspectives,2022,10.1007/978-3-031-12285-9_9,https://doi.org/10.1007/978-3-031-12285-9_9,Conference Paper,Data Analytics and Management in Data Intensive Domains,"A brief overview of the problems is given in the field of inorganic chemistry and materials science, solved using machine learning (ML). The main ML methods limitations and the subject area peculiarities are considered that must be taken into account when using ML. Solved problems examples of new inorganic compounds design and the results of comparing predictions with new experimental data are given. Systems developed by the authors are considered that aimed at not yet obtained inorganic compounds design, based on ML methods, as well as promising directions for such systems development in order to improve the predictions accuracy for new substances and their corresponding properties values estimations.",Springer
"Richoux, Florian and Baffier, Jean-Fran{\c{c}}ois and Codognet, Philippe",Learning qubo Models for Quantum Annealing: A Constraint-Based Approach,2023,10.1007/978-3-031-36030-5_12,https://doi.org/10.1007/978-3-031-36030-5_12,Conference Paper,Computational Science -- ICCS 2023,"Quantum Annealing is an optimization process taking advantage of quantum tunneling to search for the global optimum of an optimization problem, although, being a heuristic method, there is no guarantee to find the global optimum. Optimization problems solved by a Quantum Annealer machine are modeled as Quadratic Unconstrained Binary Optimization (qubo) problems. Combinatorial optimization problems, where variables take discrete values and the optimization is under constraints, can also be modeled as qubo problems to benefit from Quantum Annealing power. However, defining quadratic penalty functions representing constraints within the qubo framework can be a complex task. In this paper, we propose a method to learn from data constraint representations as a combination of patterns we isolated in {\$}{\$}Q{\$}{\$}matrices modeling optimization problems and their constraint penalty functions. We actually model this learning problem as a combinatorial optimization problem itself. We propose two experimental protocols to illustrate the strengths of our method: its scalability, where correct pattern combinations learned over data from a small constraint instance scale to large instances of the same constraint, and its robustness, where correct pattern combinations can be learned over very scarce data, composed of about 10 training elements only.",Springer
"Cardoso, Fabio and Vellasco, Marley and Figueiredo, Karla",Comparative Study Between Q-NAS and Traditional CNNs for Brain Tumor Classification,2024,10.1007/978-3-031-62495-7_8,https://doi.org/10.1007/978-3-031-62495-7_8,Conference Paper,Engineering Applications of Neural Networks,"Brain tumours caused approximately 251,329 deaths worldwide in 2020, with the primary diagnostic method for these tumours involving medical imaging. In recent years, many works and applications have observed the use of Artificial Intelligence-based models using Convolution Neural Networks (CNNs) to identify health problems using images. In our study, we searched for new architectures based on CNN using the Q-NAS algorithm. We compared its performance and number of parameters with traditional architectures such as VGG, ResNet, and MobileNet to classify types of brain tumors in MRI images. The best architecture found by Q-NAS achieved an accuracy of 92{\%} on the test data set, with a model with less than one million parameters, which is much smaller than that found in the selected traditional architectures for this study. It shows the potential of the Q-NAS algorithm and highlights the importance of efficient model design in the context of accurate and feature-aware medical image analysis.",Springer
"Holzinger, Andreas and Goebel, Randy and Palade, Vasile and Ferri, Massimo",Towards Integrative Machine Learning and Knowledge Extraction,2017,10.1007/978-3-319-69775-8_1,https://doi.org/10.1007/978-3-319-69775-8_1,Conference Paper,Towards Integrative Machine Learning and Knowledge Extraction,"This Volume is a result of workshop 15w2181 ``Advances in interactive knowledge discovery and data mining in complex and big data sets'' at the Banff International Research Station for Mathematical Innovation and Discovery. The workshop was dedicated to bring together experts with diverse backgrounds but with one common goal: to understand intelligence for the successful design, development and evaluation of algorithms that can learn from data, extract knowledge from experience, and to improve their learning behaviour over time -- similarly as we humans do. Knowledge discovery, data mining, machine learning, artificial intelligence are more or less synonymously used with no strict definitions or boundaries. ``Integrative'' means to support not only the machine learning {\&} knowledge extraction pipeline, ranging from dealing with data in arbitrarily high-dimensional spaces to the visualization of results into a lower dimension accessible to a human; it is taking into account seemingly disparate fields which can be very fruitful when brought together - for solving problems in complex application domains (e.g. health informatics). Here we want to emphasize that the most important findings in machine learning will be those we do not know yet. In this paper we provide: (1) a short motivation for the integrative approach; (2) brief summaries of the presentations given in Banff; and (3) some personally flavoured, subjective future research outlooks, e.g. in the combination of geometrical approaches with machine learning.",Springer
"Verma, Kamal Kant and Kumar, Ravi and Chauhan, Shivani and Gulati, Sagar and Singh, Brij Mohan and Mridula",Optimization of Virtual Machines in Cloud Environment,2024,10.1007/978-3-031-48774-3_8,https://doi.org/10.1007/978-3-031-48774-3_8,Conference Paper,Artificial Intelligence of Things,"The proposed VMP-LR (Virtual Machine Placement-Load Rebalancing) has three main components, namely, Resource Request Handling Component, Placement Component and Load Monitoring Component. VMP-LR is designed using a two-phase methodology, where the first phase handles the tasks involved with Resource Request Handling and Placement Components, while Phase II handles the tasks of Load Monitoring Component. The algorithms proposed in both the phases are designed to handle multiple resource requests. Dur ing non-rush hours (low traffic), as the number of requests is minimal, the VMP-LR uses a simple enhanced round-robin method to place virtual machines (VMs) to physical machines (PMs). During rush hours (heavy traffic), the three queues created are handled using three separate hybrid scheduling and load- balancing algorithms to perform placement operation efficiently and accommodate high resource demands. To solve this issue, the load monitoring component is used. For this purpose, a hybrid algorithm that combines ant colony optimiza tion (ACO) with an artificial bee colony (ABC) algorithm is used. The proposed algorithms are implemented using CloudSim Simulator and evaluated using seven performance metrics. They are throughput, response time, resource utilization rate, power usage, load unbalancing rate, SLA Violation rate and migra tion rate. The average SLA violation rate of VMP-LR is 0.6{\%} less as compared with FF (1.26{\%}), BF (1.1{\%}), RR (1.36{\%}), GA (0.98{\%}), ACO (1.16{\%}) and PSO (1.01{\%}). This shows that VMP-LR is a much-improved version among existing load balancing algorithm.",Springer
"Zielinski, Sebastian and Benkard, Magdalena and N{\""u}{\ss}lein, Jonas and Linnhoff-Popien, Claudia and Feld, Sebastian",SATQUBOLIB: A Python Framework for Creating and Benchmarking (Max-)3SAT QUBOs,2024,10.1007/978-3-031-60433-1_4,https://doi.org/10.1007/978-3-031-60433-1_4,Conference Paper,Innovations for Community Services,"In this paper, we present an open-source Python framework, called satqubolib. This framework aims to provide all necessary tools for solving (MAX)-3SAT problems on quantum hardware systems via Quadratic Unconstrained Binary Optimization (QUBO). Our framework solves two major issues when solving (MAX)-3SAT instances in the context of quantum computing. Firstly, a common way of solving satisfiability instances with quantum methods is, to transform these instances into instances of QUBO, as QUBO is the input format for quantum annealers and the Quantum Approximate Optimization Algorithm (QAOA) on quantum gate systems. Studies have shown, that the choice of this transformation can significantly impact the solution quality of quantum hardware systems. Thus, our framework provides thousands of usable QUBO transformations for satisfiability problems. Doing so also enables practitioners from any domain to immediately explore and use quantum techniques as a potential solver for their domain-specific problems, as long as they can be encoded as satisfiability problems. As a second contribution, we created a dataset of 6000 practically hard and satisfiable SAT instances that are also small enough to be solved with current quantum(-hybrid) methods. This dataset enables meaningful benchmarking of new quantum, quantum-hybrid, and classical methods for solving satisfiability problems.",Springer
"Veschetti, Adele and Bubel, Richard and H{\""a}hnle, Reiner",A Formal Modeling Language for Smart Contracts,2025,10.1007/978-3-031-77382-2_6,https://doi.org/10.1007/978-3-031-77382-2_6,Conference Paper,Software Engineering and Formal Methods,"Smart contracts codify real-world transactions and automatically execute the terms of the contract when predefined conditions are met. This paper proposes SmartML, a modeling language for smart contracts that is platform independent and easy to comprehend.  We detail its formal semantics and type system with a focus on its role in addressing security vulnerabilities. We show along a case study, how SmartML prevents reentrancy attacks, illustrating its efficacy in reinforcing the reliability and security of smart contracts within decentralized systems.",Springer
"Zheng, Yu and Zhang, Zhenrong and Fang, Wei and Liu, Wenjie",A Variable-Angle-Distance Quantum Evolutionary Algorithm for 2D HP Model,2018,10.1007/978-3-030-00021-9_30,https://doi.org/10.1007/978-3-030-00021-9_30,Conference Paper,Cloud Computing and Security,"The computational simulations under the two dimensional hydrophobic-polar (2D-HP) model from protein's amino is a fundamental and challenging problems in computational biology. In this paper, we propose an improved quantum-inspired evolutionary algorithm based on variable angle-distance rotation strategy (QEA-VAR) for this NP-hard combinatorial protein folding problems. The QEA-VAR method is based on the concept and principles of quantum computing, such as quantum bits, quantum rotation gates and superposition of states. Comparing to the previously well-known evolutionary algorithm for the protein folding problem, QEA-VAR can find optimal or near-optimal energy structure from the benchmark sequences with a small simulating samples. Moreover, the proposed method's global convergence is faster than the other evolutionary algorithms. The application studies have demonstrated the superior performance and feasibility of the proposed algorithm for the protein folding problem.",Springer
"Ben-Sasson, Eli and Chiesa, Alessandro and Riabzev, Michael and Spooner, Nicholas and Virza, Madars and Ward, Nicholas P.",Aurora: Transparent Succinct Arguments for R1CS,2019,10.1007/978-3-030-17653-2_4,https://doi.org/10.1007/978-3-030-17653-2_4,Conference Paper,Advances in Cryptology -- EUROCRYPT 2019,"We design, implement, and evaluate a zero knowledge succinct non-interactive argument (SNARG) for Rank-1 Constraint Satisfaction (R1CS), a widely-deployed NP language undergoing standardization. Our SNARG has a transparent setup, is plausibly post-quantum secure, and uses lightweight cryptography. A proof attesting to the satisfiability of n constraints has size {\$}{\$}O({\backslash}log ^2 n){\$}{\$}O(log2n); it can be produced with {\$}{\$}O(n {\backslash}log n){\$}{\$}O(nlogn)field operations and verified with O(n). At 128 bits of security, proofs are less than {\$}{\$}{\{}250{\}}{\backslash},{\backslash}mathrm{\{}kB{\}}{\$}{\$}250kBeven for several million constraints, more than {\$}{\$}10{\{}{\backslash}times {\}}{\$}{\$}10{\texttimes}shorter than prior SNARGs with similar features.",Springer
"Driff, Lydia Nahla and Berkani, Lamia and Guessoum, Ahmed and Bendjahel, Abdellah",Social Validation of Solutions in the Context of Online Communities,2015,10.1007/978-3-319-19578-0_8,https://doi.org/10.1007/978-3-319-19578-0_8,Conference Paper,Computer Science and Its Applications,"Online Communities are considered as a new organizational structure that allows individuals and groups of persons to collaborate and share their knowledge and experiences. These members need technological support in order to facilitate their learning activities (e.g. during a problem solving process).We address in this paper the problem of social validation, our aim being to support members of Online Communities of Learners to validate the proposed solutions. Our approach is based on the members' evaluations: we apply three machine learning techniques, namely a Genetic Algorithm, Artificial Neural Networks and the Na{\""i}ve Bayes approach. The main objective is to determine a validity rating of a given solution. A preliminary experimentation of our approach within a Community of Learners whose main objective is to collaboratively learn the Java language shows that Neural Networks represent the most suitable approach in this context.",Springer
"Villmann, Thomas and Engelsberger, Alexander",Quantum-Hybrid Neural Vector Quantization -- A Mathematical Approach,2021,10.1007/978-3-030-87986-0_22,https://doi.org/10.1007/978-3-030-87986-0_22,Conference Paper,Artificial Intelligence and Soft Computing,"The paper demonstrates how to realize neural vector quantizers by means of quantum computing approaches. Particularly, we consider self-organizing maps and the neural gas vector quantizer for unsupervised learning as well as generalized learning vector quantization for classification learning. We show how quantum computing concepts can be adopted for these algorithms. The respective mathematical framework is explained in detail.",Springer
"Pastorello, Davide",Quantum Machine Learning: Perspectives in Cybersecurity,2024,10.1007/978-3-031-68738-9_20,https://doi.org/10.1007/978-3-031-68738-9_20,Conference Paper,"Computer Safety, Reliability, and Security. SAFECOMP 2024 Workshops","In this work, we give an overview on some recent results related to quantum machine learning (QML) regarding the training of quantum generative adversarial neural networks by means of classical shadows, and a parametric model implemented on a quantum annealer. Then, we argue that QML models can be robust against targeted data corruption and gradient-based attacks, motivating the exploration of the relationship between QML and cybersecurity.",Springer
"Albert, Elvira and Genaim, Samir and Kirchner, Daniel and Martin-Martin, Enrique",Formally Verified EVM Block-Optimizations,2023,10.1007/978-3-031-37709-9_9,https://doi.org/10.1007/978-3-031-37709-9_9,Conference Paper,Computer Aided Verification,"The efficiency and the security of smart contracts are their two fundamental properties, but might come at odds: the use of optimizers to enhance efficiency may introduce bugs and compromise security. Our focus is on EVM (Ethereum Virtual Machine) block-optimizations, which enhance the efficiency of jump-free blocks of opcodes by eliminating, reordering and even changing the original opcodes. We reconcile efficiency and security by providing the verification technology to formally prove the correctness of EVM block-optimizations on smart contracts using the Coq proof assistant. This amounts to the challenging problem of proving semantic equivalence of two blocks of EVM instructions, which is realized by means of three novel Coq components: a symbolic execution engine which can execute an EVM block and produce a symbolic state; a number of simplification lemmas which transform a symbolic state into an equivalent one; and a checker of symbolic states to compare the symbolic states produced for the two EVM blocks under comparison.",Springer
"Chauhan, Ritu and Mehtar, Khushi and Kaur, Harleen and Alankar, Bhavya",Evaluating Cyber-Crime Using Machine Learning and AI Approach for Environmental Sustainability,2025,10.1007/978-3-031-71729-1_4,https://doi.org/10.1007/978-3-031-71729-1_4,Conference Paper,"Sustainable Development through Machine Learning, AI and IoT","The online world has become an essential part of everyday life in India due to its fast expansion and technical improvements. But as technology has advanced, cyber-crimes have also increased dramatically, posing serious risks to the economy, security, and privacy. This research examines the intricate terrain of cybercrimes targeting minors in India, scrutinizing more than 16 lakh cases that have been documented during the three years preceding this one. The study takes an extensive approach, applying machine learning modelling such as Gradient Boosting, AdaBoost, Random Forest, Gaussian Naive Bayes, Bernoulli Naive Bayes, Linear SVM, Logistic Regression, and Gradient Boosting in conjunction with exploratory assessment of data. The findings show different accuracy rates; Random Forest, Gradient Boosting, Linear SVM, and Gaussian Naive Bayes all show an impressive 88{\%} accuracy. AdaBoost and Logistic Regression reach 75{\%}, but Bernoulli Naive Bayes comes in lower at 62{\%}. The comprehension of computational interconnections is improved with correlation matrices. This thorough analysis provides important insights for academics, policymakers, and stakeholders in the field of child cybersecurity by exposing common cyber threats targeting minors and highlighting the role that algorithms for learning may play in detecting and averting these risks for environmental sustainability.",Springer
"de Arag{\~a}o, Em{\'i}lia Valen{\c{c}}a Ferreira and Mancini, Luca and He, Xiao and Faginas-Lago, Noelia and Rosi, Marzio and Ascenzi, Daniela and Pirani, Fernando",Coding Cross Sections of an Electron Charge Transfer Process,2022,10.1007/978-3-031-10592-0_24,https://doi.org/10.1007/978-3-031-10592-0_24,Conference Paper,Computational Science and Its Applications -- ICCSA 2022 Workshops,"The paper presents the algorithm of a code written for computing the cross section for a charge transfer process involving a neutral molecule and a monatomic ion. The entrance and exit potential energy surfaces, driving the collision dynamics, are computed employing the Improved Lennard-Jones function that accounts for the role of non-electrostatic forces, due to size repulsion plus dispersion and induction attraction. In addition, electrostatic components, affecting the entrance channels, are evaluated as sum of Coulomb contributions, determined by the He{\$}{\$}^+{\$}{\$}+ion interacting with the charge distribution on the molecular frame. The cross section is estimated by employing the Landau-Zener-St{\""u}ckelberg approach. The code implemented has been employed in systems involving helium cation and a small organic molecule, such as methanol, dimethyl ether and methyl formate.",Springer
"Calderan, Felipe V. and de Mendon{\c{c}}a, Jo{\~a}o Paulo A. and Silva, Juarez L. F. Da and Quiles, Marcos G.",Guided Clustering for Selecting Representatives Samples in Chemical Databases,2023,10.1007/978-3-031-37126-4_10,https://doi.org/10.1007/978-3-031-37126-4_10,Conference Paper,Computational Science and Its Applications -- ICCSA 2023 Workshops,"Machine Learning (ML) methods, from unsupervised to supervised algorithms, have been applied to solve several tasks in the Materials Science domain, such as property prediction, design of new chemical compounds, and surrogate models in molecular dynamics simulations. ML methods can also play a fundamental role in screening materials by reducing the number of compounds under scrutiny. This reduction assumes that compounds similarly represented by a given descriptor might have similar properties; thus, an unsupervised ML method, such as the K-Means algorithm, can cluster the data set and deliver a set of representative samples. However, this selection depends on the molecular representation that might not directly relate to the target property. Here, we propose a framework that lets the specialist select a set of representative samples in a guided fashion. In particular, a loop between a clustering algorithm (k-means) and an optimization method (Basin-Hopping) is implemented, which allows the system to learn feature weights to form more homogeneous clusters given the target property. The framework also offers other visual and textual functionalities to support the expert. We evaluate the proposed framework in two scenarios, and the results show that the guidance enhances clustering formations, both in coarse (few and big clusters) and fine (many small clusters) analyses.",Springer
"Pinilla, Jose P. and Wilton, Steven J. E.",Layout-Aware Embedding for Quantum Annealing Processors,2019,10.1007/978-3-030-20656-7_7,https://doi.org/10.1007/978-3-030-20656-7_7,Conference Paper,High Performance Computing,"Due to the physical limit in connectivity between qubits in Quantum Annealing Processors (QAPs), when sampling from a problem formulated as an Ising graph model, it is necessary to embed the problem onto the physical lattice of qubits. A valid mapping of the problem nodes into qubits often requires qubit chains to ensure connectivity.",Springer
"Inajetovic, Matteo Antonio and Orazi, Filippo and Macaluso, Antonio and Lodi, Stefano and Sartori, Claudio",Enabling Non-linear Quantum Operations Through Variational Quantum Splines,2023,10.1007/978-3-031-36030-5_14,https://doi.org/10.1007/978-3-031-36030-5_14,Conference Paper,Computational Science -- ICCS 2023,"One of the major issues for building a complete quantum neural network is the implementation of non-linear activation functions in a quantum computer. In fact, the postulates of quantum mechanics impose only unitary transformations on quantum states, which is a severe limitation for quantum machine learning algorithms. Recently, the idea of QSplines has been proposed to approximate non-linear quantum activation functions by means of the HHL. However, QSplines rely on a problem formulation to be represented as a block diagonal matrix and need a fault-tolerant quantum computer to be correctly implemented.",Springer
"Schwarz, Nicholas and Campbell, Stuart and Hexemer, Alexander and Mehta, Apurva and Thayer, Jana",Enabling Scientific Discovery at Next-Generation Light Sources with Advanced AI and HPC,2020,10.1007/978-3-030-63393-6_10,https://doi.org/10.1007/978-3-030-63393-6_10,Conference Paper,"Driving Scientific and Engineering Discoveries Through the Convergence of HPC, Big Data and AI","The synchrotron and free electron laser light sources, large scientific user facilities, are in the position to help solve some of the most challenging and novel scientific questions facing the world, ranging from the design of new materials to manipulate classical and quantum information with high fidelity and ultra low power consumption, to enabling systems for efficient energy storage, transportation, and conversion that will drive the emerging economy based on renewable energy, to understanding the structure and motion of protein molecules to enable individualized medicine. These scientific opportunities will be addressed by new measurement techniques, technological advances in detectors, multi-modal data utilization, and advances in data analysis algorithms, all of which are being driven to a new level of sophistication. Over the next decade, it is estimated that the US light sources will generate in the exabyte (EB) range of data, require tens to 1,000 PFLOPS of peak on-demand computing resources, and utilize billions of core hours per year. Scientific discovery on this scale will be enabled by data management and workflow tools that integrate user facility instruments with sufficient computing, networking, and storage resources, on-demand utilization of super-computing environments to enable real-time data processing, real-time data analysis capabilities to significantly reduce data volumes and provide feedback during experiments to improve data quality and to drive the direction of ongoing measurements, the application of advanced machine learning algorithms to make crucial experiment decisions, and the integration of simulations and model-based approaches to facilitate automated experiment design and steering of data collection.",Springer
"Osaba, Eneko and Villar-Rodr{\'i}guez, Esther and Gomez-Tejedor, Aitor and Oregi, Izaskun",Hybrid Quantum Solvers in Production: How to Succeed in the NISQ Era?,2025,10.1007/978-3-031-77738-7_35,https://doi.org/10.1007/978-3-031-77738-7_35,Conference Paper,Intelligent Data Engineering and Automated Learning -- IDEAL 2024,"Hybrid quantum computing is considered the present and the future within the field of quantum computing. Far from being a passing fad, this trend cannot be considered just a stopgap to address the limitations of NISQ-era devices. The foundations linking both computing paradigms will remain robust over time. The contribution of this work is twofold: first, we describe and categorize some of the most frequently used hybrid solvers, resorting to two different taxonomies recently published in the literature. Secondly, we put a special focus on two solvers that are currently deployed in real production and that have demonstrated to be near the real industry. These solvers are the LeapHybridBQMSampler contained in D-Wave's Hybrid Solver Service and Quantagonia's Hybrid Solver. We analyze the performance of both methods using as benchmarks four combinatorial optimization problems.",Springer
"Liu, Qipeng and Zhandry, Mark",Revisiting Post-quantum Fiat-Shamir,2019,10.1007/978-3-030-26951-7_12,https://doi.org/10.1007/978-3-030-26951-7_12,Conference Paper,Advances in Cryptology -- CRYPTO 2019,"The Fiat-Shamir transformation is a useful approach to building non-interactive arguments (of knowledge) in the random oracle model. Unfortunately, existing proof techniques are incapable of proving the security of Fiat-Shamir in the quantum setting. The problem stems from (1) the difficulty of quantum rewinding, and (2) the inability of current techniques to adaptively program random oracles in the quantum setting. In this work, we show how to overcome the limitations above in many settings. In particular, we give mild conditions under which Fiat-Shamir is secure in the quantum setting. As an application, we show that existing lattice signatures based on Fiat-Shamir are secure without any modifications.",Springer
"Marc, Tilen and Stopar, Miha and Hartman, Jan and Bizjak, Manca and Modic, Jolanda",Privacy-Enhanced Machine Learning with Functional Encryption,2019,10.1007/978-3-030-29959-0_1,https://doi.org/10.1007/978-3-030-29959-0_1,Conference Paper,Computer Security -- ESORICS 2019,"Functional encryption is a generalization of public-key encryption in which possessing a secret functional key allows one to learn a function of what the ciphertext is encrypting. This paper introduces the first fully-fledged open source cryptographic libraries for functional encryption. It also presents how functional encryption can be used to build efficient privacy-enhanced machine learning models and it provides an implementation of three prediction services that can be applied on the encrypted data. Finally, the paper discusses the advantages and disadvantages of the alternative approach for building privacy-enhanced machine learning models by using homomorphic encryption.",Springer
"Bettonte, Gabriella and Gilbert, Valentin and Vert, Daniel and Louise, St{\'e}phane and Sirdey, Renaud",Quantum Approaches for WCET-Related Optimization Problems,2022,10.1007/978-3-031-08760-8_18,https://doi.org/10.1007/978-3-031-08760-8_18,Conference Paper,Computational Science -- ICCS 2022,"This paper explores the potential of quantum computing on a WCET(Worst-Case Execution Time (of a program).)-related combinatorial optimization problem applied to a set of several polynomial special cases. We consider the maximization problem of determining the most expensive path in a control flow graph. In these graphs, vertices represent blocks of code whose execution times are fixed and known in advance. We port the considered optimization problem to the quantum framework by expressing it as a QUBO. We then experimentally compare the performances in solving the problem of classic Simulated Annealing (SA), Quantum Annealing (QA), and Quantum Approximate Optimization Algorithm (QAOA). Our experiments suggest that QA represents a fast equivalent of simulated annealing. Indeed, we measured the approximation ratio on the results of QA and SA, showing that their performances are comparable, at least on our set of simplified problems.",Springer
"Yu, Ying and Zhang, Chen and Ye, Lei and Yang, Ming and Zhang, Changsheng",A Multi-objective Artificial Bee Colony Algorithm for Multiple Sequence Alignment,2022,10.1007/978-3-030-97124-3_44,https://doi.org/10.1007/978-3-030-97124-3_44,Conference Paper,Simulation Tools and Techniques,"The multiple sequence alignment (MSA) problem is essential in biological research for finding specific relationship between the biologic sequences and their functions. This paper proposes a multi-objective artificial bee colony optimization algorithm for MSA (MOABC-MSA), which uses three kinds of searching to optimize a multi-objective MSA problem. The employed bee searching aims to make the solutions converge to the Pareto front (PF) of the problem; the onlooker bee accelerates the convergence speed; the scout bee facilitates the algorithm to avoid the local optimal. A comparative experiment is implemented on BAliBASE 3.0, a MSA benchmark. Experimental results show that the proposed algorithm has competitive performance with state-of-the-art metaheuristic algorithms.",Springer
"Ben-Sasson, Eli and Bentov, Iddo and Horesh, Yinon and Riabzev, Michael",Scalable Zero Knowledge with No Trusted Setup,2019,10.1007/978-3-030-26954-8_23,https://doi.org/10.1007/978-3-030-26954-8_23,Conference Paper,Advances in Cryptology -- CRYPTO 2019,"One of the approaches to constructing zero knowledge (ZK) arguments relies on ``PCP techniques'' that date back to influential works from the early 1990's [Babai et al., Arora et al. 1991-2]. These techniques require only minimal cryptographic assumptions, namely, the existence of a family of collision-resistant hash functions [Kilian, STOC 1992], and achieve two remarkable properties: (i) all messages generated by the verifier are public random coins, and (ii) total verification time is merely poly-logarithmic in the time needed to na{\""i}vely execute the computation being verified [Babai et al., STOC 1991].",Springer
"Khakpour, Narges and Parker, David",Partially-Observable Security Games for Attack-Defence Analysis in Software Systems,2025,10.1007/978-3-031-77382-2_9,https://doi.org/10.1007/978-3-031-77382-2_9,Conference Paper,Software Engineering and Formal Methods,"Given the presence of residual vulnerabilities in software systems, it is critical to apply suitable countermeasures in order to minimize the likelihood of an attack. In this paper we propose a formal approach, based on stochastic games, to threat analysis and synthesis of defence strategies for protecting systems with vulnerabilities. Crucially, we support analysis under partial observation, where some of the attacker's activities are unobservable or undetectable by the defender. We construct a one-sided partially observable security game and transform it into a perfect game, for which formal analysis is feasible. We prove that this transformation is sound for a sub-class of security games and a subset of objectives specified in the temporal logic rPATL. We implement our approach and evaluate it by applying it to a real-life example.",Springer
"Faginas-Lago, Noelia and de Arag{\~a}o, Em{\'i}lia Valen{\c{c}}a Ferreira and Mancini, Luca and Rosi, Marzio and Ascenzi, Daniela and Pirani, Fernando",Coding Cross Sections of an Electron Charge Transfer Process: Analysis of Different Cuts for the Entrance and Exit Potentials,2023,10.1007/978-3-031-37126-4_12,https://doi.org/10.1007/978-3-031-37126-4_12,Conference Paper,Computational Science and Its Applications -- ICCSA 2023 Workshops,"The paper presents the algorithm of a code written for exploring the collision dynamics of an electron transfer process between a neutral species and helium cation. Cuts of the entrance and exit potential energy surfaces are calculated in function of the radial distance to the center of mass of the neutral molecule, inclination angle and azimuth. Entrance and exit potential are calculated accounting for the electrostatic contribution and for non-electrostatic forces by employing the Improved Lennard-Jones function.",Springer
"Rao, Poojith U. and Sodhi, Balwinder",Scheduling with Multiple Dispatch Rules: A Quantum Computing Approach,2022,10.1007/978-3-031-08760-8_20,https://doi.org/10.1007/978-3-031-08760-8_20,Conference Paper,Computational Science -- ICCS 2022,"Updating the set of Multiple Dispatch Rules (MDRs) for scheduling of machines in a Flexible Manufacturing System (FMS) is computationally intensive. It becomes a major bottleneck when these rules have to be updated in real-time in response to changes in the manufacturing environment. Machine Learning (ML) based solutions for this problem are considered to be state-of-the-art. However, their accuracy and correctness depend on the availability of high-quality training data. To address the shortcomings of the ML-based approaches, we propose a novel Quadratic Unconstrained Binary Optimization (QUBO) formulation for the MDR scheduling problem. A novel aspect of our formulation is that it can be efficiently solved on a quantum annealer. We solve the proposed formulation on a production quantum annealer from D-Wave and compare the results with single dispatch rule based baseline model.",Springer
"Hafez, Wael",Information as Entanglement---A Framework for Artificial General Intelligence,2023,10.1007/978-3-031-19907-3_3,https://doi.org/10.1007/978-3-031-19907-3_3,Conference Paper,Artificial General Intelligence,"Artificial approaches to intelligence depend on computational models to process information and provide intelligent capabilities. Due to the absence of uniform definitions of what constitutes intelligence and what is information, the capabilities such models provide differ according to their interpretations of intelligence and implicit assumptions about what is information. The variety of interpretations of intelligence and information also indicate that existing computational models for intelligence provide specialized rather than general capabilities. The study argues that achieving artificial general intelligence requires a unified, universal definition of information, which would subsequently yield precise formal insights into what constitutes intelligence. The paper provides a definition of information as the level of entanglement between two agents---or between an agent and its environment---measured in bits. Accordingly, intelligence is the agent's continuous activity to maintain and maximize its entanglement with its environment in the face of change. As the level of an agent's entanglement with its environment is a direct indicator of its ability to influence it and be influenced by it, we conclude that the change in an agent's information is the primary control signal for guiding entanglement maximization and, ultimately, the intelligent capabilities of an agent. The paper then introduces a novel class of agents, the information digital twin, which enables a system or agent to control its information and quantify its intelligent activities and enable it to increase its information.",Springer
"Esser, Andre and Heuer, Felix and K{\""u}bler, Robert and May, Alexander and Sohler, Christian",Dissection-BKW,2018,10.1007/978-3-319-96881-0_22,https://doi.org/10.1007/978-3-319-96881-0_22,Conference Paper,Advances in Cryptology -- CRYPTO 2018,"The slightly subexponential algorithm of Blum, Kalai and Wasserman (BKW) provides a basis for assessing LPN/LWE security. However, its huge memory consumption strongly limits its practical applicability, thereby preventing precise security estimates for cryptographic LPN/LWE instantiations.",Springer
"Brakerski, Zvika and Lyubashevsky, Vadim and Vaikuntanathan, Vinod and Wichs, Daniel",Worst-Case Hardness for LPN and Cryptographic Hashing via Code Smoothing,2019,10.1007/978-3-030-17659-4_21,https://doi.org/10.1007/978-3-030-17659-4_21,Conference Paper,Advances in Cryptology -- EUROCRYPT 2019,"We present a worst case decoding problem whose hardness reduces to that of solving the Learning Parity with Noise (LPN) problem, in some parameter regime. Prior to this work, no worst case hardness result was known for LPN (as opposed to syntactically similar problems such as Learning with Errors). The caveat is that this worst case problem is only mildly hard and in particular admits a quasi-polynomial time algorithm, whereas the LPN variant used in the reduction requires extremely high noise rate of {\$}{\$}1/2-1/{\backslash}mathrm{\{}poly{\}}(n){\$}{\$}. Thus we can only show that ``very hard'' LPN is harder than some ``very mildly hard'' worst case problem. We note that LPN with noise {\$}{\$}1/2-1/{\backslash}mathrm{\{}poly{\}}(n){\$}{\$}already implies symmetric cryptography.",Springer
"Don, Jelle and Fehr, Serge and Majenz, Christian and Schaffner, Christian",Security of the Fiat-Shamir Transformation in the Quantum Random-Oracle Model,2019,10.1007/978-3-030-26951-7_13,https://doi.org/10.1007/978-3-030-26951-7_13,Conference Paper,Advances in Cryptology -- CRYPTO 2019,"The famous Fiat-Shamir transformation turns any public-coin three-round interactive proof, i.e., any so-called {\$}{\$}{\backslash}Sigma {\{}{\backslash}text {\{}-protocol{\}}{\}}{\$}{\$}, into a non-interactive proof in the random-oracle model. We study this transformation in the setting of a quantum adversary that in particular may query the random oracle in quantum superposition.",Springer
"Imbaquingo-Esparza, Daisy and D{\'i}az, Javier and Arciniega, Silvia and J{\'a}come, Jos{\'e} and Ortega-Bustamante, MacArthur",Metric Identification Evaluating Security Information: A Systematic Literature Review,2022,10.1007/978-3-031-19961-5_16,https://doi.org/10.1007/978-3-031-19961-5_16,Conference Paper,Technologies and Innovation,"Metrics for the evaluation of information security basically contribute to risk reduction within organizations dealing with the manipulation of information. However, in information security metric approach, generally there is not a standard classified appreciation regarding essential metrics within the required scope to do this activity in risk reduction and asset protection. Therefore, this research is a Systematic Literature Review (SLR) regarding the evaluation of information security. In this study, 50 bibliographical data-base extracted articles such as ScienceDirect, Scopus, IEEE, ACM Digital Library, Hindawi, MDPI and Springer were gathered and analyzed. Scientific documents answered the proposed research question whereas results identified several information security metric classifications such as integrity, vulnerability, authorization and confidentiality.",Springer
"Dahi, Zakaria Abdelmoiz and Chicano, Francisco and Luque, Gabriel and Derbel, Bilel and Alba, Enrique",Scalable Quantum Approximate Optimiser for Pseudo-Boolean Multi-objective Optimisation,2024,10.1007/978-3-031-70085-9_17,https://doi.org/10.1007/978-3-031-70085-9_17,Conference Paper,Parallel Problem Solving from Nature -- PPSN XVIII,"Quantum computation uses quantum mechanical principles to reach beyond-classical computational power. This has endless applications, especially in optimisation-problems' solving. Most of today's quantum optimisers, more specifically, Quantum Approximate Optimisation Algorithm (QAOA), were originally designed to solve single-objective problems, although real-life scenarios include generally dealing with multiple objectives. Very preliminary literature with design/implementation limitations has been done in this sense. This makes dealing with such limitations and expanding the QAOA applicability to multi-objective optimisation an important step towards advancing quantum computation. To do so, this work presents a decomposition-based Multi-Objective QAOA (MO-QAOA) able to solve multi-objective problems. The proposal's design explores QAOA's features considering the error-prone and limited nature of today's quantum computers as well as the costly quantum simulation. This work's contributions stand in designing both, (I) sequential and parallel MO-QAOA, based on (II) weighted-sum and Tchebycheff scalarisation, by (III) exploring the QAOA's parameters' transference. The validation has been done using 2, 3 and 4-objectives problems of several sizes/complexities/types, using up to 2000 slaves/jobs running quantum computer simulators, as well as three real IBM 127-qubits' quantum computers. The results show up to 89{\%} execution-time decrease, which supports the applicability/reliability of the proposal in today's time-constrained and error-prone quantum computers.",Springer
"Saarinen, Markku-Juhani O.","HILA5: On Reliability, Reconciliation, and Error Correction for Ring-LWE Encryption",2018,10.1007/978-3-319-72565-9_10,https://doi.org/10.1007/978-3-319-72565-9_10,Conference Paper,Selected Areas in Cryptography -- SAC 2017,"We describe a new reconciliation method for Ring-LWE that has a significantly smaller failure rate than previous proposals while reducing ciphertext size and the amount of randomness required. It is based on a simple, deterministic variant of Peikert's reconciliation that works with our new ``safe bits'' selection and constant-time error correction techniques. The new method does not need randomized smoothing to achieve non-biased secrets. When used with the very efficient ``New Hope'' Ring-LWE parametrization we achieve a decryption failure rate well below {\$}{\$}2^{\{}-128{\}}{\$}{\$}2-128(compared to {\$}{\$}2^{\{}-60{\}}{\$}{\$}2-60of the original), making the scheme suitable for public key encryption in addition to key exchange protocols; the reconciliation approach saves about {\$}{\$}40 {\backslash}{\%}{\$}{\$}40{\%}in ciphertext size when compared to the common LP11 Ring-LWE encryption scheme. We perform a combinatorial failure analysis using full probability convolutions, leading to a precise understanding of decryption failure conditions on bit level. Even with additional implementation security and safety measures the new scheme is still essentially as fast as the New Hope but has slightly shorter messages. The new techniques have been instantiated and implemented as a Key Encapsulation Mechanism (KEM) and public key encryption scheme designed to meet the requirements of NIST's Post-Quantum Cryptography effort at very high security level.",Springer
"Dudek, Jeffrey M. and Phan, Vu H. N. and Vardi, Moshe Y.",DPMC: Weighted Model Counting by Dynamic Programming on Project-Join Trees,2020,10.1007/978-3-030-58475-7_13,https://doi.org/10.1007/978-3-030-58475-7_13,Conference Paper,Principles and Practice of Constraint Programming,"We propose a unifying dynamic-programming framework to compute exact literal-weighted model counts of formulas in conjunctive normal form. At the center of our framework are project-join trees, which specify efficient project-join orders to apply additive projections (variable eliminations) and joins (clause multiplications). In this framework, model counting is performed in two phases. First, the planning phase constructs a project-join tree from a formula. Second, the execution phase computes the model count of the formula, employing dynamic programming as guided by the project-join tree. We empirically evaluate various methods for the planning phase and compare constraint-satisfaction heuristics with tree-decomposition tools. We also investigate the performance of different data structures for the execution phase and compare algebraic decision diagrams with tensors. We show that our dynamic-programming model-counting framework DPMC is competitive with the state-of-the-art exact weighted model counters Cachet, c2d, d4, and miniC2D.",Springer
"Phillipson, Frank",Leveraging Quantum Technology to Enhance Community Services and Supportive ICT Infrastructure,2024,10.1007/978-3-031-60433-1_3,https://doi.org/10.1007/978-3-031-60433-1_3,Conference Paper,Innovations for Community Services,"This article explores the transformative potential of quantum technology in community services, emphasising quantum sensing, quantum computing algorithms, and quantum communication. Community services, spanning healthcare, education, and environmental conservation, are crucial for resident well-being. Quantum technology, rooted in principles like superposition and entanglement, is presented as a game-changer. Quantum sensing offers unparalleled precision, benefiting environmental monitoring, traffic management, and healthcare diagnostics. Quantum computing algorithms, leveraging qubits, promise breakthroughs in resource allocation, data analysis, and telecommunications optimisation. Quantum communication, particularly quantum key distribution, ensures secure data transmission, safeguarding sensitive information in fields like finance and healthcare. The article envisions a future where quantum technology optimises community services, fostering data accuracy, speed, and privacy. The collaborative incorporation of quantum technology into ICT infrastructure is crucial for realising these advancements and enhancing community well-being. The recommendations stress enhancing ICT infrastructure for seamless quantum technology integration. Quantum-safe encryption, high-speed communication networks, and quantum-ready data centres are crucial. Collaboration among stakeholders is deemed essential for identifying applications and ensuring comprehensive integration.",Springer
"Booth, Kyle E. C. and O'Gorman, Bryan and Marshall, Jeffrey and Hadfield, Stuart and Rieffel, Eleanor",Quantum-Accelerated Global Constraint Filtering,2020,10.1007/978-3-030-58475-7_5,https://doi.org/10.1007/978-3-030-58475-7_5,Conference Paper,Principles and Practice of Constraint Programming,"Motivated by recent advances in quantum algorithms and gate-model quantum computation, we introduce quantum-accelerated filtering algorithms for global constraints in constraint programming. We adapt recent work in quantum algorithms for graph problems and identify quantum subroutines that accelerate the main domain consistency algorithms for the alldifferent constraint and the global cardinality constraint (gcc). The subroutines are based on quantum algorithms for finding maximum matchings and strongly connected components in graphs, and provide speedups over the best classical algorithms. We detail both complete and bounded-probability frameworks for quantum-accelerated global constraint filtering algorithms within backtracking search.",Springer
"Fathallah, Walid and Amor, Nahla Ben and Leray, Philippe",An Optimized Quantum Circuit Representation of Bayesian Networks,2024,10.1007/978-3-031-45608-4_13,https://doi.org/10.1007/978-3-031-45608-4_13,Conference Paper,Symbolic and Quantitative Approaches to Reasoning with Uncertainty,"In recent years, there has been a significant upsurge in the interest surrounding Quantum machine learning, with researchers actively developing methods to leverage the power of quantum technology for solving highly complex problems across various domains. However, implementing gate-based quantum algorithms on noisy intermediate quantum devices (NISQ) presents notable challenges due to limited quantum resources and inherent noise. In this paper, we propose an innovative approach for representing Bayesian networks on quantum circuits, specifically designed to address these challenges. Our aim is to minimize the required quantum resource needed to implement a Quantum Bayesian network (QBN) on a quantum computer. By carefully designing the sequence of quantum gates within the dynamic circuit, we can optimize the utilization of limited quantum resources while mitigating the impact of noise. Furthermore, we present an experimental study that demonstrates the effectiveness and efficiency of our proposed approach. Through simulations and experiments on NISQ devices, we show that our dynamic circuit representation significantly reduces the resource requirements and enhances the robustness of QBN implementation. These findings highlight the potential of our approach to pave the way for practical applications of Quantum Bayesian networks on currently available quantum hardware.",Springer
"Drucker, Nir and Gueron, Shay and Kostic, Dusan",To Reject or Not Reject: That Is the Question. The Case of BIKE Post Quantum KEM,2023,10.1007/978-3-031-28332-1_15,https://doi.org/10.1007/978-3-031-28332-1_15,Conference Paper,ITNG 2023 20th International Conference on Information Technology-New Generations,"NIST post-quantum cryptography standardization project just entered its final Round 4, where three KEMs are evaluated for standardization, as alternatives. BIKE is one of them. This paper deals with several considerations around building an isochronous and constant-time implementation of the errors-vector generation (EVG) that is used by BIKE. The starting point is the Round 3 BIKE (Ver. 4.2), where a recently published timing attack motivated some changes toward the Round 4 submission. The easiest mitigation simply redefines the EVG to be isochronous. This approach was readily available (already in June 2022) in [1]. It requires only minor changes in the Round 3 specification and reference code, with no changes to the KATs. BIKE team chose a different, newly proposed EVG method (with new KATs). It was integrated into the definition and reference code of the first Round 4 submission (Ver. 5.0) but turned out to be erroneous. We alerted NIST and the BIKE team about the problems, and proposed solutions. This responsible disclosure allowed the BIKE team to very quickly revisit the design decision per one of our solutions, modify the specifications document and the associated proof and submit a revised Round 4 submission (Ver. 5.1). NIST gracefully accepted the fixed specification as the submission (fortunately, before it was posted in the official NIST web site). In this paper, we explore the problems, review and compare some engineering aspects associated with different approaches, present more alternatives and conclude with our critique and recommendations.",Springer
"Yan, Peng and Jiang, Hanru and Yu, Nengkun",Approximate Relational Reasoning for Quantum Programs,2024,10.1007/978-3-031-65633-0_22,https://doi.org/10.1007/978-3-031-65633-0_22,Conference Paper,Computer Aided Verification,"Quantum computation is inevitably subject to imperfections in its implementation. These imperfections arise from various sources, including environmental noise at the hardware level and the introduction of approximate implementations by quantum algorithm designers, such as lower-depth computations. Given the significant advantage of relational logic in program reasoning and the importance of assessing the robustness of quantum programs between their ideal specifications and imperfect implementations, we design a proof system to verify the approximate relational properties of quantum programs. We demonstrate the effectiveness of our approach by providing the first formal verification of the renowned low-depth approximation of the quantum Fourier transform. Furthermore, we validate the approximate correctness of the repeat-until-success algorithm. From the technical point of view, we develop approximate quantum coupling as a fundamental tool to study approximate relational reasoning for quantum programs, a novel generalization of the widely used approximate probabilistic coupling in probabilistic programs, answering a previously posed open question for projective predicates.",Springer
"Caivano, Danilo and Catalano, Christian and De Vincentiis, Mirko and Lako, Alfred and Pagano, Alessandro",MaREA: Multi-class Random Forest for Automotive Intrusion Detection,2024,10.1007/978-3-031-49269-3_3,https://doi.org/10.1007/978-3-031-49269-3_3,Conference Paper,Product-Focused Software Process Improvement,"The technology inside modern vehicles is rapidly growing and poses newer security risks, as vehicle communication protocols are not yet fully secured and vulnerable to attacks. Consequently, the implementation of automotive cybersecurity systems has gained more attention. Controller Area Network (CAN) is one of the most studied communication protocols in the literature and lacks inherent cybersecurity measures. Several works proposed Intrusion Detection Systems (IDSs) using Machine Learning (ML) and Deep Learning (DL) algorithms to identify attacks on the CAN bus. Exploiting ML or DL techniques in a multi-class approach makes it possible to know the attack typology and to support developers' decisions to integrate concrete design methods in the software automotive development life-cycle. However, most automotive IDSs are tested on data sets that contain raw CAN messages without the possibility of decoding these messages to understand how the attack was generated. Based on these gaps, a Multi-class Random Forest for Automotive Intrusion Detection (MaREA) is presented, and a new Synthetic Automotive Hacking Dataset (SA-Hacking Dataset) is generated with a Database for CAN (DBC) file. First, the model is validated on the Car-Hacking dataset and compared with two other works in the literature that used the same classifier and dataset for the multi-class approach. Then, the Random Forest model is tested by concatenating the Survival Analysis Dataset and the SA-Hacking Dataset. The proposed approach presented better-quality results for both the Car-Hacking dataset and the aforementioned concatenated dataset.",Springer
"Alvarado-Valiente, Jaime and Romero-{\'A}lvarez, Javier and Casco-Seco, Jorge and Moguel, Enrique and Garcia-Alonso, Jose and Murillo, Juan M.",Circuit Scheduling Policies on Current QPUs: QCRAFT Scheduler,2025,10.1007/978-981-96-0808-9_15,https://doi.org/10.1007/978-981-96-0808-9_15,Conference Paper,Service-Oriented Computing,"In the contemporary context of quantum computing, the availability of quantum computing platforms through cloud services is increasing, which has democratized access to this technology. This is generating interest in the industry and the scientific community. However, the increasing demand for access to quantum computers is facing limited resource availability, leading to prolonged waiting times for users and high execution costs. Leveraging the under-utilization, it has already been shown that it is possible to optimize the use of current QPUs by scheduling quantum tasks, and the generated noise does not significantly affect the results. This can be achieved concretely by combining circuits. To this end, the main objective of this work is to define and validate three circuit scheduling policies for the QCRAFT Scheduler, improving the efficiency of QPU utilization and reducing both waiting times and associated task execution costs. A validation of each of the policies has been performed, achieving an average cost reduction of 83.67{\%} and an average task reduction of 84.20{\%} concerning the single execution of the same circuits.",Springer
"Castane, Gabriel G. and Martinez, Alejandro and Ramadan, Qusai and Gkika, Zaneta and Panagiotis, Mpempis and Vyhmeister, Eduardo",Market Analysis of a Data Platform in the European Data Ecosystem,2024,10.1007/978-3-031-63227-3_7,https://doi.org/10.1007/978-3-031-63227-3_7,Conference Paper,Artificial Intelligence Applications and Innovations. AIAI 2024 IFIP WG 12.5 International Workshops,"In the era of data analytics, industries can use data to enhance market analyses and seek better opportunities for current, or new, business opportunities. Furthermore, companies can consider their data as an intangible asset, allowing expansion, by a proper market analysis, and economic opportunities through data monetization. These strategies define the use of data for indirect and direct purposes. Despite the idea of adopting data monetization practices, a considerable gap exists between expectations and reality. For example, the definition of strategies, methods, and analyses to perform data valuation. This gap necessitates a comprehensive exploration considering the different nuisances of data monetization. To achieve a broader understanding of the data monetization landscape, a market evaluation, through an exploration of the market environment and the stakeholders involved, is necessary. The present work contributes to this understanding by facilitating a market analysis for data valuation within the European community. This analysis aims to shed light on critical aspects influencing the valuation of data in the European context, offering insights into the market dynamics, emerging trends, and the evolving landscape of data monetization strategies within this region.",Springer
"Deochakke, Advait and Tyagi, Amit Kumar",Analysis of Ransomware Security on Cloud Storage Systems,2022,10.1007/978-3-031-23724-9_5,https://doi.org/10.1007/978-3-031-23724-9_5,Conference Paper,Advancements in Interdisciplinary Research,"Over the years cloud computing and cloud storage solutions have grown into over a 50-billion-dollar industry, and that signifies over 50 {\%} of all corporate data being stored in the cloud as of 2021. In accordance, attacks over these files have grown exponentially, with average damages exceeding multiple millions of dollars per attack. Cloud storages are more susceptible to these attacks, due to the physical factor of accessing local storage being removed, and a simple connection to the internet. Despite the great convenience and arguably fulfilling core necessities during the pandemic, the Cloud storage model is vulnerable and an incredibly juicy target. These ransomware attacks are proving to be huge security risks around the world as such. Combine these with various other problems such as area of jurisdiction of law enforcement agencies and blockchain-based payments making tracing these payments a nigh-impossible task, and the threat is apparent at even the first glance. In this paper, (i) we analyse the insidious nature of ransomware and their power and threat levels, (ii) various papers and industry data to give a comprehensive analysis of the level of security that currently exists, (iii) discuss large security breaches in recent history, and (iv) consider up and coming solutions for cloud storage security. After going through these, we shall draw a final (v) conclusion, on the state of cybersecurity and cloud storage based on presented data.",Springer
"Micheli, Andrea",Against the Clock: Lessons Learned by Applying Temporal Planning in Practice,2025,10.1007/978-3-031-80607-0_1,https://doi.org/10.1007/978-3-031-80607-0_1,Conference Paper,AIxIA 2024 -- Advances in Artificial Intelligence,"Automated Planning is a foundational area of AI research, focusing on the automated synthesis of courses of actions to achieve a desired goal within a formally-modeled system. When dealing with time and temporal constraints, this problem is known as Temporal Planning. In this paper, we will present our research on the application of temporal planning to real-world scenarios, and highlight the open research directions in this field. Starting from a series of projects in different application domains -- including robotics, manufacturing, and logistics -- we will explore key challenges encountered, the (sometimes hard) lessons learned, and the techniques, tools, and methodologies that have emerged from these efforts. Additionally, we will introduce and discuss preliminary results on applying Reinforcement Learning techniques to tailor temporal planners to specific application contexts.",Springer
"Balauca, Stefan and Arusoaie, Andreea",Efficient Constructions for Simulating Multi Controlled Quantum Gates,2022,10.1007/978-3-031-08760-8_16,https://doi.org/10.1007/978-3-031-08760-8_16,Conference Paper,Computational Science -- ICCS 2022,"Multi Controlled Gates, with Multi Controlled Toffoli as primary example are a building block for a lot of complex quantum algorithms in the domains of discrete arithmetic, cryptography, machine learning, and image processing. However, these gates cannot be physically implemented in quantum hardware and therefore they need to be decomposed into many smaller elementary gates. In this work we analyse previously proposed circuit constructions for MCT gates and describe 6 new methods for generating MCT circuits with efficient costs, less restrictions, and improved applicability.",Springer
"Saito, Tsunekazu and Xagawa, Keita and Yamakawa, Takashi",Tightly-Secure Key-Encapsulation Mechanism in the Quantum Random Oracle Model,2018,10.1007/978-3-319-78372-7_17,https://doi.org/10.1007/978-3-319-78372-7_17,Conference Paper,Advances in Cryptology -- EUROCRYPT 2018,"Key-encapsulation mechanisms secure against chosen ciphertext attacks (IND-CCA-secure KEMs) in the quantum random oracle model have been proposed by Boneh, Dagdelen, Fischlin, Lehmann, Schafner, and Zhandry (CRYPTO 2012), Targhi and Unruh (TCC 2016-B), and Hofheinz, H{\""o}velmanns, and Kiltz (TCC 2017). However, all are non-tight and, in particular, security levels of the schemes obtained by these constructions are less than half of original security levels of their building blocks.",Springer
"Arman, Ala and Bellini, Pierfrancesco and Nesi, Paolo",Searching for Heterogeneous Geolocated Services via API Federation,2022,10.1007/978-3-031-10592-0_14,https://doi.org/10.1007/978-3-031-10592-0_14,Conference Paper,Computational Science and Its Applications -- ICCSA 2022 Workshops,"In the context of Smart City applications, the usage of Smart City APIs, for exposing services and data to web and mobile applications, is quite frequent. Most of the mobile solutions, using the Smart City APIs, are focused on a single city which can expose several services that are contextualized on a single geographic area. In fact, passing from one city/area to another, the users must change applications and services, and consequently, discontinuity problems could occur at the border. This also happens for the lack of interoperability among the Smart City APIs and related operators that may strongly differ, depending on the applicative levels at which they are developed. A large part of the services proposed via Smart City APIs are geo-localized, and as a result, may provide different results according to the GPS coordinates of the client context. In this paper, the problem of the federation of smart city services is addressed by proposing a solution for federating smart city APIs, related knowledge-base, and ontology. To this end, a solution to autonomously federate API services has been presented together with other requirements (e.g., efficiency, overlapped and included areas of competence, distributed searches, security and privacy, scalability, interoperability among different smart city application servers) which are typically neither all satisfied by classical Geographical Information System (GIS) solutions that federate the services at the level of database nor by those based on Internet of Things (IoT) Brokers. The solution is open-source and has been developed in the context of the Snap4City European platform enhancing the former Km4City Ontology and API of the Sii-Mobility national project (https://www.snap4city.org). The solution is presently in use in Snap4City federation of Smart City Services in Europe, among several cities/areas including, Florence, Tuscany, Bologna, Helsinki, Antwerp, Valencia, Dubrovnik, and Mostar, just to mention a few.",Springer
"Makarov, Ant{\'o}n and Taddei, M{\'a}rcio M. and Osaba, Eneko and Franceschetto, Giacomo and Villar-Rodr{\'i}guez, Esther and Oregi, Izaskun",Optimization of Image Acquisition for Earth Observation Satellites via Quantum Computing,2023,10.1007/978-3-031-48232-8_1,https://doi.org/10.1007/978-3-031-48232-8_1,Conference Paper,Intelligent Data Engineering and Automated Learning -- IDEAL 2023,"Satellite image acquisition scheduling is a problem that is omnipresent in the earth observation field; its goal is to find the optimal subset of images to be taken during a given orbit pass under a set of constraints. This problem, which can be modeled via combinatorial optimization, has been dealt with many times by the artificial intelligence and operations research communities. However, despite its inherent interest, it has been scarcely studied through the quantum computing paradigm. Taking this situation as motivation, we present in this paper two QUBO formulations for the problem, using different approaches to handle the non-trivial constraints. We compare the formulations experimentally over 20 problem instances using three quantum annealers currently available from D-Wave, as well as one of its hybrid solvers. Fourteen of the tested instances have been obtained from the well-known SPOT5 benchmark, while the remaining six have been generated ad-hoc for this study. Our results show that the formulation and the ancilla handling technique is crucial to solve the problem successfully. Finally, we also provide practical guidelines on the size limits of problem instances that can be realistically solved on current quantum computers.",Springer
"Zhandry, Mark","How to Record Quantum Queries, and Applications to Quantum Indifferentiability",2019,10.1007/978-3-030-26951-7_9,https://doi.org/10.1007/978-3-030-26951-7_9,Conference Paper,Advances in Cryptology -- CRYPTO 2019,"The quantum random oracle model (QROM) has become the standard model in which to prove the post-quantum security of random-oracle-based constructions. Unfortunately, none of the known proof techniques allow the reduction to record information about the adversary's queries, a crucial feature of many classical ROM proofs, including all proofs of indifferentiability for hash function domain extension.",Springer
"Liang, Zhen and Ren, Dejin and Liu, Wanwei and Wang, Ji and Yang, Wenjing and Xue, Bai",Safety Verification for Neural Networks Based on Set-Boundary Analysis,2023,10.1007/978-3-031-35257-7_15,https://doi.org/10.1007/978-3-031-35257-7_15,Conference Paper,Theoretical Aspects of Software Engineering,"Neural networks (NNs) are increasingly applied in safety-critical systems such as autonomous vehicles. However, they are fragile and are often ill-behaved. Consequently, their behaviors should undergo rigorous guarantees before deployment in practice. In this paper, we propose a set-boundary reachability method to investigate the safety verification problem of NNs from a topological perspective. Given an NN with an input set and a safe set, the safety verification problem is to determine whether all outputs of the NN resulting from the input set fall within the safe set. In our method, the homeomorphism property of NNs is mainly exploited, which establishes a relationship mapping boundaries to boundaries. The exploitation of this property facilitates reachability computations via extracting subsets of the input set rather than the entire input set, thus controlling the wrapping effect in reachability analysis and facilitating the reduction of computation burdens for safety verification. The homeomorphism property exists in some widely used NNs such as invertible NNs. Notable representations are invertible residual networks (i-ResNets) and Neural ordinary differential equations (Neural ODEs). For these NNs, our set-boundary reachability method only needs to perform reachability analysis on the boundary of the input set. For NNs that do not feature this property with respect to the input set, we explore subsets of the input set for establishing the local homeomorphism property and then abandon these subsets for reachability computations. Finally, some examples demonstrate the performance of the proposed method.",Springer
"Wittingen, Ellen and Huisman, Marieke and {\c{S}}akar, {\""O}mer",Deductive Verification of SYCL in VerCors,2025,10.1007/978-3-031-77382-2_11,https://doi.org/10.1007/978-3-031-77382-2_11,Conference Paper,Software Engineering and Formal Methods,"SYCL is a C++ programming model for the development of heterogeneous programs. It uses the concept of kernels, where multiple instances of a computation are executed concurrently on a computing unit. This concurrency entails that the set of possible program behaviours can be of considerable size, which makes these programs error-prone. Formal verification could be used to ensure the correctness of all these possible program behaviours. However, there exist no formal verification tools for SYCL.",Springer
"Martella, Cristian and Martella, Angelo and Longo, Antonella",EdgER: Entity Resolution at the Edge for Next Generation Web Systems,2024,10.1007/978-3-031-62362-2_13,https://doi.org/10.1007/978-3-031-62362-2_13,Conference Paper,Web Engineering,"Thanks to the advances of emerging technologies like Edge and Cloud Computing and microservice development, web architectures are evolving to support Big Data platforms fully. The decentralization of the traditional cloud-centric approach pushes microservices towards the edge of the Internet when constraints exist regarding response time, security, and proximity services availability. This work proposes an approach for detecting anomalies at the edge called EdgER based on entity resolution techniques. Such an approach can be adopted for any application providing proximity-added-value service, even in near real-time. In this sense, a case study is provided in the photovoltaics domain. By implementing EdgER's building blocks at the edge, it is possible to reconcile the received IoT data streams early against a predefined data model and identify near real-time anomalies in energy production and/or in smart photovoltaic panel operations. In general, EdgeER can also significantly contribute to improving the quality of the data managed by the overall Big Data platform and facilitating the implementation of privacy-preserving proximity-added-value services.",Springer
"Krishnamurthy, Oku and Vemulapalli, Gopichand",Advancing Sustainable Cybersecurity: Exploring Trends and Overcoming Challenges with Generative AI,2025,10.1007/978-3-031-71729-1_2,https://doi.org/10.1007/978-3-031-71729-1_2,Conference Paper,"Sustainable Development through Machine Learning, AI and IoT","This research paper delves into the realm of cybersecurity with a specific focus on the transformative potential of Generative AI. As digital landscapes evolve, the need for robust cybersecurity measures becomes paramount. The abstract explores the emerging trends and inherent challenges associated with leveraging Generative AI to enhance cybersecurity frameworks. Generative AI, encompassing technologies like deep learning and neural networks, presents a paradigm shift in cybersecurity by proactively anticipating and countering sophisticated cyber threats. The paper addresses the sustainability aspects of implementing Generative AI in cybersecurity, emphasizing responsible practices and ethical considerations. Through a comprehensive examination of current trends and challenges, this research aims to contribute valuable insights to the ongoing discourse on fortifying digital environments sustainably and effectively.",Springer
"Jalali, Amir and Azarderakhsh, Reza and Mozaffari-Kermani, Mehran",Efficient Post-Quantum Undeniable Signature on 64-Bit ARM,2018,10.1007/978-3-319-72565-9_14,https://doi.org/10.1007/978-3-319-72565-9_14,Conference Paper,Selected Areas in Cryptography -- SAC 2017,"We present a full-fledged, highly-optimized, constant-time software for post-quantum supersingular isogeny-based undeniable signature (SIUS) on the ARMv8 platforms providing 83- and 110-bit quantum security levels. To the best of our knowledge, this work is the first empirical implementation of isogeny-based quantum-resistant undeniable signature presented to date. The proposed software is developed on the top of our optimized hand-written ARMv8 assembly arithmetic library and benchmarked on a variety of platforms. The entire protocol runs less than a second on Huawei Nexus smart phone, providing 83-bit quantum security level. Moreover, our signature and public key sizes are 25{\%} smaller than the original SIUS scheme. We remark that the SIUS protocol, similar to other isogeny-based schemes, suffers from the excessive number of operations, affecting its overall performance. Nonetheless, its significantly smaller key and signature sizes make it a promising candidate for post-quantum cryptography.",Springer
"Bernholdt, David E. and Doucet, Mathieu and Godoy, William F. and Malviya-Thakur, Addi and Watson, Gregory R.",A Survey on Sustainable Software Ecosystems to Support Experimental and Observational Science at Oak Ridge National Laboratory,2022,10.1007/978-3-031-08760-8_46,https://doi.org/10.1007/978-3-031-08760-8_46,Conference Paper,Computational Science -- ICCS 2022,"In the search for a sustainable approach for software ecosystems that supports experimental and observational science (EOS) across Oak Ridge National Laboratory (ORNL), we conducted a survey to understand the current and future landscape of EOS software and data. This paper describes the survey design we used to identify significant areas of interest, gaps, and potential opportunities, followed by a discussion on the obtained responses. The survey formulates questions about project demographics, technical approach, and skills required for the present and the next five years. The study was conducted among 38 ORNL participants between June and July of 2021 and followed the required guidelines for human subjects training. We plan to use the collected information to help guide a vision for sustainable, community-based, and reusable scientific software ecosystems that need to adapt effectively to: i) the evolving landscape of heterogeneous hardware in the next generation of instruments and computing (e.g. edge, distributed, accelerators), and ii) data management requirements for data-driven science using artificial intelligence.",Springer
"Mbaye, Mouhamed Lamine and Sow, Demba and Sow, Djiby",The Post-quantum Probabilistic Signature Scheme,2022,10.1007/978-3-030-95630-1_8,https://doi.org/10.1007/978-3-030-95630-1_8,Conference Paper,Informatics and Intelligent Applications,"In this paper, we present a variant of the standard PSS-R (Probabilistic Signature Scheme with message Recovery) signature scheme, called pqPSS. Our scheme is an RSA-based signature scheme but with a random element generated for each signature process. It is proved secure against chosen message attacks in the random oracle model. Its security level is close to that of RSA. For a random of 5 bits, we have {\$}{\$}{\backslash}varepsilon {\_}{\{}{\backslash}mathcal {\{}R{\}}{\}}=0.96875 {\backslash} {\backslash}varepsilon {\_}{\{}{\backslash}mathcal {\{}A{\}}{\}}{\$}{\$}$\epsilon$R=0.96875$\epsilon$A, where {\$}{\$}{\backslash}varepsilon {\_}{\{}{\backslash}mathcal {\{}R{\}}{\}}{\$}{\$}$\epsilon$Ris the success probability of a reduction algorithm {\$}{\$}{\backslash}mathcal {\{}R{\}}{\$}{\$}Rthat can invert RSA by using an attacker {\$}{\$}{\backslash}mathcal {\{}A{\}}{\$}{\$}Athat breaks pqPSS with probability {\$}{\$}{\backslash}varepsilon {\_}{\{}{\backslash}mathcal {\{}A{\}}{\}}{\$}{\$}$\epsilon$A. We have also the success probability of the simulation independent of the number of signing and hashing oracle queries and it is possible to sign and recover a message with a large size while keeping the size of the random salt also large. This new signature scheme is more secure than PSS-R relatively to all known reductions, but it is less efficient. It is also intended to be used to obtain the integrity and authenticity of GOOSE (Generic Object Oriented Substation Event) messages in the same way as other RSA-based signature schemes such as PSS.",Springer
"Narayanan, Sri Hari Krishna and Propson, Thomas and Bongarti, Marcelo and H{\""u}ckelheim, Jan and Hovland, Paul",Reducing Memory Requirements of Quantum Optimal Control,2022,10.1007/978-3-031-08760-8_11,https://doi.org/10.1007/978-3-031-08760-8_11,Conference Paper,Computational Science -- ICCS 2022,"Quantum optimal control problems are typically solved by gradient-based algorithms such as GRAPE, which suffer from exponential growth in storage with increasing number of qubits and linear growth in memory requirements with increasing number of time steps. These memory requirements are a barrier for simulating large models or long time spans. We have created a nonstandard automatic differentiation technique that can compute gradients needed by GRAPE by exploiting the fact that the inverse of a unitary matrix is its conjugate transpose. Our approach significantly reduces the memory requirements for GRAPE, at the cost of a reasonable amount of recomputation. We present benchmark results based on an implementation in JAX.",Springer
"Aragon, Nicolas and Blazy, Olivier and Gaborit, Philippe and Hauteville, Adrien and Z{\'e}mor, Gilles",Durandal: A Rank Metric Based Signature Scheme,2019,10.1007/978-3-030-17659-4_25,https://doi.org/10.1007/978-3-030-17659-4_25,Conference Paper,Advances in Cryptology -- EUROCRYPT 2019,"We describe a variation of the Schnorr-Lyubashevsky approach to devising signature schemes that is adapted to rank based cryptography. This new approach enables us to obtain a randomization of the signature, which previously seemed difficult to derive for code-based cryptography. We provide a detailed analysis of attacks and an EUF-CMA proof for our scheme. Our scheme relies on the security of the Ideal Rank Support Learning and the Ideal Rank Syndrome problems and a newly introduced problem: Product Spaces Subspaces Indistinguishability, for which we give a detailed analysis. Overall the parameters we propose are efficient and comparable in terms of signature size to the Dilithium lattice-based scheme, with a signature size of 4 kB for a public key of size less than 20 kB.",Springer
"Pellet-Mary, Alice and Hanrot, Guillaume and Stehl{\'e}, Damien",Approx-SVP in Ideal Lattices with Pre-processing,2019,10.1007/978-3-030-17656-3_24,https://doi.org/10.1007/978-3-030-17656-3_24,Conference Paper,Advances in Cryptology -- EUROCRYPT 2019,"We describe an algorithm to solve the approximate Shortest Vector Problem for lattices corresponding to ideals of the ring of integers of an arbitrary number field K. This algorithm has a pre-processing phase, whose run-time is exponential in {\$}{\$}{\backslash}log |{\backslash}varDelta |{\$}{\$}log|$\Delta$|with {\$}{\$}{\backslash}varDelta {\$}{\$}$\Delta$the discriminant of K. Importantly, this pre-processing phase depends only on K. The pre-processing phase outputs an ``advice'', whose bit-size is no more than the run-time of the query phase. Given this advice, the query phase of the algorithm takes as input any ideal I of the ring of integers, and outputs an element of I which is at most {\$}{\$}{\backslash}exp ({\backslash}widetilde{\{}O{\}}(({\backslash}log |{\backslash}varDelta |)^{\{}{\backslash}alpha +1{\}}/n)){\$}{\$}exp(O{\textasciitilde}((log|$\Delta$|)$\alpha$+1/n))times longer than a shortest non-zero element of I (with respect to the Euclidean norm of its canonical embedding). This query phase runs in time and space {\$}{\$}{\backslash}exp ({\backslash}widetilde{\{}O{\}}( ({\backslash}log |{\backslash}varDelta |)^{\{}{\backslash}max (2/3, 1-2{\backslash}alpha ){\}})){\$}{\$}exp(O{\textasciitilde}((log|$\Delta$|)max(2/3,1-2$\alpha$)))in the classical setting, and{\$}{\$}{\backslash}exp ({\backslash}widetilde{\{}O{\}}(({\backslash}log |{\backslash}varDelta |)^{\{}1-2{\backslash}alpha {\}})){\$}{\$}exp(O{\textasciitilde}((log|$\Delta$|)1-2$\alpha$))in the quantum setting. The parameter {\$}{\$}{\backslash}alpha {\$}{\$}$\alpha$can be chosen arbitrarily in [0, 1 / 2]. Both correctness and cost analyses rely on heuristic assumptions, whose validity is consistent with experiments.",Springer
"Tasche, Philip and Herber, Paula and Huisman, Marieke",Automated Invariant Generation for Efficient Deductive Reasoning About Embedded Systems,2025,10.1007/978-3-031-77382-2_23,https://doi.org/10.1007/978-3-031-77382-2_23,Conference Paper,Software Engineering and Formal Methods,"Deductive verification is often more efficient than alternative techniques like model checking at reasoning about functional properties of programs. This is especially true when the program under verification contains very large or unbounded data ranges that model checkers struggle with. However, modular deductive verifiers struggle with verifying global properties, which are often crucial in concurrent and reactive embedded systems. Embedded systems often require complex user-defined invariants to capture the global state for the verification of local annotations, demanding high effort and expertise from the user. In this paper, we propose a method to automatically generate compact invariants that are sufficiently strong to enable effective deductive verification of global properties in embedded systems. Our key idea is that a good level of abstraction can be found automatically by choosing variables for refinement that influence relevant events and process interactions. We use this idea together with abstract interpretation to build a system's state space, abstracted to the relevant part for a given global property. We demonstrate the effectiveness of our approach on a SystemC design of an automotive control system that has in the past proved challenging to verify.",Springer
"{\'{S}}mierzchalski, Tomasz and Pawela, {\L}ukasz and Pucha{\l}a, Zbigniew and Trzci{\'{n}}ski, Tomasz and Gardas, Bart{\l}omiej",Post-error Correction for Quantum Annealing Processor Using Reinforcement Learning,2022,10.1007/978-3-031-08760-8_22,https://doi.org/10.1007/978-3-031-08760-8_22,Conference Paper,Computational Science -- ICCS 2022,"Finding the ground state of the Ising model is an important problem in condensed matter physics. Its applications spread far beyond physic due to its deep relation to various combinatorial optimization problems, such as travelling salesman or protein folding. Sophisticated new methods for solving Ising instances rely on quantum annealing, which is a paradigm of quantum computation. However, commercially available quantum annealers are still prone to errors, and their ability to find low energetic states is limited. This naturally calls for a post-processing procedure to correct errors. As a proof-of-concept, this work combines the recent ideas revolving around the DIRAC architecture with the Chimera topology and applies them in a real-world setting as an error-correcting scheme for D-Wave quantum annealers. Our preliminary results show how to correct states output by quantum annealers using reinforcement learning. Our approach exhibits excellent scalability, as it can be trained on small instances. However, its performance on the Chimera graphs is still inferior to Monte Carlo methods.",Springer
"van der Linde, Stan G. and van der Schoot, Ward and Phillipson, Frank",Efficient Quantum Solution for the Constrained Tactical Capacity Problem for Distributed Electricity Generation,2023,10.1007/978-3-031-40852-6_11,https://doi.org/10.1007/978-3-031-40852-6_11,Conference Paper,Innovations for Community Services,"With the transition to sustainable energy sources and devices, the demand for and supply of energy increases ever more. With energy grids struggling to keep up with this increase, we need to ensure that supply and demand are correctly matched. The Tactical Capacity Problem tackles this issue by choosing the optimal location of sustainable power sources to minimise the total energy loss. We extend an existing quantum approach of solving this problem in two ways. Firstly, we extend the problem to include capacity constraints, resulting in the Constrained Tactical Capacity Problem. Secondly, we propose two ways of optimising the performance of the resulting model via variable reduction. These optimisations are supported by numerical results obtained on both classical and quantum solvers.",Springer
"Poth, Alexander and Saalfeld, Luca",Improve IT Sustainability with IT Technology -- Comparison of an Explore vs. Exploit Strategy (with a Case Study on Containerized Workloads),2024,10.1007/978-3-031-71142-8_2,https://doi.org/10.1007/978-3-031-71142-8_2,Conference Paper,"Systems, Software and Services Process Improvement","The size and complexity of IT systems is growing over time. Therefore, the resource unit footprint of an IT system grows, too. But what impact has an exploration strategy of new technologies to reduce the footprint? Based on a case study of a cloud service from the Volkswagen Group IT an exploration approach is compared with an exploitation approach. It presents the methodical approach and its effects on the resource unit footprint of a micro-service architecture of the IT service. The approach enables the DevOps team to beat Wirth's law by keeping the footprint at least constant by offering more capabilities and features to their users.",Springer
"de Souza, Luciano S. and de Carvalho, Jonathan H. A. and Ferreira, Tiago A. E.",Lackadaisical Quantum Walk in the Hypercube to Search for Multiple Marked Vertices,2021,10.1007/978-3-030-91702-9_17,https://doi.org/10.1007/978-3-030-91702-9_17,Conference Paper,Intelligent Systems,"Adding self-loops at each vertex of a graph improves the performance of quantum walks algorithms over loopless algorithms. Many works approach quantum walks to search for a single marked vertex. In this article, we experimentally address several problems related to quantum walk in the hypercube with self-loops to search for multiple marked vertices. We first investigate the quantum walk in the loopless hypercube. We saw that neighbor vertices are also amplified and that approximately 1/2 of the system energy is concentrated in them. We show that the optimal value of l for a single marked vertex is not optimal for multiple marked vertices. We define a new value of {\$}{\$}l = (n/N){\backslash}cdot k{\$}{\$}l=(n/N){\textperiodcentered}kto search multiple marked vertices. Next, we use this new value of l found to analyze the search for multiple marked vertices non-adjacent and show that the probability of success is close to 1. We also use the new value of l found to analyze the search for several marked vertices that are adjacent and show that the probability of success is directly proportional to the density of marked vertices in the neighborhood. We also show that, in the case where neighbors are marked, if there is at least one non-adjacent marked vertex, the probability of success increases to close to 1. The results found show that the self-loop value for the quantum walk in the hypercube to search for several marked vertices is {\$}{\$}l = (n / N) {\backslash}cdot k {\$}{\$}l=(n/N){\textperiodcentered}k.",Springer
"Weigold, Manuela and Barzen, Johanna and Leymann, Frank and Vietz, Daniel",Patterns for Hybrid Quantum Algorithms,2021,10.1007/978-3-030-87568-8_2,https://doi.org/10.1007/978-3-030-87568-8_2,Conference Paper,Service-Oriented Computing,"Quantum computers have the potential to solve certain problems faster than classical computers. However, the computations that can be executed on current quantum devices are still limited. Hybrid algorithms split the computational tasks between classical and quantum computers circumventing some of these limitations. Therefore, they are regarded as promising candidates for useful applications in the near future. But especially for novices in quantum computing, it is hard to identify why a particular splitting strategy is proposed by an algorithm. In this work, we describe the best practices for splitting strategies as patterns to foster a common understanding of hybrid algorithms.",Springer
"Gilhuber, Sandra and Busch, Julian and Rotthues, Daniel and Frey, Christian M. M. and Seidl, Thomas",DiffusAL: Coupling Active Learning with Graph Diffusion for Label-Efficient Node Classification,2023,10.1007/978-3-031-43412-9_5,https://doi.org/10.1007/978-3-031-43412-9_5,Conference Paper,Machine Learning and Knowledge Discovery in Databases: Research Track,"Node classification is one of the core tasks on attributed graphs, but successful graph learning solutions require sufficiently labeled data. To keep annotation costs low, active graph learning focuses on selecting the most qualitative subset of nodes that maximizes label efficiency. However, deciding which heuristic is best suited for an unlabeled graph to increase label efficiency is a persistent challenge. Existing solutions either neglect aligning the learned model and the sampling method or focus only on limited selection aspects. They are thus sometimes worse or only equally good as random sampling. In this work, we introduce a novel active graph learning approach called DiffusAL, showing significant robustness in diverse settings. Toward better transferability between different graph structures, we combine three independent scoring functions to identify the most informative node samples for labeling in a parameter-free way: i) Model Uncertainty, ii) Diversity Component, and iii) Node Importance computed via graph diffusion heuristics. Most of our calculations for acquisition and training can be pre-processed, making DiffusAL more efficient compared to approaches combining diverse selection criteria and similarly fast as simpler heuristics. Our experiments on various benchmark datasets show that, unlike previous methods, our approach significantly outperforms random selection in 100{\%} of all datasets and labeling budgets tested.",Springer
"Wang, Siyi and Chattopadhyay, Anupam",Efficient Depth Optimization in Quantum Addition and Modular Arithmetic with Ling Structure,2024,10.1007/978-3-031-70947-0_4,https://doi.org/10.1007/978-3-031-70947-0_4,Conference Paper,VLSI-SoC 2023: Innovations for Trustworthy Artificial Intelligence,"Improving the performance of quantum adder is an important technical challenge with major impact on the implementation of efficient, large-scale quantum computing. Continuing along this research direction, we propose a novel parallel-prefix quantum adder based on Ling expansion. We systematically explored classical structures for parallel-prefix adders assessing their suitability to be realized in quantum domain. Furthermore, Ling adder enforces Logical OR and large fan-out, which require innovative solutions. We addressed these challenges to realize the quantum Ling adder, which results in a T-depth of only {\$}{\$}O({\backslash}log {\backslash}frac{\{}n{\}}{\{}2{\}}){\$}{\$}O(logn2). This represents a substantial improvement over the previous quantum adders based on parallel prefix structure, which require {\$}{\$}O({\backslash}log n){\$}{\$}O(logn)T-depth. Based on the proposed adder, an efficient quantum modular adder is also demonstrated in this paper, further extending the applicability of our approach. We present extensive theoretical and simulation-based studies to establish our claims.",Springer
"Roch, Christoph and Winderl, David and Linnhoff-Popien, Claudia and Feld, Sebastian",A Quantum Annealing Approach for Solving Hard Variants of the Stable Marriage Problem,2022,10.1007/978-3-031-06668-9_21,https://doi.org/10.1007/978-3-031-06668-9_21,Conference Paper,Innovations for Community Services,"The Stable Marriage Problem (SMP) describes the problem, of finding a stable matching between two equally sized sets of elements (e.g., males and females) given an ordering of preferences for each element. A matching is stable, when there does not exist any match of a male and female which both prefer each other to their current partner under the matching. Finding such a matching of maximum cardinality, when ties and incomplete preference lists are allowed, is called MAX-SMTI and is an NP-hard variation of the SMP.",Springer
"Rungta, Neha",A Billion SMT Queries a Day (Invited Paper),2022,10.1007/978-3-031-13185-1_1,https://doi.org/10.1007/978-3-031-13185-1_1,Conference Paper,Computer Aided Verification,"Amazon Web Services (AWS) is a cloud computing services provider that has made significant investments in applying formal methods to proving correctness of its internal systems and providing assurance of correctness to their end-users. In this paper, we focus on how we built abstractions and eliminated specifications to scale a verification engine for AWS access policies, Zelkova, to be usable by all AWS users. We present milestones from our journey from a thousand SMT invocations daily to an unprecedented billion SMT calls in a span of five years. In this paper, we talk about how the cloud is enabling application of formal methods, key insights into what made this scale of a billion SMT queries daily possible, and present some open scientific challenges for the formal methods community.",Springer
"Kalai, Yael Tauman and Khurana, Dakshita",Non-interactive Non-malleability from Quantum Supremacy,2019,10.1007/978-3-030-26954-8_18,https://doi.org/10.1007/978-3-030-26954-8_18,Conference Paper,Advances in Cryptology -- CRYPTO 2019,"We construct non-interactive non-malleable commitments without setup in the plain model, under well-studied assumptions.",Springer
"Ishai, Yuval and Kushilevitz, Eyal and Ostrovsky, Rafail and Sahai, Amit",Cryptographic Sensing,2019,10.1007/978-3-030-26954-8_19,https://doi.org/10.1007/978-3-030-26954-8_19,Conference Paper,Advances in Cryptology -- CRYPTO 2019,"Is it possible to measure a physical object in a way that makes the measurement signals unintelligible to an external observer? Alternatively, can one learn a natural concept by using a contrived training set that makes the labeled examples useless without the line of thought that has led to their choice? We initiate a study of ``cryptographic sensing'' problems of this type, presenting definitions, positive and negative results, and directions for further research.",Springer
"Gilbert, Valentin and Louise, St{\'e}phane and Sirdey, Renaud",TAQOS: A Benchmark Protocol for Quantum Optimization Systems,2023,10.1007/978-3-031-36030-5_13,https://doi.org/10.1007/978-3-031-36030-5_13,Conference Paper,Computational Science -- ICCS 2023,"The growing availability of quantum computers raises questions about their ability to solve concrete problems. Existing benchmark protocols still lack problem diversity and attempt to summarize quantum advantage in a single metric that measures the quality of found solutions. Unfortunately, the solution quality metric is insufficient for measuring quantum algorithm performance and should be presented along with time and instances coverage metrics. This paper aims to establish the TAQOS protocol to perform a Tight Analysis of Quantum Optimization Systems. The combination of metrics considered by this protocol helps to identify problems and instances liable to produce quantum advantage on Noisy-Intermediate Scale Quantum (NISQ) devices for useful applications. The methodology used for the benchmark process is detailed and an illustrative short case study on the Max-Cut problem is provided.",Springer
"Mei, Jingyi and Coopmans, Tim and Bonsangue, Marcello and Laarman, Alfons",Equivalence Checking of Quantum Circuits by Model Counting,2024,10.1007/978-3-031-63501-4_21,https://doi.org/10.1007/978-3-031-63501-4_21,Conference Paper,Automated Reasoning,"Verifying equivalence between two quantum circuits is a hard problem, that is nonetheless crucial in compiling and optimizing quantum algorithms for real-world devices. This paper gives a Turing reduction of the (universal) quantum circuits equivalence problem to weighted model counting (WMC). Our starting point is a folklore theorem showing that equivalence checking of quantum circuits can be done in the so-called Pauli-basis. We combine this insight with a WMC encoding of quantum circuit simulation, which we extend with support for the Toffoli gate. Finally, we prove that the weights computed by the model counter indeed realize the reduction. With an open-source implementation, we demonstrate that this novel approach can outperform a state-of-the-art equivalence-checking tool based on ZX calculus and decision diagrams.",Springer
"Dayama, Niraj and Haghparast, Majid and Stirbu, Vlad",Problem Decomposition to Leverage Quantum Computing for Optimization Problems,2024,10.1007/978-3-031-49269-3_12,https://doi.org/10.1007/978-3-031-49269-3_12,Conference Paper,Product-Focused Software Process Improvement,"The emerging paradigm of Quantum computing has the potential to transform the established way-of-working in several scientific and industrial fields if the open challenges of applying quantum computing systems for real-world applications are addressed. One of the major challenges is that the quantum computing systems accessible for industrial and commercial users have very few qubits. Several research initiatives are being proposed to work around this constraint. We investigate the amenable scope and limits of a hybrid platform where classical computing works in tandem with quantum computing to address practical problems. Instead of focusing on quantum supremacy or specialized academic problems, this paper proposes a framework where generalized industrial applications can be solved using hybrid computing systems with limited qubit capacity using a decomposition technique that can be modified to any decision-support procedure.",Springer
"Toporkov, Victor and Yemelyanov, Dmitry and Toporkova, Anna",Preference Based and Fair Resources Selection in Grid VOs,2019,10.1007/978-3-030-25636-4_7,https://doi.org/10.1007/978-3-030-25636-4_7,Conference Paper,Parallel Computing Technologies,"In this work, a preference-based resources allocation algorithm for a job-flow scheduling in Grid virtual organizations (VOs) is proposed and studied. Users' and resource providers' preferences, VOs internal policies, resources geographical distribution along with local private utilization impose specific requirements for efficient scheduling according to different, usually contradictive, criteria. The algorithm performs resources selection optimization according to a specified general criterion and may be used in a variety of scheduling procedures, such as Backfilling or First Fit. Fair scheduling policies in VOs assume resources distribution according to VO stakeholders individual preferences. For this purpose, we consider a target optimization criterion as a linear combination of global (group) and private (user) job scheduling criteria. The mutual importance factor between the private and the global criteria is introduced to achieve a balanced scheduling solution.",Springer
"Baksi, Anubhab and Dasu, Vishnu Asutosh and Karmakar, Banashri and Chattopadhyay, Anupam and Isobe, Takanori",Three Input Exclusive-OR Gate Support for Boyar-Peralta's Algorithm,2021,10.1007/978-3-030-92518-5_7,https://doi.org/10.1007/978-3-030-92518-5_7,Conference Paper,Progress in Cryptology -- INDOCRYPT 2021,"The linear layer, which is basically a binary non-singular matrix, is an integral part of cipher construction in a lot of private key ciphers. As a result, optimising the linear layer for device implementation has been an important research direction for about two decades. The Boyar-Peralta's algorithm (SEA'10) is one such common algorithm, which offers significant improvement compared to the straightforward implementation. This algorithm only returns implementation with XOR2 gates, and is deterministic. Over the last couple of years, some improvements over this algorithm has been proposed, so as to make support for XOR3 gates as well as make it randomised. In this work, we take an already existing improvement (Tan and Peyrin, TCHES'20) that allows randomised execution and extend it to support three input XOR gates. This complements the other work done in this direction (Banik et al., IWSEC'19) that also supports XOR3 gates with randomised execution. Further, noting from another work (Maximov, Eprint'19), we include one additional tie-breaker condition in the original Boyar-Peralta's algorithm. Our work thus collates and extends the state-of-the-art, at the same time offers a simpler interface. We show several results that improve from the lastly best-known results.",Springer
"Eisentr{\""a}ger, Kirsten and Hallgren, Sean and Lauter, Kristin and Morrison, Travis and Petit, Christophe",Supersingular Isogeny Graphs and Endomorphism Rings: Reductions and Solutions,2018,10.1007/978-3-319-78372-7_11,https://doi.org/10.1007/978-3-319-78372-7_11,Conference Paper,Advances in Cryptology -- EUROCRYPT 2018,"In this paper, we study several related computational problems for supersingular elliptic curves, their isogeny graphs, and their endomorphism rings. We prove reductions between the problem of path finding in the {\$}{\$}{\backslash}ell {\$}{\$}-isogeny graph, computing maximal orders isomorphic to the endomorphism ring of a supersingular elliptic curve, and computing the endomorphism ring itself. We also give constructive versions of Deuring's correspondence, which associates to a maximal order in a certain quaternion algebra an isomorphism class of supersingular elliptic curves. The reductions are based on heuristics regarding the distribution of norms of elements in quaternion algebras.",Springer
"Graham, Richard L. and Levi, Lion and Burredy, Devendar and Bloch, Gil and Shainer, Gilad and Cho, David and Elias, George and Klein, Daniel and Ladd, Joshua and Maor, Ophir and Marelli, Ami and Petrov, Valentin and Romlet, Evyatar and Qin, Yong and Zemah, Ido",Scalable Hierarchical Aggregation and Reduction Protocol (SHARP)TM Streaming-Aggregation Hardware Design and Evaluation,2020,10.1007/978-3-030-50743-5_3,https://doi.org/10.1007/978-3-030-50743-5_3,Conference Paper,High Performance Computing,"This paper describes the new hardware-based streaming-aggregation capability added to Mellanox's Scalable Hierarchical Aggregation and Reduction Protocol in its HDR InfiniBand switches. For large messages, this capability is designed to achieve reduction bandwidths similar to those of point-to-point messages of the same size, and complements the latency-optimized low-latency aggregation reduction capabilities, aimed at small data reductions. MPI{\_}Allreduce() bandwidth measured on an HDR InfiniBand based system achieves about 95{\%} of network bandwidth. For medium and large data reduction this also improves the reduction bandwidth by a factor of 2--5 relative to host-based (e.g., software-based) reduction algorithms. Using this capability also increased DL-Poly and PyTorch application performance by as much as 4{\%} and 18{\%}, respectively. This paper describes SHARP Streaming-Aggregation hardware architecture and a set of synthetic and application benchmarks used to study this new reduction capability, and the range of data sizes for which Streaming-Aggregation performs better than the low-latency aggregation algorithm.",Springer
"Hern{\'a}ndez Gonz{\'a}lez, Guillermo Jos{\'e} and Paradela, Claudio Andr{\'e}s",Quantum Agile Development Framework,2020,10.1007/978-3-030-58793-2_23,https://doi.org/10.1007/978-3-030-58793-2_23,Conference Paper,Quality of Information and Communications Technology,"The interest in quantum computing has grown exponentially in recent years, with large technology companies engaging in the creation of computers and quantum technologies. The number of qubits skyrockets and makes the future practical implementation of mathematical algorithms and the creation of commercial systems increasingly viable. However, the growth of hardware is not being accompanied by programming and engineering methodologies adapted to this new paradigm, with new needs and risks. Associated with this, we are also in a world in which current development projects are carried out in multiple paradigms associated with different needs. In this paper, our findings and proposals are defined to anticipate the future needs of quantum software project management, taking into account the new roles, requirements and deficiencies of this new technology. Specifically, we focus on defining a classical-agile hybrid project management framework that can be adapted to the needs of these new programming paradigms, taking into account not only quantum programming, but projects that integrate classical-quantum hybrid developments.",Springer
"Neumann, Niels M. P. and van der Schoot, Ward and Sijpesteijn, Thom",Quantum Cloud Computing from a User Perspective,2023,10.1007/978-3-031-40852-6_13,https://doi.org/10.1007/978-3-031-40852-6_13,Conference Paper,Innovations for Community Services,"Quantum computing is a rapidly progressing field: quantum computers are becoming more powerful and an increasing number of functionalities are offered via various quantum platforms and quantum software packages. Current quantum computers can be used almost exclusively via cloud services. It is expected that this will remain the case, at least in the near-term future. For successful adoption of quantum computing by the market, quantum cloud services should be user-centric. To that end, we explore quantum cloud computing from a user perspective. We describe a standardised overview of quantum cloud computing as a whole to create a common language to strengthen research and collaboration on quantum cloud computing. Specifically, we identify different types, information flows and relevant user functionalities of quantum cloud computing, based on their counterparts in classical cloud computing. Combined, this gives an overview of quantum cloud computing for the best user experience, paving the way towards user-centric quantum cloud computing.",Springer
"S{\""u}nkel, Leo and K{\""o}lle, Michael and Rohe, Tobias and Gabor, Thomas",Towards Federated Learning on the Quantum Internet,2024,10.1007/978-3-031-63778-0_24,https://doi.org/10.1007/978-3-031-63778-0_24,Conference Paper,Computational Science -- ICCS 2024,"While the majority of focus in quantum computing has so far been on monolithic quantum systems, quantum communication networks and the quantum internet in particular are increasingly receiving attention from researchers and industry alike. The quantum internet may allow a plethora of applications such as distributed or blind quantum computing, though research still is at an early stage, both for its physical implementation as well as algorithms; thus suitable applications are an open research question. We evaluate a potential application for the quantum internet, namely quantum federated learning. We run experiments under different settings in various scenarios (e.g. network constraints) using several datasets from different domains and show that (1) quantum federated learning is a valid alternative for regular training and (2) network topology and nature of training are crucial considerations as they may drastically influence the models performance. The results indicate that more comprehensive research is required to optimally deploy quantum federated learning on a potential quantum internet.",Springer
"Agarwal, Etika and Gurumoorthy, Karthik S. and Jain, Ankit Ajit and Manchenahally, Shantala",A Scalable Solution for the Extended Multi-channel Facility Location Problem,2023,10.1007/978-3-031-43421-1_19,https://doi.org/10.1007/978-3-031-43421-1_19,Conference Paper,Machine Learning and Knowledge Discovery in Databases: Research Track,"We study the extended version of the non-uniform, capacitated facility location problem with multiple fulfilment channels between the facilities and clients, each with their own channel capacities and service cost. Though the problem has been extensively studied in the literature, all the prior works assume a single channel of fulfilment, and the existing methods based on linear programming, primal-dual relationships, local search heuristics etc. do not scale for a large supply chain system involving millions of decision variables. Using the concepts of submodularity and optimal transport theory, we present a scalable algorithm for determining the set of facilities to be opened under a cardinality constraint. By introducing various schemes such as: (i) iterative facility selection using incremental gain, (ii) approximation of the linear program using novel multi-stage Sinkhorn iterations, (iii) creation of facilities one for each fulfilment channel etc., we develop a fast but a tight approximate solution, requiring {\$}{\$}O{\backslash}left( {\backslash}frac{\{}3+k{\}}{\{}2{\}} m {\backslash}ln {\backslash}left( {\backslash}frac{\{}1{\}}{\{}{\backslash}epsilon {\}}{\backslash}right) {\backslash}right) {\$}{\$}O3+k2mln1ç¼ä¾å³éç­stances of optimal transport problems to select k facilities from m options, each solvable in linear time. Our algorithm is implicitly endowed with all the theoretical guarantees enjoyed by submodular maximisation problems and the Sinkhorn distances. When compared against the state-of-the-art commercial MILP solvers, we obtain a 100-fold speedup in computation, while the difference in objective values lies within a narrow range of {\$}{\$}{\backslash}mathbf {\{}3{\backslash}{\%}{\}}{\$}{\$}3{\%}.",Springer
"Banegas, Gustavo and Bernstein, Daniel J.",Low-Communication Parallel Quantum Multi-Target Preimage Search,2018,10.1007/978-3-319-72565-9_16,https://doi.org/10.1007/978-3-319-72565-9_16,Conference Paper,Selected Areas in Cryptography -- SAC 2017,"The most important pre-quantum threat to AES-128 is the 1994 van Oorschot--Wiener ``parallel rho method'', a low-communication parallel pre-quantum multi-target preimage-search algorithm. This algorithm uses a mesh of p small processors, each running for approximately {\$}{\$}2^{\{}128{\}}{\backslash}!/pt{\$}{\$}2128/ptfast steps, to find one of t independent AES keys {\$}{\$}k{\_}1,{\backslash}dots ,k{\_}t{\$}{\$}k1,éä½¸å¿æ´æ»å¹ç»æ, given the ciphertexts for a shared plaintext 0.",Springer
"Aggarwal, Divesh and Kazana, Tomasz and Obremski, Maciej",Inception Makes Non-malleable Codes Stronger,2017,10.1007/978-3-319-70503-3_10,https://doi.org/10.1007/978-3-319-70503-3_10,Conference Paper,Theory of Cryptography,"Non-malleable codes (NMCs), introduced by Dziembowski et al. [DPW10], provide a useful message integrity guarantee in situations where traditional error-correction (and even error-detection) is impossible; for example, when the attacker can completely overwrite the encoded message. NMCs have emerged as a fundamental object at the intersection of coding theory and cryptography.",Springer
"Neumann, Niels M. P. and Wezeman, Robert S.",Distributed Quantum Machine Learning,2022,10.1007/978-3-031-06668-9_20,https://doi.org/10.1007/978-3-031-06668-9_20,Conference Paper,Innovations for Community Services,"Quantum computers can solve specific complex tasks for which no reasonable-time classical algorithm is known. Quantum computers do however also offer inherent security of data, as measurements destroy quantum states. Using shared entangled states, multiple parties can collaborate and securely compute quantum algorithms. In this paper we propose an approach for distributed quantum machine learning, which allows multiple parties to securely perform computations, without having to reveal their data. We will consider a distributed adder and a distributed distance-based classifier.",Springer
"Alagic, Gorjan and Gagliardoni, Tommaso and Majenz, Christian",Unforgeable Quantum Encryption,2018,10.1007/978-3-319-78372-7_16,https://doi.org/10.1007/978-3-319-78372-7_16,Conference Paper,Advances in Cryptology -- EUROCRYPT 2018,"We study the problem of encrypting and authenticating quantum data in the presence of adversaries making adaptive chosen plaintext and chosen ciphertext queries. Classically, security games use string copying and comparison to detect adversarial cheating in such scenarios. Quantumly, this approach would violate no-cloning. We develop new techniques to overcome this problem: we use entanglement to detect cheating, and rely on recent results for characterizing quantum encryption schemes. We give definitions for (i) ciphertext unforgeability, (ii) indistinguishability under adaptive chosen-ciphertext attack, and (iii) authenticated encryption. The restriction of each definition to the classical setting is at least as strong as the corresponding classical notion: (i) implies {\$}{\$}{\backslash}mathsf {\{}INT{\backslash}text {\{}-{\}}CTXT{\}}{\$}{\$}, (ii) implies {\$}{\$}{\backslash}mathsf {\{}IND{\backslash}text {\{}-{\}}CCA2{\}}{\$}{\$}, and (iii) implies {\$}{\$}{\backslash}mathsf {\{}AE{\}}{\$}{\$}. All of our new notions also imply {\$}{\$}{\backslash}mathsf {\{}QIND{\backslash}text {\{}-{\}}CPA{\}}{\$}{\$}privacy. Combining one-time authentication and classical pseudorandomness, we construct symmetric-key quantum encryption schemes for each of these new security notions, and provide several separation examples. Along the way, we also give a new definition of one-time quantum authentication which, unlike all previous approaches, authenticates ciphertexts rather than plaintexts.",Springer
"Kreuzer, Katharina and Nipkow, Tobias",Verification of NP-Hardness Reduction Functions for Exact Lattice Problems,2023,10.1007/978-3-031-38499-8_21,https://doi.org/10.1007/978-3-031-38499-8_21,Conference Paper,Automated Deduction -- CADE 29,"This paper describes the formal verification of NP-hardness reduction functions of two key problems relevant in algebraic lattice theory: the closest vector problem and the shortest vector problem, both in the infinity norm. The formalization uncovered a number of problems with the existing proofs in the literature. The paper describes how these problems were corrected in the formalization. The work was carried out in the proof assistant Isabelle.",Springer
"Czajkowski, Jan and H{\""u}lsing, Andreas and Schaffner, Christian",Quantum Indistinguishability of Random Sponges,2019,10.1007/978-3-030-26951-7_11,https://doi.org/10.1007/978-3-030-26951-7_11,Conference Paper,Advances in Cryptology -- CRYPTO 2019,"In this work we show that the sponge construction can be used to construct quantum-secure pseudorandom functions. As our main result we prove that random sponges are quantum indistinguishable from random functions. In this setting the adversary is given superposition access to the input-output behavior of the construction but not to the internal function. Our proofs hold under the assumption that the internal function is a random function or permutation. We then use this result to obtain a quantum-security version of a result by Andreeva, Daemen, Mennink, and Van Assche (FSE'15) which shows that a sponge that uses a secure PRP or PRF as internal function is a secure PRF. This result also proves that the recent attacks against CBC-MAC in the quantum-access model by Kaplan, Leurent, Leverrier, and Naya-Plasencia (Crypto'16) and Santoli, and Schaffner (QIC'16) can be prevented by introducing a state with a non-trivial inner part.",Springer
"Peikert, Chris and Shiehian, Sina",Noninteractive Zero Knowledge for NP from (Plain) Learning with Errors,2019,10.1007/978-3-030-26948-7_4,https://doi.org/10.1007/978-3-030-26948-7_4,Conference Paper,Advances in Cryptology -- CRYPTO 2019,"We finally close the long-standing problem of constructing a noninteractive zero-knowledge (NIZK) proof system for any NP language with security based on the plain Learning With Errors (LWE) problem, and thereby on worst-case lattice problems. Our proof system instantiates the framework recently developed by Canetti et al.  [EUROCRYPT'18], Holmgren and Lombardi [FOCS'18], and Canetti et al.  [STOC'19] for soundly applying the Fiat--Shamir transform using a hash function family that is correlation intractable for a suitable class of relations. Previously, such hash families were based either on ``exotic'' assumptions (e.g., indistinguishability obfuscation or optimal hardness of certain LWE variants) or, more recently, on the existence of circularly secure fully homomorphic encryption (FHE). However, none of these assumptions are known to be implied by plain LWE or worst-case hardness.",Springer
"Slysz, Mateusz and Kurowski, Krzysztof and Walig{\'o}ra, Grzegorz and W{\k{e}}glarz, Jan",Exploring the Capabilities of Quantum Support Vector Machines for Image Classification on the MNIST Benchmark,2023,10.1007/978-3-031-36030-5_15,https://doi.org/10.1007/978-3-031-36030-5_15,Conference Paper,Computational Science -- ICCS 2023,"Quantum computing is a rapidly growing field of science with many potential applications. One such field is machine learning applied in many areas of science and industry. Machine learning approaches can be enhanced using quantum algorithms and work effectively, as demonstrated in this paper. We present our experimental attempts to explore Quantum Support Vector Machine (QSVM) capabilities and test their performance on the collected well-known images of handwritten digits for image classification called the MNIST benchmark. A variational quantum circuit was adopted to build the quantum kernel matrix and successfully applied to the classical SVM algorithm. The proposed model obtained relatively high accuracy, up to 99{\%}, tested on noiseless quantum simulators. Finally, we performed computational experiments on real and recently setup IBM Quantum systems and achieved promising results of around 80{\%} accuracy, demonstrating and discussing the QSVM applicability and possible future improvements.",Springer
"Yoo, Youngho and Azarderakhsh, Reza and Jalali, Amir and Jao, David and Soukharev, Vladimir",A Post-quantum Digital Signature Scheme Based on Supersingular Isogenies,2017,10.1007/978-3-319-70972-7_9,https://doi.org/10.1007/978-3-319-70972-7_9,Conference Paper,Financial Cryptography and Data Security,"We present the first general-purpose digital signature scheme based on supersingular elliptic curve isogenies secure against quantum adversaries in the quantum random oracle model with small key sizes. This scheme is an application of Unruh's construction of non-interactive zero-knowledge proofs to an interactive zero-knowledge proof proposed by De Feo, Jao, and Pl{\^u}t. We implement our proposed scheme on an x86-64 PC platform as well as an ARM-powered device. We exploit the state-of-the-art techniques to speed up the computations for general C and assembly. Finally, we provide timing results for real world applications.",Springer
"Waugh, Harry and McIntosh-Smith, Simon",On the Use of BLAS Libraries in Modern Scientific Codes at Scale,2020,10.1007/978-3-030-63393-6_5,https://doi.org/10.1007/978-3-030-63393-6_5,Conference Paper,"Driving Scientific and Engineering Discoveries Through the Convergence of HPC, Big Data and AI","As we approach the Exascale era, computer architectures are evolving ever-greater vector and matrix acceleration units---NVIDIA's Ampere Tensor Cores, Intel's AMX, and Arm's SVE vector instruction set developments are just three recent examples [1, 2, 10]. To exploit these, it is expected that optimised math libraries such as those for dense and sparse linear algebra, will play an increasing role in achieving optimal performance. It is therefore useful to understand which of these functions dominate an application's runtime, and in particular how this changes with increasing scale. This work aims to provide a contemporary dataset regarding how much dense linear algebra (BLAS) is used in HPC codes at scale. We have analysed several science codes widely used on the UK HPC service, ARCHER (https://www.archer.ac.uk), including CASTEP, CP2K, QuantumESPRESSO, and Nektar++. To capture demands from the AI community, we have additionally traced the training stage of the Convolutional Neural Network (CNN), AlexNet [7]. HPLinpack is also included as a reference, as it exhibits a well-understood BLAS usage pattern. Results from across all the codes show that, unlike HPLinpack, BLAS usage is never more than 25{\%} of the total runtime, even when running at a modest scale (32 nodes of the Arm-based supercomputer, Isambard). This presents limited speedup opportunity when considering Amdahl's law, and suggests that application developers may need to adjust their algorithms to spend more time in optimised BLAS libraries to capitalise on new architectures and accelerators.",Springer
"Wauthier, Samuel T. and Vanhecke, Bram and Verbelen, Tim and Dhoedt, Bart",Learning Generative Models for Active Inference Using Tensor Networks,2023,10.1007/978-3-031-28719-0_20,https://doi.org/10.1007/978-3-031-28719-0_20,Conference Paper,Active Inference,"Active inference provides a general framework for behavior and learning in autonomous agents. It states that an agent will attempt to minimize its variational free energy, defined in terms of beliefs over observations, internal states and policies. Traditionally, every aspect of a discrete active inference model must be specified by hand, i.e. by manually defining the hidden state space structure, as well as the required distributions such as likelihood and transition probabilities. Recently, efforts have been made to learn state space representations automatically from observations using deep neural networks. In this paper, we present a novel approach of learning state spaces using quantum physics-inspired tensor networks. The ability of tensor networks to represent the probabilistic nature of quantum states as well as to reduce large state spaces makes tensor networks a natural candidate for active inference. We show how tensor networks can be used as a generative model for sequential data. Furthermore, we show how one can obtain beliefs from such a generative model and how an active inference agent can use these to compute the expected free energy. Finally, we demonstrate our method on the classic T-maze environment.",Springer
"Dinur, Itai and Kales, Daniel and Promitzer, Angela and Ramacher, Sebastian and Rechberger, Christian",Linear Equivalence of Block Ciphers with Partial Non-Linear Layers: Application to LowMC,2019,10.1007/978-3-030-17653-2_12,https://doi.org/10.1007/978-3-030-17653-2_12,Conference Paper,Advances in Cryptology -- EUROCRYPT 2019,"{\$}{\$}{\backslash}textsc {\{}LowMC{\}}{\$}{\$}LOWMCis a block cipher family designed in 2015 by Albrecht et al. It is optimized for practical instantiations of multi-party computation, fully homomorphic encryption, and zero-knowledge proofs. {\$}{\$}{\backslash}textsc {\{}LowMC{\}}{\$}{\$}LOWMCis used in the {\$}{\$}{\backslash}textsc {\{}Picnic{\}}{\$}{\$}PICNICsignature scheme, submitted to NIST's post-quantum standardization project and is a substantial building block in other novel post-quantum cryptosystems. Many {\$}{\$}{\backslash}textsc {\{}LowMC{\}}{\$}{\$}LOWMCinstances use a relatively recent design strategy (initiated by G{\'e}rard et al. at CHES 2013) of applying the non-linear layer to only a part of the state in each round, where the shortage of non-linear operations is partially compensated by heavy linear algebra. Since the high linear algebra complexity has been a bottleneck in several applications, one of the open questions raised by the designers was to reduce it, without introducing additional non-linear operations (or compromising security).",Springer
"Semmouni, Meryem Cherkaoui and Nitaj, Abderrahmane and Belkasmi, Mostafa",Bitcoin Security with Post Quantum Cryptography,2019,10.1007/978-3-030-31277-0_19,https://doi.org/10.1007/978-3-030-31277-0_19,Conference Paper,Networked Systems,"In a future quantum world with a large quantum computer, the security of the digital signatures used for Bitcoin transactions will be broken by Shor's algorithm. Bitcoin has to switch to post-quantum cryptography. In this paper, we show that the post quantum signatures based on LWE and ring LWE are the most promising to use in the presence of large quantum computers running Shor's algorithm.",Springer
"Mei, Jingyi and Bonsangue, Marcello and Laarman, Alfons",Simulating Quantum Circuits by Model Counting,2024,10.1007/978-3-031-65633-0_25,https://doi.org/10.1007/978-3-031-65633-0_25,Conference Paper,Computer Aided Verification,"Quantum circuit compilation comprises many computationally hard reasoning tasks that lie inside {\#}{\$}{\$}{\{}{\backslash}textsf{\{}P{\}}{\}}{\$}{\$}Pand its decision counterpart in {\$}{\$}{\{}{\backslash}textsf{\{}PP{\}}{\}}{\$}{\$}PP. The classical simulation of universal quantum circuits is a core example. We show for the first time that a strong simulation of universal quantum circuits can be efficiently tackled through weighted model counting by providing a linear-length encoding of Clifford+T circuits. To achieve this, we exploit the stabilizer formalism by Knill, Gottesmann, and Aaronson by reinterpreting quantum states as a linear combination of stabilizer states. With an open-source simulator implementation, we demonstrate empirically that model counting often outperforms state-of-the-art simulation techniques based on the ZX calculus and decision diagrams. Our work paves the way to apply the existing array of powerful classical reasoning tools to realize efficient quantum circuit compilation; one of the obstacles on the road towards quantum supremacy.",Springer
"Llivisaca, Juan and Jadan-Avil{\'e}s, Diana and Guam{\'a}n, Rodrigo and Arcentales-Carrion, Rodrigo and Pe{\~{n}}a, Mario and Siguenza-Guzman, Lorena",An Overview of Optimization Models and Technological Trends of Logistics in the Retail Sector,2022,10.1007/978-3-031-03884-6_35,https://doi.org/10.1007/978-3-031-03884-6_35,Conference Paper,Applied Technologies,"Recently, the e-commerce market has grown rapidly. For example, e-commerce generated sales of USD 504 billion in the US from January 1, 2020, to July 1, 2020, representing an increase of 11.58{\%} over the same period in 2019. This growth has forced the retail industry has had to adopt strategies to become more efficient. About 40{\%} of many companies `available time is devoted to logistics. Because these activities are consuming a disproportionate share of many companies' time, logistics is a prime topic of interest. In this context, this study aims to present an overview of optimization models and technological trends in logistics in the retail sector. Findings show that retail logistics has focused on reducing costs, time usage, and inventories while increasing transport capacity. Optimization in logistics has focused on using mathematical algorithms such as genetic algorithms with different variants, and simulation has supported testing optimization proposals. Finally, big data, omnichannel, and e-commerce continue to grow, especially in the retail sector where it has grown considerably.",Springer
"Wezeman, Robert S. and Chiscop, Irina and Anitori, Laura and van Rossum, Wim",Quantum-Classical Solution Methods for Binary Compressive Sensing Problems,2022,10.1007/978-3-031-08760-8_9,https://doi.org/10.1007/978-3-031-08760-8_9,Conference Paper,Computational Science -- ICCS 2022,"Compressive sensing is a signal processing technique used to acquire and reconstruct sparse signals using significantly fewer measurement samples. Compressive sensing requires finding the most sparse solution to an underdetermined linear system, which is an NP-hard problem and as a consequence in practise is only solved approximately. In our work we restrict ourselves to the compressive sensing problem for the case of binary signals. For that case we have defined an equivalent formulation in terms of a quadratic binary optimisation (QUBO) problem, which we solve using classical and (hybrid-)quantum computing solving techniques based on quantum annealing. Phase transition diagrams show that this approach significantly improves the number of problem types that can be successfully reconstructed when compared to a more conventional {\$}{\$}{\backslash}mathcal {\{}L{\}}{\_}1{\$}{\$}L1optimisation method. A challenge that remain is how to select optimal penalty parameters in the QUBO formulation as was shown can heavily impact the quality of the solution.",Springer
"Schubotz, Moritz and Scharpf, Philipp and Teschke, Olaf and K{\""u}hnemund, Andreas and Breitinger, Corinna and Gipp, Bela",AutoMSC: Automatic Assignment of Mathematics Subject Classification Labels,2020,10.1007/978-3-030-53518-6_15,https://doi.org/10.1007/978-3-030-53518-6_15,Conference Paper,Intelligent Computer Mathematics,"Authors of research papers in the fields of mathematics, and other math-heavy disciplines commonly employ the Mathematics Subject Classification (MSC) scheme to search for relevant literature. The MSC is a hierarchical alphanumerical classification scheme that allows librarians to specify one or multiple codes for publications. Digital Libraries in Mathematics, as well as reviewing services, such as zbMATH and Mathematical Reviews (MR) rely on these MSC labels in their workflows to organize the abstracting and reviewing process. Especially, the coarse-grained classification determines the subject editor who is responsible for the actual reviewing process.",Springer
"Kutov, Danil and Sulimov, Alexey and Tashchilova, Anna and Ilin, Ivan and Sulimov, Vladimir",Supercomputer Search for Coagulation Factor XIIa Inhibitors in the Chinese National Compound Library,2023,10.1007/978-3-031-49432-1_19,https://doi.org/10.1007/978-3-031-49432-1_19,Conference Paper,Supercomputing,"A methodology of virtual screening using docking of a large database of organic compounds is presented. The database is the Chinese National Compound Library with over one million low molecular weight organic compounds ready for purchase. In this study, for the first time, new quick parameters of the genetic algorithm were used. Docking is performed in two stages. First, docking of the entire database is performed using the SOL docking program with the quick parameters. Second, the best scored ligands are docked carefully by the same docking program with standard parameters. For the best ligands selected after the second stage, the enthalpy of protein-ligand binding is calculated using the PM7 quantum-chemical semiempirical method with the COSMO solvent model. The target protein is the coagulation factor XIIa. As a result of virtual screening, 18 compounds are selected as candidates for factor XIIa inhibitors. These potential factor XIIa inhibitors are novel and belong to chemotypes not present among reported experimentally confirmed factor XIIa inhibitors. These compounds, having confirmed their inhibitory activity in vitro and in vivo, can become the basis for the creation of new, safer anticoagulants.",Springer
"Biasse, Jean-Fran{\c{c}}ois",Approximate Short Vectors in Ideal Lattices of {\$}{\$}{\backslash}mathbb {\{}Q{\}}({\backslash}zeta {\_}{\{}p^e{\}}){\$}{\$}with Precomputation of {\$}{\$}{\{}{\backslash}text {\{}Cl{\}}{\}}({\backslash}mathcal {\{}O{\}}{\_}K){\$}{\$},2018,10.1007/978-3-319-72565-9_19,https://doi.org/10.1007/978-3-319-72565-9_19,Conference Paper,Selected Areas in Cryptography -- SAC 2017,"Let a, b be constants such that {\$}{\$}b{\backslash}le 7a - 2{\$}{\$}béä½¹åé£îå¹ç»ï¿½2and {\$}{\$}{\backslash}frac{\{}2{\}}{\{}5{\}}< a < {\backslash}frac{\{}1{\}}{\{}2{\}}{\$}{\$}25<a<12. We present a classical heuristic PIP resolution method that finds a generator of any input {\$}{\$}{\backslash}mathfrak {\{}I{\}}{\$}{\$}Isuch that {\$}{\$}{\backslash}mathcal {\{}N{\}}({\backslash}mathfrak {\{}I{\}}){\backslash}le 2^{\{}n^b{\}}{\$}{\$}N(I)éä½¹åé£îå¹ç»æ¦in time {\$}{\$}2^{\{}n^{\{}a + o(1){\}}{\}}{\$}{\$}2na+o(1)given a one time classical precomputation of cost and size {\$}{\$}2^{\{}n^{\{}2-3a+o(1){\}}{\}}{\$}{\$}2n2-3a+o(1).",Springer
"Phillipson, Frank and Neumann, Niels and Wezeman, Robert",Classification of Hybrid Quantum-Classical Computing,2023,10.1007/978-3-031-36030-5_2,https://doi.org/10.1007/978-3-031-36030-5_2,Conference Paper,Computational Science -- ICCS 2023,"As quantum computers mature, the applicability in practice becomes more important. Quantum computers will often be used in a hybrid setting, where classical computers still play an important role in operating and using the quantum computer. However the term hybrid is diffuse and multi-interpretable. In this work we define two classes of hybrid quantum-classical computing: vertical and horizontal hybrid quantum-classical computing. The first is application-agnostic and concerns using and operating quantum computers. The second is application-specific and concerns running an algorithm. For both, we give a further subdivision in different types of hybrid quantum-classical computing and we introduce terms for them.",Springer
"Cviti{\'{c}}, Ivan and Perakovi{\'{c}}, Dragan and Vladava, Josip",Systematic Analysis of Quantum Key Distribution Network Simulations Tools and Platforms,2024,10.1007/978-3-031-50051-0_1,https://doi.org/10.1007/978-3-031-50051-0_1,Conference Paper,Future Access Enablers for Ubiquitous and Intelligent Infrastructures,"Quantum Key Distribution (QKD) is one of the applications of quantum communications that is used to generate and distribute secret keys between two parties. These secrete keys are then used to establish secure communication. The security of QKD relies upon the principles of quantum mechanics, such as no-cloning theorem, that allow detection of any disturbances that quantum states could experience during transit. To facilitate these kinds of applications requires the development of quantum networks that consist of specialized hardware that is more complex than its classical counterpart. Hardware used in quantum networks is expensive, therefore it is very important to be confident in the design of network before physical implementation. This is why the development of quantum network simulation tools is of utmost importance. This research paper gives an overview and analysis of quantum network simulation tools and platforms that are capable of simulating quantum key distribution. Analysis will result in characteristics and capabilities of simulation tools and platforms that the researchers can use to choose the simulation tools most suitable for their scenario.",Springer
"Bernstein, Daniel J. and Chuengsatiansup, Chitchanok and Lange, Tanja and van Vredendaal, Christine",NTRU Prime: Reducing Attack Surface at Low Cost,2018,10.1007/978-3-319-72565-9_12,https://doi.org/10.1007/978-3-319-72565-9_12,Conference Paper,Selected Areas in Cryptography -- SAC 2017,"Several ideal-lattice-based cryptosystems have been broken by recent attacks that exploit special structures of the rings used in those cryptosystems. The same structures are also used in the leading proposals for post-quantum lattice-based cryptography, including the classic NTRU cryptosystem and typical Ring-LWE-based cryptosystems.",Springer
"Kolasani, Saydulu and Singhal, Sangeeta",Sustainable Digital and Enterprise Transformation for Omni-Channel Experiences Empowered by Data and AI/ML,2025,10.1007/978-3-031-71729-1_11,https://doi.org/10.1007/978-3-031-71729-1_11,Conference Paper,"Sustainable Development through Machine Learning, AI and IoT","This research paper explores the convergence of sustainable practices with digital and enterprise transformation, aiming to redefine and enhance omnichannel experiences. In a rapidly evolving technological landscape, the integration of data, artificial intelligence (AI), and machine learning (ML) is central to this transformation. The study delves into the strategic incorporation of sustainability principles, emphasizing eco-conscious decision-making throughout the digital and enterprise journey. By investigating how sustainable practices can be seamlessly woven into the fabric of omnichannel experiences, the paper seeks to provide insights for organizations aspiring to navigate the delicate balance between technological innovation and environmental responsibility. Through an interdisciplinary approach, the research not only highlights the potential of data-driven technologies but also examines their implications on sustainable development, contributing to a holistic understanding of the transformative power of digitalization within a responsible and ethical framework.",Springer
"Huang, Rongfeng and Yu, Tianyu and Liu, Shifang and Zhang, Xinyin and Zhao, Yonghua",A Batched Jacobi SVD Algorithm on GPUs and Its Application to Quantum Lattice Systems,2022,10.1007/978-3-030-96772-7_7,https://doi.org/10.1007/978-3-030-96772-7_7,Conference Paper,"Parallel and Distributed Computing, Applications and Technologies","Batched linear algebra problems are becoming increasingly important in engineering and scientific applications. As the performance of graphics processing units (GPUs) improves rapidly, GPUs are very attractive to solve this class of problems. This paper presents a parallel blocked Jacobi SVD algorithm for many small matrices on GPUs. The parallelism of the Jacobi algorithm is squeezed sufficiently. Our algorithm can be mapped to the GPU memory hierarchy properly due to the blocking structure. Reduction operations used for computing inner products and having low thread utilization are instead by performing the Jacobi rotation on the Gram matrix in parallel. We identify the kernels with sharing data and fuse them to improve memory locality by placing shared data, originally passed via off-chip global memory, into the on-chip shared memory. Numerical results on an NVIDIA Tesla V100 GPU show that our batched SVD routine outperforms state-of-the-art approaches between {\$}{\$}2.0{\backslash}times {\$}{\$}2.0{\texttimes}and {\$}{\$}4.1{\backslash}times {\$}{\$}4.1{\texttimes}for the examples tested. As one of the applications for our routine, the numerical simulation of quantum lattice systems is tested and achieves a maximum of {\$}{\$}54.1{\backslash}times {\$}{\$}54.1{\texttimes}speedups over the CPU implementation running on a 48-core Xeon CPU.",Springer
"Venkatesh, Supreeth Mysore and Macaluso, Antonio and Klusch, Matthias",GCS-Q: Quantum Graph Coalition Structure Generation,2023,10.1007/978-3-031-36030-5_11,https://doi.org/10.1007/978-3-031-36030-5_11,Conference Paper,Computational Science -- ICCS 2023,"The problem of generating an optimal coalition structure for a given coalition game of rational agents is to find a partition that maximizes their social welfare and known to be NP-hard. Though there are algorithmic solutions with high computational complexity available for this combinatorial optimization problem, it is unknown whether quantum-supported solutions may outperform classical algorithms.",Springer
"Tomaszewski, Lechos{\l}aw and Ko{\l}akowski, Robert",Network Slicing vs. Network Neutrality -- Is Consent Possible?,2023,10.1007/978-3-031-34171-7_6,https://doi.org/10.1007/978-3-031-34171-7_6,Conference Paper,Artificial Intelligence  Applications  and Innovations. AIAI 2023 IFIP WG 12.5 International Workshops,"Network Slicing (NS) is the inherent concept of the 5G network and beyond, ensuring dynamic and flexible use of resources, considered also a fundamental enabler of the ``Industry 4.0'' vision. However, its widespread implementation today encounters barriers, among which the paradigm of ``network neutrality'' is of key importance. This paper discusses the various factors affecting the wide implementation of NS: legal and political -- including the European Union regulation on network neutrality, trends in the telecommunications market, technical conditions of NS in 5G networks and beyond, especially physical barriers, and the fundamental conflicts of interest between various business actors in the telecommunications market as well as consequences of a dominant position of content providers over mobile operators enabled by the mentioned regulation. Based on the analysis of the above factors, it is concluded that NS has become a hostage of contradictory paradigms and visions that, if not revised, prevent sustainable development based on communication services implemented with the use of NS.",Springer
"Fournaris, Apostolos P. and Dimopoulos, Charis and Koufopavlou, Odysseas",Profiling Dilithium Digital Signature Traces for Correlation Differential Side Channel Attacks,2020,10.1007/978-3-030-60939-9_19,https://doi.org/10.1007/978-3-030-60939-9_19,Conference Paper,"Embedded Computer Systems: Architectures, Modeling, and Simulation","A significant concern for the candidate schemes of the NIST postquantum cryptography standardization project is the protection they support against side-channel attacks. One of these candidate schemes currently in the NIST standardization race is the Dilithium signature scheme. This postquantum signature solution has been analyzed for side channel attack resistance especially against timing attacks. Expanding our attention on other types of side-channel analysis, this work is focused on correlation based differential side channel attacks on the polynomial multiplication operation of Dilithium digital signature generation. In this paper, we describe how a Correlation Power Attack should be adapted for the Dilithium signature generation and describe the attack process to be followed. We determine the conditions to be followed in order for such an attack to be feasible, (isolation of polynomial coefficient multiplication inpower traces) and we create a power trace profiling paradigm for the Dilithium signature scheme executed in embedded systems to showcase that the conditions can be met in practice. Expanding the methodology of recent works that mainly use simulations for power trace collection, in this paper, power trace capturing and profiling analysis of the signature generation process was succesfully done on a, noisy, Commercial off-the-shelf ARM Cortex-M4 embedded system.",Springer
"Tanaka, Akihiro and Tyree, Juniper and Bj{\""o}rklund, Anton and M{\""a}kel{\""a}, Jarmo and Puolam{\""a}ki, Kai",{\$}{\$}{\backslash}chi {\$}{\$}iplot: Web-First Visualisation Platform for Multidimensional Data,2023,10.1007/978-3-031-43430-3_26,https://doi.org/10.1007/978-3-031-43430-3_26,Conference Paper,Machine Learning and Knowledge Discovery in Databases: Applied Data Science and Demo Track,"{\$}{\$}{\backslash}chi {\$}{\$}$\chi$iplot is an HTML5-based system for interactive exploration of data and machine learning models. A key aspect is interaction, not only for the interactive plots but also between plots. Even though {\$}{\$}{\backslash}chi {\$}{\$}$\chi$iplot is not restricted to any single application domain, we have developed and tested it with domain experts in quantum chemistry to study molecular interactions and regression models. {\$}{\$}{\backslash}chi {\$}{\$}$\chi$iplot can be run both locally and online in a web browser (keeping the data local). The plots and data can also easily be exported and shared. A modular structure also makes {\$}{\$}{\backslash}chi {\$}{\$}$\chi$iplot optimal for developing machine learning and new interaction methods.",Springer
"V{\'a}zquez, I. X. and Garc{\'i}a-Vico, A. M. and Seker, H. and Sedano, J.",Low Consumption Models for Disease Diagnosis in Isolated Farms,2025,10.1007/978-3-031-77731-8_22,https://doi.org/10.1007/978-3-031-77731-8_22,Conference Paper,Intelligent Data Engineering and Automated Learning -- IDEAL 2024,"The detection of bacterial and viral microbes is pivotal for both human and animal well-being in public health services and veterinary care, but it traditionally requires time-consuming procedures and expert technicians. However, the rise of Machine Learning and Deep Learning has led to a surge in the application of new techniques that can perform bacterial and viral detection faster and at a lower cost. Yet, despite that success, Deep Learning approaches tend to have high energy demands, which can in some contexts limit their application, increasing both costs and environmental concerns. In this study, a new hybrid methodology, in which an Artificial Neural Network was combined with a more energy efficient Spiking Neural Network, was employed to develop a model able to classify 18 species of Eimeria parasites, affecting both rabbits and chickens, from microscope images. We show how significant energy savings can be obtained from SNN layers, while their use in the model can improve its performance.",Springer
"Bhujade, Vaishali G. and Sambhe, V. K.",Multi-disease Classification and Severity Estimation of Cotton and Soybean Plants Using DenseNet,2024,10.1007/978-3-031-64070-4_2,https://doi.org/10.1007/978-3-031-64070-4_2,Conference Paper,Advanced Network Technologies and Intelligent Computing,"As agriculture plays vital role in nation's economy, early diagnosis of plant diseases is a crucial and challenging task. Soybean and Cotton are the cash crops in Maharashtra therefore this study focuses on these crops. Automatic disease recognition and classification poses a variety of challenges in consideration of available datasets, tools, and image capturing conditions and has received considerable attention in the past few decades. Diseases have proven to be the root cause to major losses in the production of crop and low-quality yield. Within this scenario, the automatic disease recognition and classification is very critical and primary challenge for sustainable farming. Traditional methods were manual which are prone to errors, time-consuming and costly. In recent years Deep learning along with image processing has garnered tremendous success in a variety of application domains including automatic disease detection, but, traditional methods were not focusing on multiple diseases available on single leaf image. In this investigation, image processing techniques are investigated for their potential application in identifying cotton and soybean leaf diseases. The study evaluates the accuracy and loss of two approaches, Inception-Visual Geometry Group Network (INC-VGGN) and FACED, following various training epochs. FACED shows superior performance than INC-VGGN for both cotton and soybean plants in terms of training and validation accuracy. FACED falls behind INC-VGGN in training accuracy at first, but at the end of 30 epochs, it has caught up and even surpassed it for soybean. FACAD gives high precision and recall over INC-VGGN.",Springer
"Dupont, Pierre-Alain and Hesse, Julia and Pointcheval, David and Reyzin, Leonid and Yakoubov, Sophia",Fuzzy Password-Authenticated Key Exchange,2018,10.1007/978-3-319-78372-7_13,https://doi.org/10.1007/978-3-319-78372-7_13,Conference Paper,Advances in Cryptology -- EUROCRYPT 2018,"Consider key agreement by two parties who start out knowing a common secret (which we refer to as ``pass-string'', a generalization of ``password''), but face two complications: (1) the pass-string may come from a low-entropy distribution, and (2) the two parties' copies of the pass-string may have some noise, and thus not match exactly. We provide the first efficient and general solutions to this problem that enable, for example, key agreement based on commonly used biometrics such as iris scans.",Springer
"Rodrigues, Vitor Hugo Mickus and Cavalcante, Lucas and Pereira, Maelso Bruno and Luporini, Fabio and Reguly, Istv{\'a}n and Gorman, Gerard and de Souza, Samuel Xavier",GPU Support for Automatic Generation of Finite-Differences Stencil Kernels,2020,10.1007/978-3-030-41005-6_16,https://doi.org/10.1007/978-3-030-41005-6_16,Conference Paper,High Performance Computing,"The growth of data to be processed in the Oil {\&} Gas industry matches the requirements imposed by evolving algorithms based on stencil computations, such as Full Waveform Inversion and Reverse Time Migration. Graphical processing units (GPUs) are an attractive architectural target for stencil computations because of its high degree of data parallelism. However, the rapid architectural and technological progression makes it difficult for even the most proficient programmers to remain up-to-date with the technological advances at a micro-architectural level. In this work, we present an extension for an open source compiler designed to produce highly optimized finite difference kernels for use in inversion methods named Devito{\textcopyright}. We embed it with the Oxford Parallel Domain Specific Language (OP-DSL) in order to enable automatic code generation for GPU architectures from a high-level representation. We aim to enable users coding in a symbolic representation level to effortlessly get their implementations leveraged by the processing capacities of GPU architectures. The implemented backend is evaluated on a NVIDIAé¹è°æªé·ç¨§TX Titan Z, and on a NVIDIAé¹è°æªé·ç¨µesla V100 in terms of operational intensity through the roof-line model for varying space-order discretization levels of 3D acoustic isotropic wave propagation stencil kernels with and without symbolic optimizations. It achieves approximately 63{\%} of V100's peak performance and 24{\%} of Titan Z's peak performance for stencil kernels over grids with 2563 points. Our study reveals that improving memory usage should be the most efficient strategy for leveraging the performance of the implemented solution on the evaluated architectures.",Springer
"Ambainis, Andris and Hamburg, Mike and Unruh, Dominique",Quantum Security Proofs Using Semi-classical Oracles,2019,10.1007/978-3-030-26951-7_10,https://doi.org/10.1007/978-3-030-26951-7_10,Conference Paper,Advances in Cryptology -- CRYPTO 2019,"We present an improved version of the one-way to hiding (O2H) Theorem by Unruh, J ACM 2015. Our new O2H Theorem gives higher flexibility (arbitrary joint distributions of oracles and inputs, multiple reprogrammed points) as well as tighter bounds (removing square-root factors, taking parallelism into account). The improved O2H Theorem makes use of a new variant of quantum oracles, semi-classical oracles, where queries are partially measured. The new O2H Theorem allows us to get better security bounds in several public-key encryption schemes.",Springer
"Kemcha, Rebiha and Nedjah, Nadia and Maouche, Amin Riad and Bougherara, Maamar",Evolutionary Design of Approximate Sequential Circuits at RTL Using Particle Swarm Optimization,2019,10.1007/978-3-030-24296-1_54,https://doi.org/10.1007/978-3-030-24296-1_54,Conference Paper,Computational Science and Its Applications -- ICCSA 2019,"Evolutionary circuit design has the ability to explore a wide part of the design space and can lead to satisfactory circuits without human experience and knowledge. In this work, we use Multi-Objective Particle Swarm Optimization to evolve approximate sequential circuits at Register-Transfer Level. A circuit is represented by a two-dimensional array. We aim to produce functional approximate circuits having good trade-off between accuracy, delay and area. The results show the efficiency of the proposed approach.",Springer
"Groot Bruinderink, Leon and H{\""u}lsing, Andreas","``Oops, I Did It Again'' -- Security of One-Time Signatures Under Two-Message Attacks",2018,10.1007/978-3-319-72565-9_15,https://doi.org/10.1007/978-3-319-72565-9_15,Conference Paper,Selected Areas in Cryptography -- SAC 2017,"One-time signatures (OTS) are called one-time, because the accompanying security reductions only guarantee security under single-message attacks. However, this does not imply that efficient attacks are possible under two-message attacks. Especially in the context of hash-based OTS (which are basic building blocks of recent standardization proposals) this leads to the question if accidental reuse of a one-time key pair leads to immediate loss of security or to graceful degradation.",Springer
"Freytag, Gabriel and Lima, Jo{\~a}o V. F. and Rech, Paolo and Navaux, Philippe O. A.",Impact of Reduced and Mixed-Precision on the Efficiency of a Multi-GPU Platform on CFD Applications,2022,10.1007/978-3-031-10542-5_39,https://doi.org/10.1007/978-3-031-10542-5_39,Conference Paper,Computational Science and Its Applications -- ICCSA 2022 Workshops,"The heterogeneity of modern computing architectures allows software engineers to refine their algorithms and assign the procedures with peculiar characteristics to the device with the most suitable architecture. In particular, the latest computing architectures, such as Nvidia's Graphics Processing Units (GPUs), feature mixed-precision Floating-Point Units (FPUs) that natively support double, single, and half-precision arithmetic operations. By using mixed precisions in a specific portion of the code can significantly improve both performances and computing efficiency. The challenge is to identify which procedure to run in lower precision without jeopardizing the accuracy loss.",Springer
"El Khatib, Rami and Azarderakhsh, Reza and Mozaffari-Kermani, Mehran",Optimized Algorithms and Architectures for Montgomery Multiplication for Post-quantum Cryptography,2019,10.1007/978-3-030-31578-8_5,https://doi.org/10.1007/978-3-030-31578-8_5,Conference Paper,Cryptology and Network Security,"Finite field multiplication plays the main role determining the efficiency of public key cryptography systems based on RSA and elliptic curve cryptography (ECC). Most recently, quantum-safe cryptographic systems are proposed based on supersingular isogenies on elliptic curves which require large integer multiplications over extended prime fields. In this work, we present two Montgomery multiplication architectures for special primes used in a post-quantum cryptography system known as supersingular isogeny key encapsulation (SIKE). We optimize two existing Montgomery multiplication algorithms and develop area-efficient and time-efficient Montgomery multiplication architectures for hardware implementations of post-quantum cryptography. Our proposed time-efficient architecture is {\$}{\$}32{\backslash}{\%}{\$}{\$}to {\$}{\$}42{\backslash}{\%}{\$}{\$}faster than the leading one (depending on the prime size) available in the literature which has been used in original SIKE submission to the NIST standardization process. The area-efficient architecture is {\$}{\$}42{\backslash}{\%}{\$}{\$}to {\$}{\$}50{\backslash}{\%}{\$}{\$}smaller than the counterparts and is about {\$}{\$}3{\backslash}{\%}{\$}{\$}to {\$}{\$}11{\backslash}{\%}{\$}{\$}faster depending on the NIST security level.",Springer
"Martin, Daniel P. and Montanaro, Ashley and Oswald, Elisabeth and Shepherd, Dan",Quantum Key Search with Side Channel Advice,2018,10.1007/978-3-319-72565-9_21,https://doi.org/10.1007/978-3-319-72565-9_21,Conference Paper,Selected Areas in Cryptography -- SAC 2017,"Recently, a number of results have been published that show how to combine classical cryptanalysis with quantum algorithms, thereby (potentially) achieving considerable speed-ups. We follow this trend but add a novel twist by considering how to utilise side channel leakage in a quantum setting. This is non-trivial because Grover's algorithm deals with unstructured data, however we are interested in searching through a key space which has structure due to the side channel information. We present a novel variation of a key enumeration algorithm that produces batches of keys that can be efficiently tested using Grover's algorithm. This results in the first quantum key search that benefits from side channel information.",Springer
"Arvanitis, Petros and Betting, Jan-Harm L. F. and Bosman, Laurens W. J. and Al-Ars, Zaid and Strydis, Christos",WhiskEras 2.0: Fast and Accurate Whisker Tracking in Rodents,2022,10.1007/978-3-031-04580-6_14,https://doi.org/10.1007/978-3-031-04580-6_14,Conference Paper,"Embedded Computer Systems: Architectures, Modeling, and Simulation","Mice and rats can rapidly move their whiskers when exploring the environment. Accurate description of these movements is important for behavioral studies in neuroscience. Whisker tracking is, however, a notoriously difficult task due to the fast movements and frequent crossings and juxtapositionings among whiskers. We have recently developed WhiskEras, a computer-vision-based algorithm for whisker tracking in untrimmed, head-restrained mice. Although WhiskEras excels in tracking the movements of individual unmarked whiskers over time based on high-speed videos, the initial version of WhiskEras still had two issues preventing its widespread use: it involved tuning a great number of parameters manually to adjust for different experimental setups, and it was slow, processing less than 1 frame per second. To overcome these problems, we present here WhiskEras 2.0, in which the unwieldy stages of the initial algorithm were improved. The enhanced algorithm is more robust, not requiring intense parameter tuning. Furthermore, it was accelerated by first porting the code from MATLAB to C++ and then using advanced parallelization techniques with CUDA and OpenMP to achieve a speedup of at least 75x when processing a challenging whisker video. The improved WhiskEras 2.0 is made publicly available and is ready for processing high-speed videos, thus propelling behavioral research in neuroscience, in particular on sensorimotor integration.",Springer
"Mulderij, J. and Aardal, K.I. and Chiscop, I. and Phillipson, F.",A Polynomial Size Model with Implicit SWAP Gate Counting for Exact Qubit Reordering,2023,10.1007/978-3-031-36030-5_7,https://doi.org/10.1007/978-3-031-36030-5_7,Conference Paper,Computational Science -- ICCS 2023,"Due to the physics behind quantum computing, quantum circuit designers must adhere to the constraints posed by the limited interaction distance of qubits. Existing circuits need therefore to be modified via the insertion of SWAP gates, which alter the qubit order by interchanging the location of two qubits' quantum states. We consider the Nearest Neighbor Compliance problem on a linear array, where the number of required SWAP gates is to be minimized. We introduce an Integer Linear Programming model of the problem of which the size scales polynomially in the number of qubits and gates. Furthermore, we solve 131 benchmark instances to optimality using the commercial solver CPLEX. The benchmark instances are substantially larger in comparison to those evaluated with exact methods before. The largest circuits contain up to 18 qubits or over 100 quantum gates. This formulation also seems to be suitable for developing heuristic methods since (near) optimal solutions are discovered quickly in the search process.",Springer
"Paier, Matteo and Van Eeden, Roberto and Miculan, Marino",Formal Analysis of Multi-Factor Authentication Schemes in Digital Identity Cards,2025,10.1007/978-3-031-77382-2_24,https://doi.org/10.1007/978-3-031-77382-2_24,Conference Paper,Software Engineering and Formal Methods,"We present a methodology for formally modelling and verifying multi-factor authentication (MFA) schemes employed in eIDAS digital identity cards. This methodology adopts an interface-based threat model to comprehensively analyse potential vulnerabilities and enumerate threat scenarios based on an attacker's capabilities. Using CIE, Italy's eIDAS-compliant digital identity card, as guiding example, we show how to automatically generate ProVerif models of these scenarios. Our analysis exposes some vulnerabilities; e.g., an attacker with Level 1 credentials can gain Level 2 authentication, even without compromising any interface. To address these vulnerabilities, we propose minor modifications to the protocols, whose correctness is proved by further formal analysis.",Springer
"Di Pietro, Roberto and Caprolu, Maurantonio and Raponi, Simone","Next Generation Information Warfare: Rationales, Scenarios, Threats, and Open Issues",2020,10.1007/978-3-030-49443-8_2,https://doi.org/10.1007/978-3-030-49443-8_2,Conference Paper,Information Systems Security and Privacy,"The technological advances made in the last twenty years radically changed our society, improving our lifestyle in almost every aspect of our daily life. This change directly affects human habits, transforming the way people share information and knowledge. The exponential technological advancement, together with the related information deluge, are also radically changing Information Warfare and its scenarios. Indeed, the consequently increase of the digital attack surface poses new challenges and threats for both personal and national security.",Springer
"Saajasto, Mika and Kaasalainen, Sanna and M{\""a}kel{\""a}, Maija and Bhuiyan, M. Zahidul H. and Koivula, Hannu and Kirkko-Jaakkola, Martti and Kuusniemi, Heidi",GNSS Signal Monitoring and Security of Supply of GNSS-Based Services,2024,10.1007/978-3-031-62139-0_11,https://doi.org/10.1007/978-3-031-62139-0_11,Conference Paper,Critical Information Infrastructures Security,"The global GNSS markets are expected to grow considerably in future, thus the number of threats against GNSS services will also increase. Understanding how GNSS services are utilized on a national level is crucial for the resilience, safety and quality of these services.",Springer
"Tsai, Ming-Hsien and Fu, Yu-Fu and Liu, Jiaxiang and Shi, Xiaomu and Wang, Bow-Yaw and Yang, Bo-Yin",CoqCryptoLine: A Verified Model Checker with Certified Results,2023,10.1007/978-3-031-37703-7_11,https://doi.org/10.1007/978-3-031-37703-7_11,Conference Paper,Computer Aided Verification,We present the verified model checker CoqCryptoLine for cryptographic programs with certified verification results. The CoqCryptoLine verification algorithm consists of two reductions. The algebraic reduction transforms into a root entailment problem; and the bit-vector reduction transforms into an SMT QF{\_}BV problem. We specify and verify both reductions formally using Coq with MathComp. The CoqCryptoLine tool is built on the OCaml programs extracted from verified reductions. CoqCryptoLine moreover employs certified techniques for solving the algebraic and logic problems. We evaluate CoqCryptoLine on cryptographic programs from industrial security libraries.,Springer
"Boneh, Dan and B{\""u}nz, Benedikt and Fisch, Ben",Batching Techniques for Accumulators with Applications to IOPs and Stateless Blockchains,2019,10.1007/978-3-030-26948-7_20,https://doi.org/10.1007/978-3-030-26948-7_20,Conference Paper,Advances in Cryptology -- CRYPTO 2019,"We present batching techniques for cryptographic accumulators and vector commitments in groups of unknown order. Our techniques are tailored for distributed settings where no trusted accumulator manager exists and updates to the accumulator are processed in batches. We develop techniques for non-interactively aggregating membership proofs that can be verified with a constant number of group operations. We also provide a constant sized batch non-membership proof for a large number of elements. These proofs can be used to build the first positional vector commitment (VC) with constant sized openings and constant sized public parameters. As a core building block for our batching techniques we develop several succinct proof systems in groups of unknown order. These extend a recent construction of a succinct proof of correct exponentiation, and include a succinct proof of knowledge of an integer discrete logarithm between two group elements. We circumvent an impossibility result for Sigma-protocols in these groups by using a short trapdoor-free CRS. We use these new accumulator and vector commitment constructions to design a stateless blockchain, where nodes only need a constant amount of storage in order to participate in consensus. Further, we show how to use these techniques to reduce the size of IOP instantiations, such as STARKs. The full version of the paper is available online [BBF18b].",Springer
"Farhat, Salman and Bliudze, Simon and Duchien, Laurence and Kouchnarenko, Olga",Composing Run-Time Variability Models,2025,10.1007/978-3-031-77382-2_14,https://doi.org/10.1007/978-3-031-77382-2_14,Conference Paper,Software Engineering and Formal Methods,"The sheer complexity of modern systems requires compositional approaches to variability modelling. To manage the variability of large systems' architecture, feature models are widely used at design-time, with several operators defined to allow their composition. However, complex systems' architectures may evolve at run-time by acquiring new features and functionalities while respecting new constraints. To address this challenge, this paper defines composition operators for component-based run-time variability models that not only encode these feature model composition operators, but also ensure safe run-time reconfiguration. To prove the correctness and compositionality properties, we propose a novel multi-step {\$}{\$}{\backslash}mathcal{\{}U{\}}{\backslash}mathcal{\{}P{\}}{\$}{\$}UP-bisimulation equivalence and use it to show that the component-based run-time variability models preserve the semantics of the composed feature models. In addition, reachability results permit safe reconfiguration.",Springer
"Hastings, Florencia and Fuentes, Ignacio and Perez-Bidegain, Mario and Navas, Rafael and Gorgoglione, Angela",Land-Cover Mapping of Agricultural Areas Using Machine Learning in Google Earth Engine,2020,10.1007/978-3-030-58811-3_52,https://doi.org/10.1007/978-3-030-58811-3_52,Conference Paper,Computational Science and Its Applications -- ICCSA 2020,"Land-cover mapping is critically needed in land-use planning and policy making. Compared to other techniques, Google Earth Engine (GEE) offers a free cloud of satellite information and high computation capabilities. In this context, this article examines machine learning with GEE for land-cover mapping. For this purpose, a five-phase procedure is applied: (1) imagery selection and pre-processing, (2) selection of the classes and training samples, (3) classification process, (4) post-classification, and (5) validation. The study region is located in the San Salvador basin (Uruguay), which is under agricultural intensification. As a result, the 1990 land-cover map of the San Salvador basin is produced. The new map shows good agreements with past agriculture census and reveals the transformation of grassland to cropland in the period 1990--2018.",Springer
"Demenkova, Tatyana and Indrishenok, Valery and Pevtsov, Evgeny",Simulation Tools for E-Learning in Microelectronics and Nanoelectronics at the University,2020,10.1007/978-3-030-46895-8_10,https://doi.org/10.1007/978-3-030-46895-8_10,Conference Paper,Modern Information Technology and IT Education,"In work results of researches in the area of simulation of electrical characteristics of the AlGaN/GaN field-effect transistor are provided. The considerable difference of transport processes in case of the strong and feeble electrical polarization is shown. The role of capture of centers in volume of a buffer layer GaN is analyzed and it is shown that deep interruptions can influence considerably on distribution of electrostatic potential and density of electrons in a buffer layer. In case of high concentration of interruptions there is a sharp lowering of density of the free electrons with increase of distance from the channel, the current density in the depth of a buffer layer decreases. The received scientific results have allowed to use the scientific software for disciplines on the automated design in electronics, automation of an experiment and for design and modeling micro and nanosystems within the direction of microelectronics and nanoelectronics for training of masters at the university. Software systems are designed for mathematical simulation of semiconductor manufacturing processes, their electrical, optical, thermal, and other characteristics. A significant advantage is the possibility of establishing a relationship between the devices characteristics and the manufacturing technology and design parameters, without involving costly experimental studies, based on their physical implementation. The software is used to develop devices and elements of integrated circuits, to study device properties in various operating modes when exposed to various external factors.",Springer
"{\.{Z}}o{\l}nierczyk, Olgierd and Wro{\'{n}}ski, Micha{\l}",Searching B-Smooth Numbers Using Quantum Annealing: Applications to Factorization and Discrete Logarithm Problem,2023,10.1007/978-3-031-36030-5_1,https://doi.org/10.1007/978-3-031-36030-5_1,Conference Paper,Computational Science -- ICCS 2023,"Integer factorization and discrete logarithm problem, two problems of classical public-key cryptography, are vulnerable to quantum attacks, especially polynomial-time Shor's algorithm, which has to be run on the general-purpose quantum computer. On the other hand, one can make quantum computations using quantum annealing, where every problem has to be transformed into an optimization problem, for example, the QUBO problem. Currently, the biggest available quantum annealer, D-Wave advantage, has almost 6,000 physical qubits, and therefore it can solve bigger problems than using general-purpose quantum computers. Even though it is impossible to run Shor's algorithm on a quantum annealer, several methods allow one to transform factorization or discrete logarithm problems into the QUBO problem. Using a D-Wave quantum annealer, the biggest factored integer had 20 bits, and the biggest field, on which it was possible to compute a discrete logarithm problem using any quantum method, had 6 bits. This paper shows how to transform searching for B-smooth numbers, an important part of the quadratic sieve method for factorization and index calculus for solving discrete logarithm problems, to the QUBO problem and then solve it using D-Wave Advantage quantum solver. The linear algebra step for integer factorization and index calculus methods has been solved using classical computations. Using our method, we factorized the 26-bit integer and computed the discrete logarithm problem over the 18-bit prime field. Therefore we broke the current records in factorization using quantum annealing by 6 bits and in discrete logarithm problem, using any quantum method, by 12 bits.",Springer
"Yang, Kun and Wu, Tong and Shen, Qingfei and Cui, Weiqun and Zhang, Guichun",Benchmark Researches from the Perspective of Metrology,2020,10.1007/978-3-030-49556-5_31,https://doi.org/10.1007/978-3-030-49556-5_31,Conference Paper,"Benchmarking, Measuring, and Optimizing","This paper discusses some problems the benchmark researches should pay attention to from the perspective of Metrology. Metrology is about the science of measurement, and it is considered as the foundation of industry development, for you have to measure it before you know what level it reaches. Metrology has a series of mechanisms to ensure the attributes of the measurement results, including Accuracy, Traceability, consistency and legality. Benchmark is widely used to evaluate the information technology products and helps the users to choose the products they need, and if absorbing the ideas of Metrology research during the designing, developing and application procedures of the benchmark, the quality of the measurement result of the benchmark will be improved greatly and become more authoritative.",Springer
"Ferradi, Houda and Naccache, David",Integer Reconstruction Public-Key Encryption,2019,10.1007/978-3-030-31578-8_23,https://doi.org/10.1007/978-3-030-31578-8_23,Conference Paper,Cryptology and Network Security,"In [AJPS18], Aggarwal, Joux, Prakash {\&} Santha described an elegant public-key encryption ({\$}{\$}{\backslash}mathsf {\{}AJPS{\}}{\$}{\$}-1) mimicking NTRU over the integers. This algorithm relies on the properties of Mersenne primes instead of polynomial rings.",Springer
"Tsiskaridze, Nestan and Barrett, Clark and Tinelli, Cesare",Generalized Optimization Modulo Theories,2024,10.1007/978-3-031-63498-7_27,https://doi.org/10.1007/978-3-031-63498-7_27,Conference Paper,Automated Reasoning,"Optimization Modulo Theories (OMT) has emerged as an important extension of the highly successful Satisfiability Modulo Theories (SMT) paradigm. The OMT problem requires solving an SMT problem with the restriction that the solution must be optimal with respect to a given objective function. We introduce a generalization of the OMT problem where, in particular, objective functions can range over partially ordered sets. We provide a formalization of and an abstract calculus for the Generalized OMT problem and prove their key correctness properties. Generalized OMT extends previous work on OMT in several ways. First, in contrast to many current OMT solvers, our calculus is theory-agnostic, enabling the optimization of queries over any theories or combinations thereof. Second, our formalization unifies both single- and multi-objective optimization problems, allowing us to study them both in a single framework and facilitating the use of objective functions that are not supported by existing OMT approaches. Finally, our calculus is sufficiently general to fully capture a wide variety of current OMT approaches (each of which can be realized as a specific strategy for rule application in the calculus) and to support the exploration of new search strategies. Much like the original abstract DPLL(T) calculus for SMT, our Generalized OMT calculus is designed to establish a theoretical foundation for understanding and research and to serve as a framework for studying variations of and extensions to existing OMT methodologies.",Springer
"Blanco, Miguel {\'A}ngel and Piattini, Mario",Adapting COBIT for Quantum Computing Governance,2020,10.1007/978-3-030-58793-2_22,https://doi.org/10.1007/978-3-030-58793-2_22,Conference Paper,Quality of Information and Communications Technology,"Quantum computing is a new paradigm that uses the properties of quantum mechanics to achieve computers and technologies more powerful. Quantum Technology will solve some types of problems more efficiently than current technology. Every organization that wants to use all the power of quantum computing to be more competitive in its sector, must have a method that allows it to take advantage of all the value that this technology can provide. This article proposes the development of a framework for the Management and Governance of Quantum Computing based on COBIT.",Springer
"Zbinden, Stefanie and B{\""a}rtschi, Andreas and Djidjev, Hristo and Eidenbenz, Stephan",Embedding Algorithms for Quantum Annealers with Chimera and Pegasus Connection Topologies,2020,10.1007/978-3-030-50743-5_10,https://doi.org/10.1007/978-3-030-50743-5_10,Conference Paper,High Performance Computing,"We propose two new algorithms -- Spring-Based MinorMiner (SPMM) and Clique-Based MinorMiner (CLMM) -- which take as input the connectivity graph of a Quadratic Unconstrained Binary Optimization (QUBO) problem and produce as output an embedding of the input graph on a host graph that models the topology of a quantum computing device. As host graphs, we take the Chimera graph and the Pegasus graph, which are the topology graphs of D-Wave's 2000 qubit (first introduced in 2017) and 5000 qubit (expected 2020) quantum annealer devices, respectively. We evaluate our algorithms on a large set of random graph QUBO inputs (Erd{\H{o}}s-R{\'e}nyi {\$}{\$}G{\_}{\{}n,p{\}}{\$}{\$}, Barab{\'a}si-Albert and d-regular graphs) on both host topologies against other embedding algorithms. For the Pegasus topology, we find that CLMM outperforms all other algorithms at edge densities larger than 0.08, while SPMM wins at edge densities smaller than 0.08 for Erd{\H{o}}s-R{\'e}nyi graphs, with very similar transition densities for the other graph classes. Surprisingly, the standard D-Wave MinorMiner embedding algorithm -- while also getting slightly outperformed by SPMM for sparse and very dense graphs on Chimera -- does not manage to extend its overall good performance on Chimera to Pegasus as it fails to embed even medium-density graphs on 175--180 nodes which are known to have clique embeddings on Pegasus.",Springer
"Tanjin, Merina and Botlero, Ishorju Agnes and Hridita, Mourina Tasnim and Riyadh, Tawsiful Islam and Onik, Md. Mehedi Hassan and Miraz, Mahdi H.",Privacy and Security Factors of Government Websites versus Private Websites in Bangladesh and USA: A Comparative Study,2021,10.1007/978-3-030-90016-8_3,https://doi.org/10.1007/978-3-030-90016-8_3,Conference Paper,Emerging Technologies in Computing,"Security and privacy are the two most vital aspects of the modern technological evolution, to ensure the required level of trust between the customers and the service providers. Personally identifiable information (PII) is mounting at an exponential rate and so does the associated manifold security risks. In fact, there are many state-of-the-art security and privacy-preserving mechanisms in practice, however, the least developed countries (LDC) are often reluctant to maintain those security standards, in comparison to their counterparts i.e. the developed countries (DC). In addition, government managed websites in LDCs are more exposed to security and privacy vulnerabilities compared with the private sector websites. This study provides a security and privacy assessment model that can thoroughly assess government as well as private websites. To validate the proposed model, this study has selected Bangladesh as a representative of the least developed countries and United States of America (USA) for the developed countries. After a detailed empirical analysis of 20 government and private websites of each of these two countries, this study found that the majority of the public websites in LSD (Bangladesh) were less secure than the private ones, in comparison to those of the DC (USA). Several underlying factors, such as corruption, financial variances, policy issues and lack of skilled workforce in security sector, were the main reasons behind this inequality. This study also outlines some guidelines and recommendations for LDC to eradicate prevailing differences amongst public and private websites' security and privacy standards.",Springer
"Hong, Chi and Huang, Jiyue and Birke, Robert and Chen, Lydia Y.",Exploring and Exploiting Data-Free Model Stealing,2023,10.1007/978-3-031-43424-2_2,https://doi.org/10.1007/978-3-031-43424-2_2,Conference Paper,Machine Learning and Knowledge Discovery in Databases: Research Track,"Deep machine learning models, e.g., image classifier, are increasingly deployed in the wild to provide services to users. Adversaries are shown capable of stealing the knowledge of these models by sending inference queries and then training substitute models based on query results. The availability and quality of adversarial query inputs are undoubtedly crucial in the stealing process. The recent prior art demonstrates the feasibility of replacing real data by exploring the synthetic adversarial queries, so called data-free attacks, under strong adversarial assumptions, i.e., the deployed classier returns not only class labels but also class probabilities. In this paper, we consider a general adversarial model and propose an effective data-free stealing algorithm, TandemGAN, which not only explores synthetic queries but also explicitly exploits the high quality ones. The core of TandemGAN is composed of (i) substitute model which imitates the target model through synthetic queries and their inferred labels; and (ii) a tandem generator consisting of two networks, {\$}{\$}{\backslash}mathcal {\{}G{\}}{\_}x{\$}{\$}and {\$}{\$}{\backslash}mathcal {\{}G{\}}{\_}e{\$}{\$}, which first explores the synthetic data space via {\$}{\$}{\backslash}mathcal {\{}G{\}}{\_}x{\$}{\$}and then exploits high-quality examples via {\$}{\$}{\backslash}mathcal {\{}G{\}}{\_}e{\$}{\$}to maximize the knowledge transfer from the target to the substitute model. Our results on four datasets show that the accuracy of our trained substitute model ranges between 96--67{\%} of the target model and outperforms the existing state-of-the-art data-free model stealing approach by up to 2.5X.",Springer
"Eaton, Edward",Leighton-Micali Hash-Based Signatures in the Quantum Random-Oracle Model,2018,10.1007/978-3-319-72565-9_13,https://doi.org/10.1007/978-3-319-72565-9_13,Conference Paper,Selected Areas in Cryptography -- SAC 2017,"Digital signatures constructed solely from hash functions offer competitive signature sizes and fast signing and verifying times. Moreover, the security of hash functions against a quantum adversary is believed to be well understood. This means that hash-based signatures are strong candidates for standard use in a post-quantum world. The Leighton-Micali signature scheme (LMS) is one such scheme being considered for standardization. However all systematic analyses of LMS have only considered a classical adversary. In this work we close this gap by showing a proof of the security of LMS in the quantum random-oracle model. Our results match the bounds imposed by Grover's search algorithm within a constant factor, and remain tight in the multi-user setting.",Springer
"Matsuda, Yoshitatsu",Optimization of Search Space for Finding Very Short Lattice Vectors,2020,10.1007/978-3-030-58208-1_9,https://doi.org/10.1007/978-3-030-58208-1_9,Conference Paper,Advances in Information and Computer Security,"Shortest vector problem on lattices (SVP) is a well-known algorithmic combinatorial problem. The hardness of SVP is a foundation for the security of Lattice-based cryptography, which is a promising candidate of the post-quantum cryptographic algorithms. Therefore, many works have focused on the estimation of the hardness of SVP and the construction of efficient algorithms. Recently, a probabilistic approach has been proposed for estimating the hardness, which is based on the randomness assumption. The approach can estimate quite accurately the distribution of very short lattice vectors in a search space. In this paper, a new method is proposed for optimizing a box-type search space in random sampling by this probabilistic approach. It has been known empirically that the tail part of the search space should be more intensively explored for finding very short lattice vectors efficiently. However, it was difficult to adjust the search space quantitatively. On the other hand, our proposed method can find the best search space approximately. Experimental results show that our method is useful when the lattice basis is small or already reduced in advance.",Springer
"Afzal, Ayesha and Hager, Georg and Wellein, Gerhard",Desynchronization and Wave Pattern Formation in MPI-Parallel and Hybrid Memory-Bound Programs,2020,10.1007/978-3-030-50743-5_20,https://doi.org/10.1007/978-3-030-50743-5_20,Conference Paper,High Performance Computing,"Analytic, first-principles performance modeling of distributed-memory parallel codes is notoriously imprecise. Even for applications with extremely regular and homogeneous compute-communicate phases, simply adding communication time to computation time does often not yield a satisfactory prediction of parallel runtime due to deviations from the expected simple lockstep pattern caused by system noise, variations in communication time, and inherent load imbalance. In this paper, we highlight the specific cases of provoked and spontaneous desynchronization of memory-bound, bulk-synchronous pure MPI and hybrid MPI+OpenMP programs. Using simple microbenchmarks we observe that although desynchronization can introduce increased waiting time per process, it does not necessarily cause lower resource utilization but can lead to an increase in available bandwidth per core. In case of significant communication overhead, even natural noise can shove the system into a state of automatic overlap of communication and computation, improving the overall time to solution. The saturation point, i.e., the number of processes per memory domain required to achieve full memory bandwidth, is pivotal in the dynamics of this process and the emerging stable wave pattern. We also demonstrate how hybrid MPI-OpenMP programming can prevent desirable desynchronization by eliminating the bandwidth bottleneck among processes. A Chebyshev filter diagonalization application is used to demonstrate some of the observed effects in a realistic setting.",Springer
"Iavich, Maksim and Iashvili, Giorgi and Gnatyuk, Sergiy and Tolbatov, Andrii and Mirtskhulava, Lela",Efficient and Secure Digital Signature Scheme for Post Quantum Epoch,2021,10.1007/978-3-030-88304-1_15,https://doi.org/10.1007/978-3-030-88304-1_15,Conference Paper,Information and Software Technologies,"It is expected the massive release of quantum computers in the near future. Quantum computers can easily break the crypto schemes, which are used in practice. Therefore, classical encryption systems have become vulnerable to quantum computer-based attacks. This involves the research efforts that look for encryption schemes that are immune to quantum computer-based attacks. This paper describes the digital signature schemes, which are safe against quantum computer attacks, but these schemes have different efficiency problems. The signature size of the scheme is very large and one-way function are used many time during the signature process. The paper offers the ways of reducing the signature size and acceleration the process of using one-way functions. It is offered to integrate the quantum key distribution algorithms into the scheme. It is also offered to use Blake family hash function as the one-way function.",Springer
"Chen, Xiangquan and Xu, Chungen and Dou, Bennian and Zhang, Pan",PPAPAFL: A Novel Approach to Privacy Protection and Anti-poisoning Attacks in Federated Learning,2024,10.1007/978-3-031-51399-2_7,https://doi.org/10.1007/978-3-031-51399-2_7,Conference Paper,"Tools for Design, Implementation and Verification of Emerging Information Technologies","In the realm of distributed machine learning, although federated learning has received considerable attention, it still confronts grave challenges such as user privacy leakage and poisoning attacks. Regrettably, the demands for privacy preservation and protection against poisoning attacks are conflicting. Measures for privacy protection generally assure the indistinguishability of local parameter updates, which conversely complicates the strategy of defending against poisoning attacks by making it harder to identify malicious users. To address these issues, we propose a privacy-preserving and anti-poisoning attack federated learning (PPAPAFL) scheme. This scheme employs the CKKS homomorphic encryption technique for gradient packaging encryption, thus ensuring data privacy. Concurrently, our designed robust aggregation algorithm can effectively resist poisoning attacks, guaranteeing the model's integrity and accuracy, and is capable of supporting heterogeneous data in a friendly manner. A plethora of comparative experimental results demonstrate that our scheme can significantly improve the model's accuracy and robustness, drastically reduce the attack success rate, and effectively protect data privacy. In comparison with advanced schemes such as Trum and PEFL, our scheme achieves a 10--50{\%} improvement in model accuracy and reduces the attack success rate to less than 3{\%}.",Springer
"Molina, Arturo",Emerging Approaches for Enterprises and Human Integration Towards Industry 5.0,2023,10.1007/978-3-031-42622-3_25,https://doi.org/10.1007/978-3-031-42622-3_25,Conference Paper,Collaborative Networks in Digitalization and Society 5.0,"Industry 5.0 represents the latest phase of industrial transformation, emphasizing the integration of advanced technologies with human capabilities to achieve new levels of productivity, efficiency, and sustainability. This research explores the emerging approaches for enterprises and human integration towards Industry 5.0. This position paper highlights the key technological advancements and their impact on industrial processes, as well as the strategies employed by enterprises to foster seamless collaboration between humans and machines. Additionally, it discusses the challenges and potential solutions in achieving successful integration and presents case studies and examples to illustrate real-world implementations. This research aims to provide insights into the evolving landscape of Industry 5.0 and its implications for enterprises and human workers.",Springer
"Koziel, Brian and Azarderakhsh, Reza and Jao, David",Side-Channel Attacks on Quantum-Resistant Supersingular Isogeny Diffie-Hellman,2018,10.1007/978-3-319-72565-9_4,https://doi.org/10.1007/978-3-319-72565-9_4,Conference Paper,Selected Areas in Cryptography -- SAC 2017,"In this paper, we present three side-channel attacks on the quantum-resistant supersingular isogeny Diffie-Hellman (SIDH) key exchange protocol. These refined power analysis attacks target the representation of a zero value in a physical implementation of SIDH to extract bits of the secret key. To understand the behavior of these zero-attacks on SIDH, we investigate the representation of zero in the context of quadratic extension fields and isogeny arithmetic. We then present three different refined power analysis attacks on SIDH. Our first and second attacks target the Jao, De Feo, and Pl{\^u}t three-point Montgomery ladder by utilizing a partial-zero attack and zero-value attack, respectively. Our third attack proposes a method to break the large-degree isogeny by utilizing zero-values in the context of isogenies. The goal of this paper is to illustrate additional security concerns for an SIDH static-key user.",Springer
"Khadiev, Kamil and Khadieva, Aliya",Two-Way Quantum and Classical Automata with Advice for Online Minimization Problems,2020,10.1007/978-3-030-54997-8_27,https://doi.org/10.1007/978-3-030-54997-8_27,Conference Paper,Formal Methods. FM 2019 International Workshops,"We consider online algorithms. Typically the model is investigated with respect to competitive ratio. In this paper, we explore two-way automata as a model for online algorithms. We focus on quantum and classical online algorithms. We show that there are problems that can be solved more efficiently by two-way automata with quantum and classical states than classical two-way automata in the case of sublogarithmic memory (sublinear size) even if classical automata get advice bits.",Springer
"Hofmeier, Michael and Seidenfad, Karl and Hofmeier, Manfred and Hommel, Wolfgang",Web-Based Protocol Enabling Distributed Identity Information Networks for Greater Sovereignty,2024,10.1007/978-3-031-60433-1_23,https://doi.org/10.1007/978-3-031-60433-1_23,Conference Paper,Innovations for Community Services,"This paper presents a design for a Distributed Identity Information Network (DistIN) that can manage digital identities in a decentralized manner while aiming for high security, scalability and sovereignty. This novel approach enables the creation and verification of electronic signatures and offers the functionality of a public key infrastructure. Due to its decentralized nature and flexibility, this system is suitable for various types of organizations, including community services. Common web technologies, state-of-the-art cryptographic algorithms as well as blockchain technology are used. This system design is developed on the basis of universal use cases and validated for its applicability, leading to the web-based DistIN protocol as a result.",Springer
"Sanchez-Rivero, Javier and Talav{\'a}n, Daniel and Garcia-Alonso, Jose and Ruiz-Cort{\'e}s, Antonio and Murillo, Juan Manuel",Operating with Quantum Integers: An Efficient `Multiples of' Oracle,2023,10.1007/978-3-031-45728-9_7,https://doi.org/10.1007/978-3-031-45728-9_7,Conference Paper,Service-Oriented Computing,"Quantum algorithms are a very promising field. However, creating and manipulating these kind of algorithms is a very complex task, specially for software engineers used to work at higher abstraction levels. The work presented here is part of a broader research focused on providing operations of a higher abstraction level to manipulate integers codified as a superposition. These operations are designed to be composable and efficient, so quantum software developers can reuse them to create more complex solutions. Specifically, in this paper we present a `multiples of' operation. To validate this operation, we show several examples of quantum circuits and their simulations, including its composition possibilities. A theoretical analysis proves that both the complexity of the required classical calculations and the depth of the circuit scale linearly with the number of qubits. Hence, the `multiples of' oracle is efficient in terms of complexity and depth. Finally, an empirical study of the circuit depth is conducted to further reinforce the theoretical analysis.",Springer
"Aono, Yoshinori and Nguyen, Phong Q. and Seito, Takenobu and Shikata, Junji",Lower Bounds on Lattice Enumeration with Extreme Pruning,2018,10.1007/978-3-319-96881-0_21,https://doi.org/10.1007/978-3-319-96881-0_21,Conference Paper,Advances in Cryptology -- CRYPTO 2018,"At Eurocrypt '10, Gama, Nguyen and Regev introduced lattice enumeration with extreme pruning: this algorithm is implemented in state-of-the-art lattice reduction software and used in challenge records. They showed that extreme pruning provided an exponential speed-up over full enumeration. However, no limit on its efficiency was known, which was problematic for long-term security estimates of lattice-based cryptosystems. We prove the first lower bounds on lattice enumeration with extreme pruning: if the success probability is lower bounded, we can lower bound the global running time taken by extreme pruning. Our results are based on geometric properties of cylinder intersections and some form of isoperimetry. We discuss their impact on lattice security estimates.",Springer
"Ney, Jonas and F{\""u}llner, Christoph and Lauinger, Vincent and Schmalen, Laurent and Randel, Sebastian and Wehn, Norbert",From Algorithm to Implementation: Enabling High-Throughput CNN-Based Equalization on FPGA for Optical Communications,2023,10.1007/978-3-031-46077-7_11,https://doi.org/10.1007/978-3-031-46077-7_11,Conference Paper,"Embedded Computer Systems: Architectures, Modeling, and Simulation","To satisfy the growing throughput demand of data-intensive applications, the performance of optical communication systems increased dramatically in recent years. With higher throughput, more advanced equalizers are crucial, to compensate for impairments caused by intersymbol interference (ISI). Latest research shows that artificial neural network (ANN)-based equalizers are promising candidates to replace traditional algorithms for high-throughput communications. However, ANNs often introduce high complexity, limiting the achievable throughput of the hardware implementation. In this work, we present a high-performance field programmable gate array (FPGA) implementation of an ANN-based equalizer, which meets the throughput requirements of modern optical communication systems. Our implementation is based on a cross-layer design approach featuring optimizations from the algorithm down to the hardware architecture. Furthermore, we present a framework to reduce the latency of the ANN-based equalizer under given throughput constraints. As a result, the bit error rate (BER) of our equalizer is around one order of magnitude lower than that of a conventional one, while the corresponding FPGA implementation achieves a throughput of more than 40 GBd, outperforming a high-performance graphics processing unit (GPU) by four orders of magnitude for a similar batch size.",Springer
"Boneh, Dan and Boyle, Elette and Corrigan-Gibbs, Henry and Gilboa, Niv and Ishai, Yuval",Zero-Knowledge Proofs on Secret-Shared Data via Fully Linear PCPs,2019,10.1007/978-3-030-26954-8_3,https://doi.org/10.1007/978-3-030-26954-8_3,Conference Paper,Advances in Cryptology -- CRYPTO 2019,"We introduce and study the notion of fully linear probabilistically checkable proof systems. In such a proof system, the verifier can make a small number of linear queries that apply jointly to the input and a proof vector.",Springer
"Bure{\v{s}}, Petr and Langr, Martin",Implementation of Traffic Service Quality Measures in Czechia,2018,10.1007/978-3-319-97955-7_2,https://doi.org/10.1007/978-3-319-97955-7_2,Conference Paper,Management Perspective for Transport Telematics,"With the implementation of the ITS Directive (2010/40/EU) concerning the pan European travel and traffic information services the quality of the service and underlying data becomes an issue. There is a number of different approaches how to assess the quality of data and of a service, each with its particular benefits, however together the approaches are not implementable and alone do not cover all the specifics of the traffic information. The paper deals with an incremental implementation of traffic information service quality measures, focusing, in the first step, only on directly measureable technical and editorial aspects of the data and a service quality. These aspects are measured and tested on the real world example and the results, its impacts on quality improvement, are discussed.",Springer
"Dorri, Ali and Jurdak, Raja and Beheshti, Amin and Barros, Alistair",Towards Scalable Blockchains Using Service-Oriented Architectures,2022,10.1007/978-3-031-14135-5_31,https://doi.org/10.1007/978-3-031-14135-5_31,Conference Paper,Service-Oriented Computing -- ICSOC 2021 Workshops,"In recent years, blockchain applications beyond cryptocurrency has received tremendous attention due to its salient features which includes distributed management, security, anonymity, and immutability. However, conventional blockchains suffer from lack of scalability, high complexity, privacy, and governance. In this paper, we study the existing solutions introduced to address these limitations. We categorize these solutions into four groups which are: i) grouping nodes where the participating nodes are formed into smaller groups, ii) side channels where selected nodes form a child ledger attached to the main ledger to communicate privately, iii) optimized consensus algorithms that aim to reduce the overheads associated with committing new blocks, and iv) Blockchain-as-a-Service (BaaS) that employ service computing concepts and offload the blockchain management overheads to the cloud. A detailed discussion on BaaS is proposed along with a study of the existing cloud architectures. We elaborate on the advantages of employing blockchain to address challenges in service computing such as service recommendation. Finally, we discuss future research directions.",Springer
"Stiller, Patrick and Bethke, Friedrich and B{\""o}hme, Maximilian and Pausch, Richard and Torge, Sunna and Debus, Alexander and Vorberger, Jan and Bussmann, Michael and Hoffmann, Nico",Large-Scale Neural Solvers for Partial Differential Equations,2020,10.1007/978-3-030-63393-6_2,https://doi.org/10.1007/978-3-030-63393-6_2,Conference Paper,"Driving Scientific and Engineering Discoveries Through the Convergence of HPC, Big Data and AI","Solving partial differential equations (PDE) is an indispensable part of many branches of science as many processes can be modelled in terms of PDEs. However, recent numerical solvers require manual discretization of the underlying equation as well as sophisticated, tailored code for distributed computing. Scanning the parameters of the underlying model significantly increases the runtime as the simulations have to be cold-started for each parameter configuration. Machine Learning based surrogate models denote promising ways for learning complex relationship among input, parameter and solution. However, recent generative neural networks require lots of training data, i.e. full simulation runs making them costly. In contrast, we examine the applicability of continuous, mesh-free neural solvers for partial differential equations, physics-informed neural networks (PINNs) solely requiring initial/boundary values and validation points for training but no simulation data. The induced curse of dimensionality is approached by learning a domain decomposition that steers the number of neurons per unit volume and significantly improves runtime. Distributed training on large-scale cluster systems also promises great utilization of large quantities of GPUs which we assess by a comprehensive evaluation study. Finally, we discuss the accuracy of GatedPINN with respect to analytical solutions- as well as state-of-the-art numerical solvers, such as spectral solvers.",Springer
"Chertenkov, Vladislav and Burovski, Evgeni and Shchur, Lev",Deep Machine Learning Investigation of Phase Transitions,2022,10.1007/978-3-031-22941-1_29,https://doi.org/10.1007/978-3-031-22941-1_29,Conference Paper,Supercomputing,"We explore the possibilities of using neural networks to study phase transitions. The main question is the level of accuracy which can be achieved for the estimates of the critical point and critical exponents of statistical physics models. We generate data for two spin models in two dimensions for which analytical solutions exist, the Ising model and Baxter-Wu model, which belong to the different universality classes. We applied six neural networks with three different architectures to the data and estimated the critical temperature and the correlation length exponent. We find that the accuracy of estimation does depend on the neural network architecture. The critical exponents of Baxter-Wu model are estimated by the deep machine learning technique for the first time.",Springer
"Pecyna, Tomasz and Kurowski, Krzysztof and R{\'o}zycki, Rafal and Walig{\'o}ra, Grzegorz and W{\k{e}}glarz, Jan",Quantum Variational Algorithms for the Aircraft Deconfliction Problem,2024,10.1007/978-3-031-63778-0_22,https://doi.org/10.1007/978-3-031-63778-0_22,Conference Paper,Computational Science -- ICCS 2024,"Tactical deconfliction problem involves resolving conflicts between aircraft to ensure safety while maintaining efficient trajectories. Several techniques exist to safely adjust aircraft parameters such as speed, heading angle, or flight level, with many relying on mixed-integer linear or nonlinear programming. These techniques, however, often encounter challenges in real-world applications due to computational complexity and scalability issues. This paper proposes a new quantum approach that applies the Quantum Approximate Optimization Algorithm (QAOA) and the Quantum Alternating Operator Ansatz (QAOAnsatz) to address the aircraft deconfliction problem. We present a formula for designing quantum Hamiltonians capable of handling a broad range of discretized maneuvers, with the aim of minimizing changes to original flight schedules while safely resolving conflicts. Our experiments show that a higher number of aircraft poses fewer challenges than a larger number of maneuvers. Additionally, we benchmark the newest IBM quantum processor and show that it successfully solves four out of five instances considered. Finally, we demonstrate that incorporating hard constraints into the mixer Hamiltonian makes QAOAnsatz superior to QAOA. These findings suggest quantum algorithms could be a valuable algorithmic candidate for addressing complex optimization problems in various domains, with implications for enhancing operational efficiency and safety in aviation and other sectors.",Springer
"Werner, Krzysztof and Wereszczy{\'{n}}ski, Kamil and Michalczuk, Agnieszka",Experiment-Driven Quantum Error Reduction,2022,10.1007/978-3-031-08760-8_17,https://doi.org/10.1007/978-3-031-08760-8_17,Conference Paper,Computational Science -- ICCS 2022,"Error correction is wide and well elaborated area of quantum information theory. Those methods, however, demand additional resources, like quantum gates, qubits or time. We have observed, in statistical sense, that the qubit's error in real quantum computers, once calibrated doesn't change much until next one. Then being so, for quantum sampling based computations, one can determine the correction experimentally and use it until the next calibration, without a need of utilize additional resources. In this work we present the method of determining such a correction and applying it to practical quantum-sampling algorithms.",Springer
"Thanos, Dimitrios and Coopmans, Tim and Laarman, Alfons",Fast Equivalence Checking of Quantum Circuits of Clifford Gates,2023,10.1007/978-3-031-45332-8_10,https://doi.org/10.1007/978-3-031-45332-8_10,Conference Paper,Automated Technology for Verification and Analysis,"Checking whether two quantum circuits are equivalent is important for the design and optimization of quantum-computer applications with real-world devices. We consider quantum circuits consisting of Clifford gates, a practically-relevant subset of all quantum operations which is large enough to exhibit quantum features such as entanglement and forms the basis of, for example, quantum-error correction and many quantum-network applications. We present a deterministic algorithm that is based on a folklore mathematical result and demonstrate that it is capable of outperforming previously considered state-of-the-art method. In particular, given two Clifford circuits as sequences of single- and two-qubit Clifford gates, the algorithm checks their equivalence in {\$}{\$}O(n {\backslash}cdot m){\$}{\$}O(n{\textperiodcentered}m)time in the number of qubits n and number of elementary Clifford gates m. Using the performant Stim simulator as backend, our implementation checks equivalence of quantum circuits with 1000 qubits (and a circuit depth of 10.000 gates) in {\$}{\$}{\backslash}sim {\$}{\$}éä½¹åéå¿å¹éï¿½s and circuits with 100.000 qubits (depth 10) in {\$}{\$}{\backslash}sim {\$}{\$}éä½¹åéå¿å¹éï¿½min, outperforming the existing SAT-based and path-integral based approaches by orders of magnitude. This approach shows that the correctness of application-relevant subsets of quantum operations can be verified up to large circuits in practice.",Springer
"Koutavas, Vasileios and Lin, Yu-Yang and Tzevelekos, Nikos",An Operational Semantics for Yul,2025,10.1007/978-3-031-77382-2_19,https://doi.org/10.1007/978-3-031-77382-2_19,Conference Paper,Software Engineering and Formal Methods,"We present a big-step and small-step operational semantics for Yul---the intermediate language used by the Solidity compiler to produce EVM bytecode---in a mathematical notation that is congruous with the literature of programming languages, lends itself to language proofs, and can serve as a precise, widely accessible specification for the language. Our two semantics stay faithful to the original, informal specification of the language but also clarify under-specified cases such as void function calls. Our presentation allows us to prove the equivalence between the two semantics. We also implement the small-step semantics in an interpreter for Yul which avails of optimisations that are provably correct. We have tested the interpreter using tests from the Solidity compiler and our own. We envisage that this work will enable the development of verification and symbolic execution technology directly in Yul, contributing to the Ethereum security ecosystem, as well as aid the development of a provably sound future type system.",Springer
"Cofala, Tim and Elend, Lars and Mirbach, Philip and Prellberg, Jonas and Teusch, Thomas and Kramer, Oliver",Evolutionary Multi-objective Design of SARS-CoV-2 Protease Inhibitor Candidates,2020,10.1007/978-3-030-58115-2_25,https://doi.org/10.1007/978-3-030-58115-2_25,Conference Paper,Parallel Problem Solving from Nature -- PPSN XVI,"Computational drug design based on artificial intelligence is an emerging research area. At the time of writing this paper, the world suffers from an outbreak of the coronavirus SARS-CoV-2. A promising way to stop the virus replication is via protease inhibition. We propose an evolutionary multi-objective algorithm (EMOA) to design potential protease inhibitors for SARS-CoV-2 's main protease. Based on the SELFIES representation the EMOA maximizes the binding of candidate ligands to the protein using the docking tool QuickVina 2, while at the same time taking into account further objectives like drug-likeness or the fulfillment of filter constraints. The experimental part analyzes the evolutionary process and discusses the inhibitor candidates.",Springer
"Liu, Liwei and Xu, Maozhi",Analysis of the Randomness Generation for PoS-Based Blockchains with Verifiable Delay Functions,2020,10.1007/978-981-15-9213-3_51,https://doi.org/10.1007/978-981-15-9213-3_51,Conference Paper,Blockchain and Trustworthy Systems,"With the development of Ethereum 2.0, the proof-of-stake-based blockchain has become more and more popular. Although not commonly deployed in existing blockchains, many PoS or its variants' consensus protocols have been proposed. As the same in many other cryptographic systems, the trustworthy randomness is crucial in PoS-based blockchains such as the selection of the block proposer. Since Boneh proposed the primitive of verifiable delay functions in 2018, it has received intensive attention and been used for many applications, among which the most interesting one is to make an unpredictable, unbiased and unstoppable randomness as the Ethereum Minimal VDF randomness beacon. In this paper, we analyze it in an algorithmic aspect, concentrating on the RANDAO scheme with verifiable delay functions to generate unbiased and public-verifiable randomness for such PoS-based blockchains. We analyze Pietrzak's verifiable delay function and give improvements to the Ethereum 2.0 Randomness beacon based on the benchmark results. We further propose some new ideas to prevent quantum attack and ASICs to break the scheme where verifiable delay functions are used.",Springer
"Phillipson, Frank and Chiscop, Irina",A Quantum Approach for Tactical Capacity Management of Distributed Electricity Generation,2022,10.1007/978-3-031-06668-9_23,https://doi.org/10.1007/978-3-031-06668-9_23,Conference Paper,Innovations for Community Services,"Matching electricity demand and supply by decentralised generators will be very important in the near future, where more and more electricity has to be produced sustainably. Optimisation problems that address this problem often have quadratic objective functions or constraints, due to the quadratic nature of energy loss. Where classical solvers struggle with quadratic, often integer or binary, optimisation problems, quantum computing (inspired) solvers are well equipped for this kind of problems. In this paper, we present such an optimisation problem and the performance of the quantum annealer in solving this problem, in comparison with classical methods and commercial solvers. We show that the hybrid, quantum-classical, solvers provided by D-Wave can outperform classical solvers despite the small-scale of the available quantum hardware.",Springer
"Liu, Qipeng and Zhandry, Mark",On Finding Quantum Multi-collisions,2019,10.1007/978-3-030-17659-4_7,https://doi.org/10.1007/978-3-030-17659-4_7,Conference Paper,Advances in Cryptology -- EUROCRYPT 2019,"A k-collision for a compressing hash function H is a set of k distinct inputs that all map to the same output. In this work, we show that for any constant k, {\$}{\$}{\backslash}varTheta {\backslash}left( N^{\{}{\backslash}frac{\{}1{\}}{\{}2{\}}(1-{\backslash}frac{\{}1{\}}{\{}2^k-1{\}}){\}}{\backslash}right) {\$}{\$}quantum queries are both necessary and sufficient to achieve a k-collision with constant probability. This improves on both the best prior upper bound (Hosoyamada et al., ASIACRYPT 2017) and provides the first non-trivial lower bound, completely resolving the problem.",Springer
"Morie, Maho Wielfrid and Marfisi-Schottman, Iza and Goore, Bi Tra",LGMD: Optimal Lightweight Metadata Model for Indexing Learning Games,2020,10.1007/978-3-030-45183-7_1,https://doi.org/10.1007/978-3-030-45183-7_1,Conference Paper,Smart Applications and Data Analysis,"Learning Games (LGs) have proven to be effective in a large variety of academic fields and for all levels; from kindergarten to professional training. They are therefore very valuable learning resources that should be shared and reused. However, the lack of catalogues that allow teachers to find existing LGs is a significant obstacle to their use in class. It is difficult for catalogues, or any type of search engine, to index LGs because they are poorly referenced. Yet, many researches have proposed elaborate metadata models for LGs. However, all these models are extensions of LOM, a metadata model that is widely used for referencing learning resources, but that contains more than 60 fields, of which more than half are irrelevant to LGs. The gap between these models and the information that game designers are willing to provide is huge. In this paper, we analyze the LG metadata models proposed in previous research to detect the fields that are specific to LGs and the fields that are irrelevant to LGs. We then propose LGMD (Learning Games Metadata Definition), an optimal lightweight metadata model that only contains the important information for LG indexing. LGMD reduces by two thirds the number of fields compared to the previous models. We confronted this model with the information actually provided by LG editors, by analyzing 736 LG page descriptions found online. This study shows that LGMD covers all the information provided by the LG editors.",Springer
"Rombach, Philipp and Keuper, Janis",SmartPred: Unsupervised Hard Disk Failure Detection,2020,10.1007/978-3-030-59851-8_15,https://doi.org/10.1007/978-3-030-59851-8_15,Conference Paper,High Performance Computing,"Due to the rapidly increasing storage consumption worldwide, as well as the expectation of continuous availability of information, the complexity of administration in today's data centers is growing permanently. Integrated techniques for monitoring hard disks can increase the reliability of storage systems. However, these techniques often lack intelligent data analysis to perform predictive maintenance. To solve this problem, machine learning algorithms can be used to detect potential failures in advance and prevent them. In this paper, an unsupervised model for predicting hard disk failures based on Isolation Forest is proposed. Consequently, a method is presented that can deal with the highly imbalanced datasets, as the experiment on the Backblaze benchmark dataset demonstrates.",Springer
"Bootle, Jonathan and Lyubashevsky, Vadim and Seiler, Gregor",Algebraic Techniques for Short(er) Exact Lattice-Based Zero-Knowledge Proofs,2019,10.1007/978-3-030-26948-7_7,https://doi.org/10.1007/978-3-030-26948-7_7,Conference Paper,Advances in Cryptology -- CRYPTO 2019,"A key component of many lattice-based protocols is a zero-knowledge proof of knowledge of a vector {\$}{\$}{\backslash}vec {\{}s{\}}{\$}{\$}with small coefficients satisfying {\$}{\$}A{\backslash}vec {\{}s{\}}={\backslash}vec {\{}u{\}}{\backslash}bmod {\backslash},q{\$}{\$}. While there exist fairly efficient proofs for a relaxed version of this equation which prove the knowledge of {\$}{\$}{\backslash}vec {\{}s{\}}'{\$}{\$}and c satisfying {\$}{\$}A{\backslash}vec {\{}s{\}}'={\backslash}vec {\{}u{\}}c{\$}{\$}where {\$}{\$}{\backslash}Vert {\backslash}vec {\{}s{\}}'{\backslash}Vert {\backslash}gg {\backslash}Vert {\backslash}vec {\{}s{\}}{\backslash}Vert {\$}{\$}and c is some small element in the ring over which the proof is performed, the proofs for the exact version of the equation are considerably less practical. The best such proof technique is an adaptation of Stern's protocol (Crypto '93), for proving knowledge of nearby codewords, to larger moduli. The scheme is a {\$}{\$}{\backslash}varSigma {\$}{\$}-protocol, each of whose iterations has soundness error {\$}{\$}2{\{}/{\}}3{\$}{\$}, and thus requires over 200 repetitions to obtain soundness error of {\$}{\$}2^{\{}-128{\}}{\$}{\$}, which is the main culprit behind the large size of the proofs produced.",Springer
"Ahmed, Abdullah DH. and Hadhoud, Marwa M. A. and Ghoneim, Vidan F.",Automatic Detection of Multiple Sclerosis Using Genomic Expression,2024,10.1007/978-3-031-55729-3_12,https://doi.org/10.1007/978-3-031-55729-3_12,Conference Paper,Advances in Model and Data Engineering in the Digitalization Era,"This study leverages microarray data together with statistical and machine learning techniques to investigate the best set of biomarkers in diagnosing multiple sclerosis (MS). In this work to build an automated system to detect MS two phases are approached. The first phase which is of emphasis is to reduce the dimension of features space and select the most discriminative set of features; biomarkers for MS diagnosis. Principal Component Analysis (PCA) was used as a dimension reduction method. Meanwhile, various feature selection methods were used (Fisher score, chi-square, relief, and MRMR). The second phase of this work is the classification phase, where the output of the first phase were assessed. This phase comprises three different classifiers: LDA, SVM, and KNN. Relief feature selection method achieved 100{\%} accuracy with KNN, using 38 differentially expressed genes (DEGs). Out of this set of these DEGs, Key biomarker genes were identified by studying the gene annotation for all. The genes MIF, PTGES3, CYLD, and JAK1 are realized to be associated with immune and neurological functions. Which is of great relevance to MS.",Springer
"Mandl, Alexander and Barzen, Johanna and Bechtold, Marvin and Leymann, Frank",Minimial-Risk Training Samples for QNN Training from Measurements,2025,10.1007/978-3-031-72578-4_6,https://doi.org/10.1007/978-3-031-72578-4_6,Conference Paper,Service-Oriented Computing,"By using Quantum Neural Networks (QNNs), the principles of quantum computing can be employed to perform supervised learning on quantum computers. Herein, a unitary transformation is trained using sets of quantum input states and their associated outputs. When the exact output states of the transformation are known, recent results show that entanglement can drastically reduce the approximation error of a QNN, without increasing the number of required training samples. However, the exact output states might not be readily available. In certain scenarios, only the measurement outcomes of these quantum states after measurement with an observable are available. Therefore, this work investigates the effect of entangled training samples when training using measurement outcomes. For observables described by one-dimensional projectors, we specify entangled training samples that minimize the approximation error. Furthermore, we validate our findings on a simulator and show that when using entangled training samples, the approximation error depends on the factorization of the entangled samples.",Springer
"Komargodski, Ilan and Naor, Moni and Yogev, Eylon",Collision Resistant Hashing for Paranoids: Dealing with Multiple Collisions,2018,10.1007/978-3-319-78375-8_6,https://doi.org/10.1007/978-3-319-78375-8_6,Conference Paper,Advances in Cryptology -- EUROCRYPT 2018,"A collision resistant hash (CRH) function is one that compresses its input, yet it is hard to find a collision, i.e. a {\$}{\$}x{\_}1 {\backslash}ne x{\_}2{\$}{\$}x1éä½¹åé æ°¶å´¹éçµª.t. {\$}{\$}h(x{\_}1) = h(x{\_}2){\$}{\$}h(x1)=h(x2). Collision resistant hash functions are one of the more useful cryptographic primitives both in theory and in practice and two prominent applications are in signature schemes and succinct zero-knowledge arguments.",Springer
"Hern{\'a}ndez-Hern{\'a}ndez, Mario and Hern{\'a}ndez-Hern{\'a}ndez, Jos{\'e} Luis and Maldonado, Edilia Rodr{\'i}guez and Miranda, Israel Herrera",Modern Code Applied in Stencil in Edge Detection of an Image for Architecture Intel Xeon Phi KNL,2019,10.1007/978-3-030-34989-9_12,https://doi.org/10.1007/978-3-030-34989-9_12,Conference Paper,Technologies and Innovation,"Modern, high-performance computers are built with a combination of heterogeneous resources, including multi-core and many cores processors, large cache, fast memory, mesh communication between large processes bandwidth, as well as high support for Input/Output capabilities. In order to achieve the best hardware results it is necessary to design highly-performance parallel software with faster modern code that could take full advantage of the vast amount of resources of today's modern machines. Code modernization encompasses a wide range of activities that aim to improve the performance of highly parallel software. Code modernization is an issue that is being discussed more and more in the field of parallel software development.",Springer
"Vep{\v{s}}tas, Linas",Purely Symbolic Induction of Structure,2023,10.1007/978-3-031-19907-3_13,https://doi.org/10.1007/978-3-031-19907-3_13,Conference Paper,Artificial General Intelligence,"Techniques honed for the induction of grammar from text corpora can be extended to visual, auditory and other sensory domains, providing a structure for such senses that can be understood in terms of symbols and grammars. This simultaneously solves the classical ``symbol grounding problem'' while also providing a pragmatic approach to developing practical software systems that can articulate the world around us in a symbolic, communicable fashion.",Springer
"Phab, Luca and Louise, St{\'e}phane and Sirdey, Renaud",A First Attempt at Cryptanalyzing a (Toy) Block Cipher by Means of QAOA,2022,10.1007/978-3-031-08760-8_19,https://doi.org/10.1007/978-3-031-08760-8_19,Conference Paper,Computational Science -- ICCS 2022,"The discovery of quantum algorithms that may have an impact on cryptography is one of the main reasons of the rise of quantum computing. Currently, all quantum cryptanalysis techniques are purely theoretical and none of them can be executed on existing or near-term quantum devices. So, this paper investigates the capability of already existing quantum computers to attack a toy block cipher (namely the Heys cipher) using the Quantum Approximate Optimization Algorithm (QAOA). Starting from a known-plaintext key recovery problem, we transform it into an instance of the MAX-SAT problem. Then, we propose two ways to implement it in a QAOA circuit and we try to solve it using publicly available IBM Q Experience quantum computers. The results suggest that the limited number of qubits requires the use of exponential algorithms to achieve the transformation of our problem into a MAX-SAT instance and, despite encouraging simulation results, that the corresponding quantum circuit is too deep to work on nowadays (too-)noisy gate-based quantum computers.",Springer
"Amaral, Marcelo Jaccoud and Borges, V{\^a}nia and Campos, Maria Luiza M.",A Terminological and Semiotic Review of the Digital Object Concept,2023,10.1007/978-3-031-47262-6_5,https://doi.org/10.1007/978-3-031-47262-6_5,Conference Paper,Conceptual Modeling,"The expression ``digital object'' is used in different initiatives dealing with the effects of exchanging and reusing information in scenarios with multiple standards and sources. However, born in different communities with distinct requirements, models, and vocabularies, the definitions of what is a digital object are usually incompatible, aggravating the interoperability problem they are trying to solve. As a contribution, this article reviews the historical and contemporary concepts of object, eliciting similarities and distinctions to result in a better understanding of the main framework proposals. Furthermore, we seek help in the Peircean concept of the semiotic sign to better understand how information flows in digital artifacts and media, and which are the relevant roles played by different agents, either human or not. We argue that, because computers can only deal with digital representations, it is irrelevant to the architecture of digital objects whether their data refers to real or virtual entities. Finally, we claim that a multipurpose definition should be broad enough to embrace new contexts and interpreters that cannot be prescribed a priori, in contrast to the usually rigid schemas found in object-oriented programming environments and relational database management systems.",Springer
"Escanez-Exposito, Daniel and Correa-Marichal, Javier and Caballero-Gil, Pino",Qubit: The Game. Teaching Quantum Computing through a Game-Based Approach,2023,10.1007/978-3-031-36030-5_9,https://doi.org/10.1007/978-3-031-36030-5_9,Conference Paper,Computational Science -- ICCS 2023,"Quantum computing is a promising and rapidly growing interdisciplinary field that attracts researchers from science and engineering. Based on the hypothesis that traditional teaching is insufficient to prepare people for their introduction to this field, this paper presents Qubit: The Game, an innovative board game to promote both the motivation to learn quantum computing and the understanding of several essential concepts of that field. The reasons for the choice of game type, design and mechanics, and the followed methodology are described in detail here. This paper also includes a preliminary study to determine the effect of the proposed game on the perception, interest and basic knowledge of quantum computing in a group of high school students. The study findings reveal that the designed game is a powerful tool to foster interest and teach essential concepts of a subject as difficult as quantum computing, which can be of great help in introducing more complex concepts.",Springer
"Puram, Varun and Karuppasamy, Krishnageetha and Thomas, Johnson P.",Optimizing Quantum Circuits Using Algebraic Expressions,2024,10.1007/978-3-031-63778-0_19,https://doi.org/10.1007/978-3-031-63778-0_19,Conference Paper,Computational Science -- ICCS 2024,"Optimizing quantum circuits and reducing errors plays a crucial role in quantum circuit computation. Every quantum circuit can be represented using algebraic expressions, we propose an approach that directly derives algebraic expressions, ensuring that parallelism is maximized, that is, the number of circuit slices is minimized, and secondly, the computation required for obtaining the desired algebraic expression is reduced. This results in quantum circuits that are more efficient in space and computation time. The simplification of algebraic expressions offers methods to streamline optimized circuits, reducing the number of gates and depth. This reduction is aimed at minimizing the overall complexity of the expressions, resulting in more efficient quantum computations. In this paper, we also show through simulations that the optimized circuit will have less errors when compared to original circuits.",Springer
"Kuppuswamy, Prakash and Al-Maliki, Sayeed Q. Al-Khalidi and John, Rajan and Mani, Mohan",A Novel Symmetric Key Based Authentication Scheme that Saves Energy for Edge Devices of the Internet of Things,2025,10.1007/978-3-031-75170-7_23,https://doi.org/10.1007/978-3-031-75170-7_23,Conference Paper,"Computing Science, Communication and Security","In today's digitally connected world, edge devices such as smartphones, tablets, wearables, and IoT devices have become an essential part of our day-to-day life. These devices facilitate seamless connectivity and enable us to access information and services at our fingertips. However, this convenience comes at a cost - the potential compromise of sensitive data due to security vulnerabilities. Edge device security has become a significant concern, and one of the solutions to address these concerns is the utilization of cryptography algorithms. With the rapid proliferation of edge devices in today's interconnected world, the basic for strong and efficient safety mechanisms has become paramount. One such mechanism is the symmetric key algorithm, which plays a vital role in securing edge devices and safeguarding critical data. A device-based authentication algorithm that saves energy and enables secure communication within the edge devices is crucial for verifying device identity and ensuring device security. This article explores a new energy-saving authentication protocol based on integers and modulo 37 called SSK (simple symmetric key algorithm). This new authentication protocol is easy to implement and is particularly suitable for edge devices on the Internet of Things that require energy savings and potential security. Additionally, this article discusses the implementation of SSK algorithms, edge device security, their functionality, and potential use cases.",Springer
"Pfau, Johannes and Figuli, Shalina Percy Delicia and B{\""a}hr, Steffen and Becker, J{\""u}rgen",Reconfigurable FPGA-Based Channelization Using Polyphase Filter Banks for Quantum Computing Systems,2018,10.1007/978-3-319-78890-6_49,https://doi.org/10.1007/978-3-319-78890-6_49,Conference Paper,"Applied Reconfigurable Computing. Architectures, Tools, and Applications","Recently proposed quantum systems use frequency multiplexed qubit technology for readout electronics rather than analog circuitry, to increase cost effectiveness of the system. In order to restore individual channels for further processing, these systems require a demultiplexing or channelization approach which can process high data rates with low latency and uses few hardware resources. In this paper, a low latency, adaptable, FPGA-based channelizer using the Polyphase Filter Bank (PFB) signal processing algorithm is presented. As only a single prototype lowpass filter needs to be designed to process all channels, PFBs can be easily adapted to different requirements and further allow for simplified filter design. Due to reutilization of the same filter for each channel they also reduce hardware resource utilization when compared to the traditional Digital Down Conversion approach. The realized system architecture is extensively generic, allowing the user to select from different numbers of channels, sample bit widths and throughput specifications. For a test setup using a 28 coefficient transpose filter and 4 output channels, the proposed architecture yields a throughput of 12.8 Gb/s with a latency of 7 clock cycles.",Springer
"Tu{\v{s}}il, Jan and Obdr{\v{z}}{\'a}lek, Jan",Minuska: Towards a Formally Verified Programming Language Framework,2025,10.1007/978-3-031-77382-2_12,https://doi.org/10.1007/978-3-031-77382-2_12,Conference Paper,Software Engineering and Formal Methods,"Programming language frameworks allow us to generate language tools (e.g., interpreters) just from a formal description of the syntax and semantics of a programming language. As these frameworks tend to be quite complex, an issue arises whether we can trust the generated tools. To address this issue, we introduce a practical formal programming language framework called Minuska, which always generates a provably correct interpreter given a valid language definition. This is achieved by (1) defining a language MinusLang for expressing programming language definitions and giving it formal semantics and (2) using the Coq proof assistant to implement an interpreter parametric in a MinusLang definition and to prove it correct. Minuska provides strong correctness guarantees and can support non-trivial languages while performing well.",Springer
"Takhar, Gourav and Roy, Subhajit",SR-SFLL: Structurally Robust Stripped Functionality Logic Locking,2023,10.1007/978-3-031-37709-9_10,https://doi.org/10.1007/978-3-031-37709-9_10,Conference Paper,Computer Aided Verification,"Logic locking was designed to be a formidable barrier to IP piracy: given a logic design, logic locking modifies the logic design such that the circuit operates correctly only if operated with the ``correct'' secret key. However, strong attacks (like SAT-based attacks) soon exposed the weakness of this defense. Stripped functionality logic locking (SFLL) was recently proposed as a strong variant of logic locking. SFLL was designed to be resilient against SAT attacks, which was the bane of conventional logic locking techniques. However, all SFLL-protected designs share certain ``circuit patterns'' that expose them to new attacks that employ structural analysis of the locked circuits.",Springer
"Chakraborty, Supratik and Shrotri, Aditya A. and Vardi, Moshe Y.",On Symbolic Approaches for Computing the Matrix Permanent,2019,10.1007/978-3-030-30048-7_5,https://doi.org/10.1007/978-3-030-30048-7_5,Conference Paper,Principles and Practice of Constraint Programming,"Counting the number of perfect matchings in bipartite graphs, or equivalently computing the permanent of 0-1 matrices, is an important combinatorial problem that has been extensively studied by theoreticians and practitioners alike. The permanent is {\#}P-Complete; hence it is unlikely that a polynomial-time algorithm exists for the problem. Researchers have therefore focused on finding tractable subclasses of matrices for permanent computation. One such subclass that has received much attention is that of sparse matrices i.e. matrices with few entries set to 1, the rest being 0. For this subclass, improved theoretical upper bounds and practically efficient algorithms have been developed. In this paper, we ask whether it is possible to go beyond sparse matrices in our quest for developing scalable techniques for the permanent, and answer this question affirmatively. Our key insight is to represent permanent computation symbolically using Algebraic Decision Diagrams (ADDs). ADD-based techniques naturally use dynamic programming, and hence avoid redundant computation through memoization. This permits exploiting the hidden structure in a large class of matrices that have so far remained beyond the reach of permanent computation techniques. The availability of sophisticated libraries implementing ADDs also makes the task of engineering practical solutions relatively straightforward. While a complete characterization of matrices admitting a compact ADD representation remains open, we provide strong experimental evidence of the effectiveness of our approach for computing the permanent, not just for sparse matrices, but also for dense matrices and for matrices with ``similar'' rows.",Springer
"Abdul Rahman, Salahuddin and Clausen, Henrik Glavind and Karabacak, {\""O}zkan and Wisniewski, Rafal",Adaptive Sampling Noise Mitigation Technique for Feedback-Based Quantum Algorithms,2024,10.1007/978-3-031-63778-0_23,https://doi.org/10.1007/978-3-031-63778-0_23,Conference Paper,Computational Science -- ICCS 2024,"Inspired by Lyapunov control techniques for quantum systems, feedback-based quantum algorithms have recently been proposed as alternatives to variational quantum algorithms for solving quadratic unconstrained binary optimization problems. These algorithms update the circuit parameters layer-wise through feedback from measuring the qubits in the previous layer to estimate expectations of certain observables. Therefore, the number of samples directly affects the algorithm's performance and may even cause divergence. In this work, we propose an adaptive technique to mitigate the sampling noise by adopting a switching control law in the design of the feedback-based algorithm. The proposed technique can lead to better performance and convergence properties. We show the robustness of our technique against sampling noise through an application for the maximum clique problem.",Springer
"Kwant, Robin and Lange, Tanja and Thissen, Kimberley",Lattice Klepto,2018,10.1007/978-3-319-72565-9_17,https://doi.org/10.1007/978-3-319-72565-9_17,Conference Paper,Selected Areas in Cryptography -- SAC 2017,This paper studies ways to backdoor lattice-based systems following Young and Yung's work on backdooring RSA and discrete-log based systems. For the NTRU encryption scheme we show how to build a backdoor and to change the system so that each ciphertext leaks information about the plaintext to the owner of the backdoor. For signature schemes the backdoor leaks information about the signing key to the backdoor owner.,Springer
"Kabi{\'{c}}, Marko and Pintarelli, Simon and Kozhevnikov, Anton and VandeVondele, Joost",COSTA: Communication-Optimal Shuffle and Transpose Algorithm with Process Relabeling,2021,10.1007/978-3-030-78713-4_12,https://doi.org/10.1007/978-3-030-78713-4_12,Conference Paper,High Performance Computing,"Communication-avoiding algorithms for Linear Algebra have become increasingly popular, in particular for distributed memory architectures. In practice, these algorithms assume that the data is already distributed in a specific way, thus making data reshuffling a key to use them. For performance reasons, a straightforward all-to-all exchange must be avoided.",Springer
"Godin, Vladimir V. and Terekhova, Anna E. and Kalamagina, Sofia V.",New Areas of Blockchain Technology Applications During the COVID-19 Pandemic,2022,10.1007/978-3-030-95494-9_16,https://doi.org/10.1007/978-3-030-95494-9_16,Conference Paper,Information Systems and Design,"The article is devoted to the analysis of new directions of application of blockchain technology that have emerged in the conditions of the Covid-19 pandemic, generalization of existing experience in using blockchain and definition of tasks for blockchain technology development. The paper analyzes the properties of blockchain technology, manifested in the created systems, which can solve several management problems in the process of combating the Covid-19 pandemic. The article describes the Covid-19 pandemic fight and their possible actions. The paper provides analysis and systematization of new areas of blockchain application, such as tracking contact with infected people, verification of vaccine authenticity, maintaining of the clinical trial data integrity, identifying counterfeit medicines and personal protective equipment, identifying foci of infection. The authors describe examples of specific solutions, showed that the blockchain technology can play an innovative role in solving a few problems that appeared during the pandemic. The existing limitations are revealed both in the blockchain technology itself and in the conditions of its application, which do not allow to fully realize the full potential of the technology. The description of new areas of application of blockchain technology is important both for the organizers of the COVID-19 pandemic response, and for researchers and developers of systems using blockchain technology.",Springer
"Ruszczak, Bogdan and Wijata, Agata M. and Nalepa, Jakub",Estimating Chlorophyll Content from Hyperspectral Data Using Gradient Features,2023,10.1007/978-3-031-36021-3_18,https://doi.org/10.1007/978-3-031-36021-3_18,Conference Paper,Computational Science -- ICCS 2023,"Non-invasive estimation of chlorophyll content in plants plays an important role in precision agriculture. This task may be tackled using hyperspectral imaging that acquires numerous narrow bands of the electromagnetic spectrum, which may reflect subtle features of the plant, and inherently offers spatial scalability. Such imagery is, however, high-dimensional, therefore it is challenging to transfer from the imaging device, store and investigate. We propose a machine learning pipeline for estimating chlorophyll content from hyperspectral data. It benefits from the Savitzky-Golay filtering to smooth the (potentially noisy) spectral curves, and from gradient-based features extracted from such a smoothed signal. The experiments revealed that our approach significantly outperforms the state of the art according to the widely-established estimation quality metrics obtained for four chlorophyll-related parameters.",Springer
"Krasnopolsky, Boris and Medvedev, Alexey",Investigating Performance of the XAMG Library for Solving Linear Systems with Multiple Right-Hand Sides,2021,10.1007/978-3-030-92864-3_26,https://doi.org/10.1007/978-3-030-92864-3_26,Conference Paper,Supercomputing,"The paper presents capabilities and implementation details for the newly developed XAMG library for solving systems of linear algebraic equations with multiple right-hand sides. The underlying code design principles and the basic data objects implemented in the library are described. Several specific optimizations providing significant speedup compared to alternative state of the art open-source libraries are highlighted. A great attention is paid to the XAMG library thorough performance investigation. The step-by-step evaluation, performed for two compute systems, compares the single right-hand side calculations against hypre, the performance gain due to simultaneous solution of system with multiple right-hand sides, the effect of mixed-precision calculations, and the advantages of the hierarchical MPI+POSIX shared memory hybrid programming model. The obtained results demonstrate more than twofold speedup for the XAMG library against hypre for the equal numerical method configurations. The solution of systems with multiple right-hand sides provides 2--2.5 times speedup compared to multiple solutions of systems with a single right-hand side.",Springer
"Soloviev, Vladimir and Moiseienko, Natalia and Tarasova, Olena",Complexity Theory and Dynamic Characteristics of Cognitive Processes,2020,10.1007/978-3-030-39459-2_11,https://doi.org/10.1007/978-3-030-39459-2_11,Conference Paper,"Information and Communication Technologies in Education, Research, and Industrial Applications","The features of modeling of the cognitive component of social and humanitarian systems have been considered. An example of using entropy multiscale, multifractal, recurrence and network complexity measures has shown that these and other synergetic models and methods allow us to correctly describe the quantitative differences of cognitive systems. The cognitive process is proposed to be regarded as a separate implementation of an individual cognitive trajectory, which can be represented as a time series and to investigate its static and dynamic features by the methods of complexity theory. Prognostic possibilities of the complex systems theory will allow to correct the corresponding pedagogical technologies. It has been proposed to track and quantitatively describe the cognitive trajectory using specially transformed computer games which can be used to test the processual characteristics of thinking.",Springer
"Sabry, Amr and Valiron, Beno{\^i}t and Vizzotto, Juliana Kaizer",From Symmetric Pattern-Matching to Quantum Control,2018,10.1007/978-3-319-89366-2_19,https://doi.org/10.1007/978-3-319-89366-2_19,Conference Paper,Foundations of Software Science and Computation Structures,"One perspective on quantum algorithms is that they are classical algorithms having access to a special kind of memory with exotic properties. This perspective suggests that, even in the case of quantum algorithms, the control flow notions of sequencing, conditionals, loops, and recursion are entirely classical. There is however, another notion of control flow, that is itself quantum. The notion of quantum conditional expression is reasonably well-understood: the execution of the two expressions becomes itself a superposition of executions. The quantum counterpart of loops and recursion is however not believed to be meaningful in its most general form.",Springer
"Yifeng, Chen and Sanders, J. W.",A Modal Approach to Consciousness of Agents,2022,10.1007/978-3-031-19759-8_9,https://doi.org/10.1007/978-3-031-19759-8_9,Conference Paper,"Leveraging Applications of Formal Methods, Verification and Validation. Adaptation and Learning","An agent's awareness is modelled as a modal operator in such a way that awareness can be iterated and consciousness formalised as awareness of awareness. Agents are not necessarily human and may a priori be animals, organisations or software, in which setting awareness is expected to exist in degrees and so is modelled with nonnegative reals rather than just Booleans. The formalism thus expresses the degree to which an agent exhibits awareness (and so consciousness).",Springer
"P{\""u}llen, Dominik and Anagnostopoulos, Nikolaos and Arul, Tolga and Katzenbeisser, Stefan",Safety Meets Security: Using IEC 62443 for a Highly Automated Road Vehicle,2020,10.1007/978-3-030-54549-9_22,https://doi.org/10.1007/978-3-030-54549-9_22,Conference Paper,"Computer Safety, Reliability, and Security","In this work, we conduct and discuss a consensus-based risk analysis for a novel architecture of a driverless and electric prototype vehicle. While well-established safety standards like ISO 26262 provide frameworks to systematically assess risks of hazardous operational situations, the automotive security field has emerged only in the last years. Today, SAE J3061 provides recommendations and high-level guiding principles of how to incorporate security into vehicle systems. ISO/SAE 21434 is a novel automotive security standard, which, however, is still under development. Therefore, we treat the aforementioned architecture as a single Industrial Automation and Control System (IACS) and provide an implementation of the IEC 62443 series. We collaboratively identify threats in a three-round process and define a scoring scheme for automotive risks. As a result, we obtain a tailored bundle of compensating security mechanisms. Based on our work, we suggest improvements for future automotive security standards when it comes to the co-engineering of safety and security.",Springer
"Bauer, Balthazar and Farshim, Pooya and Mazaheri, Sogol",Combiners for Backdoored Random Oracles,2018,10.1007/978-3-319-96881-0_10,https://doi.org/10.1007/978-3-319-96881-0_10,Conference Paper,Advances in Cryptology -- CRYPTO 2018,"We formulate and study the security of cryptographic hash functions in the backdoored random-oracle (BRO) model, whereby a big brother designs a ``good'' hash function, but can also see arbitrary functions of its table via backdoor capabilities. This model captures intentional (and unintentional) weaknesses due to the existence of collision-finding or inversion algorithms, but goes well beyond them by allowing, for example, to search for structured preimages. The latter can easily break constructions that are secure under random inversions.",Springer
"Tithi, Jesmin Jahan and Checconi, Fabio and Doerfler, Douglas and Petrini, Fabrizio",SU3{\_}Bench on a Programmable Integrated Unified Memory Architecture (PIUMA) and How that Differs from Standard NUMA CPUs,2022,10.1007/978-3-031-07312-0_4,https://doi.org/10.1007/978-3-031-07312-0_4,Conference Paper,High Performance Computing,SU3{\_}Bench explores performance portability across multiple programming models using a simple but nontrivial mathematical kernel. This kernel has been derived from the (LQCD) code used in applications such as Hadron Physics and hence should be of interest to the scientific community.,Springer
"Rodr{\'i}guez-Farr{\'e}s, Pol and Ballester, Rocco and Ans{\'o}tegui, Carlos and Levy, Jordi and Cerquides, Jesus",Implementing 3-SAT Gadgets for Quantum Annealers with Random Instances,2024,10.1007/978-3-031-63778-0_20,https://doi.org/10.1007/978-3-031-63778-0_20,Conference Paper,Computational Science -- ICCS 2024,"The Maximum Boolean Satisfiability Problem (also known as the Max-SAT problem) is the problem of determining the maximum number of disjunctive clauses that can be satisfied (i.e., made true) by an assignment of truth values to the formula's variables. This is a generalization of the well-known Boolean Satisfiability Problem (also known as the SAT problem), the first problem that was proven to be NP-complete. With the proliferation of quantum computing, a current approach to tackle this optimization problem is Quantum Annealing (QA). In this work, we compare several gadgets that translate 3-SAT problems into Quadratic Unconstrained Binary Optimization (QUBO) problems to be able to solve them in a quantum annealer. We show the performance superiority of the not-yet-considered gadgets in comparison to state-of-the-art approaches when solving random instances in D-Wave's quantum annealer.",Springer
"Mukhamedieva, D. T. and Sobirov, R. A. and Turgunova, N. M. and Samijonov, B. N.",Quantum Fourier Transform in Image Processing,2024,10.1007/978-3-031-60318-1_12,https://doi.org/10.1007/978-3-031-60318-1_12,Conference Paper,Information Technologies and Intelligent Decision Making Systems,"This paper presents an approach to apply quantum Fourier transform (QFT) to image processing using quantum computing. The use of quantum computing for image analysis and processing is becoming increasingly relevant in modern science and technology. A quantum QFT circuit is presented, implemented using the Qiskit framework, which is a tool for programming quantum computers. The paper presents the basic steps of QFT and their application to a state vector representing the pixel intensities of an image. The influence of quantum transformation on the image structure is studied and the results are presented in the form of graphs and visualizations. In addition, we have introduced QFT quantum circuit inference capabilities for a more visual representation of the algorithm. The results highlight the potential of quantum computing in the field of image processing and open new prospects for the use of quantum technologies in the field of computer vision.",Springer
"Fr{\""a}nzle, Martin and Hein, Andreas",Safer Than Perception: Increasing Resilience of Automated Vehicles Against Misperception,2025,10.1007/978-3-031-73741-1_25,https://doi.org/10.1007/978-3-031-73741-1_25,Conference Paper,Bridging the Gap Between AI and Reality,"Autonomous vehicles (AV) rely on environmental perception to take manoeuvre decisions. Safety assurance for AV thus hinges on achieving confidence in all percepts that are safe-guarding critical manoeuvres. As the safety targets for such critical manoeuvres are considerably higher than the statistical figures for the reliability of at least current learning-enabled classification algorithms within the environmental perception, we need means for assuring that the overall system is ``safer than perception'' in that the frequency of erratically adopting a critical manoeuvre is considerably lower than the frequency of individual misclassifications. We present a methodology for constructively generating reformulations of guard conditions that are more resilient to misperception than the original condition. The synthesized, rephrased guard conditions reconcile a given safety target, i.e. a given a societally accepted upper bound on erratically activating a critical manoeuvre due to a false positive in guard evaluation, with maximal availability, i.e. maximal true positive rate. By synthesizing a resilient rephrasing of the guard condition, the constructive setting presented herein complements the analytical setting from a previous companion paper [6], which merely analysed a given condition for its safety under uncertain perception.",Springer
"Penagonda, Adithya and Bhanusree, Yalamanchili",Enhanced Simulation of Collision Events Using Quantum GANs for Jet Images Generation,2024,10.1007/978-3-031-64067-4_11,https://doi.org/10.1007/978-3-031-64067-4_11,Conference Paper,Advanced Network Technologies and Intelligent Computing,"Generative Adversarial Networks (GANs) have revolutionized unsupervised machine learning with their ability in generating identical data. Their applications range from arts to sophisticated systems such as High Energy Physics (HEP). Jets---particle showers produced by high-energy collisions provide a window into the behavior of gluons and quarks, the fundamental constituents of matter, in the domain of HEP. However, due to the huge amounts of data produced by experiments like the Large Hadron Collider (LHC), typical GANs have computational and scalability issues. Enter Quantum Generative Adversarial Networks (QGANs), which harness the power of quantum physics to promise faster training times while consuming less resources. This research digs into the complexities of QGANs and their use in jet reconstruction in HEP. This study optimizes the quality of generated images by utilizing a Quantum GAN architecture with quantum fidelity measurements. QGANs not only provides a supplement to established simulation tools like Pythia, but it also points at potential nuances and patterns that traditional simulations may ignore. Our quantum simulation results show encouraging results in jet image production and illustrate the promise of quantum techniques in interpreting the huge data landscapes of HEP.",Springer
"Manohara, H. T. and Harish, B. P.",Geometric Programming (GP) Based Processor Energy Minimization Model for DVS Enabled Real-Time Task Set System,2021,10.1007/978-3-030-91244-4_35,https://doi.org/10.1007/978-3-030-91244-4_35,Conference Paper,Data Science and Computational Intelligence,"An analytical processor-level energy model to overcome power walls in communication and computation-intensive mobile applications is proposed. In real-time systems, when peak processing power is not required, judicious selection of supply voltage for energy-efficient operation is critical to address the power-performance tradeoff. The processor is operated at a lower frequency than maximum by dynamically varying its supply voltage to reduce energy. The proposed energy model, driven by a novel control variable called Task Utilization Factor (TUF), generates optimized supply voltage dynamically, within the pre-specified supply volt-age range, for each task of real-time periodic/aperiodic mixed task sets. The Geometric Programming based energy minimization model is proposed, over a range of maximum frequency, on randomly varying mixed task set to derive an optimized operating voltage. Simulation results on synthetic task data show that energy savings of 30{\%} to 38{\%} for randomly generated aperiodic task sets and 19{\%} to 28{\%} for randomly generated mixed task sets.",Springer
"Guti{\'e}rrez Hermosillo Muriedas, Juan Pedro and Fl{\""u}gel, Katharina and Debus, Charlotte and Obermaier, Holger and Streit, Achim and G{\""o}tz, Markus",perun: Benchmarking Energy Consumption of High-Performance Computing Applications,2023,10.1007/978-3-031-39698-4_2,https://doi.org/10.1007/978-3-031-39698-4_2,Conference Paper,Euro-Par 2023: Parallel Processing,"Looking closely at the Top500 list of high-performance computers (HPC) in the world, it becomes clear that computing power is not the only number that has been growing in the last three decades. The amount of power required to operate such massive computing machines has been steadily increasing, earning HPC users a higher than usual carbon footprint. While the problem is well known in academia, the exact energy requirements of hardware, software and how to optimize it are hard to quantify. To tackle this issue, we need tools to understand the software and its relationship with power consumption in today's high performance computers. With that in mind, we present perun, a Python package and command line interface to measure energy consumption based on hardware performance counters and selected physical measurement sensors. This enables accurate energy measurements on various scales of computing, from a single laptop to an MPI-distributed HPC application. We include an analysis of the discrepancies between these sensor readings and hardware performance counters, with particular focus on the power draw of the usually overlooked non-compute components such as memory. One of our major insights is their significant share of the total energy consumption. We have equally analyzed the runtime and energy overhead perun generates when monitoring common HPC applications, and found it to be minimal. Finally, an analysis on the accuracy of different measuring methodologies when applied at large scales is presented.",Springer
"Aghazadeh Ardebili, Ali and Longo, Antonella and Ficarella, Antonio and Khalil, Adem and Khalil, Sabri",Exploring Synthetic Noise Algorithms for Real-World Similar Data Generation: A Case Study on Digitally Twining Hybrid Turbo-Shaft Engines in UAV/UAS Applications,2024,10.1007/978-3-031-49333-1_7,https://doi.org/10.1007/978-3-031-49333-1_7,Conference Paper,Model and Data Engineering,"An emerging technology for automating Unmanned aircraft is digitally twining the system, and employing AI-based data-driven solutions. Digital Twin (DT) enables real-time information flow between physical assets and a virtual model, creating a fully autonomous and resilient transport system. A key challenge in DT as a Service (DTaaS) is the lack of Real-world data for training algorithms and verifying DT functionality. This article focuses on data augmentation using Real-world Similar Synthetic Data Generation (RSSDG) to facilitate DT development in the absence of training data for Machine Learning (ML) algorithms. The main focus is on the noise generation step of the RSSDG for a common Hybrid turbo-shaft engine because there is a significant gap in transforming synthetic data to Real-world similar data. Therefore we generate noise through 6 different noise generation algorithms before Rolling Linear Regression and Filtering the noisy predictions through Kalman Filter. The primary objective is to investigate the sensitivity of the RSSDG process concerning the algorithm that is used for noise generation. The study's results support the potential capacity of RSSDG for digitally twining the engine in a Real-world operational lifecycle. However, noise generation through Weibull and Von Mises distribution showed low efficiency in general. In the case of Normal Distribution, for both thermal and hybrid models, the corresponding DT model has shown high efficiency in noise filtration and a certain amount of predictions with a lower error rate on all engine parameters, except the engine torque; however, Students-T, Laplace, and log-normal show better performance for engine torque RSSDG.",Springer
"Pillai, Sanjaikanth E Vadakkethil Somanathan and Nadella, Geeta Sandeep",Exploring Network Privacy Measures in Mobile Networks,2025,10.1007/978-3-031-71729-1_16,https://doi.org/10.1007/978-3-031-71729-1_16,Conference Paper,"Sustainable Development through Machine Learning, AI and IoT","This research paper investigates the intricate landscape of mobile network privacy, analyzing the efficacy of diverse measures in safeguarding user information. Through quantitative assessments, this study unveils compelling insights: the interception rate of data packets averaged at 342 per hour, with only 12.5{\%} of encrypted traffic successfully decrypted. Sensitivity analysis revealed financial data as the most accessed (45{\%}), followed by personal (30{\%}) and location-based information (25{\%}). Evaluating the effectiveness of privacy measures, encryption demonstrated an 87.3{\%} success rate, while authentication and anomaly detection achieved rates of 95.8{\%} and 91.2{\%}, respectively. Additionally, user perceptions portrayed a significant concern for data privacy (78{\%}) despite 40{\%} being willing to trade data for enhanced services. These quantitative revelations underscore the challenges and necessities in fortifying mobile network privacy amid evolving technological landscapes.",Springer
"Pinkas, Benny and Rosulek, Mike and Trieu, Ni and Yanai, Avishay",SpOT-Light: Lightweight Private Set Intersection from Sparse OT Extension,2019,10.1007/978-3-030-26954-8_13,https://doi.org/10.1007/978-3-030-26954-8_13,Conference Paper,Advances in Cryptology -- CRYPTO 2019,"We describe a novel approach for two-party private set intersection (PSI) with semi-honest security. Compared to existing PSI protocols, ours has a more favorable balance between communication and computation. Specifically, our protocol has the lowest monetary cost of any known PSI protocol, when run over the Internet using cloud-based computing services (taking into account current rates for CPU + data). On slow networks (e.g., 10 Mbps) our protocol is actually the fastest.",Springer
"Quertier, Tony and Barru{\'e}, Gr{\'e}goire",Towards an In-Depth Detection of Malware Using Multi-QCNN,2024,10.1007/978-3-031-63778-0_29,https://doi.org/10.1007/978-3-031-63778-0_29,Conference Paper,Computational Science -- ICCS 2024,"Malware detection is an important topic of current cybersecurity, and Machine Learning appears to be one of the main considered solutions even if certain problems to generalize to new malware remain. In the aim of exploring the potential of quantum machine learning on this domain using only a few qubits, we implement a new preprocessing of our dataset using Grayscale method, and we couple it with a model composed of five quantum convolutional networks and a scoring function. We get an increase of around 20{\%} of our results, both on the accuracy of the test and its F1-score.",Springer
"Boltuc, Piotr (Peter)",Moral Space for Paraconsistent AGI,2023,10.1007/978-3-031-19907-3_16,https://doi.org/10.1007/978-3-031-19907-3_16,Conference Paper,Artificial General Intelligence,"Ben Goertzel argues that humans operate within paraconsistent ethics. There are two arguments: 1. Moral para-consistency viewed primarily as resulting from deeply rooted tensions between individuation and self-transcendence (or autopoiesis versus evolutionary fitness). 2. Paraconsistency due to human cognitive limitations (we would need massively stronger cognitive functions to handle our lives consistently). This is directly relevant for AI since advanced humanoid AIs and AGIs should follow paraconsistent norms for easier human-AI interactions. This is also indirectly relevant, in a broader ontological framework, where Goertzel analyzes paraconsistent foundations for quantum probability, programming, and concept formation. Paraconsistence in these domains does not seem to result from weakness of human cognitive functions, manifestly in quantum physics. Those paraconsistencies seem relationally veridical. Yet, in his explanations of ontological paraconsistency, Goertzel 2021a follows Weber in focusing on sorties kind of problems; this creates an impression that the issues of fuzziness are the gist of Goertzel's paraconsistent approach to AI. Yet, this is more of a heuristic start for Goertzel. Paraconsistency is not always at the boundaries, but at the core of nimble complex systems. We argue that, at least in ethics, paraconsistency is primarily based on alternative objectives or sources of value (following Goertzel's argument 1; also Ross, Haidt, Dancy, Sen); ethical problems based upon vagueness in boundary conditions, though important and interesting, are less central to the metaethical dimension of paraconsistency, and therefore to the logical make-up of future AIs.",Springer
"Stankova, E. N. and Dyachenko, N. V. and Tibilova, G. S.",Virtual Laboratories: Prospects for the Development of Techniques and Methods of Work,2018,10.1007/978-3-319-95171-3_1,https://doi.org/10.1007/978-3-319-95171-3_1,Conference Paper,Computational Science and Its Applications -- ICCSA 2018,"The possibilities of using virtual laboratories in the process of teaching physics at a university are discussed. Various scenarios for conducting classes in a virtual laboratory for both undergraduate students and masters are offered. The ways of expanding the subject and technical capabilities of the virtual laboratory are considered, methodical recommendations and their possible technical solutions are suggested.",Springer
"N{\""u}{\ss}lein, Jonas and Zielinski, Sebastian and Gabor, Thomas and Linnhoff-Popien, Claudia and Feld, Sebastian",Solving (Max) 3-SAT via Quadratic Unconstrained Binary Optimization,2023,10.1007/978-3-031-36030-5_3,https://doi.org/10.1007/978-3-031-36030-5_3,Conference Paper,Computational Science -- ICCS 2023,"We introduce a novel approach to translate arbitrary 3-sat instances to Quadratic Unconstrained Binary Optimization (qubo) as they are used by quantum annealing (QA) or the quantum approximate optimization algorithm (QAOA). Our approach requires fewer couplings and fewer physical qubits than the current state-of-the-art, which results in higher solution quality. We verified the practical applicability of the approach by testing it on a D-Wave quantum annealer.",Springer
"Aggarwal, Divesh and Chung, Kai-Min and Lin, Han-Hsuan and Vidick, Thomas",A Quantum-Proof Non-malleable Extractor,2019,10.1007/978-3-030-17656-3_16,https://doi.org/10.1007/978-3-030-17656-3_16,Conference Paper,Advances in Cryptology -- EUROCRYPT 2019,"In privacy amplification, two mutually trusted parties aim to amplify the secrecy of an initial shared secret X in order to establish a shared private key K by exchanging messages over an insecure communication channel. If the channel is authenticated the task can be solved in a single round of communication using a strong randomness extractor; choosing a quantum-proof extractor allows one to establish security against quantum adversaries.",Springer
"Tsabary, Rotem",Fully Secure Attribute-Based Encryption for t-CNF from LWE,2019,10.1007/978-3-030-26948-7_3,https://doi.org/10.1007/978-3-030-26948-7_3,Conference Paper,Advances in Cryptology -- CRYPTO 2019,"Attribute-based Encryption (ABE), first introduced by [SW05, GPSW06], is a public key encryption system that can support multiple users with varying decryption permissions. One of the main properties of such schemes is the supported function class of policies. While there are fully secure constructions from bilinear maps for a fairly large class of policies, the situation with lattice-based constructions is less satisfactory and many efforts were made to close this gap. Prior to this work the only known fully secure lattice construction was for the class of point functions (also known as IBE).",Springer
"Rosca, Miruna and Stehl{\'e}, Damien and Wallet, Alexandre",On the Ring-LWE and Polynomial-LWE Problems,2018,10.1007/978-3-319-78381-9_6,https://doi.org/10.1007/978-3-319-78381-9_6,Conference Paper,Advances in Cryptology -- EUROCRYPT 2018,"The Ring Learning With Errors problem ({\$}{\$}{\backslash}mathsf {\{}RLWE{\}}{\$}{\$}) comes in various forms. Vanilla {\$}{\$}{\backslash}mathsf {\{}RLWE{\}}{\$}{\$}is the decision dual-{\$}{\$}{\backslash}mathsf {\{}RLWE{\}}{\$}{\$}variant, consisting in distinguishing from uniform a distribution depending on a secret belonging to the dual {\$}{\$}{\backslash}mathcal {\{}O{\}}{\_}K^{\{}{\backslash}vee {\}}{\$}{\$}of the ring of integers {\$}{\$}{\backslash}mathcal {\{}O{\}}{\_}K{\$}{\$}of a specified number field K. In primal-{\$}{\$}{\backslash}mathsf {\{}RLWE{\}}{\$}{\$}, the secret instead belongs to {\$}{\$}{\backslash}mathcal {\{}O{\}}{\_}K{\$}{\$}. Both decision dual-{\$}{\$}{\backslash}mathsf {\{}RLWE{\}}{\$}{\$}and primal-{\$}{\$}{\backslash}mathsf {\{}RLWE{\}}{\$}{\$}enjoy search counterparts. Also widely used is (search/decision) Polynomial Learning With Errors ({\$}{\$}{\backslash}mathsf {\{}PLWE{\}}{\$}{\$}), which is not defined using a ring of integers {\$}{\$}{\backslash}mathcal {\{}O{\}}{\_}K{\$}{\$}of a number field K but a polynomial ring {\$}{\$}{\backslash}mathbb {\{}Z{\}}[x]/f{\$}{\$}for a monic irreducible {\$}{\$}f {\backslash}in {\backslash}mathbb {\{}Z{\}}[x]{\$}{\$}. We show that there exist reductions between all of these six problems that incur limited parameter losses. More precisely: we prove that the (decision/search) dual to primal reduction from Lyubashevsky et al. [EUROCRYPT 2010] and Peikert [SCN 2016] can be implemented with a small error rate growth for all rings (the resulting reduction is non-uniform polynomial time); we extend it to polynomial-time reductions between (decision/search) primal {\$}{\$}{\backslash}mathsf {\{}RLWE{\}}{\$}{\$}and {\$}{\$}{\backslash}mathsf {\{}PLWE{\}}{\$}{\$}that work for a family of polynomials f that is exponentially large as a function of {\$}{\$}{\backslash}deg f{\$}{\$}(the resulting reduction is also non-uniform polynomial time); and we exploit the recent technique from Peikert et al. [STOC 2017] to obtain a search to decision reduction for {\$}{\$}{\backslash}mathsf {\{}RLWE{\}}{\$}{\$}for arbitrary number fields. The reductions incur error rate increases that depend on intrinsic quantities related to K and f.",Springer
"Cimatti, Alessandro and Grosen, Thomas M. and Larsen, Kim G. and Tonetta, Stefano and Zimmermann, Martin",Exploiting Assumptions for Effective Monitoring of Real-Time Properties Under Partial Observability,2025,10.1007/978-3-031-77382-2_5,https://doi.org/10.1007/978-3-031-77382-2_5,Conference Paper,Software Engineering and Formal Methods,"Runtime verification of temporal properties over timed sequences of observations is crucial in various applications within cyber-physical systems ranging from autonomous vehicles over smart grids to medical devices. In this paper, we are addressing the challenge of effectively predicting the failure or success of properties in a continuous real-time setting. Our approach allows predictions to exploit assumptions on the system being monitored and supports predictions of non-observable system behaviour (e.g. internal faults). More concretely, in our approach properties are expressed in Metric Interval Temporal Logic (MITL), assumptions on the monitored system are specified in terms of Timed Automata, and observations are to be provided in terms of sequences of timed constraints. We present an assumption-based runtime verification algorithm and its implementation on top of the real-time verification tool UPPAAL. We show experimentally that assumptions can be effective in anticipating the satisfaction/violation of timed properties and in handling monitoring properties that predicate over unobservable events.",Springer
"Desu, Surya Sai Teja and Srivastava, Anubhav and Rao, M. V. Panduranga",Model Checking for Entanglement Swapping,2022,10.1007/978-3-031-15839-1_6,https://doi.org/10.1007/978-3-031-15839-1_6,Conference Paper,Formal Modeling and Analysis of Timed Systems,"Entanglement swapping is a basic primitive in long distance quantum communications. The stochastic nature of various operations like entanglement generation and BSMs makes the entanglement swapping primitive failure prone. It is difficult to predict whether or not an entanglement swapping operation will succeed within a stipulated time. In this paper, we use Probabilistic Timed Automata (PTA) to model the experiment and analyze it through model checking. We report a proof-of-concept mechanism, opening way for the analysis of large scale quantum networks through formal methods. We also report supporting results on a quantum simulator.",Springer
"Cuzzocrea, Alfredo and Canad{\`e}, Luigi and Fornari, Giulia and Gatto, Vittorio and Hafsaoui, Abderraouf",Effective and Efficient Heuristic Algorithms for Supporting Optimal Location of Hubs over Networks with Demand Uncertainty,2023,10.1007/978-3-031-39847-6_6,https://doi.org/10.1007/978-3-031-39847-6_6,Conference Paper,Database and Expert Systems Applications,"The problem faced in this paper concerns with finding the optimal location for the hubs in a network, under demand uncertainty, and where the allocation of the nodes is treated as a second stage decision. We proceed first with the definition of the mathematical model that we carved to fit the operational needs of GUROBI Optimizer. Afterwards, we propose a collection of heuristic algorithms able to solve the problem in a faster way with sub-optimal solutions. The heuristic algorithms proposed in our framework progressively reach a good approximation of the solution. Experimental results confirm the benefits of our approach.",Springer
"Skibina, Valeriia and Taratukhin, Victor",Towards to Extended Empathy Methods in Design Thinking,2022,10.1007/978-3-030-95494-9_27,https://doi.org/10.1007/978-3-030-95494-9_27,Conference Paper,Information Systems and Design,"The paper analyzes existing empathy methods and offers new approaches so far as of empathy being an important element for design thinking (a Stanford methodology for creative problem-solving) and companies post-COVID era redesign. It comprises an overview of such methods as: VR Technology, VR Empathy Mirror, Dare Dream World Modeling, Fingers Magic, Cosplay, Scenes, and Role games. The paper takes into account different views on the origin of consciousness: molecular biology, neuroscience, pharmacology, quantum information theory, quantum gravity and etc. Many different hypotheses on the related topics and existing approaches are discussed. The article pays attention to issues related to both the opportunities of practical implementation and the moral aspects, possible consequences of the inventions in empathy like a glance on perspective. One's Experimental basis for each of the approaches is provided. After all, understanding of human thinking/feeling is placed at the heart of the global understanding of all vital processes that surround us.",Springer
"Schmitt, Anna and Peters, Kirstin and Deng, Yuxin",Encodability Criteria for Quantum Based Systems,2022,10.1007/978-3-031-08679-3_10,https://doi.org/10.1007/978-3-031-08679-3_10,Conference Paper,"Formal Techniques for Distributed Objects, Components, and Systems","Quantum based systems are a relatively new research area for that different modelling languages including process calculi are currently under development. Encodings are often used to compare process calculi. Quality criteria are used then to rule out trivial or meaningless encodings. In this new context of quantum based systems, it is necessary to analyse the applicability of these quality criteria and to potentially extend or adapt them. As a first step, we test the suitability of classical criteria for encodings between quantum based languages and discuss new criteria.",Springer
"Becker-Kupczok, Jonas and Herber, Paula",Symbolic Execution for Precise Information Flow Analysis of Timed Concurrent Systems,2025,10.1007/978-3-031-77382-2_7,https://doi.org/10.1007/978-3-031-77382-2_7,Conference Paper,Software Engineering and Formal Methods,"Information flow analysis (IFA) is a powerful technique for verifying confidentiality and integrity. This is highly desirable for embedded systems, where security violations can lead to significant economic damages or even loss of human life. Unfortunately, if shared bus architectures are used, classical IFA that do not consider timing behavior will always classify the whole system as insecure. In this paper, we present an approach to regain precision in IFA for timed systems that concurrently execute processes using a cooperative scheduler. Our key idea is to extend a classical IFA approach based on program dependence graphs with a symbolic execution together with abstract interpretation to precisely yet abstractly capture data, control, timing, and event dependencies between processes. While this increases the cost of the analysis, the gain in precision leverages IFA even for concurrent systems with time-shared bus architectures as they are widely used, for example, in the automotive industry. We have implemented our approach for the system level description language SystemC, and demonstrate its applicability with a case study that uses a general-purpose input/ouput (GPIO).",Springer
"Bonnetain, Xavier",Quantum Key-Recovery on Full AEZ,2018,10.1007/978-3-319-72565-9_20,https://doi.org/10.1007/978-3-319-72565-9_20,Conference Paper,Selected Areas in Cryptography -- SAC 2017,"AEZ is an authenticated encryption algorithm, submitted to the CAESAR competition. It has been selected for the third round of the competition. While some classical analysis on the algorithm have been published, the cost of these attacks is beyond the security claimed by the designers.",Springer
"Alamati, Navid and Montgomery, Hart and Patranabis, Sikhar",Symmetric Primitives with Structured Secrets,2019,10.1007/978-3-030-26948-7_23,https://doi.org/10.1007/978-3-030-26948-7_23,Conference Paper,Advances in Cryptology -- CRYPTO 2019,"Securely managing encrypted data on an untrusted party is a challenging problem that has motivated the study of a wide variety of cryptographic primitives. A special class of such primitives allows an untrusted party to transform a ciphertext encrypted under one key to a ciphertext under another key, using some auxiliary information that does not leak the underlying data. Prominent examples of such primitives in the symmetric setting are key-homomorphic (weak) PRFs, updatable encryption, and proxy re-encryption. Although these primitives differ significantly in terms of their constructions and security requirements, they share two important properties: (a) they have secrets with structure or extra functionality, and (b) all known constructions of these primitives satisfying reasonably strong definitions of security are based on concrete public-key assumptions, e.g., DDH and LWE.",Springer
"de Jong, Jins and Hoek, Carmen R.",The Significance of the Quantum Volume for Other Algorithms: A Case Study for Quantum Amplitude Estimation,2024,10.1007/978-3-031-63778-0_16,https://doi.org/10.1007/978-3-031-63778-0_16,Conference Paper,Computational Science -- ICCS 2024,"The quantum volume is a comprehensive, single number metric to describe the computational power of a quantum computer. It has grown exponentially in the recent past. In this study we will assume this remains the case and translate this development into the performance development of another quantum algorithms, quantum amplitude estimation. This is done using a noise model that estimates the error probability of a single run of an algorithm. Its parameters are related to the quantum volume under the model's assumptions.",Springer
"Durasevic, Marko and Jakobovic, Domagoj and Scoczynski Ribeiro Martins, Marcella and Picek, Stjepan and Wagner, Markus",Fitness Landscape Analysis of Dimensionally-Aware Genetic Programming Featuring Feynman Equations,2020,10.1007/978-3-030-58115-2_8,https://doi.org/10.1007/978-3-030-58115-2_8,Conference Paper,Parallel Problem Solving from Nature -- PPSN XVI,"Genetic programming is an often-used technique for symbolic regression: finding symbolic expressions that match data from an unknown function. To make the symbolic regression more efficient, one can also use dimensionally-aware genetic programming that constrains the physical units of the equation. Nevertheless, there is no formal analysis of how much dimensionality awareness helps in the regression process. In this paper, we conduct a fitness landscape analysis of dimensionally-aware genetic programming search spaces on a subset of equations from Richard Feynman's well-known lectures. We define an initialisation procedure and an accompanying set of neighbourhood operators for conducting the local search within the physical unit constraints. Our experiments show that the added information about the variable dimensionality can efficiently guide the search algorithm. Still, further analysis of the differences between the dimensionally-aware and standard genetic programming landscapes is needed to help in the design of efficient evolutionary operators to be used in a dimensionally-aware regression.",Springer
"Wesolowski, Benjamin",Efficient Verifiable Delay Functions,2019,10.1007/978-3-030-17659-4_13,https://doi.org/10.1007/978-3-030-17659-4_13,Conference Paper,Advances in Cryptology -- EUROCRYPT 2019,"We construct a verifiable delay function (VDF). A VDF is a function whose evaluation requires running a given number of sequential steps, yet the result can be efficiently verified. They have applications in decentralised systems, such as the generation of trustworthy public randomness in a trustless environment, or resource-efficient blockchains. To construct our VDF, we actually build a trapdoor VDF. A trapdoor VDF is essentially a VDF which can be evaluated efficiently by parties who know a secret (the trapdoor). By setting up this scheme in a way that the trapdoor is unknown (not even by the party running the setup, so that there is no need for a trusted setup environment), we obtain a simple VDF. Our construction is based on groups of unknown order such as an RSA group, or the class group of an imaginary quadratic field. The output of our construction is very short (the result and the proof of correctness are each a single element of the group), and the verification of correctness is very efficient.",Springer
"Backes, Michael and D{\""o}ttling, Nico and Hanzlik, Lucjan and Kluczniak, Kamil and Schneider, Jonas","Ring Signatures: Logarithmic-Size, No Setup---from Standard Assumptions",2019,10.1007/978-3-030-17659-4_10,https://doi.org/10.1007/978-3-030-17659-4_10,Conference Paper,Advances in Cryptology -- EUROCRYPT 2019,"Ring signatures allow for creating signatures on behalf of an ad hoc group of signers, hiding the true identity of the signer among the group. A natural goal is to construct a ring signature scheme for which the signature size is short in the number of ring members. Moreover, such a construction should not rely on a trusted setup and be proven secure under falsifiable standard assumptions. Despite many years of research this question is still open.",Springer
"Sarker, Md. Meheruzzaman and Islam, Md. Jakirul and Hossain, Md. Zakir",A Clustering Based Niching Method for Effectively Solving the 0-1 Knapsack Problem,2023,10.1007/978-3-031-34622-4_14,https://doi.org/10.1007/978-3-031-34622-4_14,Conference Paper,Machine Intelligence and Emerging Technologies,"The 0-1 knapsack problem (01-KP) is a NP-hard combinatorial optimization problems (COPs) with several applications. Because of its non-convexity, its search space contains several local and/or global optimum solutions. In this situation, both the classical and metaheuristic global optimization approaches often failed to locate the optimal solution to the 01-KP. Therefore, this research develops a clustering-based niching (CBN) method for maintaining and locating multiple solutions within an optimization run, increasing the possibility of locating the global optimal solution to the 01-KP. To do this, CBN method divides the population individuals into a number of clusters (similar to niches in a biology or ecology system) by measuring the Hamming distance between individuals. During the optimization, the individuals in the formed clusters independently explore different regions of the combinatorial search space in order to find promising solutions. For simplicity, the proposed CBN method is implemented using a modified binary PSO (lbest-BPSO) method. The numerical results show that the CBN method is superior than the well-known metaheuristic methods on the basis of solution quality, with a better success rate and average function evaluations, over widely used sets of 0-1 knapsack instance. This guarantees that CBN method is a suitable optimization method for determining the optimal solution to combinatorial optimization problems.",Springer
"Guddad, Vijaykumar and Kulkarni, Amit and Stroobandt, Dirk",Reconfigurable FPGA Implementation of the AVC Quantiser and De-quantiser Blocks,2018,10.1007/978-3-030-01449-0_43,https://doi.org/10.1007/978-3-030-01449-0_43,Conference Paper,Advanced Concepts for Intelligent Vision Systems,"As image and video resolution continues to increase, compression plays a vital role in the successful transmission of video and image data over a limited bandwidth channel. Computation complexity, as well as the utilization of resources and power, keep increasing when we move from the H264 codec to the H265 codec. Optimizations in each particular block of the Advanced Video Coding (AVC) standard significantly improve the operating frequency of a hardware implementation. In this paper, we designed parametrized reconfigurable quantiser and de-quantiser blocks of AVC through dynamic circuit specialization, which is different from traditional reconfiguration of FPGA. We implemented the design on a Zynq-SoC board, which resulted in optimizations in resource consumption of 14.1{\%} and 20.6{\%} for the quantiser and de-quantiser blocks respectively, compared to non-reconfigurable versions.",Springer
"Stiliadou, Lavinia and Barzen, Johanna and Leymann, Frank and Mandl, Alexander and Weder, Benjamin",Exploring the Cost Landscape of Variational Quantum Algorithms,2025,10.1007/978-3-031-72578-4_7,https://doi.org/10.1007/978-3-031-72578-4_7,Conference Paper,Service-Oriented Computing,"Variational Quantum Algorithms (VQAs) have emerged as a promising approach to leverage the capabilities of quantum computing, even within the constraints of limited qubits and noise. Understanding their iterative process, including their cost landscapes, is necessary to optimize these algorithms. This landscape represents the interplay between the algorithm's parameters and the cost function, offering a visualization of the challenges for the optimization process. Regions known as barren plateaus and narrow gorges can impede optimization algorithms by causing gradients to vanish, leading to stalled optimization processes. Recognizing and devising strategies to circumvent these severe problems is essential for designing VQAs. For this purpose, we provide an overview of local and global metrics to support the understanding of the VQA cost landscape. Moreover, our results may serve as a baseline for further research on cost landscapes.",Springer
"Bo{\.{z}}ejko, Wojciech and Pempera, Jaros{\l}aw and Uchro{\'{n}}ski, Mariusz and Wodecki, Mieczys{\l}aw",Determination of the Lower Bounds of the Goal Function for a Single-Machine Scheduling Problem on D-Wave Quantum Annealer,2023,10.1007/978-3-031-36030-5_16,https://doi.org/10.1007/978-3-031-36030-5_16,Conference Paper,Computational Science -- ICCS 2023,"The fundamental problem of using metaheuristics and almost all other approximation methods for difficult discrete optimization problems is the lack of knowledge regarding the quality of the obtained solution. In this paper, we propose a methodology for efficiently estimating the quality of such approaches by rapidly -- and practically in constant time -- generating good lower bounds on the optimal value of the objective function using a quantum machine, which can be an excellent benchmark for comparing approximate algorithms. Another natural application is to use the proposed approach in the construction of exact algorithms based on the Branch and Bound method to obtain real optimal solutions.",Springer
"Fatkina, Anna and Gonchar, Maxim and Kolupaeva, Liudmila and Naumov, Dmitry and Treskov, Konstantin",CUDA Support in GNA Data Analysis Framework,2018,10.1007/978-3-319-95171-3_2,https://doi.org/10.1007/978-3-319-95171-3_2,Conference Paper,Computational Science and Its Applications -- ICCSA 2018,"Usage of GPUs as co-processors is a well-established approach to accelerate costly algorithms operating on matrices and vectors. We aim to further improve the performance of the Global Neutrino Analysis framework (GNA) by adding GPU support in a way that is transparent to the end user. To achieve our goal we use CUDA, a state of the art technology providing GPGPU programming methods.",Springer
"Coelho, Tiago and Rodrigues, Ricardo and Miranda, Rita and Portela, Filipe",Towards a Modular IOT Simulation System for Industry,2024,10.1007/978-3-031-48930-3_25,https://doi.org/10.1007/978-3-031-48930-3_25,Conference Paper,"Advanced Research in Technologies, Information, Innovation and Sustainability","In this article, there is approached the simulation of Industry 4.0 environments, being used as an example, the textile industry. There will be explained the concept of simulating Industry 4.0 factory floors, approaching many topics such as the benefits of this solution, how it can be used in every industry sector, and most importantly the work and research that has been done around the subject area. The textile industry will be used as an example and, therefore, there will be explained later in the document more specific details regarding the appliance of the solution to the industry sector that is being approached. This explanation will include the required materials for the development of a prototype, as well as the used methods and expected results. In terms of results, this study created a scalable architecture and three data models that can config and store the simulation data.",Springer
"Petz, Adam and Thomas, Will and Fritz, Anna and Barclay, T. J. and Schmalz, Logan and Alexander, Perry",Verified Configuration and Deployment of Layered Attestation Managers,2025,10.1007/978-3-031-77382-2_17,https://doi.org/10.1007/978-3-031-77382-2_17,Conference Paper,Software Engineering and Formal Methods,"Effective layered attestation systems require a trusted mechanism for their implementation, configuration, and deployment. Core to these systems are a distributed collection of Attestation Manager (AM) components that orchestrate primitive services and bundle evidence. Despite the trust placed in AMs, their configuration and deployment remain tedious and error prone, even for relatively simple attestation topologies. Beginning with a semantically sound layered attestation protocol language, we develop a verified toolchain for configuring attestation components and decidable algorithms for evaluating protocol executability and constrained evidence disclosure. The toolchain operates on configuration artifacts for AMs called Manifests that denote local attestation resources and facilitate coordination amongst remote AMs.  The Manifest Generator and Manifest Compiler tools jointly synthesize collections of Manifests from attestation protocol terms and specialize Manifests resulting in executable AMs. The resulting workflow automatically generates infrastructure for attestation protocol execution.",Springer
"Sehrawat, Vipin Singh and Desmedt, Yvo",Bi-homomorphic Lattice-Based PRFs and Unidirectional Updatable Encryption,2019,10.1007/978-3-030-31578-8_1,https://doi.org/10.1007/978-3-030-31578-8_1,Conference Paper,Cryptology and Network Security,"We define a pseudorandom function (PRF) {\$}{\$}F: {\backslash}mathcal {\{}K{\}} {\backslash}times {\backslash}mathcal {\{}X{\}} {\backslash}rightarrow {\backslash}mathcal {\{}Y{\}}{\$}{\$}to be bi-homomorphic when it is fully Key homomorphic and partially Input Homomorphic (KIH), i.e., given {\$}{\$}F(k{\_}1, x{\_}1){\$}{\$}and {\$}{\$}F(k{\_}2, x{\_}2){\$}{\$}, there is an efficient algorithm to compute {\$}{\$}F(k{\_}1 {\backslash}oplus k{\_}2, x{\_}1 {\backslash}ominus x{\_}2){\$}{\$}, where {\$}{\$}{\backslash}oplus {\$}{\$}and {\$}{\$}{\backslash}ominus {\$}{\$}are (binary) group operations. The homomorphism on the input is restricted to a fixed subset of the input bits, i.e., {\$}{\$}{\backslash}ominus {\$}{\$}operates on some pre-decided m-out-of-n bits, where {\$}{\$}|x{\_}1| = |x{\_}2| = n, m < n{\$}{\$}, and the remaining {\$}{\$}n-m{\$}{\$}bits are identical in both inputs. In addition, the output length, {\$}{\$}{\backslash}ell {\$}{\$}, of the operator {\$}{\$}{\backslash}ominus {\$}{\$}is not fixed and is defined as {\$}{\$}n {\backslash}le {\backslash}ell {\backslash}le 2n{\$}{\$}, hence leading to Homomorphically induced Variable input Length (HVL) as {\$}{\$}n {\backslash}le |x{\_}1 {\backslash}ominus x{\_}2| {\backslash}le 2n{\$}{\$}. We present a learning with errors (LWE) based construction for a HVL-KIH-PRF family. Our construction is inspired by the key homomorphic PRF construction due to Banerjee and Peikert (Crypto 2014). We use our novel PRF family to construct an updatable encryption scheme, named QPC-UE-UU, which is quantum-safe, post-compromise secure and supports unidirectional ciphertext updates, i.e., the tokens can be used to perform ciphertext updates, but they cannot be used to undo completed updates. Our PRF family also leads to the first left/right key homomorphic constrained-PRF family with HVL.",Springer
"Buser, Maxime and Liu, Joseph K. and Steinfeld, Ron and Sakzad, Amin and Sun, Shi-Feng",DGM: A Dynamic and Revocable Group Merkle Signature,2019,10.1007/978-3-030-29959-0_10,https://doi.org/10.1007/978-3-030-29959-0_10,Conference Paper,Computer Security -- ESORICS 2019,"Group signatures are considered as one of the most prominent cryptographic primitives to ensure privacy. In essence, group signatures ensure the authenticity of messages while the author of the message remains anonymous. In this study, we propose a dynamic post-quantum group signature (GS) extending the static G-Merkle group signature (PQCRYPTO 2018). In particular, our dynamic G-Merkle (DGM) allows new users to join the group at any time. Similar to G-Merkle scheme, our DGM only involves symmetric primitives and makes use of a One-Time Signature scheme (OTS). Each member of the group receives a certain amount of OTS key pairs and can ask the Manager {\$}{\$}{\backslash}mathcal {\{}M{\}}{\$}{\$}Mfor more if needed. Our DGM also provides an innovative way of signing revocation by employing Symmetric Puncturable Encryption (SPE) recently appeared in (ACM CCS 2018). DGM provides a significantly smaller signature size than other GSs based on symmetric primitives and also reduces the influence of the number of group members on the signature size and on the limitations of the application of G-Merkle.",Springer
"Bo{\.{z}}ejko, Wojciech and Pempera, Jaros{\l}aw and Uchro{\'{n}}ski, Mariusz and Wodecki, Mieczys{\l}aw",Distributed Quantum Annealing on D-Wave for the Single Machine Total Weighted Tardiness Scheduling Problem,2022,10.1007/978-3-031-08760-8_15,https://doi.org/10.1007/978-3-031-08760-8_15,Conference Paper,Computational Science -- ICCS 2022,"In the work, we are proposing a new distributed quantum annealing method of algorithm construction for solving an NP-hard scheduling problem. A method of diversification of calculations has been proposed by dividing the space of feasible solutions and using the fact that the quantum annealer of the D-Wave machine is able to optimally solve (for now) small-size subproblems only. The proposed methodology was tested on a difficult instance of a single machine total weighted tardiness scheduling problem proposed by Lawler.",Springer
"Hromei, Claudiu D. and Croce, Danilo and Basile, Valerio and Basili, Roberto",Scaling Large Language Models to the Extreme: Neural Semantic Processing of Multiple Tasks in Italian,2023,10.1007/978-3-031-47546-7_12,https://doi.org/10.1007/978-3-031-47546-7_12,Conference Paper,AIxIA 2023 -- Advances in Artificial Intelligence,"This paper explores the potential of utilizing a unified neural model to tackle multiple and complex semantic processing tasks in the Italian language. We applied a state-of-the-art instruction-tuned Decoder-only Large Language Model to the recent EVALITA 2023 [17] challenge, which encompassed 13 different tasks and 22 subtasks across diverse semantic dimensions, such as Affect Detection, Authorship Analysis, Computational Ethics, Named Entity Recognition, Information Extraction, and Discourse Coherence. Our approach focuses on representing tasks using natural language instructions, for which prompts to the model are designed able to define the process as well as the desired responses. Notably, this single neural model achieved first place in 41{\%} of the subtasks and demonstrated top-three performance in 64{\%} of them. A dedicated experiment was also conducted to investigate the degree of linguistic generalization achieved by the LLM specifically, through instruction-tuning it with limited sets of training data. Results suggest that instruction-tuning is still required to capture dependencies between input and output even in such LLMs.",Springer
"Aharonov, Dorit and Brakerski, Zvika and Chung, Kai-Min and Green, Ayal and Lai, Ching-Yi and Sattath, Or",On Quantum Advantage in Information Theoretic Single-Server PIR,2019,10.1007/978-3-030-17659-4_8,https://doi.org/10.1007/978-3-030-17659-4_8,Conference Paper,Advances in Cryptology -- EUROCRYPT 2019,"In (single-server) Private Information Retrieval (PIR), a server holds a large database {\$}{\$}{\{}{\backslash}mathtt {\{}DB{\}}{\}}{\$}{\$}of size n, and a client holds an index {\$}{\$}i {\backslash}in [n]{\$}{\$}and wishes to retrieve {\$}{\$}{\{}{\backslash}mathtt {\{}DB{\}}{\}}[i]{\$}{\$}without revealing i to the server. It is well known that information theoretic privacy even against an ``honest but curious'' server requires {\$}{\$}{\backslash}varOmega (n){\$}{\$}communication complexity. This is true even if quantum communication is allowed and is due to the ability of such an adversarial server to execute the protocol on a superposition of databases instead of on a specific database (``input purification attack'').",Springer
"Guan, Peidong and Wan, Yunqi and Zhang, Zhuoran and Zhang, Fangguo",Efficient List Decoding Applied to {\$}{\$}{\backslash}mathrm{\{}ECC{\}}^2{\$}{\$},2022,10.1007/978-3-030-96772-7_52,https://doi.org/10.1007/978-3-030-96772-7_52,Conference Paper,"Parallel and Distributed Computing, Applications and Technologies","{\$}{\$}{\backslash}mathrm{\{}ECC{\}}^2{\$}{\$}ECC2is an public key encryption system based on elliptic code. It can resist known attacks based on the special structures of algebraic geometric code. However, the computational overhead of decryption of {\$}{\$}{\backslash}mathrm{\{}ECC{\}}^2{\$}{\$}ECC2is unsatisfactory, because the list decoding algorithm occupies a major part of the computational overhead of decryption of {\$}{\$}{\backslash}mathrm{\{}ECC{\}}^2{\$}{\$}ECC2. Therefore, we propose our module basis reduction interpolation of list decoding for elliptic code to speed up the decryption of {\$}{\$}{\backslash}mathrm{\{}ECC{\}}^2{\$}{\$}ECC2. The algorithm we proposed is based on the theory of Gr{\$}{\$}{\backslash}ddot{\{}{\backslash}mathrm{\{}o{\}}{\}}{\$}{\$}o{\textasciidieresis}bner basis of modules. By implementing our proposed algorithm combined with {\$}{\$}{\backslash}mathrm{\{}ECC{\}}^2{\$}{\$}ECC2, it shows that the proposed algorithm performs better than the list decoding algorithms used in {\$}{\$}{\backslash}mathrm{\{}ECC{\}}^2{\$}{\$}ECC2.",Springer
"Gu{\'e}nin--Carlut, Avel","Contextuality, Cognitive Engagement, and Active Inference",2025,10.1007/978-3-031-77138-5_17,https://doi.org/10.1007/978-3-031-77138-5_17,Conference Paper,Active Inference,"We revisit existing criticism of the Free Energy Principle and Active Inference through the concept of cognitive contextuality. Contextuality describe the property of physical states which are brought about by the very act of their observation, such as the position or momentum of individual particles in quantum settings. Based on conceptual and physical argument, we propose that contextuality drives the construction of cognitive semiotics. As such, it constitutes a fundamental component of cognition which any formal theory thereof must capture. At a conceptual level, Active Inference seems to capture the inherently contextual nature of cognitive engagement with the world. However, the Free Energy Principle cannot formalize this intuition due to its definition in terms of Dynamical Systems Theory, which comes with a well-defined space of possible states with no contextual properties. We describe the duality between agent-driven interaction and the construction of cognitive spaces which is implicit in the very concept of cognitive contextuality. In consequence, we emphasize the importance of the ontic regime called ``Participatory Realism'', and consider some ways that the FEP could integrate it.",Springer
"Lytaev, Mikhail S.",Numerical Approximation of the One-Way Helmholtz Equation Using the Differential Evolution Method,2022,10.1007/978-3-031-08751-6_15,https://doi.org/10.1007/978-3-031-08751-6_15,Conference Paper,Computational Science -- ICCS 2022,"This paper is devoted to increasing the computational efficiency of the finite-difference methods for solving the one-way Helmholtz equation in unbounded domains. The higher-order rational approximation of the propagation operator was taken as a basis. Computation of appropriate approximation coefficients and grid sizes is formulated as the problem of minimizing the discrete dispersion relation error. Keeping in mind the complexity of the developed optimization problem, the differential evolution method was used to tackle it. The proposed method does not require manual selection of the artificial parameters of the numerical scheme. The stability of the scheme is provided by an additional constraint of the optimization problem. A comparison with the Pad{\'e} approximation method and rational interpolation is carried out. The effectiveness of the proposed approach is shown.",Springer
"Antonov, Alexander",Wiki Representation and Analysis of Knowledge About Algorithms,2022,10.1007/978-3-031-22941-1_44,https://doi.org/10.1007/978-3-031-22941-1_44,Conference Paper,Supercomputing,"As part of the project to create an AlgoWiki Open encyclopedia of parallel algorithmic features, many properties of computational algorithms are described, primarily related to parallelism. For this, wiki representation is used, which allows the entire computing community to participate in the description of such properties. At the moment, a large number of algorithms from different fields of science have already been described using a single universal scheme. But gradually the project becomes something much more than just a library of algorithms. The logical development of the AlgoWiki project extends the analysis of specific algorithms by expert evaluation of the quality of possible approaches to solving individual problems. Further expansion within the framework of the Algo500 project allows for each implementation of the algorithm from the AlgoWiki encyclopedia to build its own independent rating list, which provides new opportunities for analyzing the quality of mapping problems to computer architecture.",Springer
"Le{\'{s}}niak, Mateusz and Burek, El{\.{z}}bieta and Wro{\'{n}}ski, Micha{\l}","Unsafe Mechanisms of Bluetooth, {\$}{\$}E{\_}0{\$}{\$}Stream Cipher Cryptanalysis with Quantum Annealing",2024,10.1007/978-3-031-63778-0_28,https://doi.org/10.1007/978-3-031-63778-0_28,Conference Paper,Computational Science -- ICCS 2024,"Due to Shor's and Grover's algorithms, quantum computing has become one of the fastest-evolving areas in computational science. Nowadays, one of the most interesting branches of quantum computing is quantum annealing. This paper presents the efficient method of transforming stream cipher E0 to the QUBO problem and then retrieving the Encryption Key of this cipher using quantum annealing. Comparably to other asymmetric and symmetric cryptographic algorithms, the presented transformation is efficient, requiring only 2,728 (2,751) logical variables for attack with 128 (129) consecutive keystream bits. According to our knowledge, it is the most efficient algorithm transformation with a 128-bit key. Moreover, we show that using current quantum annealers, one can embed the attack for E0 for 58 consecutive bits of keystream, from 128 (129), which are necessary for the attack's first stage (second stage). Therefore, it is likely that it will be possible to embed E0 on available quantum annealers in the next few years.",Springer
"Sharma, Dipti and Tripathi, Ashutosh and Kumari, Meet",High-Speed FSO System for Future Generation Networks for Long Reach,2025,10.1007/978-3-031-75170-7_4,https://doi.org/10.1007/978-3-031-75170-7_4,Conference Paper,"Computing Science, Communication and Security","A free space optics (FSO) system is proposed and described mathematically to meet the needs of future networks. Various integrating and synchronizing methods of hybrid fiber optic and FSO components incorporating advanced modulation formats, are discussed. The system performance is evaluated considering FSO link losses, signal regeneration, and amplification. Simulation results depict that 200--1400 m range at 10 Gbps under clear air, rain, fog and dust for different frequencies. In addition, system throughput can be extended upto 5--20 Gbps at 200--1400 m range under diverse climate conditions. This system offers superior performance over other existing ones. In future this system can be realized for 5G based future network topologies, hybrid fiber-FSO technology for high infrastructure compatibility, high-speed, and long-reach capabilities by supporting new applications.",Springer
"Hasidi, Oussama and Abdelwahed, El Hassan and El Alaoui-Chrifi, My Abdellah and Qazdar, Aimad and Bourzeix, Fran{\c{c}}ois and Benzakour, Intissar and Bendaouia, Ahmed and Dahhassi, Charifa",Data-Driven and Model-Driven Approaches in Predictive Modelling for Operational Efficiency: Mining Industry Use Case,2024,10.1007/978-3-031-49333-1_9,https://doi.org/10.1007/978-3-031-49333-1_9,Conference Paper,Model and Data Engineering,"In this study, we explore the effectiveness of a hybrid modelling approach that seamlessly integrates data-driven techniques, specifically Machine Learning (ML), with physics-based equations in Simulation. In cases where real-world data for industrial processes is insufficient, a simulation tool is employed to generate an extensive dataset of process variables under varying operating conditions. Subsequently, this dataset is utilized for training the Machine Learning model. The paper showcases a practical use case of this hybrid modelling approach, revealing a model that consistently demonstrates strong predictive accuracy and reliability within the specific industrial context we investigate. By merging the insights derived from physics-based understanding with the adaptability of data-driven Machine Learning, the hybrid model offers a comprehensive solution for precise and accurate predictions.",Springer
"Pekar{\v{c}}ik, Peter and Chovancov{\'a}, Eva and Chovanec, Martin and Kuch{\v{c}}{\'a}kov{\'a}, Tatiana",New Approach to Crossover of Encryption Algorithms,2025,10.1007/978-3-031-72393-3_2,https://doi.org/10.1007/978-3-031-72393-3_2,Conference Paper,Future Access Enablers for Ubiquitous and Intelligent Infrastructures,"Our work presents a novel approach to creating new encryption algorithms. We were inspired by genetic algorithms based on the Darwin evolution theory. As the method of invention, we chose the crossover technique. We aim to create unique encryption algorithms that will be more secure, faster, and require less memory space or computational energy. New encryption algorithms are based on the most commonly used encryption techniques. During the crossover process, we consider the most critical metrics for encryption algorithms. We also briefly described the crossover and mutation process. The developed method is in the state of design. The design presented in this article is in the form of a flowchart diagram and detailed decryption. We plan to implement it and test it.",Springer
"Boronenko, Marina and Isaeva, Oksana and Boronenko, Yuri and Zelensky, Vladimir and Gulyaev, Pavel",Recognition of Changes in the Psychoemotional State of a Person by the Video Image of the Pupils,2021,10.1007/978-3-030-88113-9_10,https://doi.org/10.1007/978-3-030-88113-9_10,Conference Paper,Advances in Computational Collective Intelligence,"We are looking for a relationship between electrodermal activity and the amplitude of fluctuations in the size of the pupils, depending on the magnitude of the stress (stress state) experienced. Studies have been carried out on the psychophysiological reactions of a person (emotions) arising in response to external stress factors (stimuli). For this, a device was used to register changes in pupil size and galvanic skin response. It turned out that the change in the values of galvanic skin response and pupil size correlates (p{\thinspace}={\thinspace}0.9) in the presence of emotions (all other things being equal). The result of measuring galvanic skin reaction (GSR) shows that the level of attention during the test to some stimuli was higher than to others. This means that the first stimuli may be more significant for the subject than the second. The results obtained make it possible to link the galvanic skin response and the pupil response in response to the stimulus material. Our research also shows that the pupil diameter signal has a good discriminating ability to detect changes in the psychological state of a person. The results can be useful for the development of Computer Vision and Artificial Intelligence.",Springer
"Marchesi, Michele and Pinna, Andrea and Pisu, Francesco and Tonelli, Roberto",Crypto-Trading. Rechargeable Token-Based Smart Energy Market Enabled by Blockchain and IoT Technology,2020,10.1007/978-3-030-48340-1_13,https://doi.org/10.1007/978-3-030-48340-1_13,Conference Paper,Euro-Par 2019: Parallel Processing Workshops,"This paper presents the definition and the implementation of a decentralized system for the energy trading managed by blockchain technology. The system, called Crypto-Trading, is composed by three interacting subsystems: the trading platform, the blockchain, and the smart meters system. It is conceived to exploit the IoT technology of smart meters and the decentralization of smart contracts working inside the blockchain technology for managing exchange and trading of energy by means of specific tokens. The paper defines the system as a decentralized application, identifying system actors and describing user stories. Then provides the description of the use case concerning the rechargeable token, one of the main feature of our system, and its interaction with the other components of the system. Finally, the paper compares our implementation choice with other ongoing projects in the field of energy trading.",Springer
"Baum, Carsten and Bootle, Jonathan and Cerulli, Andrea and del Pino, Rafael and Groth, Jens and Lyubashevsky, Vadim",Sub-linear Lattice-Based Zero-Knowledge Arguments for Arithmetic Circuits,2018,10.1007/978-3-319-96881-0_23,https://doi.org/10.1007/978-3-319-96881-0_23,Conference Paper,Advances in Cryptology -- CRYPTO 2018,"We propose the first zero-knowledge argument with sub-linear communication complexity for arithmetic circuit satisfiability over a prime {\$}{\$}{\{}p{\}}{\$}{\$}whose security is based on the hardness of the short integer solution (SIS) problem. For a circuit with {\$}{\$}{\{}N{\}}{\$}{\$}gates, the communication complexity of our protocol is {\$}{\$}O{\backslash}left( {\backslash}sqrt{\{}{\{}N{\}}{\{}{\backslash}lambda {\}}{\backslash}log ^3{\{}{\{}N{\}}{\}}{\}}{\backslash}right) {\$}{\$}, where {\$}{\$}{\{}{\backslash}lambda {\}}{\$}{\$}is the security parameter. A key component of our construction is a surprisingly simple zero-knowledge proof for pre-images of linear relations whose amortized communication complexity depends only logarithmically on the number of relations being proved. This latter protocol is a substantial improvement, both theoretically and in practice, over the previous results in this line of research of Damg{\aa}rd et al. (CRYPTO 2012), Baum et al. (CRYPTO 2016), Cramer et al. (EUROCRYPT 2017) and del Pino and Lyubashevsky (CRYPTO 2017), and we believe it to be of independent interest.",Springer
"C{\'a}ceres-Ben{\'i}tez, Karen and Marcillo, Ana and Enr{\'i}quez-Ortega, Denisse and Chulde-Fern{\'a}ndez, Bryan and Villalba Meneses, Fernando and Alvarado-Cando, Omar and Almeida-Gal{\'a}rraga, Diego",Creation of an Alert Device for Early Detection of Epilepsy Using an EEG Signal Power Threshold,2023,10.1007/978-3-031-45438-7_20,https://doi.org/10.1007/978-3-031-45438-7_20,Conference Paper,Information and Communication Technologies,"In this study, signal processing techniques such as baseband filters and the wavelet transform method are used to analyze specific patterns in EEG signals from patients with epilepsy, collected from the Siena Scalp database. The goal is to identify predictive indicators of epileptic seizures by analyzing three key points in the fast delta wave: 1) Normal brain activity, 2) Sudden increase in amplitude, and 3) A dead stop. The results obtained will be used for the implementation of an alert device based on the power threshold of the EEG signal, and the comparison of the measured values with the pre-established power threshold. If brain activity exceeds the threshold, the device could issue an alert or signal to indicate that a desired state has been reached or to signal an abnormal or worrisome condition. This text discusses the efficacy of visual analysis of preictal phases and electronic devices for detecting and predicting seizures. Although the study shows evidence for these methods, there were limitations, including a small sample size and the use of a single electronic device.",Springer
"Lam, Chun Kit and Parreaux, Lionel",Being Lazy When It Counts,2024,10.1007/978-981-97-2300-3_11,https://doi.org/10.1007/978-981-97-2300-3_11,Conference Paper,Functional and Logic Programming,"Functional programming (FP) lets users focus on the business logic of their applications by providing them with high-level and composable abstractions. However, both automatic memory management schemes traditionally used for FP, namely tracing garbage collection and reference counting, may introduce latencies in places that can be hard to predict, which limits the applicability of the FP paradigm.",Springer
"Misztal, Krzysztof and S{\l}u{\.{z}}alec, Tomasz and Kubica-Misztal, Aleksandra",Securing Data of Biotechnological Laboratories Using Blockchain Technology,2020,10.1007/978-3-030-47679-3_8,https://doi.org/10.1007/978-3-030-47679-3_8,Conference Paper,Computer Information Systems and Industrial Management,"A few years ago blockchain technology was used in cryptocurrency. Nowadays, a variety of diverse areas are seeing the benefits of applying this technological approach to their needs. One way transactions without reverse mode is making blockchain a desirable platform for maintaining data. The authenticity, transparency and authorization of it make it ideal for healthcare or laboratory data systems. Research data should be authorized by a specific employee and never changed. The information collected should be never forged or falsified. Designing a blockchain system with access and permission rules is ideal in such a situation. In this article, we present the adaptation of blokchain technology to medical research laboratories and diagnostics. Afterwards, an RSA signature user can store information of any type and size. The new SHA-3 hash function is used to bind blocks together. This technological path makes laboratory workflow more efficient and fulfills restriction on medical laws.",Springer
"El Kaafarani, Ali and Katsumata, Shuichi and Solomon, Ravital",Anonymous Reputation Systems Achieving Full Dynamicity from Lattices,2018,10.1007/978-3-662-58387-6_21,https://doi.org/10.1007/978-3-662-58387-6_21,Conference Paper,Financial Cryptography and Data Security,"In this work, we revisit the Anonymous Reputation Systems presented by Bl{\""o}mer et al. in (FC'15). An anonymous reputation system allows users to review/rate products that they have purchased. The main security guarantee that such systems ensure is privacy, i.e., users are allowed to anonymously write reviews for any products which they have purchased. However, to avoid abuse/misuse cases, a review-once-policy is also enforced, i.e., if a user tries to write a second review for the same product, his reviews will be publicly linkable. Therefore, the system manager can revoke this user from the system.",Springer
"McLeod, Cameron Robert and Sasdelli, Michele",Benchmarking D-Wave Quantum Annealers: Spectral Gap Scaling of Maximum Cardinality Matching Problems,2022,10.1007/978-3-031-08760-8_13,https://doi.org/10.1007/978-3-031-08760-8_13,Conference Paper,Computational Science -- ICCS 2022,"Quantum computing, in particular Quantum Annealing (QA), provides a theoretically promising alternative to classical methods for solving combinatorially difficult optimization problems. In particular, QA is suitable for problems that can be formulated as a Quadratic Unconstrained Binary Optimization (QUBO) problem, such as SAT, graph colouring and travelling salesman. With commercially available QA hardware, like that offered by D-Wave Systems (D-Wave), reaching scales capable of tackling real world problems, it is timely to assess and benchmark the performance of this current generation of hardware. This paper empirically investigates the performance of D-Wave's 2000Q (2048 qubits) and Advantage (5640 qubits) quantum annealers in solving a specific instance of the maximum cardinality matching problem, building on the results of a prior paper that investigated the performance of earlier QA hardware from D-Wave. We find that the Advantage quantum annealer is able to produce optimal solutions to larger problem instances than the 2000Q. We further consider the problem's structure and its implications for suitability to QA by utilising the Landau-Zener formula to explore the potential scaling of the diabatic transition probability. We propose a method to investigate the behaviour of minimum energy gaps for scalable problems deployed to quantum annealers. We find that the minimum energy gap for our target QA problem does not scale favourably. This behaviour raises questions as to the suitability of this problem for benchmarking QA hardware, as it potentially lacks the nuance required to identify meaningful performance improvements between generations.",Springer
"da Silva, Arthur Rodrigues and Rodrigues, Rodrigo Ferreira and da Fonseca Vieira, Vin{\'i}cius and Xavier, Carolina Ribeiro",Influence Maximization in Network by Genetic Algorithm on Linear Threshold Model,2018,10.1007/978-3-319-95162-1_7,https://doi.org/10.1007/978-3-319-95162-1_7,Conference Paper,Computational Science and Its Applications -- ICCSA 2018,"The problem of maximum influence on the network consists in the search for a subset of k vertices called seeds which when activated are able to influence as much elements as possible, considering a model to simulate the propagation of influence in a network. This paper proposes a Genetic Algorithm to optimize the selection of seeds for the Linear Threshold Model (LTM), a widely adopted simulation model for influence propagation, by investigating different strategies for initial population configurations based on high centrality nodes. The results obtained by the application of the proposed methodology to the Linear Threshold Model considering real world networks show significant improvements on the convergence of the algorithm.",Springer
"Driessen, Stefan and den Heuvel, Willem-Jan van and Monsieur, Geert",ProMoTe: A Data Product Model Template for Data Meshes,2023,10.1007/978-3-031-47262-6_7,https://doi.org/10.1007/978-3-031-47262-6_7,Conference Paper,Conceptual Modeling,"As the shortcomings of monolithic data platforms such as data lakes are quickly becoming more grave and evident, many organisations are struggling to transition to data meshes, making data available for consumption in a decentralised manner. However, the emerging data mesh paradigm fails to provide sufficient (modelling) support to effectively create, manage, and describe data products, the architectural quanta of a data mesh. In this work, we introduce the data Product Model Template (ProMoTe): a formal meta-model of data products that is fully aligned with a data mesh. ProMoTe was devised, explored and partially validated based on industry requirements in tandem with academic literature and is currently being used by a major Dutch Telecom company to enable their data mesh transition.",Springer
"Yang, Rupeng and Au, Man Ho and Zhang, Zhenfei and Xu, Qiuliang and Yu, Zuoxia and Whyte, William",Efficient Lattice-Based Zero-Knowledge Arguments with Standard Soundness: Construction and Applications,2019,10.1007/978-3-030-26948-7_6,https://doi.org/10.1007/978-3-030-26948-7_6,Conference Paper,Advances in Cryptology -- CRYPTO 2019,"We provide new zero-knowledge argument of knowledge systems that work directly for a wide class of language, namely, ones involving the satisfiability of matrix-vector relations and integer relations commonly found in constructions of lattice-based cryptography. Prior to this work, practical arguments for lattice-based relations either have a constant soundness error {\$}{\$}(2/3){\$}{\$}, or consider a weaker form of soundness, namely, extraction only guarantees that the prover is in possession of a witness that ``approximates'' the actual witness. Our systems do not suffer from these limitations.",Springer
"Chen, Yilei and Vaikuntanathan, Vinod and Wee, Hoeteck","GGH15 Beyond Permutation Branching Programs: Proofs, Attacks, and Candidates",2018,10.1007/978-3-319-96881-0_20,https://doi.org/10.1007/978-3-319-96881-0_20,Conference Paper,Advances in Cryptology -- CRYPTO 2018,"We carry out a systematic study of the GGH15 graded encoding scheme used with general branching programs. This is motivated by the fact that general branching programs are more efficient than permutation branching programs and also substantially more expressive in the read-once setting. Our main results are as follows:Proofs. We present new constructions of private constrained PRFs and lockable obfuscation, for constraints (resp. functions to be obfuscated) that are computable by general branching programs. Our constructions are secure under LWE with subexponential approximation factors. Previous constructions of this kind crucially rely on the permutation structure of the underlying branching programs. Using general branching programs allows us to obtain more efficient constructions for certain classes of constraints (resp. functions), while posing new challenges in the proof, which we overcome using new proof techniques.Attacks. We extend the previous attacks on indistinguishability obfuscation (iO) candidates that use GGH15 encodings. The new attack simply uses the rank of a matrix as the distinguisher, so we call it a ``rank attack''. The rank attack breaks, among others, the iO candidate for general read-once branching programs by Halevi, Halevi, Shoup and Stephens-Davidowitz (CCS 2017).Candidate Witness Encryption and iO. Drawing upon insights from our proofs and attacks, we present simple candidates for witness encryption and iO that resist the existing attacks, using GGH15 encodings. Our candidate for witness encryption crucially exploits the fact that formulas in conjunctive normal form (CNFs) can be represented by general, read-once branching programs.",Springer
"Astarte, Troy Kaighin",What Have Formal Methods Ever Done for Us? An Audience Discussion,2020,10.1007/978-3-030-54997-8_7,https://doi.org/10.1007/978-3-030-54997-8_7,Conference Paper,Formal Methods. FM 2019 International Workshops,"The History of Formal Methods 2019 workshop ended with a discussion reflecting on the discipline of formal methods. An initial prompting question, ``What have formal methods ever done for us?'', was presented, but the discussion evolved from there into consideration of applicability, education, and even Star Trek. The session was chaired and curated by Troy Astarte, who has also prepared this summary of the discussion. It is not a perfect transcription but rather a report on the interesting and stimulating conversation that resulted.",Springer
"Yu, Yang and Ducas, L{\'e}o",Second Order Statistical Behavior of LLL and BKZ,2018,10.1007/978-3-319-72565-9_1,https://doi.org/10.1007/978-3-319-72565-9_1,Conference Paper,Selected Areas in Cryptography -- SAC 2017,"The LLL algorithm (from Lenstra, Lenstra and Lov{\'a}sz) and its generalization BKZ (from Schnorr and Euchner) are widely used in cryptanalysis, especially for lattice-based cryptography. Precisely understanding their behavior is crucial for deriving appropriate key-size for cryptographic schemes subject to lattice-reduction attacks. Current models, e.g.  the Geometric Series Assumption and Chen-Nguyen's BKZ-simulator, have provided a decent first-order analysis of the behavior of LLL and BKZ. However, they only focused on the average behavior and were not perfectly accurate. In this work, we initiate a second order analysis of this behavior. We confirm and quantify discrepancies between models and experiments ---in particular in the head and tail regions--- and study their consequences. We also provide variations around the mean and correlations statistics, and study their impact. While mostly based on experiments, by pointing at and quantifying unaccounted phenomena, our study sets the ground for a theoretical and predictive understanding of LLL and BKZ performances at the second order.",Springer
"Samanta, Ashis Kumar and Chaki, Nabendu",A Game-Based Approach for Mitigating the Sybil Attacks on Blockchain Applications,2023,10.1007/978-3-031-42823-4_9,https://doi.org/10.1007/978-3-031-42823-4_9,Conference Paper,Computer Information Systems and Industrial Management,"The data explosion of this digital century encourages the necessity of data security and maintaining privacy. The generated data through online transactions in different sectors have been increased a million times. Therefore, the trustful transaction and reliability of data became necessary for its analysis and future use in the online platform. The change of data platform from a centralized to distributed nature enhances the utility of the data use, and the security threats are also increased side by side. The Sybil attack is one of the significant security threats in the distributed network environment. Blockchain is a peer-to-peer distributed ledger that works in a distributed environment. However, the blockchain framework, which aims to provide tamper-proof security on data suffers from Sybil attacks too. This paper aims to analyze the implementation of blockchain technology in different applications and propose a new game-based model to effectively detect and mitigate Sybil attacks on the blockchain.",Springer
"Coutinho, Nayara D. and Aquilanti, Vincenzo and Sanches-Neto, Fl{\'a}vio O. and Vaz, Eduardo C. and Carvalho-Silva, Valter H.","First-Principles Molecular Dynamics and Computed Rate Constants for the Series of OH-HX Reactions (X{\thinspace}={\thinspace}H or the Halogens): Non-Arrhenius Kinetics, Stereodynamics and Quantum Tunnel",2018,10.1007/978-3-319-95174-4_47,https://doi.org/10.1007/978-3-319-95174-4_47,Conference Paper,Computational Science and Its Applications -- ICCSA 2018,"This paper is part of a series aiming at elucidating the mechanisms involved in the non-Arrhenius behavior of the four-body OH + HX (X{\thinspace}={\thinspace}H, F,Cl, Br and I) reactions. These reactions are very important in atmospheric chemistry. Additionally, these four-body reactions are also of basic relevance for chemical kinetics. Their kinetics has manifested non-Arrhenius behavior: the experimental rate constants for the OH{\thinspace}+{\thinspace}HCl and OH{\thinspace}+{\thinspace}H2 reactions, when extended to low temperatures, show a concave curvature in the Arrhenius plot, a phenomenon designated as sub-Arrhenius behavior, while reactions with HBr and HI are considered as typical processes that exhibit negative temperature dependence of the rate constants (anti-Arrhenius behavior). From a theoretical point of view, these reactions have been studied in order to obtain the potential energy surface and to reproduce these complex rate constants using the Transition State Theory. Here, in order to understand the non-Arrhenius mechanism, we exploit recent information from ab initio molecular dynamics. For OH{\thinspace}+{\thinspace}HI and OH{\thinspace}+{\thinspace}HBr, the visualizations of rearrangements of bonds along trajectories has shown how molecular reorientation occurs in order that the reactants encounter a mutual angle of approach favorable for them to proceed to reaction. Besides the demonstration of the crucial role of stereodynamics, additional documentation was also provided on the interesting manifestation of the roaming phenomenon, both regarding the search for reactive configurations sterically favorable to reaction and the subsequent departure of products involving their vibrational excitation. Under moderate tunneling regime, the OH{\thinspace}+{\thinspace}H2 reaction was satisfactory described by deformed-Transition-State Theory. In the same reaction, the catalytic effect of water can be assessed by path integral molecular dynamics. For the OH{\thinspace}+{\thinspace}HCl reaction, the theoretical rate coefficients calculated with Bell tunneling correction were in good agreement with experimental data in the entire temperature range 200--2000 K, with minimal effort compared to much more elaborate treatments. Furthermore, the Born-Oppenheimer molecular dynamics simulation showed that the orientation process was less effective than for HBr and HI reactions, emphasizing the role of the quantum tunneling effect of penetration of an energy barrier in the reaction path along the potential energy surface. These results can shed light on the clarification of the different non-Arrhenius mechanisms involved in four-body reaction, providing rate constants and their temperature dependence of relevance for pure and applied chemical kinetics.",Springer
"Boreale, Michele and Collodi, Luisa","Guaranteed Inference for Probabilistic Programs: A Parallelisable, Small-Step Operational Approach",2024,10.1007/978-3-031-50521-8_7,https://doi.org/10.1007/978-3-031-50521-8_7,Conference Paper,"Verification, Model Checking, and Abstract Interpretation","We put forward an approach to the semantics of probabilistic programs centered on an action-based language equipped with a small-step operational semantics. This approach provides benefits in terms of both clarity and effective implementation. Discrete and continuous distributions can be freely mixed, unbounded loops are allowed. In measure-theoretic terms, a product of Markov kernels is used to formalize the small-step operational semantics. This approach directly leads to an exact sampling algorithm that can be efficiently SIMD-parallelized. An observational semantics is also introduced based on a probability space of infinite sequences, along with a finite approximation theorem. Preliminary experiments with a proof-of-concept implementation based on TensorFlow show that our approach compares favourably to state-of-the-art tools for probabilistic programming and inference.",Springer
"Mamonov, Anton and Varlamov, Ruslan and Salpagarov, Soltan",Computing Load Distribution by Using Peer-to-Peer Network,2020,10.1007/978-3-030-66242-4_41,https://doi.org/10.1007/978-3-030-66242-4_41,Conference Paper,"Distributed Computer and Communication Networks: Control, Computation, Communications","Modern computation problems arise that cannot be solved by increasing the number and quality of computers alone. In this work, we develop distributed computing methods.",Springer
"Klein, Bernhard and Kuhn, Lisa and Weis, Johannes and Emmel, Arne and Stradmann, Yannik and Schemmel, Johannes and Fr{\""o}ning, Holger",Towards Addressing Noise and Static Variations of Analog Computations Using Efficient Retraining,2021,10.1007/978-3-030-93736-2_32,https://doi.org/10.1007/978-3-030-93736-2_32,Conference Paper,Machine Learning and Principles and Practice of Knowledge Discovery in Databases,"One of the most promising technologies to solve the energy efficiency problem for artificial neural networks on embedded systems is analog computing, which, however, is fraught with noise due to summations of unwanted or disturbing energy, and static variations related to manufacturing. While these inaccuracies can have a negative effect on the accuracy, in particular for naively deployed networks, the robustness of the networks can be significantly enhanced by a retraining procedure that considers the particular hardware instance. However, this hardware-in-the-loop retraining is very slow and thus often the bottleneck hindering the development of larger networks. Furthermore, it is hardware-instance-specific and requires access to the instance in question.",Springer
"Li, Ziyang","Government Responses to Digital Workforce Shortages: A Study of the U.S., Germany, Japan, and China",2023,10.1007/978-3-031-35936-1_18,https://doi.org/10.1007/978-3-031-35936-1_18,Conference Paper,Cross-Cultural Design,"An effective digital state requires a competent, empowered, and motivated workforce. The world is currently experiencing a digital workforce shortage. Policymakers are taking step to equip the workforce for Industry 4.0 and the digital age. In this study, we chose the U.S., China, Germany, and Japan as the top performers in digitalization and investigated their strategies for cultivating a digital workforce in the last three years. We found they all actively produced numerous plans and actions in scaling and upskilling the digital workforce, such as the US's National Strategy for Advanced Manufacturing, Germany's Data Strategy of the Federal German Government, Japan's Vision for a Digital Garden City Nation, and China's Action Outline for Improving Digital Literacy and Skills for All. Their strategies share common features: (1) enhancing digital skills among the populace to broaden the labor pool; (2) developing school education and social training in digital skills; (3) advancing the digital industries and workforce simultaneously; (4) attracting a global digital qualified workforce. Finally, suggestions were made concerning how global countries can increase the digital literacy of their workforce.",Springer
"Shen, Jingcheng and Wu, Yifan and Okita, Masao and Ino, Fumihiko",Accelerating GPU-Based Out-of-Core Stencil Computation with On-the-Fly Compression,2022,10.1007/978-3-030-96772-7_1,https://doi.org/10.1007/978-3-030-96772-7_1,Conference Paper,"Parallel and Distributed Computing, Applications and Technologies","Stencil computation is an important class of scientific applications that can be efficiently executed by graphics processing units (GPUs). Out-of-core approaches help run large scale stencil codes that process data with sizes larger than the limited capacity of GPU memory. Nevertheless, performance of out-of-core approaches is always limited by the data transfer between the CPU and GPU. Many optimizations have been explored to reduce such data transfer, however, published results on the use of on-the-fly compression are insufficient. In this study, we propose a method that accelerates GPU-based out-of-core stencil computation with on-the-fly compression, introducing a novel data compression scheme that solves the data dependency between contiguous decomposed data blocks. We also modify a widely used GPU-based compression library to support pipelining that overlaps data transfer with computation. Experimental results show that the proposed method achieved a speedup of 1.2{\$}{\$}{\backslash}times {\$}{\$}{\texttimes}compared with a method that involves no compression. Moreover, although precision loss caused by compression increased with the number of time steps, it was trivial up to 4,320 time steps, demonstrating the usefulness of the proposed method.",Springer
"Ribeiro, Maria I. B. and Rog{\~a}o, M{\'a}rcia C. R. and Lopes, Isabel M. and Fernandes, Ant{\'o}nio J. G.",Impact of Technology Revolution on Economic Development Over the Past Decade,2024,10.1007/978-3-031-48930-3_37,https://doi.org/10.1007/978-3-031-48930-3_37,Conference Paper,"Advanced Research in Technologies, Information, Innovation and Sustainability","In the past decade, the exponential development of ICT has generated a fast economic development. So, in order to better understand this phenomenon, a systematic literature review based on the Scopus database was carried out. The majority of the studies was developed in Europe and was secondary (82.4{\%}) and qualitative (64.7{\%}) research. Regarding the microeconomic level, the evidences are: greater efficiency of businesses and companies, improved productivity; reduction of transaction costs; improved profit/economic performance of businesses; creation of closer ties between companies and customers, suppliers and partners/collaborators; changes in the functioning of markets that become more dynamic, challenging and competitive; new ways of production organization, changes in the structure of demand and supply for goods and services; and, the emergence of new products. With regard to the macroeconomic level, the results show that ICT and emerging technologies have positive impacts on innovation, employment, economic and financial development, the human development index, social development, with greater civic participation of citizens in Society, greater social well-being, improvement of living conditions especially in the poorest rural areas, better quality of life, reduction of poverty, although there is also the risk of exclusion of significant parts of Society if not adhered to technologies. There are also researches that highlight the role of ICT in sustainable development (economic, social and environmental). It should be noted that existing studies confirm that the impacts are greater on economic growth when compared to economic development and the human development index.",Springer
"Brorholt, Asger Horn and H{\o}eg-Petersen, Andreas Holck and Larsen, Kim Guldstrand and Schilling, Christian",Efficient Shield Synthesis via State-Space Transformation,2025,10.1007/978-3-031-75434-0_14,https://doi.org/10.1007/978-3-031-75434-0_14,Conference Paper,Bridging the Gap Between AI and Reality,"We consider the problem of synthesizing safety strategies for control systems, also known as shields. Since the state space is infinite, shields are typically computed over a finite-state abstraction, with the most common abstraction being a rectangular grid. However, for many systems, such a grid does not align well with the safety property or the system dynamics. That is why a coarse grid is rarely sufficient, but a fine grid is typically computationally infeasible to obtain. In this paper, we show that appropriate state-space transformations can still allow to use a coarse grid at almost no computational overhead. We demonstrate in three case studies that our transformation-based synthesis outperforms a standard synthesis by several orders of magnitude. In the first two case studies, we use domain knowledge to select a suitable transformation. In the third case study, we instead report on results in engineering a transformation without domain knowledge.",Springer
"Gilbert, Valentin and Rodriguez, Julien and Louise, St{\'e}phane and Sirdey, Renaud",Solving Higher Order Binary Optimization Problems on NISQ Devices: Experiments and Limitations,2023,10.1007/978-3-031-36030-5_18,https://doi.org/10.1007/978-3-031-36030-5_18,Conference Paper,Computational Science -- ICCS 2023,"With the recent availability of Noisy Intermediate-Scale Quantum devices, the potential of quantum computers to impact the field of combinatorial optimization lies in quantum variational and annealing-based methods. This paper further compares Quantum Annealing (QA) and the Quantum Approximate Optimization Algorithm (QAOA) in solving Higher Order Binary Optimization (HOBO) problems. This case study considers the hypergraph partitioning problem, which is used to generate custom HOBO problems. Our experiments show that D-Wave systems quickly reach limits solving dense HOBO problems. Although the QAOA demonstrates better performance on exact simulations, noisy simulations reveal that the gate error rate should remain under {\$}{\$}10^{\{}-5{\}}{\$}{\$}to match D-Wave systems' performance, considering equal compilation overheads for both device.",Springer
"Liang, Xiao and Wang, Xiaohui and Zhang, Qianyi and Yuan, Shuai and Guan, Zhitao",A Lattice-Based Multisignature Scheme for Blockchain-Enabled Systems,2023,10.1007/978-981-19-9697-9_27,https://doi.org/10.1007/978-981-19-9697-9_27,Conference Paper,Emerging Networking Architecture and Technologies,"Multisignature scheme enables a class of users to produce a signature interactively on a shared message, thus significantly reducing the signature size. This is especially important in blockchain-enabled systems where a consensus is required to complete a transaction. However, most existing approaches are constructed based upon traditional problems, for example, the integer factoring assumption and the discrete logarithm assumption, which in turn bear the risk of quantum computing attacks. Although lattice-based solutions are considered in some studies, the computational overhead due to high level of interaction becomes a major concern. In this paper, we present a new lattice-based multisignature scheme, which is constructed upon Bimodal Lattice Signature Scheme (BLISS). Next, we apply it to the blockchain-enabled systems through the demonstration of a cryptocurrency transaction. At last, we compare the proposed model with existing works on the performance. The result shows that our work can satisfy the security and efficiency concerns of the blockchain-enabled systems.",Springer
"Degabriele, Jean Paul and Stam, Martijn",Untagging Tor: A Formal Treatment of Onion Encryption,2018,10.1007/978-3-319-78372-7_9,https://doi.org/10.1007/978-3-319-78372-7_9,Conference Paper,Advances in Cryptology -- EUROCRYPT 2018,"Tor is a primary tool for maintaining anonymity online. It provides a low-latency, circuit-based, bidirectional secure channel between two parties through a network of onion routers, with the aim of obscuring exactly who is talking to whom, even to adversaries controlling part of the network. Tor relies heavily on cryptographic techniques, yet its onion encryption scheme is susceptible to tagging attacks (Fu and Ling 2009), which allow an active adversary controlling the first and last node of a circuit to deanonymize with near-certainty. This contrasts with less active traffic correlation attacks, where the same adversary can at best deanonymize with high probability. The Tor project has been actively looking to defend against tagging attacks and its most concrete alternative is proposal 261, which specifies a new onion encryption scheme based on a variable-input-length tweakable cipher.",Springer
"Petzoldt, Albrecht and Szepieniec, Alan and Mohamed, Mohamed Saied Emam",A Practical Multivariate Blind Signature Scheme,2017,10.1007/978-3-319-70972-7_25,https://doi.org/10.1007/978-3-319-70972-7_25,Conference Paper,Financial Cryptography and Data Security,"Multivariate Cryptography is one of the main candidates for creating post-quantum cryptosystems. Especially in the area of digital signatures, there exist many practical and secure multivariate schemes. However, there is a lack of multivariate signature schemes with special properties such as blind, ring and group signatures. In this paper, we propose a generic technique to transform the Rainbow multivariate signature scheme into a blind signature schemes. The resulting scheme satisfies the usual blindness criterion and a one-more-unforgeability criterion adapted to MQ signatures, produces short blind signatures and is very efficient.",Springer
"Li, Jiahao and Agung, Mulya and Takizawa, Hiroyuki",Evaluating the Performance and Conformance of a SYCL Implementation for SX-Aurora TSUBASA,2022,10.1007/978-3-030-96772-7_4,https://doi.org/10.1007/978-3-030-96772-7_4,Conference Paper,"Parallel and Distributed Computing, Applications and Technologies","SX-Aurora TSUBASA (SX-AT) is a vector supercomputer equipped with Vector Engines (VEs). SX-AT has not only such a new system architecture, but also some execution modes to achieve high performance on executing a real-world application that often consists of vector friendly and unfriendly parts. Vector Engine Offloading (VEO) is a programming framework to offload only a vector-friendly part to VEs, and neoSYCL has been developed on top of VEO to allow programmers to use the standard SYCL interface at offload programming on SX-AT. However, it is unclear how much neoSYCL based on VEO can conform to the SYCL standard, which is primarily based on OpenCL. Therefore, this paper discusses the conformance of neoSYCL to the SYCL standard, and also the performance. Our thorough evaluation with SYCL-Bench kernels demonstrates that neoSYCL is conformant to the SYCL standard except for OpenCL-related features. In addition, the runtime overhead for using the SYCL interface on top of VEO is negligible in most cases, allowing the neoSYCL codes to achieve comparable performance with the VEO codes.",Springer
"Kanamori, Issaku and Matsufuru, Hideo",Practical Implementation of Lattice QCD Simulation on SIMD Machines with Intel AVX-512,2018,10.1007/978-3-319-95168-3_31,https://doi.org/10.1007/978-3-319-95168-3_31,Conference Paper,Computational Science and Its Applications -- ICCSA 2018,"We investigate implementation of lattice Quantum Chromodynamics (QCD) code on the Intel AVX-512 architecture. The most time consuming part of the numerical simulations of lattice QCD is a solver of linear equation for a large sparse matrix that represents the strong interaction among quarks. To establish widely applicable prescriptions, we examine rather general methods for the SIMD architecture of AVX-512, such as using intrinsics and manual prefetching, for the matrix multiplication. Based on experience on the Oakforest-PACS system, a large scale cluster composed of Intel Xeon Phi Knights Landing, we discuss the performance tuning exploiting AVX-512 and code design on the SIMD architecture and massively parallel machines. We observe that the same code runs efficiently on an Intel Xeon Skylake-SP machine.",Springer
"Duda, Piotr and Rutkowski, Leszek and Woldan, Piotr and Najgebauer, Patryk",The Streaming Approach to Training Restricted Boltzmann Machines,2021,10.1007/978-3-030-87986-0_27,https://doi.org/10.1007/978-3-030-87986-0_27,Conference Paper,Artificial Intelligence and Soft Computing,"One of the greatest challenges facing researchers of machine learning algorithms nowadays is the desire to minimize the training time of these algorithms. One of the most promising and unexplored structures of the neural network is the Restricted Boltzmann Machine. In this paper, we propose to use the BBTADD algorithm for RBM training. The performance of the algorithm has been illustrated on one of the most popular data sets.",Springer
"Bruckner, S. and Ferrarotti, F. and Ramler, R. and Wille, R. and Hillmich, S.",Towards Solving Short-Term Generation Scheduling Problems on Quantum Computers,2025,10.1007/978-3-031-78392-0_11,https://doi.org/10.1007/978-3-031-78392-0_11,Conference Paper,"Product-Focused Software Process Improvement. Industry-, Workshop-, and Doctoral Symposium Papers","Identifying possible use cases for quantum computers is important to evaluate the potential. This work-in-progress paper explores their potential for addressing the short-term generation scheduling (STGS) problem in hydropower plants. By working towards reformulating the STGS problem as a quadratic unconstrained binary optimization (QUBO) problem, we aim to leverage the capabilities of quantum computers to find optimal solutions. Initial results using piecewise linear approximation indicate promising outcomes. Further research will focus on the QUBO formulation, implementing the approach on quantum hardware, and assessing its performance.",Springer
"Sijpesteijn, Thom and Phillipson, Frank",Quantum Approaches for Medoid Clustering,2023,10.1007/978-3-031-40852-6_12,https://doi.org/10.1007/978-3-031-40852-6_12,Conference Paper,Innovations for Community Services,"The {\$}{\$}k{\$}{\$}k-medoids problem is an important problem in data clustering, which aims to partition a set of data points into {\$}{\$}k{\$}{\$}kclusters, where each cluster is represented by a medoid, i.e., a data point that is the most centrally located in the cluster. Quantum annealing might be helpful in finding the solution to this problem faster. In this paper we compare three approaches for using the quantum annealer and QUBO-formulations to solve the {\$}{\$}k{\$}{\$}k-medoids problem. The first approach revolves around a QUBO that encodes the problem as a whole. This approach turns out not to scale well for bigger problem sizes. The QUBO in the second approach comes from the literature and solves only the problem of finding medoids: assigning the datapoints to clusters requires an additional step. The QUBO formulation in the third approach is the same as in the second, but with different penalty parameters. We show that the second and third approaches scale better in terms of complexity than the first approach. However, the original penalty parameters in approach 2 (i.e. those suggested in the literature) do not work well for bigger instances. Taking different parameters makes this approach much better in performance.",Springer
"Barat, Souvik and Kulkarni, Vinay and Paranjape, Aditya and Dhandapani, Subramaniam and Manuelraj, Solomon and Parameswaran, Sai Prasad",Agent Based Digital Twin of Sorting Terminal to Improve Efficiency and Resiliency in Parcel Delivery,2022,10.1007/978-3-031-18192-4_3,https://doi.org/10.1007/978-3-031-18192-4_3,Conference Paper,"Advances in Practical Applications of Agents, Multi-Agent Systems, and Complex Systems Simulation. The PAAMS Collection","Open economy, globalization and effect of Covid19 pandemic are transforming the consumer behavior rapidly. The business is nudging consumers towards hyper consumption through online shopping, e-commerce and other conveniences with affordable cost. The companies from courier, express and parcel (CEP) industry are trying to capitalize on this opportunity by tying up with business to consumers (B2C) companies with a promise of delivering parcels to the doorstep in an ever-shrinking time window. In this endeavor, the conventional optimization-based planning approach to manage the fixed parcel payload is turning out to be inadequate. The CEP companies need to quickly adapt to the situation more frequently so as to be efficient and resilient in this growing demand situation. We propose an agent-based digital twin of the sorting terminal, a key processing element of parcel delivery operation, as an experimentation aid to: (i) explore and arrive at the right configuration of the existing sorting terminal infrastructure, (ii) be prepared for possible outlier conditions, and (iii) identify plausible solutions for mitigating the outlier conditions in an evidence-backed manner. This paper presents digital twin of the sorting terminal and demonstrates its use as ``in silico'' experimentation aid for domain experts to support evidence-backed decision-making.",Springer
"Preston, Lauren and Shivashankar",Sub-exponential ML Algorithm for Predicting Ground State Properties,2023,10.1007/978-3-031-36030-5_5,https://doi.org/10.1007/978-3-031-36030-5_5,Conference Paper,Computational Science -- ICCS 2023,"Analysing properties of ground state of a quantum systems, is an important problem with applications in various domains. Recently, Huang et al. [2021] demonstrate how machine learning algorithms can be used to efficiently solve this problem with formal guarantees. However this method requires an exponential amount of data to train. In this work we show a method with improved efficiency for a wide class of energy operator. In particular, we show an ML-based method for predicting ground state properties for structured Hamiltonian with sub-exponential scaling in training data. The method relies on efficiently learning low-degree approximation of the energy operator.",Springer
"Burek, El{\.{z}}bieta and Wro{\'{n}}ski, Micha{\l}",Quantum Annealing and Algebraic Attack on Speck Cipher,2022,10.1007/978-3-031-08760-8_12,https://doi.org/10.1007/978-3-031-08760-8_12,Conference Paper,Computational Science -- ICCS 2022,"Algebraic attacks using quantum annealing are a new idea of cryptanalysis. This paper shows how to obtain a QUBO problem equivalent to the algebraic attack on the Speck cipher, using as small a number of logical variables as possible. The main idea of minimizing the number of variables in the algebraic attack on this ARX cipher was appropriate cipher partition and insertion of additional variables. Using such an idea, in the case of the most popular variants: Speck-128/128 and Speck-128/256, the equivalent QUBO problem has 19,311 and 33,721 logical variables, which is more efficient than the same attack on AES cipher, where for AES-128 and AES-256, an equivalent QUBO problem consist of 29,770 and 72,597 logical variables, respectively. It is an open question if this kind of attack may overtake, in some cases, brutal or Grover's attack.",Springer
"Xue, Haiyang and Lu, Xianhui and Li, Bao and Liang, Bei and He, Jingnan",Understanding and Constructing AKE via Double-Key Key Encapsulation Mechanism,2018,10.1007/978-3-030-03329-3_6,https://doi.org/10.1007/978-3-030-03329-3_6,Conference Paper,Advances in Cryptology -- ASIACRYPT 2018,"Motivated by abstracting the common idea behind several implicitly authenticated key exchange (AKE) protocols, we introduce a primitive that we call double-key key encapsulation mechanism (2-key KEM). It is a special type of KEM involving two pairs of secret-public keys and satisfying some function and security property. Such 2-key KEM serves as the core building block and provides alternative approaches to simplify the constructions of AKE. To see the usefulness of 2-key KEM, we show how several existing constructions of AKE can be captured as 2-key KEM and understood in a unified framework, including widely used HMQV, NAXOS, Okamoto-AKE, and FSXY12-13 schemes. Then, we show (1) how to construct 2-key KEM from concrete assumptions, (2) how to adapt the classical Fujisaki-Okamoto transformation and KEM combiner to achieve the security requirement of 2-key KEM, (3) an elegant Kyber-AKE over lattice using the improved Fujisaki-Okamoto technique.",Springer
"Ozhigov, Yuri",On the Prospects of Quantum Computing in Models of Social Behavior,2021,10.1007/978-3-030-92864-3_28,https://doi.org/10.1007/978-3-030-92864-3_28,Conference Paper,Supercomputing,"The development of supercomputer technologies naturally leads to the use of the quantum language not only at the level of the element base, as in existing computers, but also in the logic of the computations themselves. It is shown how the transition to a quantum language in Computer Science will allow the use of a single mathematical apparatus and computational methods in such different fields as chemistry and social behavior. The importance of the quantum approach to sociology is justified in the concept of the Khrennikov ``social laser''. This paper provides a precise justification for the ``crowd effect'' - the peak-like nature of the excitement of large social groups, based on the Tavis-Cummings-Hubbard model.",Springer
"Lebedev, Anton and {\c{S}}ahin, M. Emre and Warford, Thomas",A Bayesian Optimization Through Sequential Monte Carlo and Statistical Physics-Inspired Techniques,2023,10.1007/978-3-031-36030-5_49,https://doi.org/10.1007/978-3-031-36030-5_49,Conference Paper,Computational Science -- ICCS 2023,"In this paper, we propose an approach for an application of Bayesian optimization using Sequential Monte Carlo (SMC) and concepts from the statistical physics of classical systems. Our method leverages the power of modern machine learning libraries such as NumPyro and JAX, allowing us to perform Bayesian optimization on multiple platforms, including CPUs, GPUs, TPUs, and in parallel. Our approach enables a low entry level for exploration of the methods while maintaining high performance. We present a promising direction for developing more efficient and effective techniques for a wide range of optimization problems in diverse fields.",Springer
"Ohmura, Tatsuyoshi and Shimomura, Yoichi and Egawa, Ryusuke and Takizawa, Hiroyuki",Toward Building a Digital Twin of Job Scheduling and Power Management on an HPC System,2023,10.1007/978-3-031-22698-4_3,https://doi.org/10.1007/978-3-031-22698-4_3,Conference Paper,Job Scheduling Strategies for Parallel Processing,"The purpose of this work is to reduce the burden on system administrators by virtually reproducing job scheduling and power management of their target systems and thereby helping them properly configure the system parameters and policies. Specifically, this paper focuses on a real computing system, named Supercomputer AOBA, as an example to discuss the importance of accurately reproducing the behaviors of job scheduling in the simulation. Since AOBA uses some special power saving features that are not supported by any existing job scheduling simulators, we have first implemented a component for a job scheduling simulator to support the special features, and thus to build a``Digital Twin`` of AOBA's job scheduler. By using the Digital Twin with actual operation data, a system administrator can check if the system is efficiently used in terms of computational performance and power efficiency. This paper shows a use case of exploring appropriate scheduling and power saving parameters. In the use case, we found that there are more appropriate parameter configurations, which can reduce the job waiting time by 70{\%} at most and the energy consumption by 1.2{\%} at most when the system is busy. By exploiting such a Digital Twin, therefore, it is demonstrated the feasibility that a system administrator can properly adjust various parameters without disturbing the system operation.",Springer
"de Boer, Koen and Ducas, L{\'e}o and Pellet-Mary, Alice and Wesolowski, Benjamin",Random Self-reducibility of Ideal-SVP via Arakelov Random Walks,2020,10.1007/978-3-030-56880-1_9,https://doi.org/10.1007/978-3-030-56880-1_9,Conference Paper,Advances in Cryptology -- CRYPTO 2020,"Fixing a number field, the space of all ideal lattices, up to isometry, is naturally an abelian group, called the Arakelov class group. This fact, well known to number theorists, has so far not been explicitly used in the literature on lattice-based cryptography. Remarkably, the Arakelov class group is a combination of two groups that have already led to significant cryptanalytic advances: the class group and the unit torus.",Springer
"Zhang, Huang and Zhang, Fangguo and Tian, Haibo and Au, Man Ho",Anonymous Post-Quantum Cryptocash,2018,10.1007/978-3-662-58387-6_25,https://doi.org/10.1007/978-3-662-58387-6_25,Conference Paper,Financial Cryptography and Data Security,"In this paper, we construct an anonymous and decentralized cryptocash system which is potentially secure against quantum computers. In order to achieve that, a linkable ring signature based on ideal lattices is proposed. The size of a signature in our scheme is {\$}{\$}O({\backslash}log N){\$}{\$}, where N is the cardinality of the ring. The framework of our cryptocash system follows that of CryptoNote with some modifications. By adopting the short quantum-resistant linkable ring signature scheme, our system is anonymous and efficient. We also introduce how to generate the verifying and signing key pairs of the linkable ring signature temporarily. With these techniques, the privacy of users is protected, even though their transactions are recorded in the public ledger.",Springer
"Zou, Xintong and Zhang, Yunjie",Enhanced Low Rank Tensor Multi View Clustering,2025,10.1007/978-3-031-71079-7_2,https://doi.org/10.1007/978-3-031-71079-7_2,Conference Paper,Computer and Communication Engineering,"Multi-way or tensor data analysis has attracted increasing attention recently, with many important applications in practice. In recent years, scholars have proposed many multi-view clustering methods based on tensor low rank representation. However, most of them use t-svd based kernel norms that have a strong dependence on low rank, making it difficult to flexibly handle image restoration problems in different scenarios and achieve good clustering results. Inspired by the ideas used in the enhanced tensor robust principal component analysis model, this paper proposes an enhanced low rank tensor multi view clustering method. Similar to the TLRR method, this method represents the multi view clustering problem of data as a low rank tensor learning problem, which is solved through the alternating direction method of multipliers. The experimental results on three image datasets show that this method is more efficient than existing methods.",Springer
"Agrawal, Shweta",Indistinguishability Obfuscation Without Multilinear Maps: New Methods for Bootstrapping and Instantiation,2019,10.1007/978-3-030-17653-2_7,https://doi.org/10.1007/978-3-030-17653-2_7,Conference Paper,Advances in Cryptology -- EUROCRYPT 2019,"Constructing indistinguishability obfuscation ({\$}{\$}{\backslash}mathsf{\{}iO{\}}{\$}{\$}iO) [17] is a central open question in cryptography. We provide new methods to make progress towards this goal. Our contributions may be summarized as follows:1.Bootstrapping. In a recent work, Lin and Tessaro [71] (LT) show that {\$}{\$}{\backslash}mathsf{\{}iO{\}}{\$}{\$}iOmay be constructed using (i) Functional Encryption ({\$}{\$}{\backslash}mathsf {\{}FE{\}}{\$}{\$}FE) for polynomials of degree L, (ii) Pseudorandom Generators ({\$}{\$}{\backslash}mathsf{\{}PRG{\}}{\$}{\$}PRG) with blockwise locality L and polynomial expansion, and (iii) Learning With Errors ({\$}{\$}{\backslash}mathsf{\{}LWE{\}}{\$}{\$}LWE). Since there exist constructions of {\$}{\$}{\backslash}mathsf {\{}FE{\}}{\$}{\$}FEfor quadratic polynomials from standard assumptions on bilinear maps [16, 68], the ideal scenario would be to set {\$}{\$}L=2{\$}{\$}L=2, yielding {\$}{\$}{\backslash}mathsf{\{}iO{\}}{\$}{\$}iOfrom widely believed assumptionsUnfortunately, it was shown soon after [18, 73] that {\$}{\$}{\backslash}mathsf{\{}PRG{\}}{\$}{\$}PRGwith block locality 2 and the expansion factor required by the LT construction, concretely {\$}{\$}{\backslash}varOmega (n {\backslash}cdot 2^{\{}b(3+{\backslash}epsilon ){\}}){\$}{\$}$\Omega$(n{\textperiodcentered}2b(3+ç¼ä¾å½é·ï¿? where n is the input length and b is the block length, do not exist. In the worst case, these lower bounds rule out 2-block local {\$}{\$}{\backslash}mathsf{\{}PRG{\}}{\$}{\$}PRGwith stretch {\$}{\$}{\backslash}varOmega (n {\backslash}cdot 2^{\{}b(2+{\backslash}epsilon ){\}}){\$}{\$}$\Omega$(n{\textperiodcentered}2b(2+ç¼ä¾å½é·ï¿? While [18, 73] provided strong negative evidence for constructing {\$}{\$}{\backslash}mathsf{\{}iO{\}}{\$}{\$}iObased on bilinear maps, they could not rule out the possibility completely; a tantalizing gap has remained. Given the current state of lower bounds, the existence of 2 block local {\$}{\$}{\backslash}mathsf{\{}PRG{\}}{\$}{\$}PRGwith expansion factor {\$}{\$}{\backslash}varOmega (n {\backslash}cdot 2^{\{}b(1+{\backslash}epsilon ){\}}){\$}{\$}$\Omega$(n{\textperiodcentered}2b(1+ç¼ä¾å½é·ï¿½remains open, although this stretch does not suffice for the LT bootstrapping, and is hence unclear to be relevant for {\$}{\$}{\backslash}mathsf{\{}iO{\}}{\$}{\$}iO.In this work, we improve the state of affairs as follows.(a)Weakening requirements on Boolean PRGs: In this work, we show that the narrow window of expansion factors left open by lower bounds do suffice for {\$}{\$}{\backslash}mathsf{\{}iO{\}}{\$}{\$}iO. We show a new method to construct {\$}{\$}{\backslash}mathsf {\{}FE{\}}{\$}{\$}FEfor {\$}{\$}{\backslash}mathsf {\{}NC{\}}{\_}1{\$}{\$}NC1from (i) {\$}{\$}{\backslash}mathsf {\{}FE{\}}{\$}{\$}FEfor degree L polynomials, (ii) {\$}{\$}{\backslash}mathsf{\{}PRG{\}}{\$}{\$}PRGs of block locality L and expansion factor {\$}{\$}{\backslash}tilde{\{}{\backslash}varOmega {\}}(n {\backslash}cdot 2^{\{}b(1+{\backslash}epsilon ){\}}){\$}{\$}$\Omega${\textasciitilde}(n{\textperiodcentered}2b(1+ç¼ä¾å½é·ï¿? and (iii) {\$}{\$}{\backslash}mathsf{\{}LWE{\}}{\$}{\$}LWE(or {\$}{\$}{\backslash}mathsf{\{}RLWE{\}}{\$}{\$}RLWE).(b)Broadening class of sufficient randomness generators: Our bootstrapping theorem may be instantiated with a broader class of pseudorandom generators than hitherto considered for {\$}{\$}{\backslash}mathsf{\{}iO{\}}{\$}{\$}iO, and may circumvent lower bounds known for the arithmetic degree of {\$}{\$}{\backslash}mathsf{\{}iO{\}}{\$}{\$}iO-sufficient {\$}{\$}{\backslash}mathsf{\{}PRG{\}}{\$}{\$}PRGs [18, 73]; in particular, these may admit instantiations with arithmetic degree 2, yielding {\$}{\$}{\backslash}mathsf{\{}iO{\}}{\$}{\$}iOwith the additional assumptions of {\$}{\$}{\backslash}mathsf{\{}SXDH{\}}{\$}{\$}SXDHon Bilinear maps and {\$}{\$}{\backslash}mathsf{\{}LWE{\}}{\$}{\$}LWE. In more detail, we may use the following two classes of {\$}{\$}{\backslash}mathsf{\{}PRG{\}}{\$}{\$}PRG:i.Non-Boolean PRGs: We may use pseudorandom generators whose inputs and outputs need not be Boolean but may be integers restricted to a small (polynomial) range. Additionally, the outputs are not required to be pseudorandom but must only satisfy a milder indistinguishability property (We note that our notion of non Boolean PRGs is qualitatively similar to the notion of {\$}{\$}{\backslash}varDelta {\$}{\$}$\Delta$RGs defined in the concurrent work of Ananth, Jain and Sahai [9]. We emphasize that the methods of [9] and the present work are very different, but both works independently discover the same notion of weak PRG as sufficient for building {\$}{\$}{\backslash}mathsf{\{}iO{\}}{\$}{\$}iO.).ii.Correlated Noise Generators: We introduce an even weaker class of pseudorandom generators, which we call correlated noise generators ({\$}{\$}{\backslash}mathsf{\{}CNG{\}}{\$}{\$}CNG) which may not only be non-Boolean but are required to satisfy an even milder (seeming) indistinguishability property than {\$}{\$}{\backslash}varDelta {\$}{\$}$\Delta$RG.(c)Assumptions and Efficiency. Our bootstrapping theorems can be based on the hardness of the Learning With Errors problem or its ring variant ({\$}{\$}{\backslash}mathsf{\{}LWE{\}}/ {\backslash}mathsf{\{}RLWE{\}}{\$}{\$}LWE/RLWE) and can compile {\$}{\$}{\backslash}mathsf {\{}FE{\}}{\$}{\$}FEfor degree L polynomials directly to {\$}{\$}{\backslash}mathsf {\{}FE{\}}{\$}{\$}FEfor {\$}{\$}{\backslash}mathsf {\{}NC{\}}{\_}1{\$}{\$}NC1. Previous work compiles {\$}{\$}{\backslash}mathsf {\{}FE{\}}{\$}{\$}FEfor degree L polynomials to {\$}{\$}{\backslash}mathsf {\{}FE{\}}{\$}{\$}FEfor {\$}{\$}{\backslash}mathsf {\{}NC{\}}{\_}0{\$}{\$}NC0to {\$}{\$}{\backslash}mathsf {\{}FE{\}}{\$}{\$}FEfor {\$}{\$}{\backslash}mathsf {\{}NC{\}}{\_}1{\$}{\$}NC1to {\$}{\$}{\backslash}mathsf{\{}iO{\}}{\$}{\$}iO[12, 45, 68, 72].Our method for bootstrapping to {\$}{\$}{\backslash}mathsf {\{}NC{\}}{\_}1{\$}{\$}NC1does not go via randomized encodings as in previous works, which makes it simpler and more efficient than in previous works.2.Instantiating Primitives. In this work, we provide the first direct candidate of {\$}{\$}{\backslash}mathsf {\{}FE{\}}{\$}{\$}FEfor constant degree polynomials from new assumptions on lattices. Our construction is new and does not go via multilinear maps or graded encoding schemes as all previous constructions. Together with the bootstrapping step above, this yields a completely new candidate for {\$}{\$}{\backslash}mathsf{\{}iO{\}}{\$}{\$}iO(as well as {\$}{\$}{\backslash}mathsf {\{}FE{\}}{\$}{\$}FEfor {\$}{\$}{\backslash}mathsf {\{}NC{\}}{\_}1{\$}{\$}NC1), which makes no use of multilinear or even bilinear maps. Our construction is based on the ring learning with errors assumption ({\$}{\$}{\backslash}mathsf{\{}RLWE{\}}{\$}{\$}RLWE) as well as new untested assumptions on NTRU rings.We provide a detailed security analysis and discuss why previously known attacks in the context of multilinear maps, especially zeroizing and annihilation attacks, do not appear to apply to our setting. We caution that our construction must yet be subject to rigorous cryptanalysis by the community before confidence can be gained in its security. However, we believe that the significant departure from known multilinear map based constructions opens up a new and potentially fruitful direction to explore in the quest for {\$}{\$}{\backslash}mathsf{\{}iO{\}}{\$}{\$}iO.Our construction is based entirely on lattices, due to which one may hope for post quantum security. Note that this feature is not enjoyed by instantiations that make any use of bilinear maps even if secure instances of weak PRGs, as identified by the present work, the follow-up by Lin and Matt [69] and the independent work by Ananth, Jain and Sahai [9] are found.",Springer
"Han, Jihun and Lee, Yoonsang",Hierarchical Learning to Solve PDEs Using Physics-Informed Neural Networks,2023,10.1007/978-3-031-36024-4_42,https://doi.org/10.1007/978-3-031-36024-4_42,Conference Paper,Computational Science -- ICCS 2023,"The neural network-based approach to solving partial differential equations has attracted considerable attention. In training a neural network, the network learns global features corresponding to low-frequency components while high-frequency components are approximated at a much slower rate. For a class of equations in which the solution contains a wide range of scales, the network training process can suffer from slow convergence and low accuracy due to its inability to capture the high-frequency components. In this work, we propose a sequential training based on a hierarchy of networks to improve the convergence rate and accuracy of the neural network solution to partial differential equations. The proposed method comprises multi-training levels in which a newly introduced neural network is guided to learn the residual of the previous level approximation. We validate the efficiency and robustness of the proposed hierarchical approach through a suite of partial differential equations.",Springer
"Fathi Hafshejani, Sajad and Gaur, Daya and Hossain, Shahadat and Benkoczi, Robert",Binary Orthogonal Non-negative Matrix Factorization,2023,10.1007/978-981-99-1642-9_3,https://doi.org/10.1007/978-981-99-1642-9_3,Conference Paper,Neural Information Processing,We propose a method for computing binary orthogonal non-negative matrix factorization (BONMF) for clustering and classification. The method is tested on several representative real-world data sets. The numerical results confirm that the method has improved accuracy compared to the related techniques. The proposed method is fast for training and classification and space efficient.,Springer
"Fuchsbauer, Georg and Orr{\`u}, Michele and Seurin, Yannick",Aggregate Cash Systems: A Cryptographic Investigation of Mimblewimble,2019,10.1007/978-3-030-17653-2_22,https://doi.org/10.1007/978-3-030-17653-2_22,Conference Paper,Advances in Cryptology -- EUROCRYPT 2019,"Mimblewimble is an electronic cash system proposed by an anonymous author in 2016. It combines several privacy-enhancing techniques initially envisioned for Bitcoin, such as Confidential Transactions (Maxwell, 2015), non-interactive merging of transactions (Saxena, Misra, Dhar, 2014), and cut-through of transaction inputs and outputs (Maxwell, 2013). As a remarkable consequence, coins can be deleted once they have been spent while maintaining public verifiability of the ledger, which is not possible in Bitcoin. This results in tremendous space savings for the ledger and efficiency gains for new users, who must verify their view of the system.",Springer
"N{\""u}{\ss}lein, Jonas and Roch, Christoph and Gabor, Thomas and Stein, Jonas and Linnhoff-Popien, Claudia and Feld, Sebastian",Black Box Optimization Using QUBO and the Cross Entropy Method,2023,10.1007/978-3-031-36030-5_4,https://doi.org/10.1007/978-3-031-36030-5_4,Conference Paper,Computational Science -- ICCS 2023,"Black-box optimization (BBO) can be used to optimize functions whose analytic form is unknown. A common approach to realising BBO is to learn a surrogate model which approximates the target black-box function which can then be solved via white-box optimization methods. In this paper, we present our approach BOX-QUBO, where the surrogate model is a QUBO matrix. However, unlike in previous state-of-the-art approaches, this matrix is not trained entirely by regression, but mostly by classification between ``good'' and ``bad'' solutions. This better accounts for the low capacity of the QUBO matrix, resulting in significantly better solutions overall. We tested our approach against the state-of-the-art on four domains and in all of them BOX-QUBO showed better results. A second contribution of this paper is the idea to also solve white-box problems, i.e. problems which could be directly formulated as QUBO, by means of black-box optimization in order to reduce the size of the QUBOs to the information-theoretic minimum. Experiments show that this significantly improves the results for MAX-k-SAT.",Springer
"Zhang, Zhengyu and Wei, Puwen and Xue, Haiyang",Tighter Security Proofs for Post-quantum Key Encapsulation Mechanism in the Multi-challenge Setting,2019,10.1007/978-3-030-31578-8_8,https://doi.org/10.1007/978-3-030-31578-8_8,Conference Paper,Cryptology and Network Security,"Due to the threat posed by quantum computers, a series of works investigate the security of cryptographic schemes in the quantum-accessible random oracle model (QROM) where the adversary can query the random oracle in superposition. In this paper, we present tighter security proofs of a generic transformations for key encapsulation mechanism (KEM) in the QROM in the multi-challenge setting, where the reduction loss is independent of the number of challenge ciphertexts. In particular, we introduce the notion of multi-challenge OW-CPA (mOW-CPA) security, which captures the one-wayness of the underlying public key encryption (PKE) under chosen plaintext attack in the multi-challenge setting. We show that the multi-challenge IND-CCA (mIND-CCA) security of KEM can be reduced to the mOW-CPA security of the underlying PKE scheme (with {\$}{\$}{\backslash}delta {\$}{\$}-correctness) using transformation. Then we prove that the mOW-CPA security can be tightly reduced to the underlying post-quantum assumptions by showing the tight mOW-CPA security of two concrete PKE schemes based on LWE, where one is the Regev's PKE scheme and the other is a variant of Frodo.",Springer
"Wro{\'{n}}ski, Micha{\l}",Practical Solving of Discrete Logarithm Problem over Prime Fields Using Quantum Annealing,2022,10.1007/978-3-031-08760-8_8,https://doi.org/10.1007/978-3-031-08760-8_8,Conference Paper,Computational Science -- ICCS 2022,"This paper investigates how to reduce discrete logarithm problem over prime fields to the QUBO problem to obtain as few logical qubits as possible. We show different methods of reduction of discrete logarithm problem over prime fields to the QUBO problem. In the best case, if n is the bitlength of a characteristic of the prime field {\$}{\$}{\backslash}mathbb F{\_}p{\$}{\$}Fp, there are required approximately {\$}{\$}2n^2{\$}{\$}2n2logical qubits for such reduction. We present practical attacks on discrete logarithm problem over the 4-bit prime field {\$}{\$}{\backslash}mathbb F{\_}{\{}11{\}}{\$}{\$}F11, over 5-bit prime field {\$}{\$}{\backslash}mathbb F{\_}{\{}23{\}}{\$}{\$}F23and over 6-bit prime field {\$}{\$}{\backslash}mathbb F{\_}{\{}59{\}}{\$}{\$}F59. We solved these problems using D-Wave Advantage QPU. It is worth noting that, according to our knowledge, until now, no one has made a practical attack on discrete logarithm over the prime field using quantum methods.",Springer
"Peng, Chunyan and Du, Xiujuan",New Lattice-Based Digital Multi-signature Scheme,2020,10.1007/978-981-15-7984-4_10,https://doi.org/10.1007/978-981-15-7984-4_10,Conference Paper,Data Science,"The traditional digital multi-signature schemes are mostly based on large integer factorization and the discrete logarithm, which cannot be secured in quantum environment. The paper presents a lattice-based multi-signature scheme that can resist the quantum attack using the hardness of average-case short integer solution problem (SIS). Multi-signature includes the simultaneous signature and sequential signature. The paper describes respectively the key generation, multi-signature generation and multi-signature verification of the two types of schemes. Moreover, experimental results prove that the digital multi-signature scheme based on lattice is especially efficient and secure to multi-signature generation.",Springer
"Whenish, Ruban and Ramakrishna, Seeram",BigTech Befriending Circular Economy,2022,10.1007/978-3-031-07012-9_10,https://doi.org/10.1007/978-3-031-07012-9_10,Conference Paper,Emerging Technologies in Computer Engineering: Cognitive Computing and Intelligent IoT,"Nature has a great capability of utilizing waste in its ecosystem through recycling. Earth is a significant example of a circular economy. At the same time generation of waste is inevitable as well as it has association with various disposal principles. These days, by mimicking the various natural sources, the waste is treated as a possible resource, and the conversion of waste materials into a useful product, gaining a lot of focus. The growing awareness of usage of wastages, the depletion of limited natural sources, the consciousness of the environment of human health are key players by extending the life of waste materials and reusing them again after quality enhancements. The environmental, social, and governance (ESG) are the pillars of sustainability that encourages industries as well as nations to adopt circular economy concepts to achieve a zero-carbon economy in the coming years. Resources extraction and processing, and subsequent waste management are the major causes of carbon emissions. In this perspective, the adoption of circular economy principles by big technology players and their conscious shift towards zero carbon emissions pledge through 3R (reduce, reuse and recycling) principles were discussed.",Springer
"Murukutla, Sai Amulya and Koushik, S. B. and Chinthala, Sai Pranay Raju and Bobbillapati, Abhishek and Kandaswamy, Subu",A Simple Agent Based Modeling Tool for Plastic and Debris Tracking in Oceans,2021,10.1007/978-3-030-85739-4_12,https://doi.org/10.1007/978-3-030-85739-4_12,Conference Paper,"Advances in Practical Applications of Agents, Multi-Agent Systems, and Social Good. The PAAMS Collection","Plastics and the pollution caused by their waste have always been a menace to both nature and humans. With the continual increase in plastic waste, the contamination due to plastic has stretched to the oceans. Many plastics are being drained into the oceans and rose to accumulate in the oceans. These plastics have seemed to form large patches of debris that keep floating in the oceans over the years. Identification of the plastic debris in the ocean is challenging and it is essential to clean plastic debris from the ocean. We propose a simple tool built using the agent-based modeling framework NetLogo. The tool uses ocean currents data and plastic data both being loaded using GIS (Geographic Information System) to simulate and visualize the movement of floatable plastic and debris in the oceans. The tool can be used to identify the plastic debris that has been piled up in the oceans. The tool can also be used as a teaching aid in classrooms to bring awareness about the impact of plastic pollution. This tool could additionally assist people to realize how a small plastic chunk discarded can end up as large debris drifting in the oceans. The same tool might help us narrow down the search area while looking out for missing cargo and wreckage parts of ships or flights. Though the tool does not pinpoint the location, it might help in reducing the search area and might be a rudimentary alternative for more computationally expensive models.",Springer
"Akiyama, Koichiro and Goto, Yasuhiro and Okumura, Shinya and Takagi, Tsuyoshi and Nuida, Koji and Hanaoka, Goichiro",A Public-Key Encryption Scheme Based on Non-linear Indeterminate Equations,2018,10.1007/978-3-319-72565-9_11,https://doi.org/10.1007/978-3-319-72565-9_11,Conference Paper,Selected Areas in Cryptography -- SAC 2017,"In this paper, we propose a post-quantum public-key encryption scheme whose security depends on a problem arising from a multivariate non-linear indeterminate equation. The security of lattice cryptosystems, which are considered to be the most promising candidate for a post-quantum cryptosystem, is based on the shortest vector problem or the closest vector problem in the discrete linear solution spaces of simultaneous equations. However, several improved attacks for the underlying problems have recently been developed by using approximation methods, which result in requiring longer key sizes. As a scheme to avoid such attacks, we propose a public-key encryption scheme based on the ``smallest'' solution problem in the non-linear solution spaces of multivariate indeterminate equations that was developed from the algebraic surface cryptosystem. Since no efficient algorithm to find such a smallest solution is currently known, we introduce a new computational assumption under which proposed scheme is proven to be secure in the sense of IND-CPA. Then, we perform computational experiments based on known attack methods and evaluate that the key size of our scheme is able to be much shorter than those of previous lattice cryptosystems.",Springer
"Kramarov, Sergey and Khramov, Vladimir and Bezuevskaya, Valeriya",Fuzzy Models of Educational Process Management: Digital Transformation,2020,10.1007/978-3-030-46895-8_6,https://doi.org/10.1007/978-3-030-46895-8_6,Conference Paper,Modern Information Technology and IT Education,"The approach to the formation of a multidimensional digital model of the learning environment using the mathematical unit of differential equations of the first order, implemented on the system of systems principle is considered. It is shown that within the framework of digitalization of the main components of this environment, bifurcation analysis can be carried out to detect fuzzy and under-defined learning results that do not depend directly on either the teachers or the learner. In other words, it has been found the source of the strange attractors of the learning environment as a complex nonlinear open system, which essentially depends on the initial conditions. Such situations may arise while simultaneous using old, well-established teaching methods and some new digital tools to form knowledge of learners. The results of modeling of such situations are discussed, approaches to neutralize this kind of fuzziness are considered.",Springer
"Esgin, Muhammed F. and Steinfeld, Ron and Liu, Joseph K. and Liu, Dongxi",Lattice-Based Zero-Knowledge Proofs: New Techniques for Shorter and Faster Constructions and Applications,2019,10.1007/978-3-030-26948-7_5,https://doi.org/10.1007/978-3-030-26948-7_5,Conference Paper,Advances in Cryptology -- CRYPTO 2019,"We devise new techniques for design and analysis of efficient lattice-based zero-knowledge proofs (ZKP). First, we introduce one-shot proof techniques for non-linear polynomial relations of degree {\$}{\$}k{\backslash}ge 2{\$}{\$}, where the protocol achieves a negligible soundness error in a single execution, and thus performs significantly better in both computation and communication compared to prior protocols requiring multiple repetitions. Such proofs with degree {\$}{\$}k{\backslash}ge 2{\$}{\$}have been crucial ingredients for important privacy-preserving protocols in the discrete logarithm setting, such as Bulletproofs (IEEE S{\&}P '18) and arithmetic circuit arguments (EUROCRYPT '16). In contrast, one-shot proofs in lattice-based cryptography have previously only been shown for the linear case ({\$}{\$}k=1{\$}{\$}) and a very specific quadratic case ({\$}{\$}k=2{\$}{\$}), which are obtained as a special case of our technique.",Springer
"Sm{\'e}kal, Jakub and Choudhury, Arhan and Singh, Amit Kumar and Damaty, Shady El and Friedman, Daniel Ari",Active Blockference: cadCAD with Active Inference for Cognitive Systems Modeling,2023,10.1007/978-3-031-28719-0_10,https://doi.org/10.1007/978-3-031-28719-0_10,Conference Paper,Active Inference,"Cognitive approaches to complex systems modeling are currently limited by the lack of flexible, composable, tractable simulation frameworks. Here, we present Active Blockference, an approach for cognitive modeling in complex cyberphysical systems that uses cadCAD to implement multiagent Active Inference simulations. First, we provide an account of the current state of Active Inference in cognitive modeling, with the Active Entity Ontology for Science (AEOS) as a particular example of Active Inference applied to decentralized science communities. We then give a brief overview of Active Blockference and the initial results of simulations of Active Inference agents in grid environments (Active Gridference). We conclude by sharing some preferences and expectations for further research, development, and applications. The open source package can be found at https://github.com/ActiveInferenceLab/ActiveBlockference.",Springer
"Akbari-Moghaddam, Maryam and Down, Douglas G.",SEH: Size Estimate Hedging for Single-Server Queues,2021,10.1007/978-3-030-85172-9_9,https://doi.org/10.1007/978-3-030-85172-9_9,Conference Paper,Quantitative Evaluation of Systems,"For a single server system, Shortest Remaining Processing Time (SRPT) is an optimal size-based policy. In this paper, we discuss scheduling a single-server system when exact information about the jobs' processing times is not available. When the SRPT policy uses estimated processing times, the underestimation of large jobs can significantly degrade performance. We propose a simple heuristic, Size Estimate Hedging (SEH), that only uses estimated processing times for scheduling decisions. A job's priority is increased dynamically according to an SRPT rule until it is determined that it is underestimated, at which time the priority is frozen. Numerical results suggest that SEH has desirable performance for estimation error variance that is consistent with what is seen in practice.",Springer
"Dumitru, Constantin and Muscurel, Vlad and Nordseth, {\O}rnulf and Fara, Laurentiu and Sterian, Paul",Optimization of Electro-Optical Performance and Material Parameters for a Tandem Metal Oxide Solar Cell,2018,10.1007/978-3-319-95165-2_40,https://doi.org/10.1007/978-3-319-95165-2_40,Conference Paper,Computational Science and Its Applications -- ICCSA 2018,"In this work, investigation of a silicon-based tandem heterojunction solar cell was iterated via numerical modeling. The tandem cell was split into a top metal oxide and bottom c-Si subcell, and each subcell was analyzed and compared with experimental data. For the top subcell, Silvaco Atlas was used to ascertain optimum materials for the buffer layer and their impact on the cell performance. For the bottom subcell, a Quokka 2 model has be used to evaluate and compare current-voltage and quantum efficiency curves with experimental data. Transfer matrix algorithm was used to ascertain top subcell optical field characterization. The buffer layer materials for the ZnO/Cu2O subcell that yielded best cell performance are presently TiO2 and Ga2O3 while the Quokka 2 model presents a good fit with the experimental curves.",Springer
"Serrano, Will",Echo State Networks in Data Marketplaces for Digital Content Creation,2022,10.1007/978-3-031-08223-8_31,https://doi.org/10.1007/978-3-031-08223-8_31,Conference Paper,Engineering Applications of Neural Networks,"Data marketplaces are the digital platform for data buyers and data sellers to trade information as valuable products or items. The expectation taken for granted from the users of a data marketplace is the truth of the exchanged information. However, the trade of factual data also means the marketable product is no longer unique but a series of replicas. If every user within the data marketplace owns the same information, this data eventually becomes valueless. There are specific instances where the traded products are sought to be always unique, such as predictions or digital art. This paper presents Echo State Networks (ESNs) in data marketplaces that map tradeable data into higher dimensional spaces via the dynamics of a fixed and non-linear reservoir. The reservoir generates unique tradeable data products that can not be replicated, therefore ensuring its exclusivity and commercial value. The validation results show that ESNs can also be applied to generate random tradeable products on different dimensional spaces. Specifically, the reservoir with its associated neural perturbation emulates a digital artist that generates unique and exclusive content based on 2D functions and 3D images.",Springer
"Pe{\~{n}}a P{\'e}rez Negr{\'o}n, Adriana and Mu{\~{n}}oz, Mirna and Bonilla Carranza, David",Identification of the Personal Skills Using Games,2023,10.1007/978-3-031-42307-9_7,https://doi.org/10.1007/978-3-031-42307-9_7,Conference Paper,"Systems, Software and Services Process Improvement","Software development is typically a team activity due to its complexity. However, integrating a new team can be challenging because team member needs to adapt to work with the others. In this context, the study of personal or soft skills has become relevant because they are essential for teamwork and individual success in professional life; although evaluating them is challenging. This paper presents a proposal for assessing soft skills, specifically flexibility to change, with games as an alternative. Games abstract participants, making them to forget they are observed, producing an environment in which a more natural performance is expected while recreating situations similar to those during software development projects. Also, results from a case study focused on evaluate flexibility to change are presented. Flexibility to change is a soft skill that can be evaluated at individual level and highly contributes to the success of teamwork.",Springer
"Morse, Gregory and Kozsik, Tam{\'a}s and Rakyta, P{\'e}ter",Minimal Path Delay Leading Zero Counters on Xilinx FPGAs,2023,10.1007/978-3-031-36024-4_48,https://doi.org/10.1007/978-3-031-36024-4_48,Conference Paper,Computational Science -- ICCS 2023,"We present an improved efficiency Leading Zero Counter for Xilinx FPGAs which improves the path delay while maintaining the resource usage, along with generalizing the scheme to variants whose inputs are of any size. We also show how the Ultrascale architecture also allows for better Intellectual Property solutions of certain forms of this circuit with its newly introduced logic elements. We also present a detailed framework that could be the basis for a methodology to measure results of small-scale circuit designs synthesized via high-level synthesis tools. Our result shows that very high frequencies are achievable with our design, especially at sizes where common applications like floating point addition would require them. For 16, 32 and 64-bit, our real-world build results show a 6{\%}, 14{\%} and 19{\%} path delay improvement respectively, enough of an improvement for large scale designs to have the possibility to operate close to the maximum FPGA supported frequency.",Springer
"Matulin, Marko and Mrvelj, {\v{S}}tefica and {\v{C}}op, Luka",Impact of Service Time Distributions and Server Utilization on Tandem Queueing System Performance,2025,10.1007/978-3-031-72393-3_6,https://doi.org/10.1007/978-3-031-72393-3_6,Conference Paper,Future Access Enablers for Ubiquitous and Intelligent Infrastructures,"The paper explores the performance dynamics of a tandem queueing system (TQS) comprising two interconnected nodes and assesses its responsiveness under varying service conditions. By using simulation tools, we conducted a range of tests to discover the variability of waiting times in the queues and the system, for different server utilization, as well as for cases when the service times follow exponential and normal distributions. We discovered the interplay between the nodes, i.e., how the performance of one node affects the other within the same TQS. Namely, we showed how the waiting times in the queues are crucial in understanding the TQS dynamics. We also compared the simulation results with the well-established analytical models and discovered that their applicability is limited. Particularly noteworthy was the disparity observed in the performance estimation of the second node within the TQS across all simulations, indicating potential over- or underestimation by analytical models.",Springer
"Alwen, Jo{\""e}l and Coretti, Sandro and Dodis, Yevgeniy","The Double Ratchet: Security Notions, Proofs, and Modularization for the Signal Protocol",2019,10.1007/978-3-030-17653-2_5,https://doi.org/10.1007/978-3-030-17653-2_5,Conference Paper,Advances in Cryptology -- EUROCRYPT 2019,"Signal is a famous secure messaging protocol used by billions of people, by virtue of many secure text messaging applications including Signal itself, WhatsApp, Facebook Messenger, Skype, and Google Allo. At its core it uses the concept of ``double ratcheting,'' where every message is encrypted and authenticated using a fresh symmetric key; it has many attractive properties, such as forward security, post-compromise security, and ``immediate (no-delay) decryption,'' which had never been achieved in combination by prior messaging protocols.",Springer
"Doctor, Gayatri and Joshi, Shamik and Gandhi, Axay",Optimization of ICT Street Infrastructure in Smart Cities,2021,10.1007/978-981-16-0708-0_13,https://doi.org/10.1007/978-981-16-0708-0_13,Conference Paper,Soft Computing and its Engineering Applications,"Technology solutions are now helping the urban local bodies in Indian Smart Cities to make smart and effective decisions. With these technologies coming up there IoT devices can be seen making its place on urban streets. This paper focuses on the overall view of the ICT (Information and Communication Technology) components and its placement in the city at various locations on the streets. The research for ICT street infrastructure when deployed for upcoming smart cities would help in optimization of ICT street infrastructure and bring down the total life cycle cost in terms of the cost of ownership and the recurring expense for operation and maintenance, for the deployment in upcoming cities.",Springer
"Borghesi, Costanza and Fabiani, Claudia and Pisello, Anna Laura and Giorgi, Giacomo",Quantum Confinement Effects in Materials for Daytime Radiative Cooling: An Ab-initio Investigation,2022,10.1007/978-3-031-10592-0_23,https://doi.org/10.1007/978-3-031-10592-0_23,Conference Paper,Computational Science and Its Applications -- ICCSA 2022 Workshops,"We have here performed a campaign of first-principles calculations comparing the effect of confinement in two {\$}{\$}{\backslash}text {\{}ABO{\}}{\_}{\{}3{\}}{\$}{\$}ABO3-perovskites, {\$}{\$}{\backslash}text {\{}SrTiO{\}}{\_}{\{}3{\}}{\$}{\$}SrTiO3and {\$}{\$}{\backslash}text {\{}BaSnO{\}}{\_}{\{}3{\}}{\$}{\$}BaSnO3. The study is motivated by the quest of novel materials for daytime radiative cooling devices, a recently suggested mechanism to passively cool down the temperature of sky facing objects (mainly buildings and constructions). In particular, after assessing the computational setup for the calculation of our structures, we have similarly calculated the bandstructure of 3D, 2D, and 0D systems. We both employed standard density functional theory and meta-GGA methods to do it and discussed pros and cons of the two approaches. Finally, we discuss the possible applicability of 0D species as materials for radiative cooling as function of a large and direct bandgap.",Springer
"Hanzl, Malgorzata and Kowalski, Kamil",Resilient Urban Form Assessment -- Burgage Cycle and Morphometry,2021,10.1007/978-3-030-87016-4_35,https://doi.org/10.1007/978-3-030-87016-4_35,Conference Paper,Computational Science and Its Applications -- ICCSA 2021,"Over the years, cities and urban districts undergo constant transformations. Some areas are in their prime; others experience stagnation or, in the extreme case, collapse. We aim to contribute to the definition of the concept of urban resilience. Our goal is to expand its understanding from the normative perspective of urban design. We propose the method based on contemporary research in morphometrics. Our starting point is the Conzenian process of the burgage cycle. We begin with the approach developed by Marek Koter for several streets in Lodz. We expand the method further and relate it to the well-recognised attributes of urban resilience, i.e. diversity, connectivity, redundancy and modularity. Moreover, the key issue of this study was the proper relationship between the front width, plot area and Building Coverage Ratio (BCR). The case study showcases the method applying it to the case study of Zachodnia Street in Lodz, Poland.",Springer
"Bontekoe, Tariq and Phillipson, Frank and Schoot, Ward van der",Translating Constraints into QUBOs for the Quadratic Knapsack Problem,2023,10.1007/978-3-031-36030-5_8,https://doi.org/10.1007/978-3-031-36030-5_8,Conference Paper,Computational Science -- ICCS 2023,"One of the first fields where quantum computing will likely show its use is optimisation. Many optimisation problems naturally arise in a quadratic manner, such as the quadratic knapsack problem. The current state of quantum computers requires these problems to be formulated as a quadratic unconstrained binary optimisation problem, or QUBO. Constrained quadratic binary optimisation can be translated into QUBOs by translating the constraint. However, this translation can be made in several ways, which can have a large impact on the performance when solving the QUBO. We show six different formulations for the quadratic knapsack problem and compare their performance using simulated annealing. The best performance is obtained by a formulation that uses no auxiliary variables for modelling the inequality constraint.",Springer
"Bringsjord, Selmer and Oswald, James T. and Giancola, Michael and Rozek, Brandon and Govindarajulu, Naveen Sundar",The M Cognitive Meta-architecture as Touchstone for Standard Modeling of AGI-Level Minds,2023,10.1007/978-3-031-33469-6_7,https://doi.org/10.1007/978-3-031-33469-6_7,Conference Paper,Artificial General Intelligence,"We introduce rudiments of the cognitive meta-architecture M (majuscule of {\$}{\$}{\backslash}mu {\$}{\$}and pronounced accordingly), and of a formal procedure for determining, with M as touchstone, whether a given cognitive architecture {\$}{\$}X{\_}i{\$}{\$}(from among a finite list 1 {\$}{\$}{\backslash}ldots k{\$}{\$}of modern contenders) conforms to a minimal standard model of a human-level AGI mind. The procedure, which for ease of exposition and economy in this short paper is restricted to arithmetic cognition, requires of a candidate {\$}{\$}X{\_}i{\$}{\$}, (1), a true biconditional expressing that for any human-level agent a, a property possessed by this agent, as expressed in a declarative mathematical sentence s(a), holds if and only if a formula {\$}{\$}{\backslash}chi {\_}i({\backslash}mathfrak {\{}a{\}}){\$}{\$}in the formal machinery/languages of {\$}{\$}X{\_}i{\$}{\$}holds as well ({\$}{\$}{\backslash}mathfrak {\{}a{\}}{\$}{\$}being an in-this-machinery counterpart to natural-language name a). Given then that M is such that {\$}{\$}s(a) {\backslash}text {\{} iff {\}} {\backslash}mu ({\backslash}mathfrak {\{}m{\}}){\$}{\$}, where the latter formula is in the formal language of M, with {\$}{\$}{\backslash}mathfrak {\{}m{\}}{\$}{\$}the agent modeled in M, a minimal standard modeling of an AGI-level mind is certifiably achieved by {\$}{\$}X{\_}i{\$}{\$}if, (2), it can be proved that {\$}{\$}{\backslash}chi {\_}i({\backslash}mathfrak {\{}a{\}}) {\backslash}text {\{} iff {\}} {\backslash}mu ({\backslash}mathfrak {\{}a{\}}).{\$}{\$}We conjecture herein that such confirmatory theorems can be proved with respect to both cognitive architectures NARS and SNePS, and have other cognitive architectures in our sights.",Springer
"Belgodere, Brian and Chenthamarakshan, Vijil and Das, Payel and Dognin, Pierre and Kurien, Toby and Melnyk, Igor and Mroueh, Youssef and Padhi, Inkit and Rigotti, Mattia and Ross, Jarret and Schiff, Yair and Young, Richard A.",Cloud-Based Real-Time Molecular Screening Platform with MolFormer,2023,10.1007/978-3-031-26422-1_47,https://doi.org/10.1007/978-3-031-26422-1_47,Conference Paper,Machine Learning and Knowledge Discovery in Databases,"With the prospect of automating a number of chemical tasks with high fidelity, chemical language processing models are emerging at a rapid speed. Here, we present a cloud-based real-time platform that allows users to virtually screen molecules of interest. For this purpose, molecular embeddings inferred from a recently proposed large chemical language model, named MolFormer, are leveraged. The platform currently supports three tasks: nearest neighbor retrieval, chemical space visualization, and property prediction. Based on the functionalities of this platform and results obtained, we believe that such a platform can play a pivotal role in automating chemistry and chemical engineering research, as well as assist in drug discovery and material design tasks. A demo of our platform is provided at www.ibm.biz/molecular{\_}demo.",Springer
"Bairamkulov, Rassul and Calvino, Alessandro Tempia and De Micheli, Giovanni",Synthesis of SFQ Circuits with Compound Gates,2024,10.1007/978-3-031-70947-0_1,https://doi.org/10.1007/978-3-031-70947-0_1,Conference Paper,VLSI-SoC 2023: Innovations for Trustworthy Artificial Intelligence,"Rapid single-flux quantum (RSFQ) is one of the most advanced superconducting technologies with the potential to supplement or replace conventional VLSI systems. However, scaling RSFQ systems up to VLSI complexity is challenging due to fundamental differences between RSFQ and CMOS technologies. Due to the pulse-based nature of the technology, RSFQ systems require gate-level pipelining. Moreover, logic gates have an extremely limited driving capacity. Path balancing and clock distribution constitute a major overhead, often doubling the size of circuits. Gate compounding is a novel technique that substantially enriches the functionality realizable within a single clock cycle. However, standard logic synthesis tools do not support its specific synchronization constraints. In this paper, we build first a database of minimum-area compound gates covering all the Boolean functions up to 4 variables and all possible input arrival patterns. Then, we propose a technology mapping method for RSFQ circuits that exploits compound gates using the database as a cell library. We evaluate our framework over the EPFL and ISCAS benchmark circuits. Our results show, on average, a 33{\%} lower logic depth with 24{\%} smaller area, as compared to the state of the art. We further extend our technology mapping framework to support the novel three-input SFQ gates, namely AND3, MAJ3, and OR3. We demonstrate the by using these gates, the area and logic depth of the logic networks are reduced, on average, by 11{\%} and 30{\%} respectively, indicating that developing the logic cells for these three-input gates can significantly improve the scalability of the SFQ technology.",Springer
"{\""O}z{\c{c}}ep, {\""O}zg{\""u}r L{\""u}tf{\""u} and Leemhuis, Mena and Wolter, Diedrich","Cones, Negation, and All That",2020,10.1007/978-3-030-58285-2_17,https://doi.org/10.1007/978-3-030-58285-2_17,Conference Paper,KI 2020: Advances in Artificial Intelligence,"This paper summarizes results on embedding ontologies expressed in the {\$}{\$}{\backslash}mathcal {\{}ALC{\}}{\$}{\$}ALCdescription logic into a real-valued vector space, comprising restricted existential and universal quantifiers, as well as concept negation and concept disjunction. The main result states that an {\$}{\$}{\backslash}mathcal {\{}ALC{\}}{\$}{\$}ALContology is satisfiable in the classical sense iff it is satisfiable by a partial faithful geometric model based on cones. The line of work to which we contribute aims to integrate knowledge representation techniques and machine learning. The new cone-model of {\$}{\$}{\backslash}mathcal {\{}ALC{\}}{\$}{\$}ALCproposed in this work gives rise to conic optimization techniques for machine learning, extending previous approaches by its ability to model full {\$}{\$}{\backslash}mathcal {\{}ALC{\}}{\$}{\$}ALC.",Springer
"Shaikhislamov, Denis and Voevodin, Vadim",Analysis of Software Package Usage Based on Methods for Identifying Similar HPC Applications,2021,10.1007/978-3-030-92864-3_24,https://doi.org/10.1007/978-3-030-92864-3_24,Conference Paper,Supercomputing,"In the field of High Performance Computing, the task of software package detection is poorly studied, even though the information about packages used in supercomputer applications helps to better understand the peculiarities of supercomputer usage. There are several existing solutions to tackle that problem, but they are far from ideal. In this paper we show how our previously developed method for detecting similar applications can be used to solve this problem, as well as analyze results of its operation with some insights on supercomputer usage. According to the evaluation on the Lomonosov-2 supercomputer, these methods found {\$}{\$}{\backslash}sim {\$}{\$}éä½¹åéå¿å¹éçµ³\%} more jobs with package usage than the existing method.",Springer
"Baumeister, Paul F. and Hater, Thorsten and Pleiter, Dirk and Boettiger, Hans and Maurer, Thilo and Brunheroto, Jos{\'e} R.",Exploiting In-Memory Processing Capabilities for Density Functional Theory Applications,2017,10.1007/978-3-319-58943-5_60,https://doi.org/10.1007/978-3-319-58943-5_60,Conference Paper,Euro-Par 2016: Parallel Processing Workshops,"Processing-in-memory (PIM) is an approach to address the data transport challenge in future HPC architectures and various designs have been explored in the past. Despite, it remains unclear how scientific applications could efficiently exploit massively-parallel HPC architectures integrating PIM modules. In this paper we address this question for material science applications for which we ported relevant kernels to the Active Memory Cube architecture developed by IBM Research.",Springer
"Louzeiro, Pedro",The Comprovisador's Real-Time Notation Interface (Extended Version),2018,10.1007/978-3-030-01692-0_33,https://doi.org/10.1007/978-3-030-01692-0_33,Conference Paper,Music Technology with Swing,"Comprovisador is a system designed to enable real-time mediated soloist-ensemble interaction, through machine listening, algorithmic procedures and dynamic staff-based notation. It uses multiple networked computers -- one host and several clients -- to perform algorithmic compositional procedures with the music material improvised by a soloist and to coordinate the musical response of an ensemble. Algorithmic parameters are manipulated by a conductor/composer who mediates the interaction between soloist and ensemble, making compositional decisions in real-time. The present text, an extended version of a paper presented at CMMR 2018, in Matosinhos, focuses on the notation interface of this system, after overviewing its concept and structure. A discussion is made on how rehearsals and live performances impacted the development of the interface.",Springer
"K{\'e}pes, K{\'a}lm{\'a}n and Leymann, Frank and Weder, Benjamin and Wild, Karoline",SiDD: The Situation-Aware Distributed Deployment System,2021,10.1007/978-3-030-76352-7_11,https://doi.org/10.1007/978-3-030-76352-7_11,Conference Paper,Service-Oriented Computing  -- ICSOC 2020 Workshops,"Most of today's deployment automation technologies enable the deployment of distributed applications in distributed environments, whereby the deployment execution is centrally coordinated either by a central orchestrator or a master in a distributed master-workers architectures. However, it is becoming increasingly important to support use cases where several independent partners are involved. As a result, decentralized distributed deployment automation approaches are required, since organizations typically do not provide access to their internal infrastructure to the outside or leave control over application deployments to others. Moreover, the choice of partners can depend heavily on the current situation at deployment time, e.g. the costs or availability of resources. Thus, at deployment time it is decided which partner will provide a certain part of the application depending on the situation. To tackle these challenges, we demonstrate the situation-aware distributed deployment (SiDD) system as an extension of the OpenTOSCA ecosystem.",Springer
"Kempkes, Marie C. and Dunjko, Vedran and van Nieuwenburg, Evert and Spiegelberg, Jakob",Reliable Classifications with Guaranteed Confidence Using the Dempster-Shafer Theory of Evidence,2024,10.1007/978-3-031-70344-7_6,https://doi.org/10.1007/978-3-031-70344-7_6,Conference Paper,Machine Learning and Knowledge Discovery in Databases. Research Track,"Reliably capturing predictive uncertainty is indispensable for the deployment of machine learning (ML) models in safety-critical domains. The most commonly used approaches to uncertainty quantification are, however, either computationally costly in inference or incapable of capturing different types of uncertainty (i.e., aleatoric and epistemic). In this paper, we tackle this issue using the Dempster-Shafer theory of evidence, which only recently gained attention as a tool to estimate uncertainty in ML. By training a neural network to return a generalized probability measure and combining it with conformal prediction, we obtain set predictions with guaranteed user-specified confidence. We test our method on various datasets and empirically show that it reflects uncertainty more reliably than a calibrated classifier with softmax output, since our approach yields smaller and hence more informative prediction sets at the same bounded error level in particular for samples with high epistemic uncertainty. In order to deal with the exponential scaling inherent to classifiers within Dempster-Shafer theory, we introduce a second approach with reduced complexity, which also returns smaller sets than the comparative method, even on large classification tasks with more than 40 distinct labels. Our results indicate that the proposed methods are promising approaches to obtain reliable and informative predictions in the presence of both aleatoric and epistemic uncertainty in only one forward-pass through the network.",Springer
"Abdelfattah, Ahmad and Tomov, Stan and Dongarra, Jack","Batch QR Factorization on GPUs: Design, Optimization, and Tuning",2022,10.1007/978-3-031-08751-6_5,https://doi.org/10.1007/978-3-031-08751-6_5,Conference Paper,Computational Science -- ICCS 2022,"QR factorization of dense matrices is a ubiquitous tool in high performance computing (HPC). From solving linear systems and least squares problems to eigenvalue problems, and singular value decompositions, the impact of a high performance QR factorization is fundamental to computer simulations and many applications. More importantly, the QR factorization on a batch of relatively small matrices has acquired a lot of attention in sparse direct solvers and low-rank approximations for Hierarchical matrices. To address this interest and demand, we developed and present a high performance batch QR factorization for Graphics Processing Units (GPUs). We present a multi-level blocking strategy that adjusts various algorithmic designs to the size of the input matrices. We also show that following the LAPACK QR design convention, while still useful, is significantly outperformed by unconventional code structures that increase data reuse. The performance results show multi-fold speedups against the state of the art libraries on the latest GPU architectures from both NVIDIA and AMD.",Springer
"Morawski, Micha{\l} and Karbowa{\'{n}}czyk, Micha{\l}",Multipath QUIC -- Directions of the Improvements,2022,10.1007/978-3-030-93479-8_13,https://doi.org/10.1007/978-3-030-93479-8_13,Conference Paper,"Broadband Communications, Networks, and Systems","The multipath transmission becomes the recognized alternative for traditional Quality of Service architectures. Recently, the multipath version of TCP protocol and its modern replacement -- QUIC -- has been proposed. The paper presents the dynamic properties of the data transfer between physical systems, engaging the multipath version of QUIC protocol (MPQUIC) which inherits the properties of its predecessors. The advantages and weaknesses of the transmission are emphasized and compared to the singlepath QUIC. While QUIC is designed to convey HTTP traffic, in the paper, general-purpose networking is investigated. Based on the measurements, the use recommendations are given together with the directions of improvements.",Springer
"Percassi, Francesco and Scala, Enrico and Vallati, Mauro",A Structure-Sensitive Translation from Hybrid to Numeric Planning,2023,10.1007/978-3-031-47546-7_8,https://doi.org/10.1007/978-3-031-47546-7_8,Conference Paper,AIxIA 2023 -- Advances in Artificial Intelligence,"pddl+ is an expressive planning formalism that enables the modelling of hybrid domains with both discrete and continuous dynamics. However, its expressiveness makes this language notoriously difficult to handle natively. To address this challenge, translations from time-discrete pddl+ into numeric pddl2.1 have been proposed as a way to reframe the rich expressiveness of pddl+ into a simpler and more manageable formalism. In this work, we first analyse existing translations and provide a means to compare them in terms of induced state space and the size of the reformulated tasks. Secondly, we propose a novel translation leveraging the structure of the problem to generate a compact reformulation. Our experimental results indicate that the novel translation outperforms the existing ones on a range of benchmarks.",Springer
"Lia, Matteo and Colella, Davide Damiano and Longo, Antonella and Zappatore, Marco",euFAIR: A Digital Tool for Assessing the FAIR Principles,2023,10.1007/978-3-031-47112-4_5,https://doi.org/10.1007/978-3-031-47112-4_5,Conference Paper,Advances in Conceptual Modeling,"Over the last decade, the importance of FAIR principles as a reference for data reusability and openness has increased constantly. Various tools for FAIR data assessment exist, including manual approaches like the FAIR Data Self-Assessment Tool (SAT) and automated tools as the FAIR Evaluation Services and Generic Automatic Tool (GAT). However, subjectivity in manual assessment and limited guidance in automated tools represent significant limitations. In such a context, the Italian ``Piano Triennale per l'Informatica nella Pubblica Amministrazione'' has laid the foundations for open data practices in the Italian Public Administration (PA) since 2017. In this work, we propose a tool called euFAIR for the automatic assessment of dataset FAIRness in the Italian PA. The tool incorporates European Data Quality Guidelines for a more comprehensive dataset evaluation and implements a set of specific ad-hoc designed metrics. With this tool, we aim at improving data quality and sharing, as well as the adherence to community standards in the Italian PA. To validate our results, we compared euFAIR with SAT and GAT, highlighting significant differences.",Springer
"Patel, Nisarg and Parekh, Viral and Jani, Kaushal",Improvement of Network Protocol and Analysis of Security Using Aspect of Cryptography,2023,10.1007/978-3-031-40564-8_8,https://doi.org/10.1007/978-3-031-40564-8_8,Conference Paper,"Computing Science, Communication and Security","Wireless network protocol is the top most discussed topics and used of quantum cryptography is adding value to the network performance. In our research paper we are going to make a novel approach to create a development of quantum cryptography for wireless key distribution in 802.11 networks. Due to its mobility with fast data sharing in houses, offices, and businesses they are convenient. Users now choose a wireless network over a LAN-based network connected with Ethernet cables due to advancements in contemporary wireless technology. Unfortunately, security problems are a major worry because they frequently aren't. It is simple for someone else to obtain information sent through websites or mobile apps while someone is linked to a Wi-Fi network. Based on the theory of physics, cryptographic key can be exchanged by quantum cryptography between two remote sites without any conditional security. The origin of quantum cryptography explained in the Heisenberg uncertainty principle, which tells that the certain pairs of physical channels are related in a way that measuring one property restricts the third user from knowing the value of the other at the same time. In our current research paper, we are using quantum cryptography with AOMDV routing protocol and measure the network performance so using quantum cryptography we will have both secured and improved performance in wireless adhoc network.",Springer
"Hofst{\""a}tter, Daniel and Ilager, Shashikant and Lujic, Ivan and Brandic, Ivona",SymED: Adaptive and Online Symbolic Representation of Data on the Edge,2023,10.1007/978-3-031-39698-4_28,https://doi.org/10.1007/978-3-031-39698-4_28,Conference Paper,Euro-Par 2023: Parallel Processing,"The edge computing paradigm helps handle the Internet of Things (IoT) generated data in proximity to its source. Challenges occur in transferring, storing, and processing this rapidly growing amount of data on resource-constrained edge devices. Symbolic Representation (SR) algorithms are promising solutions to reduce the data size by converting actual raw data into symbols. Also, they allow data analytics (e.g., anomaly detection and trend prediction) directly on symbols, benefiting large classes of edge applications. However, existing SR algorithms are centralized in design and work offline with batch data, which is infeasible for real-time cases. We propose SymED - Symbolic Edge Data representation method, i.e., an online, adaptive, and distributed approach for symbolic representation of data on edge. SymED is based on the Adaptive Brownian Bridge-based Aggregation (ABBA), where we assume low-powered IoT devices do initial data compression (senders) and the more robust edge devices do the symbolic conversion (receivers). We evaluate SymED by measuring compression performance, reconstruction accuracy through Dynamic Time Warping (DTW) distance, and computational latency. The results show that SymED is able to (i) reduce the raw data with an average compression rate of {\$}{\$}9.5{\backslash}{\%}{\$}{\$}9.5{\%}; (ii) keep a low reconstruction error of 13.25 in the DTW space; (iii) simultaneously provide real-time adaptability for online streaming IoT data at typical latencies of 42 ms per symbol, reducing the overall network traffic.",Springer
"Dinur, Itai and Nadler, Niv",Multi-target Attacks on the Picnic Signature Scheme and Related Protocols,2019,10.1007/978-3-030-17659-4_24,https://doi.org/10.1007/978-3-030-17659-4_24,Conference Paper,Advances in Cryptology -- EUROCRYPT 2019,"Picnic is a signature scheme that was presented at ACM CCS 2017 by Chase et al. and submitted to NIST's post-quantum standardization project. Among all submissions to NIST's project, Picnic is one of the most innovative, making use of recent progress in construction of practically efficient zero-knowledge (ZK) protocols for general circuits.",Springer
"Benso, Andrea and D'Alessandro, Flavio and Papi, Paolo",Quantum Automata and Languages of Finite Index,2024,10.1007/978-3-031-72621-7_7,https://doi.org/10.1007/978-3-031-72621-7_7,Conference Paper,Reachability Problems,"This paper continues the study of measure-once finite quantum automata building on work by Bertoni et al. and Blondel et al. We investigate conditions ensuring that, given a language recognized by such a device and a language generated by a context-free grammar of finite index or by a matrix context-free grammar, it is decidable whether or not they have a nonempty intersection.",Springer
"S{\o}lvsten, Steffan Christ and van de Pol, Jaco",Adiar 1.1,2023,10.1007/978-3-031-33170-1_28,https://doi.org/10.1007/978-3-031-33170-1_28,Conference Paper,NASA Formal Methods,We outline how support for Zero-suppressed Decision Diagrams (ZDDs) has been achieved for the external memory BDD package Adiar. This allows one to use ZDDs to solve various problems despite their size exceed the machine's limit of internal memory.,Springer
"Surendran, R. and Tamilvizhi, T. and Lakshmi, S.",Integrating the Meteorological Data into a Smart City Service Using Cloud of Things (CoT),2021,10.1007/978-3-030-90016-8_7,https://doi.org/10.1007/978-3-030-90016-8_7,Conference Paper,Emerging Technologies in Computing,"The Cloud of Things (CoT) offers consistent and adaptable access to the global resources and data. It is being achieved through data integration and resource co-allocation techniques. The data integration is a process of collecting the data from various resources. The users are requesting the meteorological data to propose the smart city service. The proposed smart city service integrates the meteorological data from the meteorological towers. The data centers acts as a broker between the service requestor and the provider. If the requested data unavailable, the nearest tower collects from other towers using co-allocation technique. The resource co-allocation technique involves the analysis of available towers based on the user's request. The meteorological towers hold the weather forecasting data and distribute it across the wide geographical areas. This includes temperature, humidity, precipitation, wind speed and atmospheric pressure. These data are heterogeneous in nature which makes data integration through MapReduce technique and virtual machinery. This research work produces accurate and faultless forecast data for the user through CoT techniques. The proposed work experimental results are proved that the service will be a time and cost effective one for the smart city.",Springer
"Roy, Debashish and Ding, Chen and Cuzzocrea, Alfredo and Belmerabet, Islam",A Machine-Learning Framework for Supporting Content Recommendation via User Feedback Data and Content Profiles in Content Managements Systems,2023,10.1007/978-3-031-39821-6_37,https://doi.org/10.1007/978-3-031-39821-6_37,Conference Paper,Database and Expert Systems Applications,"Matrix Factorization (MF) which is a Collaborative Filtering (CF) based model, is widely used in Recommendation Systems (RS). In this research, we deal with a specific recommendation problem of recommending content to users in a Content Management System (CMS) utilizing users' feedback data.",Springer
"Seo, Hwajeong and Jalali, Amir and Azarderakhsh, Reza",SIKE Round 2 Speed Record on ARM Cortex-M4,2019,10.1007/978-3-030-31578-8_3,https://doi.org/10.1007/978-3-030-31578-8_3,Conference Paper,Cryptology and Network Security,"We present the first practical software implementation of Supersingular Isogeny Key Encapsulation (SIKE) round 2, targeting NIST's 1, 2, and 5 security levels on 32-bit ARM Cortex-M4 microcontrollers. The proposed library introduces a new speed record of SIKE protocol on the target platform. We achieved this record by adopting several state-of-the-art engineering techniques as well as highly-optimized hand-crafted assembly implementation of finite field arithmetic. In particular, we carefully redesign the previous optimized implementations of filed arithmetic on 32-bit ARM Cortex-M4 platform and propose a set of novel techniques which are explicitly suitable for SIKE/SIDH primes. Moreover, the proposed arithmetic implementations are fully scalable to larger bit-length integers and can be adopted over different security levels. The benchmark result on STM32F4 Discovery board equipped with 32-bit ARM Cortex-M4 microcontrollers shows that the entire key encapsulation over p434 takes about 326 million clock cycles (i.e. 1.94 s @168 MHz). In contrast to the previous optimized implementation of the isogeny-based key exchange on low-power 32-bit ARM Cortex-M4, our performance evaluation shows feasibility of using SIKE mechanism on the target platform. In comparison to the most of the post-quantum candidates, SIKE requires an excessive number of arithmetic operations, resulting in significantly slower timings. However, its small key size makes this scheme as a promising candidate on low-end microcontrollers in the quantum era by ensuring the lower energy consumption for key transmission than other schemes.",Springer
"Manca, Vincenzo",A Brief Philosophical Note on Information,2017,10.1007/978-3-319-69775-8_8,https://doi.org/10.1007/978-3-319-69775-8_8,Conference Paper,Towards Integrative Machine Learning and Knowledge Extraction,"I will start by posing a question that arose to my attention when, some years ago, I realized the importance of Machine Learning for the future theoretical and applicative fields of Computer science.",Springer
"Lunglmayr, Michael and Guzman, Yuneisy Garcia and Calliari, Felipe and Amaral, Gustavo Castro do",Smooth Step Detection,2022,10.1007/978-3-031-25312-6_35,https://doi.org/10.1007/978-3-031-25312-6_35,Conference Paper,Computer Aided Systems Theory -- EUROCAST 2022,"We investigate the detection of smooth steps in a measured signal using an algorithm based on linearized Bregman iterations (LBI). Such smooth steps occur when a trend break does not occur abruptly but gradually over multiple samples. We extend the detection algorithm by an approximate deconvolution add-on that enables reliable step detection while even allowing reducing the number of iterations of the LBI algorithm. We present simulation results in the context of fiber fault detection demonstrating the detection performance that is achievable with this combined approach, allowing reducing the required number of iterations by approximately {\$}{\$}40{\backslash}{\%}{\$}{\$}40{\%}.",Springer
"Anton Moreno, Santiago and Mezzetti, Anita and Lacube, William",Link Prediction for Cybersecurity Companies and Technologies: Towards a Survivability Score,2021,10.1007/978-3-030-93200-8_13,https://doi.org/10.1007/978-3-030-93200-8_13,Conference Paper,Critical Information Infrastructures Security,"On the cybersecurity market, novel entities -- technologies and companies -- arise and disappear swiftly. In such a fast-paced context, assessing the survivability of those entities is crucial when it comes to make investment decisions for ensuring the security of critical infrastructures. In this paper, we present a framework for capturing the dynamic relationship between entities of the Swiss cybersecurity landscape. By using open data, we first model our dataset as a bipartite graph in which nodes are represented by technologies and companies involved in cybersecurity. Next, we use patents and job openings data to link the two entities. By extracting time series of such graphs, and by using link-prediction methods, we forecast the (dis)appearance of links. We apply several unsupervised learning similarity-based algorithms, a supervised learning method and finally we select the best model. Our preliminary results show good performance and promising validation of our survivability index. We suggest that our framework is useful for critical infrastructure operators, as a survivability index of entities can be extracted by using the outputs of our models.",Springer
"Mangiameli, Michele and Mussumeci, Giuseppe and Candiano, Alessio",A Low Cost Methodology for Multispectral Image Classification,2018,10.1007/978-3-319-95174-4_22,https://doi.org/10.1007/978-3-319-95174-4_22,Conference Paper,Computational Science and Its Applications -- ICCSA 2018,"Multispectral and hyperspectral remote sensing have significantly improved territorial surveys and mapping. However aerial images are often expensive being acquired through aircraft and satellite sensors. Furthermore, the processing and classification of these images need commercial software that increases the entire cost of the analysis. For these reasons, we propose an approach of data acquisition and analysis based on supervised classification to obtain accurately maps of the area of interest in reduced time. The images have been acquired through 3-channels Tetracam ADC-Lite camera, and processed with free and open source software, PixelWrench2 and QGIS. The results obtained demonstrate that the approach can compete with traditional acquisition and classification methods, due to simple operational procedures, low operational costs, and high accuracy of supervised classification. This approach provides promising results that encourage its development and optimization of these technologies for other purposes, such as the mapping of asbestos-cement (AC) roof coverings.",Springer
"Hirschfeld, Scott T. E. and Batten, Lynn M. and Amain, Mohammed K. I.",Efficiencies in Binary Elliptic Curves,2018,10.1007/978-3-319-95174-4_21,https://doi.org/10.1007/978-3-319-95174-4_21,Conference Paper,Computational Science and Its Applications -- ICCSA 2018,"This paper discusses the choices of elliptic curve models available to the would-be implementer, and assists the decision as to which model to use by examining the links between security and efficiency. In early public key cryptography schemes, such as ElGamal and RSA, the use of finite fields over large prime numbers was prevalent, thus preventing the need for difficult and expensive computations over extension fields. Thus, with the introduction of elliptic curve models, the same computational infrastructure using prime fields was inevitably used. As it became clear that elliptic curve models were more efficient than their public key competitors, they acquired a great deal of attention. In more recent times, and with the onset of the Internet of Things, the cryptography community is faced with the challenge of improving the efficiency of cryptography even further, resulting in many papers dealing with improvements of computational efficiencies. This search, along with improvements in both software and hardware dealing with characteristic two fields has instigated the analysis of elliptic curve constructions over binary extension fields. In particular, the ability to identify an object in the field with a bit string aids computation for binary elliptic curves. These circumstances account for our focus on binary elliptic curve fields in this paper in which we present an in-depth discussion on their efficiency and security properties along with other relevant features of various binary elliptic curve models.",Springer
"Ghasemlou, Shaban Mousavi and Ochoa-Zezzatti, Alberto and Torres, Vianey and Martinez, Erwin and Lopez, Victor",Implementation of Time Series to Determine Purchase and Use of Electric Cars in a Smart City Considering Generation Z as Target Population,2024,10.1007/978-3-031-51940-6_22,https://doi.org/10.1007/978-3-031-51940-6_22,Conference Paper,Advances in Computational Intelligence. MICAI 2023 International Workshops,"One of the biggest issues facing the globe today is greenhouse gas (GHG) emissions. In the transportation industry, the development of electric vehicles has recently been the main focus of research globally to satisfy the permissible GHG limitations where vehicles that operate on oil contribute a significant amount of GHG. In recent years, there has been a great increase in the study of electric vehicles (EVs). This integrative evaluation is an attempt to close the gap in assessments that evaluate and show the demand and development of EVs in great detail. This study provides numerous thought-provoking insights on specific events, such as the rise in popularity and desire for electric vehicles on a worldwide scale, the demand for power, and the role of government in the development of smart cities. This study gained a new perspective with the addition of the concept of a smart city created by EV implementation. The overview would be helpful for policymakers as well as academics. The findings of this study provide a summary of the arguments made by investors, regulators, and members of Generation Z in favor of electric vehicles.",Springer
"Liu, Zhen and Nguyen, Khoa and Yang, Guomin and Wang, Huaxiong and Wong, Duncan S.",A Lattice-Based Linkable Ring Signature Supporting Stealth Addresses,2019,10.1007/978-3-030-29959-0_35,https://doi.org/10.1007/978-3-030-29959-0_35,Conference Paper,Computer Security -- ESORICS 2019,"First proposed in CryptoNote, a collection of popular privacy-centric cryptocurrencies have employed Linkable Ring Signature and a corresponding Key Derivation Mechanism (KeyDerM) for keeping the payer and payee of a transaction anonymous and unlinkable. The KeyDerM is used for generating a fresh signing key and the corresponding public key, referred to as a stealth address, for the transaction payee. The stealth address will then be used in the linkable ring signature next time when the payee spends the coin. However, in all existing works, including Monero, the privacy model only considers the two cryptographic primitives separately. In addition, to be applied to cryptocurrencies, the security and privacy models for Linkable Ring Signature should capture the situation that the public key ring of a signature may contain keys created by an adversary (referred to as adversarially-chosen-key attack), since in cryptocurrencies, it is normal for a user (adversary) to create self-paying transactions so that some maliciously created public keys can get into the system without being detected .",Springer
"Lagan{\`a}, Antonio and di Giorgio, Lorenzo",A Circular Economy Proposal on CO{\$}{\$}{\_}2{\$}{\$}Reuse to Produce Methane Using Energy from Renewable Sources,2018,10.1007/978-3-319-95174-4_43,https://doi.org/10.1007/978-3-319-95174-4_43,Conference Paper,Computational Science and Its Applications -- ICCSA 2018,The case of a cluster of companies and Public Institutions producing innovation in the field of storing energy obtained from renewable sources and investing in new circular production models is investigated. The role played by externalities in making the production cycle itself a social welfare by minimizing the deadweight losses is examined in detail in the light of the Klepper and Nordhaus models and by performing a Microeconomic Analysis. The study singles out the importance of strategically positioning industrial innovation in the stream of circular economy. As a specific case study the efforts played by Master UP srl in trying to drive such segment of the energy circular economy to success by developing an efficient and fruitful business for carbon neutral methane production is analyzed in terms of production isoquant curves.,Springer
"Kolarovszki, Zolt{\'a}n and Kaposi, {\'A}goston and Kozsik, Tam{\'a}s and Zimbor{\'a}s, Zolt{\'a}n",Simulating Sparse and Shallow Gaussian Boson Sampling,2023,10.1007/978-3-031-36030-5_17,https://doi.org/10.1007/978-3-031-36030-5_17,Conference Paper,Computational Science -- ICCS 2023,"Gaussian Boson Sampling (GBS) is one of the most popular quantum supremacy protocols as it does not require universal control over the quantum system, which favors current photonic experimental platforms and there is strong theoretical evidence for its computational hardness. However, over the years, several algorithms have been proposed trying to increase the performance of classically simulating GBS assuming certain constraints, e.g., a low number of photons or shallow interferometers. Most existing improvements of the classical simulation of GBS provide a performance increase regarding the probability calculation, leaving the sampling algorithm itself untouched. This paper provides an asymptotically better sampling algorithm in the case of low squeezing and shallow circuits.",Springer
"Karajeh, Ola and Lourentzou, Ismini and Fox, Edward A.",Multi-view Graph-Based Text Representations for Imbalanced Classification,2023,10.1007/978-3-031-43849-3_22,https://doi.org/10.1007/978-3-031-43849-3_22,Conference Paper,Linking Theory and Practice of Digital Libraries,"Text classification is a fundamental task in natural language processing, notably in the context of digital libraries, where it is essential for organizing and retrieving large numbers of documents in diverse collections, especially when tackling issues with inherent class imbalance. Sequence-based models can successfully capture semantics in local consecutive text sequences. On the other hand, graph-based models can preserve global co-occurrences that capture non-consecutive and long-distance semantics. A text representation approach that combines local and global information can enhance performance in practical class imbalance text classification scenarios. Yet, multi-view graph-based text representations have received limited attention. In this work, we introduce Multi-view Minority Class Text Graph Convolutional Network (MMCT-GCN), a transductive multi-view text classification model that captures textual graph representations for the minority class, along with sequence-based text representations. Experiments show that MMCT-GCN variants outperform baseline models on multiple text collections.",Springer
"Wang, Shixiong and Zhang, Juanyang and He, Jingnan and Wang, Huaxiong and Li, Chao",Simplified Revocable Hierarchical Identity-Based Encryption from Lattices,2019,10.1007/978-3-030-31578-8_6,https://doi.org/10.1007/978-3-030-31578-8_6,Conference Paper,Cryptology and Network Security,"As an extension of identity-based encryption (IBE), revocable hierarchical IBE (RHIBE) supports both key revocation and key delegation simultaneously, which are two important functionalities for cryptographic use in practice. Recently in PKC 2019, Katsumata et al. constructed the first lattice-based RHIBE scheme with decryption key exposure resistance (DKER). Such constructions are all based on bilinear or multilinear maps before their work. In this paper, we simplify the construction of RHIBE scheme with DKER provided by Katsumata et al. With our new treatment of the identity spaces and the time period space, there is only one short trapdoor base in the master secret key and in the secret key of each identity. In addition, we claim that some items in the keys can also be removed due to the DKER setting. Our first RHIBE scheme in the standard model is presented as a result of the above simplification. Furthermore, based on the technique for lattice basis delegation in fixed dimension, we construct our second RHIBE scheme in the random oracle model. It has much shorter items in keys and ciphertexts than before, and also achieves the adaptive-identity security under the learning with errors (LWE) assumption.",Springer
"Masetti, Giulio and Chiaradonna, Silvano and Di Giandomenico, Felicita",A New Metric of Adaptivity for Self-adaptive Systems,2024,10.1007/978-3-031-70245-7_16,https://doi.org/10.1007/978-3-031-70245-7_16,Conference Paper,Quality of Information and Communications Technology,"With focus on open-ended architectural adaptation, where individual components represent alternatives that can be added and removed dynamically at runtime, a new metric is proposed to provide insights on the effectiveness of architectural changes, such as the addition or removal of components. Specifically, the new metric allows to assess how much the system actually adapts to variations of the environment by properly applying a system reconfiguration. The approach is based on a statistical analysis of the system, which exploits the Bell inequality, conveniently adapted from the Quantum Mechanic theory. The formal definition of the new adaptability metric is presented, as well as an example of application in a simple case study.",Springer
"Bujak, Andrzej",The Development of Telematics in the Context of the Concepts of ``Industry 4.0'' and ``Logistics 4.0'',2018,10.1007/978-3-319-97955-7_34,https://doi.org/10.1007/978-3-319-97955-7_34,Conference Paper,Management Perspective for Transport Telematics,"The modern world and the global economy undergo numerous rapid transformations, whose main driving force is the development of new technologies. New, prospective concepts of functioning of industry and logistics are developed, such as ``Industry 4.0'' and ``Logistics 4.0''. In this context it is worth considering the place of telematics in achieving the objectives of these concepts. Without the comprehensive implementation of telematics considerations, the projected increase in robotics, real-time data exchange and automation of many processes seems impossible. Therefore, a question arises not only about the role and importance of telematics in the practical implementation of these concepts, but also about the scope and areas of implantation of telematics solutions. It appears also reasonable to ask about the new possibilities and functionalities which telematic solutions could generate in order to fully secure the pragmatic implementation of the latest concepts. The article attempts to identify and comprehensively approach the factors determining the emergence of such solutions. The objective of the study is also to indicate trends and directions of changes in the implementation of the latest telematics solutions on the example of selected companies in Lower Silesia.",Springer
"Gavin, Gerald and Bonnevay, Stephane",Fractional LWE: A Nonlinear Variant of LWE,2019,10.1007/978-3-030-31578-8_20,https://doi.org/10.1007/978-3-030-31578-8_20,Conference Paper,Cryptology and Network Security,"Many cryptographic constructions are based on the famous problem LWE [Reg05]. In particular, this cryptographic problem is currently the most relevant to build FHE [GSW13, BV11]. In [BV11], encrypting x consists of randomly choosing a vector {\$}{\$}{\backslash}varvec{\{}c{\}}{\$}{\$}satisfying {\$}{\$}{\backslash}langle {\backslash}varvec{\{}s{\}},{\backslash}varvec{\{}c{\}}{\backslash}rangle =x+{\backslash}textsf {\{}noise{\}}{\backslash}pmod q{\$}{\$}where {\$}{\$}{\backslash}varvec{\{}s{\}}{\$}{\$}is a secret size-n vector. While the vector sum is a homomorphic operator, such a scheme is intrinsically vulnerable to lattice-based attacks. To overcome this, we propose to define {\$}{\$}{\backslash}varvec{\{}c{\}}{\$}{\$}as a pair of vectors {\$}{\$}({\backslash}varvec{\{}u{\}},{\backslash}varvec{\{}v{\}}){\$}{\$}satisfying {\$}{\$}{\backslash}langle {\backslash}varvec{\{}s{\}},{\backslash}varvec{\{}u{\}}{\backslash}rangle /{\backslash}langle {\backslash}varvec{\{}s{\}},{\backslash}varvec{\{}v{\}}{\backslash}rangle =x+{\backslash}textsf {\{}noise{\}}{\backslash}pmod q{\$}{\$}. This simple scheme is based on a new cryptographic problem intuitively not easier than LWE, called Fractional LWE (FLWE). While some homomorphic properties are lost, the secret vector {\$}{\$}{\backslash}varvec{\{}s{\}}{\$}{\$}could be hopefully chosen shorter leading to more efficient constructions. We extensively study the hardness of FLWE. We first prove that the decision and search versions are equivalent provided q is a small prime. We then propose lattice-based cryptanalysis showing that n could be chosen logarithmic in {\$}{\$}{\backslash}log q{\$}{\$}instead of polynomial for LWE.",Springer
"Krishnan, Archanaa S. and Yang, Yaling and Schaumont, Patrick",Risk and Architecture Factors in Digital Exposure Notification,2020,10.1007/978-3-030-60939-9_21,https://doi.org/10.1007/978-3-030-60939-9_21,Conference Paper,"Embedded Computer Systems: Architectures, Modeling, and Simulation","To effectively trace the infection spread in a pandemic, a large number of manual contact tracers are required to reach out to all possible contacts of infected users. Exposure notification, a.k.a. digital contact tracing, can supplement manual contact tracing to ease the burden on manual tracers and to digitally obtain accurate contact information. We study how risk emerges in security, privacy, architecture, and technology aspects of exposure notification systems. We provide potential overhead in using Bluetooth-based systems and discuss the architectural support required for other types of systems, and we wrap up with a discussion on architecture aspects to support these solutions.",Springer
"Carissan, Yannick and Dim, Chisom-Adaobi and Hagebaum-Reignier, Denis and Prcovic, Nicolas and Terrioux, Cyril and Varet, Adrien",Computing the Local Aromaticity of Benzenoids Thanks to Constraint Programming,2020,10.1007/978-3-030-58475-7_39,https://doi.org/10.1007/978-3-030-58475-7_39,Conference Paper,Principles and Practice of Constraint Programming,"Benzenoids are a subfamily of hydrocarbons (molecules that are only made of hydrogen and carbon atoms) whose carbon atoms form hexagons. These molecules are widely studied in theoretical chemistry. Then, there is a lot of problems relative to this subject, like the benzenoid generation or the enumeration of all its Kekul{\'e} structures (i.e. all valid configurations of double bonds). In this context, the computation of the local aromaticity of a given benzenoid is an important problematic since the aromaticity cannot be measured. Nowadays, computing aromaticity requires quantum chemistry calculations that are too expensive to be used on medium to large-sized molecules. But, there exist some methods related to graph theory which can allow us to compute it. In this article, we describe how constraint programming can be useful in order to compute the aromaticity of benzenoids. Moreover we show that our method is much faster than the reference one, namely NICS.",Springer
"Ferri, Massimo",Persistent Topology for Natural Data Analysis --- A Survey,2017,10.1007/978-3-319-69775-8_6,https://doi.org/10.1007/978-3-319-69775-8_6,Conference Paper,Towards Integrative Machine Learning and Knowledge Extraction,"Natural data offer a hard challenge to data analysis. One set of tools is being developed by several teams to face this difficult task: Persistent topology. After a brief introduction to this theory, some applications to the analysis and classification of cells, liver and skin lesions, music pieces, gait, oil and gas reservoirs, cyclones, galaxies, bones, brain connections, languages, handwritten and gestured letters are shown.",Springer
"Sakthivadivel, Dalton A. R.",A Worked Example of the Bayesian Mechanics of Classical Objects,2023,10.1007/978-3-031-28719-0_21,https://doi.org/10.1007/978-3-031-28719-0_21,Conference Paper,Active Inference,"Bayesian mechanics is a new approach to studying the mathematics and physics of interacting stochastic processes. We provide a worked example of a physical mechanics for classical objects, which derives from a simple application thereof. We summarise the current state of the art of Bayesian mechanics in doing so.",Springer
"Dalal, Anshul and Choudhary, Manoj and Balamurugan, S.",Design Framework of 4-Bit Radix-4 Booth Multiplier Using Perpendicular Nanomagnetic Logic in MagCAD,2021,10.1007/978-981-16-5048-2_31,https://doi.org/10.1007/978-981-16-5048-2_31,Conference Paper,"Microelectronic Devices, Circuits and Systems","Currently, researchers have been relentlessly working towards developing technologies that can potentially replace Complementary Metal Oxide Semiconductor (CMOS) technology as the scaling of CMOS technology has nearly reached its physical size limitations at the nanoscale. Nanomagnetic Logic (NML), one such promising advancement in the field of post-CMOS technology uses nanomagnets to transmit and compute data. It is a non-volatile, power-efficient technology that provides the potential to exploit the third dimension. In this paper, we have designed and implemented a 4-bit Radix-4 Booth Multiplier using And-Or-Inverter Graph (AOIG) representation in MagCAD tool using perpendicular Nano magnetic logic (pNML) technology. Subsequently, we have optimized the design using Majority Invertor Graph (MIG) manipulation techniques, a new method for efficient logic representation of boolean expressions using majority and inverter gates. MagCAD tool incorporates all the necessary design rules, physical models, libraries and technological parameters. After the design phase, a register-transfer-level (RTL) model is extracted in VHDL and it is simulated in Xilinx ISE to analyze and compare the performances of both the circuits. We evince a reduction in critical path delay, latency and area by, nearly 10{\%}, 29{\%} and 40{\%} respectively after optimizing the layout of the Booth multiplier design using Majority-Inverter-Graph manipulation rules.",Springer
"Okhotin, Alexander","Graph-Walking Automata: From Whence They Come, and Whither They are Bound",2019,10.1007/978-3-030-23679-3_2,https://doi.org/10.1007/978-3-030-23679-3_2,Conference Paper,Implementation and Application of Automata,"Graph-walking automata are finite automata walking on graphs given as an input; tree-walking automata and two-way finite automata are their well-known special cases. Graph-walking automata can be regarded both as a model of navigation in an unknown environment, and as a generic computing device, with the graph as the model of its memory. This paper presents the known results on these automata, ranging from their limitations in traversing graphs, studied already in the 1970s, to the recent work on the logical reversibility of their computations.",Springer
"Faginas-Lago, Noelia and Apriliyanto, Yusuf Bramastya and Lombardi, Andrea",Intermolecular Forces for the Interaction of H{\$}{\$}{\_}{\{}2{\}}{\$}{\$}O--Graphtriyne Membrane: Contribution of Induction Effects,2021,10.1007/978-3-030-87016-4_32,https://doi.org/10.1007/978-3-030-87016-4_32,Conference Paper,Computational Science and Its Applications -- ICCSA 2021,"Among various carbon allotropes, graphynes are a class of two-dimensional nanosheets, analogous to graphene, that recently have been considered as ideal nanofilters for small gas molecules. In this work, the authors report molecular dynamics (MD) simulations of graphtriyne-H{\$}{\$}{\_}{\{}2{\}}{\$}{\$}2O system performed using refined potentials. Intermolecular forces are the key points that govern the adsorption dynamics of gaseous molecules on graphynes surfaces. In order to define the full intermolecular potentials, the Improved Lennard-Jones (ILJ) semi-empirical potential have been subsequently modified by adding an induction term (ind) to take into account the polarizability of H{\$}{\$}{\_}{\{}2{\}}{\$}{\$}2O molecules. Evaluation of the computational cost and the distribution of H{\$}{\$}{\_}{\{}2{\}}{\$}{\$}2O molecules over graphtriyne membrane have been assessed by comparing the intermolecular forces with and without inclusion of induction potential.",Springer
"Orozco-Jim{\'e}nez, Ernesto and Mu{\~{n}}oz, Mirna and Mej{\'i}a, Jezreel",Toward the Development of a Method for Identifying Problems and Providing Strategies to Reduce Them in Software Development Teams,2024,10.1007/978-3-031-71139-8_9,https://doi.org/10.1007/978-3-031-71139-8_9,Conference Paper,"Systems, Software and Services Process Improvement","Software development teams often face challenges that impact their performance due to individual, teamwork, and organizational factors. This research aims to develop a method for identifying problems in software development teams by analyzing issues related to team building and proposing strategies that reduce the detected problems while enhancing the characteristics of highly effective teams. The method took as base the results of a systematic mapping study. We identified a set of problems and characteristics associated with the formation of effective teams. Besides, we used the People Capability Maturity Model (People CMM) framework to structure our method. Our main contribution is the definition of a method that classifies problems at the individual, team, and organizational levels, to which it offers strategies focused on the characteristics of highly effective teams for team improvement. This approach not only helps to address critical areas requiring attention but also provides a clear pathway for implementing practical solutions that enhance team efficacy and cohesion.",Springer
"Ghunaim, Yasir and Hoehndorf, Robert",Large-Scale Knowledge Integration for Enhanced Molecular Property Prediction,2024,10.1007/978-3-031-71170-1_10,https://doi.org/10.1007/978-3-031-71170-1_10,Conference Paper,Neural-Symbolic Learning and Reasoning,"Pre-training machine learning models on molecular properties has proven effective for generating robust and generalizable representations, which is critical for advancements in drug discovery and materials science. While recent work has primarily focused on data-driven approaches, the KANO model introduces a novel paradigm by incorporating knowledge-enhanced pre-training. In this work, we expand upon KANO by integrating the large-scale ChEBI knowledge graph, which includes 2,840 functional groups -- significantly more than the original 82 used in KANO. We explore two approaches, Replace and Integrate, to incorporate this extensive knowledge into the KANO framework. Our results demonstrate that including ChEBI leads to improved performance on 9 out of 14 molecular property prediction datasets. This highlights the importance of utilizing a larger and more diverse set of functional groups to enhance molecular representations for property predictions.",Springer
"Neumann, Eike",On the Complexity of Robust Eventual Inequality Testing for C-Finite Functions,2023,10.1007/978-3-031-45286-4_8,https://doi.org/10.1007/978-3-031-45286-4_8,Conference Paper,Reachability Problems,"We study the computational complexity of a robust version of the problem of testing two univariate C-finite functions for eventual inequality at large times. Specifically, working in the bit-model of real computation, we consider the eventual inequality testing problem for real functions that are specified by homogeneous linear Cauchy problems with arbitrary real coefficients and initial values. In order to assign to this problem a well-defined computational complexity, we develop a natural notion of polynomial-time decidability of subsets of computable metric spaces which extends our recently introduced notion of maximal partial decidability. We show that eventual inequality of C-finite functions is polynomial-time decidable in this sense.",Springer
"Carissan, Yannick and Hagebaum-Reignier, Denis and Prcovic, Nicolas and Terrioux, Cyril and Varet, Adrien",Using Constraint Programming to Generate Benzenoid Structures in Theoretical Chemistry,2020,10.1007/978-3-030-58475-7_40,https://doi.org/10.1007/978-3-030-58475-7_40,Conference Paper,Principles and Practice of Constraint Programming,"Benzenoids are a subfamily of hydrocarbons (molecules that are only made of hydrogen and carbon atoms) whose carbon atoms form hexagons. These molecules are widely studied in theoretical chemistry and have a lot of concrete applications. Therefore, generating benzenoids which have certain structural properties (e.g. having a given number of hexagons or having a particular structure from a graph viewpoint) is an interesting and important problem. It constitutes a preliminary step for studying their chemical properties. In this paper, we show that modeling this problem in Choco Solver and just letting its search engine generate the solutions is a fast enough and very flexible approach. It can allow to generate many different kinds of benzenoids with predefined structural properties by posting new constraints, saving the efforts of developing bespoke algorithmic methods for each kind of benzenoids.",Springer
"Choi, Kyu Young and Kim, Eunkyung and Yoon, Hyojin and Moon, Dukjae and Cho, Jihoon",Generic Construction of Bounded-Collusion IBE via Table-Based ID-to-Key Map,2019,10.1007/978-3-030-31578-8_25,https://doi.org/10.1007/978-3-030-31578-8_25,Conference Paper,Cryptology and Network Security,"In this paper, we give a new generic construction of bounded-collusion identity-based encryption (BC-IBE) scheme from public key encryption (PKE) scheme. Our construction significantly reduces the number of public parameters to O(t), where t is a collusion parameter. Especially, we present the first construction in which the number of public parameters is independent from the total number of identities in the system. To achieve this, we propose a novel table-based ID-to-key map, and a method of deriving key pair from two (public and secret) parameter tables by using a cryptographic hash function. We provide a security proof of our construction in random oracle model.",Springer
"Su{\'a}rez-Revelo, Jazm{\'i}n Ximena and Ruiz-Duque, Any and Toro, Juan Pablo and Mej{\'i}a-Bueno, Ana Mar{\'i}a and Hern{\'a}ndez-Valdivieso, Alher Mauricio",Changes in Electrocardiographic Signals During Training in Laparoscopic Surgery Simulator: A Preliminary Report,2018,10.1007/978-3-030-00353-1_25,https://doi.org/10.1007/978-3-030-00353-1_25,Conference Paper,Applied Computer Sciences in Engineering,"The aim of this work is attempting to identify physiological characteristics of the learning process in surgery residents. As an exploratory approach, we are interested in determining statistically significant changes in electrocardiographic (ECG) signals recorded while a group of eleven first year general surgery residents were performing three basic skills tasks from the virtual reality (VR) laparoscopic simulator LapSimé¹è°æªé·ï¿½These signals were processed and heart rate (HR) was calculated to analyze it along with the overall score for each exercise. Statistical analysis was performed by means of analysis of variance showing the effects of training session, difficulty of the task and participants gender on heart rate and performance. Our preliminary experimental results show that the score obtained in the tasks improves with training session, being in the women where significant changes occur. HR analysis showed that it increases with the complexity of the task. Besides, the effect of gender on HR showed that in male group there were the significant changes with the difficulty of the task, and a decrease with the training session in the intermediate level of difficulty task.",Springer
"Beknazarova, Saida and Latipova, Nodira Muxtarjanovna and Maxmudova, Munira Jurayevna and Alekseeva, Viktoriya Sergeevna",Experimental Evaluation of the Efficiency of Compression of Files by Fractal-Spectral Codec,2022,10.1007/978-3-031-21340-3_2,https://doi.org/10.1007/978-3-031-21340-3_2,Conference Paper,Information Technologies and Intelligent Decision Making Systems,"In the article describe the estimation of the accuracy of image reconstruction by lifting filters, that in video codecs, the main compression of the video stream is provided by eliminating inter-frame redundancy using motion compensation methods for image fragments of adjacent frames. However, the use of motion compensation methods requires the formation of additional data (metadata) containing information about the types of image blocks used, the coordinates of their movement, etc. At the same time, in order to increase the compression of the video stream without compromising its quality, higher accuracy of motion compensation is required, which leads to an increase in the number of blocks and, accordingly, to an increase in the volume of metadata that reduces the effectiveness of motion compensation. This is the main problem of compressing streaming video without degrading the quality of images. In addition, the higher accuracy of positioning blocks with motion compensation dramatically reduces the speed of image processing, which is not always feasible in real-time system.",Springer
"Tabata, Shota",Trade-Off of Networks on Weighted Space Analyzed via a Method Mimicking Human Walking Track Superposition,2022,10.1007/978-3-031-21094-5_18,https://doi.org/10.1007/978-3-031-21094-5_18,Conference Paper,Bioinspired Optimization Methods and Their Applications,"This study proposes a method for constructing networks with a small total weighted length and total detour rate by mimicking human walking track superposition. The present study aims to contribute to the scarce literature on multiple objectives, the total weighted length and the total detour rate, by allowing branching vertices on weighted space. The weight on space represents the spatial difference in the implementation cost, such as buildings, terrains, and land price. In modern society, we need to design a new transportation network while considering these constraints so that the network has a low total weighted length that enables a low implementation cost and a low total detour rate that leads to high efficiency. This study contributes to this requirement. The proposed method outputs solutions with various combinations of the total weighted length and the total detour rate. It approximates the Pareto frontier by connecting inherent non-dominated solutions. This approximation enables the analysis of the relationship between the weighted space and the limit of effective networks the space can generate quantitatively. Several experiments are carried out, and the result infers that the area with a huge weight significantly affects the trade-off relationship between the total weighted length and the total detour rate. Quantitatively revealing the trade-off relationship between the total weighted length and the total detour rate is helpful in managerial situations under certain constraints, including the budget, needed operational performance, and so on.",Springer
"Zhang, Ya-Wei and Ding, Wei","The Foundation, Trend and Frontier of Service Design Research in English Literature",2021,10.1007/978-3-030-78635-9_12,https://doi.org/10.1007/978-3-030-78635-9_12,Conference Paper,HCI International 2021 - Posters,"Having a deep insight of the international research progress in the field of service design is an inevitable requirement for the further development of service design industry. Based on 401 English articles on service design from the core collection database of Web of Science from 1999 to 2019, with the help of CiteSpace software, the research foundation, trend and frontier of service design are visually analyzed. The study found that: éä½¸çé¡æ°å¹ç»ç¤¹e research topics of service design cover a wide range of fields. They mainly falls into three groups: the origin of service design, the logic and method of service design, and the relationship between service design, enterprise and society. The logic and method of service design is the longest and most active knowledge group among them; éä½¸çé¡æ°å¹ç»îom 2002 to 2011, the relationship between service design and perceived service quality is the frontier of research. From 2008 to 2014, the concept and application of service-oriented architecture is the frontier of research.",Springer
"Zdunek, Rafa{\l}",Tensor Train Subspace Analysis for Classification of Hand Gestures with Surface EMG Signals,2023,10.1007/978-3-031-36021-3_63,https://doi.org/10.1007/978-3-031-36021-3_63,Conference Paper,Computational Science -- ICCS 2023,"Processing and classification of surface EMG signals is a challenging computational problem that has received increasing attention for at least two decades. When multichannel EMG signals are transformed into spectrograms, classification can be performed using multilinear features that can be extracted from a set of spectrograms by various tensor decomposition methods. In this study, we propose to use one of the most efficient tensor network models, i.e. the tensor train decomposition method and to combine it with the tensor subspace analysis to extract the more discriminant 2D features from multi-way data. Numerical experiments, carried out on surface EMG signals registered during hand gesture actions, demonstrated that the proposed feature extraction method outperforms well-known tensor decomposition methods in terms of classification accuracy.",Springer
"Perlner, Ray and Petzoldt, Albrecht and Smith-Tone, Daniel",Total Break of the SRP Encryption Scheme,2018,10.1007/978-3-319-72565-9_18,https://doi.org/10.1007/978-3-319-72565-9_18,Conference Paper,Selected Areas in Cryptography -- SAC 2017,"Multivariate Public Key Cryptography (MPKC) is one of the main candidates for secure communication in a post-quantum era. Recently, Yasuda and Sakurai proposed in [7] a new multivariate encryption scheme called SRP, which combines the Square encryption scheme with the Rainbow signature scheme and the Plus modifier.",Springer
"Zheng, Mengce and Hu, Honggang",Implicit Related-Key Factorization Problem on the RSA Cryptosystem,2019,10.1007/978-3-030-31578-8_29,https://doi.org/10.1007/978-3-030-31578-8_29,Conference Paper,Cryptology and Network Security,"In this paper, we address the implicit related-key factorization problem on the RSA cryptosystem. Informally, we investigate under what condition it is possible to efficiently factor RSA moduli in polynomial time given the implicit information of related private keys. We propose lattice-based attacks using Coppersmith's techniques. We first analyze the special case given two RSA instances with known amounts of shared most significant bits (MSBs) and least significant bits (LSBs) of unknown related private keys. Subsequently a generic attack is proposed using a heuristic lattice construction when given more RSA instances. Furthermore, we conduct numerical experiments to verify the validity of the proposed attacks.",Springer
"Sheng, Jinhua and Chen, Bin and Wang, Bocheng and Liu, Qingqiang and Ma, Yangjie and Liu, Weixiang",Hybrid Iterative Reconstruction for Low Radiation Dose Computed Tomography,2018,10.1007/978-3-030-04224-0_21,https://doi.org/10.1007/978-3-030-04224-0_21,Conference Paper,Neural Information Processing,"The purpose of this paper is to study the use of hybrid iterative reconstruction (HIR) technique for radiation dose reduction and its effect on low-contrast resolution. This method is designed to create prior information for improving image quality from low dose CT scanners. We compare the performance of lower radiation dose with the HIR and standard dose with the filtered back projection (FBP) using catphané¹è°æªé·ï¿? phantom, which is used to measure various image quality parameters. Results show that there are continuous linear reduction of noise and linear increase of CNR with increasing HIR levels compared to FBP for any given scanning protocol. It is possible to provide equivalent diagnostic image quality at low dose. In this paper, we use a quantitative method to evaluate the noise characteristics. Evidence from phantom tests demonstrates that the shape of NPSHIR is shifted continuously to low frequency with increasing HIR levels compared to FBP for any given scanning protocol. Our study confirms that even if there are continuous reduction of noise and increase of CNR with increasing HIR levels, the performance of human observers did not seem to be improved simultaneously because coarser noise could appear. Our finding that the low-frequency components (HIR) are greater than one of FBP (previously believed) may result in the discrepancy between the performance of human observers and that of the ideal low-contrast objects.",Springer
"Libert, Beno{\^i}t and Ling, San and Nguyen, Khoa and Wang, Huaxiong",Lattice-Based Zero-Knowledge Arguments for Integer Relations,2018,10.1007/978-3-319-96881-0_24,https://doi.org/10.1007/978-3-319-96881-0_24,Conference Paper,Advances in Cryptology -- CRYPTO 2018,"We provide lattice-based protocols allowing to prove relations among committed integers. While the most general zero-knowledge proof techniques can handle arithmetic circuits in the lattice setting, adapting them to prove statements over the integers is non-trivial, at least if we want to handle exponentially large integers while working with a polynomial-size modulus q. For a polynomial L, we provide zero-knowledge arguments allowing a prover to convince a verifier that committed L-bit bitstrings x, y and z are the binary representations of integers X, Y and Z satisfying {\$}{\$}Z=X+Y{\$}{\$}over {\$}{\$}{\backslash}mathbb {\{}Z{\}}{\$}{\$}. The complexity of our arguments is only linear in L. Using them, we construct arguments allowing to prove inequalities {\$}{\$}X<Z{\$}{\$}among committed integers, as well as arguments showing that a committed X belongs to a public interval {\$}{\$}[{\backslash}alpha ,{\backslash}beta ]{\$}{\$}, where {\$}{\$}{\backslash}alpha {\$}{\$}and {\$}{\$}{\backslash}beta {\$}{\$}can be arbitrarily large. Our range arguments have logarithmic cost (i.e., linear in L) in the maximal range magnitude. Using these tools, we obtain zero-knowledge arguments showing that a committed element X does not belong to a public set S using {\$}{\$}{\backslash}widetilde{\{}{\backslash}mathcal {\{}O{\}}{\}}(n {\backslash}cdot {\backslash}log |S|){\$}{\$}bits of communication, where n is the security parameter. We finally give a protocol allowing to argue that committed L-bit integers X, Y and Z satisfy multiplicative relations {\$}{\$}Z=XY{\$}{\$}over the integers, with communication cost subquadratic in L. To this end, we use our protocol for integer addition to prove the correct recursive execution of Karatsuba's multiplication algorithm. The security of our protocols relies on standard lattice assumptions with polynomial modulus and polynomial approximation factor.",Springer
"Orts, Francisco and Ortega, Gloria and Garz{\'o}n, Ester M.",Studying the Cost of n-qubit Toffoli Gates,2022,10.1007/978-3-031-08760-8_10,https://doi.org/10.1007/978-3-031-08760-8_10,Conference Paper,Computational Science -- ICCS 2022,"There are several Toffoli gate designs for quantum computers in the literature. Each of these designs is focused on a specific technology or on optimising one or several metrics (T-count, number of qubits, etc.), and therefore has its advantages and disadvantages. While there is some consensus in the state of the art on the best implementations for the Toffoli gate, scaling this gate for use with three or more control qubits is not trivial. In this paper, we analyse the known techniques for constructing an n-qubit Toffoli gate, as well as the existing state-of-the-art designs for the 2-qubit version, which is an indispensable building block for the larger gates. In particular, we are interested in a construction of the temporary logical-AND gate with more than two control qubits. This gate is widely used in the literature due to the T-count and qubit reduction it provides. However, its use with more than two control qubits has not been analysed in detail in any work. The resulting information is offered in the form of comparative tables that will facilitate its consultation for researchers and people interested in the subject, so that they can easily choose the design that best suits their interests. As part of this work, the studied implementations have been reproduced and tested on both quantum simulators and real quantum devices.",Springer
"Chen, Dingyao and Lan, Long and Wang, Mengzhu and Zhang, Xiang and Liang, Tianyi and Luo, Zhigang",Logit Distillation via Student Diversity,2023,10.1007/978-981-99-1642-9_29,https://doi.org/10.1007/978-981-99-1642-9_29,Conference Paper,Neural Information Processing,"Knowledge distillation (KD) is a technique of transferring the knowledge from a large teacher network to a small student network. Current KD methods either make a student mimic diverse teachers with knowledge amalgamation or encourage many students to do mutual/self learning free from the supervision of the teacher. Intuitively, it could be not optimal to focus on teacher diversity but ignore the teacher-student gap, or spotlight student co-learning without the guidence of the teacher. Besides, such methods mainly rely on distilling deep features from intermediate layers, thus pure logit distillation is still fully underexplored. In this paper, we propose a neat yet effective logit distillation model termed student diversity, that is, many students mimic a teacher with logit distillation, then exploit individual knowledge to collectively train a single excellent student with logit distillation again. For this aim, a multi-branch shared network as diverse students is developed to grasp the knowledge of the teacher in different degrees. Since such students share different levels of network layers, they have different yet homogeneous knowledge to pave the reliable way for bridging the teacher-student gap. To collectively train an excellent student, we fuse the semantics of all the students to pay more attention to attentive features for effective knowledge transfer. We have conducted extensive experiments on various datasets to demonstrate the effectiveness of our approach.",Springer
"Dohare, Upasana and Lobiyal, D. K.",A Load-Aware Matching Game for Node Association in Wireless Ad-Hoc Networks,2018,10.1007/978-981-13-2035-4_22,https://doi.org/10.1007/978-981-13-2035-4_22,Conference Paper,Applications of Computing and Communication Technologies,"In this paper, a load aware matching game to achieve stable one-to-one matching of senders and receivers is proposed, when distance between sender and receiver, and busyness level of receivers are taken into account. We have formulated matching game for the network formation where the nodes are capable of load sharing, selfish behaviour of node that maximize their individual utility and agreeing to cooperate in pair. Sender keeps changing one hop receiver that assist in load balancing of the network. Busyness level of receiver is introduced into matching game to initiate competition between the proposing senders. Distance is introduced to instigate competition between the receivers. The proposed matching game theoretic models compared with the state of art load balancing model for ad hoc networks in the terms of lifetime of the network and standard deviation of the load. Simulation results have shown that the proposed LAMG performs better as compared with GLBR in the terms of network lifetime and standard deviation of the load.",Springer
"Besozzi, Valerio and Della Bartola, Matteo and Gemignani, Luca",Experimental Study of a Parallel Iterative Solver for Markov Chain Modeling,2023,10.1007/978-3-031-36021-3_4,https://doi.org/10.1007/978-3-031-36021-3_4,Conference Paper,Computational Science -- ICCS 2023,"This paper presents the results of a preliminary experimental investigation of the performance of a stationary iterative method based on a block staircase splitting for solving singular systems of linear equations arising in Markov chain modelling. From the experiments presented, we can deduce that the method is well suited for solving block banded or more generally localized systems in a parallel computing environment. The parallel implementation has been benchmarked using several Markovian models.",Springer
"Lyubashevsky, Vadim and Seiler, Gregor","Short, Invertible Elements in Partially Splitting Cyclotomic Rings and Applications to Lattice-Based Zero-Knowledge Proofs",2018,10.1007/978-3-319-78381-9_8,https://doi.org/10.1007/978-3-319-78381-9_8,Conference Paper,Advances in Cryptology -- EUROCRYPT 2018,"When constructing practical zero-knowledge proofs based on the hardness of the Ring-LWE or the Ring-SIS problems over polynomial rings {\$}{\$}{\backslash}mathbb {\{}Z{\}}{\_}p[X]/(X^n+1){\$}{\$}, it is often necessary that the challenges come from a set {\$}{\$}{\backslash}mathcal {\{}C{\}}{\$}{\$}that satisfies three properties: the set should be large (around {\$}{\$}2^{\{}256{\}}{\$}{\$}), the elements in it should have small norms, and all the non-zero elements in the difference set {\$}{\$}{\backslash}mathcal {\{}C{\}}-{\backslash}mathcal {\{}C{\}}{\$}{\$}should be invertible. The first two properties are straightforward to satisfy, while the third one requires us to make efficiency compromises. We can either work over rings where the polynomial {\$}{\$}X^n+1{\$}{\$}only splits into two irreducible factors modulo p, which makes the speed of the multiplication operation in the ring sub-optimal; or we can limit our challenge set to polynomials of smaller degree, which requires them to have (much) larger norms.",Springer
"Pomyka{\l}a, Jacek and {\.{Z}}o{\l}nierczyk, Olgierd",Elliptic-Curve Factorization and Witnesses,2024,10.1007/978-3-031-63749-0_20,https://doi.org/10.1007/978-3-031-63749-0_20,Conference Paper,Computational Science -- ICCS 2024,"We define the EC (Elliptic Curve)-based factorization witnesses and prove related results within both conditional and unconditional approaches. We present experimental computations that support the conjecture of behavior of related admissible elliptic curves in relation to the deterministic complexity of suitable factoring algorithms based on the parameters of the witnesses. This paper features three main results devoted to the factorization of RSA numbers {\$}{\$}N = pq{\$}{\$}N=pq, where {\$}{\$}q>p{\$}{\$}q>p. The first result of computational complexity of elliptic curve factorization is improved by the factor {\$}{\$}D^{\{}{\backslash}sigma {\}}{\$}{\$}D$\sigma$, comparing to previously known result {\$}{\$}O{\backslash}left( D^{\{}2+o(1){\}}{\backslash}right) {\$}{\$}OD2+o(1), where D is smoothness bound, assuming additional knowledge of the admissible elliptic curve. The second result demonstrates the feasibility of achieving factorization in deterministic, polynomial time, based on knowledge obtained at a specific step in the elliptic curve method (ECM), a feat previously considered impossible. The third result establishes deterministic time for conditional factorization using the elliptic version of Fermat method. It has the magnitude order {\$}{\$}({\backslash}log N)^ {\{}O(1){\}}{\backslash}left( 1+{\backslash}left( {\backslash}frac{\{}|a{\_}p|+|a{\_}q|{\}}{\{}D{\}}{\backslash}right) ^{\{}2{\}}{\backslash}right) {\$}{\$}(logN)O(1)1+|ap|+|aq|D2, provided {\$}{\$}{\backslash}frac{\{}q{\}}{\{}p{\}} {\backslash}ll 1{\$}{\$}qpéä½¹åé£îå¹éï¿½Here {\$}{\$}a{\_}p,a{\_}q{\$}{\$}ap,aqare the Frobenius traces of the corresponding curves ({\$}{\$}E({\backslash}mathbb {\{}F{\}}{\_}{\{}p{\}}), E({\backslash}mathbb {\{}F{\}}{\_}{\{}q{\}}){\$}{\$}E(Fp),E(Fq)), and D indicates the approximation of the quotient p/q by the quotient {\$}{\$}a{\_}p/a{\_}q{\$}{\$}ap/aq, assuming that the order of the group of points over a pseudo elliptic curve {\$}{\$}E({\backslash}mathbb {\{}Z{\}}{\_}{\{}N{\}}){\$}{\$}E(ZN)is known.",Springer
"Chen, Long and Zhang, Zhenfeng and Wang, Xueqing",Batched Multi-hop Multi-key FHE from Ring-LWE with Compact Ciphertext Extension,2017,10.1007/978-3-319-70503-3_20,https://doi.org/10.1007/978-3-319-70503-3_20,Conference Paper,Theory of Cryptography,"Traditional fully homomorphic encryption (FHE) schemes support computation on data encrypted under a single key. In STOC 2012, L{\'o}pez-Alt et al. introduced the notion of multi-key FHE (MKFHE), which allows homomorphic computation on ciphertexts encrypted under different keys. In this work, we focus on MKFHE constructions from standard assumptions and propose a new construction of ring-LWE-based multi-hop MKFHE scheme. Our work is based on Brakerski-Gentry-Vaikuntanathan (BGV) FHE scheme where, in contrast, all the previous works on multi-key FHE with standard assumptions were based on Gentry-Sahai-Waters (GSW) FHE scheme. Therefore, our construction can encrypt a ring element rather than a single bit and naturally inherits the advantages in aspects of the ciphertext/plaintext ratio and the complexity of homomorphic operations. Moveover, our MKFHE scheme supports the Chinese Remainder Theorem (CRT)-based ciphertexts packing technique, achieves {\$}{\$}poly{\backslash}left( k,L,{\backslash}log n{\backslash}right) {\$}{\$}polyk,L,logncomputation overhead for k users, circuits with depth at most L and an n dimensional lattice, and gives the first batched MKFHE scheme based on standard assumptions to our knowledge. Furthermore, the ciphertext extension algorithms of previous schemes need to perform complex computation on each ciphertext, while our extension algorithm just needs to generate evaluation keys for the extended scheme. So the complexity of ciphertext extension is only dependent on the number of associated parities but not on the number of ciphertexts. Besides, our scheme also admits a threshold decryption protocol from which a generalized two-round MPC protocol can be similarly obtained as prior works.",Springer
"Canora, Filomena and Musto, Maria Assunta and Sdao, Francesco",Groundwater Recharge Assessment in the Carbonate Aquifer System of the Lauria Mounts (Southern Italy) by GIS-Based Distributed Hydrogeological Balance Method,2018,10.1007/978-3-319-95165-2_12,https://doi.org/10.1007/978-3-319-95165-2_12,Conference Paper,Computational Science and Its Applications -- ICCSA 2018,"The carbonate aquifer system of the northern sector of the Lauria Mounts, located in the southern-western part of the Basilicata region (southern Italy), represents a strategic hydrostructure of the Lucanian Apennines for its groundwater resources. Several springs exploited and not, characterized by important groundwater discharges, drain the aquifer system. In recent decades the demand of freshwater is rising in relation to the population needs, land use change and climate variations, rendering water availability in the future uncertain. For these reasons, intensive actions are being done to ensure the effective protection and quantification of the available groundwater resources. In this perspective, the assessment of the aquifer recharge is the starting point for the correct definition of the available groundwater resources, aimed at the delineation of the proper protection and adequate management of these resources. In this study the application of the inverse hydrogeological water balance method to assess the potential aquifer recharge distributed in the hydrogeological basin, has been carried out based on a GIS procedure. The hydrogeological characterization and the groundwater recharge assessment of the carbonate hydrostructure result to be essential to define integrated actions and strategies for groundwater effective protection and sustainable management.",Springer
"Barreto, Patricia R. P. and Albernaz, Alessandra F. and Aquilanti, Vincenzo and Faginas-Lago, Noelia and Grossi, Gaia and Lombardi, Andrea and Palazzetti, Federico and Pirani, Fernando",Potential Energy Surface for the Interaction of Helium with the Chiral Molecule Propylene Oxide,2018,10.1007/978-3-319-95174-4_46,https://doi.org/10.1007/978-3-319-95174-4_46,Conference Paper,Computational Science and Its Applications -- ICCSA 2018,"The discovery of propylene oxide in the interstellar medium has raised considerable interest about this molecule, which represents one of the simplest cases of chiral systems. In this paper, we present a quantum chemical study and a phenomenological approach, through the Pirani potential function, of the system He -- propylene oxide in fourteen different configurations. Comparison of the optimized molecular structure at various level of theory, as well as a discussion on the two approaches is reported. The analytical form of the Pirani potential function permits future applications of classical simulations of molecular-beam collision experiments, especially to those related to chirality discrimination phenomena, in progress in our laboratory.",Springer
"Bertolotti, Francesco and Locoro, Angela and Mari, Luca",Sensitivity to Initial Conditions in Agent-Based Models,2020,10.1007/978-3-030-66412-1_32,https://doi.org/10.1007/978-3-030-66412-1_32,Conference Paper,Multi-Agent Systems and Agreement Technologies,"In the last thirty years, agent-based modelling has become a well-known technique for studying and simulating dynamical systems. Still, there are some open issues to be addressed. One of these is the substantial absence of studies about the sensitivity to initial conditions, that is the effect of small variations at the beginning of simulation on the macro-level behaviour of the model. The goal of this preliminary work is to explore how a single modification on one agent affects the evolution of the simulation. Through the analysis of two deterministic models (a simple market model and Reynolds' flocking model), we obtain two main results. First, we observe that the impact of the variation of a single initial condition on the simulation behaviour is high in both models. Second, there is evidence of an at least qualitative relation between some general agent-based model settings (numerosity of agents in the model and rate of connections between agents) and the sensitivity to the modified initial condition. We conclude that at least some significant classes of agent-based models are affected by a high sensitivity to initial conditions that have a negative effect on the predictive power of simulations.",Springer
"Caglioti, Concetta and Lago, Maria Noelia Faginas and Lombardi, Andrea and Palazzetti, Federico",A Minimal Model of Potential Energy Surface for the CO2 -- CO System,2021,10.1007/978-3-030-87016-4_26,https://doi.org/10.1007/978-3-030-87016-4_26,Conference Paper,Computational Science and Its Applications -- ICCSA 2021,"Analytical models of potential energy surfaces are desirable for applications to classical and quantum molecular dynamics simulations, as well as calculation of spectroscopic properties. Here, we present a minimal model based on the expansion in spherical harmonics of the interaction potential between CO2 and CO molecules, both assumed as rigid rotors. This approach consists in determining a minimal number of energy points related to representative mutual orientations of the molecules (configurations) by ab initio calculations. The spherical harmonics expansion represents an exact transformation of these quantum chemical input data. The model permits interpolation and possible implementation of sets of input data at a higher level of theory.",Springer
"Siyin, Chen","``Let's Fashion Fiction!'' Fashion Designers as Speculators, Alternative Present and Possible Future with Speculative Design",2024,10.1007/978-3-031-61353-1_24,https://doi.org/10.1007/978-3-031-61353-1_24,Conference Paper,"Design, User Experience, and Usability","This research explores the transformative potential of speculative design in shaping the future of fashion, with a specific focus on the concept of fashion fiction. The article analyses two case studies from Demna Gvasalia's Balenciaga fashion collections, the 2021Fall - Afterworld game film and the 2022 Spring - Clones fashion show, to demonstrate how different ways of combining narrative building, scenario design, and parallel worldviews of fashion fiction stimulate audience imagination and discussion. It also presents a comprehensive analysis of the aesthetic system and worldview of fashion design cases, shedding light on their pivotal role in envisioning and shaping the future of fashion. Furthermore, the evolving significance of clothing in fashion shows is examined, highlighting the profound influence of fashion fiction in reshaping the experiential and conceptual dimensions of fashion presentations. By delving into the role of fashion designers as visionary speculators, the study investigates their capacity to craft alternative presents and possible futures through the creative lens of fashion fiction.",Springer
"Vekeman, Jelle and Faginas-Lago, Noelia and Cuesta, Inmaculada G. and S{\'a}nchez-Mar{\'i}n, Jos{\'e} and De Mer{\'a}s, Alfredo S{\'a}nchez",Nitrogen Gas on Graphene: Pairwise Interaction Potentials,2018,10.1007/978-3-319-95174-4_44,https://doi.org/10.1007/978-3-319-95174-4_44,Conference Paper,Computational Science and Its Applications -- ICCSA 2018,"We investigate different types of potential parameters for the graphene-nitrogen interaction. Interaction energies calculated at DFT level are fitted with the semi-emperical Improved Lennard-Jones potential. Both a pseudo-atom potential and a full atomistic potential are considered. Furthermore, we consider the influence of the electrostatic part on the parameters using different charge schemes found in the literature as well as optimizing the charges ourselves. We have obtained parameters for both the nitrogen dimer and the graphene-nitrogen system. For the former, the four-charges Cracknell scheme reproduces with high precision the CCSD(T) interaction energy as well as the experimental diffusion coefficient in both the pseudo-atom and full atomstic potential. In the second case, the atom-atom model provides an average interaction energy of 2.3 kcal/mol, comparable with the experimental graphene-{\$}{\$}{\backslash}text {\{}N{\}}{\_}{\{}{\backslash}text {\{}2{\}}{\}}{\$}{\$}interaction of 2.4 kcal/mol.",Springer
"Bielinskyi, Andrii O. and Matviychuk, Andriy V. and Serdyuk, Oleksandr A. and Semerikov, Serhiy O. and Solovieva, Victoria V. and Soloviev, Vladimir N.",Correlational and Non-extensive Nature of Carbon Dioxide Pricing Market,2022,10.1007/978-3-031-14841-5_12,https://doi.org/10.1007/978-3-031-14841-5_12,Conference Paper,ICTERI 2021 Workshops,"In this paper, at the first time, the analysis of correlational and non-extensive properties of the {\$}{\$}{\backslash}text {\{}CO{\}}{\_}{\{}2{\}}{\$}{\$}CO2emission market relying on the carbon emissions futures time series for the period 04.07.2008--10.05.2021 is performed, and the daily data of the power sector from the U.S. Carbon Monitor for the period 01.01.2019--10.05.2021, which consist the data of both individual countries (USA, Germany, China, India, United Kingdom, et al.) and global emissions (World) are investigated using such approach. To demonstrate the applicability of these methods on systems of another nature and complexity, the analysis of the Dow Jones Industrial Average (DJIA) index is presented. The results show that both futures and the DJIA are presented to be non-extensive, and the distribution of their normalized returns can be better described by power-law probability distributions, particularly, by {\$}{\$}q{\$}{\$}q-Gaussian. Tsallis triplet for the entire time series of {\$}{\$}{\backslash}text {\{}CO{\}}{\_}{\{}2{\}}{\$}{\$}CO2emissions futures and the DJIA is estimated, and {\$}{\$}q{\$}{\$}q-triplet as an indicator of crisis phenomena is presented, relying on the sliding window algorithm. It can be seen that the triplet behaves characteristically during economic crises. This study shows that the toolkit of the random matrix theory (RMT) allows to investigate the correlational nature of the carbon emissions market and to build appropriate indicators of crisis phenomena, which clearly reflect the collective dynamics of the entire research base during events of this kind.",Springer
"Iacobellis, Vito and Martellotta, Audrey M. N. and Gioia, Andrea and Prato, Davide and Totaro, Vincenzo and Bonelli, Rocco and Balacco, Gabriella and Esposito, Alisa A. M. G.","Investigation of a Flood Event Occurred on Lama Balice, in the Context of Hazard Map Evaluation in Karstic-Ephemeral Streams",2018,10.1007/978-3-319-95174-4_26,https://doi.org/10.1007/978-3-319-95174-4_26,Conference Paper,Computational Science and Its Applications -- ICCSA 2018,"In the context of flood risk assessment and urban territory protection, the proposed research is focused on the definition of flood hazard maps by using high-resolution Digital Terrain Models (DTMs) obtained by a Light Detection And Ranging [LiDAR], remote sensing technique. The hydrologic/hydraulic model was calibrated on a flood event occurred on June 2014 on Lama Balice, ephemeral stream located in Puglia (Southern Italy), using the water levels observed during field campaign. In particular the analysis was performed for the definition of hazard maps with return periods of 30, 200 and 500 years, exploiting a combined scheme of a mono/two dimensional flood propagation approach for the delineation of flooded areas. The conducted research gives a significant contribution for the assessment of techniques of dynamic hazard and risk evaluation, in order to support institutions (like Basin Authorities and Civil Protection agencies) and professionals, in the context of the application of recent European legislation on flood risk protection (Floods Directive 2007/60/EC) and for European programs of scientific research (as Horizon 2020) in ungauged karstic catchment.",Springer
"Virgo, Nathaniel and Biehl, Martin and McGregor, Simon",Interpreting Dynamical Systems as Bayesian Reasoners,2021,10.1007/978-3-030-93736-2_52,https://doi.org/10.1007/978-3-030-93736-2_52,Conference Paper,Machine Learning and Principles and Practice of Knowledge Discovery in Databases,"A central concept in active inference is that the internal states of a physical system parametrise probability measures over states of the external world. These can be seen as an agent's beliefs, expressed as a Bayesian prior or posterior. Here we begin the development of a general theory that would tell us when it is appropriate to interpret states as representing beliefs in this way. We focus on the case in which a system can be interpreted as performing either Bayesian filtering or Bayesian inference. We provide formal definitions of what it means for such an interpretation to exist, using techniques from category theory.",Springer
"Sterian, Paul E. and Pop, Florin and Iordache, Dan",Advance Multispectral Analysis for Segmentation of Satellite Image,2018,10.1007/978-3-319-95162-1_50,https://doi.org/10.1007/978-3-319-95162-1_50,Conference Paper,Computational Science and Its Applications -- ICCSA 2018,"This paper presents an application with record performance for electromagnetic spectrum analysis of multispectral satellite image. The analysis method is an application-specific pixels oriented to images segmentation. This kind of segmentation is used in remote sensing for land cover and land use classification and change detection. Regions of the image are clustered separately and then the results are combined, for this the processing method employs two types of clustering algorithms, each specialized to its task and steered towards obtaining a final meaningful segmentation. The results show good spatial coherency in segments and coherent borders between regions that were segmented separately.",Springer
"Shima, Yasuki and Hija, Ali Fathelalem",Responding to Regional Revitalisation and Socio-economic Challenges in Japan: Government Approaches and Use of Advanced Technologies,2024,10.1007/978-981-99-7339-2_24,https://doi.org/10.1007/978-981-99-7339-2_24,Conference Paper,Advances in Visual Informatics,"Japan has one of the world's fastest ageing populations, leading to a shrinking workforce and labour shortages in various industries, with consequent impacts on various aspects of Japanese life and society. Economic stagnation and deflation, energy security and environmental concerns, agricultural decline and its socio-economic effects, advances in technology and innovation are now key issues facing Japan, and government policies and initiatives have been designed to address these challenges and concerns. The objective of this paper is to explore the approaches and policies of the Japanese government and the status of the promotion and adoption of advanced technologies to address the socio-economic challenges facing Japan. The research paper examines the policies and approaches of the government, companies and farmers, and the status of the use of advanced technologies in agriculture to address socio-economic challenges, in line with the achievement of globally promoted goals. This research paper highlighted the policies and approaches applied by the government, companies and farmers, and the current status of the use of advanced technologies in agriculture to address socio-economic challenges and global strategic goals. The study shows that the Ministry of Agriculture, Forestry and Fisheries is leading the Japanese government's efforts to promote the use of advanced technologies to increase agricultural production and address socio-economic issues such as an ageing population, rural depopulation and economic stagnation in rural areas, as young people migrate to cities. Meanwhile, the Japanese government continues its initiatives and commitment to the global goals of developing sustainable energy and food supplies.",Springer
"Tolbatov, Iogann and Marrone, Alessandro",Structural Basis of the Biomolecular Action of Paddlewheel- and N-Heterocyclic-Carbene-Based Antitumor Metallodrugs: A Computational Perspective,2022,10.1007/978-3-031-10592-0_22,https://doi.org/10.1007/978-3-031-10592-0_22,Conference Paper,Computational Science and Its Applications -- ICCSA 2022 Workshops,"Metallodrugs are an essential component of the contemporary medicinal chemistry since they represent a crucial inventory of therapeutic agents against a myriad of cancers as well as viral, bacterial, and parasitic infections. Their unique features based on the presence of a metal center capable of transforming the electronic and steric features of its ligands incorporate the (possible) activation mechanisms, capability to multitarget, and the specific way of attacking a target via the ligand substitution mechanism. This minireview is dedicated to a short overview of the computational studies of paddlewheel- and N-heterocyclic-carbene-based antitumor metallodrugs with biomolecular targets, performed in our group. We particularly focus our attention on the structural features of the investigated systems, which present excellent examples highlighting the significance of incorporation of steric effects originating from metallodrug's ligands as well as the impact of the surrounding milieu.",Springer
"Rathee, Deevashwer and Schneider, Thomas and Shukla, K. K.",Improved Multiplication Triple Generation over Rings via RLWE-Based AHE,2019,10.1007/978-3-030-31578-8_19,https://doi.org/10.1007/978-3-030-31578-8_19,Conference Paper,Cryptology and Network Security,"An important characteristic of recent MPC protocols is an input-independent setup phase in which most computations are offloaded, which greatly reduces the execution overhead of the online phase where parties provide their inputs. For a very efficient evaluation of arithmetic circuits in an information-theoretic online phase, the MPC protocols consume Beaver multiplication triples generated in the setup phase. Triple generation is generally the most expensive part of the protocol, and improving its efficiency is the aim of our work.",Springer
"Tolbatov, Iogann and Marrone, Alessandro and Paciotti, Roberto and Re, Nazzareno and Coletti, Cecilia",Multilayered Modelling of the Metallation of Biological Targets,2021,10.1007/978-3-030-87016-4_30,https://doi.org/10.1007/978-3-030-87016-4_30,Conference Paper,Computational Science and Its Applications -- ICCSA 2021,"The unique property of metals -- the remarkable ability to modulate the electronic structure of both metal center and bound ligands -- is the reason for their omnipresence in enzymes and in metal-coordinating biological factors. Modern metallodrug chemistry began with the serendipitous unveiling of the antitumour properties of cisplatin, followed by an avalanche of synthesized novel metallodrugs. The metallation of biological targets has then become a new paradigm in the field of bioinorganic chemistry, and a plethora of computational approaches have been developed and utilized to ease the detailed comprehension of its mechnisms with a focus on medical applications. Studies of the electronic structure of metallodrugs and of the coordination of metal elements with biomolecular ligands, as well as an accurate description of both thermodynamics and kinetics of reactions with biomolecules, are crucial for development of novel metallodrugs with improved therapeutic profiles. Here, we provide an account of the application of multilayered computational schemes developed in our group for the study of processes leading and/or culminating with the metallation of biomolecules, the key step in the mechanism of action of metallodrugs.",Springer
"Battaglia, Stefano and Evangelisti, Stefano and Leininger, Thierry and Faginas-Lago, Noelia",Confinement of the Pentanitrogen Cation Inside Carbon Nanotubes,2018,10.1007/978-3-319-95174-4_45,https://doi.org/10.1007/978-3-319-95174-4_45,Conference Paper,Computational Science and Its Applications -- ICCSA 2018,"In recent years, the field of polynitrogen chemistry has seen a sparking activity, with new outstanding theoretical and experimental results. Polynitrogen clusters are excellent candidates for high-energy density materials, but their intrinsic instability poses great challenges for the synthesis and the subsequent storage. In this work, we explore by means of quantum chemical calculations the confinement of the pentanitrogen cation, N{\$}{\$}{\_}5^+{\$}{\$}, inside carbon nanotubes of different diameters. The interaction of the two fragments is such that a charge transfer from the nanotube to the nitrogen cation occurs and leads to the subsequent decomposition of N{\$}{\$}{\_}5^+{\$}{\$}, thus resulting in an overall unstable system. Nonetheless, preliminary results on the confinement of the neutral N{\$}{\$}{\_}8{\$}{\$}chain (as the product of an N{\$}{\$}{\_}5^+{\$}{\$}+ N{\$}{\$}{\_}3^-{\$}{\$}addition) are presented, where it is shown that the encapsulation decreases the overall energy of the complex system. Two stable N{\$}{\$}{\_}8{\$}{\$}isomers are discussed and a first investigation on possible decomposition pathways is carried out.",Springer
"Dambra, Carlo and Graf, Chanan and Arias, Jordi and Gralewski, Alex",A Dynamic Risk Assessment (DRA) Methodology for High Impact Low Probability (HILP) Security Risks,2020,10.1007/978-3-030-37670-3_15,https://doi.org/10.1007/978-3-030-37670-3_15,Conference Paper,Critical Information Infrastructures Security,"This paper proposes a Dynamic Risk Assessment (DRA) methodology applicable to the so-called High Impact Low Probability (HILP) security risks which, by their very nature, are difficult to identify or occur only infrequently. DRA is based on the processing of Weak Signals (WSs) to protect critical infrastructures and soft targets against HILP security risks before they materialise. DRA allows to rank WSs according to the reliability and credibility of the sources and to correlate them to obtain threat precursors. Experimental results have shown that DRA is effective and helps suppressing irrelevant alerts.",Springer
"Sha, Chunlin and Zhao, Hongyong",Design of Synthesizing Multi-valued High-Capacity Auto-associative Memories Based on Complex-Valued Networks,2018,10.1007/978-3-030-04167-0_42,https://doi.org/10.1007/978-3-030-04167-0_42,Conference Paper,Neural Information Processing,This paper presents a novel design method which is aimed to synthesize arbitrary multi-valued auto-associative memories via complex-valued neural networks. Globally exponential stable criteria are obtained to guarantee that the unique storage prototype can be retrieved. The proposed procedure enables auto-associative memories to be synthesized by satisfying the constraints of inequalities rather than the learning procedure. The main emphasis of the research presented here is on multi-valued high-capacity auto-associative memories via complex-valued networks. The designed auto-associative memories with {\$}{\$}(2r+2)^n{\$}{\$}high memory capacities are robust with respect to design parameter selection and extend the scope of application of complex-valued neural networks. The approach of external inputs via complex-valued neural networks avoids spurious equilibria and retrieves the stored patters accurately. Some applicable experiments are given to illustrate the effectiveness and superiority.,Springer
"Andr{\'e}, {\'E}tienne and Duflot, Marie and Laversa, Laetitia and Lefaucheux, Engel",Execution-Time Opacity Control for Timed Automata,2025,10.1007/978-3-031-77382-2_20,https://doi.org/10.1007/978-3-031-77382-2_20,Conference Paper,Software Engineering and Formal Methods,"Timing leaks in timed automata (TA) can occur whenever an attacker is able to deduce a secret by observing some timed behavior. In execution-time opacity, the attacker aims at deducing whether a private location was visited, by observing only the execution time. It can be decided whether a TA is opaque in this setting. In this work, we tackle control, and show that we are able to decide whether a TA can be controlled at runtime to ensure opacity. Our method is constructive, in the sense that we can exhibit such a controller. We also address the case when the attacker cannot have an infinite precision in its observations.",Springer
"Iordache, Dan Alexandru and Sterian, Paul Enache",Study of Some Complex Systems by Using Numerical Methods,2018,10.1007/978-3-319-95165-2_38,https://doi.org/10.1007/978-3-319-95165-2_38,Conference Paper,Computational Science and Its Applications -- ICCSA 2018,"The study deals with the complex systems in Nature by using of some specific numerical methods. First the method of the physical similarity is used for the characterization of the fluids flow regimes. Then, the method of the power laws and some of its multiple uses in Physics and another related fields are analyzed. The method of phenomenological universality, applied to the description of the growth processes is also discussed. The authors results presented in the paper were mainly obtained by computer simulations using the finite difference (FD) method and the classical gradient method (CGM).",Springer
"Caglioti, Concetta and De Luca, Antonella and Pennetta, Chiara and Monarca, Lorenzo and Ragonese, Francesco and Sabbatini, Paola and Lago, Maria Noelia Faginas and Lombardi, Andrea and Palazzetti, Federico and Fioretti, Bernard",A Theoretical Study on trans-Resveratrol - Cu(I) Complex,2022,10.1007/978-3-031-10592-0_18,https://doi.org/10.1007/978-3-031-10592-0_18,Conference Paper,Computational Science and Its Applications -- ICCSA 2022 Workshops,"Resveratrol is a natural occurring phenol, found in peanuts, cocoa, and fruits like for example grapes, blueberries, and strawberries. It has become popular in the last decades for the possible correlation of wine, especially red wine, and cardioprotective properties. It is widely employed in nutraceutics production. It presents stilbenoid structure; in nature there are two isomers, cis and trans, this latter is the most stable. Here, we present a preliminary investigation on the most stable complex that trans-resveratrol forms with Cu(I), an essential trace element in living organisms, that takes part to redox processes, where resveratrol plays an antioxidative role. The structure of trans-resveratrol - Cu(I) is optimized in vacuum and in solvents like water and ethanol, by Density Functional Theory methods. Dissociation and solvation energies of the complex are calculated. Infrared spectra are calculated and compared with experimental data, available in literature.",Springer
"Sokolova, Ana and Woracek, Harald",Proper Semirings and Proper Convex Functors,2018,10.1007/978-3-319-89366-2_18,https://doi.org/10.1007/978-3-319-89366-2_18,Conference Paper,Foundations of Software Science and Computation Structures,"Esik and Maletti introduced the notion of a proper semiring and proved that some important (classes of) semirings -- Noetherian semirings, natural numbers -- are proper. Properness matters as the equivalence problem for weighted automata over a semiring which is proper and finitely and effectively presented is decidable. Milius generalised the notion of properness from a semiring to a functor. As a consequence, a semiring is proper if and only if its associated ``cubic functor'' is proper. Moreover, properness of a functor renders soundness and completeness proofs for axiomatizations of equivalent behaviour.",Springer
"Gadarapulla, Rasheed and Sriadibhatla, Sridevi",Tunnel FET Based SRAM Cells -- A Comparative Review,2021,10.1007/978-981-16-5048-2_17,https://doi.org/10.1007/978-981-16-5048-2_17,Conference Paper,"Microelectronic Devices, Circuits and Systems","This paper reviews some of the recent developments in Tunnel FET based SRAM cells. Tunnel Field Effect Transistor (TFET) is a potential contender to outperform CMOS at low voltages. Unique characteristics of TFET such as band-to-band tunneling, subthreshold swing (SS){\thinspace}<{\thinspace}60 mV/dec, and very low leakage current are suitable for designing ultra-low-power circuits. Novel techniques are proposed in recent years to address the issue of low ON-current (ION) and ambipolarity in TFET. We will review the performance of various TFET based SRAM cells in terms of stability, access times, and power consumption during the read and write operation. Parameters such as read static noise margin (RSNM), write SNM (WSNM), read delay, and write delay, read power, write power, and leakage power are considered for comparing various TFET based SRAM cells. The study shows that the heterojunction TFET based SRAM is superior to homojunction TFET based SRAM in terms of lower power consumption and faster access times.",Springer
"Wu, Shi-Liang and Li, Cui-Xia",Modified LPMHSS Method for a Class of Complex Symmetric Linear Systems,2021,10.1007/978-3-030-72792-5_14,https://doi.org/10.1007/978-3-030-72792-5_14,Conference Paper,Simulation Tools and Techniques,"In this paper, a modified LPMHSS (MLPMHSS) method is proposed to solve the problem of a class of complex symmetric linear systems with strong Hermitian parts. Theoretical analysis shows that the MLPMHSS method can converge to the unique solution of linear equations under appropriate conditions. Numerical experiments show that the method is effective.",Springer
"Sultana, Sanjida and Haassan, Md. Faiyaz Bin and Biswas, Shovasis Kumar and Talukder, Hriteshwar",A Highly Sensitive Gold-TiO2 Coated Dual-Core PCF-SPR Sensor with a Large Detection Range,2021,10.1007/978-981-16-5048-2_33,https://doi.org/10.1007/978-981-16-5048-2_33,Conference Paper,"Microelectronic Devices, Circuits and Systems","This study is based on the design and numerical investigation of a high-accuracy plasmonic biosensor. A dual-core Photonic Crystal Fiber (PCF) has been designed to obtain superior characteristics to its kindred. As for the plasmonic layer, a thin layer of titanium dioxide over a layer of gold has been used both of which contribute to the occurrence of Surface Plasmon Resonance (SPR). Circular airholes positioned in a rectangular manner pave the way to light entrapment. A Perfectly Matched layer (PML) is placed to help absorb the reflected light. The analysis of this structure's performance was carried out considering the wavelength and amplitude sensitivity, the figure of merit (FOM), and the sensor resolution. The values go as fine as 22,000 nm/RIU for wavelength sensitivity, 3446 RIUéä½¹åéå¿å¹éçµor amplitude sensitivity, and 4.54{\thinspace}{\texttimes}{\thinspace}10éä½¹åéå¿å¹éçµor the sensor's resolution. Also, the maximum FOM found is 241.76 RIUéä½¹åéå¿å¹éï¿½The proposed structure, where the external sensing technique is used, shows excellent micro-scale sensing properties. To achieve such attributes, different structural parameters like pitch, gold and TiO2 thickness, and air-hole diameters were altered. Keeping in mind the feasibility of fabrication, the design was kept simple while balancing the optimum properties.",Springer
"Vanuzzo, Gianmarco and Giustini, Andrea and Rosi, Marzio and Casavecchia, Piergiorgio and Balucani, Nadia","Theoretical Study of the Reaction O(3P){\thinspace}+{\thinspace}1,2-Butadiene",2022,10.1007/978-3-031-10592-0_19,https://doi.org/10.1007/978-3-031-10592-0_19,Conference Paper,Computational Science and Its Applications -- ICCSA 2022 Workshops,"The triplet and singlet potential energy surfaces of the O(3P){\thinspace}+{\thinspace}1,2-butadiene reaction have been investigated by electronic structure calculations at the coupled-cluster (CCSD(T)(aug-cc-pVTZ) level. We focused our attention, in particular, on the different sites of attack of atomic oxygen to 1, 2-butadiene. The results for minima, transition states and reaction channel energetics are compared with the results of previous CCSD(T)(aug-cc-pVTZ)-CBS and CASPT2 calculations to explore the adequacy of simpler computational schemes for discussing the reaction dynamics, in particular the product branching fractions derived from crossed molecular beam experiments.",Springer
"Diaz-Munoz, Ana; Rodriguez, Moises; Piattini, Mario",Implementing an environment for hybrid software evaluation,2024,10.1016/j.scico.2024.103109,https://doi.org/10.1016/j.scico.2024.103109,Journal,SCIENCE OF COMPUTER PROGRAMMING,"Quantum computing is a revolutionary paradigm in computer science based on the principles of quantum mechanics. It has the potential to solve problems that are currently unsolvable for classical computing. Applications of quantum computing already span a variety of sectors. Ongoing enhancements to the integrated programming and development environment simplify the creation and optimization of quantum algorithms. Ultimately, the focus on supporting tools represents the starting point towards achieving quantum computing maturity, facilitating its transition from an experimental domain to a practical industry. As quantum software gains ground and relevance in various domains, it is essential to address the evaluation of hybrid systems that combine classical and quantum elements to ensure diverse quality characteristics. However, in the realm of quantum software, models, metrics, and tools are still to be established. The primary contribution of this paper is to present the first technological environment for measuring and evaluating the analyzability of hybrid software. Real -world examples of hybrid software are provided to showcase the functionality of the different tools in the environment, yielding readable and representative results for the evaluator.",Web of Science
"Di Marcantonio, Francesco; Incudini, Massimiliano; Tezza, Davide; Grossi, Michele",Quantum Advantage Seeker with Kernels (QuASK): a software framework to speed up the research in quantum machine learning,2023,10.1007/s42484-023-00107-2,https://doi.org/10.1007/s42484-023-00107-2,Journal,QUANTUM MACHINE INTELLIGENCE,"Exploiting the properties of quantum information to the benefit of machine learning models is perhaps the most active field of research in quantum computation. This interest has supported the development of a multitude of software frameworks (e.g. Qiskit, Pennylane, Braket) to implement, simulate, and execute quantum algorithms. Most of them allow us to define quantum circuits, run basic quantum algorithms, and access low-level primitives depending on the hardware such software is supposed to run. For most experiments, these frameworks have to be manually integrated within a larger machine learning software pipeline. The researcher is in charge of knowing different software packages, integrating them through the development of long code scripts, analyzing the results, and generating the plots. Long code often leads to erroneous applications, due to the average number of bugs growing proportional with respect to the program length. Moreover, other researchers will struggle to understand and reproduce the experiment, due to the need to be familiar with all the different software frameworks involved in the code script. We propose QuASK, an open-source quantum machine learning framework written in Python that aids the researcher in performing their experiments, with particular attention to quantum kernel techniques. QuASK can be used as a command-line tool to download datasets, pre-process them, quantum machine learning routines, analyze and visualize the results. QuASK implements most state-of-the-art algorithms to analyze the data through quantum kernels, with the possibility to use projected kernels, (gradient-descent) trainable quantum kernels, and structure-optimized quantum kernels. Our framework can also be used as a library and integrated into pre-existing software, maximizing code reuse.",Web of Science
"Sangeetha, M.; Malathi, S.",Modeling Metaheuristic Optimization with Deep Learning Software Bug Prediction Model,2022,10.32604/iasc.2022.025192,https://doi.org/10.32604/iasc.2022.025192,Journal,INTELLIGENT AUTOMATION AND SOFT COMPUTING,"Software testing is an effective means of verifying software stability and trustworthiness. It is essential in the software development process and needs a huge quantity of resources such as labor, money, and time. Automated software testing can be used to save manual work, shorten testing times, and improve testing performance. Recently, Software Bug Prediction (SBP) models have been developed to improve the software quality assurance (SQA) process through the prediction of bug parts. Advanced deep learning (DL) models can be used to classify faults in software parts. Because hyperparameters have a significant impact on the performance of any DL model, a proper hyperparameter optimization approach utilizing metaheuristic methods is required. This paper provides a unique Metaheuristic Optimization with Deep Learning based SBP (MODL-SBP) methodology to ensure software dependability and trustworthiness. The suggested technique entails creating a hybrid Convolution Neural Network (CNN) bi-directional long short-term memory (BiLSTM) to forecast software problems. Furthermore, the Chaotic Quantum Grasshopper Optimization Algorithm (CQGOA) is used for hyperparameter optimization of the CNN-BiLSTM models, which enhances predictive accuracy. To demonstrate the superior performance of the MODL-SBP technique, a wide range of simulations are performed on benchmark datasets, with the results highlighting the superior performance of the proposed model over other recent techniques.",Web of Science
"Kumari, A. Charan; Srinivas, K.",Comparing the performance of quantum-inspired evolutionary algorithms for the solution of software requirements selection problem,2016,10.1016/j.infsof.2016.04.010,https://doi.org/10.1016/j.infsof.2016.04.010,Journal,INFORMATION AND SOFTWARE TECHNOLOGY,"Context: In requirements engineering phase of the software development life cycle, one of the main concerns of software engineers is to select a set of software requirements for implementation in the next release of the software from many requirements proposed by the customers, while balancing budget and customer satisfaction.Objective: To analyse the efficacy of Quantum-inspired Elitist Multi-objective Evolutionary Algorithm (QE-MEA), Quantum-inspired Multi-objective Differential Evolution Algorithm (QMDEA) and Multi-objective Quantum-inspired Hybrid Differential Evolution (MQHDE) in solving the software requirements selection problem.Method: The paper reports on empirical evaluation of the performance of three quantum-inspired multi objective evolutionary algorithms along with Non-dominated Sorting Genetic Algorithm-II (NSGA-II). The comparison includes the obtained Pareto fronts, the three performance metrics - Generational Distance, Spread and Hypervolume, attained boundary solutions, and size of the Pareto front.Results: The results reveal that MQHDE outperformed other methods in producing high quality solutions; while QMDEA is able to produce well distributed solutions with extreme boundary solutions.Conclusion: The hybridization of Differential Evolution with Genetic Algorithms coupled with quantum computing concepts (MQHDE) provided a means to effectively balance the two issues of multi-objective optimization - convergence and diversity. (c) 2016 Elsevier B.V. All rights reserved.",Web of Science
"Anju, A. J.; Judith, J. E.",Adaptive recurrent neural network for software defect prediction with the aid of quantum theory- particle swarm optimization,2023,10.1007/s11042-022-14065-7,https://doi.org/10.1007/s11042-022-14065-7,Journal,MULTIMEDIA TOOLS AND APPLICATIONS,"With the proliferation of software programs, predicting defects has become a big concern. Therefore, to overcome this challenge, this research introduces a new Optimized Deep Learning model. The software defect is predicted using the new Adaptive Recurrent Neural network (ARNN), wherein the hyper-parameters (weight) function is fine-tuned using the new Levy-Flight Integrated Cuckoo Search Optimization (LICSO) model to accurately predict the defects. First, the data is pre-processed via box-cox transformation. The outcomes of the pre-processed data are then subjected to a Feature Selection technique, wherein the relevant features are selected using the new Quantum Theory-Particle Swarm Optimization (QPSO-FS). Finally, ARNN is utilized to predict the software defects. To validate the performance of the proposed approach evaluation metrics are considered such as detection Accuracy, Precision, Recognition error, Sensitivity, Specificity, F1-Score, and Processing time are evaluated and tested. As per the acquired results, the projected model outperforms the existing models. The projected model has recorded the highest accuracy level as 96.48%.",Web of Science
"Liu, Bo; Zhou, Guo; Zhou, Yongquan; Luo, Qifang; Wei, Yuanfei",Quantum-inspired multi-objective African vultures optimization algorithm with hierarchical structure for software requirement,2024,10.1007/s10586-024-04503-6,https://doi.org/10.1007/s10586-024-04503-6,Journal,CLUSTER COMPUTING-THE JOURNAL OF NETWORKS SOFTWARE TOOLS AND APPLICATIONS,"The software requirement selection problem endeavors to ascertain the optimal set of software requirements with the dual objectives of minimizing software cost and maximizing customer satisfaction. The intricate nature of this problem stems from the interdependencies among individual software requirements, rendering it a complicated NP-hard problem. In this paper, we introduce a novel multi-objective optimization algorithm christened the Quantum -Inspired Multi-Objective African Vulture Optimization Algorithm with Hierarchical Structures (QMO_HSAVOA), where hierarchical structure and in-quantum computation ideas are introduced to improve the performance of the algorithm in QMO_HSAVOA. To gauge the efficacy of QMO_HSAVOA in tackling the software requirement selection problem, we empirically apply it to the problem, orchestrating three distinct simulation experiments. The ensuing evaluation of QMO_HSAVOA's performance is conducted with meticulous scrutiny through the application of Friedman's statistical test to the experimental outcomes. These results decisively demonstrate that the proposed QMO_HSAVOA not only delivers exceptionally competitive outcomes but also outshines alternative algorithms. This finding provision is an innovative and highly efficient solution for addressing the software requirement selection problem.",Web of Science
"Akbar, Muhammad Azeem; Khan, Arif Ali; Shameem, Mohammad; Nadeem, Mohammad",Genetic model-based success probability prediction of quantum software development projects,2024,10.1016/j.infsof.2023.107352,https://doi.org/10.1016/j.infsof.2023.107352,Journal,INFORMATION AND SOFTWARE TECHNOLOGY,"Context: Quantum computing (QC) holds the potential to revolutionize computing by solving complex problems exponentially faster than classical computers, transforming fields such as cryptography, optimization, and scientific simulations. To unlock the potential benefits of QC, quantum software development (QSD) enables harnessing its power, further driving innovation across diverse domains. To ensure successful QSD projects, it is crucial to concentrate on key variables.Objective: This study aims to identify key variables in QSD and develop a model for predicting the success probability of QSD projects.Methodology: We identified key QSD variables from existing literature to achieve these objectives and collected expert insights using a survey instrument. We then analyzed these variables using an optimization model, i.e., Genetic Algorithm (GA), with two different prediction methods the Naive Bayes Classifier (NBC) and Logistic Regression (LR).Results: The results of success probability prediction models indicate that as the QSD process matures, project success probability significantly increases, and costs are notably reduced. Furthermore, the best fitness rankings for each QSD project variable determined using NBC and LR indicated a strong positive correlation (rs=0.945). The t-test results (t = 0.851, p = 0.402>0.05) show no significant differences between the rankings calculated by the two methods (NBC and LR).Conclusion: The results reveal that the developed success probability prediction model, based on 14 identified QSD project variables, highlights the areas where practitioners need to focus more in order to facilitate the costeffective and successful implementation of QSD projects.",Web of Science
"Romero-Alvarez, Javier; Alvarado-Valiente, Jaime; Moguel, Enrique; Garcia-Alonso, Jose; Murillo, Juan M.",Enabling continuous deployment techniques for quantum services,2024,10.1002/spe.3326,https://doi.org/10.1002/spe.3326,Journal,SOFTWARE-PRACTICE & EXPERIENCE,"Early advances in quantum computing have provided new opportunities to tackle intricate problems in diverse areas such as cryptography, optimization, and simulation. However, current methodologies employed in quantum computing often require, among other things, a broad understanding of quantum hardware and low-level programming languages, posing challenges to software developers in effectively creating and implementing quantum services. This study advocates the adoption of software engineering principles in quantum computing, thereby establishing a higher level of hardware abstraction that allows developers to focus on application development. With this proposal, developers can design and deploy quantum services with less effort, which is similar to the facilitation provided by service-oriented computing for the development of conventional software services. This study introduces a continuous deployment strategy adapted to the development of quantum services that covers the creation and deployment of such services. For this purpose, an extension of the OpenAPI specification is proposed, which allows the generation of services that implement quantum algorithms. The proposal was validated through the creation of an application programming interface with diverse quantum algorithm implementations and evaluated through a survey of various developers and students who were introduced to the tool with positive results.","Web of Science, Wiley"
"Jin, Cong",Cross-project software defect prediction based on domain adaptation learning and optimization,2021,10.1016/j.eswa.2021.114637,https://doi.org/10.1016/j.eswa.2021.114637,Journal,EXPERT SYSTEMS WITH APPLICATIONS,"Software defect prediction (SDP) is very helpful for optimizing the resource allocation of software testing and improving the quality of software products. The cross-project defect prediction (CPDP) model based on machine learning is first learned through the existing training data with sufficient number and defect labels on one project, and then used to predict the defect labels of another new project with insufficient number and fewer labeled data. However, its prediction performance has a large gap compared with the within-project defect prediction (WPDP) model. The main reason is that there are usually differences between the distributions of training data in different software projects, and it has a greater impact on the prediction performance of the CPDP model. To solve this problem, the kernel twin support vector machines (KTSVMs) is used to implement domain adaptation (DA) to match the distributions of training data for different projects. Moreover, KTSVMs with DA function (called DA-KTSVM) is further used as the CPDP model in this paper. Since the parameters of DA-KTSVM have an impact on its predictive performance, these parameters are optimized by an improved quantum particle swarm optimization algorithm (IQPSO), and the optimized DA-KTSVM is called as DAKTSVMO. In order to confirm the effectiveness of DA-KTSVMO, some experiments are implemented on 17 open source software projects. Experimental results and analysis show that DA-KTSVMO can not only achieve better prediction performance than other CPDP models compared, but also achieve almost the same or better compared performance than WPDP models when the training sample data is sufficient. In addition, DA-KTSVMO can make better use of existing sufficient data knowledge and realize the reuse of defective data to improve the prediction performance of DA-KTSVMO.",Web of Science
"Zhang, Quanyuan; Li, Haolun; Liu, Yanli; Ouyang, Shangrong; Fang, Caiting; Mu, Wentao; Gao, Hao",A new quantum particle swarm optimization algorithm for controller placement problem in software-defined networking,2021,10.1016/j.compeleceng.2021.107456,https://doi.org/10.1016/j.compeleceng.2021.107456,Journal,COMPUTERS & ELECTRICAL ENGINEERING,"As a new network control and management method for network, software-defined networking (SDN) algorithms have attracted more attention to make networks agile and flexible. To meet the requirements of users and conquer the physical limitation of network, it is necessary to design an efficient controller placement mechanism of SDN, which is defined as an optimization problem to determine the proper positions and number of its controllers. As a modern optimization tool, Quantum-behavior particle swarm optimization (QPSO) algorithm demonstrates power fast convergence rate but limits in global search ability. In this paper, by introducing a full search history and excellent dimension update strategy into the traditional QPSO algorithm which enhances its performance, simulation results show that the proposed algorithm achieves better performance in dozens of different multi-controller placement problems.",Web of Science
"Jin, Cong; Jin, Shu-Wei",Parameter optimization of software reliability growth model with S-shaped testing-effort function using improved swarm intelligent optimization,2016,10.1016/j.asoc.2015.11.041,https://doi.org/10.1016/j.asoc.2015.11.041,Journal,APPLIED SOFT COMPUTING,"Software reliability growth model (SRGM) with testing-effort function (TEF) is very helpful for software developers and has been widely accepted and applied. However, each SRGM with TEF ( SRGMTEF) contains some undetermined parameters. Optimization of these parameters is a necessary task. Generally, these parameters are estimated by the Least Square Estimation (LSE) or the Maximum Likelihood Estimation (MLE). We found that the MLE can be used only when the software failure data to satisfy some assumptions such as to satisfy a certain distribution. However, the software failure data may not satisfy such a distribution. In this paper, we investigate the improvement and application of a swarm intelligent optimization algorithm, namely quantum particle swarm optimization (QPSO) algorithm, to optimize these parameters of SRGMTEF. The performance of the proposed SRGMTEF model with optimized parameters is also compared with other existing models. The experiment results show that the proposed parameter optimization approach using QPSO is very effective and flexible, and the better software reliability growth performance can be obtained based on SRGMTEF on the different software failure datasets. (C) 2015 Elsevier B.V. All rights reserved.",Web of Science
"Karimi, Mehdi; Tuncel, Levent",Domain-Driven Solver (DDS) Version 2.1: a MATLAB-based software package for convex optimization problems in domain-driven form,2024,10.1007/s12532-023-00248-2,https://doi.org/10.1007/s12532-023-00248-2,Journal,MATHEMATICAL PROGRAMMING COMPUTATION,"Domain-Driven Solver (DDS) is a MATLAB-based software package for convex optimization. The current version of DDS accepts every combination of the following function/set constraints: (1) symmetric cones (LP, SOCP, and SDP); (2) quadratic constraints that are SOCP representable; (3) direct sums of an arbitrary collection of 2-dimensional convex sets defined as the epigraphs of univariate convex functions (including as special cases geometric programming and entropy programming); (4) generalized Koecher (power) cone; (5) epigraphs of matrix norms (including as a special case minimization of nuclear norm over a linear subspace); (6) vector relative entropy; (7) epigraphs of quantum entropy and quantum relative entropy; and (8) constraints involving hyperbolic polynomials. The infeasible-start primal-dual algorithms used for DDS rely heavily on duality theory and properties of Legendre-Fenchel conjugate functions, and are designed to rigorously determine the status of a given problem. We discuss some important implementation details and techniques we used to improve the robustness and efficiency of the software. The appendix contains many examples.",Web of Science
"Bajaj, Anu; Sangwan, Om Prakash; Abraham, Ajith",Improved novel bat algorithm for test case prioritization and minimization,2022,10.1007/s00500-022-07121-9,https://doi.org/10.1007/s00500-022-07121-9,Journal,SOFT COMPUTING,"Regression testing is essential for continuous integration and continuous development. It is needed to ensure that the modifications have not produced any errors or faults, thereby maintaining the quality and reliability of the software. The testers usually avoid exhaustive retesting because it requires lots of effort and time. The test case prioritization and minimization solve the issue by scheduling the critical test cases and removing redundant ones. Optimization techniques help by improving the efficiency of these techniques while utilizing limited resources. This paper proposed an enhanced discrete novel bat algorithm for the test case prioritization. The algorithm is modified in two ways. First, we have proposed a fix-up mechanism for the discrete combinatorial problem, which conducts the perturbation in the population using the asexual reproduction algorithm. Second, the novel bat algorithm is improved, where the bats hunt in different habitats with quantum behavior using Gaussian distribution and search in the limited habitat with Doppler effect. In addition, we have embedded the test case minimization procedure in the algorithm for redundancy reduction. The experimental results are empirically analyzed using different testing criteria, i.e., fault and statement coverage on three subject programs from the software infrastructure repository. Consequently, test selection percentage, coverage loss, fault detection loss, and cost reduction percentages are deduced for the test case minimization at program and version levels. Empirical results and statistical comparisons with the random search, bat algorithm, novel bat algorithm, birds swarm algorithm, whale optimization algorithm, and genetic algorithm show the outperformance of the proposed algorithm.",Web of Science
"Kushnir, Samuel; Leng, Jiaqi; Peng, Yuxiang; Fan, Lei; Wu, Xiaodi",QHDOPT: A Software for Nonlinear Optimization with Quantum Hamiltonian Descent,2024,10.1287/ijoc.2024.0587,https://doi.org/10.1287/ijoc.2024.0587,Journal,INFORMS JOURNAL ON COMPUTING,"We develop an open-source, end-to-end software (named QHDOPT), which can solve nonlinear optimization problems using the quantum Hamiltonian descent (QHD) algorithm. QHDOPT offers an accessible interface and automatically maps tasks to various supported quantum backends (i.e., quantum hardware machines). These features enable users, even those without prior knowledge or experience in quantum computing, to utilize the power of existing quantum devices for nonlinear and nonconvex optimization tasks. In its intermediate compilation layer, QHDOPT employQs SimuQ, an efficient interface for Hamiltonian-oriented programming, to facilitate multiple algorithmic specifications and ensure compatible cross-hardware deployment. The detailed documentation of QHDOPT is available at https://github.com/jiaqileng/QHDOPT.",Web of Science
"Schaetzle, Z.; Szabo, P. B.; Mezera, M.; Hermann, J.; Noe, F.",DeepQMC: An open-source software suite for variational optimization of deep-learning molecular wave functions,2023,10.1063/5.0157512,https://doi.org/10.1063/5.0157512,Journal,JOURNAL OF CHEMICAL PHYSICS,"Computing accurate yet efficient approximations to the solutions of the electronic Schrodinger equation has been a paramount challenge of computational chemistry for decades. Quantum Monte Carlo methods are a promising avenue of development as their core algorithm exhibits a number of favorable properties: it is highly parallel and scales favorably with the considered system size, with an accuracy that is limited only by the choice of the wave function Ansatz. The recently introduced machine-learned parametrizations of quantum Monte Carlo Ansatze rely on the efficiency of neural networks as universal function approximators to achieve state of the art accuracy on a variety of molecular systems. With interest in the field growing rapidly, there is a clear need for easy to use, modular, and extendable software libraries facilitating the development and adoption of this new class of methods. In this contribution, the DEEPQMC program package is introduced, in an attempt to provide a common framework for future investigations by unifying many of the currently available deep-learning quantum Monte Carlo architectures. Furthermore, the manuscript provides a brief introduction to the methodology of variational quantum Monte Carlo in real space, highlights some technical challenges of optimizing neural network wave functions, and presents example black-box applications of the program package. We thereby intend to make this novel field accessible to a broader class of practitioners from both the quantum chemistry and the machine learning communities.",Web of Science
"Almotiri, Sultan H",Quantum-resilient software security: A fuzzy AHP-based assessment framework in the era of quantum computing.,2024,10.1371/journal.pone.0316274,https://doi.org/10.1371/journal.pone.0316274,Journal,PloS one,"The introduction of quantum computing has transformed the setting of information technology, bringing both unprecedented opportunities and significant challenges. As quantum technologies continue to evolve, addressing their implications for software security has become an essential area of research. This paradigm change provides an unprecedented chance to strengthen software security from the start, presenting a plethora of novel alternatives. We use a multi-criteria decision-making methodology in this work to evaluate the efficacy of quantum computing approaches in improving software security. As the number of electronic applications grows, software developers strive to produce more sophisticated and user-friendly alternatives. However, in the pursuit of complexity, vulnerabilities may be introduced inadvertently, posing a substantial danger to software security. Our study addresses five major components of the quantum method to overcome these challenges: lattice-based cryptography, fully homomorphic algorithms, quantum key distribution, quantum hash functions, and blind quantum algorithms. The rapid development of quantum bits (qubits) regarded as basic quantum entities adds complexity and risk to the software security landscape. As a result, in the age of quantum computing, evaluating software security becomes not only necessary but also critical. To accomplish this objective, we propose the Fuzzy Analytic Hierarchy Process (F-AHP), a soft computing method, as a reliable tool for accomplishing this goal. Our research aims to prioritise security variables using quantum security criteria, providing an innovative viewpoint on software security evaluation in the quantum computing era.",Web of Science
"Nguyen, Hoa T.; Usman, Muhammad; Buyya, Rajkumar",QFaaS: A serverless function-as-a-service framework for quantum computing,2024,10.1016/j.future.2024.01.018,https://doi.org/10.1016/j.future.2024.01.018,Journal,INTERNATIONAL JOURNAL OF PHARMACEUTICS,"Quantum computing is rapidly reaching a point in which its application design and engineering aspects must beseriously considered. However, quantum software engineering is still in its infancy, with numerous challenges,especially in dealing with the diversity of quantum programming languages and noisy intermediate-scalequantum (NISQ) systems. To alleviate these challenges, we propose QFaaS, a holisticQuantumFunction-as-a-Service framework, which leverages the advantages of the serverless model, DevOps lifecycle, and thestate-of-the-art software techniques to advance practical quantum computing for next-generation applicationdevelopment in the NISQ era. Our framework provides essential elements of a serverless quantum systemto streamline service-oriented quantum application development in cloud environments, such as combininghybrid quantum-classical computation, automating the backend selection, cold start mitigation, and adaptingDevOps techniques. QFaaS offers a full-stack and unified quantum serverless platform by integrating multiplewell-known quantum software development kits (Qiskit, Q#, Cirq, and Braket), quantum simulators, and cloudproviders (IBM Quantum and Amazon Braket). This paper proposes the concept of quantum function-as-a-service, system design, operation workflows, implementation of QFaaS, and lessons learned on the benefitsand limitations of quantum serverless computing. We also present practical use cases with various quantumapplications on today's quantum computers and simulators to demonstrate our framework capability tofacilitate the ongoing quantum software transition.",Web of Science
"Tao, Yujun; Giese, Timothy J.; Ekesan, Solen; Zeng, Jinzhe; Aradi, Balint; Ben Hourahine; Aktulga, Hasan Metin; Gotz, Andreas W.; Merz Jr, Kenneth M.; York, Darrin M.",Amber free energy tools: Interoperable software for free energy simulations using generalized quantum mechanical/molecular mechanical and machine learning potentials,2024,10.1063/5.0211276,https://doi.org/10.1063/5.0211276,Journal,JOURNAL OF CHEMICAL PHYSICS,"We report the development and testing of new integrated cyberinfrastructure for performing free energy simulations with generalized hybrid quantum mechanical/molecular mechanical (QM/MM) and machine learning potentials (MLPs) in Amber. The Sander molecular dynamics program has been extended to leverage fast, density-functional tight-binding models implemented in the DFTB+ and xTB packages, and an interface to the DeePMD-kit software enables the use of MLPs. The software is integrated through application program interfaces that circumvent the need to perform system calls and enable the incorporation of long-range Ewald electrostatics into the external software's self-consistent field procedure. The infrastructure provides access to QM/MM models that may serve as the foundation for QM/MM-Delta MLP potentials, which supplement the semiempirical QM/MM model with a MLP correction trained to reproduce ab initio QM/MM energies and forces. Efficient optimization of minimum free energy pathways is enabled through a new surface-accelerated finite-temperature string method implemented in the FE-ToolKit package. Furthermore, we interfaced Sander with the i-PI software by implementing the socket communication protocol used in the i-PI client-server model. The new interface with i-PI allows for the treatment of nuclear quantum effects with semiempirical QM/MM-Delta MLP models. The modular interoperable software is demonstrated on proton transfer reactions in guanine-thymine mispairs in a B-form deoxyribonucleic acid helix. The current work represents a considerable advance in the development of modular software for performing free energy simulations of chemical reactions that are important in a wide range of applications.",Web of Science
"Seo, Seog Chung; An, Sang Woo; Choi, Dooho",Accelerating Falcon Post-Quantum Digital Signature Algorithm on Graphic Processing Units,2023,10.32604/cmc.2023.033910,https://doi.org/10.32604/cmc.2023.033910,Journal,CMC-COMPUTERS MATERIALS & CONTINUA,"Since 2016, the National Institute of Standards and Technology (NIST) has been performing a competition to standardize post-quantum cryptography (PQC). Although Falcon has been selected in the competition as one of the standard PQC algorithms because of its advantages in short key and signature sizes, its performance overhead is larger than that of other lattice-based cryptosystems. This study presents multiple methodologies to accelerate the performance of Falcon using graphics processing units (GPUs) for server-side use. Direct GPU porting significantly degrades performance because the Falcon reference codes require recursive functions in its sampling process. Thus, an iterative sampling approach for efficient parallel process-ing is presented. In this study, the Falcon software applied a fine-grained execution model and reported the optimal number of threads in a thread block. Moreover, the polynomial multiplication performance was optimized by parallelizing the number-theoretic transform (NTT)-based polynomial multiplication and the fast Fourier transform (FFT)-based multiplication. Furthermore, dummy-based parallel execution methods have been introduced to handle the thread divergence effects. The presented Falcon software on RTX 3090 NVIDA GPU based on the proposed methods with Falcon-512 and Falcon-1024 parameters outperform at 35.14, 28.84, and 34.64 times and 33.31, 27.45, and 34.40 times, respectively, better than the central processing unit (CPU) reference implementation using Advanced Vector Extensions 2 (AVX2) instructions on a Ryzen 9 5900X running at 3.7 GHz in key genera-tion, signing, and verification, respectively. Therefore, the proposed Falcon software can be used in servers managing multiple concurrent clients for efficient certificate verification and be used as an outsourced key generation and signature generation server for Signature as a Service (SaS).",Web of Science
"Lourenco, Maicon Pierre; Herrera, Lizandra Barrios; Hostas, Jiri; Calaminici, Patrizia; Koster, Andreas M.; Tchagang, Alain; Salahub, Dennis R.",A new active learning approach for adsorbate-substrate structural elucidation in silico,2022,10.1007/s00894-022-05173-0,https://doi.org/10.1007/s00894-022-05173-0,Journal,JOURNAL OF MOLECULAR MODELING,"Adsorbate interactions with substrates (e.g. surfaces and nanoparticles) are fundamental for several technologies, such as functional materials, supramolecular chemistry, and solvent interactions. However, modeling these kinds of systems in silico, such as finding the optimum adsorption geometry and energy, is challenging, due to the huge number of possibilities of assembling the adsorbate on the surface. In the current work, we have developed an artificial intelligence (AI) approach based on an active learning (AL) method for adsorption optimization on the surface of materials. AL uses machine learning (ML) regression algorithms and their uncertainties to make a decision (based on a policy) for the next unexplored structures to be computed, increasing, though, the probability of finding the global minimum with a small number of calculations. The methodology allows an accurate and automated structural elucidation of the adsorbate on the surface, based on the minimization of the total electronic energy. The new AL method for adsorption optimization was developed and implemented in the quantum machine learning software/agent for material design and discovery (QMLMaterial) program and was applied for C-60@TiO2 anatase (101). It marks another software extension with a new feature in addition to the automatic structural elucidation of defects in materials and of nanoparticles as well. SCC-DFTB calculations were used to build the complex search surfaces with a reasonably low computational cost. An artificial neural network (NN) was employed in the AL framework evaluated together with two uncertainty quantification methods: K-fold cross-validation and non-parametric bootstrap (BS) resampling. Also, two different acquisition functions for decision-making were used: expected improvement (EI) and the lower confidence bound (LCB).",Web of Science
"Neuhaus, Leonhard; Croquette, Michael; Metzdorff, Remi; Chua, Sheon; Jacquet, Pierre-Edouard; Journeaux, Alexandre; Heidmann, Antoine; Briant, Tristan; Jacqmin, Thibaut; Cohadon, Pierre-Francois; Deleglise, Samuel",Python Red Pitaya Lockbox (PyRPL): An open source software package for digital feedback control in quantum optics experiments,2024,10.1063/5.0178481,https://doi.org/10.1063/5.0178481,Journal,REVIEW OF SCIENTIFIC INSTRUMENTS,"We present the Python Red Pitaya Lockbox (PyRPL), an open source software package that allows the implementation of automatic digital feedback controllers for quantum optics experiments on commercially available, affordable Field-Programmable Gate Array (FPGA) boards. Our software implements the digital generation of various types of error signals, from an analog input through the application of loop filters of high complexity and real-time gain adjustment for multiple analog output signals, including different algorithms for resonance search, lock acquisition sequences, and in-loop gain optimization. Furthermore, all necessary diagnostic instruments, such as an oscilloscope, a network analyzer, and a spectrum analyzer, are integrated into our software. Apart from providing a quickly scalable, automatic feedback controller, the lock performance that can be achieved by using PyRPL with imperfect equipment, such as piezoelectric transducers and noisy amplifiers, is better than the one achievable with standard analog controllers due to the higher complexity of implementable filters and possibilities of nonlinear operations in the FPGA. This drastically reduces the cost of added complexity when introducing additional feedback loops to an experiment. The open-source character also distinguishes PyRPL from commercial solutions, as it allows users to customize functionalities at various levels, ranging from the easy integration of PyRPL-based feedback controllers into existing setups to the modification of the FPGA functionality. A community of developers provides fast and efficient implementation and testing of software modifications.",Web of Science
"Noakes, Travis; Harpur, Patricia; Uys, Corrie",Noteworthy Disparities With Four CAQDAS Tools: Explorations in Organising Live Twitter Data,2024,10.1177/08944393231204163,https://doi.org/10.1177/08944393231204163,Journal,SOCIAL SCIENCE COMPUTER REVIEW,"Qualitative data analysis software (QDAS) packages that support live data extraction are a relatively recent innovation. Little has been written concerning the research implications of differences in such QDAS packages' functionalities, and how such disparities might contribute to contrasting analytical opportunities. Consequently, early-stage researchers may experience difficulties in choosing an apt QDAS for Twitter analysis. In response to both methodological gaps, this paper presents a software comparison across the four QDAS tools that support live Twitter data imports, namely, ATLAS.ti (TM), NVivo (TM), MAXQDA (TM) and QDA Miner (TM). The authors' QDAS features checklist for these tools spotlights many differences in their functionalities. These disparities were tested through data imports and thematic coding that was derived from the same queries and codebook. The authors' resultant QDAS experiences were compared during the first activity of a broad qualitative analysis process, 'organising data'. Notwithstanding large difference in QDAS pricing, it was surprising how much the tools varied for aspects of qualitative research organisation. Notably, the quantum of data extracted for the same query differed, largely due to contrasts in the types and amount of data that the four QDAS could extract. Variations in how each supported visual organisation also shaped researchers' opportunities for becoming familiar with Twitter users and their tweet content. Such disparities suggest that choosing a suitable QDAS for organising live Twitter data must dovetail with a researcher's focus: ATLAS.ti accommodates scholars focused on wrangling unstructured data for personal meaning-making, while MAXQDA suits the mixed-methods researcher. QDA Miner's easy-to-learn user interface suits a highly efficient implementation of methods, whilst NVivo supports relatively rapid analysis of tweet content. Such findings may help guide Twitter social science researchers and others in QDAS tool selection. Future research can explore disparities in other qualitative research phases, or contrast data extraction routes for a variety of microblogging services.",Web of Science
"Long, Peixun; Zhao, Jianjun","Equivalence, identity, and unitarity checking in black-box testing of quantum programs",2024,10.1016/j.jss.2024.112000,https://doi.org/10.1016/j.jss.2024.112000,Journal,JOURNAL OF SYSTEMS AND SOFTWARE,"Quantum programs exhibit inherent non -deterministic behavior, which poses more significant challenges for error discovery compared to classical programs. While several testing methods have been proposed for quantum programs, they often overlook fundamental questions in black -box testing. In this paper, we bridge this gap by presenting three novel algorithms specifically designed to address the challenges of equivalence, identity, and unitarity checking in black -box testing of quantum programs. We also explore optimization techniques for these algorithms, including specialized versions for equivalence and unitarity checking, and provide valuable insights into parameter selection to maximize performance and effectiveness. To evaluate the effectiveness of our proposed methods, we conducted comprehensive experimental evaluations, which demonstrate that our methods can rigorously perform equivalence, identity, and unitarity checking, offering robust support for black -box testing of quantum programs.",Web of Science
"Guo, Xu; Song, Xiaoyu; Zhou, Jian-tao",A synergic quantum particle swarm optimisation for constrained combinatorial test generation,2022,10.1049/sfw2.12054,https://doi.org/10.1049/sfw2.12054,Journal,IET SOFTWARE,"Combinatorial testing (CT) can efficiently detect failures caused by interactions of parameters of software under test. The CT study has undergone a transition from traditional CT to constrained CT, which is crucial for real-world systems testing. Under this scenario, constrained covering array generation (CCAG), a vital combinatorial optimisation issue targeted with constructing a test suite of minimal size while properly addressing constraints, remains challenging in CT. To the authors' best knowledge, this paper presents a synergic method first based on quantum particle swarm optimisation (QPSO) for the CCAG problems. Three auxiliary strategies, including contraction-expansion coefficient adaptive change strategy, differential evolution strategy, and discretisation strategy, are proposed to improve the performance of QPSO. Meanwhile, the improved QPSO method combines with the three different constraint handling strategies and an enhanced one-test-at-a-time strategy as a synergic QPSO method named QPIO to solve the CCAG problem. In the experiment, we investigate the impacts of parameter settings on the performance of the QPIO. Extensive experimental results show that the QPIO algorithm is a competitive method compared to the representative methods for CCAG. Besides, the QPIO method enriches the application of the QPSO algorithm in the context of CT.","Web of Science, Wiley"
"Tahmasebi, Shirin; Rasouli, Nayereh; Kashefi, Amir Hosein; Rezabeyk, Elmira; Faragardi, Hamid Reza",SYNCOP: An evolutionary multi-objective placement of SDN controllers for optimizing cost and network performance in WSNs,2021,10.1016/j.comnet.2020.107727,https://doi.org/10.1016/j.comnet.2020.107727,Journal,COMPUTER NETWORKS,"Due to the highly dynamic nature of Wireless Sensor Networks (WSN), Software-Defined Network (SDN) is a promising technology to ease network management by providing a logically centralized control plane. It is a common approach to employ multiple SDN controllers to form a physically distributed SDN to achieve better fault tolerance, boost scalability, and enhance performance. Despite physical distribution, since the notion behind SDN is to logically centralize network management, it is essential to provide a consistent view of the network's state for all controllers. Deploying multiple controllers result in higher synchronization and deployment cost. Since network performance and inter-controller synchronization cost seem to be contradicting objectives, it is a research challenge to choose the best placement of SDN controllers to optimize both the performance and synchronization cost of an SDN-enabled WSN simultaneously.In this paper, we first formulate the controller placement problem as a multi-objective optimization problem. In this regard, multiple constraints are considered, including reliability, fault tolerance, performance in terms of latency, synchronization overhead, and deployment cost. Moreover, we leverage the Cuckoo optimization algorithm, a nature-inspired population-based meta-heuristic algorithm to solve the optimization problem. This algorithm seeks to find the global optimum by imitating brood parasitism of some cuckoo species. Finally, to evaluate our proposed method, we compare it against several existing methods in the literature. The experiments reveal that our proposed method considerably outperforms existing methods, namely Simulated Annealing (SA) and Quantum Annealing (QA), in terms of both performance and synchronization cost. Additionally, our proposed algorithm, in contrast to Integer Linear Programming (ILP), is considerably more scalable, which makes it applicable for large-scale WSNs.",Web of Science
"Tong, Lian; Yang, Lan; Zhao, Xin; Liu, Li",How can a hybrid quantum-inspired gravitational search algorithm decrease energy consumption in IoT-based software-defined networks?,2023,10.1016/j.suscom.2023.100920,https://doi.org/10.1016/j.suscom.2023.100920,Journal,SUSTAINABLE COMPUTING-INFORMATICS & SYSTEMS,"The growth of Internet of Things (IoT) devices has prompted the growing use of software-defined networks (SDNs) in today's quickly changing technological environment. In SDN, execution and security of supporting applications and creating an adaptable network design allow the network to associate with applications legitimately. As a result, SDN promotes the growth of IoT-enabled devices, boosts network resource-sharing effectiveness, and boosts the reliability of IoT services. While these interconnected systems offer unprecedented convenience and efficiency, they also come with an increasing energy consumption challenge. The original features of these networks, such as the dynamic topology and energy constraints, challenge the routing issue in these networks. This article delves into the strategies and innovations that can effectively decrease energy consumption in IoT-based SDNs. The previous methods had some problems, such as increasing energy consumption, delay and network lifetime, etc. Thus, fuzzy and meta-heuristic methods have been used to maximize the search space and achieve optimum results. Due to the NP-hard nature of this issue, the Binary QuantumInspired Gravitational Search Algorithm (BQIGSA) is used in this paper to offer a fuzzy-based routing approach in IoT-based SDN, which aims to optimize energy, delay, and expected transmission rate. Fuzzy modeling, and particularly fuzzy routing algorithms, are explained in this study in relation to the decisionmaking component. The synergy of Fuzzy Logic and BQIGSA offers a promising avenue for enhancing IoTbased SDNs. This innovative approach tackles the challenges of uncertainty, energy optimization, and adaptive decision-making that are inherent in IoT networks. The simulation is performed through MATLAB. The outcomes of simulations and tests demonstrated that the suggested approach performed better than the current methods in terms of energy usage, delay rate, and data delivery rate.",Web of Science
"Huang, Li",iQIST v0.7: An open source continuous-time quantum Monte Carlo impurity solver toolkit,2017,10.1016/j.cpc.2017.08.026,https://doi.org/10.1016/j.cpc.2017.08.026,Journal,COMPUTER PHYSICS COMMUNICATIONS,"In this paper, we present a new version of the iQIST software package, which is capable of solving various quantum impurity models by using the hybridization expansion (or strong coupling expansion) continuous-time quantum Monte Carlo algorithm. In the revised version, the software architecture is completely redesigned. New basis (intermediate representation or singular value decomposition representation) for the single-particle and two-particle Green's functions is introduced. A lot of useful physical observables are added, such as the charge susceptibility, fidelity susceptibility, Binder cumulant, and autocorrelation time. Especially, we optimize measurement for the two-particle Green's functions. Both the particle-hole and particle-particle channels are supported. In addition, the block structure of the two particle Green's functions is exploited to accelerate the calculation. Finally, we fix some known bugs and limitations. The computational efficiency of the code is greatly enhanced.",Web of Science
"Xiong, Gang; Sun, Penghao; Hu, Yuxiang; Lan, Julong; Li, Kan",An Optimized Deployment Mechanism for Virtual Middleboxes in NFV- and SDN-Enabling Network,2016,10.3837/tiis.2016.08.003,https://doi.org/10.3837/tiis.2016.08.003,Journal,KSII TRANSACTIONS ON INTERNET AND INFORMATION SYSTEMS,"Network Function Virtualization (NFV) and Software Defined Networking (SDN) are recently considered as very promising drivers of the evolution of existing middlebox services, which play intrinsic and fundamental roles in today's networks. To address the virtual service deployment issues that caused by introducing NFV or SDN to networks, this paper proposes an optimal solution by combining quantum genetic algorithm with cooperative game theory. Specifically, we first state the concrete content of the service deployment problem and describe the system framework based on the architecture of SDN. Second, for the service location placement sub-problem, an integer linear programming model is built, which aims at minimizing the network transport delay by selecting suitable service locations, and then a heuristic solution is designed based on the improved quantum genetic algorithm. Third, for the service amount placement sub-problem, we apply the rigorous cooperative game-theoretic approach to build the mathematical model, and implement a distributed algorithm corresponding to Nash bargaining solution. Finally, experimental results show that our proposed method can calculate automatically the optimized placement locations, which reduces 30% of the average traffic delay compared to that of the random placement scheme. Meanwhile, the service amount placement approach can achieve the performance that the average metric values of satisfaction degree and fairness index reach above 90%. And evaluation results demonstrate that our proposed mechanism has a comprehensive advantage for network application.",Web of Science
"Lourenco, Maicon Pierre; Hostas, Jiri; Bellinger, Colin; Tchagang, Alain; Salahub, Dennis R.",Reinforcement learning for in silico determination of adsorbate-substrate structures,2024,10.1002/jcc.27322,https://doi.org/10.1002/jcc.27322,Journal,JOURNAL OF COMPUTATIONAL CHEMISTRY,"Reinforcement learning (RL) methods have helped to define the state of the art in the field of modern artificial intelligence, mostly after the breakthrough involving AlphaGo and the discovery of novel algorithms. In this work, we present a RL method, based on Q-learning, for the structural determination of adsorbate@substrate models in silico, where the minimization of the energy landscape resulting from adsorbate interactions with a substrate is made by actions on states (translations and rotations) chosen from an agent's policy. The proposed RL method is implemented in an early version of the reinforcement learning software for materials design and discovery (RLMaterial), developed in Python3.x. RLMaterial interfaces with deMon2k, DFTB+, ORCA, and Quantum Espresso codes to compute the adsorbate@substrate energies. The RL method was applied for the structural determination of (i) the amino acid glycine and (ii) 2-amino-acetaldehyde, both interacting with a boron nitride (BN) monolayer, (iii) host-guest interactions between phenylboronic acid and beta-cyclodextrin and (iv) ammonia on naphthalene. Density functional tight binding calculations were used to build the complex search surfaces with a reasonably low computational cost for systems (i)-(iii) and DFT for system (iv). Artificial neural network and gradient boosting regression techniques were employed to approximate the Q-matrix or Q-table for better decision making (policy) on next actions. Finally, we have developed a transfer-learning protocol within the RL framework that allows learning from one chemical system and transferring the experience to another, as well as from different DFT or DFTB levels.We have developed a reinforcement learning approach for in silico automatic structural determination of adsorbate interactions with substrates. The proposed RL method allows transferring the learning between different chemical systems or theoretical methods. The RL method was implemented in the RLMaterial software. image",Web of Science
"Hussein, Hager; Younes, Ahmed; Abdelmoez, Walid",Quantum algorithm for solving the test-suite minimization problem,2021,10.1080/23311916.2021.1882116,https://doi.org/10.1080/23311916.2021.1882116,Journal,COGENT ENGINEERING,"Test-suite minimization problem is an essential problem in software engineering as its application helps to improve the software quality. This paper proposes a quantum algorithm to solve the test-suite minimization problem with high probability in O(root 2(n)), where n is the number of test cases. It generates an incomplete superposition to find the best solution. It also handles the non-uniform amplitudes' distribution case for the system with multisolutions. The proposed algorithm uses amplitude amplification techniques to search for the minimum number of test cases required to test all the requirements. The proposed algorithm employs two quantum search algorithms, Younes et al. algorithm for quantum searching via entanglement and partial diffusion to prepare incomplete superpositions that represent different search spaces such that the number of test cases is incremented in each search space, and updated Arima's algorithm to handle the multisolutions case. The updated Arima's algorithm searches for a quantum state that satisfies an oracle that represent the instance of the test-suite minimization problem.",Web of Science
"Bajaj, Anu; Abraham, Ajith; Ratnoo, Saroj; Gabralla, Lubna Abdelkareim","Test Case Prioritization, Selection, and Reduction Using Improved Quantum-Behaved Particle Swarm Optimization",2022,10.3390/s22124374,https://doi.org/10.3390/s22124374,Journal,SENSORS,"The emerging areas of IoT and sensor networks bring lots of software applications on a daily basis. To keep up with the ever-changing expectations of clients and the competitive market, the software must be updated. The changes may cause unintended consequences, necessitating retesting, i.e., regression testing, before being released. The efficiency and efficacy of regression testing techniques can be improved with the use of optimization approaches. This paper proposes an improved quantum-behaved particle swarm optimization approach for regression testing. The algorithm is improved by employing a fix-up mechanism to perform perturbation for the combinatorial TCP problem. Second, the dynamic contraction-expansion coefficient is used to accelerate the convergence. It is followed by an adaptive test case selection strategy to choose the modification-revealing test cases. Finally, the superfluous test cases are removed. Furthermore, the algorithm's robustness is analyzed for fault as well as statement coverage. The empirical results reveal that the proposed algorithm performs better than the Genetic Algorithm, Bat Algorithm, Grey Wolf Optimization, Particle Swarm Optimization and its variants for prioritizing test cases. The findings show that inclusivity, test selection percentage and cost reduction percentages are higher in the case of fault coverage compared to statement coverage but at the cost of high fault detection loss (approx. 7%) at the test case reduction stage.",Web of Science
"Rodriguez-Borbon, Jose M.; Wang, Xian; Dieguez, Adrian P.; Ibrahim, Khaled Z.; Wong, Bryan M.",VAN-DAMME: GPU-accelerated and symmetry-assisted quantum optimal control of multi-qubit systems,2025,10.1016/j.cpc.2024.109403,https://doi.org/10.1016/j.cpc.2024.109403,Journal,COMPUTER PHYSICS COMMUNICATIONS,"We present an open-source software package, VAN-DAMME (Versatile Approaches to Numerically Design, Accelerate, and Manipulate Magnetic Excitations), for massively-parallelized quantum optimal control (QOC) calculations of multi-qubit systems. To enable large QOC calculations, the VAN-DAMME software package utilizes symmetry-based techniques with custom GPU-enhanced algorithms. This combined approach allows for the simultaneous computation of hundreds of matrix exponential propagators that efficiently leverage the intraGPU parallelism found in high-performance GPUs. In addition, to maximize the computational efficiency of the VAN-DAMME code, we carried out several extensive tests on data layout, computational complexity, memory requirements, and performance. These extensive analyses allowed us to develop computationally efficient approaches for evaluating complex-valued matrix exponential propagators based on Pad & eacute; approximants. To assess the computational performance of our GPU-accelerated VAN-DAMME code, we carried out QOC calculations of systems containing 10- 15 qubits, which showed that our GPU implementation is 18.4x faster than the corresponding CPU implementation. Our GPU-accelerated enhancements allow efficient calculations of multiqubit systems, which can be used for the efficient implementation of QOC applications across multiple domains. Program summary Program Title: VAN-DAMME CPC Library link to program files:: https://doi.org /10 .17632 /zcgw2n5bjf.1 Licensing provisions: GNU General Public License 3 Programming language: C++ and CUDA Nature of problem: The VAN-DAMME software package utilizes GPU-accelerated routines and new algorithmic improvements to compute optimized time-dependent magnetic fields that can drive a system from a known initial qubit configuration to a specified target state with a large (approximate to 1) transition probability. Solution method: Quantum control, GPU acceleration, analytic gradients, matrix exponential, and gradient ascent optimization.",Web of Science
"Sanchez-Marquez, Jesus; Garcia, Victor; Zorrilla, David; Fernandez, Manuel",Software to obtain spatially localized functions from different radial functions,2020,10.1007/s10822-019-00272-2,https://doi.org/10.1007/s10822-019-00272-2,Journal,JOURNAL OF COMPUTER-AIDED MOLECULAR DESIGN,"We have developed an algorithm that enables simplified box orbital functions (SBO) to be obtained with optimized coefficients by fitting them to functions of many types. SBOs are a linear combination of radial functions useful in quantum chemistry calculations which can be spatially restricted (defined in 0 <= r < r(0) interval, and zero for r >= r(0)). The algorithm proposed makes it possible to obtain the optimal radius r 0 and the coefficients of the SBOs of any number of terms from the functions to be fitted, but also allows the user to define a particular radius r and calculate the coefficients of the combination of terms of the SBOs. SBOs have proved to be useful in the calculation of molecular properties, and can reduce the complexity of the integral calculations, especially in huge chemical systems such as atomic clusters. These types of functions are also adequate for studying confined systems such as molecules in solution or big chemical systems such as atomic clusters. In addition, while carrying out the examples presented in this study we have tested the suitability of SBO functions to calculate molecular reactivity, showing that the basis functions provide results as good as the basis sets typically used for this kind of calculations.",Web of Science
"Wen, Juan; Qu, Xing; Liu, Jie; Lin, Siyu; Xiao, Qiankang",A novel fault location method for the active distribution network based on dynamic quantum genetic algorithm,2024,10.1007/s00202-024-02244-8,https://doi.org/10.1007/s00202-024-02244-8,Journal,ELECTRICAL ENGINEERING,"The fault location of an active distribution network is a vital analysis to prevent major outages in the power system. Considering the influence of renewable distributed generations on fault characteristics, this paper proposes a novel location method based on a dynamic quantum genetic algorithm to solve for fault locations in active distribution networks. In the method, the fault current code is measured based on feeder terminal units. A universal switching function is presented to convert the feeder switch status into an uploaded fault current code. The fault location model is defined as an optimization problem that presents the evaluation objective function with an anti-false-positive factor. The dynamic quantum genetic algorithm is developed to locate the fault feeder according to the uploaded fault current code of the feeder terminal unit. The algorithm adopts dynamic rotating gate strategy and adaptive quantum crossover strategy to satisfy the requirements of quickness and accuracy for fault location. Moreover, the method avoids easily falling into a local optimum by integrating the discrete quantum mutation. The proposed fault location technique is tested and compared to other existing techniques on a 33-bus active distribution network. The simulation results show that the proposed fault location method can locate fault feeders accurately with fast computational times under conditions of single or multiple faults and with an information distortion of the feeder terminal unit.",Web of Science
"Haidar, Mohammad; Rancic, Marko J. J.; Ayral, Thomas; Maday, Yvon; Piquemal, Jean-Philip",Open source variational quantum eigensolver extension of the quantum learning machine for quantum chemistry,2023,10.1002/wcms.1664,https://doi.org/10.1002/wcms.1664,Journal,WILEY INTERDISCIPLINARY REVIEWS-COMPUTATIONAL MOLECULAR SCIENCE,"Quantum chemistry (QC) is one of the most promising applications of quantum computing. However, present quantum processing units (QPUs) are still subject to large errors. Therefore, noisy intermediate-scale quantum (NISQ) hardware is limited in terms of qubit counts/circuit depths. Variational quantum eigensolver (VQE) algorithms can potentially overcome such issues. Here, we introduce the OpenVQE open-source QC package. It provides tools for using and developing chemically-inspired adaptive methods derived from unitary coupled cluster (UCC). It facilitates the development and testing of VQE algorithms and is able to use the Atos Quantum Learning Machine (QLM), a general quantum programming framework enabling to write/optimize/simulate quantum computing programs. We present a specific, freely available QLM open-source module, myQLM-fermion. We review its key tools for facilitating QC computations (fermionic second quantization, fermion-spin transforms, etc.). OpenVQE largely extends the QLM's QC capabilities by providing: (i) the functions to generate the different types of excitations beyond the commonly used UCCSD ansatz; (ii) a new Python implementation of the adaptive derivative assembled pseudo-Trotter method (ADAPT-VQE). Interoperability with other major quantum programming frameworks is ensured thanks to the myQLM-interop package, which allows users to build their own code and easily execute it on existing QPUs. The combined OpenVQE/myQLM-fermion libraries facilitate the implementation, testing and development of variational quantum algorithms, while offering access to large molecules as the noiseless Schrodinger-style dense simulator can reach up to 41 qubits for any circuit. Extensive benchmarks are provided for molecules associated to qubit counts ranging from 4 to 24. We focus on reaching chemical accuracy, reducing the number of circuit gates and optimizing parameters and operators between fixed-length UCC and ADAPT-VQE ansatze.This article is categorized under:Software > Quantum ChemistryQuantum Computing > Algorithms","Web of Science, Wiley"
"Poberznik, M.; Gunde, M.; Salles, N.; Jay, A.; Hemeryck, A.; Richard, N.; Mousseau, N.; Martin-Samos, L.",pARTn: A plugin implementation of the Activation Relaxation Technique nouveau that takes over the FIRE minimisation algorithm,2024,10.1016/j.cpc.2023.108961,https://doi.org/10.1016/j.cpc.2023.108961,Journal,COMPUTER PHYSICS COMMUNICATIONS,"Nowadays, the interoperability and interfacing of codes and libraries have become crucial aspects of software development and engineering, and the basis for enabling and simplifying the sharing of methods and tools, both within and among communities. One of the most important bottlenecks that arises when developing and maintaining an interface of a library with an already existing software, is to keep it aligned with the development route of the latter. This might include significant changes, such as changes in the data structures used by the library, which are communicated through the interface. In this paper, an approach for inserting a new algorithm into existing software is presented, through a minimally invasive interface, that takes over an already present algorithm, and thus changes its original purpose. The approach is applied to the well-established Activation-Relaxation Technique nouveau (ARTn) algorithm, that is revisited and re-engineered to bias and take over the FIRE minimization algorithm, as presently implemented in two community codes for atomistic simulations, namely Quantum ESPRESSO (PWscf) and LAMMPS. ARTn is a well established single-ended saddle-point search algorithm that allows for the exploration of potential energy surfaces. The resulting algorithm acts as a plugin, and is distributed in the form of an external library (pARTn).",Web of Science
"Karimi, Mehdi; Tuncel, Levent",Efficient Implementation of Interior-Point Methods for Quantum Relative Entropy,2024,10.1287/ijoc.2024.0570,https://doi.org/10.1287/ijoc.2024.0570,Journal,INFORMS JOURNAL ON COMPUTING,"Quantum relative entropy (QRE) programming is a recently popular and challenging class of convex optimization problems with significant applications in quantum computing and quantum information theory. We are interested in modern interior-point (IP) methods based on optimal self-concordant barriers for the QRE cone. A range of theoretical and numerical challenges associated with such barrier functions and the QRE cones have hindered the scalability of IP methods. To address these challenges, we propose a series of numerical and linear algebraic techniques and heuristics aimed at enhancing the efficiency of gradient and Hessian computations for the self-concordant barrier function, solving linear systems, and performing matrix-vector products. We also introduce and deliberate about some interesting concepts related to QRE such as symmetric quantum relative entropy. We design a two-phase method for performing facial reduction that can significantly improve the performance of QRE programming. Our new techniques have been implemented in the latest version (DDS 2.2) of the software package Domain-Driven Solver (DDS). In addition to handling QRE constraints, DDS accepts any combination of several other conic and nonconic convex constraints. Our comprehensive numerical experiments encompass several parts, including (1) a comparison of DDS 2.2 with Hypatia for the nearest correlation matrix problem, (2) using DDS 2.2 for combining QRE constraints with various other constraint types, and (3) calculating the key rate for quantum key distribution (QKD) channels and presenting results for several QKD protocols.",Web of Science
"Yoshioka, Takuya; Sasada, Keita; Nakano, Yuichiro; Fujii, Keisuke",Fermionic quantum approximate optimization algorithm,2023,10.1103/PhysRevResearch.5.023071,https://doi.org/10.1103/PhysRevResearch.5.023071,Journal,PHYSICAL REVIEW RESEARCH,"Quantum computers are expected to accelerate solving combinatorial optimization problems, including algorithms such as Grover adaptive search and quantum approximate optimization algorithm (QAOA). However, many combinatorial optimization problems involve constraints which, when imposed as soft constraints in the cost function, can negatively impact the performance of the optimization algorithm. In this paper, we propose fermionic quantum approximate optimization algorithm (FQAOA) for solving combinatorial optimization problems with constraints. Specifically, FQAOA tackles the constrains issue by using fermion particle number preservation to intrinsically impose them throughout QAOA. We provide a systematic guideline for designing the driver Hamiltonian for a given problem Hamiltonian with constraints. The initial state can be chosen to be a superposition of states satisfying the constraint and the ground state of the driver Hamiltonian. This property is important since FQAOA reduced to quantum adiabatic computation in the large limit of circuit depth p and improved performance, even for shallow circuits with optimizing the parameters starting from the fixed-angle determined by Trotterized quantum adiabatic evolution. We perform an extensive numerical simulation and demonstrate that proposed FQAOA provides substantial performance advantages against existing approaches in portfolio optimization problems. Furthermore, the Hamiltonian design guideline is useful not only for QAOA but also Grover adaptive search and quantum phase estimation to solve combinatorial optimization problems with constraints. Since software tools for fermionic systems have been developed in quantum computational chemistry both for noisy intermediate-scale quantum computers and fault-tolerant quantum computers, FQAOA allows us to apply these tools for constrained combinatorial optimization problems.",Web of Science
"Lourenco, Maicon Pierre; Herrera, Lizandra Barrios; Hostas, Jiri; Calaminici, Patrizia; Koster, Andreas M.; Tchagang, Alain; Salahub, Dennis R.",Automatic structural elucidation of vacancies in materials by active learning,2022,10.1039/d2cp02585j,https://doi.org/10.1039/d2cp02585j,Journal,PHYSICAL CHEMISTRY CHEMICAL PHYSICS,"Finding the optimum structures of non-stoichiometric or berthollide materials, such as (1D, 2D, 3D) materials or nanoparticles (0D), is challenging due to the huge chemical/structural search space. Computational methods coupled with global optimization algorithms have been used successfully for this purpose. In this work, we have developed an artificial intelligence method based on active learning (AL) or Bayesian optimization for the automatic structural elucidation of vacancies in solids and nanoparticles. AL uses machine learning regression algorithms and their uncertainties to take decisions (from a policy) on the next unexplored structures to be computed, increasing the probability of finding the global minimum with few calculations. The methodology allows an accurate and automated structural elucidation for vacancies, which are common in non-stoichiometric (berthollide) materials, helping to understand chemical processes in catalysis and environmental sciences, for instance. The AL vacancies method was implemented in the quantum machine learning software/agent for material design and discovery (QMLMaterial). Also, two additional acquisition functions for decision making were implemented, besides the expected improvement (EI): the lower confidence bound (LCB) and the probability of improvement (PI). The new software was applied for the automatic structural search for graphite (C-36) with 3 (C36-3) and 4 (C36-4) carbon vacancies and C-60 (C60-4) fullerene with 4 carbon vacancies. DFTB calculations were used to build the complex search surfaces with reasonably low computational cost. Furthermore, with the AL method for vacancies, it was possible to elucidate the optimum oxygen vacancy distribution in CaTiO3 perovskite by DFT, where a semiconductor behavior results from oxygen vacancies. Throughout the work, a Gaussian process with its uncertainty was employed in the AL framework using different acquisition functions (EI, LCB and PI), and taking into account different descriptors: Ewald sum matrix and sine matrix. Finally, the performance of the proposed AL method was compared to random search and genetic algorithm.",Web of Science
"Rodriguez-Borbon, Jose M.; Wang, Xian; Dieguez, Adrian P.; Ibrahim, Khaled Z.; Wong, Bryan M.",TRAVOLTA: GPU acceleration and algorithmic improvements for constructing quantum optimal control fields in photo-excited systems,2024,10.1016/j.cpc.2023.109017,https://doi.org/10.1016/j.cpc.2023.109017,Journal,COMPUTER PHYSICS COMMUNICATIONS,"We present an open-source software package, TRAVOLTA (Terrific Refinements to Accelerate, Validate, and Optimize Large Time-dependent Algorithms), for carrying out massively parallelized quantum optimal control calculations on GPUs. The TRAVOLTA software package is a significant overhaul of our previous NIC-CAGE algorithm and also includes algorithmic improvements to the gradient ascent procedure to enable faster convergence. We examine three different variants of GPU parallelization to assess their performance in constructing optimal control fields in a variety of quantum systems. In addition, we provide several examples with extensive benchmarks of our GPU-enhanced TRAVOLTA code to show that it generates the same results as previous CPU-based algorithms but with a speedup that is more than ten times faster. Our GPU enhancements and algorithmic improvements enable large quantum optimal control calculations that can be efficiently and routinely executed on modern multi-core computational hardware.Program summaryProgram Title: TRAVOLTACPC Library link to program files: https://doi .org /10 .17632 /grwppm37rn .1Licensing provisions: GNU General Public License 3Programming language: C++, openBLAS, and CUDASupplementary material: Brief review of LU decomposition, raw numerical values used to generate Fig. 6 in the main text, and input examples for the TRAVOLTA software package.Nature of problem: The TRAVOLTA software package utilizes GPU accelerated routines and new algorithmic improvements to compute optimized electric fields that can drive a system from a known initial vibrational eigenstate to a specified final quantum state with a large (approximate to 1) transition probability.Solution method: Quantum control, GPU acceleration, analytic gradients, Crank-Nicolson propagation, and gradient ascent optimization.",Web of Science
"Georgescu, Alexandru B.; Kim, Minjung; Ismail-Beigi, Sohrab",Boson Subsidiary Solver (BoSS) v1.1,2021,10.1016/j.cpc.2021.107991,https://doi.org/10.1016/j.cpc.2021.107991,Journal,COMPUTER PHYSICS COMMUNICATIONS,"How best to model systems of interacting electrons in an accurate and computationally efficient manner is an outstanding problem in theoretical and computational materials science. For materials where strong electronic interactions are primarily of a localized character and act within a subspace of localized quantum states on separate atomic sites (e.g., in transition metal and rare-earth compounds), their electronic behaviors are typically described by the Hubbard model and its extensions. In this work, we describe BoSS (Boson Subsidiary Solver), a software implementation of the subsidiary-boson (also known as slave-boson or auxiliary-boson) method appropriate for describing a variety of extended Hubbard models, namely p - d models that include both the interacting atomic sites (d states) and non-interacting or ligand sites (p states). We provide a theoretical background, a description of the equations solved by BoSS, an overview of the algorithms used, the key input/output and control variables of the software program, and tutorial examples of its use featuring band renormalization in SrVO3, Ni 3d multiplet structure in LaNiO3, and the relation between the formation of magnetic moments and insulating behavior in SmNiO3. BoSS interfaces directly with popular electronic structure codes: it can read the output of the Wannier90 software package [1,2] which postprocesses results from workhorse electronic structure software such as Quantum Espresso [3] or VASP [4].Program summaryProgram title: Boson Subsidiary Solver (BoSS)CPC Library link to progrom files: https://doi.org/10.17632/3bwx6prn2w.1Developer's repository link: bitbucket.org/yalebosscode/bossCode Ocean capsule: https://codeocean.com/capsule/9605047Licensing provisions: Creative Commons by 4.0Programming language: MATLAB [5]Nature of problem: The BoSS approach, a type of subsidiary-boson method (also called slave-boson or auxiliary-boson method), provides approximate solutions to interacting electron problems described by Hubbard models in a computationally efficient manner. Hubbard models are widely used to describe materials systems with strongly localized electron-electron interactions. The interacting fermion problem is mapped onto two separate, but easier, coupled quantum problems: non-interacting fermions moving on a lattice (spinons) via tunneling between nearby atomic orbitals, and interacting subsidiary bosons that live on individual atomic sites. A self-consistent description of the two degrees of freedom requires matching of mean particle numbers (spinons and bosons) on each site as well as the renormalization of tunneling events for one set of particles due to the fluctuations of the other set of particles. The method can be used to describe the interacting electronic ground state of a particular electronic configuration, or more generally it can find the minimum energy electronic configuration by searching over various symmetry broken phases (e.g., magnetic configurations, configurations with unequal occupation of nominally equivalent atomic orbitals, etc.)Solution method: The spinon and subsidiary-boson problems are each represented as Hermitian eigenvalue problems where the lowest energy (eigenvalue) state is sought. The present implementation uses dense matrix digaonalization for the spinon problem and can use either dense or sparse matrix diagonalization for the boson problem. Particle number matching between the two descriptions is achieved by adjustment of Lagrange multipliers which represent potential energies for the bosons: their appropriate values are found by applying Newton's method to match spinon and boson occupancies. Self-consistency is achieved by simple fixed point iteration (solving spinon, then subsidiary, then spinon, etc.) Minimization of the energy uses gradient descent with adjustable step size.Additional comments including restrictions and unusual features: Most users will prepare the input data for BoSS by running band structure calculations on a material, e.g., density functional theory (DFT) using available software packages such as Quantum Espresso [3] or VASP [4]. Post processing of these calculations to create a spatially localized basis set provides the input to BoSS: most users will create the localized description by using software that transforms the electronic description into a Wannier function basis such as Wannier90 [1] which BoSS interfaces with by default. However, one can bypass this approach and create BoSS input files manually to describe specific localized electron models. (C) 2021 Elsevier B.V. All rights reserved.",Web of Science
"Bahadori, Behnoosh; Atabati, Morteza",Harmony Search as a Powerful Tool for Feature Selection in QSPR Study of the Drugs Lipophilicity,2017,10.2174/1386207320666170315123604,https://doi.org/10.2174/1386207320666170315123604,Journal,COMBINATORIAL CHEMISTRY & HIGH THROUGHPUT SCREENING,"Aims & Scope: Lipophilicity represents one of the most studied and most frequently used fundamental physicochemical properties. In the present work, harmony search (HS) algorithm is suggested to feature selection in quantitative structure-property relationship (QSPR) modeling to predict lipophilicity of neutral, acidic, basic and amphotheric drugs that were determined by UHPLC. Harmony search is a music-based metaheuristic optimization algorithm. It was affected by the observation that the aim of music is to search for a perfect state of harmony.Materials & Methods: Semi-empirical quantum-chemical calculations at AM1 level were used to find the optimum 3D geometry of the studied molecules and variant descriptors (1497 descriptors) were calculated by the Dragon software. The selected descriptors by harmony search algorithm (9 descriptors) were applied for model development using multiple linear regression (MLR). In comparison with other feature selection methods such as genetic algorithm and simulated annealing, harmony search algorithm has better results. The root mean square error (RMSE) with and without leave-one out cross validation (LOOCV) were obtained 0.417 and 0.302, respectively.Results & Conclusion: The results were compared with those obtained from the genetic algorithm and simulated annealing methods and it showed that the HS is a helpful tool for feature selection with fine performance.",Web of Science
"Tribello, Gareth A.; Bonomi, Massimiliano; Branduardi, Davide; Camilloni, Carlo; Bussi, Giovanni",PLUMED 2: New feathers for an old bird,2014,10.1016/j.cpc.2013.09.018,https://doi.org/10.1016/j.cpc.2013.09.018,Journal,COMPUTER PHYSICS COMMUNICATIONS,"Enhancing sampling and analyzing simulations are central issues in molecular simulation. Recently, we introduced PLUMED, an open-source plug-in that provides some of the most popular molecular dynamics (MD) codes with implementations of a variety of different enhanced sampling algorithms and collective variables (CVs). The rapid changes in this field, in particular new directions in enhanced sampling and dimensionality reduction together with new hardware, require a code that is more flexible and more efficient. We therefore present PLUMED 2 here a,complete rewrite of the code in an object-oriented programming language (C++). This new version introduces greater flexibility and greater modularity, which both extends its core capabilities and makes it far easier to add new methods and CVs. It also has a simpler interface with the MD engines and provides a single software library containing both tools and core facilities. Ultimately, the new code better serves the ever-growing community of users and contributors in coping with the new challenges arising in the field.Program summaryProgram title: PLUMED 2Catalogue identifier: AEEE_v2_0Program summary URL: http://cpc.cs.qub.ac.uk/summaries/AEEE_v2_0.htmlProgram obtainable from: CPC Program Library, Queen's University, Belfast, N. IrelandLicensing provisions: YesNo. of lines in distributed program, including test data, etc.: 700646No. of bytes in distributed program, including test data, etc.: 6618136Distribution format: tar.gzProgramming language: ANSI-C++.Computer: Any computer capable of running an executable produced by a C++ compiler.Operating system: Linux operating system, Unix OSs.Has the code been vectorized or parallelized?: Yes, parallelized using MPI.RAM: Depends on the number of atoms, the method chosen and the collective variables used.Classification: 3, 7.7, 23. Catalogue identifier of previous version: AEEE_v1_0.Journal reference of previous version: Comput. Phys. Comm. 180 (2009) 1961.External routines: GNU libmatheval, Lapack, Bias, MPI. (C) 2013 Elsevier B.V. All rights reserved.",Web of Science
"Pracht, Philipp; Grimme, Stefan; Bannwarth, Christoph; Bohle, Fabian; Ehlert, Sebastian; Feldmann, Gereon; Gorges, Johannes; Mueller, Marcel; Neudecker, Tim; Plett, Christoph; Spicher, Sebastian; Steinbach, Pit; Wesolowski, Patryk A.; Zeller, Felix",CREST-A program for the exploration of low-energy molecular chemical space,2024,10.1063/5.0197592,https://doi.org/10.1063/5.0197592,Journal,JOURNAL OF CHEMICAL PHYSICS,"Conformer-rotamer sampling tool (CREST) is an open-source program for the efficient and automated exploration of molecular chemical space. Originally developed in Pracht et al. [Phys. Chem. Chem. Phys. 22, 7169 (2020)] as an automated driver for calculations at the extended tight-binding level (xTB), it offers a variety of molecular- and metadynamics simulations, geometry optimization, and molecular structure analysis capabilities. Implemented algorithms include automated procedures for conformational sampling, explicit solvation studies, the calculation of absolute molecular entropy, and the identification of molecular protonation and deprotonation sites. Calculations are set up to run concurrently, providing efficient single-node parallelization. CREST is designed to require minimal user input and comes with an implementation of the GFNn-xTB Hamiltonians and the GFN-FF force-field. Furthermore, interfaces to any quantum chemistry and force-field software can easily be created. In this article, we present recent developments in the CREST code and show a selection of applications for the most important features of the program. An important novelty is the refactored calculation backend, which provides significant speed-up for sampling of small or medium-sized drug molecules and allows for more sophisticated setups, for example, quantum mechanics/molecular mechanics and minimum energy crossing point calculations.",Web of Science
"Wang, Yuxiang; Wang, Ruijin; Li, Dongfen; Adu-Gyamfi, Daniel; Tian, Kaibin; Zhu, Yixin",Improved Handwritten Digit Recognition using Quantum K-Nearest Neighbor Algorithm,2019,10.1007/s10773-019-04124-5,https://doi.org/10.1007/s10773-019-04124-5,Journal,INTERNATIONAL JOURNAL OF THEORETICAL PHYSICS,"Handwritten numeral recognition is a technology for automatic recognition and classification of handwritten numeral input through machine learning model. This is widely used in postal code digital automatic system to sort letters. The classical k-nearest neighbor algorithm is used in the traditional digital recognition training model. The recognized digital image classification is obtained through similarity measure or calculation and K value selection. Nonetheless, as the applied data volume exceeds a certain threshold, the time complexity of the model increases exponentially upon the similarity measure and K value search. This condition makes it hard to apply the model universally. In this paper, we introduce quantum computing, that is where digital image information is stored in the quantum state, and its similarity is calculated in parallel. Also, the most similar K points are obtained through the Grover algorithm. The theoretical analysis of the proposed improved algorithm shows that, handwritten numeral recognition based on quantum k-neighbor algorithm can improved upon time complexity of of the existing algorithm.",Web of Science
"Romero-Alvarez, Javier; Alvarado-Valiente, Jaime; Casco-Seco, Jorge; Moguel, Enrique; Garcia-Alonso, Jose; Murillo, Juan M.",A Noise Validation for Quantum Circuit Scheduling Through a Service-Oriented Architecture,2024,10.1142/S0218194024410018,https://doi.org/10.1142/S0218194024410018,Journal,INTERNATIONAL JOURNAL OF SOFTWARE ENGINEERING AND KNOWLEDGE ENGINEERING,"Progress in the realm of quantum technologies is paving the way for a multitude of potential applications across different sectors. However, the reduced number of available quantum computers, their technical limitations, and the high demand for their use are posing some problems for developers and researchers. Mainly, users trying to execute quantum circuits on these devices are usually facing long waiting times in the task queues. In this context, this work proposes a Service-Oriented architecture to reduce waiting times and optimize quantum computer usage by scheduling the circuits from different users into combined circuits that are executed at the same time. To validate this proposal, different widely known quantum algorithms have been selected and executed in combined circuits. The obtained results are then compared with the results of executing the same algorithms in an isolated way. This allowed us to measure the impact of the use of the scheduler against quantum noise. Among the obtained results, it has been possible to verify that the noise suffered by executing a combination of circuits through the proposed scheduler does not critically affect the outcomes.",Web of Science
"Gorni, Tommaso; Baseggio, Oscar; Delugas, Pietro; Baroni, Stefano; Timrov, Iurii",turboMagnon - A code for the simulation of spin-wave spectra using the Liouville-Lanczos approach to time-dependent density-functional perturbation theory,2022,10.1016/j.cpc.2022.108500,https://doi.org/10.1016/j.cpc.2022.108500,Journal,COMPUTER PHYSICS COMMUNICATIONS,"We introduce turboMagnon, an implementation of the Liouville-Lanczos approach to linearized time-dependent density-functional theory, designed to simulate spin-wave spectra in solid-state materials. The code is based on the noncollinear spin-polarized framework and the self-consistent inclusion of spin-orbit coupling that allow to model complex magnetic excitations. The spin susceptibility matrix is computed using the Lanczos recursion algorithm that is implemented in two flavors -the non-Hermitian and the pseudo-Hermitian one. turboMagnon is open-source software distributed under the terms of the GPL as a component of QUANTUM ESPRESSO. As with other components, turboMagnon is optimized to run on massively parallel architectures using native mathematical libraries (LAPACK and FFTW) and a hierarchy of custom parallelization layers built on top of MPI. The effectiveness of the code is showcased by computing magnon dispersions for the CrI3 monolayer, and the importance of the spin-orbit coupling is discussed. (C) 2022 The Author(s). Published by Elsevier B.V.",Web of Science
"Mitikiri, Praveen; Jana, Gourhari; Sural, Shamik; Chattaraj, Pratim K.",A machine learning technique toward generating minimum energy structures of small boron clusters,2018,10.1002/qua.25672,https://doi.org/10.1002/qua.25672,Journal,INTERNATIONAL JOURNAL OF QUANTUM CHEMISTRY,"The search for a global minimum related to molecular electronic structure and chemical bonding has received wide attention based on some theoretical calculations at various levels of theory. Particle swarm optimization (PSO) algorithm and modified PSO have been used to predict the energetically stable/metastable states associated with a given chemical composition. Out of a variety of techniques such as genetic algorithm, basin hopping, simulated annealing. PSO, and so on. PSO is considered to be one of the most suitable methods due to its various advantages over others. We use a swarm-intelligence based parallel code to improve a PSO algorithm in a multidimensional search space augmented by quantum chemical calculations on gas phase structures at 0 K without any symmetry constraint to obtain an optimal solution. Our currently employed code is interfaced with Gaussian software for single point energy calculations. The code developed here is shown to be efficient. Small population size (small cluster) in the multidimensional space is actually good enough to get better results with low computational cost than the typical larger population. But for larger systems also the analysis is possible. One can try with a large number of particles as well. We have also analyzed how arbitrary and random structures and the local minimum energy structures gravitate toward the target global minimum structure. At the same time, we compare our results with that obtained from other evolutionary techniques.","Web of Science, Wiley"
"Wang, Fei; Wang, Zhanchang; Li, Xiang; Chen, Yu",Tensor projection mechanism and algorithm implementation,2021,10.1007/s10489-021-02332-3,https://doi.org/10.1007/s10489-021-02332-3,Journal,APPLIED INTELLIGENCE,"This paper analyses the mechanism of tensor projection transformation in depth and introduces a high-efficiency original algorithm developed in a quantum computing language for forward and backward projection between multidimensional tensors and one-dimensional vectors. Additionally, the author compares this algorithm with similar methods from both the Python scientific computing package and other relative development kits in method calls and source code to demonstrate the innovation of the tensor projection algorithm. On this basis, the classical convolution operation program commonly used in machine learning has been parallelized and improved, the analysis algorithm of the Beidou communication satellite view area has been parallelized and improved, and the actual operating efficiency has been greatly improved. After verification, the tensor projection transformation successfully solves the problem of location index mapping of the entity units among different dimensions, can provide a means for optimizing the traditional model of traversal algorithm, and can have significant reference value in eigenspace transformation against a tensor field.",Web of Science
"Bassman, Lindsay; Gulania, Sahil; Powers, Connor; Li, Rongpeng; Linker, Thomas; Liu, Kuang; Satish Kumar, T. K.; Kalia, Rajiv K.; Nakano, Aiichiro; Vashishta, Priya",Domain-specific compilers for dynamic simulations of quantum materials on quantum computers,2021,10.1088/2058-9565/abbea1,https://doi.org/10.1088/2058-9565/abbea1,Journal,QUANTUM SCIENCE AND TECHNOLOGY,"Simulation of the dynamics of quantum materials is emerging as a promising scientific application for noisy intermediate-scale quantum (NISQ) computers. Due to their high gate-error rates and short decoherence times, however, NISQ computers can only produce high-fidelity results for those quantum circuits smaller than some given circuit size. Dynamic simulations, therefore, pose a challenge as current algorithms produce circuits that grow in size with each subsequent time-step of the simulation. This underscores the crucial role of quantum circuit compilers to produce executable quantum circuits of minimal size, thereby maximizing the range of physical phenomena that can be studied within the NISQ fidelity budget. Here, we present two domain-specific (DS) quantum circuit compilers for the Rigetti and IBM quantum computers, specifically designed to compile circuits simulating dynamics under a special class of time-dependent Hamiltonians. The compilers outperform state-of-the-art general-purpose compilers in terms of circuit size reduction by around 25%-30% as well as wall-clock compilation time by around 40% (dependent on system size and simulation time-step). Drawing on heuristic techniques commonly used in artificial intelligence, both compilers scale well with simulation time-step and system size. Code for both compilers is open-source and packaged into a full-stack quantum simulation software with tutorials included for ease of use for future researchers wishing to perform dynamic simulations of quantum materials on quantum computers. As our DS compilers provide significant improvements in both compilation time and simulation fidelity, they provide a building block for accelerating progress toward physical quantum supremacy.",Web of Science
"Du, Dou; Baird, Taylor J.; Bonella, Sara; Pizzi, Giovanni","OSSCAR, an open platform for collaborative development of computational tools for education in science",2023,10.1016/j.cpc.2022.108546,https://doi.org/10.1016/j.cpc.2022.108546,Journal,COMPUTER PHYSICS COMMUNICATIONS,"In this paper we present the Open Software Services for Classrooms and Research (OSSCAR) platform. OSSCAR provides an open collaborative environment to develop and access educational resources in the form of web applications, for which various deployment methods are discussed and compared. To minimize efforts in the creation and use of new educational material, OSSCAR combines software tools that have emerged as standards with custom domain-specific ones. The technical solutions adopted to create and distribute content are described and motivated on the basis of reliability, sustainability, ease of uptake and use. Examples from courses in the domains of physics, chemistry, and materials science are shown to demonstrate the style and level of interactivity of typical applications. The tools presented are easy to use, and create a uniform and open environment exploitable by a large community of teachers, students, and researchers with the goal of facilitating learning and avoiding, when possible, duplication of efforts in creating teaching material. Contributions to expand the educational content of the OSSCAR project are welcome.",Web of Science
"Xiong, Gang; Hu, Yu-xiang; Tian, Le; Lan, Ju-long; Li, Jun-fei; Zhou, Qiao",A virtual service placement approach based on improved quantum genetic algorithm,2016,10.1631/FITEE.1500494,https://doi.org/10.1631/FITEE.1500494,Journal,FRONTIERS OF INFORMATION TECHNOLOGY & ELECTRONIC ENGINEERING,"Despite the critical role that middleboxes play in introducing new network functionality, management and innovation of them are still severe challenges for network operators, since traditional middleboxes based on hardware lack service flexibility and scalability. Recently, though new networking technologies, such as network function virtualization (NFV) and software-defined networking (SDN), are considered as very promising drivers to design cost-efficient middlebox service architectures, how to guarantee transmission efficiency has drawn little attention under the condition of adding virtual service process for traffic. Therefore, we focus on the service deployment problem to reduce the transport delay in the network with a combination of NFV and SDN. First, a framework is designed for service placement decision, and an integer linear programming model is proposed to resolve the service placement and minimize the network transport delay. Then a heuristic solution is designed based on the improved quantum genetic algorithm. Experimental results show that our proposed method can calculate automatically the optimal placement schemes. Our scheme can achieve lower overall transport delay for a network compared with other schemes and reduce 30% of the average traffic transport delay compared with the random placement scheme.",Web of Science
"Wang, Baonan; Yang, Xiaoting; Zhang, Dan",Research on Quantum Annealing Integer Factorization Based on Different Columns,2022,10.3389/fphy.2022.914578,https://doi.org/10.3389/fphy.2022.914578,Journal,FRONTIERS IN PHYSICS,"The majority of scholars believe that Shor's algorithm is a unique and powerful quantum algorithm for RSA cryptanalysis, so current postquantum cryptography research has largely considered only the potential threats of Shor's algorithm. This paper verifies the feasibility of deciphering RSA public key cryptography based on D-Wave, which is the second most effective RSA attack method after Shor's algorithm. This paper proposes the influence of different column methods on the final integer factorization, puts forward a new dimension reduction formula, simplifies the integer factorization model based on quantum annealing, simulates it with the qbsolv quantum computing software environment provided by D-Wave, and factors the integer 1630729 (an 11-bit prime factor multiplied by an 11-bit prime factor). The research results show that choosing an appropriate number of columns and column width in the binary integer factorization multiplication table is very important for studying the optimization ability of the quantum annealing algorithm. In fact, Science, Nature, IEEE Spectrum, and the National Academies of Sciences (NAS) are consistent in asserting that the practical application of general-purpose quantum computers is far in the future. Therefore, although D-Wave computers were initially mainly purchased by Lockheed Martin, Google, etc., for purposes such as image processing, machine learning, combinatorial optimization, and software verification, post quantum cryptography research should further consider the potential of the D-Wave quantum computer in deciphering RSA cryptosystems in the future, and a discussion of this potential is one of the contributions of this paper.",Web of Science
"Sarkar, Kanchan; Topsakal, Mehmet; Holzwarth, N. A. W.; Wentzcovitch, Renata M.",Evolutionary optimization of PAW data-sets for accurate high pressure simulations,2017,10.1016/j.jcp.2017.06.032,https://doi.org/10.1016/j.jcp.2017.06.032,Journal,JOURNAL OF COMPUTATIONAL PHYSICS,"We examine the challenge of performing accurate electronic structure calculations at high pressures by comparing the results of all-electron full potential linearized augmented-plane-wave calculations, as implemented in the WIEN2k code, with those of the projector augmented wave (PAW) method, as implemented in Quantum ESPRESSO or Abinit code. In particular, we focus on developing an automated and consistent way of generating transferable PAW data-sets that can closely produce the all electron equation of state defined from zero to arbitrary high pressures. The technique we propose is an evolutionary search procedure that exploits the ATOMPAW code to generate atomic data-sets and the Quantum ESPRESSO software suite for total energy calculations. We demonstrate different aspects of its workability by optimizing PAW basis functions of some elements relatively abundant in planetary interiors. In addition, we introduce a new measure of atomic data-set goodness by considering their performance uniformity over an extended pressure range. (C) 2017 Elsevier Inc. All rights reserved.",Web of Science
"Lee, Kyunghoon; Kim, Jun Hyeong; Kim, Woo Youn",Computer Programs Physics pyMCD: Python package for searching transition states via the multicoordinate driven method,2023,10.1016/j.cpc.2023.108831,https://doi.org/10.1016/j.cpc.2023.108831,Journal,COMPUTER PHYSICS COMMUNICATIONS,"Elucidation of activation barriers is essential to understand the energetics of chemical reactions. Transition states (TSs) are the key information necessary to evaluate activation barriers. Among various methods, the multicoordinate driven (MCD) method is particularly useful for searching TSs because it requires simple inputs but shows high reliability with reasonable computation costs. This method starts from reactants and generates a reaction path by scanning multiple active coordinates until it arrives at the products, eventually leading to a TS and the corresponding activation barrier. Despite its high reliability, however, the source code is not publicly available. Herein, we present a Python package, hereafter referred to as pyMCD that searches for TSs using the MCD method. We slightly revised the original MCD method proposed by Berente and coworkers [1] to improve its computational efficiency while minimizing loss of accuracy. The package is extremely user-friendly, requiring minimal effort from users for input preparation. Moreover, it is well organized, so users can readily customize it for their purposes. The current version has been interfaced with Gaussian and ORCA, but can be interfaced with any quantum chemistry package by slightly modifying the source code. We demonstrated the high reliability of the revised method by testing it with various chemical reactions.Program summary Program Title: pyMCDCPC Library link to program files: https://doi .org /10 .17632 /wb6r97mb5s .1Developer's repository link: https://github .com /kyunghoonlee777 /pyMCD .gitLicensing provisions: BSD-3-clauseProgramming language: PythonSupplementary material:1. Input files for the results section (input_files.tar)2. Output files of the results section (output_files.tar)3. Manual for installing and running pyMCD (manual.pdf)Nature of problem: Rapid and reliable transition state (TS) exploration is challenging because TSs are saddle points on the potential energy surface of chemical reactions. The multicoordinate driven (MCD) method was proposed as a powerful approach for TS searching with various advantages, including high reliability and convenience of its use. Unfortunately, neither the source code nor any executable version of it is publicly available.Solution method: We provide a Python package, namely, pyMCD, that can search TSs using the MCD method. The method was implemented in Python with high-performance and user-friendly environments. Our test study demonstrated the high reliability of our implementation. The code structure is well organized, so users can easily customize it for their purposes. Moreover, it can be readily interfaced with any quantum chemistry software with minimal effort. At present, it has been interfaced with Gaussian and ORCA.& COPY; 2023 Elsevier B.V. All rights reserved.",Web of Science
"Castro, Alberto",qocttools: A program for quantum optimal control calculations,2024,10.1016/j.cpc.2023.108983,https://doi.org/10.1016/j.cpc.2023.108983,Journal,COMPUTER PHYSICS COMMUNICATIONS,"The qocttools code performs optimization calculations on quantum systems using optimal control theory. The problem that it solves is the following: given a system governed by a Hamiltonian whose precise form can be tuned through the variation of some control parameters, and given a user-defined merit function of the system trajectory, what are the values of those parameters that lead to the time evolution that maximizes the merit function? The code permits to work on generic systems, and uses either Schrodinger's or Lindblad's equation in order to deal with closed or open systems, respectively. It may also use the tools of Floquet formalism when dealing with periodic perturbations. It is written in Python, and the user can interface with it by preparing driver Python scripts that define the model, and load the appropriate qocttools modules. It is open and free software, and also relies on open and free widely used libraries and packages, such as QuTiP (to handle the quantum model definition and manipulation), and NLopt (to perform the optimizations).Program summary Program Title: qocttools CPC Library link to program files: https://doi .org /10 .17632 /49z3vydmwk .1 Developer's repository link: https://gitlab .com /acbarrigon /qocttools Code Ocean capsule: https://codeocean .com /capsule /7560215 Licensing provisions:GPLv3 Programming language: Python Nature of problem: When a quantum system can be driven by external perturbations, one may be interested in finding the form of those perturbations that lead to a certain behavior. For example, driving the system from its ground to a given excited state, maximizing the value of some observable, etc. This can be interpreted as an inverse spectroscopy: the goal is not to predict the reaction of a piece of matter to an external probe or perturbation (e.g. an electromagnetic field), but instead to predict the precise shape of the perturbation that leads to a given predefined reaction. This problem may be posed for closed systems evolving coherently, or in the context of open quantum systems, in the presence of an environment. Also, when considering periodic perturbations, the problem may be formulated in the language of quantum Floquet theory.Solution method: This code implements the fundamental equations of quantum optimal control theory [1], the mathematical framework that addresses the problem described above. It (1) handles both closed or open quantum systems; (2) allows the user to specify any form for the target function (the one that is to be optimized, and encodes the desired system behavior), as it may be specified through any user-defined Python function; (3) allows the user to specify general parameterized forms for the control functions, and to set bounds and constraints on those parameters; (4) implements formulas, based on the adjoint method in most cases, for the computation of the gradient of the target functions with respect to the control parameters, as these gradients are the key tools for an efficient optimization, and (5) interfaces to a generic optimization library (NLopt), that permits to perform the optimization with numerous different algorithms, allowing for the use of bounds and linear or nonlinear constraints.",Web of Science
"Alzubi, Omar A.; Alzubi, Jafar A.; Alzubi, Tareq Mahmod; Singh, Ashish",Quantum Mayfly Optimization with Encoder-Decoder Driven LSTM Networks for Malware Detection and Classification Model,2023,10.1007/s11036-023-02105-x,https://doi.org/10.1007/s11036-023-02105-x,Journal,MOBILE NETWORKS & APPLICATIONS,"Malware refers to malicious software developed to penetrate or damage a computer system without any owner's informed consent. It uses target system susceptibilities, like bugs in legitimate software that can be harmed. For dealing with the new malware, new approaches have been developed to identify and prevent any damage caused. The recent advances in Deep Learning (DL) models are useful for malware detection because they are trained via feature learning instead of task-specific approaches. This paper presents an Optimal Encoder-Decoder Driven LSTM Networks for Malware Detection and Classification (OELSTM-MDC) technique. The presented OELSTM-MDC technique involves the identification and classification of malware. To accomplish this, the OELSTM-MDC model applies pre-processing in the initial stage for data normalization. In addition, Quantum Mayfly Optimization-based Feature Selection (QMFO-FS) approach is derived from choosing an optimal subset of features. Finally, the Butterfly Optimization Algorithm (BOA) is employed for optimal hyperparameter tuning of the ELSTM model. A wide range of empirical analysis is investigated on benchmark datasets to assess the better malware classification performance of the OELSTM-MDC model. It is also compared with the conventional machine learning models such as Random Forest, XGBoost, support vector machine, etc. According to the comparison studies, the OELSTM-MDC model outperformed conventional techniques by detecting the malware class and benign class with accuracy of 97.14% and 98.33% based on the training and testing datasets.",Web of Science
"Ejalonibu, Murtala A.; Ogundare, Segun A.; Elrashedy, Ahmed A.; Ejalonibu, Morufat A.; Lawal, Monsurat M.; Mhlongo, Ndumiso N.; Kumalo, Hezekiel M.",Drug Discovery for Mycobacterium tuberculosis Using Structure-Based Computer-Aided Drug Design Approach,2021,10.3390/ijms222413259,https://doi.org/10.3390/ijms222413259,Journal,INTERNATIONAL JOURNAL OF MOLECULAR SCIENCES,"Developing new, more effective antibiotics against resistant Mycobacterium tuberculosis that inhibit its essential proteins is an appealing strategy for combating the global tuberculosis (TB) epidemic. Finding a compound that can target a particular cavity in a protein and interrupt its enzymatic activity is the crucial objective of drug design and discovery. Such a compound is then subjected to different tests, including clinical trials, to study its effectiveness against the pathogen in the host. In recent times, new techniques, which involve computational and analytical methods, enhanced the chances of drug development, as opposed to traditional drug design methods, which are laborious and time-consuming. The computational techniques in drug design have been improved with a new generation of software used to develop and optimize active compounds that can be used in future chemotherapeutic development to combat global tuberculosis resistance. This review provides an overview of the evolution of tuberculosis resistance, existing drug management, and the design of new anti-tuberculosis drugs developed based on the contributions of computational techniques. Also, we show an appraisal of available software and databases on computational drug design with an insight into the application of this software and databases in the development of anti-tubercular drugs. The review features a perspective involving machine learning, artificial intelligence, quantum computing, and CRISPR combination with available computational techniques as a prospective pathway to design new anti-tubercular drugs to combat resistant tuberculosis.",Web of Science
"Rossignolo, Marco; Reisser, Thomas; Marshall, Alastair; Rembold, Phila; Pagano, Alice; Vetter, Philipp J.; Said, Ressa S.; Mueller, Matthias M.; Motzoi, Felix; Calarco, Tommaso; Jelezko, Fedor; Montangero, Simone",QuOCS: The quantum optimal control suite,2023,10.1016/j.cpc.2023.108782,https://doi.org/10.1016/j.cpc.2023.108782,Journal,COMPUTER PHYSICS COMMUNICATIONS,"Quantum optimal control includes a family of pulse-shaping algorithms that aim to unlock the full potential of a variety of quantum technologies. The Quantum Optimal Control Suite (QuOCS) unites experimental focus and model-based approaches in a unified framework. Easy usage and installation presented here and the availability of various combinable optimization strategies is designed to improve the performance of many quantum technology platforms, such as color defects in diamond, superconducting qubits, atom-or ion-based quantum computers. It can also be applied to the study of more general phenomena in physics. In this paper, we describe the software and the toolbox of gradient -free and gradient-based algorithms. We then show how the user can connect it to their experiment. In addition, we provide illustrative examples where our optimization suite solves typical quantum optimal control problems, in both open-and closed-loop settings. Integration into existing experimental control software is already provided for the experiment control software Qudi (Binder et al., 2017 [41]), and further extensions are investigated and highly encouraged. QuOCS is available from GitHub, under Apache License 2.0, and can be found on the PyPI repository. Program summary Program Title: QuOCS -Quantum Optimal Control Suite CPC Library link to program files: https://doi .org /10 .17632 /wjjch757fk.1 Developer's repository link: https://github .com /Quantum -OCS /QuOCS Licensing provisions: Apache-2.0 Programming language: Python External routines: NumPy [1], SciPy [1], JAX [2] Nature of problem: Quantum systems are typically controlled by time-dependent electromagnetic fields to perform a certain set of quantum operations. Those operations may in turn provide building blocks for various quantum information processing tasks such as quantum computation, communication, simulation, sensing, and metrology. Numerous control strategies exist to design and improve such operations [3]. While some strategies are constructed to target a rather specific problem with high efficiency, others are more general to solve a wide range of applications [4,5]. To access the different algorithms, one has to download different optimization suites with different input and output parameters, making them hard to compare and combine. To benefit from the variety of algorithms, we have devised a customizable and intuitive optimization suite that simultaneously provides access to some of the most popular quantum optimal control algorithms.Solution method: We combine, in a unified framework, some of the frequently used optimal control algorithms which are the dressed Chopped Random Basis method (dCRAB) [6], and Gradient Ascent Pulse Engineering (GRAPE) [7], with an extension to make use of Automatic Differentiation (AD) [8]. The software is able to connect to both models of quantum dynamics in simulations and real-time quantum experiments to perform open-and closed-loop optimization, respectively. With minimal knowledge of optimal control theory, the user can manage to run optimizations of quantum processes using a variety of additional features such as stopping criteria and drift compensation. Logging and data management of the optimization progress and results are also handled by the suite. Its modular structure allows for extensions that accommodate customized algorithms and can be implemented by the user straightforwardly.Additional comments including unusual features: The connection to the experiments is performed by an extension that enables a direct integration to a laboratory control software Qudi [9].References[1] T.E. Oliphant, Comput. Sci. Eng. 9 (2007) 10, http://www.scipy.org/.[2] J. Bradbury, et al., JAX: composable transformations of Python+NumPy programs, http://github .com / google /jax, 2018.[3] S. Glaser, U. Boscain, T. Calarco, et al., Eur. Phys. J. D 69 (2015) 279. [4] C.P. Koch, U. Boscain, T. Calarco, et al., EPJ Quantum Technol. 9 (2022) 19.[5] Schaefer, Ido, Ronnie Kosloff, Phys. Rev. A 101 (2) (2020).[6] N. Rach, M.M. Muller, T. Calarco, S. Montangero, Phys. Rev. A 92 (2015) 6. [7] N. Khaneja, et al., J. Magn. Reson. 92 (6) (2015) 296-305. [8] N. Leung, et al., Phys. Rev. A 95 (2017) 4.[9] J.M. Binder, et al., SoftwareX 6 (2017) 85-90. & COPY; 2023 Elsevier B.V. All rights reserved.",Web of Science
"Xu, Hong-Ze; Zhuang, Wei-Feng; Wang, Zheng-An; Huang, Kai-Xuan; Shi, Yun-Hao; Ma, Wei-Guo; Li, Tian-Ming; Chen, Chi-Tong; Xu, Kai; Feng, Yu-Long; Liu, Pei; Chen, Mo; Li, Shang-Shu; Yang, Zhi-Peng; Qian, Chen; Jin, Yu-Xin; Ma, Yun-Heng; Xiao, Xiao; Qian, Peng; Gu, Yanwu; Chai, Xu-Dan; Pu, Ya-Nan; Zhang, Yi-Peng; Wei, Shi-Jie; Zeng, Jin-Feng; Li, Hang; Long, Gui-Lu; Jin, Yirong; Yu, Haifeng; Fan, Heng; Liu, Dong E.; Hu, Meng-Jun",Quafu-Qcover: Explore combinatorial optimization problems on cloud-based quantum computers,2024,10.1088/1674-1056/ad18ab,https://doi.org/10.1088/1674-1056/ad18ab,Journal,CHINESE PHYSICS B,"We introduce Quafu-Qcover, an open-source cloud-based software package developed for solving combinatorial optimization problems using quantum simulators and hardware backends. Quafu-Qcover provides a standardized and comprehensive workflow that utilizes the quantum approximate optimization algorithm (QAOA). It facilitates the automatic conversion of the original problem into a quadratic unconstrained binary optimization (QUBO) model and its corresponding Ising model, which can be subsequently transformed into a weight graph. The core of Qcover relies on a graph decomposition-based classical algorithm, which efficiently derives the optimal parameters for the shallow QAOA circuit. Quafu-Qcover incorporates a dedicated compiler capable of translating QAOA circuits into physical quantum circuits that can be executed on Quafu cloud quantum computers. Compared to a general-purpose compiler, our compiler demonstrates the ability to generate shorter circuit depths, while also exhibiting superior speed performance. Additionally, the Qcover compiler has the capability to dynamically create a library of qubits coupling substructures in real-time, utilizing the most recent calibration data from the superconducting quantum devices. This ensures that computational tasks can be assigned to connected physical qubits with the highest fidelity. The Quafu-Qcover allows us to retrieve quantum computing sampling results using a task ID at any time, enabling asynchronous processing. Moreover, it incorporates modules for results preprocessing and visualization, facilitating an intuitive display of solutions for combinatorial optimization problems. We hope that Quafu-Qcover can serve as an instructive illustration for how to explore application problems on the Quafu cloud quantum computers.",Web of Science
"Lee, Jihye; Kim, Whijin; Kim, Ji-Hoon",A Programmable Crypto-Processor for National Institute of Standards and Technology Post-Quantum Cryptography Standardization Based on the RISC-V Architecture,2023,10.3390/s23239408,https://doi.org/10.3390/s23239408,Journal,SENSORS,"The advancement of quantum computing threatens the security of conventional public-key cryptosystems. Post-quantum cryptography (PQC) was introduced to ensure data confidentiality in communication channels, and various algorithms are being developed. The National Institute of Standards and Technology (NIST) has initiated PQC standardization, and the selected algorithms for standardization and round 4 candidates were announced in 2022. Due to the large memory footprint and highly repetitive operations, there have been numerous attempts to accelerate PQC on both hardware and software. This paper introduces the RISC-V instruction set extension for NIST PQC standard algorithms and round 4 candidates. The proposed programmable crypto-processor can support a wide range of PQC algorithms with the extended RISC-V instruction set and demonstrates significant reductions in code size, the number of executed instructions, and execution cycle counts of target operations in PQC algorithms of up to 79%, 92%, and 87%, respectively, compared to RV64IM with optimization level 3 (-O3) in the GNU toolchain.",Web of Science
"Mundada, Pranav S.; Barbosa, Aaron; Maity, Smarak; Wang, Yulun; Merkh, Thomas; Stace, T. M.; Nielson, Felicity; Carvalho, Andre R. R.; Hush, Michael; Biercuk, Michael J.; Baum, Yuval",Experimental Benchmarking of an Automated Deterministic Error-Suppression Workflow for Quantum Algorithms,2023,10.1103/PhysRevApplied.20.024034,https://doi.org/10.1103/PhysRevApplied.20.024034,Journal,PHYSICAL REVIEW APPLIED,"Excitement about the promise of quantum computers is tempered by the reality that the hardware remains exceptionally fragile and error prone, forming a bottleneck in the development of alternative applications. In this paper, we describe and experimentally test a fully autonomous workflow designed to deterministically suppress errors in quantum algorithms from the gate level through to circuit execution and measurement. We introduce the key elements of this workflow, delivered as a software package called Fire Opal, and survey the underlying physical concepts: error-aware compilation, automated system-wide gate optimization, automated dynamical decoupling embedding for circuit-level error cancellation, and calibration-efficient measurement-error mitigation. We then present a comprehensive suite of performance benchmarks executed on IBM hardware, demonstrating up to > 1000x improvement over the best alternative expert-configured techniques available in the open literature. Benchmarking includes experiments using up to 16 qubit systems executing the following: Bernstein Vazirani, quantum Fourier transform, drome extraction on a five-qubit quantum error-correction code, and quantum volume. Experiments reveal a strong contribution of Non-Markovian errors to baseline algorithmic performance; in all cases the deterministic error-suppression workflow delivers the highest performance and approaches incoherent error bounds without the need for any additional sampling or randomization overhead, while maintaining compatibility with all additional probabilistic error suppression techniques.",Web of Science
"McClean, Jarrod R.; Rubin, Nicholas C.; Sung, Kevin J.; Kivlichan, Ian D.; Bonet-Monroie, Xavier; Cao, Yudong; Dai, Chengyu; Fried, E. Schuyler; Gidney, Craig; Gimby, Brendan; Gokhale, Pranav; Haner, Thomas; Hardikar, Tarini; Havlicek, Vojtech; Higgott, Oscar; Huang, Cupjin; Izaac, Josh; Jiang, Zhang; Liu, Xinle; McArdle, Sam; Neeley, Matthew; O'Brien, Thomas; O'Gorman, Bryan; Ozfidan, Isil; Radin, Maxwell D.; Romero, Jhonathan; Sawaya, Nicolas P. D.; Senjean, Bruno; Setia, Kanav; Sim, Sukin; Steiger, Damian S.; Steudtner, Mark; Sun, Qiming; Sun, Wei; Wang, Daochen; Zhang, Fang; Babbush, Ryan",OpenFermion: the electronic structure package for quantum computers,2020,10.1088/2058-9565/ab8ebc,https://doi.org/10.1088/2058-9565/ab8ebc,Journal,QUANTUM SCIENCE AND TECHNOLOGY,"Quantum simulation of chemistry and materials is predicted to be an important application for both near-term and fault-tolerant quantum devices. However, at present, developing and studying algorithms for these problems can be difficult due to the prohibitive amount of domain knowledge required in both the area of chemistry and quantum algorithms. To help bridge this gap and open the field to more researchers, we have developed the OpenFermion software package (). OpenFermion is an open-source software library written largely in Python under an Apache 2.0 license, aimed at enabling the simulation of fermionic and bosonic models and quantum chemistry problems on quantum hardware. Beginning with an interface to common electronic structure packages, it simplifies the translation between a molecular specification and a quantum circuit for solving or studying the electronic structure problem on a quantum computer, minimizing the amount of domain expertise required to enter the field. The package is designed to be extensible and robust, maintaining high software standards in documentation and testing. This release paper outlines the key motivations behind design choices in OpenFermion and discusses some basic OpenFermion functionality which we believe will aid the community in the development of better quantum algorithms and tools for this exciting area of research.",Web of Science
"Melo, Marcelo C. R.; Bernardi, Rafael C.",Fostering discoveries in the era of exascale computing: How the next generation of supercomputers empowers computational and experimental biophysics alike,2023,10.1016/j.bpj.2023.01.042,https://doi.org/10.1016/j.bpj.2023.01.042,Journal,BIOPHYSICAL JOURNAL,"Over a century ago, physicists started broadly relying on theoretical models to guide new experiments. Soon thereafter, chemists began doing the same. Now, biological research enters a new era when experiment and theory walk hand in hand. Novel software and specialized hardware became essential to understand experimental data and propose new models. In fact, current petascale computing resources already allow researchers to reach unprecedented levels of simulation throughput to connect in silico and in vitro experiments. The reduction in cost and improved access allowed a large number of research groups to adopt supercomputing resources and techniques. Here, we outline how large-scale computing has evolved to expand decades-old research, spark new research efforts, and continuously connect simulation and observation. For instance, multiple publicly and privately funded groups have dedicated extensive resources to develop artificial intelligence tools for computational biophysics, from accelerating quantum chemistry calculations to proposing protein structure models. More-over, advances in computer hardware have accelerated data processing from single-molecule experimental observations and simulations of chemical reactions occurring throughout entire cells. The combination of software and hardware has opened the way for exascale computing and the production of the first public exascale supercomputer, Frontier, inaugurated by the Oak Ridge National Laboratory in 2022. Ultimately, the popularization and development of computational techniques and the training of researchers to use them will only accelerate the diversification of tools and learning resources for future generations.",Web of Science
"Ning, Tao; Huang, Yiming",Low carbon emission management for flexible job shop scheduling: a study case in China,2021,10.1007/s12652-021-03330-6,https://doi.org/10.1007/s12652-021-03330-6,Journal,JOURNAL OF AMBIENT INTELLIGENCE AND HUMANIZED COMPUTING,"For flexible job-shop scheduling problem with low carbon emission constraints, an improved quantum genetic algorithm based on double chains coding is proposed. Firstly, a mathematical model is established to minimize makespan, total workload of machines and carbon emissions of machines. Secondly, carbon emission equations in job shop scheduling process are inducted and designed. Based on the selected model, a method using an improved quantum genetic algorithm with double chains to solve processing route selection is proposed. Finally, on the basis of Kacem example, the performance of the method proposed in the paper was analyzed by ANOVA through experimental simulation and compared with the algorithms commonly used at present. The results show that the method not only achieves the goal of optimization, but also meets the practical requirements of reducing carbon emissions in production and processing.",Web of Science
"Garcia, Matias; Alcayaga, Hernan; Pizarro, Alonso",Automatic Segmentation of Water Bodies Using RGB Data: A Physically Based Approach,2023,10.3390/rs15051170,https://doi.org/10.3390/rs15051170,Journal,REMOTE SENSING,"A novel method is proposed to automatically segment water extent using optical data. The key features of this approach are (i) the development of a simple physically based model that utilises only RGB data for water extent segmentation; (ii) the achievement of high accuracy in the results, particularly in the estimation of water surface area and perimeter; (iii) the avoidance of any data training process; (iv) the requirement of minimal computational resources; and (v) the release of an open-source software package that provides both command-line codes and a user-friendly graphical interface, making it accessible for various applications, research, and educational purposes. The physically based model integrates reflectance of the water surface with spectral and quantum interpretation of light. The algorithm was tested on 27 rivers and compared to manually-based delimitation, with a resulting robust segmentation procedure. Quantified errors were RMSE = 11.91 (m(2)) for surface area, RMSE = 12.25 (m) for perimeter, and RMSE in x: 52 (px), RMSE in y: 93 (px) for centroid location. Processing time was faster for automatic segmentation than manual delimitation, with a time reduction of 40% (case-by-case analysis) and 65% (using all case studies together in one run). Shadows, light spots, and natural and non-natural elements in the field of view may affect the accuracy of results.",Web of Science
"Karalekas, Peter J.; Tezak, Nikolas A.; Peterson, Eric C.; Ryan, Colm A.; da Silva, Marcus P.; Smith, Robert S.",A quantum-classical cloud platform optimized for variational hybrid algorithms,2020,10.1088/2058-9565/ab7559,https://doi.org/10.1088/2058-9565/ab7559,Journal,QUANTUM SCIENCE AND TECHNOLOGY,"In order to support near-term applications of quantum computing, a new compute paradigm has emerged-the quantum-classical cloud-in which quantum computers (QPUs) work in tandem with classical computers (CPUs) via a shared cloud infrastructure. In this work, we enumerate the architectural requirements of a quantum-classical cloud platform, and present a framework for benchmarking its runtime performance. In addition, we walk through two platform-level enhancements, parametric compilation and active qubit reset, that specifically optimize a quantum-classical architecture to support variational hybrid algorithms, the most promising applications of near-term quantum hardware. Finally, we show that integrating these two features into the Rigetti Quantum Cloud Services platform results in considerable improvements to the latencies that govern algorithm runtime.",Web of Science
"Huang, Li; Wang, Yilin; Meng, Zi Yang; Du, Liang; Werner, Philipp; Dai, Xi",iQIST: An open source continuous-time quantum Monte Carlo impurity solver toolkit,2015,10.1016/j.cpc.2015.04.020,https://doi.org/10.1016/j.cpc.2015.04.020,Journal,COMPUTER PHYSICS COMMUNICATIONS,"Quantum impurity solvers have a broad range of applications in theoretical studies of strongly correlated electron systems. Especially, they play a key role in dynamical mean-field theory calculations of correlated lattice models and realistic materials. Therefore, the development and implementation of efficient quantum impurity solvers is an important task. In this paper, we present an open source interacting quantum impurity solver toolkit (dubbed iQIST). This package contains several highly optimized quantum impurity solvers which are based on the hybridization expansion continuous-time quantum Monte Carlo algorithm, as well as some essential pre- and post-processing tools. We first introduce the basic principle of continuous-time quantum Monte Carlo algorithm and then discuss the implementation details and optimization strategies. The software framework, major features, and installation procedure for iQIST are also explained. Finally, several simple tutorials are presented in order to demonstrate the usage and power of iQIST.Program summaryProgram title: iQISTCatalogue identifier: AEWQ_v1_0Program summary URL: http://cpc.cs.qub.ac.uk/summaries/AEWQ_v1_0.htmlProgram obtainable from: CPC Program Library, Queen's University, Belfast, N. IrelandLicensing provisions: GNU General Public License, version 3No. of lines in distributed program, including test data, etc.: 226270No. of bytes in distributed program, including test data, etc.: 5263144Distribution format: tar.gzProgramming language: Fortran 2008 and Python.Computer: Desktop PC, laptop, high performance computing cluster.Operating system: Unix, Linux, Mac OS X, Windows.Has the code been vectorized or parallelized?: Yes, it is parallelized by MPI and OpenMPRAM: Depends on the complexity of the problemClassification: 7.3.External routines: BLAS, LAPACK, Latex is required to build the user manual.Nature of problem:Quantum impurity models were originally proposed to describe magnetic impurities in metallic hosts. In these models, the Coulomb interaction acts between electrons occupying the orbitals of the impurity atom. Electrons can hop between the impurity and the host, and in an action formulation, this hopping is described by a time-dependent hybridization function. Nowadays quantum impurity models have a broad range of applications, from the description of heavy fermion systems, and Kondo insulators, to quantum dots in nano-science. They also play an important role as auxiliary problems in dynamical mean-field theory and its diagrammatic extensions [1-3], where an interacting lattice model is mapped onto a quantum impurity model in a self-consistent manner. Thus, the accurate and efficient solution of quantum impurity models becomes an essential task.Solution method:The quantum impurity model can be solved by the numerically exact continuous-time quantum Monte Carlo method, which is the most efficient and powerful impurity solver for finite temperature simulations. In the iQIST software package, we implemented the hybridization expansion version of continuous-time quantum Monte Carlo algorithm. Both the segment representation and general matrix formalism are supported. The key idea of this algorithm is to expand the partition function diagrammatically in powers of the impurity-bath hybridization, and to stochastically sample these diagrams to all relevant orders using the Metropolis Monte Carlo algorithm. For a detailed review of the continuous-time quantum Monte Carlo algorithms, please refer to [4].Running time:Depends on the complexity of the problem. The sample run supplied in the distribution takes about 1.5 minutes. (C) 2015 Elsevier B.V. All rights reserved.",Web of Science
"Moussa, Charles; Patel, Yash J.; Dunjko, Vedran; Baeck, Thomas; van Rijn, Jan N.",Hyperparameter importance and optimization of quantum neural networks across small datasets,2023,10.1007/s10994-023-06389-8,https://doi.org/10.1007/s10994-023-06389-8,Journal,MACHINE LEARNING,"As restricted quantum computers become available, research focuses on finding meaningful applications. For example, in quantum machine learning, a special type of quantum circuit called a quantum neural network is one of the most investigated approaches. However, we know little about suitable circuit architectures or important model hyperparameters for a given task. In this work, we apply the functional ANOVA framework to the quantum neural network architectures to analyze which of the quantum machine learning hyperparameters are most influential for their predictive performance. We restrict our study to 7 open-source datasets from the OpenML-CC18 classification benchmark, which are small enough for simulations on quantum hardware with fewer than 20 qubits. Using this framework, three main levels of importance were identified, confirming expected patterns and revealing new insights. For instance, the learning rate is identified as the most important hyperparameter on all datasets, whereas the particular choice of entangling gates used is found to be the least important on all except for one dataset. In addition to identifying the relevant hyperparameters, for each of them, we also learned data-driven priors based on values that perform well on previously seen datasets, which can then be used to steer hyperparameter optimization processes. We utilize these priors in the hyperparameter optimization method hyperband and show that these improve performance against uniform sampling across all datasets by, on average, 0.53%, up to 6.11%, in cross-validation accuracy. We also demonstrate that such improvements hold on average regardless of the configuration hyperband is run with. Our work introduces new methodologies for studying quantum machine learning models toward quantum model selection in practice. All research code is made publicly available.",Web of Science
"Mohanty, Nishikanta; Behera, Bikash K.; Ferrie, Christopher",Analysis of the Vehicle Routing Problem Solved via Hybrid Quantum Algorithms in the Presence of Noisy Channels,2023,10.1109/TQE.2023.3303989,https://doi.org/10.1109/TQE.2023.3303989,Journal,IEEE TRANSACTIONS ON QUANTUM ENGINEERING,"The vehicle routing problem (VRP) is an NP-hard optimization problem that has been an interest of research for decades in science and industry. The objective is to plan routes of vehicles to deliver goods to a fixed number of customers with optimal efficiency. Classical tools and methods provide good approximations to reach the optimal global solution. Quantum computing and quantum machine learning provide a new approach to solving combinatorial optimization of problems faster due to inherent speedups of quantum effects. Many solutions of VRP are offered across different quantum computing platforms using hybrid algorithms, such as quantum approximate optimization algorithm and quadratic unconstrained binary optimization. In this work, we build a basic VRP solver for three and four cities using the variational quantum eigensolver on a fixed ansatz. The work is further extended to evaluate the robustness of the solution in several examples of noisy quantum channels. We find that the performance of the quantum algorithm depends heavily on what noise model is used. In general, noise is detrimental, but not equally so among different noise sources.",Web of Science
"Huber, Stefan; Koenig, Robert; Tomamichel, Marco",Jointly Constrained Semidefinite Bilinear Programming With an Application to Dobrushin Curves,2020,10.1109/TIT.2019.2939474,https://doi.org/10.1109/TIT.2019.2939474,Journal,IEEE TRANSACTIONS ON INFORMATION THEORY,"We propose a branch-and-bound algorithm for minimizing a bilinear functional of the form f(X,Y) = \mathrm {tr}((X\otimes Y)Q)+ \mathrm {tr}(AX)+ \mathrm {tr}(BY) , of pairs of Hermitian matrices (X,Y) restricted by joint semidefinite programming constraints. The functional is parametrized by self-adjoint matrices Q , A and B . This problem generalizes that of a bilinear program, where X and Y belong to polyhedra. The algorithm converges to a global optimum and yields upper and lower bounds on its value in every step. Various problems in quantum information theory can be expressed in this form. As an example application, we compute Dobrushin curves of quantum channels, giving upper bounds on classical coding with energy constraints.",Web of Science
"Cao, Bin; Fan, Shanshan; Zhao, Jianwei; Yang, Po; Muhammad, Khan; Tanveer, Mohammad",Quantum-enhanced multiobjective large-scale optimization via parallelism,2020,10.1016/j.swevo.2020.100697,https://doi.org/10.1016/j.swevo.2020.100697,Journal,SWARM AND EVOLUTIONARY COMPUTATION,"Traditional quantum-based evolutionary algorithms are intended to solve single-objective optimization problems or multiobjective small-scale optimization problems. However, multiobjective large-scale optimization problems are continuously emerging in the big-data era. Therefore, the research in this paper, which focuses on combining quantum mechanics with multiobjective large-scale optimization algorithms, will be beneficial to the study of quantum-based evolutionary algorithms. In traditional quantum-behaved particle swarm optimization (QPSO), particle position uncertainty prevents the algorithm from easily falling into local optima. Inspired by the uncertainty principle of position, the authors propose quantum-enhanced multiobjective large-scale algorithms, which are parallel multiobjective large-scale evolutionary algorithms (PMLEAs). Specifically, PMLEA-QDE, PMLEA-QjDE and PMLEA-QJADE are proposed by introducing the search mechanism of the individual particle from QPSO into differential evolution (DE), differential evolution with self-adapting control parameters (jDE) and adaptive differential evolution with optional external archive (JADE). Moreover, the proposed algorithms are implemented with parallelism to improve the optimization efficiency. Verifications performed on several test suites indicate that the proposed quantum-enhanced algorithms are superior to the state-of-the-art algorithms in terms of both effectiveness and efficiency.",Web of Science
"Qiao, Wenxin; Lu, Hao; Lu, Yu; Meng, Lijie; Liu, Yicen",A Dynamic Service Reconfiguration Method for Satellite-Terrestrial Integrated Networks,2021,10.3390/fi13100260,https://doi.org/10.3390/fi13100260,Journal,FUTURE INTERNET,"Satellite-terrestrial integrated networks (STINs) are regarded as a promising solution to meeting the demands of global high-speed seamless network access in the future. Software-defined networking and network function virtualization (SDN/NFV) are two complementary technologies that can be used to ensure that the heterogeneous resources in STINs can be easily managed and deployed. Considering the dual mobility of satellites and ubiquitous users, along with the dynamic requirements of user requests and network resource states, it is challenging to maintain service continuity and high QoE performance in STINs. Thus, we investigate the service migration and reconfiguration scheme, which are of great significance to the guarantee of continuous service provisioning. Specifically, this paper proposes a dynamic service reconfiguration method that can support flexible service configurations on integrated networks, including LEO satellites and ground nodes. We first model the migration cost as an extra delay incurred by service migration and reconfiguration and then formulate the selection processes of the location and migration paths of virtual network functions (VNFs) as an integer linear programming (ILP) optimization problem. Then, we propose a fuzzy logic and quantum genetic algorithm (FQGA) to obtain an approximate optimal solution that can accelerate the solving process efficiently with the benefits of the high-performance computing capacity of QGA. The simulation results validate the effectiveness and improved performance of the scheme proposed in this paper.",Web of Science
"Kundu, Sohang; Makri, Nancy",PathSum: A C++ and Fortran suite of fully quantum mechanical real-time path integral methods for (multi-)system + bath dynamics.,2023,10.1063/5.0151748,https://doi.org/10.1063/5.0151748,Journal,The Journal of chemical physics,"This paper reports the release of PathSum, a new software suite of state-of-the-art path integral methods for studying the dynamics of single or extended systems coupled to harmonic environments. The package includes two modules, suitable for system-bath problems and extended systems comprising many coupled system-bath units, and is offered in C++ and Fortran implementations. The system-bath module offers the recently developed small matrix path integral (SMatPI) and the well-established iterative quasi-adiabatic propagator path integral (i-QuAPI) method for iteration of the reduced density matrix of the system. In the SMatPI module, the dynamics within the entanglement interval can be computed using QuAPI, the blip sum, time evolving matrix product operators, or the quantum-classical path integral method. These methods have distinct convergence characteristics and their combination allows a user to access a variety of regimes. The extended system module provides the user with two algorithms of the modular path integral method, applicable to quantum spin chains or excitonic molecular aggregates. An overview of the methods and code structure is provided, along with guidance on method selection and representative examples.",Web of Science
"Van de Vijver, Ruben; Zador, Judit",KinBot: Automated stationary point search on potential energy surfaces,2020,10.1016/j.cpc.2019.106947,https://doi.org/10.1016/j.cpc.2019.106947,Journal,COMPUTER PHYSICS COMMUNICATIONS,"KinBot is a Python code that automatically characterizes kinetically important stationary points on reactive potential energy surfaces and arranges the results into a form that lends itself easily to master equation calculations. This version of KinBot tackles C, H, O and S atom containing species and unimolecular (isomerization or dissociation) reactions. KinBot iteratively changes the geometry of the reactant to obtain initial guesses for reactive saddle points defined by KinBot's reaction types, which are then optimized by a third-party quantum chemistry package. KinBot verifies the connectivity of the saddle points with the reactant and identifies the products through intrinsic reaction coordinate calculations. New calculations can be automatically spawned from the products to obtain complete potential energy surfaces. The utilities of KinBot include conformer searches, projected frequency and hindered rotor calculations, and the automatic determination of the rotational symmetry numbers. Input files for popular RRKM master equation codes are automatically built, enabling an automated workflow all the way to the calculation of pressure and temperature dependent rate coefficients. Four examples are included. (i) [1,3]-sigmatropic H-migration reactions of unsaturated hydrocarbons and oxygenates are calculated to assess the relative importance of suprafacial and antrafacial reactions. (ii) Saddle points on three products of gamma-valerolactone thermal decomposition are studied and compared to literature potential energy surfaces. (iii) The previously published propene+OH reaction is reproduced to show the capability of building an entire potential energy surface. (iv) All species up to C4 in the Aramco Mech 2.0 are subjected to a KinBot search.Program summaryProgram title: KinBotProgram files doi: http://dx.doLorgi10.17632/hsh6dvv2zj.1Licensing provisions: BSD 3-ClauseProgramming language: PythonSupplementary material:1. A static version of the source code (KinBot.tar),2. The manual for the static version (KinBot_Manual.pdf)3. Geometries and energies of the stationary points on the potential energy surface of the sigmatropic reaction search (sigmatropic_H_shift.out)4. Geometries and energies of the stationary points on the potential energy surface of the propene+OH central and terminal addition reaction (propene+oh central addition.out, propene+oh terminal addition.out)5. Geometries and energies of the stationary points on the potential energy surface of gamma valerolactone, 4-pentenoic acid and 3-pentenoic acid (GVL energies and geometries.out, 4PA energies and geometries.out, 3PA energies and geometries.out)6. Example runs including all input and output files for a one-well search for propanol radical, full PES search for the n-pentyl radical, a search for all homolytic scission in propanol, and the reaction searches for GVL (output.zip)7. Results of symmetry calculations for a literature benchmark dataset (Symmetry_correct.pdf, Symmetry_wrong.pdf)Nature of problem: Automatic discovery of unimolecular reaction pathways (isomerization and dissociation) for molecules and radicals relevant in gas-phase combustion and atmospheric chemistry, including oxidation and pyrolytic processes for structures including carbon, oxygen, sulfur and hydrogen atoms. The reactants, products, and transition states are characterized using a suite of tools coupled to electronic structure codes, and the results are provided in a format that lends itself easily to calculating rate coefficients based on statistical rate theories with other external codes.Solution method: Reaction pathways are identified using heuristic searches starting from a reactant by iteratively altering its geometry toward a good guess for a transition state for reactions with barriers. The transition state is identified as a first-order saddle point on the potential energy surface, which is located using local optimization methods of third-party quantum chemistry codes. We use intrinsic reaction coordinate calculations to verify the direct connectivity of the saddle point to the reactant and to identify the product species. Conformational searches, hindered rotor potentials, frequency calculations, and high-level optimizations yield the necessary data for RRKM master equation calculations.Additional comments including restrictions and unusual features: KinBot is designed to run on Unix clusters, and is written in Python, compatible with versions 2.7 and 3. It communicates with a PBS or SLURM workload manager to submit quantum chemistry calculations to third-party software. It makes use of a modified fork of ASE for the input writing, calling and output parsing of the quantum chemistry software which has been tested with Gaussian (G09RevD.01). OpenBabel (2.4.1) and RDKit (2018.09.01) are used to convert smiles to internal species representations and for species comparison and results visualization. The output of KinBot can be visualized with the PESViewer script, and graph structures are drawn using NetworkX. The master equation solvers MESS or MESMER are needed to calculate rate coefficients at the end of a given run. This version of KinBot can handle H, C, S, and O atom-containing molecules, and searches for isomerization and dissociation pathways. (C) 2019 Published by Elsevier B.V.",Web of Science
"Wang, Ling; Ni, Haoqi; Yang, Ruixin; Pappu, Vijay; Fenn, Michael B.; Pardalos, Panos M.",Feature selection based on meta-heuristics for biomedicine,2014,10.1080/10556788.2013.834900,https://doi.org/10.1080/10556788.2013.834900,Journal,OPTIMIZATION METHODS & SOFTWARE,"Feature selection can efficiently improve the accuracy of classification and reduce the measurement, storage and computation demands, and thus it has been applied in biomedical research increasingly. Considering the non-deterministic polynomial-time hard characteristic of feature selection, meta-heuristics are introduced into feature selection in biomedicine on account of their excellent global search ability. However, most of biomedical problems are characterized by high dimensionality, which is a challenge for feature selection methods based on meta-heuristics due to the curse of dimensionality. Thus, six meta-heuristics, that is, a genetic algorithm, particle swarm optimization, ant colony optimization, harmony search, differential evolution, and quantum-inspired evolutionary algorithm, which are widely studied in the meta-heuristic community, are introduced into feature selection in this paper and the performance of the algorithms is analysed and compared with each other for solving feature selection in biomedicine effectively. To evaluate the search ability of the algorithms fairly and exactly, a set of feature selection benchmark problems are designed and yielded for the performance tests. The experimental results show that all the meta-heuristics are powerful enough to achieve the ideal results on low-dimensional feature selection problems, while it is essential to choose a proper algorithm for the high-dimensional ones.",Web of Science
"Barnes, Kenton M.; Buyskikh, Anton; Chen, Nicholas Y.; Gallardo, Gabriel; Ghibaudi, Marco; Ruszala, Matthew J. A.; Underwood, Daniel S.; Agarwal, Abhishek; Lall, Deep; Runggar, Ivan; Schoinas, Nikolaos",Optimising the quantum/classical interface for efficiency and portability with a multi-level hardware abstraction layer for quantum computers,2023,10.1140/epjqt/s40507-023-00192-z,https://doi.org/10.1140/epjqt/s40507-023-00192-z,Journal,EPJ QUANTUM TECHNOLOGY,"Steady progress is being made in the development of quantum computing platforms based on different types of qubit technologies. Each platform requires bespoke strategies to maximise the efficiency of the quantum/classical interface when operating close to the qubits. At a higher level, however, a shared interface allowing portability of quantum algorithms across all the available quantum platforms is preferred. Striking the right balance between portability and performance of the algorithm as implemented on quantum hardware remains a major challenge for this field. Here, we propose a quantum hardware abstraction layer (QHAL) providing a multi-level intermediate representation of the quantum stack. A collaborative effort between software specialists and quantum hardware developers operating on four major qubit technologies (photonics, silicon, superconducting and trapped ions) led to the identification of a minimum common set of instructions and metadata allowing the QHAL to interact efficiently with multiple platforms. Access to the stack from the higher levels increases latency yet minimises the amount of hardware architecture parameters to be handled by the algorithm developer, thus simplifying code development and reducing security threats from misuse or malicious access for hardware developers. Access to the stack from the lowest-closest to the qubits-level provides the highest hardware responsiveness, suitable for algorithms requiring minimum latency for data and instruction transfer. With respect to existing quantum assembly languages, the QHAL extends further down in the stack by defining an application-binary interface to interact with the quantum hardware. By defining a standard representation of the quantum stack, a common reference framework is provided to both software and hardware developers which would ensure future integration of their R&D efforts.",Web of Science
"Joudaki, Daryoush; Shafiei, Fatemeh",QSPR Models to Predict Thermodynamic Properties of Cycloalkanes Using Molecular Descriptors and GA-MLR Method,2020,10.2174/1573409915666190227230744,https://doi.org/10.2174/1573409915666190227230744,Journal,CURRENT COMPUTER-AIDED DRUG DESIGN,"Aims and Objectives: QSPR models establish relationships between different types of structural information to their observed properties. In the present study the relationship between the molecular descriptors and quantum properties of cycloalkanes is represented.Materials and Methods: Genetic Algorithm (GA) and Multiple Linear Regressions (MLR) were successfully developed to predict quantum properties of cycloalkanes. A large number of molecular descriptors were calculated with Dragon software and a subset of calculated descriptors was selected with a genetic algorithm as a feature selection technique. The quantum properties consist of the heat capacity (Cv)/Jmol(-1) K-1 entropy(S)/Jmol(-1) K-1 and thermal energy(E-th)/ kJmol(-1) were obtained from quantum-chemistry technique at the Hartree-Fock (HF) level using the ab initio 6-31G* basis sets.Results: The Genetic Algorithm (GA) method was used to select important molecular descriptors and then they were used as inputs for SPSS software package. The predictive powers of the MLR models were discussed using Leave-One-Out ( LOO) cross-validation, leave-group (5-fold)-out (LGO) and external prediction series. The statistical parameters of the training and test sets for GA-MLR models were calculated.Conclusion: The resulting quantitative GA-MLR models of Cv, S, and Eth were obtained:[r(2)=0.950, Q(2)=0.989, r(ext)(2)=0.969, MAE((overall,5-flod))=0.6825 Jmol(-1) K-1], [r(2)=0.980, Q(2)=0.947, r(ext)(2)=0.943, MAE((overall,5-flod))=0.5891 Jmol(-1) K-1], and [r(2)=0.980, Q(2)=0.809, r(ext)(2)=0.985, MAE((overall,5-flod))=2.0284 kJmol(-1)]. The results showed that the predictive ability of the models was satisfactory, and the constitutional, topological indices and ring descriptor could be used to predict the mentioned properties of 103 cycloalkanes.",Web of Science
"Cao, Heng; Gao, Qianhui",Comprehensive Evaluation Method of Teaching Effect Based on Particle Swarm Optimization Neural Network Model,2022,10.1155/2022/8525531,https://doi.org/10.1155/2022/8525531,Journal,DISCRETE DYNAMICS IN NATURE AND SOCIETY,"The important role of teaching evaluation system is embodied in: starting from the teaching goal and the vocational education teaching activities. This paper studies the optimization algorithm and optimization system, it not only makes the algorithm involve basic mathematical operations, and the computer support required for the data processing process is not high, but it also improves the evaluation of the degree of optimization. In view of these characteristics, this paper has conducted in-depth research to fully prove the feasibility and superiority of the content of this article. The specific summary is as follows: (1) Introduced the design concept of particle swarm optimization teaching evaluation system. (2) The use of object-oriented programming algorithms makes it easier for the algorithm to find an entry point, solve practical problems, and optimize the reusability of the algorithm method. (3) Particle swarm optimization based on quantum behavior, adjusting parameter values, the highest and the lowest, greatly reduces the difficulty of program parameter adjustment. (4) In terms of operation, it can quickly and efficiently complete the maintenance of teacher teaching information, evaluation relationship management of teacher teaching quality evaluation, evaluation content management, student evaluation, supervision evaluation, college leadership evaluation, evaluation performance management, and other operations. The interface is extremely humane. It adopts a web-style tour method. There are many types of functions, and the system includes common functions required for general teacher teaching information management and quality evaluation, and while providing various functions, it closely integrates the various actual needs of the college. The security performance is good. The system provides user name and password verification, which improves the security of the system. Database management is convenient and fast, providing a database-friendly management interface, and timely and accurate query. (5) This system adopts an object-oriented development method. During the development process, full consideration of the user's needs enabled the system to have powerful functions and streamlined procedures. In the end, this application software basically completed the goals required by the requirements analysis.","Web of Science, Wiley"
"Shao, Yihan; Gan, Zhengting; Epifanovsky, Evgeny; Gilbert, Andrew T. B.; Wormit, Michael; Kussmann, Joerg; Lange, Adrian W.; Behn, Andrew; Deng, Jia; Feng, Xintian; Ghosh, Debashree; Goldey, Matthew; Horn, Paul R.; Jacobson, Leif D.; Kaliman, Ilya; Khaliullin, Rustam Z.; Kus, Tomasz; Landau, Arie; Liu, Jie; Proynov, Emil I.; Rhee, Young Min; Richard, Ryan M.; Rohrdanz, Mary A.; Steele, Ryan P.; Sundstrom, Eric J.; Woodcock, H. Lee, III; Zimmerman, Paul M.; Zuev, Dmitry; Albrecht, Ben; Alguire, Ethan; Austin, Brian; Beran, Gregory J. O.; Bernard, Yves A.; Berquist, Eric; Brandhorst, Kai; Bravaya, Ksenia B.; Brown, Shawn T.; Casanova, David; Chang, Chun-Min; Chen, Yunqing; Chien, Siu Hung; Closser, Kristina D.; Crittenden, Deborah L.; Diedenhofen, Michael; DiStasio, Robert A., Jr.; Do, Hainam; Dutoi, Anthony D.; Edgar, Richard G.; Fatehi, Shervin; Fusti-Molnar, Laszlo; Ghysels, An; Golubeva-Zadorozhnaya, Anna; Gomes, Joseph; Hanson-Heine, Magnus W. D.; Harbach, Philipp H. P.; Hauser, Andreas W.; Hohenstein, Edward G.; Holden, Zachary C.; Jagau, Thomas-C.; Ji, Hyunjun; Kaduk, Benjamin; Khistyaev, Kirill; Kim, Jaehoon; Kim, Jihan; King, Rollin A.; Klunzinger, Phil; Kosenkov, Dmytro; Kowalczyk, Tim; Krauter, Caroline M.; Lao, Ka Un; Laurent, Adele D.; Lawler, Keith V.; Levchenko, Sergey V.; Lin, Ching Yeh; Liu, Fenglai; Livshits, Ester; Lochan, Rohini C.; Luenser, Arne; Manohar, Prashant; Manzer, Samuel F.; Mao, Shan-Ping; Mardirossian, Narbe; Marenich, Aleksandr V.; Maurer, Simon A.; Mayhall, Nicholas J.; Neuscamman, Eric; Oana, C. Melania; Olivares-Amaya, Roberto; O'Neill, Darragh P.; Parkhill, John A.; Perrine, Trilisa M.; Peverati, Roberto; Prociuk, Alexander; Rehn, Dirk R.; Rosta, Edina; Russ, Nicholas J.; Sharada, Shaama M.; Sharma, Sandeep; Small, David W.; Sodt, Alexander; Stein, Tamar; Stueck, David; Su, Yu-Chuan; Thom, Alex J. W.; Tsuchimochi, Takashi; Vanovschi, Vitalii; Vogt, Leslie; Vydrov, Oleg; Wang, Tao; Watson, Mark A.; Wenzel, Jan; White, Alec; Williams, Christopher F.; Yang, Jun; Yeganeh, Sina; Yost, Shane R.; You, Zhi-Qiang; Zhang, Igor Ying; Zhang, Xing; Zhao, Yan; Brooks, Bernard R.; Chan, Garnet K. L.; Chipman, Daniel M.; Cramer, Christopher J.; Goddard, William A., III; Gordon, Mark S.; Hehre, Warren J.; Klamt, Andreas; Schaefer, Henry F., III; Schmidt, Michael W.; Sherrill, C. David; Truhlar, Donald G.; Warshel, Arieh; Xu, Xin; Aspuru-Guzik, Alan; Baer, Roi; Bell, Alexis T.; Besley, Nicholas A.; Chai, Jeng-Da; Dreuw, Andreas; Dunietz, Barry D.; Furlani, Thomas R.; Gwaltney, Steven R.; Hsu, Chao-Ping; Jung, Yousung; Kong, Jing; Lambrecht, Daniel S.; Liang, WanZhen; Ochsenfeld, Christian; Rassolov, Vitaly A.; Slipchenko, Lyudmila V.; Subotnik, Joseph E.; Van Voorhis, Troy; Herbert, John M.; Krylov, Anna I.; Gill, Peter M. W.; Head-Gordon, Martin",Advances in molecular quantum chemistry contained in the Q-Chem 4 program package,2015,10.1080/00268976.2014.952696,https://doi.org/10.1080/00268976.2014.952696,Journal,MOLECULAR PHYSICS,"A summary of the technical advances that are incorporated in the fourth major release of the Q-Chem quantum chemistry program is provided, covering approximately the last seven years. These include developments in density functional theory methods and algorithms, nuclear magnetic resonance (NMR) property evaluation, coupled cluster and perturbation theories, methods for electronically excited and open-shell species, tools for treating extended environments, algorithms for walking on potential surfaces, analysis tools, energy and electron transfer modelling, parallel computing capabilities, and graphical user interfaces. In addition, a selection of example case studies that illustrate these capabilities is given. These include extensive benchmarks of the comparative accuracy of modern density functionals for bonded and non-bonded interactions, tests of attenuated second order Moller-Plesset (MP2) methods for intermolecular interactions, a variety of parallel performance benchmarks, and tests of the accuracy of implicit solvation models. Some specific chemical examples include calculations on the strongly correlated Cr-2 dimer, exploring zeolite-catalysed ethane dehydrogenation, energy decomposition analysis of a charged ter-molecular complex arising from glycerol photoionisation, and natural transition orbitals for a Frenkel exciton state in a nine-unit model of a self-assembling nanotube.",Web of Science
"Loke, T.; Wang, J. B.; Chen, Y. H.",OptQC: An optimized parallel quantum compiler,2014,10.1016/j.cpc.2014.07.022,https://doi.org/10.1016/j.cpc.2014.07.022,Journal,COMPUTER PHYSICS COMMUNICATIONS,"The software package Qcompiler (Chen and Wang 2013) provides a general quantum compilation framework, which maps any given unitary operation into a quantum circuit consisting of a sequential set of elementary quantum gates. In this paper, we present an extended software OptQC, which finds permutation matrices P and Q for a given unitary matrix U such that the number of gates in the quantum circuit of U = Q(T)P(T)U'PQ is significantly reduced, where U' is equivalent to U up to a permutation and the quantum circuit implementation of each matrix component is considered separately. We extend further this software package to make use of high-performance computers with a multiprocessor architecture using MPI. We demonstrate its effectiveness in reducing the total number of quantum gates required for various unitary operators.Program summaryProgram title: OptQCCatalogue identifier: AEUA_v1_0Program summary URL: http://cpc.cs.qub.ac.uk/summaries/AEUA_v1_0.htmlProgram obtainable from: CPC Program Library, Queen's University, Belfast, N. IrelandLicensing provisions: Standard CPC licence, http://cpc.cs.qub.ac.uk/licence/licence.htmlNo. of lines in distributed program, including test data, etc.: 178435No. of bytes in distributed program, including test data, etc.: 491574Distribution format: tar.gzProgramming language: Fortran, MPI.Computer: Any computer with Fortran compiler and MPI library.Operating system: Linux.Classification: 4.15.Nature of problem: It aims to minimize the number of quantum gates required to implement a given unitary operation.Solution method: It utilizes a threshold-based acceptance strategy for simulated annealing to select permutation matrices P and Q for a given unitary matrix U such that the number of gates in the quantum circuit of U Q= Q(T)P(T)U'PQ is minimized, where U' is equivalent to U up to a permutation. The decomposition of a unitary operator is performed by recursively applyingthe cosine-sine decomposition.Running time: Running time increases with the size of the unitary matrix, as well as the prescribed maximum number of iterations for qubit permutation selection and the subsequent simulated annealing algorithm. Running time estimates are provided for each example in Section 4. All simulation results presented in this paper are obtained from running the program on the Fornax supercomputer managed by iVEC@UWA with Intel Xeon X5650 CPUs. (C) 2014 Elsevier B.V. All rights reserved.",Web of Science
"Rodriguez-Fernandez, Roberto; Pereira, Francisco B.; Marques, Jorge M. C.; Martinez-Nunez, Emilio; Vazquez, Saulo A.","GAFit: A general-purpose, user-friendly program for fitting potential energy surfaces",2017,10.1016/j.cpc.2017.02.008,https://doi.org/10.1016/j.cpc.2017.02.008,Journal,COMPUTER PHYSICS COMMUNICATIONS,"We have developed a software package based on a genetic algorithm that fits an analytic function to a given set of data points. The code, called GAFit, was also interfaced with the CHARMM and MOPAC programs in order to facilitate force field parameterizations and fittings of specific reaction parameters (SRP) for semiempirical Hamiltonians. The present tool may be applied to a wide range of fitting problems, though it has been especially designed to significantly reduce the hard work involved in the development of potential energy surfaces for complex systems. For this purpose, it has been equipped with several programs to help the user in the preparation of the input files. We showcase the application of the computational tool to several chemical-relevant problems: force-field parameterization, with emphasis on nonbonded energy terms or intermolecular potentials, derivation of SRP for semiempirical Hamiltonians, and fittings of generic analytical functions.Program summaryProgram title: GAFitProgram Files doi: http://dx.doi.org/10.17632/9gy6bjcwk5.1Licensing provisions: GNU General Public License 3 (GPL)Programming language: Fortran 90, C, Perl and JavaNature of problem: Potential energy surfaces (PESs) have a key role in reaction dynamics and molecular dynamics. Chemical dynamics simulations can be performed by using analytical PESs or by,direct dynamics, that is, by computing energies and forces on-the-fly by molecular structure calculations. The development of analytical PESs is, quite often, a very complex and tedious task. There are several programs in the literature that may help to develop PESs but, as far as we know, none of them show, at the same time, great generality and flexibility.Solution method: GAFit was designed to help users develop analytical potential energy functions. We made special efforts to write a code that exhibits the three features mentioned above. For this reason, we have also interfaced GAFit with the CHARMM and MOPAC programs. The former is one of the popular packages for molecular dynamics and the latter is a semiempirical quantum chemistry program that may be conveniently used for direct dynamics simulations. Because, in general, the fitting of PESs involves a simultaneous optimization of many nonlinear parameters, we have selected a genetic algorithm as the driver for the parameterizations. As shown in the paper, GAFit may be applied to other fitting problems. (C) 2017 Elsevier B.V. All rights reserved.",Web of Science
"Wright, Paul; White, Catherine; Parker, Ryan C.; Pegon, Jean-Sebastien; Menchetti, Marco; Pearse, Joseph; Bahrami, Arash; Moroz, Anastasia; Wonfor, Adrian; Penty, Richard, V; Spiller, Timothy P.; Lord, Andrew",5G network slicing with QKD and quantum-safe security,2021,10.1364/JOCN.413918,https://doi.org/10.1364/JOCN.413918,Journal,JOURNAL OF OPTICAL COMMUNICATIONS AND NETWORKING,"We demonstrate how the 5G network slicing model can be enhanced to address data security requirements. In this work, we demonstrate two different slice configurations, with different encryption requirements, representing two diverse use-cases for 5G networking, namely, an enterprise application hosted at a metro network site and a content delivery network. We create a modified software-defined networking (SDN) orchestrator that calculates and provisions network slices according to the requirements, including encryption backed by quantum key distribution (QKD) and other methods. Slices are automatically provisioned by SDN orchestration of network resources, allowing selection of encrypted links as appropriate, including those that use encryption with standard Diffie-Hellman key exchange, QKD, or quantum-resistant algorithms, as well as no encryption at all. We show that the setup and teardown times of the network slices take approximately 1-2 min, which is at least an order of magnitude improvement over manually provisioning a link today. (C) 2021 Optical Society of America",Web of Science
"Moshayedi, Shiva; Shafiei, Fatemeh; Isfahani, Tahereh Momeni",QSPR models to predict quantum chemical properties of imidazole derivatives using genetic algorithm-multiple linear regression and back-propagation-artificial neural network,2022,10.1002/qua.27003,https://doi.org/10.1002/qua.27003,Journal,INTERNATIONAL JOURNAL OF QUANTUM CHEMISTRY,"Imidazole derivatives are the foundation of different types of drugs with a wide range of biological activities. In this study, the genetic algorithm-multiple linear regression (GA-MLR), and backpropagation-artificial neural network (BP-ANN) were applied to design QSPR models to predict the quantum chemical properties like the entropy (S) and enthalpy of formation ( increment H-f) of imidazole derivatives. In order to draw molecular structure of 84 derivative compounds Gauss View 05 program was used. These structures were optimized at DFT-B3LYP/6-311G* level with Gaussian09W. The Dragon software was used to calculate a set of different molecular descriptors, and the genetic algorithm procedure and backward stepwise regression were applied for the selection of descriptors. The resulting quantitative GA-MLR model of increment H-f, showed that there is good linear correlation between the selected descriptors and increment H-f of compounds. Also the results show that the BP-ANN model appeared to be superior to GA-MLR model for prediction of entropy. Different internal and external validation metrics were adopted to verify the predictive performance of QSPR models. The predictive powers of the models were found to be acceptable. Thus, these QSPR models may be useful for designing new series of imidazole derivatives and prediction of their properties.",Web of Science
"Bahrami, Samira; Shafiei, Fatemeh; Marjani, Azam; Isfahani, Tahereh Momeni",QSPR analysis to predict some quantum chemical properties of 2-phenylindol derivatives as anticancer drugs using molecular descriptor and genetic algorithm multiple linear regression,2024,10.1002/qua.27260,https://doi.org/10.1002/qua.27260,Journal,INTERNATIONAL JOURNAL OF QUANTUM CHEMISTRY,"Thermodynamic properties of molecules provide fundamental information for binding in fragment-based drug discovery programs and for understanding complex interactions. Experimental measurements of some thermodynamic properties are not always feasible. Quantum mechanical methods and group contribution methods are the major toolboxes to obtain some theoretical quantities. In drug discovery and development, computational studies can reduce the costs and risks of bringing a new medicine to market. Computational methods have been widely used to optimize promising new ligands by estimating their binding affinity to proteins using the thermodynamic ligand binding parameters (Gibbs energy, enthalpy, entropy, and heat capacity). In this article, the relationship between molecular descriptors and quantum chemical properties, such as the Gibbs free energy (Delta G kJ mol(-1)) and enthalpy of formation (Delta H-f kJ mol(-1)) of 2-phenylindole derivatives as anticancer drugs is studied. These properties were calculated at the DFT-B3LYP/6-311G (d,p) level of quantum chemistry by Gaussian 09 software. Molecular descriptors were calculated by Dragon 5.4 software, and the stepwise multiple linear regression (MLR) and the Genetic algorithm (GA) techniques were used to select the best descriptors and build QSPR models. To evaluate the predictive ability of developed quantitative structure-property relationship (QSPR) models, different internal and external validation methods were adopted. The predictive powers of the models were found to be satisfactory. The models revealed that 3D matrix-based descriptors (H3D, SEig) are useful to predict the Gibbs free energy and enthalpy of formation of the investigated compounds respectively.","Web of Science, Wiley"
"Rehfeldt, Daniel; Koch, Thorsten; Shinano, Yuji",Faster exact solution of sparse MaxCut and QUBO problems,2023,10.1007/s12532-023-00236-6,https://doi.org/10.1007/s12532-023-00236-6,Journal,MATHEMATICAL PROGRAMMING COMPUTATION,"The maximum-cut problem is one of the fundamental problems in combinatorial optimization. With the advent of quantum computers, both the maximum-cut and the equivalent quadratic unconstrained binary optimization problem have experienced much interest in recent years. This article aims to advance the state of the art in the exact solution of both problems-by using mathematical programming techniques. The main focus lies on sparse problem instances, although also dense ones can be solved. We enhance several algorithmic components such as reduction techniques and cutting-plane separation algorithms, and combine them in an exact branch-and-cut solver. Furthermore, we provide a parallel implementation. The new solver is shown to significantly outperform existing state-of-the-art software for sparse maximum-cut and quadratic unconstrained binary optimization instances. Furthermore, we improve the best known bounds for several instances from the 7th DIMACS Challenge and the QPLIB, and solve some of them (for the first time) to optimality.",Web of Science
"Wang, Youle",Near-optimal quantum kernel principal component analysis,2025,10.1088/2058-9565/ad9176,https://doi.org/10.1088/2058-9565/ad9176,Journal,QUANTUM SCIENCE AND TECHNOLOGY,"Kernel principal component analysis (kernel PCA) is a nonlinear dimensionality reduction technique that employs kernel functions to map data into a high-dimensional feature space, thereby extending the applicability of linear PCA to nonlinear data and facilitating the extraction of informative principal components. However, kernel PCA necessitates the manipulation of large-scale matrices, leading to high computational complexity and posing challenges for efficient implementation in big data environments. Quantum computing has recently been integrated with kernel methods in machine learning, enabling effective analysis of input data within intractable feature spaces. Although existing quantum kernel PCA proposals promise exponential speedups, they impose stringent requirements on quantum hardware that are challenging to fulfill. In this work, we propose a quantum algorithm for kernel PCA by establishing a connection between quantum kernel methods and block encoding, thereby diagonalizing the centralized kernel matrix on a quantum computer. The query complexity is logarithmic with respect to the size of the data vector, D, and linear with respect to the size of the dataset. An exponential speedup could be achieved when the dataset consists of a few high-dimensional vectors, wherein the dataset size is polynomial in log(D), with D being significantly large. In contrast to existing work, our algorithm enhances the efficiency of quantum kernel PCA and reduces the requirements for quantum hardware. Furthermore, we have also demonstrated that the algorithm based on block encoding matches the lower bound of query complexity, indicating that our algorithm is nearly optimal. Our research has laid down new pathways for developing quantum machine learning algorithms aimed at addressing tangible real-world problems and demonstrating quantum advantages within machine learning.",Web of Science
"Chong, Frederic T.; Franklin, Diana; Martonosi, Margaret",Programming languages and compiler design for realistic quantum hardware,2017,10.1038/nature23459,https://doi.org/10.1038/nature23459,Journal,NATURE,"Quantum computing sits at an important inflection point. For years, high-level algorithms for quantum computers have shown considerable promise, and recent advances in quantum device fabrication offer hope of utility. A gap still exists, however, between the hardware size and reliability requirements of quantum computing algorithms and the physical machines foreseen within the next ten years. To bridge this gap, quantum computers require appropriate software to translate and optimize applications (toolflows) and abstraction layers. Given the stringent resource constraints in quantum computing, information passed between layers of software and implementations will differ markedly from in classical computing. Quantum toolflows must expose more physical details between layers, so the challenge is to find abstractions that expose key details while hiding enough complexity.",Web of Science
"Ramadass, Parthasarathy; Sekar, Raja Shree; Srinivasan, Saravanan; Mathivanan, Sandeep Kumar; Shivahare, Basu Dev; Mallik, Saurav; Ahmad, Naim; Ghribi, Wade",BSDN-HMTD: A blockchain supported SDN framework for detecting DDoS attacks using deep learning method,2024,10.1016/j.eij.2024.100515,https://doi.org/10.1016/j.eij.2024.100515,Journal,EGYPTIAN INFORMATICS JOURNAL,"The surge in Distributed Denial of Service (DDoS) attacks within SDN environments demands more potent defense strategies. While Moving Target Defense (MTD) holds promise, current MTD approaches against DDoS suffer from security gaps due to overwhelming malicious traffic and static detection areas. In order to tackle these difficulties, we have implemented BSDN-HMTD, a combination of deep learning and blockchain technologies within SDN environments, as a framework. Our strategy starts by employing blockchain technology to authenticate users. We use the NTRU-based Nyberg Rueppel Digital Signature Algorithm for this purpose. This ensures that only authenticated user flows are allowed for validation and forwarding. Within the forwarding layer, Quantum Convolutional Neural Networks (QCNN) evaluate authentic flows by analyzing many characteristics, effectively differentiating between regular, malicious, and dubious flows. Utilizing an Enhanced Spotted Hyena Optimization (EHSO) method to activate switches in real-time modifies the vulnerable points of attack, so impeding attackers and simultaneously decreasing energy usage. The Forwarding Layer Organizer (FLO) oversees the detection of possible attacker surveillance activities and transmits the collected information to local controllers in the control layer. The controllers, functioning in a structured controller network, carry out proactive Moving Target Defense (MTD) techniques, such as host virtual IP hopping, which make attacker plans more complex and raise their operational expenses. Reactive MTD actions are implemented based on the results of flow validation. These actions utilize techniques such as secure honeypots and host virtual IP hopping to effectively prevent attacks. The blockchain securely logs all processed data related to packet validation, authentication, and honeypot activities to ensure the protection of data privacy. Our studies, conducted using Network Simulator-3.26 (NS-3.26), show that our proposed framework outperforms existing techniques in terms of several validation criteria.",Web of Science
"Ning, Tao; Jin, Hua; Song, Xudong; Li, Bo",An improved quantum genetic algorithm based on MAGTD for dynamic FJSP,2018,10.1007/s12652-017-0486-4,https://doi.org/10.1007/s12652-017-0486-4,Journal,JOURNAL OF AMBIENT INTELLIGENCE AND HUMANIZED COMPUTING,"For the purpose of solving the dynamic flexible job-shop scheduling problem, this paper establishes the mathematical model to minimize the makespan and stability value, an improved double chains quantum genetic algorithm was proposed. Firstly, it is proposed that the method of double chains structure coding including machine allocation chain and process chain. Secondly, it is proposed that non- dominated sorting based on the crowding distance selection strategy. Thirdly, the most satisfying solution is obtained through the multi-attribute grey target decision model. Finally, the novel method is applied to the Brandimarte example and a dynamic simulation, the result of comparing with other classical algorithms verifies its effectiveness.",Web of Science
"Sim, Minjoo; Lee, Minwoo; Seo, Hwajeong",HAETAE on ARMv8,2024,10.3390/electronics13193863,https://doi.org/10.3390/electronics13193863,Journal,ELECTRONICS,"In this work, we present the highly optimized implementation of the HAETAE algorithm, submitted to the second round of the Korean Post-Quantum Cryptography (KpqC) competition and to the first round of NIST's additional post-quantum standardization for digital signatures on 64-bit ARMv8 embedded processors. To the best of our knowledge, this is the first optimized implementation of the HAETAE algorithm on 64-bit ARMv8 embedded processors. We apply various optimization techniques to enhance the multiplication operations in the HAETAE algorithm. We utilize parallel operation techniques involving vector registers and NEON (Advanced SIMD technology used in ARM processors) instructions of ARMv8 embedded processors. In particular, we achieved the best performance of the HAETAE algorithm on ARMv8 embedded processors by applying all the state-of-the-art NTT (Number Theoretic Transform) implementation techniques. Performance improvements of up to 3.07x, 3.63x, and 9.15x were confirmed for NTT, Inverse-NTT, and pointwise Montgomery operations (Montgomery multiplication used in modular arithmetic), respectively, by applying the state-of-the-art implementation techniques, including the proposed techniques. As a result, we achieved a maximum performance improvement of up to 1.16x for the key generation algorithm, up to 1.14x for the signature algorithm, and up to 1.25x for the verification algorithm.",Web of Science
"Sarkar, Kanchan; Holzwarth, N. A. W.; Wentzcovitch, R. M.",EPAW-1.0 code for evolutionary optimization of PAW datasets especially for high-pressure applications,2018,10.1016/j.cpc.2018.05.019,https://doi.org/10.1016/j.cpc.2018.05.019,Journal,COMPUTER PHYSICS COMMUNICATIONS,"We present a bio-inspired stochastic optimization strategy that optimizes projector augmented wave (PAW) datasets, for a user-specified pressure range, to realize the highest possible accuracy in high-throughput density functional theory calculations within the framework of PAW method. We named the optimizer Evolutionary Generator of projector augmented wave datasets (EPAW-1.0). The self-learning evolutionary algorithms in EPAW-1.0 adaptively tune some of the PAW parameters (such as different radii, and reference energies) to generate evolutionary optimized PAW (EPAW) datasets. In the course of designing EPAW dataset with a specific pseudo partial waves and projectors generation scheme, the code keeps the user-specified electronic configuration unaltered and the augmentation radius (r(c)) on the verge of the user allowed maximum without resulting in sphere overlap. The EPAW-1.0 algorithm homes on to a soft, transferable and unified EPAW dataset using various measures including the equation of state (EoS) of standard elemental materials within a user-specified pressure range that allows probing similar to 50% volume compression with respect to the equilibrium atomic volume (corresponding to the energy minimum). The measures used by the EPAW algorithm also can be used to balance the efficiency and accuracy of the dataset.Program Title: EPAW-1.0Program Files doi : http://dx.doi.org/10.17632/ms52ym7vcn.1Licensing provisions: GNU General Public License 3 (GPLv3)Programming languages: Fortran90, Fortran77, Python3.0, bash shell, gnuplot5.0.External routines/libraries: ATOMPAW, Quantum ESPRESSO, related linear algebra package.Nature of problem: EPAW-1.0 is a hybrid recipe [2] that documents an interdisciplinary research integrating evolutionary computing with density functional theory (DFT). It offers a partially automated and consistent route to generate evolutionary optimized PAW (EPAW) datasets that show uniform performance for simulations up to a predefined high pressure. In particular, EPAW-1.0 makes use of evolutionary algorithms [3-7], PAW dataset generator (ATOMPAW [8], for example) and electronics-tructure calculation code (Quantum Espresso [9], for example) to generate efficient and transferable EPAW datasets. EPAW datasets provide optimal accuracy in solid-state ab initio calculations within the favorable PAW computational framework - very close to the precision of targeted all-electron full potential linearized Augmented-plane-wave (AE-FLAPW) approach. We set the EoS from WIEN2k [1] calculations as our target, but any reliable EoS can be in use. The better the target EoS, the better is the performance of the EPAW datasets. Similarly, electronic-structure calculation code and PAW dataset generator code can also be replaced.Solution Method: The implementation has two parts: a. Generating a diverse random initial population for EPAW-1.0 to start with; b. Generating EPAW dataset using EPAW-1.0.A hybrid method, combining an in-house evolutionary strategy named Completely Adaptive Random Mutation Hill Climbing [6] (CARMHC) with ATOMPAW [8] program, quickly optimizes a set (population) of n oon solutions (PAW dataset descriptors) from which the iterative process of EPAW-1.0 starts. The optimization condition involves superimposing the logarithmic derivative curves of the all-electron and pseudo radial wave functions, simultaneously satisfying necessary constraints on logarithmic derivatives, partial waves, pseudo partial waves and projector basis sets [2,8,10-12]. To start with, the method generates a diverse initial population of n(pop) solution vector (n(pop) = cardinality of the GA's population in EPAW-1.0) randomly in the neighborhood of the initial educated guess based on problem-specific knowledge from the ATOMPAW program and iteratively tunes the population to minimize the area under the logarithmic derivative curves.Once n(pop) number of solution strings have been optimized, n pop individuals are feed into the EPAW1.0's initial population. Equilibrium total energies are evaluated using Quantum Espresso distribution [9] and fitted to a finite strain expansion. Pressures are calculated using a 4-parameter Birch-Murnaghan fit [13,14 EPAW-1.0 employs genetic algorithms (GAs) [15-19] as the evolutionary procedure and iteratively tunes the free parameters of the PAW dataset generator to minimize the difference in equation of states (EoS) with respect to the given target EoS for the specified pressure range.Additional comments: EPAW-1.0 is an evolutionary procedure blended with external density functional theory (DFT) formalism (as implemented in ATOMPAW and Quantum Espresso, for example). The ATOMPAW code generates dataset by a self-consistent all-electron atomic structure calculation within the framework of DFT. The projector and basis functions are derived from the eigenstates of the all-electron atomic Hamiltonian. They are determined by iteratively solving radial differential equations. Equilibrium total energies at some equidistant volume points for a specific elemental crystal are evaluated using Quantum Espresso distribution [9]. The EPAW-1.0 program conserves different constraints [2] on logarithmic derivatives and basis sets to avoid numerical instability, ghost states, and to promote an excellent transferability. More details about the constraints can be found in the methodology part of reference 1. It also provides a goodness measure of the generated dataset concerning the targeted results. (C) 2018 Elsevier B.V. All rights reserved.",Web of Science
"Jain, Richa; Sharma, Neelam",A quantum inspired hybrid SSA-GWO algorithm for SLA based task scheduling to improve QoS parameter in cloud computing,2023,10.1007/s10586-022-03740-x,https://doi.org/10.1007/s10586-022-03740-x,Journal,CLUSTER COMPUTING-THE JOURNAL OF NETWORKS SOFTWARE TOOLS AND APPLICATIONS,"Software as a service (SaaS) provider hires resources from an Infrastructure as a Service (IaaS) provider and provides these sharable resources to user's applications on lease. However, it is becoming a more challenging issue for SaaS providers to meet user's Quality of Service (QoS) Parameter and maximize profit from cloud infrastructure. This proposed work satisfies both the user and the service provider by fulfilling service level agreement (SLA), user's QoS requirement, and increasing profit with efficient resources utilization. This paper proposes an Improved Quantum Salp Swarm Algorithm (IQSSA), which improves the Salp Swarm algorithm by incorporating the principles of Quantum computing to increase the convergence rate. Further, Quantum-inspired Salp Swarm Grey Wolf Algorithm (QSSGWA) embeds SSA with Grey Wolf Optimizer (GWO) to improve the global optimum solution, and quantum operator is used to initializing population. Proposed algorithms execute tasks under the user-defined deadline and budget constraints. Furthermore, the penalty cost is formulated and applied in the case of a deadline violation. IQSSA and QSSGWA are tested on 19 global benchmark functions, and results prove their superior performance compared to SSA, GWO, BAT, and Particle Swarm Optimization (PSO) algorithm. Furthermore, these algorithms are simulated on CloudSim, and performance matrices such as service provider's profit, makespan, SLA violation rate, task rejection rate, throughput, resource utilization, and response time are compared. The comparison analysis demonstrates that the proposed algorithms offer better performance and more efficient scheduling than existing metaheuristics. Furthermore, simulation results clearly show that QSSGWA gives the best results for all performance matrices. This proposed approach can be applied in many scientific domains, where distributed processing of data or large scale data analysis is required such as distributed and federated machine learning, serverless computing, medical applications, etc.",Web of Science
"Deng, Lijuan; Wan, Long; Guo, Jian",Research on Security Anomaly Detection for Big Data Platforms Based on Quantum Optimization Clustering,2022,10.1155/2022/4805035,https://doi.org/10.1155/2022/4805035,Journal,MATHEMATICAL PROBLEMS IN ENGINEERING,"Due to the explosive growth of data in the Internet, more and more applications are being deployed on Big Data platforms. However, as the scale of data continues to increase, the probability of anomalies in the platform is also increasing. However, traditional anomaly detection techniques cannot effectively handle the massive amount of historical data and can hardly meet the security requirements of big data platforms. In order to solve the above problems, this paper proposes a security anomaly detection method for big data platforms based on quantum optimization clustering. Firstly, a framework of big data platform anomaly detection system is designed based on distributed software architecture through Hadoop and Spark big data open source technology. The system achieves effective detection of network anomalies by collecting and analyzing big data platform server log data. Secondly, an offline anomaly detection algorithm based on quantum ant colony optimized affinity propagation clustering is designed for various anomalies mined from historical data. The bias parameters of the affinity propagation clustering are treated as individual ants to construct an ant colony, and the clustering accuracy is set as fitness. Finally, in order to improve the accuracy of the optimal path search of the ant colony, quantum bit encoding is applied to the ant colony position to refine the granularity of the individual ant colony position update. The experimental results show that the proposed method can effectively complete the anomaly clustering detection of massive data. With a reasonable threshold, the quantum ant colony-based affinity propagation clustering has high detection accuracy.","Web of Science, Wiley"
"You, Qi; Li, Chao; Sun, Jun; Palade, Vasile; Pan, Feng",Entropy-based lamarckian quantum-behaved particle swarm optimization for flexible ligand docking,2023,10.1002/minf.202200080,https://doi.org/10.1002/minf.202200080,Journal,MOLECULAR INFORMATICS,"AutoDock is a widely used software for flexible ligand docking problems since it is open source and easy to be implemented. In this paper, a novel hybrid algorithm is proposed and applied in the docking environment of AutoDock version 4.2.6 in order to enhance the accuracy and the efficiency for dockings with flexible ligands. This search algorithm, called entropy-based Lamarckian quantum-behaved particle swarm optimization (ELQPSO), is a combination of the QPSO with an entropy-based update strategy and the Solis and Wet local search (SWLS) method. By using the PDBbind core set v.2016, the ELQPSO is compared with the Lamarckian genetic algorithm (LGA), Lamarckian particle swarm optimization (LPSO) and Lamarckian QPSO (LQPSO). The experimental results reveal that the corresponding docking program of ELQPSO, named as EQDOCK in this paper, has a competitive performance in dealing with the protein-ligand docking problems. Moreover, for the test cases with different number of torsions, the EQDOCK outperforms the other three docking programs in finding docking conformations with small root mean squared deviation (RMSD) values in most cases. In particular, it has an advantage of solving highly flexible ligand docking problems over the others.","Web of Science, Wiley"
"Shirmohammadi, Meysam; Mohammadinasab, Esmat; Bayat, Zakiyeh",Modeling Physico-Chemical Properties of Quinolonc Derivatives Using GA-MLR as a Computational Study,2020,10.2174/1573409915666191212152439,https://doi.org/10.2174/1573409915666191212152439,Journal,CURRENT COMPUTER-AIDED DRUG DESIGN,"Background: In this study, we used a hierarchical approach to develop quantitative structure-activity relationship (QSAR) models for modeling physico-chemical properties of quinolone derivatives.Objective: The relationship between some of the molecular descriptors with physic-chemical properties such as refractive index (n), polarizability (alpha) and HOMO-LUMO energy gap (Delta EH-L) was represented.Materials and Methods: Quantum mechanical calculations using abinitio method at the #HF/6-31++G** level were carried out to obtain the optimized geometry and then, the comprehensive set of molecular descriptors was computed by using the Dragon software. Genetic algorithm using multiple linear regression (GA-MLR) with backward method by SPSS software were utilized to construct QSAR models.Results: The analytical powers of the established theoretical models were discussed using leave-one-out (LOO) cross-validation technique. A multi-parametric equation containing maximum three descriptors with suitable statistical qualities was obtained for predicting the studied properties.Conclusion: The QSPR analysis for the prediction of the refractive index, the polarizability and the HOMO-LUMO energy gap of 40 quinolone derivatives using GA-MLR method was performed. The achieved results showed that the best model for predicting the refractive index, the polarizability and the HOMO-LUMO energy gap contains maximum three descriptors. MLR analysis, using genetic algorithms as suitable descriptors selection method showed that the three selected descriptors play a vital role in the prediction of physicochemical properties of quinolone derivatives. It can be noted that the best descriptors in the final obtained models can be used to design and screen new drugs.",Web of Science
"Baniata, Hamza",SoK: quantum computing methods for machine learning optimization,2024,10.1007/s42484-024-00180-1,https://doi.org/10.1007/s42484-024-00180-1,Journal,QUANTUM MACHINE INTELLIGENCE,"Hyperparameter optimization (HPO) and neural architecture search (NAS) of machine learning (ML) models are in the core implementation steps of AI-enabled systems. With multi-objective and multi-level optimization of complex ML models, it is agreed-on that HPO and NAS are NP-hard problems. That is, the size of the search space grows exponentially with the number of hyperparameters, possible architecture elements, and configurations. In 2017, the first proposal of QC-enabled HPO and NAS optimization was proposed. Simultaneously, advancements related to quantum neural networks (QNNs) resulted in more powerful ML due to their deployment on QC infrastructure. For such, quantum architecture search (QAS) problem arose as a similar problem, aiming to achieve optimal configuration of quantum circuits. Although classical approaches to solve these problems were thoroughly studied in the literature, a systematic overview that summarizes quantum-based methods is still missing. Our work addresses this gap and provides the first Systemization of Knowledge (SoK) to differentiate, and bridge the gap between the utilization of QC for optimizing ML rather than learning. Specifically, we provide qualitative and empirical analysis of related works, and we classify the properties of QC-based HPO, NAS, and QAS optimization systems. Additionally, we present a taxonomy of studied works, and identify four main types of quantum methods used to address the aforementioned problems. Finally, we set the agenda for this new field by identifying promising directions and open issues for future research.",Web of Science
"Sim, Minjoo; Eum, Siwoo; Song, Gyeongju; Yang, Yujin; Kim, Wonwoong; Seo, Hwajeong",K-XMSS and K-SPHINCS+: Enhancing Security in Next-Generation Mobile Communication and Internet Systems with Hash Based Signatures Using Korean Cryptography Algorithms,2023,10.3390/s23177558,https://doi.org/10.3390/s23177558,Journal,SENSORS,"As Mobile Communication and Internet Systems (MCIS) have rapidly developed, security issues related to MCIS have become increasingly important. Therefore, the development and research of security technologies for mobile communication and internet systems are actively being conducted. Hash-Based Signature (HBS) uses a hash function to construct a digital signature scheme, where its security is guaranteed by the collision resistance of the hash function used. To provide sufficient security in the post-quantum environment, the length of hash should be satisfied for the security requirement. Modern HBS can be classified into stateful and stateless schemes. Two representative stateful and stateless HBS are eXtended Merkle Signature Scheme(XMSS) and SPHINCS+, respectively. In this paper, we propose two HBS schemes: K-XMSS and K-SPHINCS+, which replace internal hash functions of XMSS and SPHINCS+ with Korean cryptography algorithms. K-XMSS is a stateful signature, while K-SPHINCS+ is its stateless counterpart. We showcase the reference implementation of K-XMSS and K-SPHINCS+ employing Lightweight Secure Hash (LSH) and two hash functions based on block ciphers (i.e., CHAM and LEA) as the internal hash function. In addition, K-XMSS and K-SPHINCS+ using Advanced Vector Extensions 2 (AVX2) have been provided, demonstrating that they can be optimized for better performance using advanced implementation techniques than previous approaches.",Web of Science
"Chen, Xin; Wang, Li-Fang; Gao, Xing-Yu; Zhao, Ya-Fan; Lin, De-Ye; Chu, Wei-Dong; Song, Hai-Feng",Machine learning enhanced empirical potentials for metals and alloys,2021,10.1016/j.cpc.2021.108132,https://doi.org/10.1016/j.cpc.2021.108132,Journal,COMPUTER PHYSICS COMMUNICATIONS,"Interatomic potential (i.e. force-field) plays a vital role in atomistic simulation of materials. Empirical potentials like the embedded atom method (EAM) and its variant angular-dependent potential (ADP) have proven successful in many metals. In the past few years, machine learning has become a compelling approach for modeling interatomic interactions. Powered by big data and efficient optimizers, machine learning interatomic potentials can generally approximate to the accuracy of the first-principles calculations based on the quantum mechanics theory. In this works, we successfully developed a route to express EAM and ADP within machine learning framework in highly-vectorizable form and further incorporated several physical constraints into the training. As it is proved in this work, the performances of empirical potentials can be significantly boosted with few training data. For energy and force predictions, machine tuned EAM and ADP, can be almost as accurate as the computationally expensive spectral neighbor analysis potential (SNAP) on the fcc Ni, bcc Mo and Mo-Ni alloy systems. Machine learned EAM and ADP can also reproduce some key materials properties, such as elastic constants, melting temperatures and surface energies, close to the first-principles accuracy. Our results suggest a new and systematic route for developing machine learning interatomic potentials. All the new algorithms have been implemented in our program TensorAlloy.Program summaryProgram Title: TensorAlloyCPC Library link to program files: https://doi.org/10.17632/w8htd7vmwh.2Code Ocean capsule: https://codeocean.com/capsule/1671487Licensing provisions: LGPLProgramming language: Python 3.7Journal reference of previous version: Comput. Phys. Commun. 250 (2020) 107057, https://doi.org/10.1016/j.cpc.2019.107057Does the new version supersede the previous version?: YesReasons for the new version: This new version is a significant extension to the previous version. Now machine learning approaches and physical constraints can be used together to tune empirical potentials (for example the embedded atom method). Machine learning optimized empirical potentials can be almost as accurate as machine learning interaction potentials but run much faster.Nature of problem: Optimizing empirical potentials with machine learning approaches and physical constraints.Solution method: The TensorAlloy program is built upon TensorFlow and the virtual-atom approach. We successfully developed a route to express the embedded atom method and the angular-dependent potential within machine learning framework in highly-vectorizable form and further enhanced the potentials with physical constraints. Machine learning can significantly boost their performances with few training data.Additional comments including restrictions and unusual features: This program needs TensorFlow 1.14.*. Neither newer or older TensorFlow is supported. (C) 2021 Elsevier B.V. All rights reserved.",Web of Science
"Markidis, Stefano",Programming Quantum Neural Networks on NISQ Systems: An Overview of Technologies and Methodologies,2023,10.3390/e25040694,https://doi.org/10.3390/e25040694,Journal,ENTROPY,"Noisy Intermediate-Scale Quantum (NISQ) systems and associated programming interfaces make it possible to explore and investigate the design and development of quantum computing techniques for Machine Learning (ML) applications. Among the most recent quantum ML approaches, Quantum Neural Networks (QNN) emerged as an important tool for data analysis. With the QNN advent, higher-level programming interfaces for QNN have been developed. In this paper, we survey the current state-of-the-art high-level programming approaches for QNN development. We discuss target architectures, critical QNN algorithmic components, such as the hybrid workflow of Quantum Annealers and Parametrized Quantum Circuits, QNN architectures, optimizers, gradient calculations, and applications. Finally, we overview the existing programming QNN frameworks, their software architecture, and associated quantum simulators.",Web of Science
"Wu, Weizu; Xie, Dongqing; Liu, Liqun",Heterogeneous Differential Evolution with Memory Enhanced Brownian and Quantum Individuals for Dynamic Optimization Problems,2018,10.1142/S0218001418590036,https://doi.org/10.1142/S0218001418590036,Journal,INTERNATIONAL JOURNAL OF PATTERN RECOGNITION AND ARTIFICIAL INTELLIGENCE,"In order to solve the dynamic optimization problem (DOP), this paper proposes to use a heterogeneous differential evolution (HDE) algorithm framework with memory enhanced Brownian and quantum (MEBQ) individual scheme. The proposed HDE/MEBQ algorithm has the following two advantages when solving DOP. First and foremost, the HDE optimization framework can satisfy the problem requirement of different characteristics. DOP is actually a continuous process to solve different kinds of optimization problems to meet new requirements when the search environmental change occurs. Therefore, HDE/MEBQ is able to fastly respond to the environmental changes of DOP as the HDE framework uses multiple populations with heterogeneous parameters and operators to meet different search requirements in various search environments. Secondly, according to the phenomenon that most of the environmental changes may not be too drastic in real-world applications, historical information in the past may be useful for finding the optimum solution in the new environment. Thus, the MEBQ scheme used in HDE/MEBQ provides helpful historical evolutionary information from the elite ancestors for guiding individuals to evolve in a new environment strongly and to obtain faster convergence and a more precise solution. We evaluated HDE/MEBQ on several DOPs from CEC 2009 and compared with several state-of-the-art dynamic evolutionary algorithms. The results show that HDE/MEBQ performs superior in statistics and gets very competitive results in most of the test conditions, especially in complex DOPs.",Web of Science
"Omar, Karwan A.; Korsaye, Feven A.; Tandiana, Rika; Tolu, Damien; Deviers, Jean; Wu, Xiaojing; Parise, Angela; Alvarez-Ibarra, Aurelio; Moncada, Felix; Pedroza-Montero, Jesus Nain; Mejia-Rodriguez, Daniel; Van-Oanh, Nguyen-Thi; Cailliez, Fabien; Clavaguera, Carine; Hasnaoui, Karim; de la Lande, Aurelien",Current status of deMon2k for the investigation of the early stages of matter irradiation by time-dependent DFT approaches,2023,10.1140/epjs/s11734-023-00905-6,https://doi.org/10.1140/epjs/s11734-023-00905-6,Journal,EUROPEAN PHYSICAL JOURNAL-SPECIAL TOPICS,"We summarize in this article the recent progress made in our laboratories in the development of numerical approaches dedicated to investigating ultrafast physicochemical responses of biological matter subjected to ionizing radiations. Our modules are integrated into the deMon2k software which is a readily available program with highly optimized algorithms for conducting Auxiliary Density Functional Theory (ADFT) calculations. We have developed a computational framework based on Real-Time Time-dependent ADFT to simulate the electronic responses of molecular systems to strong perturbations, while molecular dynamics simulations in the ground and excited states (Ehrenfest dynamics) are available to simulate irradiation-induced ultrafast bond breaking/formation. Constrained ADFT and Multi-component ADFT have also been incorporated to simulate charge transfer processes and nuclear quantum effects, respectively. Finally, a coupling to polarizable force fields further permits to realistically account for the electrostatic effects that the systems' environment has on the perturbed electron density. The code runs on CPU or hybrid CPU/GPU architectures affording simulations of systems comprised up to 1000 atoms at the DFT level with controlled numerical accuracy. We illustrate the applications of these methodologies by taking results from our recent articles that aimed principally at understanding experimental data from pulse radiolysis experiments.",Web of Science
"Yu, Wenbin; Xiong, Zijia; Liu, Yang; Rong, Shanshan; Wang, Siyao; Xu, Yinsong; Liu, Alex X.",Zero-error channel capacity of quantum 5-symbol obfuscation model,2020,10.1504/IJES.2020.110646,https://doi.org/10.1504/IJES.2020.110646,Journal,INTERNATIONAL JOURNAL OF EMBEDDED SYSTEMS,"The existing noise channel coding methods need to be optimised in terms of channel capacity and algorithm complexity. Based on the characteristics of the quantum 5-symbol confusion-channel model and the theory of matrices, a coding method is proposed which combines the 5-symbol confusion channel with the quantum-superposition-state coding. This coding method uses two isomorphism steps to obtain the zero-error code words, which are the isomorphism between quantum superposition states and vectors and the isomorphism between channels and matrices. The theoretical derivation proves that the channel capacity is able to increase by employing quantum zero-error coding other than its classical counterpart.",Web of Science
"Voronych, Oksana; Buraczewski, Adam; Matuszewski, Michal; Stobinska, Magdalena",Numerical modeling of exciton-polariton Bose-Einstein condensate in a microcavity,2017,10.1016/j.cpc.2017.02.021,https://doi.org/10.1016/j.cpc.2017.02.021,Journal,COMPUTER PHYSICS COMMUNICATIONS,"A novel, optimized numerical method of modeling of an exciton polariton superfluid in a semiconductor microcavity was proposed. Exciton polaritons are spin-carrying quasiparticles formed from photons strongly coupled to excitons. They possess unique properties, interesting from the point of view of fundamental research as well as numerous potential applications. However, their numerical modeling is challenging due to the structure of nonlinear differential equations describing their evolution. In this paper, we propose to solve the equations with a modified Runge Kutta method of 4th order, further optimized for efficient computations. The algorithms were implemented in form of C++ programs fitted for parallel environments and utilizing vector instructions. The programs form the EPCGP suite which has been used for theoretical investigation of exciton polaritons.Program summaryProgram title: EPCGP Catalogue identifier: AFBQ_v1_0Program summary URL: http://cpc.cs.qub.ac.uk/summaries/AFBQ_v1_0.htmlProgram obtainable from: CPC Program Library, Queen's University, Belfast, N. IrelandLicensing provisions: BSD-3No. of lines in distributed program, including test data, etc.: 2157No. of bytes in distributed program, including test data, etc.: 498994Distribution format: tar.gzProgramming language: C++ with OpenMP extensions (main numerical program), Python (helper scripts).Computer: Modern PC (tested on AMD and Intel processors), HP BL2x220.Operating system: Unix/Linux and Windows.Has the code been vectorized or parallelized?: Yes (OpenMP)RAM: 200 MB for single runClassification: 7, 7.7.Nature of problem: An exciton polariton superfluid is a novel, interesting physical system allowing investigation of high temperature Bose Einstein condensation of exciton polaritons-quasiparticles carrying spin. They have brought a lot of attention due to their unique properties and potential applications in polariton-based optoelectronic integrated circuits. This is an out-of-equilibrium quantum system confined within a semiconductor microcavity. It is described by a set of nonlinear differential equations similar in spirit to the Gross Pitaevskii (GP) equation, but their unique properties do not allow standard GP solving frameworks to be utilized. Finding an accurate and efficient numerical algorithm as well as development of optimized numerical software is necessary for effective theoretical investigation of exciton-polaritons.Solution method: A Runge Kutta method of 4th order was employed to solve the set of differential equations describing exciton-polariton superfluids. The method was fitted for the exciton polariton equations and further optimized. The C++ programs utilize OpenMP extensions and vector operations in order to fully utilize the computer hardware.Running time: 6h for 100 ps evolution, depending on the values of parameters (C) 2017 Elsevier B.V. All rights reserved.",Web of Science
"Perrier, Elija; Youssry, Akram; Ferrie, Chris","QDataSet, quantum datasets for machine learning",2022,10.1038/s41597-022-01639-1,https://doi.org/10.1038/s41597-022-01639-1,Journal,SCIENTIFIC DATA,"The availability of large-scale datasets on which to train, benchmark and test algorithms has been central to the rapid development of machine learning as a discipline. Despite considerable advancements, the field of quantum machine learning has thus far lacked a set of comprehensive large-scale datasets upon which to benchmark the development of algorithms for use in applied and theoretical quantum settings. In this paper, we introduce such a dataset, the QDataSet, a quantum dataset designed specifically to facilitate the training and development of quantum machine learning algorithms. The QDataSet comprises 52 high-quality publicly available datasets derived from simulations of one- and two-qubit systems evolving in the presence and/or absence of noise. The datasets are structured to provide a wealth of information to enable machine learning practitioners to use the QDataSet to solve problems in applied quantum computation, such as quantum control, quantum spectroscopy and tomography. Accompanying the datasets on the associated GitHub repository are a set of workbooks demonstrating the use of the QDataSet in a range of optimisation contexts.",Web of Science
"Bonny, Talal; Haq, A.",Emulation of high-performance correlation-based quantum clustering algorithm for two-dimensional data on FPGA,2020,10.1007/s11128-020-02683-9,https://doi.org/10.1007/s11128-020-02683-9,Journal,QUANTUM INFORMATION PROCESSING,"Clustering algorithms are used to classify the unlabeled data into a number of categories with polynomial time complexity. Quantum clustering algorithms are developed to improve the performance and to achieve higher gain. In this work, we implement the quantum k-means clustering algorithm on field-programmable gate array (FPGA) by exploiting the implicit parallelism of the FPGA technology to achieve high speed among the software-implemented recent proposals. To do that, we establish a new method to measure the inner product between two qubits which is based on the correlation between the Euclidean distance and the inner product. We also optimize the quantum gates in terms of speed and removing the discretization error. Experimental results show a reduction in the running time by 500x as compared to the classical k-means algorithm for the A1 standard dataset.",Web of Science
"Ning, Tao; Huang, Ming; Liang, Xu; Jin, Hua",A novel dynamic scheduling strategy for solving flexible job-shop problems,2016,10.1007/s12652-016-0370-7,https://doi.org/10.1007/s12652-016-0370-7,Journal,JOURNAL OF AMBIENT INTELLIGENCE AND HUMANIZED COMPUTING,"A simulation model was established, minimizing the makespan and stability value, to solve the dynamic scheduling of flexible job-shop problems, and an improved hybrid multi-phase quantum particle swarm algorithm is proposed. Firstly, a double chain structure coding method, including a machine allocation chain and a process chain, is proposed. Secondly, a dynamic periodic and event-driven scheduling strategy is proposed. Finally, the novel method is applied to the Brandimarte set and a dynamic simulation is performed. Comparing the results with the results of existing algorithms demonstrates the effectiveness of the proposed hybrid multi-phase quantum particle swarm optimization algorithm and strategy for solving the dynamic scheduling of flexible job-shop problems.",Web of Science
"Zhou, Xiangzhen; Feng, Yuan; Li, Sanjiang",Supervised Learning Enhanced Quantum Circuit Transformation,2023,10.1109/TCAD.2022.3179223,https://doi.org/10.1109/TCAD.2022.3179223,Journal,IEEE TRANSACTIONS ON COMPUTER-AIDED DESIGN OF INTEGRATED CIRCUITS AND SYSTEMS,"A quantum circuit transformation (QCT) is required when executing a quantum program in a real quantum processing unit (QPU). By inserting auxiliary SWAP gates, a QCT algorithm transforms a quantum circuit to one that satisfies the connectivity constraint imposed by the QPU. Due to the nonnegligible gate error and the limited qubit coherence time of the QPU, QCT algorithms that minimize gate number or circuit depth or maximize the fidelity of output circuits are in urgent need. Unfortunately, finding optimized transformations often involve exhaustive searches, which are extremely time consuming and not practical for most circuits. In this article, we propose a framework that uses a policy artificial neural network (ANN) trained by supervised learning on shallow circuits to help existing QCT algorithms select the most promising SWAP gate. ANNs can be trained offline in a distributed way and the trained ANN can be easily incorporated into QCT algorithms to enable them to search deeper without bringing too much overhead in time complexity. Exemplary embeddings of the trained ANNs into target QCT algorithms demonstrate that the transformation performance can be consistently improved on QPUs with various connectivity structures and random or realistic quantum circuits.",Web of Science
"Jung, Jihye; Choi, In-Chan",A multi-commodity network model for optimal quantum reversible circuit synthesis,2021,10.1371/journal.pone.0253140,https://doi.org/10.1371/journal.pone.0253140,Journal,PLOS ONE,"Quantum computing is a newly emerging computing environment that has recently attracted intense research interest in improving the output fidelity, fully utilizing its high computing power from both hardware and software perspectives. In particular, several attempts have been made to reduce the errors in quantum computing algorithms through the efficient synthesis of quantum circuits. In this study, we present an application of an optimization model for synthesizing quantum circuits with minimum implementation costs to lower the error rates by forming a simpler circuit. Our model has a unique structure that combines the arc-subset selection problem with a conventional multi-commodity network flow model. The model targets the circuit synthesis with multiple control Toffoli gates to implement Boolean reversible functions that are often used as a key component in many quantum algorithms. Compared to previous studies, the proposed model has a unifying yet straightforward structure for exploiting the operational characteristics of quantum gates. Our computational experiment shows the potential of the proposed model, obtaining quantum circuits with significantly lower quantum costs compared to prior studies. The proposed model is also applicable to various other fields where reversible logic is utilized, such as low-power computing, fault-tolerant designs, and DNA computing. In addition, our model can be applied to network-based problems, such as logistics distribution and time-stage network problems.",Web of Science
"Gerlach, Marvin; Herren, Florian; Lang, Martin","tapir: A tool for topologies, amplitudes, partial fraction decomposition and input for reductions",2023,10.1016/j.cpc.2022.108544,https://doi.org/10.1016/j.cpc.2022.108544,Journal,COMPUTER PHYSICS COMMUNICATIONS,"The demand for precision predictions in the field of high energy physics has dramatically increased over recent years. Experiments conducted at the LHC, as well as precision measurements at the intensity frontier such as Belle II require equally precise theoretical predictions to make full use of the acquired data. To match the experimental precision, second-, third-and, for certain quantities, even higher-order calculations in perturbative quantum field theory are required. To facilitate such calculations, computer software automating as many steps as possible is required. Yet, each calculation poses different challenges and thus, a high level of configurability is required. In this context we present tapir: a tool for identification, manipulation and minimization of Feynman integral families. It is designed to integrate in toolchains based on the computer algebra system FORM, the use of which is common practice in the field. tapir can be used to reduce the complexity of multi-loop problems with cut-filters, topology mapping, partial fraction decomposition and alike.Program summaryProgram Title: tapirCPC Library link to program files: https://doi.org/10.17632/ptc9t46xyn.1Developer's repository link: https://gitlab.com /tapir-devs/tapirLicensing provisions:GPLv3Programming language: python 3, C++Nature of problem: Multi-loop computations require the automatization of a large number of different tasks related to Feynman integral topologies. Among them are the identification and minimization of integral topologies, partial fraction decomposition of topologies in the case of linearly dependent propagators as well as mapping scalar products of loop momenta to scalar functions.Solution method: The minimization of topologies is performed by comparison of their respective Nickel indices [1], even further minimization utilizes Pak's algorithm [2]. To efficiently map scalar products of loop momenta to scalar functions FORM [3] code is generated.Additional comments including restrictions and unusual features: Minimization based on Pak's algorithm slows down for many lines and scales. A coarser minimization using the Nickel indices, however, is still possible.",Web of Science
"Bayerstadler, Andreas; Becquin, Guillaume; Binder, Julia; Botter, Thierry; Ehm, Hans; Ehmer, Thomas; Erdmann, Marvin; Gaus, Norbert; Harbach, Philipp; Hess, Maximilian; Klepsch, Johannes; Leib, Martin; Luber, Sebastian; Luckow, Andre; Mansky, Maximilian; Mauerer, Wolfgang; Neukart, Florian; Niedermeier, Christoph; Palackal, Lilly; Pfeiffer, Ruben; Polenz, Carsten; Sepulveda, Johanna; Sievers, Tammo; Standen, Brian; Streif, Michael; Strohm, Thomas; Utschig-Utschig, Clemens; Volz, Daniel; Weiss, Horst; Winter, Fabian",Industry quantum computing applications,2021,10.1140/epjqt/s40507-021-00114-x,https://doi.org/10.1140/epjqt/s40507-021-00114-x,Journal,EPJ QUANTUM TECHNOLOGY,"Quantum computing promises to overcome computational limitations with better and faster solutions for optimization, simulation, and machine learning problems. Europe and Germany are in the process of successfully establishing research and funding programs with the objective to advance the technology's ecosystem and industrialization, thereby ensuring digital sovereignty, security, and competitiveness. Such an ecosystem comprises hardware/software solution providers, system integrators, and users from research institutions, start-ups, and industry. The vision of the Quantum Technology and Application Consortium (QUTAC) is to establish and advance the quantum computing ecosystem, supporting the ambitious goals of the German government and various research programs. QUTAC is comprised of ten members representing different industries, in particular automotive manufacturing, chemical and pharmaceutical production, insurance, and technology. In this paper, we survey the current state of quantum computing in these sectors as well as the aerospace industry and identify the contributions of QUTAC to the ecosystem. We propose an application-centric approach for the industrialization of the technology based on proven business impact. This paper identifies 24 different use cases. By formalizing high-value use cases into well-described reference problems and benchmarks, we will guide technological progress and eventually commercialization. Our results will be beneficial to all ecosystem participants, including suppliers, system integrators, software developers, users, policymakers, funding program managers, and investors.",Web of Science
"Liu, Fang; Zhou, Zhiguang",An improved QPSO algorithm and its application in the high-dimensional complex problems,2014,10.1016/j.chemolab.2014.01.003,https://doi.org/10.1016/j.chemolab.2014.01.003,Journal,CHEMOMETRICS AND INTELLIGENT LABORATORY SYSTEMS,"In allusion to the deficiencies of the low computational efficiency and local optimal solution of particle swarm optimization (PSO) algorithm, an improved PSO algorithm based on combining the simulated annealing (SA), co-evolution theory, quantum behavior theory and diversity-guided mutation strategy (MSCQPSO) is proposed in this paper. In the proposed MSCQPSO algorithm, the population is divided into multi-populations according to the computed fitness value. The SA and diversity-guided mutation strategy are introduced to enhance the global search ability. The quantum behavior theory is introduced into co-evolution theory to change the updating mode of the particles in order to guarantee the simplification and effectiveness. In order to prove the validity of the proposed MSCQPSO algorithm, the ten high-dimensional complex benchmark functions are selected in here. The experiment results show that the proposed MSCQPSO algorithm takes on the fast convergence, the high searching accuracy, the better robustness for solving the high-dimensional complex problems than the PSO algorithm, the CPSO algorithm and HPSO algorithm. (c) 2014 Elsevier B.V. All rights reserved.",Web of Science
"Teplukhin, Alexander; Kendrick, Brian K.; Mniszewski, Susan M.; Tretiak, Sergei; Dub, Pavel A.",Sampling electronic structure quadratic unconstrained binary optimization problems (QUBOs) with Ocean and Mukai solvers,2022,10.1371/journal.pone.0263849,https://doi.org/10.1371/journal.pone.0263849,Journal,PLOS ONE,"The most advanced D-Wave Advantage quantum annealer has 5000+ qubits, however, every qubit is connected to a small number of neighbors. As such, implementation of a fully-connected graph results in an order of magnitude reduction in qubit count. To compensate for the reduced number of qubits, one has to rely on special heuristic software such as qbsolv, the purpose of which is to decompose a large quadratic unconstrained binary optimization (QUBO) problem into smaller pieces that fit onto a quantum annealer. In this work, we compare the performance of the open-source qbsolv which is a part of the D-Wave Ocean tools and a new Mukai QUBO solver from Quantum Computing Inc. (QCI). The comparison is done for solving the electronic structure problem and is implemented in a classical mode (Tabu search techniques). The Quantum Annealer Eigensolver is used to map the electronic structure eigenvalue-eigenvector equation to a QUBO problem, solvable on a D-Wave annealer. We find that the Mukai QUBO solver outperforms the Ocean qbsolv with one to two orders of magnitude more accurate energies for all calculations done in the present work, both the ground and excited state calculations. This work stimulates the further development of software to assist in the utilization of modern quantum annealers.",Web of Science
"Huang, Yan; Wang, Peng; Li, Jianping; Chen, Xiuhong; Li, Tao",A Binary Multi-Scale Quantum Harmonic Oscillator Algorithm for 0-1 Knapsack Problem With Genetic Operator,2019,10.1109/ACCESS.2019.2942340,https://doi.org/10.1109/ACCESS.2019.2942340,Journal,IEEE ACCESS,"The 0-1 knapsack problem is a typical discrete combinatorial optimization problem with numerous applications. In this paper, a binary multi-scale quantum harmonic oscillator algorithm (BMQHOA) with genetic operator is proposed for solving 0-1 knapsack problem. The framework of BMQHOA is consisted of three nested phases including energy level stablization, energy level decline and scale adjustment. In BMQHOA, the number of different bits between solutions is defined as the distance between solutions to map the continuous search space into the discrete search space. Repair operator with greedy strategy is adopted in BMQHOA to guarantee the knapsack capacity constraint. The current best solution is used to perform a random mutation with the origin solutions, making solutions evolve towards the current optimal solution. The performance of BMQHOA is evaluated on two low-dimensional and three high-dimensional KP01 data sets, and computational results are compared with several state-of-art 0-1 knapsack algorithms. Experimental results demonstrate that the proposed BMQHOA can get the best solutions of most knapsack data sets, and performs well on convergence and stability.",Web of Science
"Zwolak, Justyna P.; Kalantre, Sandesh S.; Wu, Xingyao; Ragole, Stephen; Taylor, Jacob M.",QFlow lite dataset: A machine-learning approach to the charge states in quantum dot experiments,2018,10.1371/journal.pone.0205844,https://doi.org/10.1371/journal.pone.0205844,Journal,PLOS ONE,"BackgroundOver the past decade, machine learning techniques have revolutionized how research and science are done, from designing new materials and predicting their properties to data mining and analysis to assisting drug discovery to advancing cybersecurity. Recently, we added to this list by showing how a machine learning algorithm (a so-called learner) combined with an optimization routine can assist experimental efforts in the realm of tuning semiconductor quantum dot (QD) devices. Among other applications, semiconductor quantum dots are a candidate system for building quantum computers. In order to employ QDs, one needs to tune the devices into a desirable configuration suitable for quantum computing. While current experiments adjust the control parameters heuristically, such an approach does not scale with the increasing size of the quantum dot arrays required for even near-term quantum computing demonstrations. Establishing a reliable protocol for tuning QD devices that does not rely on the gross-scale heuristics developed by experimentalists is thus of great importance.Materials and methodsTo implement the machine learning-based approach, we constructed a dataset of simulated QD device characteristics, such as the conductance and the charge sensor response versus the applied electrostatic gate voltages. The gate voltages are the experimental 'knobs' for tuning the device into useful regimes. Here, we describe the methodology for generating the dataset, as well as its validation in training convolutional neural networks.Results and discussionFrom 200 training sets sampled randomly from the full dataset, we show that the learner's accuracy in recognizing the state of a device is 96.5% when using either current-based or charge-sensor-based training. The spread in accuracy over our 200 training sets is 0.5% and 1.8% for current- and charge-sensor-based data, respectively. In addition, we also introduce a tool that enables other researchers to use this approach for further research: QFlow lite a Python-based mini-software suite that uses the dataset to train neural networks to recognize the state of a device and differentiate between states in experimental data. This work gives the definitive reference for the new dataset that will help enable researchers to use it in their experiments or to develop new machine learning approaches and concepts.",Web of Science
"Borowka, S.; Heinrich, G.; Jahn, S.; Jones, S. P.; Kerner, M.; Schlenk, J.; Zirke, T.",pySecDec: A toolbox for the numerical evaluation of multi-scale integrals,2018,10.1016/j.cpc.2017.09.015,https://doi.org/10.1016/j.cpc.2017.09.015,Journal,COMPUTER PHYSICS COMMUNICATIONS,"We present pySEcDEc, a new version of the program SEcDEc, which performs the factorization of dimensionally regulated poles in parametric integrals, and the subsequent numerical evaluation of the finite coefficients. The algebraic part of the program is now written in the form of python modules, which allow a very flexible usage. The optimization of the C++ code, generated using FORM, is improved, leading to a faster numerical convergence. The new version also creates a library of the integrand functions, such that it can be linked to user-specific codes for the evaluation of matrix elements in a way similar to analytic integral libraries.Program summaryProgram Title: pySecDecProgram Files doi: http://dx.doi.org/10.17632/3y8bbz9c9v.1Licensing provisions: GNU Public License v3Programming language: python, FORM, C++External routines/libraries: catch [1], gsl [2], numpy [3], sympy [4], Nauty [5], Cuba [6], FORM [7], Normaliz [8]. The program can also be used in a mode which does not require Normaliz.Journal reference of previous version: Comput. Phys. Commun. 196 (2015) 470-491.Nature of the problem: Extraction of ultraviolet and infrared singularities from parametric integrals appearing in higher order perturbative calculations in quantum field theory. Numerical integration in the presence of integrable singularities (e.g. kinematic thresholds).Solution method: Algebraic extraction of singularities within dimensional regularization using iterated sector decomposition. This leads to a Laurent series in the dimensional regularization parameter epsilon (and optionally other regulators), where the coefficients are finite integrals over the unit-hypercube. Those integrals are evaluated numerically by Monte Carlo integration. The integrable singularities are handled by choosing a suitable integration contour in the complex plane, in an automated way. The parameter integrals forming the coefficients of the Laurent series in the regulator(s) are provided in the form of libraries which can be linked to the calculation of (multi-) loop amplitudes.Restrictions: Depending on the complexity of the problem, limited by memory and CPU time.References:[1] https://github.com/philsquared/Catch/.[2] http://www.gnu.org/software/gsl/.[3] http://www.numpy.org/.[4] http://www.sympy.org/.[5] http://pallini.di.uniromal.it/.[6] T. Hahn, CUBA: A Library for multidimensional numerical integration, Comput. Phys. Commun. 168 (2005) 78 [hep-ph/0404043], http://www.feynarts.de/cuba/.[7] J. Kuipers, T. Ueda and J. A. M. Vermaseren, Code Optimization in FORM, Comput. Phys. Commun. 189 (2015) 1 [arXiv:1310.7007], http://www.nikhef.nl/form/.[8] W. Bruns, B. Ichim, B. and T. Muer, C. Soger, Normaliz. Algorithms for rational cones and affine monoids. http://www.math.uos.de/normaliz/. (C) 2017 Elsevier B.V. All rights reserved.",Web of Science
"Kuo, Shu-Yu; Jiang, Yu-Chi; Chou, Yao-Hsin; Kuo, Sy-Yen; Kung, Sun-Yuan",Quantum Computer-Aided Design Automation,2023,10.1109/MNANO.2023.3249500,https://doi.org/10.1109/MNANO.2023.3249500,Journal,IEEE NANOTECHNOLOGY MAGAZINE,"Quantum computing is an essential issue for taking advantage of quantum properties in real-world applications. Realizing quantum computing with a corresponding quantum circuit is a critical step. This study introduces the AngelQ system, which provides quantum computing-as-a-service (QCaaS) for the cloud. The AngelQ system integrates quantum design automation (QDA) to achieve quantum and reversible circuit synthesis by a quantum-inspired optimization (QiO) technique and has visualization software interfaces to verify the QiO process and the correctness of the synthesized quantum and reversible circuits. First, the proposed novel QiO method has four significant features: Adaptive strategy, quantum-Not gate, update mechanism by Global solutions, and Entanglement Local search, named Angel QiO. which is a flexible technique to realize various circuits under different gate libraries with a few alterations. Angel QiO can construct diversified function-equivalent circuits to assess the circuit composition and boost the development of circuit synthesis. Second, researchers can observe the QiO algorithm process and inspect the intermediate result formula through AngelQ system's visualization interface to further adjust the parameters and improve the performance. Moreover, it benefits beginners' learning and adds convenience to education. In summary, the AngelQ system can extend and facilitate the future design and automation of quantum computing.",Web of Science
"Rao, Poojith U.; Sodhi, Balwinder",Hybrid quantum-classical solution for electric vehicle charger placement problem,2023,10.1007/s00500-022-07478-x,https://doi.org/10.1007/s00500-022-07478-x,Journal,SOFT COMPUTING,"Building a dependable network of electric vehicle charging stations (EVCSs) requires satisfying the demands and constraints of EV owners, energy grids, and the entities that will own and operate the EVCSs. Thus, determining the optimal spatial placement of EVCS becomes essential for the success of EVs in a market. Time taken by classical computers to solve such combinatorial optimization problems increases exponentially with the size of the area, making them non-scalable. We propose a novel quantum-classical solution to solve this problem. A crucial idea of our approach is to move the more complex combinatorial optimization portion of the problem into a quantum algorithm. We show that our solution gives more than 500% improvement in speed compared to the state-of-the-art classical methods, thus making it well suited for scalability scenarios. For allowing independent verification of our results, we have shared all our software artefacts here:",Web of Science
"Zhu, Haihong; Luo, Ning; Li, Xiaoping",A quantum-inspired cuckoo co-evolutionary algorithm for no-wait flow shop scheduling,2021,10.1049/cim2.12002,https://doi.org/10.1049/cim2.12002,Journal,IET COLLABORATIVE INTELLIGENT MANUFACTURING,"No-wait flow shop scheduling problems (NWFSPs) are widespread in practical applications. The authors propose a quantum-inspired cuckoo co-evolutionary algorithm for the NWFSP to minimize the makespan. There are three algorithm components: quantum solution construction, quantum population evolution, and an improved neighbourhood local search. They generate initial solutions, search solutions, and improve solution qualities, respectively. Parameters of the proposed algorithm are calibrated statistically. The proposal with calibrated parameters is compared with three existing algorithms on Reeves and Taillard benchmark instances with middle scales. Experimental results show that the proposal outperforms the compared algorithms.","Web of Science, Wiley"
"Ning, Tao; Wang, Zi; Duan, Xiaodong; Liu, Xiangdong",Research on flexible job shop scheduling with low-carbon technology based on quantum bacterial foraging optimization,2021,10.1093/ijlct/ctab005,https://doi.org/10.1093/ijlct/ctab005,Journal,INTERNATIONAL JOURNAL OF LOW-CARBON TECHNOLOGIES,"In order to further reduce the carbon emission of manufacturing process in flexible job shop, a multi-objective integrated optimization model of flexible job-shop scheduling (FJSP) is proposed. A mathematics model is built in this paper to minimize makespan, total workload of machines and carbon emissions of machines and to optimize process method of each machine characteristic, process sequence and machine allocation. Considering many parameters are interactional and to be optimized in the proposed model, a quantum bacterial foraging optimization is designed to code the related parameters. On the basis of Kacem example through experimental simulation, the performance of the proposed method in the paper was analysed with ANOVA, and by comparing with the algorithms of current separated optimization method of process planning and scheduling, the effect of proposed integrated optimization model on reducing carbon emission in practical requirements of FJSP is verified.",Web of Science
"Lee, Yongseok; Youn, Jonghee; Nam, Kevin; Oh, Hyunyoung; Paek, Yunheung",Optimizing Hardware Resource Utilization for Accelerating the NTRU-KEM Algorithm,2023,10.3390/computers12120259,https://doi.org/10.3390/computers12120259,Journal,COMPUTERS,"This paper focuses on enhancing the performance of the Nth-degree truncated-polynomial ring units key encapsulation mechanism (NTRU-KEM) algorithm, which ensures post-quantum resistance in the field of key establishment cryptography. The NTRU-KEM, while robust, suffers from increased storage and computational demands compared to classical cryptography, leading to significant memory and performance overheads. In environments with limited resources, the negative impacts of these overheads are more noticeable, leading researchers to investigate ways to speed up processes while also ensuring they are efficient in terms of area utilization. To address this, our research carefully examines the detailed functions of the NTRU-KEM algorithm, adopting a software/hardware co-design approach. This approach allows for customized computation, adapting to the varying requirements of operational timings and iterations. The key contribution is the development of a novel hardware acceleration technique focused on optimizing bus utilization. This technique enables parallel processing of multiple sub-functions, enhancing the overall efficiency of the system. Furthermore, we introduce a unique integrated register array that significantly reduces the spatial footprint of the design by merging multiple registers within the accelerator. In experiments conducted, the results of our work were found to be remarkable, with a time-area efficiency achieved that surpasses previous work by an average of 25.37 times. This achievement underscores the effectiveness of our optimization in accelerating the NTRU-KEM algorithm.",Web of Science
"Liu, Rong; Zhang, Liangpei; Du, Bo",A Novel Endmember Extraction Method for Hyperspectral Imagery Based on Quantum-Behaved Particle Swarm Optimization,2017,10.1109/JSTARS.2016.2640274,https://doi.org/10.1109/JSTARS.2016.2640274,Journal,IEEE JOURNAL OF SELECTED TOPICS IN APPLIED EARTH OBSERVATIONS AND REMOTE SENSING,"Endmember extraction is one of the most important issues in hyperspectral image analysis. Under the linear mixing model and pure pixel assumption, a number of convex-geometry-based methods have been developed in the past decades. However, these traditional methods generally produce unsatisfactory results since they require the hyperspectral image to have a convex structure and this is not exactly the case with the real image scene. The particle swarm optimization (PSO) algorithm has recently been employed to address the endmember extraction problem, but its performance is limited by the premature convergence and lower precision of the standard PSO, and much effort is required to enhance the optimization result. To address these problems, in this study, a novel quantum-behaved particle swarm optimization (QPSO) algorithm is proposed for hyperspectral endmember extraction. The notable advantages of the proposed method include: 1) a row-column coding approach for the particles is designed to accelerate the optimization process; 2) a cooperative approach is employed to update the particles' individual and global best positions, in order to help the particles' optimization behavior in the multidimensional search space; and 3) two kinds of objective functions, namely, maximizing the simplex volume formed by the endmember combination, and minimizing the root-mean-square error between the original image and its remixed image, are incorporated in a sequential optimization approach for the endmember extraction problem, which makes the algorithm robust to outliers at an acceptable time cost. The extensive experimental results prove that QPSO is able to find the optimal endmember combination.",Web of Science
"Orts, Francisco; Paulavicius, Remigijus; Filatovas, Ernestas",Quantum circuit optimization of an integer divider,2024,10.1016/j.jss.2024.112091,https://doi.org/10.1016/j.jss.2024.112091,Journal,JOURNAL OF SYSTEMS AND SOFTWARE,"Efficient arithmetic operations in quantum circuits play a vital role in the implementation of quantum algorithms. Quantum circuits constructed exclusively using gates of the Clifford+T group are compatible with error detection and correction codes available in the quantum literature. However, the T gate, a member of this group, has a higher cost compared to other gates, making it crucial to minimize its usage to reduce circuit expenses. While the T gate cannot be entirely avoided since the Clifford group is not a universal set of gates, circuit optimization can effectively reduce the number of T gates required for implementation. In this work, we present a novel divider circuit for quantum computing that focuses on reducing the number of T gates while maintaining a reasonable number of qubits for this type of operation. To achieve this, we introduce variants of minor circuits, including a comparator and two types of subtractors. These circuits are based on published literature but undergo modifications to optimize their resource utilization for performing the division operation. The obtained results demonstrate that the proposed divider circuit outperforms other currently published divider circuits in terms of T gate usage, highlighting its efficiency and potential practicality in quantum algorithms.",Web of Science
"Jin, Jin; Zhang, Qian; He, Jia; Yu, Hongnian",Quantum Dynamic Optimization Algorithm for Neural Architecture Search on Image Classification,2022,10.3390/electronics11233969,https://doi.org/10.3390/electronics11233969,Journal,ELECTRONICS,"Deep neural networks have proven to be effective in solving computer vision and natural language processing problems. To fully leverage its power, manually designed network templates, i.e., Residual Networks, are introduced to deal with various vision and natural language tasks. These hand-crafted neural networks rely on a large number of parameters, which are both data-dependent and laborious. On the other hand, architectures suitable for specific tasks have also grown exponentially with their size and topology, which prohibits brute force search. To address these challenges, this paper proposes a quantum dynamic optimization algorithm to find the optimal structure for a candidate network using Quantum Dynamic Neural Architecture Search (QDNAS). Specifically, the proposed quantum dynamics optimization algorithm is used to search for meaningful architectures for vision tasks and dedicated rules to express and explore the search space. The proposed quantum dynamics optimization algorithm treats the iterative evolution process of the optimization over time as a quantum dynamic process. The tunneling effect and potential barrier estimation in quantum mechanics can effectively promote the evolution of the optimization algorithm to the global optimum. Extensive experiments on four benchmarks demonstrate the effectiveness of QDNAS, which is consistently better than all baseline methods in image classification tasks. Furthermore, an in-depth analysis is conducted on the searchable networks that provide inspiration for the design of other image classification networks.",Web of Science
"Zhang, Kaifei; Zhang, Jufang",A technique for designing nano-scale circuits using a fuzzy logic and nature-inspired fish swarm optimization algorithm,2022,10.1016/j.ijleo.2022.169756,https://doi.org/10.1016/j.ijleo.2022.169756,Journal,OPTIK,"Recent breakthroughs in quantum processing software and hardware have shown substantial development toward operational results. We anticipate quantum computing to have significant applications in some domains ranging from machine learning and optimization to drug development in the future. Quantum computing and designing have gotten a lot of interest from investigators. Physical design is one of the two main stages in designing nano-scale circuits that receive a list of circuit nodes as input and produce the final arrangement in a particular technology. However, it has encountered several design issues and execution limits in the long term. Moreover, designing nano-scale circuits is an NP-hard problem in terms of cost, delay, and energy consumption. This paper has provided a new method for solving the optimal design of nano-scale circuits using a fuzzy-based Fish Swarm Algorithm (FSA). The FSA represents fish, hunting, and fish behavior to get the best results. It has a quick integration speed, a powerful global search capacity, and a significant shortcoming. In our proposed method, the fuzzy observer is responsible for detecting the system's state within the defined area and maintaining the state within it. The proposed method has been evaluated against some benchmarks, and cost, delay, energy, and area characteristics have been reduced. Simulation outcomes demonstrated the suggested method's correct performance in terms of energy, cost, area, and delay where the suggested technique outperforms others (GA, PSO, FSA and ACO).",Web of Science
"Ullah, Md Habib; Eskandarpour, Rozhin; Zheng, Honghao; Khodaei, Amin",Quantum computing for smart grid applications,2022,10.1049/gtd2.12602,https://doi.org/10.1049/gtd2.12602,Journal,IET GENERATION TRANSMISSION & DISTRIBUTION,"Computational complexities in modern power systems are reportedly increasing daily, and it is anticipated that traditional computers might be inadequate to provide the computation prerequisite in future complex power grids. In that given context, quantum computing (QC) can be considered a next-generation alternative solution to deal with upcoming computational challenges in smart grids. The QC is a relatively new yet promising technology that leverages the unique phenomena of quantum mechanics in processing information and computations. This emerging paradigm shows a significant potential to overcome the barrier of computational limitations with better and faster solutions in optimization, simulations, and machine learning problems. In recent years, substantial progress in developing advanced quantum hardware, software, and algorithms have made QC more feasible to apply in various research areas, including smart grids. It is evident that considerable research has already been carried out, and such efforts are remarkably continuing. As QC is a highly evolving field of study, a brief review of the existing literature will be vital to realize the state-of-art on QC for smart grid applications. Therefore, this article summarizes the research outcomes of the most recent papers, highlights their suggestions for utilizing QC techniques for various smart grid applications, and further identifies the potential smart grid applications. Several real-world QC case studies in various research fields besides power and energy systems are demonstrated. Moreover, a brief overview of available quantum hardware specifications, software tools, and algorithms is described with a comparative analysis.","Web of Science, Wiley"
"Wang, Yuanheng; Seritan, Stefan; Lahana, Dean; Ford, Jason E.; Valentini, Alessio; Hohenstein, Edward G.; Martinez, Todd J.",INTERACHEM: Exploring Excited States in Virtual Reality with Ab Initio Interactive Molecular Dynamics,2022,10.1021/acs.jctc.2c00005,https://doi.org/10.1021/acs.jctc.2c00005,Journal,JOURNAL OF CHEMICAL THEORY AND COMPUTATION,"INTERACHEM is an ab initio interactive molecular dynamics (AI-IMD) visualizer that leverages recent advances in virtual reality hardware and software, as well as the graphical processing unit (GPU)-accelerated TERACHEM electronic structure package, in order to render quantum chemistry in real time. We introduce the exploration of electronically excited states via AI-IMD using the floating occupation molecular orbital-complete active space configuration interaction method. The optimization tools in INTERACHEM enable identification of excited state minima as well as minimum energy conical intersections for further characterization of excited state chemistry in small- to medium-sized systems. We demonstrate that finite-temperature Hartree-Fock theory is an efficient method to perform ground state Al-IMD. INTERACHEM allows users to track electronic properties such as molecular orbitals and bond order in real time, resulting in an interactive visualization tool that aids in the interpretation of excited state chemistry data and makes quantum chemistry more accessible for both research and educational purposes.",Web of Science
"Dumitrescu, Eugene F.; Fisher, Allison L.; Goodrich, Timothy D.; Humble, Travis S.; Sullivan, Blair D.; Wright, Andrew L.",Benchmarking treewidth as a practical component of tensor network simulations,2018,10.1371/journal.pone.0207827,https://doi.org/10.1371/journal.pone.0207827,Journal,PLOS ONE,"Tensor networks are powerful factorization techniques which reduce resource requirements for numerically simulating principal quantum many-body systems and algorithms. The computational complexity of a tensor network simulation depends on the tensor ranks and the order in which they are contracted. Unfortunately, computing optimal contraction sequences (orderings) in general is known to be a computationally difficult (NP-complete) task. In 2005, Markov and Shi showed that optimal contraction sequences correspond to optimal (minimum width) tree decompositions of a tensor network's line graph, relating the contraction sequence problem to a rich literature in structural graph theory. While treewidth-based methods have largely been ignored in favor of dataset-specific algorithms in the prior tensor networks literature, we demonstrate their practical relevance for problems arising from two distinct methods used in quantum simulation: multi-scale entanglement renormalization ansatz (MERA) datasets and quantum circuits generated by the quantum approximate optimization algorithm (QAOA). We exhibit multiple regimes where treewidth-based algorithms outperform domain-specific algorithms, while demonstrating that the optimal choice of algorithm has a complex dependence on the network density, expected contraction complexity, and user run time requirements. We further provide an open source software framework designed with an emphasis on accessibility and extendability, enabling replicable experimental evaluations and future exploration of competing methods by practitioners.",Web of Science
"Dong, Shi; Xia, Yuanjun; Kamruzzaman, Joarder",Quantum Particle Swarm Optimization for Task Offloading in Mobile Edge Computing,2023,10.1109/TII.2022.3225313,https://doi.org/10.1109/TII.2022.3225313,Journal,IEEE TRANSACTIONS ON INDUSTRIAL INFORMATICS,"Mobile edge computing (MEC) deploys servers on the edge of the mobile network to reduce the data transmission delay between servers and mobile devices, and can meet the computing demand of mobile computing tasks. It alleviates the problem of computing power and delay requirements of mobile computing tasks and reduces the energy consumption of mobile devices. However, the MEC server has limited computing and storage resources and mobile network bandwidth, making it impossible to offload all mobile computing tasks to MEC servers for processing. Therefore, MEC needs to reasonably offload and schedule mobile computing tasks, to achieve efficient utilization of server resources. To solve the above-mentioned problems, in this article, the task offloading problem is formulated as an optimization problem, and particle swarm optimization (PSO) and quantum PSO based task offloading strategies are proposed. Extensive simulation results show that the proposed algorithm can significantly reduce the system energy consumption, task completion time, and running time compared with recent advanced strategies, namely ant colony optimization, multiagent deep deterministic policy gradients, deep meta reinforcement learning-based offloading, iterative proximal algorithm, and parallel random forest.",Web of Science
"Gerlach, Marvin",Three-loop topology analysis of neutral B-meson mixing with tapir,2023,10.1088/1742-6596/2438/1/012156,https://doi.org/10.1088/1742-6596/2438/1/012156,Conference Paper,20th International Workshop on Advanced Computing and Analysis Techniques in Physics Research (ACAT),"Modern advances in particle physics depend strongly on the usage of reliable computer programs. In this context two issues become important: The usage of powerful algorithms to handle the amount of evaluated data properly, and a software architecture capable of overcoming the problems of maintainability and extendability. We present our approach to such a computer program, called tapir. This tool assists computations in perturbative quantum field theory in many ways. Such calculations often involve the evaluation of a large amount of Feynman diagrams with multiple loops. tapir helps in reducing the number of diagrams, and the resulting integrals thereof, by identifying and minimizing their topological structure. We will focus on a three-loop calculation which is needed for the next-to-next-to leading order predictions of neutral B-meson systems. We show how tapir can be utilized for this kind of calculation.",Web of Science
"Fazili, Mohammad Mudakir; Shah, Mohsin Fayaz; Naz, Syed Farah; Shah, Ambika Prasad",Next generation QCA technology based true random number generator for cryptographic applications,2022,10.1016/j.mejo.2022.105502,https://doi.org/10.1016/j.mejo.2022.105502,Journal,MICROELECTRONICS JOURNAL,"The penchant for almost all modern-day devices is high data and communication security. To achieve the highest standard of security, hardware-based encryption architectures like true random number generators (TRNG) and physically unclonable functions (PUF) supersede attack deterrence to any known software-based cryptography algorithm. The keys generated are random and unpredictable. This paper proposes a new architecture for TRNG in quantum-dot cellular automata (QCA) technology using feedback and feed-forward D flip-flop arrangement with small delay defects. A new optimized negative edge-triggered D flip-flop is presented using only 25-QCA cells. This unique and carefully curated TRNG structure ensures the generated output bits are highly unpredictable and truly random in behavior. Furthermore, 15 statistical tests designed for random number generators are performed. These test results validate the random nature of the generated outputs and unpredictable behavior of the proposed TRNG design. The energy dissipation analysis shows a significant improvement of 49.6% for energy dissipation per bit compared to existing designs.",Web of Science
"He, Run-Hong; Xu, Xu-Sheng; Byrd, Mark S.; Wang, Zhao-Ming",Modularized and scalable compilation for double quantum dot quantum computing,2024,10.1088/2058-9565/acfe38,https://doi.org/10.1088/2058-9565/acfe38,Journal,QUANTUM SCIENCE AND TECHNOLOGY,"Any quantum program on a realistic quantum device must be compiled into an executable form while taking into account the underlying hardware constraints. Stringent restrictions on architecture and control imposed by physical platforms make this very challenging. In this paper, based on the quantum variational algorithm, we propose a novel scheme to train an Ansatz circuit and realize high-fidelity compilation of a set of universal quantum gates for singlet-triplet qubits in semiconductor double quantum dots, a fairly heavily constrained system. Furthermore, we propose a scalable architecture for a modular implementation of quantum programs in this constrained systems and validate its performance with two representative demonstrations, the Grover's algorithm for the database searching (static compilation) and a variant of variational quantum eigensolver for the Max-Cut optimization (dynamic compilation). Our methods are potentially applicable to a wide range of physical devices. This work constitutes an important stepping-stone for exploiting the potential for advanced and complicated quantum algorithms on near-term devices.",Web of Science
"Ong, Shyue Ping",Accelerating materials science with high-throughput computations and machine learning,2019,10.1016/j.commatsci.2019.01.013,https://doi.org/10.1016/j.commatsci.2019.01.013,Journal,COMPUTATIONAL MATERIALS SCIENCE,"With unprecedented amounts of materials data generated from experiments as well as high-throughput density functional theory calculations, machine learning techniques has the potential to greatly accelerate materials discovery and design. Here, we review our efforts in the Materials Virtual Lab to integrate software automation, data generation and curation and machine learning to (i) design and optimize technological materials for energy storage, energy efficiency and high-temperature alloys; (ii) develop scalable quantum-accurate models, and (iii) enhance the speed and accuracy in interpreting characterization spectra.",Web of Science
"Mageswari, R. Uma; Althubiti, Sara A.; Alenezi, Fayadh; Lydia, E. Laxmi; Joshi, Gyanendra Prasad; Cho, Woong",Enhanced Metaheuristics-Based Clustering Scheme for Wireless Multimedia Sensor Networks,2022,10.32604/cmc.2022.030806,https://doi.org/10.32604/cmc.2022.030806,Journal,CMC-COMPUTERS MATERIALS & CONTINUA,"Traditional Wireless Sensor Networks (WSNs) comprise of costeffective sensors that can send physical parameters of the target environment to an intended user. With the evolution of technology, multimedia sensor nodes have become the hot research topic since it can continue gatheringmultimedia content and scalar from the target domain. The existence ofmultimedia sensors, integrated with effective signal processing andmultimedia source coding approaches, has led to the increased application of Wireless Multimedia Sensor Network (WMSN). This sort of network has the potential to capture, transmit, and receive multimedia content. Since energy is a major source in WMSN, novel clustering approaches are essential to deal with adaptive topologies of WMSN and prolonged network lifetime. With this motivation, the current study develops an Enhanced Spider Monkey Optimization-based Energy-Aware Clustering Scheme (ESMO-EACS) for WMSN. The proposed ESMO-EACS model derives ESMO algorithm by incorporating the concepts of SMO algorithm and quantum computing. The proposed ESMO-EACS model involves the design of fitness functions using distinct input parameters for effective construction of clusters. A comprehensive experimental analysis was conducted to validate the effectiveness of the proposed ESMO-EACS technique in terms of different performance measures. The simulation outcome established the superiority of the proposed ESMO-EACS technique to other methods under various measures.",Web of Science
"Mandal, Ashis Kumar; Sen, Rikta; Chakraborty, Basabi",Quantum-Inspired Owl Search Algorithm with Ensembles of Filter Methods for Gene Subset Selection from Microarray Data,2023,10.1142/S0218001423510011,https://doi.org/10.1142/S0218001423510011,Journal,INTERNATIONAL JOURNAL OF PATTERN RECOGNITION AND ARTIFICIAL INTELLIGENCE,"Finding the optimum subset of genes for microarray classification is laborious because microarray data are often high-dimensional and contain many irrelevant and redundant genes. To overcome this problem, we have proposed a two-step technique. In the first step, to reduce the vast number of genes or features, an ensemble of popular rank-based feature selection algorithms with filter evaluation metrics are used to select a group of top-ranking genes. In the next step, the quantum-inspired owl search algorithm (QIOSAf), a new filter fitness function-based metaheuristic search technique incorporating concepts from quantum computing, is developed to identify the best subset of genes from the predetermined list. The experimental findings reveal that the ensemble approach in the first step can select more dominant groups of genes than each of the individual filters. Furthermore, it has been found that QIOSAf can reduce the cardinality of the selected optimum gene subset with comparable classification accuracy and requires lesser computational time than our earlier proposed QIOSA-based wrapper approach (i.e. QIOSAw). Besides, compared with three popular evolutionary feature subset selection algorithms, QIOSAf efficiently reduces the optimum cardinality of the gene subset while maintaining acceptable classification accuracy.",Web of Science
"Chesalin, Denis D.; Kulikov, Eugene A.; Yaroshevich, Igor A.; Maksimov, Eugene G.; Selishcheva, Alla A.; Pishchalnikov, Roman Y.",Differential evolution reveals the effect of polar and nonpolar solvents on carotenoids: A case study of astaxanthin optical response modeling,2022,10.1016/j.swevo.2022.101210,https://doi.org/10.1016/j.swevo.2022.101210,Journal,SWARM AND EVOLUTIONARY COMPUTATION,"The task to simulate realistic absorption spectra of electronic transitions in pigment molecules takes the form of the art of optimization, particularly if one must choose between the quality of the results obtained and the calculation time necessary to get such quality. The semiclassical theory of optical response provides us with a good opportunity to escape a so-called sum-over-state procedure of considering the innumerable number of vibronic states of a pigment by applying a correlation function approach. This approach, known as the multi -mode Brownian oscillator model (MBOM), involves replacing an infinite set of vibronic states, which interacts with an electronic transition, with a finite set of effective vibronic modes. Thus, the parameters of effective vibronic modes and an electronic transition can be found only by fitting experimental data. This situation gives rise to the following problem: as the number of free parameters increases, it becomes more difficult to find a single solution. To overcome this obstacle, differential evolution (DE), a method of global optimization, which is based on the idea of natural selection, seems to be the right choice. To test the efficiency of DE in solving quantum mechanical problems, we simulated absorption spectra of astaxanthin (AST) in 18 different organic solvents by using the MBOM. To do so, we developed software that implements both the DE algorithm and linear absorption modeling procedures. We have shown that simulating practically identical AST spectra, DE allows determining the effect of polar and nonpolar solvents on several parameters of MBOM of AST with high accuracy.",Web of Science
"Gambella, Claudio; Simonetto, Andrea",Multiblock ADMM Heuristics for Mixed-Binary Optimization on Classical and Quantum Computers,2020,10.1109/TQE.2020.3033139,https://doi.org/10.1109/TQE.2020.3033139,Journal,IEEE TRANSACTIONS ON QUANTUM ENGINEERING,"Solving combinatorial optimization problems on current noisy quantum devices is currently being advocated for (and restricted to) binary polynomial optimization with equality constraints via quantum heuristic approaches. This is achieved using, for example, the variational quantum eigensolver (VQE) and the quantum approximate optimization algorithm (QAOA). In this article, we present a decomposition-based approach to extend the applicability of current approaches to quadratic plus convex mixed binary optimization (MBO) problems, so as to solve a broad class of real-world optimization problems. In the MBO framework, we show that the alternating direction method of multipliers (ADMM) can split the MBO into a binary unconstrained problem (that can be solved with quantum algorithms), and continuous constrained convex subproblems (that can be solved cheaply with classical optimization solvers). The validity of the approach is then showcased by numerical results obtained on several optimization problems via simulations with VQE and QAOA on the quantum circuits implemented in Qiskit, an open-source quantum computing software development framework.",Web of Science
"Zhang, Yuzhi; Wang, Haidi; Chen, Weijie; Zeng, Jinzhe; Zhang, Linfeng; Wang, Han; Weinan, E.",DP-GEN: A concurrent learning platform for the generation of reliable deep learning based potential energy models,2020,10.1016/j.cpc.2020.107206,https://doi.org/10.1016/j.cpc.2020.107206,Journal,COMPUTER PHYSICS COMMUNICATIONS,"In recent years, promising deep learning based interatomic potential energy surface (PES) models have been proposed that can potentially allow us to perform molecular dynamics simulations for large scale systems with quantum accuracy. However, making these models truly reliable and practically useful is still a very non-trivial task. A key component in this task is the generation of datasets used in model training. In this paper, we introduce the Deep Potential GENerator (DP-GEN), an open-source software platform that implements the recently proposed on-the-fly learning procedure (Zhang et al. 2019) and is capable of generating uniformly accurate deep learning based PES models in a way that minimizes human intervention and the computational cost for data generation and model training. DP-GEN automatically and iteratively performs three steps: exploration, labeling, and training. It supports various popular packages for these three steps: LAMMPS for exploration, Quantum Espresso, VASP, CP2K, etc. for labeling, and DeePMD-kit for training. It also allows automatic job submission and result collection on different types of machines, such as high performance clusters and cloud machines, and is adaptive to different job management tools, including Slurm, PBS, and LSF. As a concrete example, we illustrate the details of the process for generating a general-purpose PES model for Cu using DP-GEN.Program summaryProgram Title: DP-GENProgram Files doi: http://dx.dot.org/10.17632/sxybkgc5xc.1Licensing provisions: LGPLProgramming language: PythonNature of problem: Generating reliable deep learning based potential energy models with minimal human intervention and computational cost.Solution method: The concurrent learning scheme is implemented. Supports for sampling configuration space with LAMMPS, generating ab initio data with Quantum Espresso, VASP, CP2K and training potential models with DeePMD-kit are provided. Supports for different machines including workstations, high performance clusters and cloud machines are provided. Supports for job management tools including Slurm, PBS, LSF are provided. (C) 2020 Elsevier B.V. All rights reserved.",Web of Science
"Gupta, Mayank; Nene, Manisha J.",Quantum computing: A measurement and analysis review,2021,10.1002/cpe.6344,https://doi.org/10.1002/cpe.6344,Journal,CONCURRENCY AND COMPUTATION-PRACTICE & EXPERIENCE,"Computing methodologies with rapid proliferation and need for greater concurrency have evolved over the years from parallel and distributed computing to latest technologies like cloud computing. A paradigm shift in computing methodologies has been witnessed in the form of exponential speed up, optimization of problem solutions, and solvability of few classically unsolvable problems with emergence of quantum computing. The study in this article presents observations on executing basic quantum operations that play a vital role in quantum computing. The results and analysis demonstrate how parameters of time, deviation, and shots have a significant effect on outcomes of quantum circuits executed which can be a reference point for the community in general engaged in designing of quantum circuits, protocols, algorithms, and quantum hardware to leverage quantum characteristics and properties. The study by means of experimental use cases provides a rigorous review of qubit behavior, standard, and entangled qubit measurement with practical results over a simulator and real quantum hardware for variable qubit configurations using a selected platform of IBM Q Experience. With the paradigm shift from classical to quantum computing, this article provides basic but very vital observations which can be brought to use by anyone intending to build quantum applications.","Web of Science, Wiley"
"Huang, Yiming; Lei, Hang; Li, Xiaoyu; Zhu, Qingsheng; Ren, Wanghao; Liu, Xusheng",Quantum Generative Model with Variable-Depth Circuit,2020,10.32604/cmc.2020.010390,https://doi.org/10.32604/cmc.2020.010390,Journal,CMC-COMPUTERS MATERIALS & CONTINUA,"In recent years, an increasing number of studies about quantum machine learning not only provide powerful tools for quantum chemistry and quantum physics but also improve the classical learning algorithm. The hybrid quantum-classical framework, which is constructed by a variational quantum circuit (VQC) and an optimizer, plays a key role in the latest quantum machine learning studies. Nevertheless, in these hybrid -framework-based quantum machine learning models, the VQC is mainly constructed with a fixed structure and this structure causes inflexibility problems. There are also few studies focused on comparing the performance of quantum generative models with different loss functions. In this study, we address the inflexibility problem by adopting the variable-depth VQC model to automatically change the structure of the quantum circuit according to the qBAS score. The basic idea behind the variable-depth VQC is to consider the depth of the quantum circuit as a parameter during the training. Meanwhile, we compared the performance of the variable-depth VQC model based on four widely used statistical distances set as the loss functions, including Kullback-Leibler divergence (KL-divergence), Jensen-Shannon divergence (JS-divergence), total variation distance, and maximum mean discrepancy. Our numerical experiment shows a promising result that the variable-depth VQC model works better than the original VQC in the generative learning tasks.",Web of Science
"Wilkens, Sascha; Moorhouse, Joe",Quantum computing for financial risk measurement,2023,10.1007/s11128-022-03777-2,https://doi.org/10.1007/s11128-022-03777-2,Journal,QUANTUM INFORMATION PROCESSING,"Quantum computing allows a significant speed-up over traditional CPU-and GPUbased algorithms when applied to particular mathematical challenges such as optimisation and simulation. Despite promising advances and extensive research in hard-and software developments, currently available quantum systems are still largely limited in their capability. In line with this, practical applications in quantitative finance are still in their infancy. This paper analyses requirements and concrete approaches for the application to risk management in a financial institution. On the examples of Value-at-Risk for market risk and Potential Future Exposure for counterparty credit risk, the main contribution lies in going beyond textbook illustrations and instead exploring must-have model features and their quantum implementations. While conceptual solutions and small-scale circuits are feasible at this stage, the leap needed for real-life applications is still significant. In order to build a usable risk measurement system, the hardware capacity-measured in number of qubits-would need to increase by several magnitudes from their current value of about 102. Quantum noise poses an additional challenge, and research into its control and mitigation would need to advance in order to render risk measurement applications deployable in practice. Overall, given the maturity of established classical simulation-based approaches that allow risk computations in reasonable time and with sufficient accuracy, the business case for a move to quantum solutions is not very strong at this point.",Web of Science
"Fried, E. Schuyler; Sawaya, Nicolas P. D.; Cao, Yudong; Kivlichan, Ian D.; Romero, Jhonathan; Aspuru-Guzik, Alan",qTorch: The quantum tensor contraction handler,2018,10.1371/journal.pone.0208510,https://doi.org/10.1371/journal.pone.0208510,Journal,PLOS ONE,"Classical simulation of quantum computation is necessary for studying the numerical behavior of quantum algorithms, as there does not yet exist a large viable quantum computer on which to perform numerical tests. Tensor network (TN) contraction is an algorithmic method that can efficiently simulate some quantum circuits, often greatly reducing the computational cost over methods that simulate the full Hilbert space. In this study we implement a tensor network contraction program for simulating quantum circuits using multi-core compute nodes. We show simulation results for the Max-Cut problem on 3-through 7-regular graphs using the quantum approximate optimization algorithm (QAOA), successfully simulating up to 100 qubits. We test two different methods for generating the ordering of tensor index contractions: one is based on the tree decomposition of the line graph, while the other generates ordering using a straight-forward stochastic scheme. Through studying instances of QAOA circuits, we show the expected result that as the treewidth of the quantum circuit's line graph decreases, TN contraction becomes significantly more efficient than simulating the whole Hilbert space. The results in this work suggest that tensor contraction methods are superior only when simulating Max-Cut/QAOA with graphs of regularities approximately five and below. Insight into this point of equal computational cost helps one determine which simulation method will be more efficient for a given quantum circuit. The stochastic contraction method outperforms the line graph based method only when the time to calculate a reasonable tree decomposition is prohibitively expensive. Finally, we release our software package, qTorch (Quantum TensOR Contraction Handler), intended for general quantum circuit simulation. For a nontrivial subset of these quantum circuits, 50 to 100 qubits can easily be simulated on a single compute node.",Web of Science
"He, Zhimin; Chen, Chuangtao; Li, Zhengjiang; Situ, Haozhen; Zhang, Fei; Zheng, Shenggen; Li, Lvzhou",A meta-trained generator for quantum architecture search,2024,10.1140/epjqt/s40507-024-00255-9,https://doi.org/10.1140/epjqt/s40507-024-00255-9,Journal,EPJ QUANTUM TECHNOLOGY,"Variational Quantum Algorithms (VQAs) have made great success in the Noisy Intermediate-Scale Quantum (NISQ) era due to their relative resilience to noise and high flexibility relative to quantum resources. Quantum Architecture Search (QAS) aims to enhance the performance of VQAs by refining the structure of the adopted Parameterized Quantum Circuit (PQC). QAS is garnering increased attention owing to its automation, reduced reliance on expert experience, and its ability to achieve better performance while requiring fewer quantum gates than manually designed circuits. However, existing QAS algorithms optimize the structure from scratch for each VQA without using any prior experience, rendering the process inefficient and time-consuming. Moreover, determining the number of quantum gates, a crucial hyper-parameter in these algorithms is a challenging and time-consuming task. To mitigate these challenges, we accelerate the QAS algorithm via a meta-trained generator. The proposed algorithm directly generates high-performance circuits for a new VQA by utilizing a meta-trained Variational AutoEncoder (VAE). The number of quantum gates required in the designed circuit is automatically determined based on meta-knowledge learned from a variety of training tasks. Furthermore, we have developed a meta-predictor to filter out circuits with suboptimal performance, thereby accelerating the algorithm. Simulation results on variational quantum compiling and Quantum Approximation Optimization Algorithm (QAOA) demonstrate the superior performance of our method over a state-of-the-art algorithm, namely Differentiable Quantum Architecture Search (DQAS).",Web of Science
"Bystrov, Vladimir S.",Molecular self-assembled helix peptide nanotubes based on some amino acid molecules and their dipeptides: molecular modeling studies,2024,10.1007/s00894-024-05995-0,https://doi.org/10.1007/s00894-024-05995-0,Journal,JOURNAL OF MOLECULAR MODELING,"ContextThe paper considers the features of the structure and dipole moments of several amino acids and their dipeptides which play an important role in the formation of the peptide nanotubes based on them. The influence of the features of their chirality (left L and right D) and the alpha-helix conformations of amino acids are taken into account. In particular, amino acids with aromatic rings, such as phenylalanine (Phe/F), and branched-chain amino acids (BCAAs)-leucine (Leu/L) and isoleucine (Ile/I)-as well as corresponding dipeptides (diphenylalanine (FF), dileucine (LL), and diisoleucine (II)) are considered. The main features and properties of these dipeptide structures and peptide nanotubes (PNTs), based on them, are investigated using computational molecular modeling and quantum-chemical semi-empirical calculations. Their polar, piezoelectric, and photoelectronic properties and features are studied in detail. The results of calculations of dipole moments and polarization, as well as piezoelectric coefficients and band gap width, for different types of helical peptide nanotubes are presented. The calculated values of the chirality indices of various nanotubes are given, depending on the chirality of the initial dipeptides-the results obtained are consistent with the law of changes in the type of chirality as the hierarchy of molecular structures becomes more complex. The influence of water molecules in the internal cavity of nanotubes on their physical properties is estimated. A comparison of the results of these calculations by various computational methods with the available experimental data is presented and discussed.MethodThe main tool for molecular modeling of all studied nanostructures in this work was the HyperChem 8.01 software package. The main approach used here is the Hartree-Fock (HF) self-consistent field (SCF) with various quantum-chemical semi-empirical methods (AM1, PM3, RM1) in the restricted Hartree-Fock (RHF) and in the unrestricted Hartree-Fock (UHF) approximations. Optimization of molecular systems and the search for their optimal geometry is carried out in this work using the Polak-Ribeire algorithm (conjugate gradient method), which determines the optimized geometry at the point of their minimum total energy. For such optimized structures, dipole moments D and electronic energy levels (such as EHOMO and ELUMO), as well as the band gap Eg = ELUMO - EHOMO, were then calculated. For each optimized molecular structure, the volume was calculated using the QSAR program implemented also in the HyperChem software package.",Web of Science
"Chen, Michael S.; Morawietz, Tobias; Mori, Hideki; Markland, Thomas E.; Artrith, Nongnuch",AENET-LAMMPS and AENET-TINKER: Interfaces for accurate and efficient molecular dynamics simulations with machine learning potentials,2021,10.1063/5.0063880,https://doi.org/10.1063/5.0063880,Journal,JOURNAL OF CHEMICAL PHYSICS,"Machine-learning potentials (MLPs) trained on data from quantum-mechanics based first-principles methods can approach the accuracy of the reference method at a fraction of the computational cost. To facilitate efficient MLP-based molecular dynamics and Monte Carlo simulations, an integration of the MLPs with sampling software is needed. Here, we develop two interfaces that link the atomic energy network (AE net) MLP package with the popular sampling packages TINKER and LAMMPS. The three packages, AE net, TINKER, and LAMMPS, are free and open-source software that enable, in combination, accurate simulations of large and complex systems with low computational cost that scales linearly with the number of atoms. Scaling tests show that the parallel efficiency of the AE net-TINKER interface is nearly optimal but is limited to shared-memory systems. The AE net-LAMMPS interface achieves excellent parallel efficiency on highly parallel distributed-memory systems and benefits from the highly optimized neighbor list implemented in LAMMPS. We demonstrate the utility of the two MLP interfaces for two relevant example applications: the investigation of diffusion phenomena in liquid water and the equilibration of nanostructured amorphous battery materials.",Web of Science
"Borowka, S.; Heinrich, G.; Jahn, S.; Jones, S. P.; Kerner, M.; Schlenk, J.",A GPU compatible quasi-Monte Carlo integrator interfaced to pySecDec,2019,10.1016/j.cpc.2019.02.015,https://doi.org/10.1016/j.cpc.2019.02.015,Journal,COMPUTER PHYSICS COMMUNICATIONS,"The purely numerical evaluation of multi-loop integrals and amplitudes can be a viable alternative to analytic approaches, in particular in the presence of several mass scales, provided sufficient accuracy can be achieved in an acceptable amount of time. For many multi-loop integrals, the fraction of time required to perform the numerical integration is significant and it is therefore beneficial to have efficient and well-implemented numerical integration methods. With this goal in mind, we present a new stand-alone integrator based on the use of (quasi-Monte Carlo) rank-1 shifted lattice rules. For integrals with high variance we also implement a variance reduction algorithm based on fitting a smooth function to the inverse cumulative distribution function of the integrand dimension-by-dimension.Additionally, the new integrator is interfaced to pySEcDEc to allow the straightforward evaluation of multi-loop integrals and dimensionally regulated parameter integrals. In order to make use of recent advances in parallel computing hardware, our integrator can be used both on CPUs and CUDA compatible GPUs where available.Program summaryProgram Title: pySecDec, qmcProgram Files doi: http://dx.doi.org/10. 17632/dnrkf5jxzh.2Licensing provisions: GNU General Public License v3Programming language: python, FORM, C++, CUDAExternal routines/libraries: catch [1], gsl [2], numpy [3], sympy [4], Nauty [5], Cuba [6], FORM [7], Normaliz [8]. The program can also be used in a mode which does not require Normaliz.Journal reference of previous version: Comput. Phys. Commun. 222 (2018) 313-326.Does the new version supersede the previous version?: YesNature of problem: Extraction of ultraviolet and infrared singularities from parametric integrals appearing in higher order perturbative calculations in quantum field theory. Numerical integration in the presence of integrable singularities (e.g. kinematic thresholds).Solution method: Algebraic extraction of singularities within dimensional regularization using iterated sector decomposition. This leads to a Laurent series in the dimensional regularization parameter is an element of (and optionally other regulators), where the coefficients are finite integrals over the unit-hypercube. Those integrals are evaluated numerically by Monte Carlo integration. The integrable singularities are handled by choosing a suitable integration contour in the complex plane, in an automated way. The parameter integrals forming the coefficients of the Laurent series in the regulator(s) are provided in the form of libraries which can be linked to the calculation of (multi-) loop amplitudes.Restrictions: Depending on the complexity of the problem, limited by memory and CPU/CPU time.References:[1] https://github.com/philsquared/Catch/.[2] http://www.gnu.org/software/gsl/.[3] http://www.numpy.org/.[4] http://www.sympy.org/.[5] http://pallini.di.uniromal.it/.[6] T. Hahn, CUBA: A Library for multidimensional numerical integration, Comput. Phys. Commun. 168 (2005) 78 [hep-ph/0404043], http://www.feynarts.de/cuba/.[7] J. Kuipers, T. Ueda and J. A. M. Vermaseren, Code Optimization in FORM, Comput. Phys. Commun. 189 (2015) 1 [arXiv:1310.7007], http://www.nikhef.nl/-form/.[8] W. Bruns, B. lchim, B. and T. Romer, C. Roger, Normaliz. Algorithms for rational cones and affine monoids. http://www.math.uos.de/normaliz/. (C) 2019 The Authors. Published by Elsevier B.V.",Web of Science
"Liu, Xiaoyu; Bharos, Niv; Markovich, Liubov; Borregaard, Johannes",Error correlations in photonic qudit-mediated entanglement generation,2024,10.1103/PhysRevResearch.6.023075,https://doi.org/10.1103/PhysRevResearch.6.023075,Journal,PHYSICAL REVIEW RESEARCH,"Generating entanglement between distributed network nodes is a prerequisite for the quantum internet. Entanglement distribution protocols based on high-dimensional photonic qudits enable the simultaneous generation of multiple entangled pairs, which can significantly reduce the required coherence time of the qubit registers. However, current schemes require fast optical switching, which is experimentally challenging. In addition, the higher degree of error correlation between the generated entangled pairs in qudit protocols compared to qubit protocols has not been widely studied in detail. We propose a qudit-mediated entangling protocol that completely circumvents the need for optical switches at the expense of a lower success probability of the scheme. Furthermore, we quantify the amount of error correlation between the simultaneously generated entangled pairs and analyze the effect on entanglement purification algorithms and teleportation-based quantum error correction. We find that optimized purification schemes can efficiently correct the correlated errors, while the quantum error correction codes studied here perform worse than for uncorrelated error models.",Web of Science
"Caforio, Andrea; Balli, Fatih; Banik, Subhadeep",Melting SNOW-V: improved lightweight architectures,2022,10.1007/s13389-020-00251-6,https://doi.org/10.1007/s13389-020-00251-6,Journal,JOURNAL OF CRYPTOGRAPHIC ENGINEERING,"SNOW-V is a stream cipher proposed by Ekdahl et al. at IACR ToSC 2019(3) with an objective to be deployed as the encryption primitive in 5G systems. The stream cipher offers 256-bit security and is ready for deployment in the post-quantum era, in which as a rule of thumb (due to Grover's algorithm), quantum security will vary as the square root of the classical security parameters. The authors further report good software performance figures in systems supporting the AES-NI instruction set. However, they only provide a theoretical analysis of the cipher's hardware efficiency. In this paper, we aim to fill this gap. We look at the three most important metrics of hardware efficiency: area, speed and power/energy, and propose circuits that optimize each of these metrics and validate our results using three different standard cell libraries. The smallest SNOW-V circuit we propose occupies only around 4776 gate equivalents of silicon area. Furthermore, we also report implementations which consume as little as 12.7 pJ per 128 bits of keystream and operate at a throughput rate of more than 1 Tbps.",Web of Science
"Burger, Michael; Nguyen, Giang Nam; Bischof, Christian",SimAnMo-A parallelized runtime model generator,2022,10.1002/cpe.6771,https://doi.org/10.1002/cpe.6771,Journal,CONCURRENCY AND COMPUTATION-PRACTICE & EXPERIENCE,"In this article, we present the novel features of the recent version of SimAnMo, the Simulated Annealing Modeler. The tool creates models that correlate the size of one input parameter of an application to the corresponding runtime and thus SimAnMo allows predictions for larger input sizes. A focus lies on applications whose runtime grows exponentially in the input parameter size. Such programs are, for example, of high interest for cryptanalysis to analyze practical security of traditional and post-quantum secure schemes. However, SimAnMo also generates reliable models for the widespread case of polynomial runtime behavior and also for the important case of factorial runtime increase. SimAnMo's model generation is based on a parallelized simulated annealing procedure and heuristically minimizes the costs of a model. Those may rely on different quality metrics. Insights into SimAnMo's software design and its usage are provided. We demonstrate the quality of SimAnMo's models for different algorithms from various application fields. We show that our approach also works well on ARM architectures.",Web of Science
"McGill, Charles; Forsuelo, Michael; Guan, Yanfei; Green, William H.",Predicting Infrared Spectra with Message Passing Neural Networks,2021,10.1021/acs.jcim.1c00055,https://doi.org/10.1021/acs.jcim.1c00055,Journal,JOURNAL OF CHEMICAL INFORMATION AND MODELING,"Infrared (IR) spectroscopy remains an important tool for chemical characterization and identification. Chemprop-IR has been developed as a software package for the prediction of IR spectra through the use of machine learning. This work serves the dual purpose of providing a trained general-purpose model for the prediction of IR spectra with ease and providing the Chemprop-IR software framework for the training of new models. In Chemprop-IR, molecules are encoded using a directed message passing neural network, allowing for molecule latent representations to be learned and optimized for the task of spectral predictions. Model training incorporates spectra metrics and normalization techniques that offer better performance with spectral predictions than standard practice in regression models. The model makes use of pretraining using quantum chemistry calculations and ensembling of multiple submodels to improve generalizability and performance. The spectral predictions that result are of high quality, showing capability to capture the extreme diversity of spectral forms over chemical space and represent complex peak structures.",Web of Science
"Liu, Zhe; Li, Shurong",A numerical method for interval multi-objective mixed-integer optimal control problems based on quantum heuristic algorithm,2022,10.1007/s10479-021-03998-1,https://doi.org/10.1007/s10479-021-03998-1,Journal,ANNALS OF OPERATIONS RESEARCH,"This article is concerned with the numerical solution for a class of interval multi-objective mixed-integer optimal control problems (IMOMIOCPs). The IMOMIOCPs under investigation are typical NP-hard problems involve unknown-but-bounded interval parameters, multiple objectives, and mixed-integer dynamic controls. Accordingly, a new numerical method based on quantum heuristic algorithm is designed, which has the following modules: (i) Control vector parameterization and the fourth order Runge-Kutta method for model discretization, (ii) interval programming based on interval credibility for addressing interval parameters, (iii) coevolution of Quantum Annealing and Quantum Krill Herd for searching the optimal mixed-integer decisions, and (iv) the multiple populations for multi-objective technology for establishing the Pareto optimal front. The analyses on convergence and computational complexity of the proposed optimization mechanism are given. Moreover, simulation results on benchmark functions and a practical engineering IMOMIOCP verify that the proposed numerical method is more excel at achieving promising results than some classic algorithms and state-of-the-art algorithms.",Web of Science
"Nardin, Antonella; D'Andreagiovanni, Fabio",A Quantum-Inspired Ant Colony Optimization Algorithm for Parking Lot Rental to Shared E-Scooter Services,2024,10.3390/a17020080,https://doi.org/10.3390/a17020080,Journal,ALGORITHMS,"Electric scooter sharing mobility services have recently spread in major cities all around the world. However, the bad parking behavior of users has become a major source of issues, provoking accidents and compromising urban decorum of public areas. Reducing wild parking habits can be pursued by setting reserved parking spaces. In this work, we consider the problem faced by a municipality that hosts e-scooter sharing services and must choose which locations in its territory may be rented as reserved parking lots to sharing companies, with the aim of maximizing a return on renting and while taking into account spatial consideration and parking needs of local residents. Since this problem may result difficult to solve even for a state-of-the-art optimization software, we propose a hybrid metaheuristic solution algorithm combining a quantum-inspired ant colony optimization algorithm with an exact large neighborhood search. Results of computational tests considering realistic instances referring to the Italian capital city of Rome show the superior performance of the proposed hybrid metaheuristic.",Web of Science
"Belov, Mikhail Gennadievich; Malyshkin, Vladislav Gennadievich",Partially unitary learning,2024,10.1103/PhysRevE.110.055306,https://doi.org/10.1103/PhysRevE.110.055306,Journal,PHYSICAL REVIEW E,"The problem of an optimal mapping between Hilbert spaces IN of |' and OUT of |phi based on a set of wavefunction measurements (within a phase) ' l -> phi l , l = 1, ... , M , is formulated as an optimization problem maximizing the total fidelity Ml = 1 omega ( l ) |phi l | U |'l|2 subject to probability preservation constraints on U (partial unitarity). The constructed operator U can be considered as an IN to OUT quantum channel; it is a partially unitary rectangular matrix (an isometry) of dimension dim(OUT) x dim(IN) transforming operators as A OUT = UA IN U dagger . An iterative algorithm for finding the global maximum of this optimization problem is developed, and its application to a number of problems is demonstrated. A software product implementing the algorithm is available from the authors.",Web of Science
"Wang, Han; Zhang, Linfeng; Han, Jiequn; E, Weinan",DeePMD-kit: A deep learning package for many-body potential energy representation and molecular dynamics,2018,10.1016/j.cpc.2018.03.016,https://doi.org/10.1016/j.cpc.2018.03.016,Journal,COMPUTER PHYSICS COMMUNICATIONS,"Recent developments in many-body potential energy representation via deep learning have brought new hopes to addressing the accuracy-versus-efficiency dilemma in molecular simulations. Here we describe DeePMD-kit, a package written in Python/C++ that has been designed to minimize the effort required to build deep learning based representation of potential energy and force field and to perform molecular dynamics. Potential applications of DeePMD-kit span from finite molecules to extended systems and from metallic systems to chemically bonded systems. DeePMD-kit is interfaced with TensorFlow, one of the most popular deep learning frameworks, making the training process highly automatic and efficient. On the other end, DeePMD-kit is interfaced with high-performance classical molecular dynamics and quantum (path-integral) molecular dynamics packages, i.e., LAMMPS and the i-PI, respectively. Thus, upon training, the potential energy and force field models can be used to perform efficient molecular simulations for different purposes. As an example of the many potential applications of the package, we use DeePMD-kit to learn the interatomic potential energy and forces of a water model using data obtained from density functional theory. We demonstrate that the resulted molecular dynamics model reproduces accurately the structural information contained in the original model.Program summaryProgram Title: DeePMD-kitProgram Files doi: http://dx.doi.org/10.17632/hvfh9yvncf.1Licensing provisions: LGPLProgramming language: Python/C++Nature of problem: Modeling the many-body atomic interactions by deep neural network models. Running molecular dynamics simulations with the models.Solution method: The Deep Potential for Molecular Dynamics (DeePMD) method is implemented based on the deep learning framework TensorFlow. Supports for using a DeePMD model in LAMMPS and i-PI, for classical and quantum (path integral) molecular dynamics are provided.Additional comments including Restrictions and Unusual features: The code defines a data protocol such that the energy, force, and virial calculated by different third-party molecular simulation packages can be easily processed and used as model training data. (C) 2018 Elsevier B.V. All rights reserved.",Web of Science
"Zhao, Huimin; Deng, Wu; Yang, Xinhua; Li, Xiumei; Li, Zhengguang",Study on a novel fault diagnosis method based on information fusion method,2016,10.21595/jve.2016.16859,https://doi.org/10.21595/jve.2016.16859,Journal,JOURNAL OF VIBROENGINEERING,"For the low accuracy and calculation speed of traditional fault diagnosis methods, the chaos optimization algorithm (COA), quantum particle swarm optimization (QPSO) algorithm and support vector machine (SVM) are introduced into the fault diagnosis to propose a novel fault diagnosis (CQPSMFD) method in this paper. In the proposed CQPSMFD method, the COA is used to initialize the parameters of the QPSO algorithm in order to obtain the CQPSO algorithm with the better convergence speed. Then the CQPSO algorithm is used to optimize the parameters of the SVM model to construct a high-precision SVM model (CQPSM) with the higher accuracy and stronger generalization ability. Next, the CQPSMFD method based on CQPSM method is proposed for motor. Finally, the experiment data from Case Western bearing dataset and actual motor are selected to verify the CQPSMFD method. The results show that the CQPSO algorithm can obtain the optimal parameter combination and the CQPSMFD method can effectively improve the fault diagnosis accuracy and speed.",Web of Science
"Ning, Tao; Gou, Tao; Zhang, Peng",Disruption management strategy of terminal logistics under accidental travel time delay based on prospect theory,2019,10.3233/JIFS-190916,https://doi.org/10.3233/JIFS-190916,Journal,JOURNAL OF INTELLIGENT & FUZZY SYSTEMS,"Focus on the distribution vehicle scheduling problem under travel time delay, a series of rescue modes generalized from practical vehicle planner' experiences were presented. The measurement method of value function based on prospect theory and the disruption management strategy of customer's psychological perception are put forward in this paper. A multi-objective optimization model for disruption management of logistics distribution is established through multi-objective programming at first. Next, the idea of gradual optimization for the target to obtain the terminal logistics distribution adjustment scheme with minimum disturbance is introduced. Acting the customer's psychological perception time as the reference point, the degree of the customer's psychological perception of the expected time of goods is measured with the prospect theory. In order to optimize the disruption management model and search the optimum solution of multi-objective optimization problem, an improved quantum bacterial foraging algorithm is proposed. The effectiveness and practicability of the proposed method is verified through the comparison and analysis with rescheduling method.",Web of Science
"Young, Stefano; Bakic, Predrag R.; Myers, Kyle J.; Jennings, Robert J.; Park, Subok",A virtual trial framework for quantifying the detectability of masses in breast tomosynthesis projection data,2013,10.1118/1.4800501,https://doi.org/10.1118/1.4800501,Journal,MEDICAL PHYSICS,"Purpose: Digital breast tomosynthesis (DBT) is a promising breast cancer screening tool that has already begun making inroads into clinical practice. However, there is ongoing debate over how to quantitatively evaluate and optimize these systems, because different definitions of image quality can lead to different optimal design strategies. Powerful and accurate tools are desired to extend our understanding of DBT system optimization and validate published design principles.Methods: The authors developed a virtual trial framework for task-specific DBT assessment that uses digital phantoms, open-source x-ray transport codes, and a projection-space, spatial-domain observer model for quantitative system evaluation. The authors considered evaluation of reconstruction algorithms as a separate problem and focused on the information content in the raw, unfiltered projection images. Specifically, the authors investigated the effects of scan angle and number of angular projections on detectability of a small (3 mm diameter) signal embedded in randomly-varying anatomical backgrounds. Detectability was measured by the area under the receiver-operating characteristic curve (AUC). Experiments were repeated for three test cases where the detectability-limiting factor was anatomical variability, quantum noise, or electronic noise. The authors also juxtaposed the virtual trial framework with other published studies to illustrate its advantages and disadvantages.Results: The large number of variables in a virtual DBT study make it difficult to directly compare different authors' results, so each result must be interpreted within the context of the specific virtual trial framework. The following results apply to 25% density phantoms with 5.15 cm compressed thickness and 500 mu m(3) voxels (larger 500 mu m(2) detector pixels were used to avoid voxel-edge artifacts): 1. For raw, unfiltered projection images in the anatomical-variability-limited regime, AUC appeared to remain constant or increase slightly with scan angle. 2. In the same regime, when the authors fixed the scan angle, AUC increased asymptotically with the number of projections. The threshold number of projections for asymptotic AUC performance depended on the scan angle. In the quantum- and electronic-noise dominant regimes, AUC behaviors as a function of scan angle and number of projections sometimes differed from the anatomy-limited regime. For example, with a fixed scan angle, AUC generally decreased with the number of projections in the electronic-noise dominant regime. These results are intended to demonstrate the capabilities of the virtual trial framework, not to be used as optimization rules for DBT.Conclusions: The authors have demonstrated a novel simulation framework and tools for evaluating DBT systems in an objective, task-specific manner. This framework facilitates further investigation of image quality tradeoffs in DBT. (c) 2013 American Association of Physicists in Medicine.",Web of Science
Ning Tao; Shi Shishasha; Zhang Peng; Gou Tao,Disruption management decision model for VRPSDP under changes of customer distribution demand,2021,10.1007/s12652-020-02304-4,https://doi.org/10.1007/s12652-020-02304-4,Journal,JOURNAL OF AMBIENT INTELLIGENCE AND HUMANIZED COMPUTING,"In order to solve the disruption of vehicle routing problem with simultaneous delivery and pickup (VRPSDP), a two-stage disruption management method based on the changes of customer demand is proposed. Firstly, a mathematical model of the problem is established to minimize the distribution cost and time window deviation, then to identify the disruption caused by the change of the original distribution scheme. Next, considering the strong global searching ability of bacteria foraging algorithm a hybrid quantum bacterial foraging scheduling algorithm (HQBFO) is designed combing with the advantages of superposition and parallelism of quantum computing. At last, the validity of the model and algorithm is tested by Solomon standard example and simulation test. The comparison with the global rescheduling scheme and additional vehicle scheme verifies the effectiveness of the proposed disruption management and improvement of the quantum algorithm performance.",Web of Science
"Saunders, Matthew; Wineman-Fisher, Vered; Jakobsson, Eric; Varma, Sameer; Pandit, Sagar A.",High-Dimensional Parameter Search Method to Determine Force Field Mixing Terms in Molecular Simulations,2022,10.1021/acs.langmuir.1c03105,https://doi.org/10.1021/acs.langmuir.1c03105,Journal,LANGMUIR,"Molecular dynamics (MD) force fields for lipids and ions are typically developed independently of one another. In simulations consisting of both lipids and ions, lipid-ion interaction energies are estimated using a predefined set of mixing rules for Lennard-Jones (LJ) interactions. This, however, does not guarantee their reliability. In fact, compared to the quantum mechanical reference data, Lorentz-Berthelot mixing rules substantially underestimate the binding energies of Na+ ions with small-molecule analogues of lipid headgroups, yielding errors on the order of 80 and 130 kJ/mol, respectively, for methyl acetate and diethyl phosphate. Previously, errors associated with mixing force fields have been reduced using approaches such as NB-fix in which LJ interactions are computed using explicit cross terms rather than those from mixing rules. Building on this idea, we derive explicit lipid-ion cross terms that also may implicitly include many-body cooperativity effects. Additionally, to account for the interdependency between cross terms, we optimize all cross terms simultaneously by performing high-dimensional searches using our ParOpt software. The cross terms we obtain reduce the errors due to mixing rules to below 10 kJ/mol. MD simulation of the lipid bilayer conducted using these optimized cross terms resolves the structural discrepancies between our previous simulations and small-angle X-ray and neutron scattering experiments. These results demonstrate that simulations of lipid bilayers with ions that are accurate up to structural data from scattering experiments can be performed without explicit polarization terms. However, it is worth noting that such NB-fix cross terms are not based on any physical principle; a polarizable lipid model would be more realistic and is still desired. Our approach is generic and can be applied to improve the accuracies of simulations employing mixed force fields.",Web of Science
"Li, Yangyang; Bai, Xiaoyu; Jiao, Licheng; Xue, Yu",Partitioned-cooperative quantum-behaved particle swarm optimization based on multilevel thresholding applied to medical image segmentation,2017,10.1016/j.asoc.2017.03.018,https://doi.org/10.1016/j.asoc.2017.03.018,Journal,APPLIED SOFT COMPUTING,"In this paper, in order to search the global optimum solution with a very fast convergence speed across the whole search space, we propose a partitioned and cooperative quantum-behaved particle swarm optimization (SCQPSO) algorithm. The auxiliary swarms and partitioned search space are introduced to increase the population diversity. The cooperative theory is introduced into QPSO algorithm to change the updating mode of the particles in order to guarantee that this algorithm well balances the effectiveness and simplification. Firstly, we explain how this method leads to enhanced population diversity and improved algorithm over previous strategies, and emphasize this algorithm with comparative experiments using five benchmark test functions and five shift complex functions. After that we demonstrate a reasonable application of the proposed algorithm, by showing how it can be used to optimize the parameters for OTSU image segmentation for processing medical images. The results show that the proposed SCQPSO algorithm outperforms than the other improved QPSO in terms of the quality of the solution, and performs better for solving the image segmentation than the QPSO algorithm, the sunCQPSO algorithm, the CCQPSO algorithm. (C) 2017 Elsevier B.V. All rights reserved.",Web of Science
"Zhang, Jiang; Yu, Yu; Feng, Dengguo; Fan, Shuqin; Zhang, Zhenfeng","Committed-programming reductions: formalizations, implications and relations",2024,10.1007/s11432-022-3893-3,https://doi.org/10.1007/s11432-022-3893-3,Journal,SCIENCE CHINA-INFORMATION SCIENCES,"In this work, we introduce a class of black-box (BB) reductions called committed-programming reduction (CPRed) in the random oracle model (ROM) and obtain the following interesting results: (1) we demonstrate that some well-known schemes, including the full-domain hash (FDH) signature (Eurocrypt 1996) and the Boneh-Franklin identity-based encryption (IBE) scheme (Crypto 2001), are provably secure under CPReds; (2) we prove that a CPRed associated with an instance-extraction algorithm implies a reduction in the quantum ROM (QROM). This unifies several recent results, including the security of the Gentry-Peikert-Vaikuntanathan IBE scheme by Zhandry (Crypto 2012) and the key encapsulation mechanism (KEM) variants using the Fujisaki-Okamoto transform by Jiang et al. (Crypto 2018) in the QROM. Finally, we show that CPReds are incomparable to non-programming reductions (NPReds) and randomly-programming reductions (RPReds) formalized by Fischlin et al. (Asiacrypt 2010).",Web of Science
He Zhenxue; Wu Xiaoqian; Wang Chao; Huo Zhisheng; Xiao Limin; Wang Xiang,Delay optimization for ternary fixed polarity Reed-Muller circuits based on multilevel adaptive quantum genetic algorithm,2021,10.1002/int.22538,https://doi.org/10.1002/int.22538,Journal,INTERNATIONAL JOURNAL OF INTELLIGENT SYSTEMS,"Delay optimization has now emerged as an important optimization goal in logic synthesis. The delay optimization for ternary fixed polarity Reed-Muller (FPRM) circuits aims to find a ternary FPRM circuit with a minimum delay. Because the delay optimization for ternary FPRM circuits is a combinatorial optimization problem, in this paper, we first propose a multilevel adaptive quantum genetic algorithm (MAQGA), which divides individuals into three-level populations: high-level population, intermediate-level population, and low-level population and uses the proposed ternary quantum rotation gate, proposed ternary quantum correction gate, and proposed multi-operator adaptive mutation mechanism to make the three-level populations evolve. Moreover, based on the proposed delay decomposition strategy, we propose a delay optimization approach (DOA) for ternary FPRM circuits under the unit delay model, which searches for a ternary FPRM circuit with a minimum delay using the MAQGA. Experimental results demonstrated the effectiveness and superiority of the DOA in optimizing the delay of ternary FPRM circuits.",Web of Science
"Schmidt, Burkhard; Hartmann, Carsten","WavePacket: A Matlab package for numerical quantum dynamics. II: Open quantum systems, optimal control, and model reduction",2018,10.1016/j.cpc.2018.02.022,https://doi.org/10.1016/j.cpc.2018.02.022,Journal,COMPUTER PHYSICS COMMUNICATIONS,"WavePacket is an open-source program package for numeric simulations in quantum dynamics. It can solve time-independent or time-dependent linear Schrodinger and Liouville-von Neumann-equations in one or more dimensions. Also coupled equations can be treated, which allows, e.g., to simulate molecular quantum dynamics beyond the Born-Oppenheimer approximation. Optionally accounting for the interaction with external electric fields within the semi-classical dipole approximation, WavePacket can be used to simulate experiments involving tailored light pulses in photo-induced physics or chemistry. Being highly versatile and offering visualization of quantum dynamics 'on the fly', WavePacket is well suited for teaching or research projects in atomic, molecular and optical physics as well as in physical or theoretical chemistry. Building on the previous Part I [Comp. Phys. Comm. 213, 223-234 (2017)] which dealt with closed quantum systems and discrete variable representations, the present Part II focuses on the dynamics of open quantum systems, with Lindblad operators modeling dissipation and dephasing. This part also describes the WavePacket function for optimal control of quantum dynamics, building on rapid monotonically convergent iteration methods. Furthermore, two different approaches to dimension reduction implemented in WavePacket are documented here. In the first one, a balancing transformation based on the concepts of controllability and observability Gramians is used to identify states that are neither well controllable nor well observable. Those states are either truncated or averaged out. In the other approach, the H2-error for a given reduced dimensionality is minimized by H2 optimal model reduction techniques, utilizing a bilinear iterative rational Krylov algorithm.The present work describes the MATLAB version of WavePacket 5.3.0 which is hosted and further developed at the Sourceforge platform, where also extensive Wiki-documentation as well as numerous worked-out demonstration examples with animated graphics can be found.Program summaryProgram Title: WAVEPACKETProgram Files doi: http://dx.doi.org/10.17632/9g8b7jychy.1Licensing provisions: GPLv3Programming language: MATLABJournal reference of previous version: Comput. Phys. Comm. 213 (2017), 223.Does the new version supersede the previous version?: The previous article focused on the treatment of closed quantum systems by discrete variable representations and implementation of various numerical algorithms for solving Schrobdinger's equations. Complementary to that, the present second part is concerned with open quantum systems and optimal control by external fields. In addition, two approaches to dimension reduction useful in modeling of quantum control are described.Reasons for the new version: The reason for having a second article on the WavePacket software package lies in the fact that a complete description of the package would have exceeded the scope of a regular article. Several significant features of the WAVEPACKET package are introduced here which could not be mentioned in the first article, due to length constraints.Summary of revisions: Here we describe the numerical treatment of open quantum systems dynamics modeled by Lindblad master equations. Moreover, we explain the WAVEPACKET functions for optimal control simulations, both for closed and open quantum systems. To address the problem of computational effort, two strategies for model reduction have been included.Nature of problem: Dynamics of closed and open systems are described by Schrodinger or Liouvillevon Neumann equations, respectively, where the latter ones will be restricted to the Lindblad master equation. Emphasis is on the interaction of quantum system with external electric fields, treated within the semi-classical dipole approximation. Quantum optimal control simulations are used for the design of tailored fields achieving specified targets in quantum dynamics. With these features, WAVEPACKET can be instrumental for the simulation, understanding, and prediction of modern experiments in atomic, molecular and optical physics involving temporally shaped fields.Solution method: Representing state vectors or reduced density matrices in a discrete basis, SchrOdinger or Liouville-von Neumann equations are cast into systems of ordinary differential equations. Those are treated by self-written or MATLAB'S built-in solvers, the latter ones offering adaptive time-stepping. The optimal control equations are solved by the rapid monotonically convergent iteration methods developed by Zhu, Rabitz, Ohtsuki and others. In order to reduce the dimensionality of large scale control problems, the balanced truncation method as well as H2-optimal model reduction approaches are available in WAVEPACKET.Additional comments including restrictions and unusual features: The WAVEPACKET program package is rather easy and intuitive to use, providing visualization of quantum dynamics 'on the fly'. It is mainly intended for low-dimensional systems, typically not exceeding three to five degrees of freedom. Detailed user guides and reference manuals are available through numerous Wiki pages hosted at the SOURCEFORGE platform where also a large number of well documented demonstration examples can be found. (C) 2018 Elsevier B.V. All rights reserved.",Web of Science
"Yan, Wei; Li, Mei-Jing; Mei, Na; Qu, Chun-Yan; Wang, Yuan; Liu, Li-Ping",Control strategy research of electric vehicle thermal management system based on MGA-SVR algorithm,2023,10.1177/00202940221105851,https://doi.org/10.1177/00202940221105851,Journal,,"The thermal management system is one of the important assemblies that ensure the secure operation of electric vehicles (EVs). Using intelligent algorithms to optimize the control strategy of the thermal management system can reduce energy consumption under the premise of effective heat dissipation of EVs. This paper attempts to construct the control strategy of EV thermal management system by coupling the modified genetic algorithm (MGA) and support vector regression (SVR). Firstly, the double-population adaptive mutation method and a novel optimization process are adopted to obtain MGA. Afterward, the performance of MGA is verified by four benchmark functions compared with three typical algorithms, which are genetic algorithm (GA), double-population genetic algorithm (DPGA), and quantum genetic algorithm (QGA). The results demonstrate that the accuracy and stability of MGA are obviously better than the other three algorithms. Secondly, MGA is applied to modify parameters of SVR kernel function, and the accuracy of MGA-SVR algorithm is verified by the Auto-MPG and Computer Hardware data sets. The mean square deviations of the SVR algorithm test set are 0.0186 and 0.0806, respectively, and the mean square deviations of the MGA-SVR algorithm test set are 0.0099 and 0.0054, respectively, which fully shows that MGA-SVR have more accurate forecasting capabilities. Finally, the thermal management system model of EV is built by the one-dimensional simulation software KULI. Under the Chinese working condition, fan speed which meets the cooling requirements of the motor and controller is obtained from the KULI model, and the database is constructed. Then, MGA-SVR is trained by database and employed to predict fan speed under the Chinese working condition and obtain control strategy of the thermal management system. Compared with traditional control strategy, the thermal management system based on MGA-SVR control strategy can not only meet the radiating requirements, but also effectively reduce the power consumption of fans.",Web of Science
"Zhang, De-gan; Cui, Yu-ya; Zhang, Ting",New quantum-genetic based OLSR protocol (QG-OLSR) for Mobile Ad hoc Network,2019,10.1016/j.asoc.2019.03.053,https://doi.org/10.1016/j.asoc.2019.03.053,Journal,APPLIED SOFT COMPUTING,"Due to the mobility, self-organization and distributed control of Mobile Ad hoc Network (MANET), the routing protocol of MANET must adapt to the rapid changes of the network structure, and ensure the maximum savings of network resources. This paper proposes a kind of new quantum-genetic based OLSR protocol (QG-OLSR) for MANET. The protocol adopts the MPR (multi-point relay) technology in OLSR (Optimal Link State Routing). By embedding new augmented Q-Learning algorithm and combining the OLSR algorithm to optimize the selection of MPR sets, it can effectively reduce the consumption of network topology control, improve the delivery rate of data packets, and reduce the time delay of the end-to-end packet transmission between nodes. The results of the experimental testings show that the new protocol is reliable and highly efficient, which is suitable for many applications of MANET. (C) 2019 Elsevier B.V. All rights reserved.",Web of Science
"Liu, Wen-Jie; Gao, Pei-Pei; Yu, Wen-Bin; Qu, Zhi-Guo; Yang, Ching-Nung",Quantum Relief algorithm,2018,10.1007/s11128-018-2048-x,https://doi.org/10.1007/s11128-018-2048-x,Journal,QUANTUM INFORMATION PROCESSING,"Relief algorithm is a feature selection algorithm used in binary classification proposed by Kira and Rendell, and its computational complexity remarkably increases with both the scale of samples and the number of features. In order to reduce the complexity, a quantum feature selection algorithm based on Relief algorithm, also called quantum Relief algorithm, is proposed. In the algorithm, all features of each sample are superposed by a certain quantum state through the CMP and rotation operations, then the swap test and measurement are applied on this state to get the similarity between two samples. After that, Near-hit and Near-miss are obtained by calculating the maximal similarity, and further applied to update the feature weight vector WT to get (WT) over bar that determine the relevant features with the threshold tau. In order to verify our algorithm, a simulation experiment based on IBM Q with a simple example is performed. Efficiency analysis shows the computational complexity of our proposed algorithm is O(M), while the complexity of the original Relief algorithm is O(NM), where N is the number of features for each sample, and M is the size of the sample set. Obviously, our quantum Relief algorithm has superior acceleration than the classical one.",Web of Science
"Mendolicchio, Marco; Penocchio, Emanuele; Licari, Daniele; Tasinato, Nicola; Barone, Vincenzo",Development and Implementation of Advanced Fitting Methods for the Calculation of Accurate Molecular Structures,2017,10.1021/acs.jctc.7b00279,https://doi.org/10.1021/acs.jctc.7b00279,Journal,JOURNAL OF CHEMICAL THEORY AND COMPUTATION,"The determination of accurate equilibrium molecular structures plays a fundamental role for understanding many physical-chemical properties of molecules, ranging from the precise evaluation of the electronic structure to the analysis of dynamical and environmental effects in tuning their overall behavior. For this purpose the so-called semiexperimental approach, based on a nonlinear least-squares fit of the moments of inertia associated with a set of available isotopologues, allows one to obtain very accurate results, without the unfavorable computational cost characterizing high-level quantum chemical methods. In the present work the MSR (Molecular Structure Refinement) software for the determination of equilibrium structures by means of the semiexperimental approach is presented, and its implementation is discussed in some detail. The software, which is interfaced with a powerful graphical user interface, includes different optimization algorithms, an extended error analysis, and a number of advanced features, the most remarkable ones concerning the choice of internal coordinates and the method of predicate observations. In particular, a new black-box scheme for defining automatically a suitable set of nonredundant internal coordinates of Al symmetry in place of the customary Z-matrix has been designed and tested. Finally, the implementation of the method of the predicate observations is discussed and validated for a set of test molecules. As an original application, the method is employed for the determination of the semiexperimental structure for the most stable conformer of glycine.",Web of Science
"Lorenz, Jeanette Miriam",The quest for a practical quantum advantage or the importance of applications for quantum computing,2024,10.1142/S0217732324300064,https://doi.org/10.1142/S0217732324300064,Journal,MODERN PHYSICS LETTERS A,"Quantum computing as emerging technology raises high expectations to accelerate complicated calculations, superseding capabilities of presently available supercomputers and to provide a solution to the ever-increasing challenge of processing big amount of data. Besides theoretical promises, quantum computers have successfully been realized in experimental settings during the past few years, and can now also be accessed commercially. Given this availability of quantum computers, their application potential can be scrutinized. Promised to lead to disruptive changes in addressing and solving problems from the domains of simulation, optimization and machine learning, quantum computers have been researched in context of many application scenarios in industrial and academic setting in the recent years. However, it turns out that currently available quantum computers are still to small in size and limited in quality to fulfill the high hopes set in them at the moment. This review reflects on the current state of the technology coming from the perspective of the application, and indicates the developments required on hardware, software and algorithmic side to eventually make quantum computing beneficial for applications.",Web of Science
"Neira, David E. Bernal; Laird, Carl D.; Lueg, Laurens R.; Harwood, Stuart M.; Trenev, Dimitar; Venturelli, Davide",Utilizing modern computer architectures to solve mathematical optimization problems: A survey,2024,10.1016/j.compchemeng.2024.108627,https://doi.org/10.1016/j.compchemeng.2024.108627,Journal,COMPUTERS & CHEMICAL ENGINEERING,"Numerical algorithms to solve mathematical optimization problems efficiently are essential to applications in many areas of engineering and computational science. To solve optimization problems of ever-increasing scale and complexity, we need methods that exploit emerging hardware systems. However, the complexities of specific architectures and their impact on performance can be challenging. This article provides an overview of emerging hardware architectures and how they are used to solve mathematical optimization problems. We focus on parallel high -performance computing architectures, which are well-established yet challenging to employ for optimization, as well as digital quantum computing, which has recently gained attention due to its potential for transformative computational performance. Furthermore, we highlight several other emerging hardware architectures that may become relevant for mathematical optimization. We intend for this review to encourage the optimization and process engineering communities to increasingly consider both hardware and software developments in the pursuit of superior computational performance.",Web of Science
"Arouche, Tiago da Silva; Lobato, Julio Cesar Mendes; Borges, Rosivaldo dos Santos; de Oliveira, Mozaniel Santana; Neto, Antonio Maia de Jesus Chaves","Molecular interactions of the Omicron, Kappa, and Delta SARS-CoV-2 spike proteins with quantum dots of graphene oxide",2024,10.1007/s00894-024-05996-z,https://doi.org/10.1007/s00894-024-05996-z,Journal,JOURNAL OF MOLECULAR MODELING,"ContextThe Omicron, Kappa, and Delta variants are different strains of the SARS-CoV-2 virus. Graphene oxide quantum dots (GOQDs) represent a burgeoning class of oxygen-enriched, zero-dimensional materials characterized by their sub-20-nm dimensions. Exhibiting pronounced quantum confinement and edge effects, GOQDs manifest exceptional physical-chemical attributes. This study delves into the potential of graphene oxide quantum dots, elucidating their inherent properties pertinent to the surface structures of SARS-CoV-2, employing an integrated computational approach for the repositioning of inhibitory agents.MethodsFollowing rigorous adjustment tests, a spectrum of divergent bonding conformations emerged, with particular emphasis placed on identifying the conformation exhibiting optimal adjustment scores and interactions. The investigation employed molecular docking simulations integrating affinity energy evaluations, electrostatic potential clouds, molecular dynamics encompassing average square root calculations, and the computation of Gibbs-free energy. These values quantify the strength of interaction between GOQDs and SARS-CoV-2 spike protein variants. The receptor structures were optimized using the CHARM-GUI server employing force field AMBERFF14SB. The algorithm embedded in CHARMM offers an efficient interpolation scheme and automatic step size selection, enhancing the efficiency of the optimization process. The 3D structures of the ligands are constructed and optimized with density functional theory (DFT) method based on the most stable conformer of each binder. Autodock Vina Software (ADV) was utilized, where essential parameters were specified. Electrostatic potential maps (MEPs) provide a visual depiction of molecules' charge distributions and related properties. After this, molecular dynamics simulations employing the CHARM36 force field in Gromacs 2022.2 were conducted to investigate GOs' interactions with surface macromolecules of SARS-CoV-2 in an explicit aqueous environment. Furthermore, our investigation suggests that lower values indicate stronger binding. Notably, GO-E consistently showed the most negative values across interactions with different variants, suggesting a higher affinity compared to other GOQDs (GO-A to GO-D).",Web of Science
"Bond, Liam J.; Safavi-Naini, Arghavan; Minar, Jiri",Fast Quantum State Preparation and Bath Dynamics Using Non-Gaussian Variational Ansatz and Quantum Optimal Control,2024,10.1103/PhysRevLett.132.170401,https://doi.org/10.1103/PhysRevLett.132.170401,Journal,PHYSICAL REVIEW LETTERS,"Fast preparation of quantum many-body states is essential for myriad quantum algorithms and metrological applications. Here, we develop a new pathway for fast, nonadiabatic preparation of quantum many-body states that combines quantum optimal control with a variational Ansatz based on non-Gaussian states. We demonstrate our approach on the spin-boson model, a single spin interacting with the bath. We use a multipolaron Ansatz to prepare near-critical ground states. For one mode, we achieve a reduction in infidelity of up to approximate to 60 (approximate to 10) times compared to linear (optimized local adiabatic) ramps; for many modes, we achieve a reduction in infidelity of up to approximate to 5 times compared to nonadiabatic linear ramps. Further, we show that the typical control quantity, the leakage from the variational manifold, provides only a loose bound on the state's fidelity. Instead, in analogy to the bond dimension of matrix product states, we suggest a controlled convergence criterion based on the number of polarons. Finally, motivated by the possibility of realizations in trapped ions, we study the dynamics of a system with bath properties going beyond the paradigm of (sub- and/or super-) Ohmic couplings.",Web of Science
"Khakimov, Dmitry V.; Pivina, Tatyana S.",Is everything correct? The formation enthalpy estimation and data revision of nitrate and perchlorate salts,2023,10.1007/s00894-023-05477-9,https://doi.org/10.1007/s00894-023-05477-9,Journal,JOURNAL OF MOLECULAR MODELING,"Context Inmodern searches for the structure of high-energy-density compounds with highoperational, detonation,and physicochemical characteristics, a special place belongs to salts, whichhave a numberof significant advantages over neutral compounds. The development of this areaof HEDMis hampered by the lack of effective calculation schemes for estimating theenthalpy of formationDH(f)(0) of salts, as a key parameter in assessing theprospects for their use. Based on the author'smethod (MICCM), which is superior in accuracy to currently availablecalculation methods,the enthalpies of formation of various salts of nitrates and perchlorates for apromising classof high-energy amino-1,2,4-triazoles are calculated and the accuracy ofcalculations is estimatedby other methods. Relationships between the thermochemical characteristics ofsalts dependingon various cations are considered. Among the considered compounds, calculationsof theenthalpies of salts of three amino-1,2,4-triazoles showed a significantdiscrepancy with the experimentaldata.Methods CalculationsDH(f)(0)of salts were performed using three methods: volume-basethermodynamic (Jenkins/Bartlett-method), the method of adding of ions contributions (MAIC, Matyushin's method),and the method of ions and cocrystals contribution mixing (MICCM, Khakimov's method).Calculations by the MICCM method were carried out on the basis of quantum chemistrymethods (when estimating the enthalpies of formation in the gas phase) and the methodof atom-atom potentials (AAP) when calculating the enthalpy of sublimation ofsalts. We haveoptimized all the structures in the gas phase using the Becke three hybridexchange and Lee-Yang-Parrcorrelation functional with Grimme's dispersion correction, B3LYP-D2, and aug-cc-pVDZbasis set using the Gaussian16 software. The AAP calculations were performedusing theFitMEP software packages (for adjusting the charges of the molecularelectrostatic potential) andPMC (for the procedure for constructing crystal packings and searching foroptimal ones).",Web of Science
"Singh, Ajay K.; Farag, Youssef M. K.; Zheng, Zihe; Bakris, George L.",Clinical trial designs of emerging therapies for diabetic kidney disease (DKD),2024,10.1080/00325481.2024.2377529,https://doi.org/10.1080/00325481.2024.2377529,Journal,POSTGRADUATE MEDICINE,"Current evidence for medical therapies for diabetic kidney disease (DKD) is largely based on large-scale clinical trials. These trials, however, often exhibit heterogeneity in participant characteristics and baseline kidney function. These differences may lead to misinterpretation in clinical practice, such that treatment effects from different trials are directly compared and generalized to broader populations beyond the population in which each trial was conducted. This is particularly relevant if comparisons on efficacy and safety are made when the underlying study populations are distinctly different. Indeed, key clinical trials evaluating sodium-glucose transport protein-2 inhibitors (SGLT2i), non-steroidal mineralocorticoid receptor antagonist (nsMRA), and glucagon-like peptide-1 receptor agonist (GLP-1RA) differed in recruitment requirements (inclusion/exclusion criteria), resulting in differences in the severity of the underlying kidney disease as well as risk factor profiles. Moreover, these trials defined their primary and secondary outcomes differently. Collectively, these factors lead to distinct study populations with different baseline risks for DKD progression in the placebo arm in each clinical trial. Consequently, a direct head-to-head comparison of the treatment effect between treatments using relative risk measures from placebo-controlled clinical trials alone is not recommended. In addition, healthcare professionals should be equipped to understand the specific target population of clinical trials to avoid over-generalization when drawing conclusions from these trials.",Web of Science
"Yuan, Tianmeng; Liu, Dapeng; Yun, Fei; Cai, Jiwei; Sun, Jiayue",Quantum-enhanced multi-objective collaboration for wind and solar hydrogen storage optimization,2024,10.1007/s11082-023-05883-6,https://doi.org/10.1007/s11082-023-05883-6,Journal,OPTICAL AND QUANTUM ELECTRONICS,"In pursuit of the Dual Carbon Goals and to mitigate the adverse effects of power supply restrictions, a microgrid scheme integrating wind and solar power with hydrogen energy storage is proposed. This paper introduces the principles of system capacity configuration and establishes a mathematical model. This research offers a novel method for configuring wind and solar hydrogen storage systems called quantum-enhanced multi-objective collaboration. This work intends to address the complicated issues of achieving effective energy storage, reducing prices, and maximising renewable energy utilisation by leveraging the capabilities of quantum computing. A multi-objective capacity optimization configuration model for wind-solar-hydrogen energy storage is developed using Homer Pro software and an enhanced BAS-GA algorithm. Under off-grid operating conditions, the wind-solar-hydrogen energy storage system's capacity optimization configuration model is validated through practical examples. The results indicate that, in comparison to wind storage, solar storage, wind-solar storage, and wind-solar-diesel storage systems, the net present value and levelized cost of electricity of the wind-solar-hydrogen energy storage system decrease to 14.25 million RMB and 1.529 RMB/(kW h), respectively. The renewable energy utilization rate increases to 98.7%, and the load shedding rate decreases to 5.50%.",Web of Science
"Hu, Yunfeng; Chen, Huan; Wang, Ping; Chen, Hong; Ren, Luquan",Nonlinear model predictive controller design based on learning model for turbocharged gasoline engine of passenger vehicle,2018,10.1016/j.ymssp.2018.02.012,https://doi.org/10.1016/j.ymssp.2018.02.012,Journal,MECHANICAL SYSTEMS AND SIGNAL PROCESSING,"In this paper, a neural-network-based nonlinear model predictive control (NMPC) scheme is investigated to realize coordinated control over the throttle and wastegate of a turbocharged gasoline engine of a passenger vehicle. First, due to the presence of MAPs and the complex structure of the turbocharged engine, establishing a mechanism model for controller design is very complicated. Benefiting from a large amount of experimental data, a predictive model is learned by a neural network to predict the future dynamics of the engine air-path system, and the accuracy of this model is verified. Second, to address the system constraints and coupling, a nonlinear model predictive controller is proposed to track the desired intake manifold pressure and boost pressure for meeting the engine torque demand. Third, quantum-behaved particle swarm optimization (QPSO) is applied for optimization of the NMPC objective function to obtain a more accurate solution. Finally, the performance of the control system is tested using the commercial simulation software AMESim. (C) 2018 Elsevier Ltd. All rights reserved.",Web of Science
"De Bone, Sebastian; Ouyang, Runsheng; Goodenough, Kenneth; Elkouss, David",Protocols for Creating and Distilling Multipartite GHZ States With Bell Pairs,2020,10.1109/TQE.2020.3044179,https://doi.org/10.1109/TQE.2020.3044179,Journal,IEEE TRANSACTIONS ON QUANTUM ENGINEERING,"The distribution of high-quality Greenberger-Horne-Zeilinger (GHZ) states is at the heart of many quantum communication tasks, ranging from extending the baseline of telescopes to secret sharing. They also play an important role in error-correction architectures for distributed quantum computation, where Bell pairs can be leveraged to create an entangled network of quantum computers. We investigate the creation and distillation of GHZ states out of nonperfect Bell pairs over quantum networks. In particular, we introduce a heuristic dynamic programming algorithm to optimize over a large class of protocols that create and purify GHZ states. All protocols considered use a common framework based on measurements of nonlocal stabilizer operators of the target state (i.e., the GHZ state), where each nonlocal measurement consumes another (nonperfect) entangled state as a resource. The new protocols outperform previous proposals for scenarios without decoherence and local gate noise. Furthermore, the algorithms can be applied for finding protocols for any number of parties and any number of entangled pairs involved.",Web of Science
"Xue, RiXin; Tang, Peng; Fang, Shudong",A new method for logic optimization of QCA-based circuits using a golden ball algorithm,2022,10.1016/j.ijleo.2022.169403,https://doi.org/10.1016/j.ijleo.2022.169403,Journal,OPTIK,"Quantum-dot Cellular Automata (QCA) is an approach for constructing low-power digital circuits and various high-performance calculations at the nano-scale. This technique has little power dissipation due to its nature. Implementing circuits using QCA is an active research topic because of the necessary qualities, like short switching time, high device density, and comparatively low power. The primary gates in this technology are the inverter and majority gates, which can function as universal logic gates to build any circuit. This study provides an effective approach to synthesize multi-output Boolean functions using QCA circuits. Due to the NP-hard nature of the logic optimization problem, a golden ball algorithm-based method is utilized to decrease delay time and energy usage in the design process. The simulations utilizing MATLAB software are used to test the functionality of the suggested approach. The empirical findings indicate that the suggested technique performs better than prior methods in numerous instances.",Web of Science
"Xu, Zeyu; Yu, Wenbin; Zhang, Chengjun; Chen, Yadang",Quantum Convolutional Long Short-Term Memory Based on Variational Quantum Algorithms in the Era of NISQ,2024,10.3390/info15040175,https://doi.org/10.3390/info15040175,Journal,INFORMATION,"In the era of noisy intermediate-scale quantum (NISQ) computing, the synergistic collaboration between quantum and classical computing models has emerged as a promising solution for tackling complex computational challenges. Long short-term memory (LSTM), as a popular network for modeling sequential data, has been widely acknowledged for its effectiveness. However, with the increasing demand for data and spatial feature extraction, the training cost of LSTM exhibits exponential growth. In this study, we propose the quantum convolutional long short-term memory (QConvLSTM) model. By ingeniously integrating classical convolutional LSTM (ConvLSTM) networks and quantum variational algorithms, we leverage the variational quantum properties and the accelerating characteristics of quantum states to optimize the model training process. Experimental validation demonstrates that, compared to various LSTM variants, our proposed QConvLSTM model outperforms in terms of performance. Additionally, we adopt a hierarchical tree-like circuit design philosophy to enhance the model's parallel computing capabilities while reducing dependence on quantum bit counts and circuit depth. Moreover, the inherent noise resilience in variational quantum algorithms makes this model more suitable for spatiotemporal sequence modeling tasks on NISQ devices.",Web of Science
"Agrawal, Sonam; Gupta, Rajan Dev",Development of SOA-based WebGIS framework for education sector,2020,10.1007/s12517-020-05490-9,https://doi.org/10.1007/s12517-020-05490-9,Journal,ARABIAN JOURNAL OF GEOSCIENCES,"The applications of Geographic Information System (GIS) in the education sector are increasing day by day. The geospatial information can be published, discovered, searched, analyzed, and displayed through webGIS-based applications. Lack of an open source geospatial resource-based platform for data sharing, discovery, and service delivery in the education sector is a critical issue in managing the education of large population in India. The use of open geospatial consortium (OGC) developed open standards for geospatial web services will result in the interoperability of geographic information. In this paper, an interoperable and secure service-oriented architecture (SOA)-based webGIS framework is developed to handle the technical and non-technical issues in the education sector. In this research work, spatial analysis on schools is performed along with the design and development of webGIS framework using SOA, OGC standards, and open source software. The developed webGIS framework, acronym as EduGIS, is interoperable and secure which is implemented for the education sector. The development of webGIS framework is based upon three-tier thin client architecture. The present research work has investigated an optimized adoption of various free and open source software like Quantum GIS, GeoServer, Apache Tomcat, PostGIS, and uDig in different tiers of developed webGIS framework. The interoperability of developed EduGIS ensures that it can be shared across different technologies, data, platforms, and organizations. The development of open source-based webGIS framework will serve as a means of reducing licensing costs in developing countries like India and will promote indigenous technological development for primary education in rural areas.",Web of Science
"Xiang, Qiu-Yu; Li, Dong-Fen; Sun, Yu-Chen; Hu, Zhi-kang; Yuan, Yu-Hang; Hua, Xiao-Yu; Zhu, Yong-Hao; Fu, You; Jiang, Yang-Yang",Performance analysis of quantum convolutional layers for image classification,2024,10.1088/1402-4896/ad8d17,https://doi.org/10.1088/1402-4896/ad8d17,Journal,PHYSICA SCRIPTA,"In recent years, with the rapid development of quantum computing technology, the fusion of quantum computing and machine learning techniques is becoming a research hotspot in the field of machine learning. This article aims to explore the impact of the depth and width of quantum convolutional layers on image classification tasks in Quantum-Classical Hybrid Convolutional Neural Networks. To this end, a model combining parameterized quantum circuits and classical neural networks is designed, and a series of experiments are conducted on the MNIST dataset to assess the specific effects of different configurations of quantum convolutional layers on model performance. The research results indicate that simply increasing the depth or width of quantum convolutional layers does not guarantee performance improvement and sometimes may even lead to performance degradation. Therefore, when designing quantum convolutional layers, we should make reasonable choices based on the actual needs of the application scenarios. Finally, based on these findings, a multidimensional optimization strategy is proposed to enhance the overall performance of the model. The achievements of this research not only provide important guidance for the design and optimization of Quantum-Classical Hybrid Convolutional Neural Networks but also offer new research perspectives for researchers in the field of quantum machine learning.",Web of Science
"Jovic, Ozren; Smuc, Tomislav",Combined Machine Learning and Molecular Modelling Workflow for the Recognition of Potentially Novel Fungicides,2020,10.3390/molecules25092198,https://doi.org/10.3390/molecules25092198,Journal,MOLECULES,"Novel machine learning and molecular modelling filtering procedures for drug repurposing have been carried out for the recognition of the novel fungicide targets of Cyp51 and Erg2. Classification and regression approaches on molecular descriptors have been performed using stepwise multilinear regression (FS-MLR), uninformative-variable elimination partial-least square regression, and a non-linear method called Forward Stepwise Limited Correlation Random Forest (FS-LM-RF). Altogether, 112 prediction models from two different approaches have been built for the descriptor recognition of fungicide hit compounds. Aiming at the fungal targets of sterol biosynthesis in membranes, antifungal hit compounds have been selected for docking experiments from the Drugbank database using the Autodock4 molecular docking program. The results were verified by Gold Protein-Ligand Docking Software. The best-docked conformation, for each high-scored ligand considered, was submitted to quantum mechanics/molecular mechanics (QM/MM) gradient optimization with final single point calculations taking into account both the basis set superposition error and thermal corrections (with frequency calculations). Finally, seven Drugbank lead compounds were selected based on their high QM/MM scores for the Cyp51 target, and three were selected for the Erg2 target. These lead compounds could be recommended for further in vitro studies.",Web of Science
"Huang, Yan; Li, Jian-ping; Wang, Peng",Unusual phenomenon of optimizing the Griewank function with the increase of dimension,2019,10.1631/FITEE.1900155,https://doi.org/10.1631/FITEE.1900155,Journal,FRONTIERS OF INFORMATION TECHNOLOGY & ELECTRONIC ENGINEERING,"The Griewank function is a typical multimodal benchmark function, composed of a quadratic convex function and an oscillatory nonconvex function. The comparative importance of Griewank's two major parts alters in different dimensions. Different from most test functions, an unusual phenomenon appears when optimizing the Griewank function. The Griewank function first becomes more difficult and then becomes easier to optimize with the increase of dimension. In this study, from the methodology perspective, this phenomenon is explained by structural, mathematical, and quantum analyses. Furthermore, frequency transformation and amplitude transformation are implemented on the Griewank function to make a generalization. The multi-scale quantum harmonic oscillator algorithm (MQHOA) with quantum tunnel effect is used to verify its characteristics. Experimental results indicate that the Griewank function's two-scale structure is the main reason for this phenomenon. The quantum tunneling mechanism mentioned in this paper is an effective method which can be generalized to analyze the generation and variation of solutions for numerous swarm optimization algorithms.",Web of Science
"Duan, Chenru; Du, Yuanqi; Jia, Haojun; Kulik, Heather J.",Accurate transition state generation with an object-aware equivariant elementary reaction diffusion model,2023,10.1038/s43588-023-00563-7,https://doi.org/10.1038/s43588-023-00563-7,Journal,NATURE COMPUTATIONAL SCIENCE,"Transition state search is key in chemistry for elucidating reaction mechanisms and exploring reaction networks. The search for accurate 3D transition state structures, however, requires numerous computationally intensive quantum chemistry calculations due to the complexity of potential energy surfaces. Here we developed an object-aware SE(3) equivariant diffusion model that satisfies all physical symmetries and constraints for generating sets of structures-reactant, transition state and product-in an elementary reaction. Provided reactant and product, this model generates a transition state structure in seconds instead of hours, which is typically required when performing quantum-chemistry-based optimizations. The generated transition state structures achieve a median of 0.08 A root mean square deviation compared to the true transition state. With a confidence scoring model for uncertainty quantification, we approach an accuracy required for reaction barrier estimation (2.6 kcal mol-1) by only performing quantum chemistry-based optimizations on 14% of the most challenging reactions. We envision usefulness for our approach in constructing large reaction networks with unknown mechanisms.A diffusion model that generates chemical reactions in 3D with all desired symmetries preserved is established and shown to reduce transition state search from days to seconds and complement intuition-based reaction exploration with generative AI.",Web of Science
"Zhang, Jiawei; Liu, Fang; Liu, Zulin; Perez, Ignacio Javier; Cabrerizo, Francisco Javier",Existence and simulation of multiple solutions to an optimization model for completing incomplete fuzzy preference relations,2024,10.1007/s10489-024-05667-9,https://doi.org/10.1007/s10489-024-05667-9,Journal,APPLIED INTELLIGENCE,"When addressing a decision making problem with incomplete preference relations, missing information could be estimated by proposing an optimization model. The previous studies always focus on a unique solution to optimization models through a software program. But theoretical and simulation investigations of multiple solutions are seldom considered. This paper investigates the existence of multiple solutions to an optimization model and proposes a simulation procedure. First, an optimization model is recalled for completing incomplete fuzzy preference relations. It is the first time to theoretically prove the existence of multiple solutions to the optimization model under various incomplete entries. The obtained results reveal that the optimal solution to an optimization model may be an interval value, which is dependent on the number and position of missing entries in an incomplete fuzzy preference relation. The idea of multiple solutions is further extended to the situation where an intransitive fuzzy preference relation should be adjusted to a weakly transitive matrix. Second, multiple solutions to the optimization model are simulated using the quantum-behaved particle swarm optimization algorithm. It is found that multiple solutions do appear under some conditions by only running the algorithm for multiple times. Finally, the impact of multiple solutions on the optimal alternative(s) of a decision making problem is analyzed by comparing with the existing studies. The result shows that the existence of multiple solutions reflects the uncertainty of optimization models, which is of concerns to propose an effective decision-making model.",Web of Science
"Berry, Dominic W.; Su, Yuan; Gyurik, Casper; King, Robbie; Basso, Joao; Barba, Alexander Del Toro; Rajput, Abhishek; Wiebe, Nathan; Dunjko, Vedran; Babbush, Ryan",Analyzing Prospects for Quantum Advantage in Topological Data Analysis,2024,10.1103/PRXQuantum.5.010319,https://doi.org/10.1103/PRXQuantum.5.010319,Journal,PRX QUANTUM,"Lloyd et al. [Nat. Commun. 7, 10138 (2016)] were first to demonstrate the promise of quantum algorithms for computing Betti numbers, a way to characterize topological features of data sets. Here, we propose, analyze, and optimize an improved quantum algorithm for topological data analysis (TDA) with reduced scaling, including a method for preparing Dicke states based on inequality testing, a more efficient amplitude estimation algorithm using Kaiser windows, and an optimal implementation of eigenvalue projectors based on Chebyshev polynomials. We compile our approach to a fault-tolerant gate set and estimate constant factors in the Toffoli complexity. Our analysis reveals that superquadratic quantum speedups are only possible for this problem when targeting a multiplicative error approximation and the Betti number grows asymptotically. Further, we propose a dequantization of the quantum TDA algorithm that shows that having exponentially large dimension and Betti number are necessary, but insufficient conditions, for superpolynomial advantage. We then introduce and analyze specific problem examples which have parameters in the regime where superpolynomial advantages may be achieved, and argue that quantum circuits with tens of billions of Toffoli gates can solve seemingly classically intractable instances.",Web of Science
"Kim, Youngbeom; Song, Jingyo; Youn, Taek-Young; Seo, Seog Chung",Crystals-Dilithium on ARMv8,2022,10.1155/2022/5226390,https://doi.org/10.1155/2022/5226390,Journal,SECURITY AND COMMUNICATION NETWORKS,"Crystals-Dilithium is one of the digital-signature algorithms in NIST's ongoing post-quantum cryptography (PQC) standardization final round. Security and computational efficiency concerning software and hardware implementations are the primary criteria for PQC standardization. Many studies were conducted to efficiently apply Dilithium in various environments; however, they are focused on traditionally used PC and 32-bit Advanced RISC Machine (ARM) processors (Cortex-M4). ARMv8-based processors are more advanced embedded microcontrollers (MCUs) and have been widely used for various IoT devices, edge computing devices, and On-Board Units in autonomous driving cars. In this study, we present an efficient Crystals-Dilithium implementation on ARMv8-based MCU. To enhance Dilithium's performance, we optimize number theoretic transform (NTT)-based polynomial multiplication, the core operation of Dilithium, by leveraging ARMv8's architectural properties such as large register sets and NEON engine. We apply task parallelism to NTT-based polynomial multiplication using the NEON engine. In addition, we reduced the number of memory accesses during NTT-based polynomial multiplication with the proposed merging and register-holding techniques. Finally, we present an interleaved NTT-based multiplication simultaneously executed with ARM processor and NEON engine. This implementation can further optimize performance by eliminating the ARM processor latency with NEON overheads. Through the proposed optimization methods, for Dilithium 3, we achieved a performance improvement of about 43.83% in key pair generation, 113.25% in signing, and 41.92% in verification compared to the reference implementation submitted to the final round of the NIST PQC competition.","Web of Science, Wiley"
"Manda, Timothy; Barasa, Godfrey Okumu; Louis, Hitler; Irfan, Ahmad; Agumba, John Onyango; Lugasi, Solomon Omwoma; Pembere, Anthony M. S.",A data-guided approach for the evaluation of zeolites for hydrogen storage with the aid of molecular simulations,2024,10.1007/s00894-024-05837-z,https://doi.org/10.1007/s00894-024-05837-z,Journal,JOURNAL OF MOLECULAR MODELING,"ContextThis study employs a data-guided approach to evaluate zeolites for hydrogen storage, utilizing molecular simulations. The development of efficient and practical hydrogen storage materials is crucial for advancing clean energy technologies. Zeolites have shown promise as potential candidates due to their unique porous structure and tunable properties. However, the selection and design of suitable zeolites for hydrogen storage remain challenging. Therefore, this work aims to address this materials science question by utilizing molecular simulations and data-guided approaches to evaluate zeolites' performance for hydrogen storage. The results obtained from this study provide valuable insights into the evaluation of zeolites for hydrogen storage. Through molecular simulations, we analyze the adsorption behavior of hydrogen molecules in various zeolite structures. The performance of different zeolite frameworks in terms of hydrogen storage capacity, adsorption energy, and diffusion properties is assessed. Linde type A zeolite (LTA) had the highest capacity with a hydrogen capacity of 4.8wt% out of the 233 investigated zeolites. Furthermore, we investigate the influence of different factors such as mass (M), density (D), helium void fraction (HVF), accessible pore volume (APV), gravimetric surface area (GSA), and largest overall cavity diameter (Di) on the hydrogen storage performance of zeolites. The results show that Di, D, and M have a negative effect on the percentage weight capacity, while GSA and VSA have the highest positive contribution to the percentage weight. This study, therefore, provides new insights into the factors that affect their hydrogen storage capacity by exhibiting the importance of considering multiple factors when evaluating the performance of zeolites and demonstrates the potential of combining different computational methods to provide a more comprehensive understanding of materials. The current study contributes to the understanding of zeolite-based materials for hydrogen storage applications, aiding in the development of more efficient and practical hydrogen storage systems.MethodsComputational techniques were employed to investigate the hydrogen storage properties of zeolites. Molecular simulations were performed using classical force fields and molecular dynamics methods. The calculations were carried out at a force field level of theory with the GGA functional. To accurately capture the thermodynamics and kinetics of hydrogen adsorption, enhanced sampling techniques such as Monte Carlo simulations and molecular dynamics with metadynamics were utilized. We employed Grand Canonical Monte Carlo (GCMC) simulations to model hydrogen adsorption in zeolite structures for hydrogen storage. Our approach involved performing a substantial number of Monte Carlo steps (10,000) to ensure system equilibration and precise results. We defined a cutoff distance for particle interactions as 12.5 A and considered 0.000e framework charge per cell and 0.000e sorbate charge in energy calculations. The choice of an appropriate simulation cell size (50 x 50 x 50) A was crucial, mirroring real-world conditions. We specified lower and upper fugacity values (1 to 10 atm) to capture the range of gas pressures in the simulations. These methodical steps collectively enabled us to accurately model hydrogen adsorption within zeolites, forming the core of our hydrogen storage evaluation. In this research, we utilized DFT calculations to thoroughly investigate the interactions between zeolites and hydrogen.We employed pseudopotentials to describe electron behavior in zeolite systems, choosing them in line with DFT norms and basis set compatibility. Our simulation cell design replicated zeolite periodicity and eliminated boundary effects. Pre-geometry optimization was performed with HyperChem29, ensuring stable conformations with strict convergence criteria. We utilized 6-31 + G(d) and LanL2DZ basis sets for light and heavy atoms, aligning with field standards for computational efficiency and precision. A machine learning algorithm was used to rank the importance of various structural features such as mass (M), density (D), helium void fraction (HVF), accessible pore volume (APV), gravimetric surface area (GSA), and largest overall cavity diameter (Di) and how they affect the capacity of the zeolites. Machine learning analysis was performed with the Scikit-learn library, an open-source Python tool. We employed a range of machine learning models, including SVMs, random forests, and neural networks, primarily for data analysis and feature extraction. Pearson correlation analysis, a classical statistical technique, was used to evaluate linear relationships between variables and assess the strength and direction of these relationships. It served as a complementary tool to understand the interplay of variables in our dataset, distinguishing it from machine learning algorithms. Further quantum chemical calculations were also performed to calculate the adsorption energy, global reactivity electronic descriptors, and natural bond orbital analysis in order to provide insights into the interaction of the zeolites with hydrogen. The simulations and data analysis were performed using BIOVIA material studio software, Gaussian, and Origin Pro software.",Web of Science
"Krishnan Vijayan, Madhav; Paler, Alexandru; Gavriel, Jason; Myers, Casey R.; Rohde, Peter P.; Devitt, Simon J.",Compilation of algorithm-specific graph states for quantum circuits,2024,10.1088/2058-9565/ad1f39,https://doi.org/10.1088/2058-9565/ad1f39,Journal,QUANTUM SCIENCE AND TECHNOLOGY,"We present a quantum circuit compiler that prepares an algorithm-specific graph state from quantum circuits described in high level languages, such as Cirq and Q#. The computation can then be implemented using a series of non-Pauli measurements on this graph state. By compiling the graph state directly instead of starting with a standard lattice cluster state and preparing it over the course of the computation, we are able to better understand the resource costs involved and eliminate wasteful Pauli measurements on the actual quantum device. Access to this algorithm-specific graph state also allows for optimisation over locally equivalent graph states to implement the same quantum circuit. The compiler presented here finds ready application in measurement based quantum computing, NISQ devices and logical level compilation for fault tolerant implementations.",Web of Science
"Mironowicz, Piotr",Semi-definite programming and quantum information,2024,10.1088/1751-8121/ad2b85,https://doi.org/10.1088/1751-8121/ad2b85,Journal,JOURNAL OF PHYSICS A-MATHEMATICAL AND THEORETICAL,"This paper presents a comprehensive exploration of semi-definite programming (SDP) techniques within the context of quantum information. It examines the mathematical foundations of convex optimization, duality, and SDP formulations, providing a solid theoretical framework for addressing optimization challenges in quantum systems. By leveraging these tools, researchers and practitioners can characterize classical and quantum correlations, optimize quantum states, and design efficient quantum algorithms and protocols. The paper also discusses implementational aspects, such as solvers for SDP and modeling tools, enabling the effective employment of optimization techniques in quantum information processing. The insights and methodologies presented in this paper have proven instrumental in advancing the field of quantum information, facilitating the development of novel communication protocols, self-testing methods, and a deeper understanding of quantum entanglement.",Web of Science
"Zheng, Min; Moriarty, Nigel W.; Xu, Yanting; Reimers, Jeffrey R.; Afonine, Pavel V.; Waller, Mark P.",Solving the scalability issue in quantum-based refinement: Q|R#1,2017,10.1107/S2059798317016746,https://doi.org/10.1107/S2059798317016746,Journal,ACTA CRYSTALLOGRAPHICA SECTION D-STRUCTURAL BIOLOGY,"Accurately refining biomacromolecules using a quantum-chemical method is challenging because the cost of a quantum-chemical calculation scales approximately as n(m), where n is the number of atoms and m (>= 3) is based on the quantum method of choice. This fundamental problem means that quantum-chemical calculations become intractable when the size of the system requires more computational resources than are available. In the development of the software package called Q|R, this issue is referred to as Q|R#1. A divide-and-conquer approach has been developed that fragments the atomic model into small manageable pieces in order to solve Q|R#1. Firstly, the atomic model of a crystal structure is analyzed to detect noncovalent interactions between residues, and the results of the analysis are represented as an interaction graph. Secondly, a graph-clustering algorithm is used to partition the interaction graph into a set of clusters in such a way as to minimize disruption to the noncovalent interaction network. Thirdly, the environment surrounding each individual cluster is analyzed and any residue that is interacting with a particular cluster is assigned to the buffer region of that particular cluster. A fragment is defined as a cluster plus its buffer region. The gradients for all atoms from each of the fragments are computed, and only the gradients from each cluster are combined to create the total gradients. A quantum-based refinement is carried out using the total gradients as chemical restraints. In order to validate this interaction graph-based fragmentation approach in Q|R, the entire atomic model of an amyloid cross-beta spine crystal structure (PDB entry 2oNA) was refined.",Web of Science
"Misra-Spieldenner, Aditi; Bode, Tim; Schuhmacher, Peter K.; Stollenwerk, Tobias; Bagrets, Dmitry; Wilhelm, Frank K.",Mean-Field Approximate Optimization Algorithm,2023,10.1103/PRXQuantum.4.030335,https://doi.org/10.1103/PRXQuantum.4.030335,Journal,PRX QUANTUM,"The quantum approximate optimization algorithm (QAOA) is suggested as a promising application on early quantum computers. Here a quantum-inspired classical algorithm, the mean-field approximate optimization algorithm (mean-field AOA), is developed by replacement of the quantum evolution of the QAOA with classical spin dynamics through the mean-field approximation. Because of the alternating structure of the QAOA, this classical dynamics can be found exactly for any number of QAOA layers. We benchmark its performance against the QAOA on the Sherrington-Kirkpatrick model and the partition problem, and find that the mean-field AOA outperforms the QAOA in both cases for most instances. Our algorithm can thus serve as a tool to delineate optimization problems that can be solved classically from those that cannot, i.e., we believe that it will help to identify instances where a true quantum advantage can be expected from the QAOA. To quantify quantum fluctuations around the mean-field trajectories, we solve an effective scattering problem in time, which is characterized by a spectrum of time-dependent Lyapunov exponents. These provide an indicator for the hardness of a given optimization problem relative to the mean-field AOA.",Web of Science
"Zhang, Lin; Alsubai, Shtwai; Alqahtani, Abdullah; Alanazi, Abed; Abualigah, Laith",Leveraging quantum-inspired chimp optimization and deep neural networks for enhanced profit forecasting in financial accounting systems,2024,10.1111/exsy.13563,https://doi.org/10.1111/exsy.13563,Journal,EXPERT SYSTEMS,"Deep learning and metaheuristic algorithms have recently increased in various sciences, including financial accounting information systems (FAISs). However, the existence of large datasets has dramatically increased the complexity of these hybrid networks, so to address this shortcoming, this paper aims to develop a quantum-behaved chimp optimization algorithm (QCHOA) and deep neural network (DNN) for the prediction of the profit based on FAISs. Considering that there is no suitable dataset for the challenge, a novel dataset is developed utilizing the 15 features from the Chinese market dataset to compare more. This work designs QCHOA and five DNN-based predictors to forecast profit. These algorithms include the universal learning CHOA (ULCHOA), the niching CHOA (NCHOA) as the two best-modified versions of CHOA, the quantum-behaved whale optimization algorithm (QWOA), and the quantum-behaved grey wolf optimizer (QGWO) as the two best quantum-behaved optimizers as well as classic CHOA. The most effective deep learning-based predictors for forecasting the profit, ranked from highest to lowest, are DNN-QCHOA, DNN-NCHOA, DNN-QWOA, DNN-QGWO, DNN-ULCHOA, DNN-CHOA, and classic DNN, with corresponding ranking scores of 42, 36, 30, 24, 18, 12, and 6. As a final suggestion for profit prediction, the DNN-CHOA is shown to be the most accurate model.","Web of Science, Wiley"
"Tong, Qunchao; Lv, Jian; Gao, Pengyue; Wang, Yanchao",The CALYPSO methodology for structure prediction,2019,10.1088/1674-1056/ab4174,https://doi.org/10.1088/1674-1056/ab4174,Journal,CHINESE PHYSICS B,"Structure prediction methods have been widely used as a state-of-the-art tool for structure searches and materials discovery, leading to many theory-driven breakthroughs on discoveries of new materials. These methods generally involve the exploration of the potential energy surfaces of materials through various structure sampling techniques and optimization algorithms in conjunction with quantum mechanical calculations. By taking advantage of the general feature of materials potential energy surface and swarm-intelligence-based global optimization algorithms, we have developed the CALYPSO method for structure prediction, which has been widely used in fields as diverse as computational physics, chemistry, and materials science. In this review, we provide the basic theory of the CALYPSO method, placing particular emphasis on the principles of its various structure dealing methods. We also survey the current challenges faced by structure prediction methods and include an outlook on the future developments of CALYPSO in the conclusions.",Web of Science
"Ning, Tao; Duan, Xiaodong; An, Lu; Gou, Tao",Research on disruption management of urgent arrival in job shop with deteriorating effect,2021,10.3233/JIFS-210166,https://doi.org/10.3233/JIFS-210166,Journal,JOURNAL OF INTELLIGENT & FUZZY SYSTEMS,"A disruption management method based on cumulative prospect theory is proposed for the urgent with deteriorating effect arrival in flexible job shop scheduling problem (FJSP). First, the mathematical model of problem is established with minimizing the completion time of urgent order, minimizing the total process time of the system and minimizing the total cost as the target. Then, the cumulative prospect theory equation of the urgent arrival in job shop scheduling process is induced designed. Based on the selected model, an optimized multi-phase quantum particle swarm algorithm (MQPSO) is proposed for selecting processing route. Finally, using Solomon example simulation and company Z riveting shop example as the study object, the performance of the proposed method is analyzed. It is compared with the current common rescheduling methods, and the results verify that the method proposed in this paper not only meets the goal of the optimized objects, but improves the practical requirements for the stability of production and processing system during urgent arrival. Lastly, the optimized multiphase quantum particle swarm algorithm is used to solve disruption management of urgent arrival problem. Through instance analysis and comparison, the effectiveness and efficiency of urgent arrival disruption management method with deteriorating effect are verified.",Web of Science
Cao Zhixiang; Zeng Meiling; Yang Jian; Jin Xiangliang,Detection Probability Model and Verification of an Improved SinglePhoton Avalanche Diode,2023,10.3788/AOS222111,https://doi.org/10.3788/AOS222111,Journal,ACTA OPTICA SINICA,"Objective A method considering the light transmission of silicon dioxide film on the device surface can be proposed to address the large error between the existing photon detection probability ( PDP) model and actual test results, which can accurately predict the detection probability of single- photon avalanche diodes ( SPADs). Visible light communication requires a high-sensitivity receiver to receive optical signals, and single-photon detectors play an extremely important role in visible light communication because of their high sensitivity, high gain, and high visible light wide- spectrum response. Due to the time- consuming and cost- intensive bipolar- complementary metal oxide semiconductor- double diffusion metal oxide semiconductor (BCD) process workflow, prediction of SPAD performance is critical to optimize its design before fabrication. Although commercial semiconductor simulation software can usually simulate the electrical properties of SPADs, such as breakdown voltage, impact ionization rate, and electric field distribution, their statistical performance cannot be directly simulated. Additionally, since the internal operating mechanism of the semiconductor simulation software is not open, it is impossible to know the detailed simulation process, and it is also prone to non- convergence during the simulation. Therefore, it is of practical significance to model the performance parameters of SPADs. In fact, although there are some theoretical models for the calculation of PDP, due to the complex factors of its physical process, various models have large errors and are inconsistent with the experimental test trend in the short wavelength range. Thus, the photon-quantitative and reliable prediction of detection probability is challenging.Methods The PDP is defined as the product of the light transmission of a photon passing through the silicon dioxide layer on the silicon surface and the internal quantum efficiency of the device. The internal quantum efficiency of the device is the probability triggered when a photon is absorbed by the device and results in an avalanche. The internal quantum efficiency of P+ /N well/deep N well SPAD is divided into three parts. In the neutral region P, photons are absorbed in the P+ layer on top of the SPAD to generate electron-hole pairs, and some photogenerated electrons will diffuse to the upper boundary of the depletion region, triggering an avalanche probability. In the depletion region, photogenerated electrons and holes drift in opposite directions under the action of a strong electric field in this region and trigger an avalanche after moving a very short distance. In the neutral region N, photogenerated holes can reach the bottom of the depletion region without being recombined, and initiate an avalanche trigger. In this study, the doping concentration provided by the device processing factory and the designed SPAD layout structure are imported into the TCAD tool to rebuild the twodimensional device model. Through the function library that comes with Sentaurus Sdevice, parameters such as temperature, bias voltage, and incident light wavelength are set for electrical simulation, and the electric field intensity and width of the depletion region are obtained. Then, the electric field strength and the width of the depletion region are imported into the model built by Matlab software to obtain the internal quantum efficiency. The particle swarm optimization algorithm is adopted to obtain the fitting parameters of the transmission spectrum in the passivation layer of the silicon dioxide film, and finally acquire the PDP.Results and Discussions Firstly, two- dimensional process simulations are carried out through the Sentaurus SED based on the standard 0. 18 mu m BCD process and the SPAD device structure obtained from the process simulations. The simulated electric field distribution of the SPAD at an excess bias voltage of 1 V is simulated by Sentaurus Sdevice (Fig. 4) to extract the one-dimensional (1D) electric field distribution at the center of the device at an excess bias voltage of 1 V (Fig. 5). The electric field distributions at 0. 5, 1. 0, 2. 0, and 3. 0 V over-bias respectively are employed to calculate the avalanche trigger probability at each location in the depletion region ( Fig. 6). The theoretical model of the PDP is improved by considering the effect of the silica passivation layer film on the incident light wavelength. The wavelengthdependent transmission of the silica film is fitted through a particle swarm optimization algorithm by comparing the theoretical model with experimental test results (Fig. 7). The PDPs contributed by each of the three components of the neutral P, depletion, and neutral N regions are calculated (Fig. 8), and the total PDP is the sum of the three components (Fig. 9). Finally, a PDP model with a low mean error is achieved (Fig. 10). The results show good agreement between the PDP predictions and experimental tests, with an average error of only 1. 72%.Conclusions We discuss the PDP for simulating typical over-bias voltages from 0. 5 to 3 V without substrate contribution. The model and experimental test results are compared at the over-bias voltage of 0. 5 V with an average error of only 1. 72%. The average error is defined as the average of the sum of the absolute errors for each wavelength. The improved model for PDP considering the transmission spectrum of a thin film of silica passivation layer provides a research direction for the development of new SPAD device structures. Results show that the model can reduce the nonconvergence problems in commercial device simulation software, and greatly reduce the time and cost required to develop new structures for SPAD devices. Additionally, the building of models for electric field strength, avalanche trigger probability, and carrier lifetime can help dark counting analysis, thus enlightening related researchers.",Web of Science
"Wu, Jiawei; Hao, Wang; Xing, Fu; Qiang, Liu",Advances and Challenges in Intelligent Optical Computing Based on Laser Cavities,2023,10.3788/CJL230475,https://doi.org/10.3788/CJL230475,Journal,CHINESE JOURNAL OF LASERS-ZHONGGUO JIGUANG,"Significance With the advent of the information era, the development of artificial intelligence technology has undergone an unprecedented transformation, leading to a growing demand for computing resources and efficiency. However, conventional computers based on electronic transistors, constrained by von Neumann architectures, encounter performance bottlenecks in complex computing tasks such as deep neural networks and large-scale combinatorial optimizations. To circumvent the limitations of traditional computing hardware systems, researchers have begun exploiting the inherent properties of different physical systems for computation or computing acceleration, including quantum computing, DNA computing, neuromorphic computing, and optical computing. Among the innovative computing approaches mentioned above, optical computing aims to construct all -optical or optoelectronic systems for information processing by leveraging the physical properties of light and the intricate interactions between light and matter. Optical computing excels in many complex computing tasks due to ultra -fast transmission speeds, high parallelism, and minimal energy consumption. Since the proposal of the optical correlator in the 1950s and 1960s, optical computing has consistently drawn the attention of researchers across various fields. With emerging concepts, such as on -chip optical neural networks, diffractive deep neural networks, optoelectronic reservoir computing, and photonic Ising machines, the application potential of photons in diverse complex computing tasks is becoming increasingly evident. It is not an exaggeration to state that photons are evolving into one of the foundations of next -generation computing. Lasers, as high -performance light sources, play a crucial role in industrial manufacturing and scientific research. Generated by laser cavities, laser has been widely employed in fabrication, measurement, communication, medicine, and other fields. In recent years, researchers have discovered that lasers can also serve as powerful computational tools. Specifically, the randomness and nonlinearity of lasers in chaotic oscillations, relaxation oscillations, and other unsteady states can be harnessed to address complex calculation problems. Additionally, in the absence of external disturbances, physical processes, such as mode competition, can cause the light field in laser cavities to spontaneously evolve into a stable oscillation state with the lowest loss, which can be mapped to the solution of a complex computation problem. As optical computing continues to advance, and laser generation, control, and detection technologies mature, there is a growing interest in the computational capabilities of lasers. Therefore, it is essential to summarize the progress of optical computing based on laser cavities to guide the further integration of lasers and artificial intelligence technology, ultimately promoting the development of intelligent laser computing systems. Progress In this review, we comprehensively summarize the recent progress in optical computing based on laser cavities, primarily focusing on reinforcement learning using laser chaos, reservoir computing by lasers with optical delayed feedback, and spin models for solving combinatorial optimization problems simulated by laser networks. Firstly, we introduce methods that utilize laser chaos signals generated by semiconductor lasers to perform reinforcement learning (RL). Naruse et al.initially demonstrated RL assisted by laser chaos, which served as random numbers, and proved that laser chaos signals outperform pseudorandom numbers generated by conventional electronic circuitry in this calculation task. Subsequent research aiming at scalability and parallelism improvement is also discussed (Fig. 2). To further exploit the properties of oscillations within laser cavities, RL based on mode switching in a ring laser, lag synchronization of coupled lasers and laser networks, and chaotic itinerancy in a multimode semiconductor laser have been proposed and demonstrated as well (Fig. 3). Subsequently, we discuss optoelectronic reservoir computing (RC) based on lasers, mainly focusing on delay-based RC using lasers with optical delayed feedback. Since 2013, when Brunner et al. experimentally implemented reservoir computing using a semiconductor laser as the nonlinear node, numerous studies have been conducted to enhance performance. These include RC based on semiconductor ring lasers, microchip lasers, vertical cavity surface-emitting lasers, and photonic integrated circuits (Fig. 6, Fig. 7). Finally, we review recent advances in simulating spin models using laser networks. Artificial spin models can be employed to solve NP-hard combinatorial optimization problems, as their ground states are associated with the solutions. Under certain circumstances, the steady oscillation state of a laser network system can be mapped to the ground state of the spin Hamiltonian, and thus, to the solution of the combinatorial optimization problem. Photonic Ising machines based on injection-locked laser networks (Fig. 8) and XY model simulators based on degenerate cavity lasers (Fig. 11) are outlined, respectively. Additionally, other types of challenging computational problems solved by degenerate cavity lasers are presented, including real-time wavefront shaping, phase retrieval, generation of arbitrary-shaped laser beams, and real-time full -field imaging through scattering media (Fig. 12). Conclusions and Prospects In addition to the inherent advantages of optical computing, such as ultra -fast transmission speed, high parallelism, and negligible energy consumption, laser -based optical computing fully utilizes the unique physical processes occurring in laser cavities, as well as various mature laser technologies, to provide a wealth of solutions for complex computing tasks. In the future, the theoretical model of optical computing based on laser cavities needs further optimization to continuously expand its application in various intelligent computing fields and to improve calculation accuracy, scale, and dimension. Additionally, with the exploration and development of intelligent algorithms and optoelectronic devices that are better suited for optical computing, combined with rapidly advancing online training and in situ training schemes, intelligent laser computing is expected to gradually achieve all -optical, high -efficiency, and real-time performance. Furthermore, by utilizing novel laser cavity structures, advanced laser technologies, and photon integration technologies, along with metamaterial and metasurface technologies, it is anticipated that more compact on -chip intelligent laser computing systems will be developed. In summary, the establishment of high-speed and high -efficiency intelligent laser systems for information processing and computation is a significant and promising research direction that encompasses the simultaneous development of hardware, software, and algorithms.",Web of Science
"Naik, Debadatta; Dharavath, Ramesh; Qi, Lianyong",Quantum-PSO based unsupervised clustering of users in social networks using attributes,2024,10.1007/s10586-023-03993-0,https://doi.org/10.1007/s10586-023-03993-0,Journal,CLUSTER COMPUTING-THE JOURNAL OF NETWORKS SOFTWARE TOOLS AND APPLICATIONS,"Unsupervised cluster detection in social network analysis involves grouping social actors into distinct groups, each distinct from the others. Users in the clusters are semantically very similar to those in the same cluster and dissimilar to those in different clusters. Social network clustering reveals a wide range of useful information about users and has many applications in daily life. Various approaches are developed to find social network users' clusters, using only links or attributes and links. This work proposes a method for detecting social network users' clusters based solely on their attributes. In this case, users' attributes are considered categorical values. The most popular clustering algorithm used for categorical data is the K-mode algorithm. However, it may suffer from local optimum due to its random initialization of centroids. To overcome this issue, this manuscript proposes a methodology named the Quantum PSO approach based on user similarity maximization. In the proposed approach, firstly, dimensionality reduction is conducted by performing the relevant attribute set selection followed by redundant attribute removal. Secondly, the QPSO technique is used to maximize the similarity score between users to get clusters. Three different similarity measures are used separately to perform the dimensionality reduction and similarity maximization processes. Experiments are conducted on two popular social network datasets; ego-Twitter, and ego-Facebook. The results show that the proposed approach performs better clustering results in terms of three different performance metrics than K-Mode and K-Mean algorithms.",Web of Science
"Sarvaghad-Moghaddam, Moein; Orouji, Ali A.; Ramezani, Zeinab; Elhoseny, Mohamed; Farouk, Ahmed; Kumar, N. Arun",Modelling the spice parameters of SOI MOSFET using a combinational algorithm,2019,10.1007/s10586-018-2289-6,https://doi.org/10.1007/s10586-018-2289-6,Journal,CLUSTER COMPUTING-THE JOURNAL OF NETWORKS SOFTWARE TOOLS AND APPLICATIONS,"Progress in the technology of submicron semiconductor device, which makes a short-channel and quantum effects, having equations of nonlinear modelling, leads to complicated and time-consuming calculations. In order to control these complexities and obtain the device characteristics according to device parameters, a faster method is needed. In this paper, a combinational algorithm is proposed for modelling a nano silicon-on-insulator metal-oxide-semiconductor field effect transistor (SOI MOSFET) characteristic. The proposed method shows the same device characteristics with lower input parameters. In this method, a combination of genetic algorithm (GA) and artificial neural network are used. Then quantum evolutionary algorithm (QEA) is employed instead of genetic algorithm (GA) for comparing and modifying algorithm. Results show that the algorithm's accuracy is 95% and 98% for test data of GA and QGA, respectively. Moreover, the reduction percentage of input parameters are 11% and 52% for GA and QEA, respectively. The simulation results represent that the implemented quantum genetic algorithm for prediction of device characteristics is more effective and accurate than GA.",Web of Science
"Kolhe, Likhesh; Jetawat, Ashok Kumar; Khairnar, Vaishali",Robust product recommendation system using modified grey wolf optimizer and quantum inspired possibilistic fuzzy C-means,2021,10.1007/s10586-020-03171-6,https://doi.org/10.1007/s10586-020-03171-6,Journal,CLUSTER COMPUTING-THE JOURNAL OF NETWORKS SOFTWARE TOOLS AND APPLICATIONS,"In recent years, several researchers have developed web-based product recommendation systems to assist customers in product search and selection during online shopping. In addition, the product recommendation systems deliver true personalization by recommending the products based on the other customer's preferences. This study has investigated how the product recommendation system influences the customer's decision effort and quality. In this study, the proposed system comprises of five major phases: data collection, pre-processing, key word extraction, keyword optimization and similar data clustering. The input data were collected from amazon customer review dataset. After the data collection, pre-processing was carried-out to enhance the quality of collected amazon data. The pre-processing phase comprises of two systems lemmatization and removal of stop-words & uniform resource locators (URLs). Then, a superior topic modelling method Latent Dirichlet allocation (LDA) along with modified grey wolf optimizer (MGWO) was applied in order to identify the optimal keywords. The extracted key-words were clustered into two forms (positive and negative) by applying a clustering algorithm named as quantum inspired possibilistic fuzzy C-means (QIPFCM). Experimental results showed that the proposed system achieved better performance in the product recommendation system compared to the existing systems in terms of accuracy, precision, recall and f-measure.",Web of Science
"Wang, Huan; Gao, Qing; Li, Hao; Wang, Hao; Yan, Liping; Liu, Guanghua",A Structural Evolution-Based Anomaly Detection Method for Generalized Evolving Social Networks,2022,10.1093/comjnl/bxaa168,https://doi.org/10.1093/comjnl/bxaa168,Journal,COMPUTER JOURNAL,"Recently, text-based anomaly detection methods have obtained impressive results in social network services, but their applications are limited to social texts provided by users. To propose a method for generalized evolving social networks that have limited structural information, this study proposes a novel structural evolution-based anomaly detection method (SeaDM), which mainly consists of an evolutional state construction algorithm (ESCA) and an optimized evolutional observation algorithm (OEOA). ESCA characterizes the structural evolution of the evolving social network and constructs the evolutional state to represent the macroscopic evolution of the evolving social network. Subsequently, OEOA reconstructs the quantum-inspired genetic algorithm to discover the optimized observation vector of the evolutional state, which maximally reflects the state change of the evolving social network. Finally, SeaDM combines ESCA and OEOA to evaluate the state change degrees and detect anomalous changes to report anomalies. Experimental results on real-world evolving social networks with artificial and real anomalies show that our proposed SeaDM outperforms the state-of-the-art anomaly detection methods.",Web of Science
"Huang, Yi-Ming; Li, Xiao-Yu; Zhu, Yi-Xuan; Lei, Hang; Zhu, Qing-Sheng; Yang, Shan",Learning Unitary Transformation by Quantum Machine Learning Model,2021,10.32604/cmc.2021.016663,https://doi.org/10.32604/cmc.2021.016663,Journal,CMC-COMPUTERS MATERIALS & CONTINUA,"Quantum machine learning (QML) is a rapidly rising research field that incorporates ideas from quantum computing and machine learning to develop emerging tools for scientific research and improving data processing. How to efficiently control or manipulate the quantum system is a fundamental and vexing problem in quantum computing. It can be described as learning or approximating a unitary operator. Since the success of the hybrid-based quantum machine learning model proposed in recent years, we investigate to apply the techniques from QML to tackle this problem. Based on the Choi-Jamiolkowski isomorphism in quantum computing, we transfer the original problem of learning a unitary operator to a min-max optimization problem which can also be viewed as a quantum generative adversarial network. Besides, we select the spectral norm between the target and generated unitary operators as the regularization term in the loss function. Inspired by the hybrid quantum-classical framework widely used in quantum machine learning, we employ the variational quantum circuit and gradient descent based optimizers to solve the min-max optimization problem. In our numerical experiments, the results imply that our proposed method can successfully approximate the desired unitary operator and dramatically reduce the number of quantum gates of the traditional approach. The average fidelity between the states that are produced by applying target and generated unitary on random input states is around 0.997.",Web of Science
"Kapaev, Roman R.; Egorova, Ksenia S.; Toukach, Philip V.","Carbohydrate Structure Generalization Scheme for Database-Driven Simulation of Experimental Observables, Such as NMR Chemical Shifts",2014,10.1021/ci500267u,https://doi.org/10.1021/ci500267u,Journal,JOURNAL OF CHEMICAL INFORMATION AND MODELING,"Carbohydrates play an immense role in different aspects of life. NMR spectroscopy is the most powerful tool for investigation of these compounds. Nowadays, progress in computational procedures has opened up novel opportunities giving an impulse to the development of new instruments intended to make the research simpler and more efficient. In this paper, we present a new approach for simulating C-13 NMR chemical shifts of carbohydrates. The approach is suitable for any atomic observables, which could be stored in a database. The method is based on sequential generalization of the chemical surroundings of the atom under prediction and heuristic averaging of database data. Unlike existing applications, the generalization scheme is tuned for carbohydrates, including those containing phosphates, amino acids, alditols, and other non-carbohydrate constituents. It was implemented in the Glycan-Optimized Dual Empirical Spectrum Simulation (GODESS) software, which is freely available on the Internet. In the field of carbohydrates, our approach was shown to outperform all other existing methods of NMR spectrum prediction (including quantum-mechanical calculations) in accuracy. Only this approach supports NMR spectrum simulation for a number of structural features in polymeric structures.",Web of Science
"Borges, Lucas R.; de Oliveira, Helder C. R.; Nunes, Polyana F.; Bakic, Predrag R.; Maidment, Andrew D. A.; Vieira, Marcelo A. C.",Method for simulating dose reduction in digital mammography using the Anscombe transformation,2016,10.1118/1.4948502,https://doi.org/10.1118/1.4948502,Journal,MEDICAL PHYSICS,"Purpose: This work proposes an accurate method for simulating dose reduction in digital mammography starting from a clinical image acquired with a standard dose.Methods: The method developed in this work consists of scaling a mammogram acquired at the standard radiation dose and adding signal-dependent noise. The algorithm accounts for specific issues relevant in digital mammography images, such as anisotropic noise, spatial variations in pixel gain, and the effect of dose reduction on the detective quantum efficiency. The scaling process takes into account the linearity of the system and the offset of the detector elements. The inserted noise is obtained by acquiring images of a flat-field phantom at the standard radiation dose and at the simulated dose. Using the Anscombe transformation, a relationship is created between the calculated noise mask and the scaled image, resulting in a clinical mammogram with the same noise and gray level characteristics as an image acquired at the lower-radiation dose.Results: The performance of the proposed algorithm was validated using real images acquired with an anthropomorphic breast phantom at four different doses, with five exposures for each dose and 256 nonoverlapping ROIs extracted from each image and with uniform images. The authors simulated lower-dose images and compared these with the real images. The authors evaluated the similarity between the normalized noise power spectrum (NNPS) and power spectrum (PS) of simulated images and real images acquired with the same dose. The maximum relative error was less than 2.5% for every ROI. The added noise was also evaluated by measuring the local variance in the real and simulated images. The relative average error for the local variance was smaller than 1%.Conclusions: A new method is proposed for simulating dose reduction in clinical mammograms. In this method, the dependency between image noise and image signal is addressed using a novel application of the Anscombe transformation. NNPS, PS, and local noise metrics confirm that this method is capable of precisely simulating various dose reductions. (C) 2016 American Association of Physicists in Medicine.","Web of Science, Wiley"
"Wang, Qisheng; Liu, Junyi; Ying, Mingsheng",E quivalence checking of quantum finite-state machines,2021,10.1016/j.jcss.2020.08.004,https://doi.org/10.1016/j.jcss.2020.08.004,Journal,JOURNAL OF COMPUTER AND SYSTEM SCIENCES,"In this paper, we introduce the model of quantum Mealy machines and study the equivalence checking and minimisation problems of them. Two efficient algorithms are developed for checking equivalence of two states in the same machine and for checking equivalence of two machines. As an application, they are used in equivalence checking of quantum circuits. Moreover, the minimisation problem is proved to be in PSPACE. (C) 2020 Elsevier Inc. All rights reserved.",Web of Science
"Shahsavani, Soheil Nazar; Pedram, Massoud",A Minimum-Skew Clock Tree Synthesis Algorithm for Single Flux Quantum Logic Circuits,2019,10.1109/TASC.2019.2943930,https://doi.org/10.1109/TASC.2019.2943930,Journal,IEEE TRANSACTIONS ON APPLIED SUPERCONDUCTIVITY,"This article presents a synchronous minimum-skew clock tree synthesis algorithm for single flux quantum circuits considering splitter delays and placement blockages. The proposed methodology improves the state-of-the-art by accounting for splitter delays and creating a fully balanced clock tree structure in which the number of clock splitters from the clock source to all the sink nodes is identical. Additionally, a mixed integer linear programming based algorithm is presented that removes the overlaps among the clock splitters and placed cells (i.e., placement blockages) and minimizes the clock skew, simultaneously. Using the proposed method, the average clock skew for 17 benchmark circuits is 4.6 ps, improving the state-of-the-art algorithm by 70%. Finally, a clock tree synthesis algorithm for imbalanced topologies is presented that reduces the clock skew and the number of clock splitters in the clock network by 56% and 37%, respectively, compared with a fully balanced clock tree solution.",Web of Science
"Gusev, A. A.; Chuluunbaatar, O.; Vinitsky, S. I.; Abrashkevich, A. G.",POTHEA: A program for computing eigenvalues and eigenfunctions and their first derivatives with respect to the parameter of the parametric self-adjoined 2D elliptic partial differential equation,2014,10.1016/j.cpc.2014.04.014,https://doi.org/10.1016/j.cpc.2014.04.014,Journal,COMPUTER PHYSICS COMMUNICATIONS,"A FORTRAN 77 program is presented for calculating with the given accuracy eigenvalues, surface eigenfunctions and their first derivatives with respect to a parameter of the parametric self-adjoined 20 elliptic partial differential equation with the Dirichlet and/or Neumann type boundary conditions on a finite two-dimensional region. The program calculates also potential matrix elements that are integrals of the products of the surface eigenfunctions and/or the first derivatives of the surface eigenfunctions with respect to a parameter. Eigenvalues and matrix elements computed by the POTHEA program can be used for solving the bound state and multi-channel scattering problems for a system of coupled second order ordinary differential equations with the help of the KANTBP program (Chuluunbaatar et al., 2007). Benchmark calculations of eigenvalues and eigenfunctions of the ground and first excited states of a Helium atom in the framework of a coupled-channel hyperspherical adiabatic approach are presented. As a test desk, the program is applied to the calculation of the eigensolutions of a 20 boundary value problem, their first derivatives with respect to a parameter and potential matrix elements used in the benchmark calculations.Program SummaryProgram title: POTHEACatalogue identifier: AESX_v1_0Program summary URL: http://cpc.cs.qub.ac.uk/summaries/AESX_v1_0.htmlProgram obtainable from:Licensing provisions: Standard CPC licence, http://cpc.cs.qub.ac.uk/licence/licence.htmlNo. of bits in distributed program, including test data, etc.: 36 929No. of lines in distributed program, including test data, etc.: 3 756Distribution format: tar.gzProgramming language: FORTRAN 77Computer: Personal computerOperating system: Unix/Linux, WindowsRAM: depends on(a) the number of differential equations,(b) the number and order of finite elements, and(b) the number of eigensolutions required.Classification: 2.7External routine: SSPACE [1], GAULEG [2]Nature of problem: Solutions of boundary value problems (BVPs) for the elliptic partial differential equations (PDEs) of the Schrodinger type find wide application in molecular, atomic and nuclear physics, for example, in three-dimensional tunneling of a diatomic molecule incident upon a potential barrier, fission model of collision of heavy ions, fragmentation of light nuclei, a hydrogen atom in magnetic field, photoionization of Helium like atoms, one photon ionization of atoms, electron-impact ionization of molecular hydrogen and photodissociation of molecules in strong laser field [3,4]. In the coupled-channel adiabatic approach (CCAA) [4], known in mathematical physics as the Kantorovich method, the desirable solution of the original boundary value problem (BVP) is expanded over surface eigenfunctions in fast variables (for example, angular variables) of an auxiliary BVP for an appropriate PDE dependent on a slow variable (for example, radial variable) as a parameter. Averaging of the original BVP over the surface eigenfunctions leads to 1D BVP for a system of coupled second-order ordinary differential equations (SOODEs) containing the potential matrix elements and first-derivative coupling terms that are integrals of the products of the surface eigenfunctions and/or the first derivatives of the surface eigenfunctions with respect to a parameter [4]. The purpose of this paper is to present the finite element method procedure based on the use of high-order accuracy approximations for calculating eigenvalues, 'surface eigenfunctions and their first derivatives with respect to a parameter of the parametric BVP for self-adjoined 2D PDE with the Dirichlet and/or Neumann type boundary conditions on a finite 2D region which arise at the reduction of the 3D BVP to 1D BVP for a system of coupled SOODEs in the framework of CCAA. The program developed calculates potential matrix elements that are integrals of the products of the surface eigenfunctions and/or the first derivatives of the surface eigenfunctions with respect to a parameter. These eigenvalues and potential matrix elements can be used for solving the bound state and multi-channel scattering problems for a system of coupled SOODEs with the help of the KANTBP program [5].Solution method: We seek the desirable solution of the parametric 2D BVP in the form of expansion in the basis functions of the auxiliary Sturm-Liouville problem with respect to one of the fast variables. They are chosen in analytical form or calculated by the ODPEVP program [6]. The coefficients of the expansion are vector-eigenfunctions of the parametric homogeneous 1D BVP for a system of coupled SOODEs obtained by averaging the original 2D problem over the basis functions. First derivatives with respect to the parameter of these vector-eigenfunctions and eigenvalues are solutions of the parametric inhomogeneous 1D BVP, obtained by taking a derivative of the parametric homogeneous 1D BVP with respect to the parameter [7]. Then, we solve the reduced parametric homogeneous and inhomogeneous 1D BVPs by the finite element method using high-order accuracy approximations [6]. The generalized algebraic eigenvalue problem AF = E BF with respect to a pair of unknowns (E, F) arising after the replacement of the differential problem by the finite-element approximation is solved by the subspace iteration method using the SSPACE program [1]. First derivatives of the vector-eigenfunctions and eigenvalues with respect to the parameter are obtained by solving the inhomogeneous algebraic equations in accordance with the algorithm used in [6]. Finally, we evaluate the desirable matrix elements using the calculated eigenvalues, vector-eigenfunctions and their derivatives, which can be applied to generate the coupled system equations in the slow variable in the CCAA.Benchmark calculations of eigenvalues and eigenfunctions of the ground and first excited states of a Helium atom in the framework of a coupled-channel hyperspherical adiabatic approach are presented. Additionally a convergence of the eigenvalues versus both the number of parametric vector-eigenfunctions and the number of their components is studied. As a test desk, the program is applied to the calculation of the eigensolutions and their first derivatives with respect to the parameter of the parametric 2D BVP including evaluation of matrix elements, which are used in the benchmark calculations.Restrictions: The computer memory requirements depend on:(a) the number of differential equations,(b) the number and order of finite elements, and(c) the number of eigensolutions required.Restrictions due to dimension sizes may be easily alleviated by altering PARAMETER statements (see Long Write-Up). The user must also supply subroutine POTCLC for evaluating potential matrix elements. The user must also supply additional three DOUBLE PRECISION functions (see Long Write-Up for details).Running rime: The running time depends critically upon:(a) the number of differential equations,(b) the number and order of finite elements, and(c) the number of eigensolutions required.The test run which accompanies this paper took 15 s with calculation of matrix potentials on computer Intel Core i5 CPU 3.33 GHz, 4 GB RAM, Windows 7. This test run requires 10 MB of disk storage.References:[1] K.J. Bathe, Finite Element Procedures in Engineering Analysis, Englewood Cliffs, Prentice Hall, New York, 1982.[2] W.H. Press, S.A. Teukolsky, W.T. Vetterling and B.P. Flannery, Numerical Recipes: The Art of Scientific Computing, Cambridge University Press, Cambridge, 1986.[3] M. Shapiro and P. Brumer, Quantum Control of Molecular Processes, Weley VCH, Verlag GmbH & Co. KGaA, Boschstr. 12, 69469 Weinheim, Germany, 2012.[4] U. Fano, Rep. Progr. Phys. 46 (1983) 97-165; U. Fano and A.R.P. Rau, Atomic Collisions and Spectra, Academic Press, Florida, 1986.[5] O. Chuluunbaatar, A.A. Gusev, A.G. Abrashkevich, A. Amaya-Tapia, M.S. Kaschiev, S.Y. Larsen and S.I. Vinitsky, Comput. Phys. Commun. 177 (2007) 649-675.[6] O. Chuluunbaatar, A.A. Gusev, S.I. Vinitsky and A.G. Abrashkevich, Comput. Phys. Commun. 180 (2009) 1358-1375.[7] A.G. Abrashkevich, M.S. Kaschiev and S.I. Vinitsky, J. Comp. Phys. 163 (2000) 328-348. (C) 2014 Elsevier B.V. All rights reserved.",Web of Science
"Goodenough, Kenneth; Elkouss, David; Wehner, Stephanie",Optimizing repeater schemes for the quantum internet,2021,10.1103/PhysRevA.103.032610,https://doi.org/10.1103/PhysRevA.103.032610,Journal,PHYSICAL REVIEW A,"The rate at which quantum communication tasks can be performed using direct transmission is fundamentally hindered by the channel loss. Quantum repeaters allow one, in principle, to overcome these limitations, but their introduction necessarily adds an additional layer of complexity to the distribution of entanglement. This additional complexity-along with the stochastic nature of processes such as entanglement generation, Bell swaps, and entanglement distillation-makes finding good quantum repeater schemes nontrivial. We develop an algorithm that can efficiently perform a heuristic optimization over a subset of quantum repeater schemes for general repeater platforms. We find a strong improvement in the generation rate in comparison to an optimization over a simpler class of repeater schemes based on BDCZ (Briegel, Dur, Cirac, Zoller) repeater schemes. We use the algorithm to study three different experimental quantum repeater implementations on their ability to distribute entanglement, which we dub information processing implementations, multiplexed elementary pair generation implementations, and combinations of the two. We perform this heuristic optimization of repeater schemes for each of these implementations for a wide range of parameters and different experimental settings. This allows us to make estimates on what are the most critical parameters to improve for entanglement generation, how many repeaters to use, and which implementations perform best in their ability to generate entanglement.",Web of Science
"Li, Boxi; Coopmans, Tim; Elkouss, David",Efficient Optimization of Cutoffs in Quantum Repeater Chains,2021,10.1109/TQE.2021.3099003,https://doi.org/10.1109/TQE.2021.3099003,Journal,IEEE TRANSACTIONS ON QUANTUM ENGINEERING,"Quantum communication enables the implementation of tasks that are unachievable with classical resources. However, losses on the communication channel preclude the direct long-distance transmission of quantum information in many relevant scenarios. In principle, quantum repeaters allow one to overcome losses. However, realistic hardware parameters make long-distance quantum communication a challenge in practice. For instance, in many protocols an entangled pair is generated that needs to wait in quantum memory until the generation of an additional pair. During this waiting time the first pair decoheres, impacting the quality of the final entanglement produced. At the cost of a lower rate, this effect can be mitigated by imposing a cutoff condition. For instance, a maximum storage time for entanglement after which it is discarded. In this article, we optimize the cutoffs for quantum repeater chains. First, we develop an algorithm for computing the probability distribution of the waiting time and fidelity of entanglement produced by repeater chain protocols which include a cutoff. Then, we use the algorithm to optimize cutoffs in order to maximize the secret-key rate between the end nodes of the repeater chain. In this article, we find that the use of the optimal cutoff extends the parameter regime for which secret key can be generated and, moreover, significantly increases the secret-key rate for a large range of parameters.",Web of Science
"Stanisic, Stasja; Bosse, Jan Lukas; Gambetta, Filippo Maria; Santos, Raul A.; Mruczkiewicz, Wojciech; O'Brien, Thomas E.; Ostby, Eric; Montanaro, Ashley",Observing ground-state properties of the Fermi-Hubbard model using a scalable algorithm on a quantum computer,2022,10.1038/s41467-022-33335-4,https://doi.org/10.1038/s41467-022-33335-4,Journal,NATURE COMMUNICATIONS,"The Fermi-Hubbard model represents one of the benchmarks for testing quantum computational methods for condensed matter. Here, the authors are able to reproduce qualitative properties of the model on 1 x 8 and 2 x 4 lattices, by running a VQE-based algorithm on a superconducting quantum processor.The famous, yet unsolved, Fermi-Hubbard model for strongly-correlated electronic systems is a prominent target for quantum computers. However, accurately representing the Fermi-Hubbard ground state for large instances may be beyond the reach of near-term quantum hardware. Here we show experimentally that an efficient, low-depth variational quantum algorithm with few parameters can reproduce important qualitative features of medium-size instances of the Fermi-Hubbard model. We address 1 x 8 and 2 x 4 instances on 16 qubits on a superconducting quantum processor, substantially larger than previous work based on less scalable compression techniques, and going beyond the family of 1D Fermi-Hubbard instances, which are solvable classically. Consistent with predictions for the ground state, we observe the onset of the metal-insulator transition and Friedel oscillations in 1D, and antiferromagnetic order in both 1D and 2D. We use a variety of error-mitigation techniques, including symmetries of the Fermi-Hubbard model and a recently developed technique tailored to simulating fermionic systems. We also introduce a new variational optimisation algorithm based on iterative Bayesian updates of a local surrogate model.",Web of Science
"Chan, Heang-Ping; Helvie, Mark A.; Gao, Mingjie; Hadjiiski, Lubomir; Zhou, Chuan; Garver, Kim; Klein, Katherine A.; McLaughlin, Carol; Oudsema, Rebecca; Rahman, W. Tania; Roubidoux, Marilyn A.",Deep learning denoising of digital breast tomosynthesis: Observer performance study of the effect on detection of microcalcifications in breast phantom images,2023,10.1002/mp.16439,https://doi.org/10.1002/mp.16439,Journal,MEDICAL PHYSICS,"BackgroundThe noise in digital breast tomosynthesis (DBT) includes x-ray quantum noise and detector readout noise. The total radiation dose of a DBT scan is kept at about the level of a digital mammogram but the detector noise is increased due to acquisition of multiple projections. The high noise can degrade the detectability of subtle lesions, specifically microcalcifications (MCs). PurposeWe previously developed a deep-learning-based denoiser to improve the image quality of DBT. In the current study, we conducted an observer performance study with breast radiologists to investigate the feasibility of using deep-learning-based denoising to improve the detection of MCs in DBT. MethodsWe have a modular breast phantom set containing seven 1-cm-thick heterogeneous 50% adipose/50% fibroglandular slabs custom-made by CIRS, Inc. (Norfolk, VA). We made six 5-cm-thick breast phantoms embedded with 144 simulated MC clusters of four nominal speck sizes (0.125-0.150, 0.150-0.180, 0.180-0.212, 0.212-0.250 mm) at random locations. The phantoms were imaged with a GE Pristina DBT system using the automatic standard (STD) mode. The phantoms were also imaged with the STD+ mode that increased the average glandular dose by 54% to be used as a reference condition for comparison of radiologists' reading. Our previously trained and validated denoiser was deployed to the STD images to obtain a denoised DBT set (dnSTD). Seven breast radiologists participated as readers to detect the MCs in the DBT volumes of the six phantoms under the three conditions (STD, STD+, dnSTD), totaling 18 DBT volumes. Each radiologist read all the 18 DBT volumes sequentially, which were arranged in a different order for each reader in a counter-balanced manner to minimize any potential reading order effects. They marked the location of each detected MC cluster and provided a conspicuity rating and their confidence level for the perceived cluster. The visual grading characteristics (VGC) analysis was used to compare the conspicuity ratings and the confidence levels of the radiologists for the detection of MCs. ResultsThe average sensitivities over all MC speck sizes were 65.3%, 73.2%, and 72.3%, respectively, for the radiologists reading the STD, dnSTD, and STD+ volumes. The sensitivity for dnSTD was significantly higher than that for STD (p < 0.005, two-tailed Wilcoxon signed rank test) and comparable to that for STD+. The average false positive rates were 3.9 +/- 4.6, 2.8 +/- 3.7, and 2.7 +/- 3.9 marks per DBT volume, respectively, for reading the STD, dnSTD, and STD+ images but the difference between dnSTD and STD or STD+ did not reach statistical significance. The overall conspicuity ratings and confidence levels by VGC analysis for dnSTD were significantly higher than those for both STD and STD+ (p <= 0.001). The critical alpha value for significance was adjusted to be 0.025 with Bonferroni correction. ConclusionsThis observer study using breast phantom images showed that deep-learning-based denoising has the potential to improve the detection of MCs in noisy DBT images and increase radiologists' confidence in differentiating noise from MCs without increasing radiation dose. Further studies are needed to evaluate the generalizability of these results to the wide range of DBTs from human subjects and patient populations in clinical settings.","Web of Science, Wiley"
"Elsedimy, E. I.; Elhadidy, Hala; Abohashish, Sara M. M.",A novel intrusion detection system based on a hybrid quantum support vector machine and improved Grey Wolf optimizer,2024,10.1007/s10586-024-04458-8,https://doi.org/10.1007/s10586-024-04458-8,Journal,CLUSTER COMPUTING-THE JOURNAL OF NETWORKS SOFTWARE TOOLS AND APPLICATIONS,"The Internet of Things (IoT) has grown significantly in recent years, allowing devices with sensors to share data via the internet. Despite the growing popularity of IoT devices, they remain vulnerable to cyber-attacks. To address this issue, researchers have proposed the Hybrid Intrusion Detection System (HIDS) as a way to enhance the security of IoT. This paper presents a novel intrusion detection model, namely QSVM-IGWO, for improving the detection capabilities and reducing false positive alarms of HIDS. This model aims to improve the performance of the Quantum Support Vector Machine (QSVM) by incorporating parameters from the Improved Grey Wolf Optimizer (IGWO) algorithm. IGWO is introduced under the hypothesis that the social hierarchy observed in grey wolves enhances the searching procedure and overcomes the limitations of GWO. In addition, the QSVM model is employed for binary classification by selecting the kernel function to obtain an optimal solution. Experimental results show promising performance of QSVM-IGWO in terms of accuracy, Recall, Precision, F1 score, and ROC curve, when compared with recent detection models.",Web of Science
"Ferrari, Davide; Carretta, Stefano; Amoretti, Michele",A Modular Quantum Compilation Framework for Distributed Quantum Computing,2023,10.1109/TQE.2023.3303935,https://doi.org/10.1109/TQE.2023.3303935,Journal,IEEE TRANSACTIONS ON QUANTUM ENGINEERING,"For most practical applications, quantum algorithms require large resources in terms of qubit number, much larger than those available with current noisy intermediate-scale quantum processors. With the network and communication functionalities provided by the quantum Internet, distributed quantum computing (DQC) is considered as a scalable approach for increasing the number of available qubits for computational tasks. For DQC to be effective and efficient, a quantum compiler must find the best partitioning for the quantum algorithm and then perform smart remote operation scheduling to optimize Einstein-Podolsky-Rosen (EPR) pair consumption. At the same time, the quantum compiler should also find the best local transformation for each partition. In this article, we present a modular quantum compilation framework for DQC that takes into account both network and device constraints and characteristics. We implemented and tested a quantum compiler based on the proposed framework with some circuits of interest, such as the VQE and QFT ones, considering different network topologies, with quantum processors characterized by heavy-hexagon coupling maps. We also devised a strategy for remote scheduling that can exploit both TeleGate and TeleData operations and tested the impact of using either only TeleGates or both. The evaluation results show that TeleData operations can have a positive impact on the number of consumed EPR pairs, depending on the characteristic of compiled circuit. Meanwhile, choosing a more connected network topology helps reduce the number of layers dedicated to remote operations.",Web of Science
"Yang, Lidong; Zhang, Yabin; Wang, Qianqian; Chan, Kai-Fung; Zhang, Li",Automated Control of Magnetic Spore-Based Microrobot Using Fluorescence Imaging for Targeted Delivery With Cellular Resolution,2020,10.1109/TASE.2019.2937232,https://doi.org/10.1109/TASE.2019.2937232,Journal,IEEE TRANSACTIONS ON AUTOMATION SCIENCE AND ENGINEERING,"Microrobotic delivery possesses a promising perspective for precision medicine and has attracted much attention recently. However, its automation remains challenging, especially with complex environmental conditions, such as obstacles and obstructed optical feedback. In this article, we propose an automated control approach for a new type of magnetic microrobot, i.e., the multifunctional magnetic spore (Mag-Spore), which has good potential for targeted delivery. By the surface functionalization of the spore with Fe3O4 nanoparticles and carbon quantum dots (QDs), it can be remotely actuated and tracked by an electromagnetic coil system and the fluorescence microscopy, respectively. Our control approach uses fluorescence imaging for vision feedback, which enhances the recognition and tracking of Mag-Spores, obstacles, and cells. Then, information of the obstacles, targeted cells, and Mag-Spores for planning and control is identified by image processing, and an optimal path planner with obstacle-avoidance capability is designed based on the particle swarm optimization (PSO) algorithm. To make the Mag-Spore follow the planed path accurately, a robust model predictive trajectory-tracking controller is synthesized. Simulations are conducted to validate the proposed control approach and tune the control parameters. Experiments demonstrate the effective targeted delivery of the Mag-Spore by using the proposed automated control method under the guidance of fluorescence imaging. Note to Practitioners-This article was motivated by the recent wide interest of precise targeted delivery using biohybrid magnetic microrobots. Driven by external magnetic fields, microrobots accomplish the targeted delivery tasks. In practical applications, obstacles and obstructed optical feedback often exist that make the delivery task challenging. The Mag-Spore presented here has a hollow structure, so that the cargo-carrying capability is maximized and supported by the proposed automated control techniques, and the delivery precision and efficiency are promised in multiple-obstacle scenarios. In addition, the control method has the robustness to model uncertainties and external disturbances that should be considered and well solved in applications. Fluorescence imaging, a common way for observing biomaterials, is compatible with the proposed control scheme and the developed software so that the recognition and tracking of the Mag-Spore and other biomaterials are improved. Moreover, the self-established plug-and-play (PnP) electromagnetic magnetic coil system has the feature of easy installation and configuration on fluorescence microscopes. Simulations and experiments validate the effectiveness of our method in fluorescence-guided targeted delivery using magnetic microrobots.",Web of Science
"Thorp, K. R.; Hunsaker, D. J.; French, A. N.; Bautista, E.; Bronson, K. F.","Integrating geospatial data and cropping system simulation within a geographic information system to analyze spatial seed cotton yield, water use, and irrigation requirements",2015,10.1007/s11119-015-9393-x,https://doi.org/10.1007/s11119-015-9393-x,Journal,PRECISION AGRICULTURE,"The development of sensors that provide geospatial information on crop and soil conditions has been a primary success for precision agriculture. However, further developments are needed to integrate geospatial data into computer algorithms that spatially optimize crop production while considering potential environmental impacts and resource limitations. The objective of this research was to combine several information technologies, including remote sensing, a cropping system model, and a geographic information system (GIS), to synthesize and interpret geospatial data collected during two irrigation scheduling experiments conducted in 2009 and 2011 in a 5-ha cotton field in central Arizona. The Geospatial Simulation (GeoSim) plug-in for Quantum GIS was used to manage geospatial data and conduct site-specific simulations with the CSM-CROPGRO-Cotton model. Simulated annealing optimization was used to adjust five model parameters to simulate site-specific conditions in 320 zones across the field. Using input parameters for GeoSim, a multiple criteria objective function was developed to incorporate measured and simulated leaf area index (LAI), crop canopy height, seed cotton yield, and evapotranspiration (ET) for site-specific optimization of CSM-CROPGRO-Cotton. Parameter identifiability and equifinality issues associated with model inversion were investigated. The optimized model was used for post hoc analysis of irrigation rates that maximized site-specific irrigation water use efficiency. With spatial optimization, the model was able to simulate LAI with root mean squared errors (RMSE) of 15 and 8 % in the 2009 and 2011 experiments, respectively. The RMSEs between measured and simulated canopy height, seed cotton yield, and ET were 5 % or less in both seasons. Some parameters were more identifiable than others during model inversions. Multiple temporal estimates of LAI were effective for constraining the model's specific leaf area parameter (SLAVR, cm(2) g(-1)), but lack of information on root growth reduce identifiability of a parameter related to that process (SRGF0). Post-hoc simulation analysis of irrigation management options showed that irrigation schedules based on remotely sensed vegetation indices increased irrigation water use efficiency as compared to traditional scheduling methods, particularly in the 2009 growing season. In 2011, the analysis showed that all scheduling methods resulted in excess irrigation application, and higher deep seepage rates were simulated in that season. Taken together, the results demonstrate that well-designed software tools and algorithms for data processing and interpretation can be potentially transformative for integrating multiple geospatial data sets to compute optimum scenarios for precision irrigation management.",Web of Science
"Wang, Xingwei; Qu, Dapeng; Li, Keqin; Cheng, Hui; Das, Sajal K.; Huang, Min; Wang, Renzheng; Chen, Shuliu",A flexible and generalized framework for access network selection in heterogeneous wireless networks,2017,10.1016/j.pmcj.2017.01.001,https://doi.org/10.1016/j.pmcj.2017.01.001,Journal,PERVASIVE AND MOBILE COMPUTING,"The rapid development and integration of heterogeneous wireless networks provide ubiquitous communications for mobile users. The intelligent and multimodal mobile terminals should select the best access network at any time anywhere. However, the best'' is a complex and fuzzy concept, which has different meanings to different users and even to the same user under different conditions. There are various factors to consider when deciding which one is the best for a mobile terminal. In this paper, we design a generalized and flexible framework for the access network selection in heterogeneous wireless networks. The framework is generalized because it considers various factors in a comprehensive way to get the solutions. These factors can be classified as network-related or user-related, economic or non-economic, objective or subjective, accurate or fuzzy. Meanwhile, the framework is also flexible because these factors can be customized and adapted to specific solutions. Under the framework, given Nmobile terminals and M access networks, we have developed a novel access network selection scheme based on a Quantum-inspired Immune Clonal Algorithm (QICA). Experimental results demonstrate that our proposed scheme provides better utilities for both the users and the access networks, and also better services for users as compared with four other schemes. (C) 2017 Elsevier B.V. All rights reserved.",Web of Science
"Chen, Zhenyu; Lin, Lijinzhi; Lin, Xiaodie; Wei, Zhaohui; Yao, Penghui",The Generations of Classical Correlations via Quantum Schemes,2024,10.1109/TIT.2024.3391341,https://doi.org/10.1109/TIT.2024.3391341,Journal,IEEE TRANSACTIONS ON INFORMATION THEORY,"Suppose two separated parties, Alice and Bob, share a bipartite quantum state or a classical correlation called a seed, and they try to generate a target classical correlation by performing local quantum or classical operations on the seed, i.e., any communications are not allowed. We consider the following fundamental problem about this setting: whether Alice and Bob can use a given seed to generate a target classical correlation. We show that this problem has rich mathematical structures. Firstly, we prove that even if the seed is a pure bipartite state, the above decision problem is already NP-hard and a similar conclusion can also be drawn when the seed is also a classical correlation, implying that this problem is hard to solve generally. Furthermore, we prove that when the seed is a pure quantum state, solving the problem is equivalent to finding out whether the target classical correlation has some diagonal form of positive semi-definite factorizations that matches the seed pure state, revealing an interesting connection between the current problem and optimization theory. Based on this observation and other insights, we give several necessary conditions where the seed pure state has to satisfy to generate the target classical correlation, and it turns out that these conditions can also be generalized to the case that the seed is a mixed quantum state. Lastly, since diagonal forms of positive semi-definite factorizations play a crucial role in solving the problem, we develop an algorithm that can compute them for an arbitrary classical correlation, which has decent performance on the cases we test.",Web of Science
"Rao, A. Rama Mohan; Lakshmi, K.; Kumar, S. Krishna",Detection of delamination in laminated composites with limited measurements combining PCA and dynamic QPSO,2015,10.1016/j.advengsoft.2015.04.005,https://doi.org/10.1016/j.advengsoft.2015.04.005,Journal,ADVANCES IN ENGINEERING SOFTWARE,"This paper presents an output only damage diagnostic algorithm based on frequency response functions and the principal components for health monitoring of laminated composite structures. The principal components evaluated from frequency response data, are employed as dynamical invariants to handle the effects of operational/environmental variability on the dynamic response of the structure. Finite element models of a laminated composite beam and plate are used to generate vibration data for healthy and damaged structures. Three numerical examples include a laminated composite beam, cantilever plate made of carbon-epoxy and a laminated composite simply supported plate. Varied levels of delamination of laminated composite plies and matrix cracking at varied locations in the plies are simulated at different spatial locations of the structure. Numerical investigations have been carried out to identify the spatial location of damage using the proposed principal component analysis (PCA) based algorithm. In order to limit the number of sensors on the structure, an optimal sensor placement algorithm based on PCA is employed in the present work and the effectiveness of the proposed algorithm with a limited number of sensors is also investigated. Finally, the inverse problem associated with the detection of delamination and matrix cracking is formulated as an optimization problem and is solved using the newly developed dynamic quantum particle swarm optimization (DQPSO) algorithm. Studies carried out and presented in this paper clearly indicate that the proposed SHM scheme can robustly identify the instant of damage, spatial location, the extent of delamination and matrix cracking even with limited sensor measurements and also with noisy data. (C) 2015 Elsevier Ltd. All rights reserved.",Web of Science
"Gunisetti, Loshma; Koduri, Shirin Bhanu; Jagannathan, Veeraraghavan",Optimized deep learning system for smart maize leaf disease detection in IoT platform via routing algorithm,2023,10.1007/s11042-022-13775-2,https://doi.org/10.1007/s11042-022-13775-2,Journal,MULTIMEDIA TOOLS AND APPLICATIONS,"Automatic recognition of leaf disease in plant is a difficult task in trending intelligent agriculture because of the variances of appearances and surroundings of crop diseases. In this paper, initially, the IoT nodes are simulated for gathering leaf information and the gathered information is transmitted through the optimal routes where the routes are selected using developed Competitive Shuffled Shepherd Optimization (CSSO) algorithm. The CSSO algorithm is designed by the integration of Competitive Swarm Optimizer (CSO) and Shuffled Shepherd Optimization algorithm (SSOA) for selecting the optimal path. The Leaf disease detection process is performed in the base station, where the detection process includes, pre-processing, feature extraction and disease detection. The pre-processing is carried out though ROI extraction, and the features, like Convolutional Neural Network (CNN) features, statistical features and energy texture features is employed to extract the relevant features. Finally, the maize leaf disease is detected from the extracted features using Deep Quantum Neural Network (Deep QNN), where the weight of Deep QNN is trained using developed CSSO algorithm. The experimental result demonstrates that the developed method outperforms than the existing methods based on the accuracy, sensitivity, specificity, F-Measure, energy, and delay of 95.037%, 96.404%, 93.35%, 95.12%, 99.9 J and 11.3 s, respectively.",Web of Science
"Cheng, Hao; Grossschaedl, Johann; Ronne, Peter B.; Ryan, Peter Y. A.",Lightweight Post-quantum Key Encapsulation for 8-bit AVR Microcontrollers,2021,10.1007/978-3-030-68487-7_2,https://doi.org/10.1007/978-3-030-68487-7_2,Conference Paper,19th International Conference on Smart Card Research and Advanced Applications (CARDIS),"Recent progress in quantum computing has increased interest in the question of how well the existing proposals for post-quantum cryptosystems are suited to replace RSA and ECC. While some aspects of this question have already been researched in detail (e.g. the relative computational cost of pre- and post-quantum algorithms), very little is known about the RAM footprint of the proposals and what execution time they can reach when low memory consumption rather than speed is the main optimization goal. This question is particularly important in the context of the Internet of Things (IoT) since many IoT devices are extremely constrained and possess only a few kB of RAM. We aim to contribute to answering this question by exploring the software design space of the lattice-based key-encapsulation scheme ThreeBears on an 8-bit AVR microcontroller. More concretely, we provide new techniques for the optimization of the ring arithmetic of ThreeBears (which is, in essence, a 3120-bit modular multiplication) to achieve either high speed or low RAM footprint, and we analyze in detail the trade-offs between these two metrics. A low-memory implementation of BabyBear that is secure against Chosen Plaintext Attacks (CPA) needs just about 1.7 kB RAM, which is significantly below the RAM footprint of other lattice-based cryptosystems reported in the literature. Yet, the encapsulation time of this RAM-optimized BabyBear version is below 12.5 million cycles, which is less than the execution time of scalar multiplication on Curve25519. The decapsulation is more than four times faster and takes roughly 3.4 million cycles on an ATmega1284 microcontroller.",Web of Science
"Zeng, Yuping",Parameter optimization of plug-in hybrid electric vehicle based on quantum genetic algorithm,2019,10.1007/s10586-018-2424-4,https://doi.org/10.1007/s10586-018-2424-4,Journal,CLUSTER COMPUTING-THE JOURNAL OF NETWORKS SOFTWARE TOOLS AND APPLICATIONS,"The parameters of the power system and the control strategy parameters are coupled,they work together to affect the power, economy and emission of the plug-in hybrid electric vehicle. Firstly, the real-time optimal control strategy based on the optimum of the vehicle power system's efficiency is developed. Secondly, the cost of the power system and indicators of vehicle's power performance are taken as constraints, the fuel consumption and emissions considering the engine's cold-heat effect are taken as the optimization objective, and in order to obtain the optimum solution of the power system's parameters and control strategy parameters, the standard genetic algorithm (SGA) and the quantum genetic algorithm (QGA) are applied to coordinated optimize them respectively. Finally, the simulation model of the vehicle system is established. After simulation, the simulation results show that compared with the original vehicle, the fuel economy and emission performance of the vehicle which parameters optimized by SGA and QGA has greatly improved, compared to the parameters optimization by SGA, the optimization by QGA can suppress premature convergence and have better fuel economy and emission performance.",Web of Science
"Stavdas, Alexandros and Kosmatos, Evangelos and Maple, Carsten and Hugues-Salas, Emilio and Epiphaniou, Gregory and Fowler, Daniel S. and Razak, Shadi A. and Matrakidis, Chris and Yuan, Hu and Lord, Andrew",Quantum Key Distribution for V2I communications with software-defined networking,2024,https://doi.org/10.1049/qtc2.12070,https://onlinelibrary.wiley.com/doi/abs/10.1049/qtc2.12070,Journal,IET Quantum Communication,"The evolution of Connected and Autonomous Vehicles (CAVs) promises improvements in our travel experience and the potential to enhance road safety and reduce environmental impact. This will be utilising highly diverse traffic environments that enable several advanced mobility applications. A secure, efficient, reliable, and resilient communications infrastructure is required to support developments in these CAV systems. Next generation of telecommunication networks will seamlessly integrate terrestrial, satellite, and airborne networks into a single wireless system satisfying the requirements of trustworthy future transport systems. Given the increasing importance of CAVs, coupled with their attractiveness as a cyber-attack for threat agents (e.g., disruption of transportation systems by nation states), security is paramount. Future communications systems offer an opportunity to integrate Quantum Key Distribution (QKD) into vehicular environments, protecting against advances in quantum computation that render many of the classical algorithms that underpin Public Key Infrastructure obsolete. This paper proposes a method for the integration of QKD in V2I networks to enable secure data communication. Quantum Key Distribution is used in the end-to-end path of vehicle-to-infrastructure (V2I) networks. Furthermore, an overarching Software-Defined Network, with integrated QKD, is introduced. We have investigated the security performance of QKD in a V2I network over an urban environment.",Wiley
"Li, Hang and Gao, Pan and Zhang, Jiang and Liu, Zhiyuan and Wei, Hai and Wen, Kai and Wei, Shijie and Long, Gui-Lu",BQ-Chem: A Quantum Software Program for Chemistry Simulation Based on the Full Quantum Eigensolver Algorithm,2022,https://doi.org/10.1155/2022/5872283,https://onlinelibrary.wiley.com/doi/abs/10.1155/2022/5872283,Journal,Quantum Engineering,"We describe a quantum chemistry simulation software program BQ-Chem, which can calculate the low-energy spectrum and potential energy surface of molecules on a quantum computer. BQ-Chem is based on the full quantum eigensolver (FQE), which is implemented with a quantum gradient descent algorithm. Benefiting from FQE, BQ-Chem can perform all the calculations on a quantum computer. Compared with the classical optimization methods which encounter the optimization difficulty of high-dimensional and multivariable functions in dealing with multielectron orbitals of macromolecules, FQE provides an exponential speedup. FQE works fully on a quantum computer; thus, BQ-Chem can be smoothly transited to future large-scale quantum computers.",Wiley
"Temen, Story and Jain, Amber and Akimov, Alexey V.",Hierarchical equations of motion in the Libra software package,2020,https://doi.org/10.1002/qua.26373,https://onlinelibrary.wiley.com/doi/abs/10.1002/qua.26373,Journal,International Journal of Quantum Chemistry,"We report the implementation of a hierarchical equations of motion (HEOM) module within the open-source Libra software. It includes the standard and scaled HEOM algorithms for computing the dynamics of open quantum systems interacting with a harmonic bath. The module allows the computing of the evolution of the reduced density matrix, as well as spectral lineshapes. The truncation, filtering, and ¡°update list¡± schemes, as well as OpenMP parallelization, allow for further computational saving. The package is written in a mix of C++ and Python languages, delivering the best compromise between user friendliness and efficiency. The Python layer of the package takes advantage of standard Python libraries, such as h5py, which allows efficient storage and retrieval of the generated results. The package can be seamlessly used within Jupyter notebooks; its careful design shall provide the maximal convenience and intuitiveness to its users.",Wiley
"Louren?o, Maicon Pierre and Hosta?, Ji?¨ª and Bellinger, Colin and Tchagang, Alain and Salahub, Dennis R.",Reinforcement learning for in silico determination of adsorbate¡ªsubstrate structures,2024,https://doi.org/10.1002/jcc.27322,https://onlinelibrary.wiley.com/doi/abs/10.1002/jcc.27322,Journal,Journal of Computational Chemistry,"Reinforcement learning (RL) methods have helped to define the state of the art in the field of modern artificial intelligence, mostly after the breakthrough involving AlphaGo and the discovery of novel algorithms. In this work, we present a RL method, based on Q-learning, for the structural determination of adsorbate@substrate models in silico, where the minimization of the energy landscape resulting from adsorbate interactions with a substrate is made by actions on states (translations and rotations) chosen from an agent's policy. The proposed RL method is implemented in an early version of the reinforcement learning software for materials design and discovery (RLMaterial), developed in Python3.x. RLMaterial interfaces with deMon2k, DFTB+, ORCA, and Quantum Espresso codes to compute the adsorbate@substrate energies. The RL method was applied for the structural determination of (i) the amino acid glycine and (ii) 2-amino-acetaldehyde, both interacting with a boron nitride (BN) monolayer, (iii) host-guest interactions between phenylboronic acid and ¦Â-cyclodextrin and (iv) ammonia on naphthalene. Density functional tight binding calculations were used to build the complex search surfaces with a reasonably low computational cost for systems (i)¨C(iii) and DFT for system (iv). Artificial neural network and gradient boosting regression techniques were employed to approximate the Q-matrix or Q-table for better decision making (policy) on next actions. Finally, we have developed a transfer-learning protocol within the RL framework that allows learning from one chemical system and transferring the experience to another, as well as from different DFT or DFTB levels.",Wiley
"Liu, Zhongyu and Chu, Xu and Lu, Yan and Yu, Wanli and Miao, Shuguang and Ding, Enjie",A Joint Optimization Framework of the Embedding Model and Classifier for Meta-Learning,2021,https://doi.org/10.1155/2021/1538914,https://onlinelibrary.wiley.com/doi/abs/10.1155/2021/1538914,Journal,Scientific Programming,"The aim of meta-learning is to train the machine to learn quickly and accurately. Improving the performance of the meta-learning model is important in solving the problem of small samples and in achieving general artificial intelligence. A meta-learning method based on feature embedding that exhibits good performance on the few-shot problem was previously proposed. In this method, the pretrained deep convolution neural network was used as the embedding model of sample features, and the output of one layer was used as the feature representation of samples. The main limitation of the method is the inability to fuse low-level texture features and high-level semantic features of the embedding model and joint optimization of the embedding model and classifier. Therefore, a multilayer adaptive joint training and optimization method of the embedding model was proposed in the current study. The main characteristics of the current method include using multilayer adaptive hierarchical loss to train the embedding model and using the quantum genetic algorithm to jointly optimize the embedding model and classifier. Validation was performed based on multiple public datasets for meta-learning model testing. The proposed method shows higher accuracy compared with multiple baseline methods.",Wiley
"Cheema, Sikander Singh and Singh, Amardeep and Gritli, Hass¨¨ne",Optimal Crop Selection Using Gravitational Search Algorithm,2021,https://doi.org/10.1155/2021/5549992,https://onlinelibrary.wiley.com/doi/abs/10.1155/2021/5549992,Journal,Mathematical Problems in Engineering,"For the economic growth of the crop, the optimal utilization of soil is found to be an open area of research. An efficient utilization includes various advantages such as watershed insurance, expanded biodiversity, and reduction of provincial destitution. Generally, soils present synthetic confinements for crop improvement. Therefore, in this paper, a novel diversified crop model is proposed to predict the suitable soil for good production of the crop. The proposed model utilizes a quantum value-based gravitational search algorithm (GSA) to optimize the best solution. Various features of soil are required to be investigated before crop selection. These features are refined further by applying quantum optimization. The crop selection based upon the soil requirement does not require any additional fertilizers which will reduce the production cost. Thus, the proposed model can select the optimal crop according to the soil components using the gravitational search algorithm. Therefore, the gravitational search algorithm is applied to the quantum values obtained from the crop and soil dataset. Extensive experiments show that the proposed model achieves an optimal selection of crops.",Wiley
"Pakela, Julia M. and Tseng, Huan-Hsin and Matuszak, Martha M. and Ten Haken, Randall K. and McShan, Daniel L. and El Naqa, Issam",Quantum-inspired algorithm for radiotherapy planning optimization,2020,https://doi.org/10.1002/mp.13840,https://onlinelibrary.wiley.com/doi/abs/10.1002/mp.13840,Journal,Medical Physics,"Purpose Modern inverse radiotherapy treatment planning requires nonconvex, large-scale optimizations that must be solved within a clinically feasible timeframe. We have developed and tested a quantum-inspired, stochastic algorithm for intensity-modulated radiotherapy (IMRT): quantum tunnel annealing (QTA). By modeling the likelihood probability of accepting a higher energy solution after a particle tunneling through a potential energy barrier, QTA features an additional degree of freedom (the barrier width, w) not shared by traditional stochastic optimization methods such as Simulated Annealing (SA). This additional degree of freedom can improve convergence rates and achieve a more efficient and, potentially, effective treatment planning process. Methods To analyze the character of the proposed QTA algorithm, we chose two stereotactic body radiation therapy (SBRT) liver cases of variable complexity. The ¡°easy¡± first case was used to confirm functionality, while the second case, with a more challenging geometry, was used to characterize and evaluate the QTA algorithm performance. Plan quality was assessed using dose-volume histogram-based objectives and dose distributions. Due to the stochastic nature of the solution search space, extensive tests were also conducted to determine the optimal smoothing technique, ensuring balance between plan deliverability and the resulting plan quality. QTA convergence rates were investigated in relation to the chosen barrier width function, and QTA and SA performances were compared regarding sensitivity to the choice of solution initializations, annealing schedules, and complexity of the dose-volume constraints. Finally, we investigated the extension from beamlet intensity optimization to direct aperture optimization (DAO). Influence matrices were calculated using the Eclipse scripting application program interface (API), and the optimizations were run on the University of Michigan's high-performance computing cluster, Flux. Results Our results indicate that QTA¡¯s barrier-width function can be tuned to achieve faster convergence rates. The QTA algorithm reached convergence up to 46.6\% faster than SA for beamlet intensity optimization and up to 26.8\% faster for DAO. QTA and SA were ultimately found to be equally insensitive to the initialization process, but the convergence rate of QTA was found to be more sensitive to the complexity of the dose-volume constraints. The optimal smoothing technique was found to be a combination of a Laplace-of-Gaussian (LOG) edge-finding filter implemented as a penalty within the objective function and a two-dimensional Savitzky¨CGolay filter applied to the final iteration; this achieved total monitor units more than 20\% smaller than plans optimized by commercial treatment planning software. Conclusions We have characterized the performance of a stochastic, quantum-inspired optimization algorithm, QTA, for radiotherapy treatment planning. This proof of concept study suggests that QTA can be tuned to achieve faster convergence than SA; therefore, QTA may be a good candidate for future knowledge-based or adaptive radiation therapy applications.",Wiley
"Atwal, P and Ramaseshan, R",SU-F-T-463: Light-Field Based Dynalog Verification,2016,https://doi.org/10.1118/1.4956648,https://onlinelibrary.wiley.com/doi/abs/10.1118/1.4956648,Journal,Medical Physics,"Purpose: To independently verify leaf positions in so-called dynalog files for a Varian iX linac with a Millennium 120 MLC. This verification provides a measure of confidence that the files can be used directly as part of a more extensive intensity modulated radiation therapy / volumetric modulated arc therapy QA program. Methods: Initial testing used white paper placed at the collimator plane and a standard hand-held digital camera to image the light and shadow of a static MLC field through the paper. Known markings on the paper allow for image calibration. Noise reduction was attempted with removal of ¡®inherent noise¡¯ from an open-field light image through the paper, but the method was found to be inconsequential. This is likely because the environment could not be controlled to the precision required for the sort of reproducible characterization of the quantum noise needed in order to meaningfully characterize and account for it. A multi-scale iterative edge detection algorithm was used for localizing the leaf ends. These were compared with the planned locations from the treatment console. Results: With a very basic setup, the image of the central bank A leaves 15¨C45, which are arguably the most important for beam modulation, differed from the planned location by [0.38¡À0.28] mm. Similarly, for bank B leaves 15¨C45 had a difference of [0.42¡À0.28] mm Conclusion: It should be possible to determine leaf position accurately with not much more than a modern hand-held camera and some software. This means we can have a periodic and independent verification of the dynalog file information. This is indicated by the precision already achieved using a basic setup and analysis methodology. Currently, work is being done to reduce imaging and setup errors, which will bring the leaf position error down further, and allow meaningful analysis over the full range of leaves.",Wiley
"Asna, Madathodika and Shareef, Hussain and Muhammad, Munir Azam and Ismail, Leila and Prasanthi, Achikkulath",Multi-objective quantum atom search optimization algorithm for electric vehicle charging station planning,2022,https://doi.org/10.1002/er.8399,https://onlinelibrary.wiley.com/doi/abs/10.1002/er.8399,Journal,International Journal of Energy Research,"Summary This paper presents an effective planning methodology for electric vehicle (EV) fast-charging stations (CS) using a multi-objective binary version of the atom search optimization (ASO) algorithm. The proposed method uses quantum operations to binarize the algorithm and achieve a higher convergence rate than the existing binary ASO algorithm. Additionally, a modified atom selection function is used to improve the searching capability of the ASO algorithm. Furthermore, the nondominated sorting procedure and pareto concepts are infused to solve the CS location problem (CSLP) considering the EV travel time, CS costs, and grid power loss as independent multi-objectives. The efficacy of the proposed multi-objective quantum ASO (MO-QASO) algorithm is evaluated using performance metrics namely, inverted generational distance (IGD), spacing (SP), and maximum spread (MS). The MO-QASO simulation results are compared with the results of other heuristic algorithms. MO-QASO achieves the best IGD (0.0021), SP (0.0002), and MS (0.9982) values, verifying the convergence and diversity of the algorithm. Importantly, the best CS planning solution obtained from MO-QASO is similar to the true solution obtained from the exhaustive search method. The MO-QASO efficiency is further validated by solving a CSLP from literature. Thus, the MO-QASO algorithm is a promising optimization tool for solving CSLP.",Wiley
"Di Pasquale, Nicodemo and Bane, Michael and Davie, Stuart J. and Popelier, Paul L. A.",FEREBUS: Highly parallelized engine for kriging training,2016,https://doi.org/10.1002/jcc.24486,https://onlinelibrary.wiley.com/doi/abs/10.1002/jcc.24486,Journal,Journal of Computational Chemistry,"FFLUX is a novel force field based on quantum topological atoms, combining multipolar electrostatics with IQA intraatomic and interatomic energy terms. The program FEREBUS calculates the hyperparameters of models produced by the machine learning method kriging. Calculation of kriging hyperparameters (¦È and p) requires the optimization of the concentrated log-likelihood . FEREBUS uses Particle Swarm Optimization (PSO) and Differential Evolution (DE) algorithms to find the maximum of . PSO and DE are two heuristic algorithms that each use a set of particles or vectors to explore the space in which is defined, searching for the maximum. The log-likelihood is a computationally expensive function, which needs to be calculated several times during each optimization iteration. The cost scales quickly with the problem dimension and speed becomes critical in model generation. We present the strategy used to parallelize FEREBUS, and the optimization of through PSO and DE. The code is parallelized in two ways. MPI parallelization distributes the particles or vectors among the different processes, whereas the OpenMP implementation takes care of the calculation of , which involves the calculation and inversion of a particular matrix, whose size increases quickly with the dimension of the problem. The run time shows a speed-up of 61 times going from single core to 90 cores with a saving, in one case, of ?98\% of the single core time. In fact, the parallelization scheme presented reduces computational time from 2871 s for a single core calculation, to 41 s for 90 cores calculation. ? 2016 The Authors. Journal of Computational Chemistry Published by Wiley Periodicals, Inc.",Wiley
"Gokcan, Hatice and Isayev, Olexandr",Learning molecular potentials with neural networks,2022,https://doi.org/10.1002/wcms.1564,https://onlinelibrary.wiley.com/doi/abs/10.1002/wcms.1564,Journal,WIREs Computational Molecular Science,"The potential energy of molecular species and their conformers can be computed with a wide range of computational chemistry methods, from molecular mechanics to ab initio quantum chemistry. However, the proper choice of the computational approach based on computational cost and reliability of calculated energies is a dilemma, especially for large molecules. This dilemma is proved to be even more problematic for studies that require hundreds and thousands of calculations, such as drug discovery. On the other hand, driven by their pattern recognition capabilities, neural networks started to gain popularity in the computational chemistry community. During the last decade, many neural network potentials have been developed to predict a variety of chemical information of different systems. Neural network potentials are proved to predict chemical properties with accuracy comparable to quantum mechanical approaches but with the cost approaching molecular mechanics calculations. As a result, the development of more reliable, transferable, and extensible neural network potentials became an attractive field of study for researchers. In this review, we outlined an overview of the status of current neural network potentials and strategies to improve their accuracy. We provide recent examples of studies that prove the applicability of these potentials. We also discuss the capabilities and shortcomings of the current models and the challenges and future aspects of their development and applications. It is expected that this review would provide guidance for the development of neural network potentials and the exploitation of their applicability. This article is categorized under: Data Science > Artificial Intelligence/Machine Learning Molecular and Statistical Mechanics > Molecular Interactions Software > Molecular Modeling",Wiley
"Faritha Banu, J. and Neelakandan, S. and Geetha, B.T and Selvalakshmi, V. and Umadevi, A. and Martinson, Eric Ofori",Artificial Intelligence Based Customer Churn Prediction Model for Business Markets,2022,https://doi.org/10.1155/2022/1703696,https://onlinelibrary.wiley.com/doi/abs/10.1155/2022/1703696,Journal,Computational Intelligence and Neuroscience,"The introduction of artificial intelligence (AI) and machine learning (ML) technologies in recent years has resulted in improved company performance. Customer churn forecast is a difficult problem in many corporate sectors, particularly the telecommunications industry. Because customer churns have a direct impact on a company's total revenue, telecommunications firms have begun to develop 76 models to reduce churns at an earlier stage. Previous research has revealed that AI and ML models are effective CCP solutions. According to this viewpoint, this study proposes a unique AI-based CCP model for Telecommunication Business Markets (AICCP-TBM). The AICCP-TBM model's purpose is to control the existence of churners and non-churners in the telecom sector. The proposed AICCP-TBM model employs a Chaotic Salp Swarm Optimization-based Feature Selection (CSSO-FS) method for the best feature assortment. In addition, a Fuzzy Rule-based Classifier(FRC) is used to distinguish between client churners and non-churners. A technique known as Quantum Behaved Particle Swarm Optimization (QPSO) is used to pick the membership functions for the FRC model in order to improve the classification performance of the FRC model. The performance of the AICCP-TBM model is validated using a benchmark CCP dataset and the experimental results are reviewed from several angles. In relations of presentation, the imitation consequences demonstrated that the AICCP-TBM model surpassed the most recent state-of-the-art CPP models. The suggested AICCP-TBM method's comparative accuracy was thoroughly tested on the three datasets used. Using datasets 1-3, this technique obtained better levels of accuracy, with the maximum attainable values being 97.25 \%, 97.5 \% and 94.33 \%. The simulation results for the AICCP-TBM model demonstrated improved prediction performance.",Wiley
"Nazareth, D and Spaans, J",SU-F-BRD-13: Quantum Annealing Applied to IMRT Beamlet Intensity Optimization,2014,https://doi.org/10.1118/1.4889067,https://onlinelibrary.wiley.com/doi/abs/10.1118/1.4889067,Journal,Medical Physics,"Purpose: We report on the first application of quantum annealing (QA) to the process of beamlet intensity optimization for IMRT. QA is a new technology, which employs novel hardware and software techniques to address various discrete optimization problems in many fields. Methods: We apply the D-Wave Inc. proprietary hardware, which natively exploits quantum mechanical effects for improved optimization. The new QA algorithm, running on this hardware, is most similar to simulated annealing, but relies on natural processes to directly minimize the free energy of a system. A simple quantum system is slowly evolved into a classical system, representing the objective function. To apply QA to IMRT-type optimization, two prostate cases were considered. A reduced number of beamlets were employed, due to the current QA hardware limitation of ?500 binary variables. The beamlet dose matrices were computed using CERR, and an objective function was defined based on typical clinical constraints, including dose-volume objectives. The objective function was discretized, and the QA method was compared to two standard optimization Methods: simulated annealing and Tabu search, run on a conventional computing cluster. Results: Based on several runs, the average final objective function value achieved by the QA was 16.9 for the first patient, compared with 10.0 for Tabu and 6.7 for the SA. For the second patient, the values were 70.7 for the QA, 120.0 for Tabu, and 22.9 for the SA. The QA algorithm required 27¨C38\% of the time required by the other two methods. Conclusion: In terms of objective function value, the QA performance was similar to Tabu but less effective than the SA. However, its speed was 3¨C4 times faster than the other two methods. This initial experiment suggests that QA-based heuristics may offer significant speedup over conventional clinical optimization methods, as quantum annealing hardware scales to larger sizes.",Wiley
"Lafata, K and Ren, L and Wu, Q and Kelsey, C and Hong, J and Cai, J and Yin, F",SU-D-204-01: A Methodology Based On Machine Learning and Quantum Clustering to Predict Lung SBRT Dosimetric Endpoints From Patient Specific Anatomic Features,2016,https://doi.org/10.1118/1.4955606,https://onlinelibrary.wiley.com/doi/abs/10.1118/1.4955606,Journal,Medical Physics,"Purpose: To develop a data-mining methodology based on quantum clustering and machine learning to predict expected dosimetric endpoints for lung SBRT applications based on patient-specific anatomic features. Methods: Ninety-three patients who received lung SBRT at our clinic from 2011¨C2013 were retrospectively identified. Planning information was acquired for each patient, from which various features were extracted using in-house semi-automatic software. Anatomic features included tumor-to-OAR distances, tumor location, total-lung-volume, GTV and ITV. Dosimetric endpoints were adopted from RTOG-0195 recommendations, and consisted of various OAR-specific partial-volume doses and maximum point-doses. First, PCA analysis and unsupervised quantum-clustering was used to explore the feature-space to identify potentially strong classifiers. Secondly, a multi-class logistic regression algorithm was developed and trained to predict dose-volume endpoints based on patient-specific anatomic features. Classes were defined by discretizing the dose-volume data, and the feature-space was zero-mean normalized. Fitting parameters were determined by minimizing a regularized cost function, and optimization was performed via gradient descent. As a pilot study, the model was tested on two esophageal dosimetric planning endpoints (maximum point-dose, dose-to-5cc), and its generalizability was evaluated with leave-one-out cross-validation. Results: Quantum-Clustering demonstrated a strong separation of feature-space at 15Gy across the first-and-second Principle Components of the data when the dosimetric endpoints were retrospectively identified. Maximum point dose prediction to the esophagus demonstrated a cross-validation accuracy of 87\%, and the maximum dose to 5cc demonstrated a respective value of 79\%. The largest optimized weighting factor was placed on GTV-to-esophagus distance (a factor of 10 greater than the second largest weighting factor), indicating an intuitively strong correlation between this feature and both endpoints. Conclusion: This pilot study shows that it is feasible to predict dose-volume endpoints based on patient-specific anatomic features. The developed methodology can potentially help to identify patients at risk for higher OAR doses, thus improving the efficiency of treatment planning. R01-184173",Wiley
"Jin, Ki-Sung and Cha, Gyu-Il","QPlayer: Lightweight, scalable, and fast quantum simulator",2023,https://doi.org/10.4218/etrij.2021-0442,https://onlinelibrary.wiley.com/doi/abs/10.4218/etrij.2021-0442,Journal,ETRI Journal,"With the rapid evolution of quantum computing, digital quantum simulations are essential for quantum algorithm verification, quantum error analysis, and new quantum applications. However, the exponential increase in memory overhead and operation time is challenging issues that have not been solved for years. We propose a novel approach that provides more qubits and faster quantum operations with smaller memory than before. Our method selectively tracks realized quantum states using a reduced quantum state representation scheme instead of loading the entire quantum states into memory. This method dramatically reduces memory space ensuring fast quantum computations without compromising the global quantum states. Furthermore, our empirical evaluation reveals that our proposed idea outperforms traditional methods for various algorithms. We verified that the Grover algorithm supports up to 55 qubits and the surface code algorithm supports up to 85 qubits in 512?GB memory on a single computational node, which is against the previous studies that support only between 35 qubits and 49 qubits.",Wiley
"Chen, HaiDong and Zhang, JuFang",[Retracted] An Intelligent Evaluation Method of Information Course Teaching Effect Based on Image Analysis,2021,https://doi.org/10.1155/2021/3200865,https://onlinelibrary.wiley.com/doi/abs/10.1155/2021/3200865,Journal,Scientific Programming,"Due to its own limitations, the traditional teaching quality evaluation method has been unable to adapt to the development of information-based curriculum teaching. Therefore, the establishment of a scientific and intelligent teaching effect evaluation method will help to improve the teaching quality of college teachers. To solve the above problems, a student fatigue state evaluation method based on the quantum particle swarm optimization artificial neural network is proposed. Firstly, face detection is realized by adding three Haar-like feature blocks and improving the AdaBoost algorithm of a weak classifier connection. Secondly, in order to effectively improve the image imbalance, the MSR algorithm is used to enhance the face data image, which is effectively suitable for network training. Then, by readjusting the connection mode, the DenseNet is improved to fully reflect the local detail feature information of the low level. Finally, quantum particle swarm optimization (QPSO) is used to optimize the DenseNet structure, which makes the optimization of network structure more automatic and solves the uncertainty of manual selection. The experimental results show that the proposed method has a good detection effect and prove the effectiveness and correctness of the proposed method.",Wiley
"Laghuvarapu, Siddhartha and Pathak, Yashaswi and Priyakumar, U. Deva",BAND NN: A Deep Learning Framework for Energy Prediction and Geometry Optimization of Organic Small Molecules,2020,https://doi.org/10.1002/jcc.26128,https://onlinelibrary.wiley.com/doi/abs/10.1002/jcc.26128,Journal,Journal of Computational Chemistry,"Recent advances in artificial intelligence along with the development of large data sets of energies calculated using quantum mechanical (QM)/density functional theory (DFT) methods have enabled prediction of accurate molecular energies at reasonably low computational cost. However, machine learning models that have been reported so far require the atomic positions obtained from geometry optimizations using high-level QM/DFT methods as input in order to predict the energies and do not allow for geometry optimization. In this study, a transferable and molecule size-independent machine learning model bonds (B), angles (A), nonbonded (N) interactions, and dihedrals (D) neural network (BAND NN) based on a chemically intuitive representation inspired by molecular mechanics force fields is presented. The model predicts the atomization energies of equilibrium and nonequilibrium structures as sum of energy contributions from bonds (B), angles (A), nonbonds (N), and dihedrals (D) at remarkable accuracy. The robustness of the proposed model is further validated by calculations that span over the conformational, configurational, and reaction space. The transferability of this model on systems larger than the ones in the data set is demonstrated by performing calculations on selected large molecules. Importantly, employing the BAND NN model, it is possible to perform geometry optimizations starting from nonequilibrium structures along with predicting their energies. ? 2019 Wiley Periodicals, Inc.",Wiley
"Hua, Nan and Liu, Han-Yang and Xiong, Xiao-Yun and Wang, Jin-Long and Liang, Jun-Qing",A Dynamic Image Encryption Scheme Based on Quantum Walk and Chaos-Induced DNA,2023,https://doi.org/10.1155/2023/3431107,https://onlinelibrary.wiley.com/doi/abs/10.1155/2023/3431107,Journal,Quantum Engineering,"The development of quantum information technology and increasing attention of people to the secure transmission of image information in the Internet have put forward higher requirements for traditional image encryption algorithms that not only take advantage of the exponential acceleration ability of quantum computing compared with classical computing but also reduce the risk of encryption algorithms being cracked. Therefore, in order to seek the combination of the advantages of quantum computing and classical image encryption algorithms, this paper proposes a new dynamic encryption image scheme of quantum walk and chaos-induced DNA. Firstly, the RGB three-channel pixels of the color image are extracted and combined into a one-dimensional array, and a random sequence is generated by quantum walk to reorder it to obtain a preliminary scrambled image; secondly, the color image is processed by the SHA-256 algorithm and divided into the generated message digest as the initial condition of the chaotic model. The random sequence was generated by the high-dimensional chaotic model which encodes each pixel independently and disorderly as DNA bases. The difference of the chaotic sequence ensures the dynamic selection of random DNA encoding and decoding rules during encryption. At the same time, the number of times of DNA encryption of the encoded pixel value is also controlled by the dynamic induction of the chaotic sequence, and ultimately, the DNA coding sequence is replaced with the decimal pixel value to obtain the encrypted image. The simulation results show that the information entropy of the encrypted image is above 7.99, and the correlation of each channel is close to 0, which can effectively resist brute force attacks, plaintext attacks, statistical analysis attacks, noise attacks, etc. In addition, in this paper, extracting the watermark embedded in the encrypted image to judge whether image information is tampered or forged further improves the security of the image information.",Wiley
"Moshayedi, Shiva and Shafiei, Fatemeh and Momeni Isfahani, Tahereh",QSPR models to predict quantum chemical properties of imidazole derivatives using genetic algorithm¨Cmultiple linear regression and back-propagation¨Cartificial neural network,2022,https://doi.org/10.1002/qua.27003,https://onlinelibrary.wiley.com/doi/abs/10.1002/qua.27003,Journal,International Journal of Quantum Chemistry,"Imidazole derivatives are the foundation of different types of drugs with a wide range of biological activities. In this study, the genetic algorithm¨Cmultiple linear regression (GA¨CMLR), and backpropagation¨Cartificial neural network (BP¨CANN) were applied to design QSPR models to predict the quantum chemical properties like the entropy (S) and enthalpy of formation (?Hf) of imidazole derivatives. In order to draw molecular structure of 84 derivative compounds Gauss View 05 program was used. These structures were optimized at DFT-B3LYP/6-311G* level with Gaussian09W. The Dragon software was used to calculate a set of different molecular descriptors, and the genetic algorithm procedure and backward stepwise regression were applied for the selection of descriptors. The resulting quantitative GA¨CMLR model of ?Hf, showed that there is good linear correlation between the selected descriptors and ?Hf of compounds. Also the results show that the BP¨CANN model appeared to be superior to GA¨CMLR model for prediction of entropy. Different internal and external validation metrics were adopted to verify the predictive performance of QSPR models. The predictive powers of the models were found to be acceptable. Thus, these QSPR models may be useful for designing new series of imidazole derivatives and prediction of their properties.",Wiley
"Wang, Wen and Zhang, Xin and Liu, Xiaoning",[Retracted] Construction and Quality Control of Subway Wet Loess in Concealed Tunnel Based on Particle Swarm Optimization Algorithm,2022,https://doi.org/10.1155/2022/3655202,https://onlinelibrary.wiley.com/doi/abs/10.1155/2022/3655202,Journal,Journal of Sensors,"To reduce urban pressure, urban rail transit has become an effective way to reduce traffic congestion, mitigate traffic accidents, reduce environmental pollution, and improve commuting efficiency. Subway as the main means of urban public transport travel, in recent years by people¡¯s favor, although the construction industry of rail transit is developing rapidly and the industry scale is expanding, but because the construction of rail transit construction projects is very difficult, especially in the wet loess within the concealed excavation tunnel, but also frequent accidents, and the quality of the project is not easy to guarantee, so the underground railroad wet loess within the concealed excavation tunnel construction technology is poor. Therefore, it is especially important to study the construction technology and project quality management of underground railway concealed tunnel in wet loess. In this paper, based on the in-depth study of the basic principle of quantum particle swarm optimization calculation and the realization of key engineering technologies, the particle swarm optimization algorithm is programed using MATLAB software, and the coding scheme, operation specification, and operation parameters are designed. Then, combined with the particle swarm optimization algorithm and assisted MATLAB software, the main analysis of the construction and quality control of wet loess in concealed tunnels of subway projects was carried out, mainly by systematizing the relationship between the three major elements of subway project schedule, cost, and management and the construction and quality control of wet loess in concealed tunnels of a subway, and concluded that the construction and quality control of wet loess in concealed tunnels of the subway needed schedule. It is concluded that the construction and quality control of subway wet loess tunnel requires stable schedule, adequate cost budget, and management personnel.",Wiley
"Ouedrhiri, Oumayma and Banouar, Oumayma and El Hadaj, Salah and Raghay, Said",Intelligent recommender system based on quantum clustering and matrix completion,2022,https://doi.org/10.1002/cpe.6943,https://onlinelibrary.wiley.com/doi/abs/10.1002/cpe.6943,Journal,Concurrency and Computation: Practice and Experience,"Faster than classical algorithms, quantum algorithms benefit from the superposition property of quantum information to offer significant speedup to complex algorithms. Therefore, quantum computing can be used to help machine learning algorithms by boosting their performance and accelerate the processing of time-consuming ones. Clustering algorithms are very complex unsupervised learning algorithms. Indeed, the similarity calculation (distance) between input vectors is a resource-consuming step, especially when working with large datasets. In this article, we propose a new better-performing recommender system that operates as a combination of an adapted quantum K-means algorithm and the singular value decomposition (SVT) algorithm. We integrate the developed quantum clustering algorithm to a prediction process of the proposed recommender system using matrix completion. To the best of our knowledge, no system with such details was proposed in the literature. The system was applied on the MovieLens dataset without a dimensionality reduction step and evaluated according to measures of information retrieval systems. The results of the quantum K-means algorithm show that the quantum version leads to a logarithmic reduction of the time complexity compared to the classical algorithm. The proposed system has proved to be better than the previous tested ones in terms of precision and recall.",Wiley
"Jiang, Huiyan and Zhao, Di and Zheng, Ruiping and Ma, Xiaoqi",Construction of Pancreatic Cancer Classifier Based on SVM Optimized by Improved FOA,2015,https://doi.org/10.1155/2015/781023,https://onlinelibrary.wiley.com/doi/abs/10.1155/2015/781023,Journal,BioMed Research International,"A novel method is proposed to establish the pancreatic cancer classifier. Firstly, the concept of quantum and fruit fly optimal algorithm (FOA) are introduced, respectively. Then FOA is improved by quantum coding and quantum operation, and a new smell concentration determination function is defined. Finally, the improved FOA is used to optimize the parameters of support vector machine (SVM) and the classifier is established by optimized SVM. In order to verify the effectiveness of the proposed method, SVM and other classification methods have been chosen as the comparing methods. The experimental results show that the proposed method can improve the classifier performance and cost less time.",Wiley
"Panda, Arnapurna",Determining approximate solution of partial differential equations using radial basis function model trained with parallel symbiotic organisms search algorithm,2023,https://doi.org/10.1002/cpe.7558,https://onlinelibrary.wiley.com/doi/abs/10.1002/cpe.7558,Journal,Concurrency and Computation: Practice and Experience,"Summary Partial differential equations (PDEs) find extensive applications in geophysics (weather and climate modeling), astrophysics, and quantum mechanics. Solving PDEs by the conventional methods at times becomes difficult due to the complexity involved in these real-world problems. Thus instead of an exact solution determining an approximate solution is also helpful for solving the problems. Here a model based on radial basis function (RBF) trained with parallel symbiotic organism search (PSOS) optimization is proposed to find out an approximate solution. The PSOS is a nature-inspired optimization algorithm that ensures better accuracy due to the potential exploration of agents in the search space. Simultaneously, the computational complexity of this algorithm is low due to inbuilt parallelism. Simulation studies are reported for five real applications of PDEs: 2D modified Helmholtz equation, Poisson problem with Dirichlet boundary condition, elliptic PDE equation, and two convection-diffusion equations. Comparison is carried out with the same RBF model parameters trained with parallel social spider optimization, original symbiotic organisms search algorithm, real coded genetic algorithm, and particle swarm optimization. The proposed model achieves minimum root mean square errors in most of the cases and achieves it with lower run time compared to the existing algorithms.",Wiley
"Eugene DePrince III, A.",Variational determination of the two-electron reduced density matrix: A tutorial review,2024,https://doi.org/10.1002/wcms.1702,https://onlinelibrary.wiley.com/doi/abs/10.1002/wcms.1702,Journal,WIREs Computational Molecular Science,"The two-electron reduced density matrix (2RDM) carries enough information to evaluate the electronic energy of a many-electron system. The variational 2RDM (v2RDM) approach seeks to determine the 2RDM directly, without knowledge of the wave function, by minimizing this energy with respect to variations in the elements of the 2RDM, while also enforcing known N-representability conditions. In this tutorial review, we provide an overview of the theoretical underpinnings of the v2RDM approach and the N-representability constraints that are typically applied to the 2RDM. We also discuss the semidefinite programming (SDP) techniques used in v2RDM computations and provide enough Python code to develop a working v2RDM code that interfaces to the libSDP library of SDP solvers. This article is categorized under: Electronic Structure Theory > Ab Initio Electronic Structure Methods Software > Quantum Chemistry",Wiley
"Mafu, Mhlambululi",Advances in artificial intelligence and machine learning for quantum communication applications,2024,https://doi.org/10.1049/qtc2.12094,https://onlinelibrary.wiley.com/doi/abs/10.1049/qtc2.12094,Journal,IET Quantum Communication,"Artificial intelligence (AI) and classical machine learning (ML) techniques have revolutionised numerous fields, including quantum communication. Quantum communication technologies rely heavily on quantum resources, which can be challenging to produce, control, and maintain effectively to ensure optimum performance. ML has recently been applied to quantum communication and networks to mitigate noise-induced errors and analyse quantum protocols. The authors systematically review state-of-the-art ML applications to advance theoretical and experimental central quantum communication protocols, specifically quantum key distribution, quantum teleportation, quantum secret sharing, and quantum networks. Specifically, the authors survey the progress on how ML and, more broadly, AI techniques have been applied to optimise various components of a quantum communication system. This has resulted in ultra-secure quantum communication protocols with optimised key generation rates as well as efficient and robust quantum networks. Integrating AI and ML techniques opens intriguing prospects for securing and facilitating efficient and reliable large-scale communication between multiple parties. Most significantly, large-scale communication networks have the potential to gradually develop the maturity of a future quantum internet.",Wiley
"Liu, Hong-Xia and Zhang, Yong-Heng and Tsai, Sang-Bing",Cloud Education Chain and Education Quality Evaluation Based on Hybrid Quantum Neural Network Algorithm,2021,https://doi.org/10.1155/2021/1909345,https://onlinelibrary.wiley.com/doi/abs/10.1155/2021/1909345,Journal,Wireless Communications and Mobile Computing,"This paper proposes the functional model and application service implementation process of the education cloud platform application service architecture. The entire cloud application service architecture mainly includes four parts: cloud service management, cloud application service rapid creation and deployment, dynamic process configuration, and unified identity authentication. Based on the basic theory of workflow, the process status and business services of cloud application services are discussed. The BP neural network weight optimization model based on the improved quantum evolution method is studied, and a method that combines the improved quantum evolution algorithm (IQEA) and the BP algorithm to complete the back propagation neural network training is proposed, that is, the IQEA-BP algorithm. Firstly, the traditional quantum evolution algorithm is improved, and then, the improved quantum evolution algorithm is used to optimize the network weights as a whole to overcome the shortcomings of the BP algorithm that is easy to fall into the local optimum; then, we use the BP algorithm to find the better weight as the initial value to improve the training and prediction accuracy of the network. In order to enrich the school education quality evaluation system, this article adds soft indicators that can reflect school education performance on the basis of the existing ¡°National Education Inspection Team¡± indicators and uses analytical methods to prove the effectiveness and feasibility of the new evaluation indicators. The X1-X10 index data is selected as the evaluation index of the school education quality evaluation system in this paper. Testing the performance of the BP neural network, the accuracy rate of the school education quality evaluation is 93.3\%, the average absolute error is 0.067, and the accuracy and recall rate of the test set grade gradient of 0, 1, 2, 3, 5, 6, and 8 are all 93\%, indicating that the IQEA-BP neural network algorithm has a good effect on the evaluation of school education quality.",Wiley
"Hoffmann, Roald and Malrieu, Jean-Paul","Simulation vs. Understanding: A Tension, in Quantum Chemistry and Beyond. Part A. Stage Setting",2020,https://doi.org/10.1002/ange.201902527,https://onlinelibrary.wiley.com/doi/abs/10.1002/ange.201902527,Journal,Angewandte Chemie,"We begin our tripartite Essay with a triangle of understanding, theory and simulation. Sketching the intimate tie between explanation and teaching, we also point to the emotional impact of understanding. As we trace the development of theory in chemistry, Dirac's characterization of what is known and what is needed for theoretical chemistry comes up, as does the role of prediction, and Thom's phrase ¡°To predict is not to explain.¡± We give a typology of models, and then describe, no doubt inadequately, machine learning and neural networks. In the second part, we leave philosophy, beginning by describing Roald's being beaten by simulation. This leads us to artificial intelligence (AI), Searle's Chinese room, and Strevens¡¯ account of what a go-playing program knows. Back to our terrain¡ªwe ask ¡°Quantum Chemistry, ? ca. 2020?¡± Then move to examples of AI affecting social matters, ranging from trivial to scary. We argue that moral decisions are hardly to be left to a computer. At this point, we try to pull the reader up, giving the opposing view of an optimistic, limitless future a voice. But we don't do justice to that view¡ªhow could we? We return to questioning the ascetic dimension of scientists, their romance with black boxes. Onward: In the 3rd part of this Essay, we work our way up from pessimism. We trace (another triangle!) the special interests of experimentalists, who want the theory we love, and reliable numbers as well. We detail in our own science instances where theory gave us real joy. Two more examples-on magnetic coupling in inorganic diradicals, and the way to think about alkali metal halides, show us the way to integrate simulation with theory. Back and forth is how it should be¡ªbetween painfully-obtained, intriguing numbers, begging for interpretation, in turn requiring new concepts, new models, new theoretically grounded tools of computation. Through such iterations understanding is formed. As our tripartite Essay ends, we outline a future of consilience, with a role both for fact-seekers, and searchers for understanding. Chemistry's streak of creation provides in that conjoined future a passage to art and to perceiving, as we argue we must, the sacred in science.",Wiley
"Demerdash, Omar and Wang, Lee-Ping and Head-Gordon, Teresa",Advanced models for water simulations,2018,https://doi.org/10.1002/wcms.1355,https://onlinelibrary.wiley.com/doi/abs/10.1002/wcms.1355,Journal,WIREs Computational Molecular Science,"Molecular simulations of water using classical, molecular mechanic potential energy functions have enjoyed a 50-year history of development, and much has been learned regarding their parameterization and the essential physics that must be captured in order to reproduce water properties across the phase diagram and across system sizes, from the dimer to the condensed phase. While pairwise-additive force fields using fixed, point charge-based electrostatics have dominated this history owing to computational cost, their limitations in transferability are being recognized, owing particularly to the lack of many-body effects, as well as an inherent difficulty in capturing quantum mechanical effects that become important at short intermolecular separation. This has spurred an impressive development of novel functional forms and parameterization schemes to account for such effects, especially the leading many-body effect of polarization. This review discusses recent efforts in the development of advanced models of water, particularly with regard to important details of their parameterization from quantum mechanical or experimental data, the development of novel functional forms including machine learning-based models, and algorithms that reduce the computational cost of polarization dramatically, permitting them to potentially become competitive with pairwise-additive models as the standby of condensed-phase simulation. These technical developments are appraised based on their ability to impact numerical calculations on water, particularly the condensed phase, and it is hoped that this article provides a clear connection between the essential physics captured by the model and their fitness across a range of environments. WIREs Comput Mol Sci 2018, 8:e1355. doi: 10.1002/wcms.1355 This article is categorized under: Computer and Information Science > Computer Algorithms and Programming Molecular and Statistical Mechanics > Molecular Interactions Software > Simulation Methods",Wiley
"Butscher, Julian F. and Kwon, Seonil and Popczyk, Anna and Gather, Malte C.",Open-Source Tools for the Fabrication and Characterization of Organic Electronics,,https://doi.org/10.1002/aelm.202400460,https://onlinelibrary.wiley.com/doi/abs/10.1002/aelm.202400460,Journal,Advanced Electronic Materials,,Wiley
"Wang, Ting and Xia, Ke-Wen and Tang, Hai-Lin and Zhang, Su-Wei and Sandrine, Mukase",A Modified Wolf Pack Algorithm for Multiconstrained Sparse Linear Array Synthesis,2020,https://doi.org/10.1155/2020/9483971,https://onlinelibrary.wiley.com/doi/abs/10.1155/2020/9483971,Journal,International Journal of Antennas and Propagation,"The aim of the research is to propose a new optimization method for the multiconstrained optimization of sparse linear arrays (including the constraints of the number of elements, the aperture of arrays, and the minimum distance between adjacent elements). The new method is a modified wolf pack optimization algorithm based on the quantum theory. In the new method, wolves are coded by Bloch spherical coordinates of quantum bits, updated by quantum revolving gates, and selectively adaptively mutated when performing poorly. Because of the three-coordinate characteristics of the sphere, the number of global optimum solutions is greatly expanded and ultimately can be searched with a higher probability. Selective mutation enhances the robustness of the algorithm and improves the search speed. Furthermore, because the size of each dimension of Bloch spherical coordinates is always [?1, 1], the variables transformed by solution space must satisfy the constraints of the aperture of arrays and the minimum distance between adjacent elements, which effectively avoids infallible solutions in the process of updating and mutating the position of the wolf group, reduces the judgment steps, and improves the efficiency of optimization. The validity and robustness of the proposed method are verified by the simulation of two typical examples, and the optimization efficiency of the proposed method is higher than the existing methods.",Wiley
"Liu, Wenjie and Chen, Junxiu and Wang, Yuxiang and Gao, Peipei and Lei, Zhibin and Ma, Xu",Quantum-Based Feature Selection for Multiclassification Problem in Complex Systems with Edge Computing,2020,https://doi.org/10.1155/2020/8216874,https://onlinelibrary.wiley.com/doi/abs/10.1155/2020/8216874,Journal,Complexity,"The complex systems with edge computing require a huge amount of multifeature data to extract appropriate insights for their decision making, so it is important to find a feasible feature selection method to improve the computational efficiency and save the resource consumption. In this paper, a quantum-based feature selection algorithm for the multiclassification problem, namely, QReliefF, is proposed, which can effectively reduce the complexity of algorithm and improve its computational efficiency. First, all features of each sample are encoded into a quantum state by performing operations CMP and Ry, and then the amplitude estimation is applied to calculate the similarity between any two quantum states (i.e., two samples). According to the similarities, the Grover¨CLong method is utilized to find the nearest k neighbor samples, and then the weight vector is updated. After a certain number of iterations through the above process, the desired features can be selected with regards to the final weight vector and the threshold ¦Ó. Compared with the classical ReliefF algorithm, our algorithm reduces the complexity of similarity calculation from O(MN) to O(M), the complexity of finding the nearest neighbor from O(M) to OM, and resource consumption from O(MN) to O(MlogN). Meanwhile, compared with the quantum Relief algorithm, our algorithm is superior in finding the nearest neighbor, reducing the complexity from O(M) to OM. Finally, in order to verify the feasibility of our algorithm, a simulation experiment based on Rigetti with a simple example is performed.",Wiley
"Hong Enriquez, Rolando P. and Badia, Rosa M. and Chapman, Barbara and Bresniker, Kirk and Pakin, Scott and Mishra, Alok and Bruel, Pedro and Dhakal, Aditya and Rattihalli, Gourav and Hogade, Ninad and Frachtenberg, Eitan and Milojicic, Dejan",Quantum optimization algorithms: Energetic implications,2024,https://doi.org/10.1002/cpe.8121,https://onlinelibrary.wiley.com/doi/abs/10.1002/cpe.8121,Journal,Concurrency and Computation: Practice and Experience,"Summary Since the dawn of quantum computing (QC), theoretical developments like Shor's algorithm proved the conceptual superiority of QC over traditional computing. However, such quantum supremacy claims are difficult to achieve in practice because of the technical challenges of realizing noiseless qubits. In the near future, QC applications will need to rely on noisy quantum devices that offload part of their work to classical devices. One way to achieve this is by using parameterized quantum circuits in optimization or even in machine learning tasks. The energy requirements of quantum algorithms have not yet been studied extensively. In this article, we explore several optimization algorithms using both theoretical insights and numerical experiments to understand their impact on energy consumption. Specifically, we highlight why and how algorithms like quantum natural gradient descent, simultaneous perturbation stochastic approximations or circuit learning methods, are at least 2¡Á\$\$ 2\times \$\$ to 4¡Á\$\$ 4\times \$\$ more energy efficient than their classical counterparts; why feedback-based quantum optimization is energy-inefficient; and how techniques like Rosalin can improve the energy efficiency of other algorithms by a factor of ¡Ý\$\$ \ge \$\$20¡Á\$\$ \times \$\$. Finally, we use the NchooseK high-level programming model to run optimization problems on both gate-based quantum computers and quantum annealers. Empirical data indicate that these optimization problems run faster, have better success rates, and consume less energy on quantum annealers than on their gate-based counterparts.",Wiley
"Ragab, Mahmoud and Alshehri, Samah and Alhakamy, Nabil A. and Alsaggaf, Wafaa and Alhadrami, Hani A. and Alyami, Jaber",Machine Learning with Quantum Seagull Optimization Model for COVID-19 Chest X-Ray Image Classification,2022,https://doi.org/10.1155/2022/6074538,https://onlinelibrary.wiley.com/doi/abs/10.1155/2022/6074538,Journal,Journal of Healthcare Engineering,"Early and accurate detection of COVID-19 is an essential process to curb the spread of this deadly disease and its mortality rate. Chest radiology scan is a significant tool for early management and diagnosis of COVID-19 since the virus targets the respiratory system. Chest X-ray (CXR) images are highly useful in the effective detection of COVID-19, thanks to its availability, cost-effective means, and rapid outcomes. In addition, Artificial Intelligence (AI) techniques such as deep learning (DL) models play a significant role in designing automated diagnostic processes using CXR images. With this motivation, the current study presents a new Quantum Seagull Optimization Algorithm with DL-based COVID-19 diagnosis model, named QSGOA-DL technique. The proposed QSGOA-DL technique intends to detect and classify COVID-19 with the help of CXR images. In this regard, the QSGOA-DL technique involves the design of EfficientNet-B4 as a feature extractor, whereas hyperparameter optimization is carried out with the help of QSGOA technique. Moreover, the classification process is performed by a multilayer extreme learning machine (MELM) model. The novelty of the study lies in the designing of QSGOA for hyperparameter optimization of the EfficientNet-B4 model. An extensive series of simulations was carried out on the benchmark test CXR dataset, and the results were assessed under different aspects. The simulation results demonstrate the promising performance of the proposed QSGOA-DL technique compared to recent approaches.",Wiley
"Zhao, Yanwei and Leng, Longlong and Zhang, Jingling and Zhang, Chunmiao and Wang, Wanliang",Evolutionary Hyperheuristics for Location-Routing Problem with Simultaneous Pickup and Delivery,2020,https://doi.org/10.1155/2020/9291434,https://onlinelibrary.wiley.com/doi/abs/10.1155/2020/9291434,Journal,Complexity,"This paper presents an evolution-based hyperheuristic (EHH) for addressing the capacitated location-routing problem (CLRP) and one of its more practicable variants, namely, CLRP with simultaneous pickup and delivery (CLRPSPD), which are significant and NP-hard model in the complex logistics system. The proposed approaches manage a pool of low-level heuristics (LLH), implementing a set of simple, cheap, and knowledge-poor operators such as ¡°shift¡± and ¡°swap¡± to guide the search. Quantum (QS), ant (AS), and particle-inspired (PS) high-level learning strategies (HLH) are developed as evolutionary selection strategies (ESs) to improve the performance of the hyperheuristic framework. Meanwhile, random permutation (RP), tabu search (TS), and fitness rate rank-based multiarmed bandit (FRR-MAB) are also introduced as baselines for comparisons. We evaluated pairings of nine different selection strategies and four acceptance mechanisms and monitored the performance of the first four outstanding pairs in 36 pairs by solving three sets of benchmark instances from the literature. Experimental results show that the proposed approaches outperform most fine-tuned bespoke state-of-the-art approaches in the literature, and PS-AM and AS-AM perform better when compared to the rest of the pairs in terms of obtaining a good trade-off of solution quality and computing time.",Wiley
"Li, Yuanyuan and Sun, Qichun and Xu, Hua and Li, Xiaogang and Fang, Zhijun and Yao, Wei",Rolling Bearing Fault Diagnosis Based on SVM Optimized with Adaptive Quantum DE Algorithm,2022,https://doi.org/10.1155/2022/8126464,https://onlinelibrary.wiley.com/doi/abs/10.1155/2022/8126464,Journal,Shock and Vibration,"In order to optimize traditional fault diagnosis models for practical applications, a fault diagnosis model based on support vector machines optimized with the adaptive quantum differential evolution of (AQDE-SVM) is proposed in this study. First, the traditional differential evolution is rewritten based on real number encoded into a qubit encoding. Second, this study proposes an adaptive quantum rotation gate and uses this gate to update the probability amplitude of the qubits. Finally, compared with quantum genetic algorithm support vector machines (QGA-SVM) and differential evolution-support vector machines (DE-SVM), etc., the results show that the algorithm proposed in this study has a higher diagnosis accuracy and shorter running time, providing great practical engineering value in the application of rolling bearing fault diagnosis.",Wiley
"Yuan, Kai and Zhou, Shuai and Li, Ning and Li, Tianyan and Ding, Bowen and Guo, Danhuai and Ma, Yingjin",Fault-tolerant quantum chemical calculations with improved machine-learning models,2024,https://doi.org/10.1002/jcc.27459,https://onlinelibrary.wiley.com/doi/abs/10.1002/jcc.27459,Journal,Journal of Computational Chemistry,"Easy and effective usage of computational resources is crucial for scientific calculations. Following our recent work of machine-learning (ML) assisted scheduling optimization [J. Comput. Chem. 2023, 44, 1174], we further propose (1) the improved ML models for the better predictions of computational loads, and as such, more elaborate load-balancing calculations can be expected; (2) the idea of coded computation, that is, the integration of gradient coding, in order to introduce fault tolerance during the distributed calculations; and (3) their applications together with re-normalized exciton model with time-dependent density functional theory (REM-TDDFT) for calculating the excited states. Illustrated benchmark calculations include P38 protein, and solvent model with one or several excitable centers. The results show that the improved ML-assisted coded calculations can further improve the load-balancing and cluster utilization, owing primarily profit in fault tolerance that aims at the automated quantum chemical calculations for both ground and excited states.",Wiley
"Zhou, Guo and Zhao, Ruxin and Luo, Qifang and Zhou, Yongquan",Optimal hydropower station dispatch using quantum social spider optimization algorithm,2022,https://doi.org/10.1002/cpe.5782,https://onlinelibrary.wiley.com/doi/abs/10.1002/cpe.5782,Journal,Concurrency and Computation: Practice and Experience,"Summary In this article, a new quantum social spider optimization (QSSO) algorithm is proposed. In the QSSO algorithm, we introduce an encoding approach based on bits described on social spider optimization (SSO) and serves as the evolution method of the population space. For the encoding of individuals, the probability amplitude expression of quantum bit is applied to describe the position of individuals, by which one individual's position can be expressed as the superposition of multistates. In such a way, the population diversity and the global searching capability of the SSO algorithm are enhanced. The QSSO algorithm was used to optimize the hydropower station dispatch, and the calculation results show that QSSO algorithm has fast convergence, small number of tuning parameters, high calculation accuracy, stability, simple, and is easy to be implemented with strong global search capability.",Wiley
"Shrivastava, Pranav and Alam, Bashir and Alam, Mansaf",Blockchain assisted blind signature algorithm with data integrity verification scheme,2024,https://doi.org/10.1002/cpe.8071,https://onlinelibrary.wiley.com/doi/abs/10.1002/cpe.8071,Journal,Concurrency and Computation: Practice and Experience,"Summary As the demand for cloud storage systems increases, ensuring the security and integrity of cloud data becomes a challenge. Data uploaded to cloud systems are vulnerable to numerous sorts of assaults, which must be handled appropriately to avoid data tampering issues. In addition, quantum computers are expected to be introduced soon, which may face multiple security issues by destroying all traditional cryptosystems. This work introduces a quantum-resistant blockchain centered data integrity verification system with the use of several techniques. Initially, the keys and signatures are generated by the users with the help of the lattice-based blind signature algorithm (L\_BSA), which is a combination of lattice cryptography and a blind signature algorithm. From the generated random keys, the most optimal key is then selected by the Puzzle Optimization Algorithm (POA), which is then made available to the encryption phase. Then, the upgraded Merkle tree-assisted vacuum filter (Vac-UMT) algorithm is executed to accomplish the encryption task. Then the data are converted into blocks using blockchain technology and uploaded to the cloud. When receiving the audit requests, the verification process is carried out, and the evidence report is generated for the users. The proposed work is simulated in JAVA and assessed with the UNSW-NB15 dataset, and the outcomes demonstrated that the system is highly efficient and secure.",Wiley
"Zhang, Cheng and Sjarif, Nilam Nur Amir and Ibrahim, Roslina",Deep learning models for price forecasting of financial time series: A review of recent advancements: 2020¨C2022,2024,https://doi.org/10.1002/widm.1519,https://onlinelibrary.wiley.com/doi/abs/10.1002/widm.1519,Journal,WIREs Data Mining and Knowledge Discovery,"Accurately predicting the prices of financial time series is essential and challenging for the financial sector. Owing to recent advancements in deep learning techniques, deep learning models are gradually replacing traditional statistical and machine learning models as the first choice for price forecasting tasks. This shift in model selection has led to a notable rise in research related to applying deep learning models to price forecasting, resulting in a rapid accumulation of new knowledge. Therefore, we conducted a literature review of relevant studies over the past 3?years with a view to aiding researchers and practitioners in the field. This review delves deeply into deep learning-based forecasting models, presenting information on model architectures, practical applications, and their respective advantages and disadvantages. In particular, detailed information is provided on advanced models for price forecasting, such as Transformers, generative adversarial networks (GANs), graph neural networks (GNNs), and deep quantum neural networks (DQNNs). The present contribution also includes potential directions for future research, such as examining the effectiveness of deep learning models with complex structures for price forecasting, extending from point prediction to interval prediction using deep learning models, scrutinizing the reliability and validity of decomposition ensembles, and exploring the influence of data volume on model performance. This article is categorized under: Technologies > Prediction Technologies > Artificial Intelligence",Wiley
"Hoffmann, Roald and Malrieu, Jean-Paul","Simulation vs. Understanding: A Tension, in Quantum Chemistry and Beyond. Part B. The March of Simulation, for Better or Worse",2020,https://doi.org/10.1002/ange.201910283,https://onlinelibrary.wiley.com/doi/abs/10.1002/ange.201910283,Journal,Angewandte Chemie,"In the second part of this Essay, we leave philosophy, and begin by describing Roald's being trashed by simulation. This leads us to a general sketch of artificial intelligence (AI), Searle's Chinese room, and Strevens¡¯ account of what a go-playing program knows. Back to our terrain¡ªwe ask ¡°Quantum Chemistry, ? ca. 2020?¡± Then we move to examples of Big Data, machine learning and neural networks in action, first in chemistry and then affecting social matters, trivial to scary. We argue that moral decisions are hardly to be left to a computer. And that posited causes, even if recognized as provisional, represent a much deeper level of understanding than correlations. At this point, we try to pull the reader up, giving voice to the opposing view of an optimistic, limitless future. But we don't do justice to that view¡ªhow could we, older mammals on the way to extinction that we are? We try. But then we return to fuss, questioning the ascetic dimension of scientists, their romance with black boxes. And argue for a science of many tongues.",Wiley
"Ahia, Chinedu Christian and Meyer, Edson L.",Advances in the Use of Atomic Force Microscopy as a Diagnostic Tool for Solar Cells Characterization: From Material Design to Device Applications,2024,https://doi.org/10.1002/pssa.202300293,https://onlinelibrary.wiley.com/doi/abs/10.1002/pssa.202300293,Journal,physica status solidi (a),"Considerable efforts in search for an effective characterization technique for photovoltaic devices with utmost precision is on the increase. For precise analysis and tailoring of device performance, a reliable technique is vital. Atomic force microscopy is one of the leading surface analysis techniques of choice for probing surface patterns in a variety of materials with atomic precision using a cantilever. It has evolved as a reliable technique for the investigation of subatomic scale properties of materials such as photocurrent heterogeneity, electromechanical response, charge distribution, molecular weight effects, and many other material parameters. The integration of artificial intelligence hybrid algorithms in atomic force microscope for optoelectronic device fabrication and characterization has increasingly emerged to be desirable due to its reliability and effectiveness in achieving high image resolution, automated analysis, actuation, and the coupling of manufactured units with a precision down to atomic units. In this review, an investigation of topical developments in the use of atomic force microscopy as a diagnostic tool for solar cells characterization is presented with special focus on polymer solar cells, perovskite solar cells, quantum dots-sensitized solar cells, dye-sensitized solar cells, fullerene-based solar cells, III-V-based solar cells, and silicon-based solar cells.",Wiley
"Sworna Kokila, M. L. and Bibin Christopher, V. and Ramya, G.",Enhanced power system fault detection using quantum-AI and herd immunity quantum-AI fault detection with herd immunity optimisation in power systems,2024,https://doi.org/10.1049/qtc2.12106,https://onlinelibrary.wiley.com/doi/abs/10.1049/qtc2.12106,Journal,IET Quantum Communication,"Quantum computing and deep learning have recently gained popularity across various industries, promising revolutionary advancements. The authors introduce QC-PCSANN-CHIO-FD, a novel approach that enhances fault detection in electrical power systems by combining quantum computing, deep learning, and optimisation algorithms. The network, based on a Pyramidal Convolution Shuffle Attention Neural Network (PCSANN) optimised with the Coronavirus Herd Immunity Optimiser, shows promising results. Initially, historical datasets are used for fault detection. Preprocessing, which includes handling missing data and outliers using Adaptive Variational Bayesian Filtering is followed by Dual-Domain Feature Extraction to extract grayscale statistical features. These features are processed by PCSANN to detect faults. The Coronavirus Herd Immunity Optimisation Algorithm is proposed to optimise PCSANN for precise fault detection. Performance of the proposed QC-PCSANN-CHIO-FD approach attains 24.11\%, 28.56\% and 22.73\% high specificity, 21.89\%, 23.04\% and 9.51\% lower computation Time, 25.289\%, 15.35\% and 19.91\% higher ROC and 8.65\%, 13.8\%, and 7.15\% higher Accuracy compared with existing methods, such as combining deep learning based on quantum computing for electrical power system malfunction diagnosis (QC-ANN-FD), electrical power system fault diagnostics using hybrid quantum-classical deep learning (QC-CRBM-FD), applications of machine learning to the identification of power system faults: Recent developments and future directions (QC-RF-FD).",Wiley
"Antkowiak, M. and Kucharski, ?. and Lema¨½ski, R. and Kamieniarz, G.",Algorithms on low energy spectra of the Hubbard model pertinent to molecular nanomagnets,2024,https://doi.org/10.1002/cpe.7931,https://onlinelibrary.wiley.com/doi/abs/10.1002/cpe.7931,Journal,Concurrency and Computation: Practice and Experience,"Summary Computer supported design of materials with tailored properties is an important part of computational science so that developments of new effective algorithms is a key issue. Molecular magnetism deals with complex objects described by the quantum physics and their simulations come up against the computational constraints. In this work, we consider a numerical version of a recently developed hybrid approach that combines the ab initio DFT method with the exact diagonalization of the microscopic Hubbard model (HM). The latter avoids the prior perturbative framework but increases computing resources needed for solving the eigenvalue problem of the matrix representation of HM. We demonstrate that in the case of the ring-shape molecular nanomagnets the computational demands can be curbed due to efficient numerical matrix construction algorithms provided. These algorithms pertain both to the calculation of the single nonzero matrix elements and to their localization in the final sparse matrix that is subsequently diagonalized. Their implementation executed on a simple six-core-computer system and the Mathematica environment leads to a significant gain in the computing time for the exemplary chromium-based molecule denoted Cr8\$\$ {}\_8 \$\$, running the code sequentially. We claim, referring to the numerical diagonalization of the spin Hamiltonian matrices, that the parallelization flaws related to the high-level programming approach can be all removed, porting the code to the appropriate HPC environment. A prospective implementation of the code, based on some dedicated and optimized mathematical libraries, will ultimately open a window for further applications of the Hubbard model in molecular magnetism.",Wiley
"Dovesi, Roberto and Erba, Alessandro and Orlando, Roberto and Zicovich-Wilson, Claudio M. and Civalleri, Bartolomeo and Maschio, Lorenzo and R¨¦rat, Michel and Casassa, Silvia and Baima, Jacopo and Salustro, Simone and Kirtman, Bernard",Quantum-mechanical condensed matter simulations with CRYSTAL,2018,https://doi.org/10.1002/wcms.1360,https://onlinelibrary.wiley.com/doi/abs/10.1002/wcms.1360,Journal,WIREs Computational Molecular Science,"The features of the publicly distributed CRYSTAL program for quantum-mechanical condensed matter simulations are reviewed and the latest version of the code, namely CRYSTAL17, is introduced.",Wiley
"Saleem, Sehar and Sherwani, Rehan Ahmad Khan and Amin, Muhammad and Khalid, Maryam and Ali, Nouman",Development of New Robust Optimal Score Function for the Weibull Distributed Error Term in Multilevel Models,2021,https://doi.org/10.1155/2021/1953546,https://onlinelibrary.wiley.com/doi/abs/10.1155/2021/1953546,Journal,Mathematical Problems in Engineering,"A popular robust estimation technique for linear models is the rank-based method as an alternative to the ordinary least square (OLS) and restricted maximum likelihood (REML) in the presence of extreme observations. This method is applied in machine reliability analysis and quantum engineering, especially in artificial intelligence and optimization problems where outliers are commonly observed. This technique is also extended for the multilevel model, where the shape of error distribution contributes a significant role in more efficient estimation. In this study, we proposed the Weibull score function for the Weibull distributed error terms in the multilevel model. The efficiency of the proposed score function is compared with the existing Wilcoxon score function and the traditional method REML via Monte Carlo simulations after adding simulated extreme observations. For small values of shape parameter in Weibull distribution of error term showing the presence of outliers, the Weibull score function was found to be efficient as compared to the Wilcoxon and REML methods. However, for a large value of shape parameter, Wilcoxon score appeared either equally efficient than the Weibull score function. REML is observed least precise in all situations. These findings are verified through a real application on test scores data, with a small value of shape parameter, and the Weibull score function turned out the most efficient.",Wiley
"de Avila, Anderson B. and Reiser, Renata H. S. and Pilla, Mauricio L.",Quantum computing simulation through reduction and decomposition optimizations with a case study of Shor's algorithm,2017,https://doi.org/10.1002/cpe.3961,https://onlinelibrary.wiley.com/doi/abs/10.1002/cpe.3961,Journal,Concurrency and Computation: Practice and Experience,"Summary Because of the expansion of transformations and read/write memory states by tensor products in multidimensional quantum applications, the exponential increase in temporal and spatial complexities constitutes one of the main challenges for quantum computing simulations. Simulation of these systems is very relevant to develop and test new quantum algorithms. In order to overcome the increase in simulation complexity, this work presents reduction and decomposition optimizations for the Distributed Geometric Machine environment. By exploring properties as the sparsity of the Identity operator and partiality of dense unitary transformations, better storage and distribution of quantum information are achieved. The main improvements are reached by decreasing replication and void elements inherited from quantum operators. In the evaluation of this proposal, Hadamard transformations from 21 to 28 qubits and Quantum Fourier Transforms from 26 to 28 qubits were simulated over CPU, sequentially and in parallel, and in graphics processing unit, showing reduced temporal complexity and, consequently, shorter simulation time. Moreover, evaluations of the Shor's algorithm considering 2n + 3 qubits in the order-finding quantum algorithm were simulated up to 25 qubits. When comparing our implementations running on the same hardware with language-integrated quantum operation, academic release version, our new simulator was faster and allowed for the simulation of more qubits. Copyright ? 2016 John Wiley \& Sons, Ltd.",Wiley
"Dharminder, Dharminder and Das, Ashok Kumar and Saha, Sourav and Bera, Basudeb and Vasilakos, Athanasios V.",Post-Quantum Secure Identity-Based Encryption Scheme using Random Integer Lattices for IoT-enabled AI Applications,2022,https://doi.org/10.1155/2022/5498058,https://onlinelibrary.wiley.com/doi/abs/10.1155/2022/5498058,Journal,Security and Communication Networks,"Identity-based encryption is an important cryptographic system that is employed to ensure confidentiality of a message in communication. This article presents a provably secure identity based encryption based on post quantum security assumption. The security of the proposed encryption is based on the hard problem, namely Learning with Errors on integer lattices. This construction is anonymous and produces pseudo random ciphers. Both public-key size and ciphertext-size have been reduced in the proposed encryption as compared to those for other relevant schemes without compromising the security. Next, we incorporate the constructed identity based encryption (IBE) for Internet of Things (IoT) applications, where the IoT smart devices send securely the sensing data to their nearby gateway nodes(s) with the help of IBE and the gateway node(s) secure aggregate the data from the smart devices by decrypting the messages using the proposed IBE decryption. Later, the gateway nodes will securely send the aggregated data to the cloud server(s) and the Big data analytics is performed on the authenticated data using the Artificial Intelligence (AI)/Machine Learning (ML) algorithms for accurate and better predictions.",Wiley
"Lee, Y. H. and Khalil-Hani, M. and Marsono, M. N.",An FPGA-Based Quantum Computing Emulation Framework Based on Serial-Parallel Architecture,2016,https://doi.org/10.1155/2016/5718124,https://onlinelibrary.wiley.com/doi/abs/10.1155/2016/5718124,Journal,International Journal of Reconfigurable Computing,"Hardware emulation of quantum systems can mimic more efficiently the parallel behaviour of quantum computations, thus allowing higher processing speed-up than software simulations. In this paper, an efficient hardware emulation method that employs a serial-parallel hardware architecture targeted for field programmable gate array (FPGA) is proposed. Quantum Fourier transform and Grover¡¯s search are chosen as case studies in this work since they are the core of many useful quantum algorithms. Experimental work shows that, with the proposed emulation architecture, a linear reduction in resource utilization is attained against the pipeline implementations proposed in prior works. The proposed work contributes to the formulation of a proof-of-concept baseline FPGA emulation framework with optimization on datapath designs that can be extended to emulate practical large-scale quantum circuits.",Wiley
"Yang, Jun",Making quantum chemistry compressive and expressive: Toward practical ab-initio simulation,2024,https://doi.org/10.1002/wcms.1706,https://onlinelibrary.wiley.com/doi/abs/10.1002/wcms.1706,Journal,WIREs Computational Molecular Science,"Ab-initio quantum chemistry simulations are essential for understanding electronic structure of molecules and materials in almost all areas of chemistry. A broad variety of electronic structure theories and implementations has been developed in the past decades to hopefully solve the many-body Schr?dinger equation in an approximate manner on modern computers. In this review, we present recent progress in advancing low-rank electronic structure methodologies that rely on the wavefunction sparsity and compressibility to select the important subset of electronic configurations for both weakly and strongly correlated molecules. Representative chemistry applications that require the many-body treatment beyond traditional density functional approximations are discussed. The low-rank electronic structure theories have further prompted us to highlight compressive and expressive principles that are useful to catalyze idea of quantum learning models. The intersection of the low-rank correlated feature design and the modern deep neural network learning provides new feasibilities to predict chemically accurate correlation energies of unknown molecules that are not represented in the training dataset. The results by others and us are discussed to reveal that the electronic feature sets from an extremely low-rank correlation representation, which is very poor for explicit energy computation, are however sufficiently expressive for capturing and transferring electron correlation patterns across distinct molecular compositions, bond types and geometries. This article is categorized under: Electronic Structure Theory > Ab Initio Electronic Structure Methods Software > Quantum Chemistry Software > Simulation Methods",Wiley
"Ghaempanah, Faezeh and Moasses Ghafari, Bahar and Hesami, Darya and Hossein Zadeh, Reza and Noroozpoor, Rashin and Moodi Ghalibaf, AmirAli and Hasanabadi, Parsa",Metaverse and its impact on medical education and health care system: A narrative review,2024,https://doi.org/10.1002/hsr2.70100,https://onlinelibrary.wiley.com/doi/abs/10.1002/hsr2.70100,Journal,Health Science Reports,"Background and Aims The metaverse has enormous potential in health care, continuously developing and offering innovative solutions by combining artificial intelligence (AI), augmented reality (AR)/virtual reality (VR), Internet of Medical Devices, and quantum computing technologies. In addition to using virtual platforms to help and boost medical education, familiarity with this platform is necessary to strengthen medical skills and communication with patients in medical sciences in the future. Methods We conducted a comprehensive search using keywords and their MeSH synonyms, including ¡°metaverse,¡± ¡°medical education,¡± and ¡°health care,¡± across PubMed, Scopus, and Web of Science. After screening the results, relevant articles were selected to inform the writing of this manuscript. Results The metaverse is shaping the future of medical sciences, offering new opportunities for health education, advocacy training, and patient outcome improvement. The combination of real and virtual worlds may advance international relations, facilitate data sharing, increase medical care speed, and reduce infectious diseases. The metaverse, despite its benefits, has some limitations. Only 37\% of 15?24-year-olds have internet access, and AR/VR glasses are expensive and may cause eye discomfort. It is also a potential risk for medical students, who may need help understanding the limitations of simulations and develop unrealistic expectations. Considering the metaverse as a supplement to clinical practice, not a replacement for supervised training, is crucial. Ethical concerns, data security, privacy, and lack of instructions for education are also issues. However, providing information about the metaverse can increase health care workers' attribution to use it for patient examinations, students' education, and tests. Conclusion This paper explores the impact of the metaverse on medical science education and underscores the need to integrate the metaverse into all areas of medical sciences as a supplement to existing evidence.",Wiley
"Sabaawi, Abdulbasit M. A. and Almasaoodi, Mohammed R. and El Gaily, Sara and Imre, S¨¢ndor","Energy efficiency optimisation in massive multiple-input, multiple-output network for 5G applications using new quantum genetic algorithm",2024,https://doi.org/10.1049/ntw2.12104,https://onlinelibrary.wiley.com/doi/abs/10.1049/ntw2.12104,Journal,IET Networks,"Devising efficient optimisation methods has been a subject of great research attention since current evolving trends in communication networks, machine learning, and other cutting-edge systems that need a fast and accurate optimised computational model. Classical computers became incapable of handling new optimisation problems posed by newly emerging trends. Quantum optimisation algorithms appear as alternative solutions. The existing bottleneck that restricts the use of the newly developed quantum strategies is the limited qubit size of the available quantum computers (the size of the most recent universal quantum computer is 433 qubits). A new quantum genetic algorithm (QGA) is proposed that handles the presented problem. A quantum extreme value searching algorithm and quantum blind computing framework are utilised to extend the search capabilities of the GA. The quantum genetic strategy is exploited to maximise energy efficiency at full spectral efficiency of massive multiple-input, multiple-output (M-MIMO) technology as a toy example for pointing out the efficiency of the presented quantum strategy. The authors run extensive simulations and prove how the presented quantum method outperforms the existing classical genetic algorithm.",Wiley
"Barfeii, Hamideh and Garkani-Nejad, Zahra","A Comparative QSRR Study on Enantioseparation of Ethanol Ester Enantiomers in HPLC Using Multivariate Image Analysis, Quantum Mechanical and Structural Descriptors",2017,https://doi.org/10.1002/jccs.201600253,https://onlinelibrary.wiley.com/doi/abs/10.1002/jccs.201600253,Journal,Journal of the Chinese Chemical Society,"Quantitative structure¨Cretention relationship study was carried out for predicting the retention times of twenty-six 1-(2-naphtyl)-1 ethanol ester enantiomers in high-pressure liquid chromatography by using original molecular, quantum mechanical, and multivariate image analysis (MIA) descriptors. Multiple linear regressions, partial least squares (PLS), and partial component regression (PCR) models combined with genetic algorithm (GA) were constructed as variable selection methods by using molecular descriptors to investigate the potential relationship between the selected descriptors and the retention times of the enantiomers. The molecular descriptors were generated from the molecular structure of enantiomers and calculated by the DRAGON software. Besides 504 DRAGON descriptors, additional 38 quantum mechanical descriptors were obtained using density functional theory/B3LYP/6-31G method. Then, the results of the obtained models were compared with MIA descriptors that are pixels of two-dimensional (2D) chemical structures. MIA descriptors were analyzed by correlation ranking-PCR and PLS methods. The predictive ability of the models was evaluated using cross-validation and an external test set. The results showed that GA is a good method for variable selection using structural descriptors combined with the PLS model. Since MIA descriptors are 2D pixels of the chemical structures, they can differentiate between the (R) and (S) isomers of enantiomers better than the quantum mechanical and structural descriptors. Comparison between the different models indicated that the GA-PLS and MIA-PLS models were the best methods.",Wiley
"Huo, Yachao and Zhao, Zongqu and Qin, Panke and Wang, Shujing and Zheng, Chengfu",Post-quantum secure two-party computing protocols against malicious adversaries,2024,https://doi.org/10.1002/cpe.7923,https://onlinelibrary.wiley.com/doi/abs/10.1002/cpe.7923,Journal,Concurrency and Computation: Practice and Experience,"Summary Secure two-party computation allows a pair of parties to compute a function together while keeping their inputs private. Ultimately, each party receives only its own correct output. In this paper, a post-quantum secure two-party computation protocol is proposed that can be used to effectively block malicious parties. The protocol solves the problems of traditional protocols based on garbled circuits, which are vulnerable to quantum attacks, high communication costs and low computational efficiency. The input garbled keys of the circuit constructor is structured as a Learning with Error (LWE) equation, enabling the circuit constructor to employ a zero-knowledge proof that demonstrates the uniformity of inputs across all circuits.In the key transfer phase, an LWE-based batch single-choice cut-and-choose oblivious transfer is proposed to avoid selective failure attacks. In addition, the protocol employs a penalty mechanism to detect if the circuit constructor has generated an incorrect circuit. We have compared the communication overhead of this protocol with three other secure two-party computation protocols based on Cut-and-Choose technology. The analytical results show that this protocol has the best error probability and is resilient to quantum attacks under the malicious adversary model. In addition, with appropriate parameters, the protocol is able to reduce its communication bandwidth by an average of 40.41\%.",Wiley
"Do?an, Yunus and Dalk?l??, Feri?tah and Birant, Derya and Kut, Recep Alp and Y?lmaz, Reyat",Novel Two-Dimensional Visualization Approaches for Multivariate Centroids of Clustering Algorithms,2018,https://doi.org/10.1155/2018/9253295,https://onlinelibrary.wiley.com/doi/abs/10.1155/2018/9253295,Journal,Scientific Programming,"The dimensionality reduction and visualization problems associated with multivariate centroids obtained by clustering algorithms are addressed in this paper. Two approaches are used in the literature for the solution of such problems, specifically, the self-organizing map (SOM) approach and mapping selected two features manually (MS2Fs). In addition, principle component analysis (PCA) was evaluated as a component for solving this problem on supervised datasets. Each of these traditional approaches has drawbacks: if SOM runs with a small map size, all centroids are located contiguously rather than at their original distances according to the high-dimensional structure; MS2Fs is not an efficient method because it does not take features outside of the method into account, and lastly, PCA is a supervised method and loses the most valuable feature. In this study, five novel hybrid approaches were proposed to eliminate these drawbacks by using the quantum genetic algorithm (QGA) method and four feature selection methods, Pearson¡¯s correlation, gain ratio, information gain, and relief methods. Experimental results demonstrate that, for 14 datasets of different sizes, the prediction accuracy of the proposed weighted clustering approaches is higher than the traditional K-means++ clustering approach. Furthermore, the proposed approach combined with K-means++ and QGA shows the most efficient placements of the centroids on a two-dimensional map for all the test datasets.",Wiley
"Li, Hongzhi and Zhong, Ziyan and Li, Lin and Gao, Rui and Cui, Jingxia and Gao, Ting and Hu, Li Hong and Lu, Yinghua and Su, Zhong-Min and Li, Hui",A cascaded QSAR model for efficient prediction of overall power conversion efficiency of all-organic dye-sensitized solar cells,2015,https://doi.org/10.1002/jcc.23886,https://onlinelibrary.wiley.com/doi/abs/10.1002/jcc.23886,Journal,Journal of Computational Chemistry,"A cascaded model is proposed to establish the quantitative structure¨Cactivity relationship (QSAR) between the overall power conversion efficiency (PCE) and quantum chemical molecular descriptors of all-organic dye sensitizers. The cascaded model is a two-level network in which the outputs of the first level (JSC, VOC, and FF) are the inputs of the second level, and the ultimate end-point is the overall PCE of dye-sensitized solar cells (DSSCs). The model combines quantum chemical methods and machine learning methods, further including quantum chemical calculations, data division, feature selection, regression, and validation steps. To improve the efficiency of the model and reduce the redundancy and noise of the molecular descriptors, six feature selection methods (multiple linear regression, genetic algorithms, mean impact value, forward selection, backward elimination, and +n-m algorithm) are used with the support vector machine. The best established cascaded model predicts the PCE values of DSSCs with a MAE of 0.57 (\%), which is about 10\% of the mean value PCE (5.62\%). The validation parameters according to the OECD principles are R2(0.75), Q2(0.77), and (0.76), which demonstrate the great goodness-of-fit, predictivity, and robustness of the model. Additionally, the applicability domain of the cascaded QSAR model is defined for further application. This study demonstrates that the established cascaded model is able to effectively predict the PCE for organic dye sensitizers with very low cost and relatively high accuracy, providing a useful tool for the design of dye sensitizers with high PCE. ? 2015 Wiley Periodicals, Inc.",Wiley
"Singh, Krishan Veer and Raza, Zahid",A quantum-inspired binary gravitational search algorithm¨Cbased job-scheduling model for mobile computational grid,2017,https://doi.org/10.1002/cpe.4103,https://onlinelibrary.wiley.com/doi/abs/10.1002/cpe.4103,Journal,Concurrency and Computation: Practice and Experience,"Summary Owing to the advancements in low-power consumption processors and high-power storage in a small-sized battery, the cost of handheld mobile devices, eg, mobiles, tabs, or personal digital assistants, have reduced to a great extent. This has enabled people to have at least 1 smartphone in general with this number increasing exponentially. However, the increasing use of these mobile devices results in an equal increase in the underused processing capacity of these devices too. This encourages the research aiming to use this processing power by forming a mobile computational grid. Because of the inherent limitations of bandwidth, battery, and computational power, job scheduling on these devices demands an efficient scheduling approach to harness the true potential of the grid. The problem becomes even more challenging considering the dynamic nature of these mobile devices. Job scheduling being nondeterministic polynomial time¨Ccomplete allows the use of evolutionary approaches by exploring and exploiting the search space efficiently. The exploration gets boosted even more with the use of quantum-computing concepts. This work proposes a quantum-inspired Newtonian approach of attraction based on gravitational search algorithm for scheduling the jobs on mobile computational grid. Simulation study has been performed to evaluate the performance of the model over various dimensions. A comparative study has been performed with quantum-genetic algorithm. Simulation result establishes the effectiveness of model under various test conditions.",Wiley
"Andriani, Giuseppe and Pio, Gianmaria and Salzano, Ernesto and Vianello, Chiara and Mocellin, Paolo",Evaluating the thermal stability of chemicals and systems: A review,2025,https://doi.org/10.1002/cjce.25422,https://onlinelibrary.wiley.com/doi/abs/10.1002/cjce.25422,Journal,The Canadian Journal of Chemical Engineering,"In the realm of chemical processing, particularly at the industrial scale, safety is of utmost importance. A predominant factor causing accidents within the chemical industry is runaway phenomena, primarily initiated by uncontrolled exothermic reactions. This review critically examines the often-overlooked decomposition mechanisms as a significant contributor to thermal energy release, necessitating a comprehensive revision and understanding of both experimental and theoretical strategies for assessing thermal degradation. Key to this discourse is the explication of calorimetry as the principal experimental technique, alongside ab initio quantum chemistry simulations as a robust theoretical framework for quantifying the most relevant properties. However, more than mere cognisance of these methodologies is required for a meticulous thermal stability assessment. The review emphasizes identifying and quantifying fundamental parameters through experimental and theoretical investigations. Only upon acquiring these parameters, including kinetic, thermodynamic, onset, and peak characteristics of the exothermic decomposition reactions, can one effectively mitigate risks and hazards in designing and optimizing chemical processes and apparatus. Furthermore, this review delineates qualitative and quantitative methodologies for hazard assessment, proffering strategies for estimating safe operational conditions and sizing relief devices. The paper culminates in exploring future trajectories in thermal stability assessments, focusing on emerging applications in lithium-ion batteries, electrolyzers, electrified reactors, ionic liquids, artificial intelligence and machine learning approaches. Thus, the paper underlines the evolving landscape of thermal risk management in contemporary and future chemical industries.",Wiley
"Attari, Kamal and Amhaimar, Lahcen and El yaakoubi, Ali and Asselman, Adel and Bassou, Mounir",The Design and Optimization of GaAs Single Solar Cells Using the Genetic Algorithm and Silvaco ATLAS,2017,https://doi.org/10.1155/2017/8269358,https://onlinelibrary.wiley.com/doi/abs/10.1155/2017/8269358,Journal,International Journal of Photoenergy,"Single-junction solar cells are the most available in the market and the most simple in terms of the realization and fabrication comparing to the other solar devices. However, these single-junction solar cells need more development and optimization for higher conversion efficiency. In addition to the doping densities and compromises between different layers and their best thickness value, the choice of the materials is also an important factor on improving the efficiency. In this paper, an efficient single-junction solar cell model of GaAs is presented and optimized. In the first step, an initial model was simulated and then the results were processed by an algorithm code. In this work, the proposed optimization method is a genetic search algorithm implemented in Matlab receiving ATLAS data to generate an optimum output power solar cell. Other performance parameters such as photogeneration rates, external quantum efficiency (EQE), and internal quantum efficiency (EQI) are also obtained. The simulation shows that the proposed method provides significant conversion efficiency improvement of 29.7\% under AM1.5G illumination. The other results were Jsc?=?34.79?mA/cm2, Voc?=?1?V, and fill factor (FF)?=?85\%.",Wiley
"Rezende, Umar Lucio and De Souza, Leonardo A. and Belchior, Jadson C.",An approach based on genetic algorithms and machine learning coupled for studying alloy and molecular clusters by optimizing quantum energy surfaces,2023,https://doi.org/10.1002/jcc.27174,https://onlinelibrary.wiley.com/doi/abs/10.1002/jcc.27174,Journal,Journal of Computational Chemistry,"A new genetic algorithm has been proposed focusing on direct ab initio potential energy surface (PES) global minima search. Besides the commonly used operators, this new approach uses an operator to: improve the initial cluster generation, classify and compare all generated clusters, and use machine learning to model the quantum PES used in parallel optimization. Part of the validation process for this methodology was done with CunAum (n+m¡ÜX for X=14,19,38,55) and AunAgn (n=10,20,30,40,50,60,70, and 75). The results are in fair agreement with the literature and led to a new global minimum for Cu12Au7. A search has been done for the lowest energies of Lin nanoclusters with 2¨C8 atoms using the DFT approach and for Li3,Li4,Li2H, Li3H using DLPNO-CCSD(T) approach. NQGA successfully performed the MP2 optimizations for (H2O)11 cluster. In all cases, the proposed genetic algorithm located the previously reported global minima with very efficient performance. The new proposed methodology makes it possible to optimize cluster geometries directly using high-level ab initio methods relinquishing any bias introduced by a classical approach. Our results show that this proposed method has great potential applications due to its flexibility and efficiency in identifying global minima in the tested atomic systems.",Wiley
"Kordzanganeh, Mohammad and Buchberger, Markus and Kyriacou, Basil and Povolotskii, Maxim and Fischer, Wilhelm and Kurkin, Andrii and Somogyi, Wilfrid and Sagingalieva, Asel and Pflitsch, Markus and Melnikov, Alexey",Benchmarking Simulated and Physical Quantum Processing Units Using Quantum and Hybrid Algorithms,2023,https://doi.org/10.1002/qute.202300043,https://onlinelibrary.wiley.com/doi/abs/10.1002/qute.202300043,Journal,Advanced Quantum Technologies,"Powerful hardware services and software libraries are vital tools for quickly and affordably designing, testing, and executing quantum algorithms. A robust large-scale study of how the performance of these platforms scales with the number of qubits is key to providing quantum solutions to challenging industry problems. This work benchmarks the runtime and accuracy for a representative sample of specialized high-performance simulated and physical quantum processing units. Results show the QMware simulator can reduce the runtime for executing a quantum circuit by up to 78\% compared to the next fastest option for algorithms with fewer than 27 qubits. The Amazon Web Service State-Vector Simulator 1 offers a runtime advantage for larger circuits, up to the maximum 34 qubits. Beyond this limit, QMware can execute circuits as large as 40 qubits. Physical quantum devices, such as Rigetti's Aspen-M2, can provide an exponential runtime advantage for circuits with more than 30 qubits. However, the high financial cost of physical quantum processing units presents a serious barrier to practical use. Moreover, only IonQ's Harmony quantum device achieves high fidelity with more than four qubits. This study paves the way to understanding the optimal combination of available software and hardware for executing practical quantum algorithms.",Wiley
"Xi, Maolong and Sun, Jun and Liu, Li and Fan, Fangyun and Wu, Xiaojun",Cancer Feature Selection and Classification Using a Binary Quantum-Behaved Particle Swarm Optimization and Support Vector Machine,2016,https://doi.org/10.1155/2016/3572705,https://onlinelibrary.wiley.com/doi/abs/10.1155/2016/3572705,Journal,Computational and Mathematical Methods in Medicine,"This paper focuses on the feature gene selection for cancer classification, which employs an optimization algorithm to select a subset of the genes. We propose a binary quantum-behaved particle swarm optimization (BQPSO) for cancer feature gene selection, coupling support vector machine (SVM) for cancer classification. First, the proposed BQPSO algorithm is described, which is a discretized version of original QPSO for binary 0-1 optimization problems. Then, we present the principle and procedure for cancer feature gene selection and cancer classification based on BQPSO and SVM with leave-one-out cross validation (LOOCV). Finally, the BQPSO coupling SVM (BQPSO/SVM), binary PSO coupling SVM (BPSO/SVM), and genetic algorithm coupling SVM (GA/SVM) are tested for feature gene selection and cancer classification on five microarray data sets, namely, Leukemia, Prostate, Colon, Lung, and Lymphoma. The experimental results show that BQPSO/SVM has significant advantages in accuracy, robustness, and the number of feature genes selected compared with the other two algorithms.",Wiley
"Sulimov, V. B. and Katkova, E. V. and Oferkin, I. V. and Sulimov, A. V. and Romanov, A. N. and Roschin, A. I. and Beloglazova, I. B. and Plekhanova, O. S. and Tkachuk, V. A. and Sadovnichiy, V. A.",Application of Molecular Modeling to Urokinase Inhibitors Development,2014,https://doi.org/10.1155/2014/625176,https://onlinelibrary.wiley.com/doi/abs/10.1155/2014/625176,Journal,BioMed Research International,"Urokinase-type plasminogen activator (uPA) plays an important role in the regulation of diverse physiologic and pathologic processes. Experimental research has shown that elevated uPA expression is associated with cancer progression, metastasis, and shortened survival in patients, whereas suppression of proteolytic activity of uPA leads to evident decrease of metastasis. Therefore, uPA has been considered as a promising molecular target for development of anticancer drugs. The present study sets out to develop the new selective uPA inhibitors using computer-aided structural based drug design methods. Investigation involves the following stages: computer modeling of the protein active site, development and validation of computer molecular modeling methods: docking (SOL program), postprocessing (DISCORE program), direct generalized docking (FLM program), and the application of the quantum chemical calculations (MOPAC package), search of uPA inhibitors among molecules from databases of ready-made compounds to find new uPA inhibitors, and design of new chemical structures and their optimization and experimental examination. On the basis of known uPA inhibitors and modeling results, 18 new compounds have been designed, calculated using programs mentioned above, synthesized, and tested in vitro. Eight of them display inhibitory activity and two of them display activity about 10?¦ÌM.",Wiley
"Anand, Ravi and Nandi, Rimpa and Isobe, Takanori",Analysis of Atom against quantum attacks,2024,https://doi.org/10.1049/qtc2.12076,https://onlinelibrary.wiley.com/doi/abs/10.1049/qtc2.12076,Journal,IET Quantum Communication,"A significant amount of study is being done to review the security promises made for the various ciphers now in use as a result of the development of quantum computing technology. A general attack against symmetric key cryptography primitives that can reduce search costs to the square root is Grover's search algorithm. To implement Grover's algorithm, it is necessary that the target cipher be implemented as a quantum circuit. Despite being relatively new, this area of study has received significant attention from the research community. The authors have estimated the cost of Grover's key search attack against the stream cipher Atom, for the first time, under circuit depth restrictions defined in National Institute of Standards and Technology (NIST) PQC standardisation process. The authors implement the quantum circuit of Atom in QISKIT, (open-source software development kit for working with quantum computers running on IBM Quantum Experience). The results are also compared with other existing literature on LFSR-based stream ciphers, such as Grain-v1, Grain-128-AEAD, and Lizard. The authors also find that, to the best of their knowledge, in the existing literature on estimating the cost of Grover's attack on symmetric ciphers, Atom is the only 128-bit key cipher that meets the threshold of ¡Ö2170 set by NIST for quantum security of 128-bit key ciphers. The authors also analyse the security of Atom against quantum TMDTO attacks.",Wiley
"Jency, W. G. and Judith, J. E.",Homogenized Point Mutual Information and Deep Quantum Reinforced Wind Power Prediction,2022,https://doi.org/10.1155/2022/3686786,https://onlinelibrary.wiley.com/doi/abs/10.1155/2022/3686786,Journal,International Transactions on Electrical Energy Systems,"Accurate wind power prediction is very predominant for genuine and effective power systems with high wind power perception. Wind power prediction, as well as wind power generation resources, receives the electrical energy by converting wind into rotational energy of the blades and converting rotational energy into electrical energy by the generator. Wind energy increases with the cube of wind speed. There are numerous common and deep learning methods that have evolved to attain wind power prediction. Deep learning-based methods are referred to as straightforward, and robust, and have been utilized in the recent few years for wind power prediction with a certain level of success. However, due to the lack of an appropriate feature selection process and to minimize the effect of losses used for wind power prediction, a large amount of computation is necessitated when processing multi-input wind power data, therefore causing a negative influence on scalability and hence affecting wind power prediction time. To address these issues, in this work, a method called, Homogenized Point Mutual Information and Deep Quantum Reinforced (HPMI-QDR) wind power prediction are proposed. The HPMI-DQR method is split into two sections. In the first section, informative and relevant features required for robust wind power prediction using input wind turbine data are designed using Homogenized Point Mutual (HPM) Feature Selection model. With the relevant features selected, in the second section, the actual wind power prediction is made using the Deep Quantum Reinforced Learning model. To validate the proposed method, Wind Turbine SCADA Dataset is used for constructing and testing. Simulation of proposed method attains enhancement within wind power prediction accuracy as 13\%, minimal wind power prediction time as 25\%, as well as better wind energy generation as 20\% and true positive rate as 25\%, compared using conventional techniques. Moreover, a substantial improvement was also found in wind power prediction time with minimum error.",Wiley
"Yang, Fan and Chen, Jiawen and Li, Jinyang and Yang, Zhichun and Cao, Yanchun",Application of QGA algorithm improved by gradient descent in fault diagnosis and location of distributed distribution network,2024,https://doi.org/10.1002/adc2.172,https://onlinelibrary.wiley.com/doi/abs/10.1002/adc2.172,Journal,Advanced Control for Applications,"A fault diagnosis and localization approach for distributed distribution networks is created using an upgraded quantum genetic algorithm to swiftly identify and detect flaws in the network. In this method, the dynamic rotation strategy in gradient descent method is used to update the quantum gate to enhance the convergence speed, that is, the gradient descent quantum genetic algorithm is constructed. The results of single fault and multiple fault simulation test on the distribution network model of regional node of distributed power supply show that the average iteration of gradient descent quantum genetic algorithm 85.36, 86.35, 88.24, and 88.69?times can reach the target optimal value. In four different cases, the algorithm of gradient descent quantum genetic algorithm can reach the optimal by iterating 88, 91, 92, and 90?times, respectively. Compared with other algorithms, the convergence rate of gradient descent quantum genetic algorithm is the fastest in the four experimental cases. The consistency between the output score and the real score of the gradient descent quantum genetic algorithm is above 0.9. The results above show that the algorithm is effective. The optimization ability and stability of the algorithm are also stronger, and it has certain application potential.",Wiley
"Misra, Bitan and Mahanti, Gautam Kumar and Panda, Ganapati",Reduction of side lobes in the entire azimuth plane in a planar elliptical array antenna,2022,https://doi.org/10.1002/dac.5067,https://onlinelibrary.wiley.com/doi/abs/10.1002/dac.5067,Journal,International Journal of Communication Systems,"Summary A novel synthesis method to reduce the maximum side lobe in the entire azimuth plane and for achieving a desired value of directivity of a concentric elliptical array antenna is addressed in this paper. Three well-performing meta-heuristic optimization algorithms, teaching learning-based optimization (TLBO), symbiotic organism search (SOS), and quantum particle swarm optimization (QPSO), are employed to optimize the cost function and to obtain the desired radiation pattern. Different simulation-based experiments are performed to obtain the best possible set of angular positions and the distribution of isotropic antennas across the ellipses by rigorously maintaining non-overlapping constraints. The major benefit of the proposed design is the deprecation of interference in all phi planes. The statistical analysis of the simulation results demonstrate perceptible improvement compared with that of a uniformly spaced concentric elliptical array and hence show the efficiency of the proposed algorithms. In both simulation studies, the results obtained using TLBO, SOS, and QPSO are compared. Analysis of the results exhibits that for the stated objective, the TLBO- and SOS-based side lobe reduction approach performs superior to QPSO method. Proposed multi-objective research work could lead to reduce payload and can simultaneously achieve isoflux coverage in entire azimuth plane on the earth surface which can essentially be utilized in (Low Earth Orbit) LEO and (Geostationary Earth Orbit) GEO satellites applications.",Wiley
"Zhang, Jianxia and Yang, Fuchao and Nie, Guanghua and Zhang, Jianxin",Optimal Trajectory Planning for Minimizing Base Disturbance of a Redundant Space Robot with IQPSO,2022,https://doi.org/10.1155/2022/3398810,https://onlinelibrary.wiley.com/doi/abs/10.1155/2022/3398810,Journal,Journal of Electrical and Computer Engineering,"With the development of aerospace technology, the practical application of a free-floating redundant space robot has become more and more popular. The problem of minimizing base disturbance has been paid attention among academic researchers. If the space robot moves, it would have an impact on the pose of a base. The interference on a base should be reduced, which was caused by the movements of the space robot. In the paper, the simplified model of a redundant space robot has been described, which consists of a base and a 7-joint manipulator. Using the nonholonomic redundancy features, the pose of the base has been optimized planning. First, a set of kinematic equations of the redundant space robot was founded. Second, the 5-order polynomial function could be used for the parametric 7 joints. Third, on the basis of the pose requirements, a fitness function was defined. At last, the proposed improved quantum particle swarm optimization (IQPSO) algorithm was presented. The proposed IQPSO algorithm not only searched the optimal value easily but also had a good robust performance. The advantages could be shown through the numerical experiments, compared with the quantum-behaved particle swarm optimization (QPSO) algorithm, particle swarm optimization (PSO) algorithm, and simulated annealing particle swarm (SAPSO) algorithm. Then, the proposed IQPSO algorithm was used to optimize the fitness function of trajectory planning. By the simulation results, it could be confirmed that the proposed IQPSO algorithm searched the global optimal solution not only easily but also smoothly, compared with the QPSO, PSO, and SAPSO algorithms. The proposed approach was suitable for planning an optimal trajectory.",Wiley
"Ahmadi, Mohsen and Sharifi, Abbas and Hassantabar, Shayan and Enayati, Saman",QAIS-DSNN: Tumor Area Segmentation of MRI Image with Optimized Quantum Matched-Filter Technique and Deep Spiking Neural Network,2021,https://doi.org/10.1155/2021/6653879,https://onlinelibrary.wiley.com/doi/abs/10.1155/2021/6653879,Journal,BioMed Research International,"Tumor segmentation in brain MRI images is a noted process that can make the tumor easier to diagnose and lead to effective radiotherapy planning. Providing and building intelligent medical systems can be considered as an aid for physicians. In many cases, the presented methods¡¯ reliability is at a high level, and such systems are used directly. In recent decades, several methods of segmentation of various images, such as MRI, CT, and PET, have been proposed for brain tumors. Advanced brain tumor segmentation has been a challenging issue in the scientific community. The reason for this is the existence of various tumor dimensions with disproportionate boundaries in medical imaging. This research provides an optimized MRI segmentation method to diagnose tumors. It first offers a preprocessing approach to reduce noise with a new method called Quantum Matched-Filter Technique (QMFT). Then, the deep spiking neural network (DSNN) is implemented for segmentation using the conditional random field structure. However, a new algorithm called the Quantum Artificial Immune System (QAIS) is used in its SoftMax layer due to its slowness and nonsegmentation and the identification of suitable features for selection and extraction. The proposed approach, called QAIS-DSNN, has a high ability to segment and distinguish brain tumors from MRI images. The simulation results using the BraTS2018 dataset show that the accuracy of the proposed approach is 98.21\%, average error-squared rate is 0.006, signal-to-noise ratio is 97.79?dB, and lesion structure criteria including the tumor nucleus are 80.15\%. The improved tumor is 74.50\%, and the entire tumor is 91.92\%, which shows a functional advantage over similar previous methods. Also, the execution time of this method is 2.58 seconds.",Wiley
"Khan, Saad Saleem and Shareef, Hussain and Bouhaddioui, Chafik and Errouissi, Rachid",Membrane-hydration-state detection in proton exchange membrane fuel cells using improved ambient-condition-based dynamic model,2020,https://doi.org/10.1002/er.4927,https://onlinelibrary.wiley.com/doi/abs/10.1002/er.4927,Journal,International Journal of Energy Research,"Summary Proton-exchange-membrane fuel cells (PEMFCs) are a popular source of alternative energy because of their operational reliability and compactness. This paper presents an improved model to represent the semi-empirical voltage of PEMFCs to overcome the limitations of existing models. The proposed model considers variations in ambient conditions, such as the ambient temperature and relative humidity, to obtain the accurate output voltage that corresponds to variations in dynamic and static loads. The proposed model was developed by conducting several experiments on the Horizon PEMFC system under normal, humid, and dry ambient conditions. Subsequently, the model parameters corresponding to each case were optimised using the quantum lightning search algorithm (QLSA). Parameters demonstrating significant variations with ambient conditions were finally represented as a function of the ambient temperature and relative humidity via statistical regression analysis. The voltage obtained using the modified model was verified by conducting experiments on both the Horizon and NEXA PEMFC systems by varying the ambient temperature and relative humidity with root mean square error (RMSE) less than 0.5. As observed, the results we obtained using the modified model closely approximated those obtained using PEMFCs under various operating conditions, and in both cases, the PEMFC voltage was observed to vary with the ambient and load conditions. The inherent advantages of the proposed PEMFC model include its ability to determine the membrane-water content and water pressure inside PEMFCs. The membrane-water content provides clear indications regarding the occurrence of drying and flooding faults. Under normal conditions, this membrane water content ranges from 11 to 7 for both the Horizon and NEXA PEMFC system. The simulation results suggested using the threshold membrane-water-content level as a possible indicator of fault occurrence under extreme ambient conditions. The limits of the said threshold were observed to be useful for fault diagnosis within PEMFC systems.",Wiley
"Neese, Frank",The SHARK integral generation and digestion system,2023,https://doi.org/10.1002/jcc.26942,https://onlinelibrary.wiley.com/doi/abs/10.1002/jcc.26942,Journal,Journal of Computational Chemistry,"In this paper, the SHARK integral generation and digestion engine is described. In essence, SHARK is based on a reformulation of the popular McMurchie/Davidson approach to molecular integrals. This reformulation leads to an efficient algorithm that is driven by BLAS level 3 operations. The algorithm is particularly efficient for high angular momentum basis functions (up to L = 7 is available by default, but the algorithm is programmed for arbitrary angular momenta). SHARK features a significant number of specific programming constructs that are designed to greatly simplify the workflow in quantum chemical program development and avoid undesirable code duplication to the largest possible extent. SHARK can handle segmented, generally and partially generally contracted basis sets. It can be used to generate a host of one- and two-electron integrals over various kernels including, two-, three-, and four-index repulsion integrals, integrals over Gauge Including Atomic Orbitals (GIAOs), relativistic integrals and integrals featuring a finite nucleus model. SHARK provides routines to evaluate Fock like matrices, generate integral transformations and related tasks. SHARK is the essential engine inside the ORCA package that drives essentially all tasks that are related to integrals over basis functions in version ORCA 5.0 and higher. Since the core of SHARK is based on low-level basic linear algebra (BLAS) operations, it is expected to not only perform well on present day but also on future hardware provided that the hardware manufacturer provides a properly optimized BLAS library for matrix and vector operations. Representative timings and comparisons to the Libint library used by ORCA are reported for Intel i9 and Apple M1 max processors.",Wiley
"Zeguendry, Amine and Jarir, Zahi and Quafafou, Mohamed",Quantum-Enhanced K-Nearest Neighbors for Text Classification: A Hybrid Approach with Unified Circuit and Reduced Quantum Gates,2024,https://doi.org/10.1002/qute.202400122,https://onlinelibrary.wiley.com/doi/abs/10.1002/qute.202400122,Journal,Advanced Quantum Technologies,"Text classification, a key process in natural language processing (NLP), relies on the k-nearest neighbors (KNN) algorithm for its simplicity and effectiveness. Traditional methods often grapple with the high-dimensional nature of textual data, leading to substantial computational demands. This study introduces a novel classical quantum k-nearest neighbors (CQKNN) algorithm, which integrates quantum circuits into a conventional machine-learning framework to enhance computational efficiency and reduce storage requirements. This hybrid approach uses a unified quantum circuit that simplifies multiple similarity calculations through mid-circuit measurements and qubit reset operations, significantly improving upon traditional multi-circuit quantum k-nearest neighbors (QKNN) models. The CQKNN algorithm, tested on datasets such as SMS Spam Collection, Twitter US Airline Sentiment, and IMDB Movie Reviews, not only outperforms classical KNN but also addresses challenges posed by noisy intermediate-scale quantum (NISQ) devices through advanced error mitigation techniques. This work highlights resource efficiency and reduced gate complexity and demonstrates the practical application of fidelity in quantum similarity calculations, setting new standards for quantum-enhanced machine learning and advancing current quantum technology capabilities in complex data classification tasks.",Wiley
"Kim, Moon-Seok and Rehman, Shania and Khan, Muhammad Farooq and Kim, Sungho",Mem-Transistor-Based Gaussian Error¨CGenerating Hardware for Post-Quantum Cryptography Applications,,https://doi.org/10.1002/qute.202400394,https://onlinelibrary.wiley.com/doi/abs/10.1002/qute.202400394,Journal,Advanced Quantum Technologies,,Wiley
"Tang, Minan and Liang, Kai and Qiu, Jiandong",Small insulator target detection based on multi-feature fusion,2023,https://doi.org/10.1049/ipr2.12735,https://onlinelibrary.wiley.com/doi/abs/10.1049/ipr2.12735,Journal,IET Image Processing,"The proportion of insulators in aerial power patrol images is small and the background of overhead lines is complex, often leading to incomplete and inaccurate detection of insulators. Therefore, an algorithm for detecting insulator targets based on multi-feature fusion is developed in this study. Firstly, a dynamic threshold oriented fast and rotated brief algorithm is proposed, which uses the bag-of-words dictionary model to determine local shape features of the image, applies gradient weighting to the global texture feature vector extracted by the histogram of oriented gradients algorithm and performs radial gradient transformations to get the improved HOG of features. Secondly, the feature vectors are fused serially, the learning machine is trained and the parameters of the support vector machine are optimized using the quantum particle swarm optimization algorithm. Finally, the target area is pre-divided by the selective search algorithm, and the area is classified by the learning machine. The experimental results show that the proposed feature extraction method can describe the image details more accurately than the existing methods, and the average accuracy of the feature extraction classifier can reach 93.7\%, which helps to overcome the incomplete detection problem of insulator detection at the aerial work site.",Wiley
"Fikadu Tilaye, Getahun and Pandey, Amit",Investigating the Effects of Hyperparameters in Quantum-Enhanced Deep Reinforcement Learning,2023,https://doi.org/10.1155/2023/2451990,https://onlinelibrary.wiley.com/doi/abs/10.1155/2023/2451990,Journal,Quantum Engineering,"Quantum machine learning uses quantum mechanical concepts of superposition of states to make the decision. In this work, we used these quantum advantages to enhance deep reinforcement learning (DRL). Our primary and foremost goal is to investigate and elucidate a way of representing and solving the frozen lake problems by using PennyLane which contains Xanadu¡¯s back-end quantum processing unit. This paper specifically discusses how to enhance classical deep reinforcement learning algorithms with quantum computing technology, making quantum agents get a maximum reward after a fixed number of epochs and realizing the effect of a number of variational quantum layers on the trainability of enhanced framework. We have analyzed that, as the number of layers increases, the ability of the quantum agent to converge to the optimal state also increases. For this work, we have trained the framework agent with 2, 3, and 5 variational quantum layers. An agent with 2 layers converges to a total reward of 0.95 after the training episode of 526. The other agent with layers converges to a total reward of 0.95 after the training episode of 397 and the agent which uses 5 quantum variational layers converges to a total reward of 0.95 after the training episode of 72. From this, we can understand that the agent with a more variational layer exploits more and converges to the optimal state before the other agent. We also analyzed our work in terms of different learning rate hyperparameters. We recorded every single learning epoch to demonstrate the outcomes of enhanced DRL algorithms with selected 0.1, 0.2, 0.3, and 0.4 learning rates or alpha values. From this result, we can conclude that the greater the learning rate values in quantum deep reinforcement learning, the fewer timesteps it takes to move from the start point to the goal state.",Wiley
"Liu, Yi and Li, Gengsong and Zheng, Qibin and Yang, Guoli and Liu, Kun and Qin, Wei",An evolutionary algorithm-based classification method for high-dimensional imbalanced mixed data with missing information,2024,https://doi.org/10.1049/ell2.70052,https://onlinelibrary.wiley.com/doi/abs/10.1049/ell2.70052,Journal,Electronics Letters,"The data scale keeps growing by leaps and the majority of it is high-dimensional imbalanced data, which is hard to classify. Data missing often happens in software which further aggravates the difficulty of classifying the data. In order to resolve high-dimensional imbalanced mixed-variables missing data classification problem, a novel method based on particle swarm optimization is developed. It has three original components including multiple feature selection, mixed attribute imputation, and quantum oversampling. Multiple feature selection uses a two-stage strategy to obtain stable relevant features. Mixed attribute imputation separates features into continuous and discrete features and fills missing values with different models. Quantum oversampling chooses instances to balance data based on the quantum operator. Furthermore, particle swarm optimization is employed to optimize the parameters of the components to obtain preferable classification results. Six representative classification datasets, six typical algorithms, and four measures are taken to conduct exhaust experiments, and results indicate that the proposed method is superior to the comparison algorithms.",Wiley
"He, Zhimin and Li, Zhengjiang and Deng, Maijie and Zheng, Shenggen and Situ, Haozhen and Li, Lvzhou",Quantum Architecture Search with Neural Predictor Based on Graph Measures,2024,https://doi.org/10.1002/qute.202400223,https://onlinelibrary.wiley.com/doi/abs/10.1002/qute.202400223,Journal,Advanced Quantum Technologies,"Quantum architecture search (QAS) has attracted increasing attention owing to its remarkable ability to automate the design of quantum circuits for variational quantum algorithms (VQAs). However, evaluating the performance of numerous quantum circuits is essential to provide feedback for the search strategy, which inevitably renders QAS computationally expensive. Performance predictors have emerged as highly efficient evaluation methods to mitigate this challenge. However, the performance predictor faces a critical challenge in reducing the required number of circuit-performance pairs for training. This study encodes circuit architecture by representing a quantum circuit as a relational graph that emphasizes message exchange. Subsequently, valuable information about circuit architecture is extracted through three types of graph measures, including distance-based, degree-based, and cluster-based measures. The graph measures define a smooth space related to circuit performance, facilitating the training of the performance predictor. The effectiveness of the proposed method is assessed across three tasks within variational quantum eigensolvers (VQE): identifying the ground states of the Transverse Field Ising Model (TFIM), the Heisenberg model, and the BeH2\$\text{BeH}\_2\$ molecule. The simulation results demonstrate notable enhancements in predictive accuracy achieved by our method, coupled with a substantial reduction in the required number of training samples for the predictor.",Wiley
"Maray, Mohammed and Alghamdi, Mohammed and Alrayes, Fatma S. and Alotaibi, Saud S. and Alazwari, Sana and Alabdan, Rana and Al Duhayyim, Mesfer",Intelligent metaheuristics with optimal machine learning approach for malware detection on IoT-enabled maritime transportation systems,2022,https://doi.org/10.1111/exsy.13155,https://onlinelibrary.wiley.com/doi/abs/10.1111/exsy.13155,Journal,Expert Systems,"The latest advancements in Internet of Things (IoT) have revolutionized the productivity of global shipping industry in the recent years. It also led to the emergence of IoT-enabled Maritime Transportation Systems (MTS). These approaches detect the malware in network before the execution process. Various machine learning (ML) models have been proposed and designed in literature for effective malware detection. However, the existence of numerous features in the data bring dimensionality problem which can be only resolved by the use of feature selection approaches. Therefore, the current research work presents Intelligent Metaheuristics-based Feature Selection model with Optimal ML approach for Malware Detection (IMFSOML-MD) on IoT-enabled MTS. Primarily, IMFSOML-MD technique involves the design of Quantum Invasive Weed Optimization Algorithm-based Feature Selection technique to optimally choose a subset of features. Moreover, an Optimal Wavelet Neural Network (OWNN) model is employed to perform classification process. The initial parameters of WNN model are optimally tuned with the help of Colliding Bodies Optimization algorithm thereby improving the detection performance. The proposed IMFSOML-MD technique was experimentally validated using publicly-available CICMalDroid2020 dataset. The results from extensive comparative analysis demonstrated the superiority of the proposed IMFSOML-MD technique over other compared methods in terms of detection performance with maximum accuracy of 98.96\%.",Wiley
"Wang, Haibin and Zhao, Jiaojiao and Wang, Bosi and Tong, Lian",A Quantum Approximate Optimization Algorithm with Metalearning for MaxCut Problem and Its Simulation via TensorFlow Quantum,2021,https://doi.org/10.1155/2021/6655455,https://onlinelibrary.wiley.com/doi/abs/10.1155/2021/6655455,Journal,Mathematical Problems in Engineering,"A quantum approximate optimization algorithm (QAOA) is a polynomial-time approximate optimization algorithm used to solve combinatorial optimization problems. However, the existing QAOA algorithms have poor generalization performance in finding an optimal solution from a feasible solution set of combinatorial problems. In order to solve this problem, a quantum approximate optimization algorithm with metalearning for the MaxCut problem (MetaQAOA) is proposed. Specifically, a quantum neural network (QNN) is constructed in the form of the parameterized quantum circuit to detect different topological phases of matter, and a classical long short-term memory (LSTM) neural network is used as a black-box optimizer, which can quickly assist QNN to find the approximate optimal QAOA parameters. The experiment simulation via TensorFlow Quantum (TFQ) shows that MetaQAOA requires fewer iterations to reach the threshold of the loss function, and the threshold of the loss value after training is smaller than comparison methods. In addition, our algorithm can learn parameter update heuristics which can generalize to larger system sizes and still outperform other initialization strategies of this scale.",Wiley
"Modee, Rohit and Laghuvarapu, Siddhartha and Priyakumar, U. Deva",Benchmark study on deep neural network potentials for small organic molecules,2022,https://doi.org/10.1002/jcc.26790,https://onlinelibrary.wiley.com/doi/abs/10.1002/jcc.26790,Journal,Journal of Computational Chemistry,"There has been tremendous advancement in machine learning (ML) applications in computational chemistry, particularly in neural network potentials (NNP). NNPs can approximate potential energy surface (PES) as a high dimensional function by learning from existing reference data, thereby circumventing the need to solve the electronic Schr?dinger equation explicitly. As a result, ML accelerates chemical space exploration and property prediction compared to quantum mechanical methods. Novel ML methods have the potential to provide efficient means for predicting the properties of molecules. However, this potential has been limited by the lack of standard comparative evaluations. In this work, we compare four selected models, that is, ANI, PhysNet, SchNet, and BAND-NN, developed to represent the PES of small organic molecules. We evaluate these models for their accuracy and transferability on two different test sets (i) Small organic molecules of up to eight-heavy atoms on which ANI and SchNet achieve root mean square error (RMSE) of 0.55 and 0.60?kcal/mol, respectively. (ii) On random selection of molecules from the GDB-11 database with 10-heavy atoms, ANI achieves RMSE of 1.17?kcal/mol and SchNet achieves RMSE of 1.89?kcal/mol. We examine their ability to produce smooth meaningful surface by performing PES scans for bond stretch, angle bend, and dihedral rotations on relatively large molecules to assess their possible application in molecular dynamics simulations. We also evaluate their performance for yielding minimum energy structures via geometry optimization using various minimization algorithms. All these models were also able to accurately differentiate different isomers of the same empirical formula . ANI and PhysNet achieve an RMSE of 0.29 and 0.52?kcal/mol, respectively, on isomers.",Wiley
"Shen, Yijun and Zhang, Guanhong",Adaptive predistortion algorithm based on the multilinear multiplier fusion,2018,https://doi.org/10.1002/cpe.4645,https://onlinelibrary.wiley.com/doi/abs/10.1002/cpe.4645,Journal,Concurrency and Computation: Practice and Experience,"Summary Aiming at solving the problem of the insufficiency in the predistortion structure and low accuracy of the memory nonlinear power amplifier in the wireless communication system, an adaptive predistortion method for dual loop learning structure based on the fusion of multilinear multiplier model recognition is put forward. On the basis of the real number delay multilinear multiplier model, an improved quantum behaved optimization (QBO) algorithm is adopted in this method to carry out indirect learning structure off-line training of the multilinear multiplier, so as to determine the model parameters as an initial value of the predistorter. And then, the least square method (LSM) algorithm is used to carry out direct learning structure on-line micro adjustment of the parameters of the predistorter and to conduct fitting on the nonlinearity and memory effect of the power amplifier. The method has the advantages of simple structure, fast convergence, and high precision, which has avoided the local optimum. The experimental results show that the adjacent channel power in this scheme is improved by approximately 7 dB compared with that of the classical dual loop structure predistortion method, and the linearization performance of the amplifier has been significantly improved, thus its feasibility has been verified.",Wiley
"Mi, Bo and Zou, Yongxing and Huang, Darong and Liu, Yang and Chen, Lu",New Constructions of Existential Unforgeable Aggregate Signature Scheme from CSP,2022,https://doi.org/10.1155/2022/8954767,https://onlinelibrary.wiley.com/doi/abs/10.1155/2022/8954767,Journal,Security and Communication Networks,"In future, hundreds of years of mathematical problems that the security of public key cryptography algorithms rely on may be defeated by quantum algorithms. How can a digital signature scheme gracefully balance security and efficiency? This study uses the conjugate search problem and the left self-distributive system to combine and uses the RSA-like algorithm as the underlying structure to propose a new aggregated signature scheme. We, through the EUF game, under the random metaphor model, prove that the security of the scheme satisfies the adaptation unforgeability under selective message attack, the scheme can be finally reduced to the discrete logarithm problem or large prime number decomposition problem. In addition, we can achieve antiquantum attack and exhaustive attack by performing matrix calculations on the message, defining and changing the structure of the matrix by encoding, and setting thresholds for the matrix dimension and the length of the private key. In terms of efficiency, the message signature implementation is linear compared with the expansion rate in terms of storage and computing overhead, and the generation and verification of the final signature pair have nothing to do with the number of users. In addition, the length of the signature is fixed and the size is only the length of a single group, which effectively reduces the generation of public and private key pairs and saves a lot of storage space. The storage space and computational complexity are also effectively improved compared with other solutions.",Wiley
"Muniswamy, Saravanan and Vignesh, Radhakrishnan",Joint optimization of load balancing and resource allocation in cloud environment using optimal container management strategy,2024,https://doi.org/10.1002/cpe.8035,https://onlinelibrary.wiley.com/doi/abs/10.1002/cpe.8035,Journal,Concurrency and Computation: Practice and Experience,"Summary Due to the high performance of cloud computing-based microservices, a wide range of industries and fields rely on them. In a containerized cloud, traditional resource management strategies are typically used to allocate and migrate virtual machines. A major problem for cloud service providers is resource allocation for containers, which directly affects system performance and resource consumption. In this paper, we propose a joint optimization of load balancing and resource allocation in the cloud using an optimal container management strategy. We aim to enhance scheduling efficiency and reduce costs by improving the container's schedule requested digitally by users. An improved backtracking search optimization (IBSO) algorithm is used to allocate resources between end-users/IoT devices and the cloud under the consideration of service-level agreements. Mechanic quantum recurrent neural networks (MQ-RNNs) are designed to allocate, consolidate, and migrate containers in cloud environments. The various simulation measures used to validate the proposed strategy are energy consumption, number of active servers, number of interruptions, total cost, runtime, and statistical measures.",Wiley
"Bernal, David E. and Ajagekar, Akshay and Harwood, Stuart M. and Stober, Spencer T. and Trenev, Dimitar and You, Fengqi",Perspectives of quantum computing for chemical engineering,2022,https://doi.org/10.1002/aic.17651,https://onlinelibrary.wiley.com/doi/abs/10.1002/aic.17651,Journal,AIChE Journal,"Quantum computing has been attracting public attention recently. This interest is driven by the advancements in hardware, software, and algorithms required for its successful usage and the promise that it entails the potential acceleration of computational tasks compared to classical computing. This perspective article presents a short review on quantum computing, how this computational approach solves problems, and three fields that quantum computing can potentially impact the most while relevant to chemical engineering: computational chemistry, optimization, and machine learning. Here, we present a series of chemical engineering applications, the developments, potential improvements with respect to classical computing, and challenges that quantum computing faces for each of these fields. This article intends to provide a clear picture of the challenges and potential advantages that quantum technology may yield for chemical engineering, together with an invitation for our colleagues to join us in the adoption and development of quantum computing.",Wiley
"Hedhli, Ameni and Mezni, Haithem and Ben Said, Lamjed",Predictive BPaaS management with quantum and neural computing,2022,https://doi.org/10.1002/smr.2421,https://onlinelibrary.wiley.com/doi/abs/10.1002/smr.2421,Journal,Journal of Software: Evolution and Process,"With the increasing adoption of cloud computing, the deployment and management of business processes over cloud environments have become an essential operation for most enterprises, leading to the emergence of BPaaS (Business Process as a Service) as a new cloud service model. This SaaS-like service, like its ancestors, should be strategically distributed and managed over multiple cloud zones, while taking into account several constraints and conditions (e.g., sensitivity of BPaaS fragments, insecure and untrusted cloud zones, lack of resources, and workload changes). However, current BPaaS approaches are static, which means that they are no longer suitable to manage such enterprise-oriented cloud service model and to deal with the uncertain and dynamic nature of cloud availability zones. To fill this gap, we adopt a predictive BPaaS management strategy by proposing a model that forecasts the next-short time overload of cloud zones. These latter, as hosting environments for the managed BPaaS, are categorized as overloaded or underloaded, which triggers the migration of BPaaS fragments to high-performance cloud zones. The proposed neural network prediction model (called QGA-NN) is enhanced with a quantum genetic algorithm to optimize the prediction of cloud zones' overload. QGA-NN is evaluated using a BPaaS placement algorithm, which we defined as a triggered management operation. Experimental results have proved the accuracy and effectiveness of our predictive approach, compared with state-of-the-art solutions.",Wiley
"Xing, Yiming and Ban, Xiaojuan and Guo, Chong",Probabilistic Forecasting of Traffic Flow Using Multikernel Based Extreme Learning Machine,2017,https://doi.org/10.1155/2017/2073680,https://onlinelibrary.wiley.com/doi/abs/10.1155/2017/2073680,Journal,Scientific Programming,"Real-time and accurate prediction of traffic flow is the key to intelligent transportation systems (ITS). However, due to the nonstationarity of traffic flow data, traditional point forecasting can hardly be accurate, so probabilistic forecasting methods are essential for quantification of the potential risks and uncertainties for traffic management. A probabilistic forecasting model of traffic flow based on a multikernel extreme learning machine (MKELM) is proposed. Moreover, the optimal output weights of MKELM are obtained by utilizing Quantum-behaved particle swarm optimization (QPSO) algorithm. To verify its effectiveness, traffic flow probabilistic prediction using QPSO-MKELM was compared with other learning methods. Experimental results show that QPSO-MKELM is more effective for practical applications. And it will help traffic managers to make right decisions.",Wiley
"Vermeer, Michael J. D. and Heitzenrater, Chad and Parker, Edward and Moon, Alvin and Lumpkin, Domenique and Awan, Jalal",Evaluating cryptographic vulnerabilities created by quantum computing in industrial control systems,2024,https://doi.org/10.1002/jci3.12024,https://onlinelibrary.wiley.com/doi/abs/10.1002/jci3.12024,Journal,Journal of Critical Infrastructure Policy,"Quantum computing is expected to eventually be able to break the public-key cryptography algorithms currently used throughout information technology (IT) infrastructure, undermining foundational tools used to maintain information security across the country's critical infrastructure. As these systems converge, the security posture of operational technology (OT) systems has to adapt to a new threat landscape and adopt some of the same security controls as those used in enterprise IT, especially cryptographic controls that rely on public-key cryptography, which are ubiquitous in enterprise IT systems. Operators and manufacturers of industrial control systems (ICSs) and OT systems will need to understand and address the unique ways in which these systems will be vulnerable to adversaries equipped with quantum computers. We assessed quantum computing¨Cfacilitated cryptographic vulnerabilities in ICSs and OT systems to identify the issues in need of the most-urgent attention from ICS and OT owners, operators, and manufacturers. Employing a modified consequence-driven, cyber-informed engineering process informed by literature review and analysis, we mapped protocols using or enabling cryptographic protections across common ICS network topologies as part of an assessment of how an attacker could cause harm, especially damaging physical consequences resulting from manipulation of cyber¨Cphysical systems, through the cryptographic compromise of ICS and OT networks and components. Our evaluation of identified and ranked risks to related control systems was also informed by relevant literature on ICS risk assessment and mitigation, cyber harms, and historical attacks on critical infrastructure. Using our analysis, we assessed the overall difficulty in mitigating risk from each of the identified vulnerability archetypes. The resulting analysis identified vulnerabilities associated with code-signing processes as the highest priority for attention when updating systems for a postquantum future. This risk was followed by vulnerabilities associated with forged certificates for identification and vulnerabilities associated with forged session keys, identified as lower priorities but still of concern. Informed by our findings, we offer recommendations related to the protection of these vulnerabilities and the improvement of ICS security in developed systems.",Wiley
"Deng, Qi and Zhang, Shanshan and Chen, Gang and Lu, Huaxiang",Blind separation of noncooperative paired carrier multiple access signals based on improved quantum-inspired evolutionary algorithm and receding horizon optimization,2022,https://doi.org/10.1002/cpe.6119,https://onlinelibrary.wiley.com/doi/abs/10.1002/cpe.6119,Journal,Concurrency and Computation: Practice and Experience,"The single-channel blind source separation of paired carrier multiple access (PCMA) signal is a key technology in satellite communications. Due to the high-order complexity of existing separation methods and the uncertainty of channel parameters, the processing of noncooperative PCMA signals with long memory remains a great challenge. In this article, the blind separation was solved as the joint channel estimation and sequence detection, and a novel blind separation algorithm based on the improved quantum-inspired evolutionary algorithm (IQEA) and receding horizon optimization was proposed. Considering the practical scenarios, a mixed PCMA signal model with noninteger period sampling was presented in advance. Combined with the proposed signal model, the IQEA was applied to recover the uplink signals from the mixed PCMA signals by its iterative estimation. Meanwhile, to reduce the computational complexity caused by long memory of PCMA signals, the receding horizon optimization was introduced to process the whole signal sequence as a dynamic programming problem. The simulation results verified that the proposed RH-IQEA outperforms existing state-of-the-art separation algorithms in the blind separation of noncooperative PCMA signals, with higher accuracy, lower-order complexity and stronger robustness to parameter estimation errors.",Wiley
"Zhenxue, He and Xiaoqian, Wu and Chao, Wang and Zhisheng, Huo and Limin, Xiao and Xiang, Wang",Delay optimization for ternary fixed polarity Reed¨CMuller circuits based on multilevel adaptive quantum genetic algorithm,2021,https://doi.org/10.1002/int.22538,https://onlinelibrary.wiley.com/doi/abs/10.1002/int.22538,Journal,International Journal of Intelligent Systems,"Delay optimization has now emerged as an important optimization goal in logic synthesis. The delay optimization for ternary fixed polarity Reed¨CMuller (FPRM) circuits aims to find a ternary FPRM circuit with a minimum delay. Because the delay optimization for ternary FPRM circuits is a combinatorial optimization problem, in this paper, we first propose a multilevel adaptive quantum genetic algorithm (MAQGA), which divides individuals into three-level populations: high-level population, intermediate-level population, and low-level population and uses the proposed ternary quantum rotation gate, proposed ternary quantum correction gate, and proposed multi-operator adaptive mutation mechanism to make the three-level populations evolve. Moreover, based on the proposed delay decomposition strategy, we propose a delay optimization approach (DOA) for ternary FPRM circuits under the unit delay model, which searches for a ternary FPRM circuit with a minimum delay using the MAQGA. Experimental results demonstrated the effectiveness and superiority of the DOA in optimizing the delay of ternary FPRM circuits.",Wiley
"Wang, ShaoPeng and Zhang, Yu-Hang and Lu, Jing and Cui, Weiren and Hu, Jerry and Cai, Yu-Dong",Analysis and Identification of Aptamer-Compound Interactions with a Maximum Relevance Minimum Redundancy and Nearest Neighbor Algorithm,2016,https://doi.org/10.1155/2016/8351204,https://onlinelibrary.wiley.com/doi/abs/10.1155/2016/8351204,Journal,BioMed Research International,"The development of biochemistry and molecular biology has revealed an increasingly important role of compounds in several biological processes. Like the aptamer-protein interaction, aptamer-compound interaction attracts increasing attention. However, it is time-consuming to select proper aptamers against compounds using traditional methods, such as exponential enrichment. Thus, there is an urgent need to design effective computational methods for searching effective aptamers against compounds. This study attempted to extract important features for aptamer-compound interactions using feature selection methods, such as Maximum Relevance Minimum Redundancy, as well as incremental feature selection. Each aptamer-compound pair was represented by properties derived from the aptamer and compound, including frequencies of single nucleotides and dinucleotides for the aptamer, as well as the constitutional, electrostatic, quantum-chemical, and space conformational descriptors of the compounds. As a result, some important features were obtained. To confirm the importance of the obtained features, we further discussed the associations between them and aptamer-compound interactions. Simultaneously, an optimal prediction model based on the nearest neighbor algorithm was built to identify aptamer-compound interactions, which has the potential to be a useful tool for the identification of novel aptamer-compound interactions. The program is available upon the request.",Wiley
"Jiao, Xiongfei and Li, Juan and Zhao, Zhilei and Badami, Benjamin",An all-inclusive computer-aided melanoma diagnosis based on soft computing,2022,https://doi.org/10.1002/ima.22708,https://onlinelibrary.wiley.com/doi/abs/10.1002/ima.22708,Journal,International Journal of Imaging Systems and Technology,"This paper provides a different optimized approach for melanoma diagnosis from the inputted dermoscopy images. The technique is a pipeline technique with four main steps, including noise reduction, lesion segmentation, feature selection, and final classification. For decreasing the complexity of the feature extraction stage, Fuzzy C-means has been used. The classifier has been improved based on a developed decision tree. The modification of the classifier is based on a new enhanced design of a metaheuristic, called Quantum Fluid Search Optimizer. The efficiency of the suggested technique is calculated by considering some measurement indicators and their achievements are compared with five other latest methods. The results showed the maximum accuracy equal to 94.12\% with the highest precision being achieved by the proposed method. The results also indicate that the proposed method with the highest value of 91.18\% sensitivity against the other techniques, provides the highest reliability.",Wiley
"Burger, Michael and Nguyen, Giang Nam and Bischof, Christian",SimAnMo¡ªA parallelized runtime model generator,2022,https://doi.org/10.1002/cpe.6771,https://onlinelibrary.wiley.com/doi/abs/10.1002/cpe.6771,Journal,Concurrency and Computation: Practice and Experience,"In this article, we present the novel features of the recent version of SimAnMo, the Simulated Annealing Modeler. The tool creates models that correlate the size of one input parameter of an application to the corresponding runtime and thus SimAnMo allows predictions for larger input sizes. A focus lies on applications whose runtime grows exponentially in the input parameter size. Such programs are, for example, of high interest for cryptanalysis to analyze practical security of traditional and post-quantum secure schemes. However, SimAnMo also generates reliable models for the widespread case of polynomial runtime behavior and also for the important case of factorial runtime increase. SimAnMo's model generation is based on a parallelized simulated annealing procedure and heuristically minimizes the costs of a model. Those may rely on different quality metrics. Insights into SimAnMo's software design and its usage are provided. We demonstrate the quality of SimAnMo's models for different algorithms from various application fields. We show that our approach also works well on ARM architectures.",Wiley
"Sajid, Mohammad and Raza, Zahid",Energy-efficient quantum-inspired stochastic Q-HypE algorithm for batch-of-stochastic-tasks on heterogeneous DVFS-enabled processors,2019,https://doi.org/10.1002/cpe.5327,https://onlinelibrary.wiley.com/doi/abs/10.1002/cpe.5327,Journal,Concurrency and Computation: Practice and Experience,"Summary Scheduling on dynamic voltage and frequency scaling enabled processors to determine the Pareto-optimal solutions with optimized makespan and energy consumption demands faster multi-objective scheduling algorithms. In general, the problem of multi-objective optimization, ie, finding the Pareto-optimal solutions to optimize two or more QoS parameters, has been proven to be an NP-complete problem. In this work, we propose a novel energy-efficient quantum-inspired stochastic Q-HypE algorithm to schedule the batch-of-stochastic-tasks (BoT) on DVFS-enabled processors with the aim to optimize the makespan of BoT as well as the energy consumption of processors. The stochastic processing times of tasks are drawn from independent probability distributions. The proposed Q-HypE algorithm evolves from combined characteristics of quantum computing and a hypervolume based multi-objective optimization HypE algorithm. The proposed Q-HypE algorithm simultaneously minimizes the makespan and energy consumption of the Pareto-optimal solutions whereas the dynamics of quantum computing accelerate the process of HypE to further minimize the overheads of hypervolume estimation. Experimental results reveal the effectiveness of the proposed Q-HypE algorithm both in terms of the number and quality of solutions offered.",Wiley
"Backholer, Kathryn and Baum, Fran and Finlay, Summer M and Friel, Sharon and Giles-Corti, Billie and Jones, Alexandra and Patrick, Rebecca and Shill, Jane and Townsend, Belinda and Armstrong, Fiona and Baker, Phil and Bowen, Kathryn and Browne, Jennifer and B¨¹sst, Cara and Butt, Andrew and Canuto, Karla and Canuto, Kootsy and Capon, Anthony and Corben, Kirstan and Daube, Mike and Goldfeld, Sharon and Grenfell, Robert and Gunn, Lucy and Harris, Patrick and Horton, Kellie and Keane, Lewis and Lacy-Nichols, Jennifer and Lo, Selina N and Lovett, Raymond W and Lowe, Melanie and Martin, Jane E and Neal, Nadia and Peeters, Anna and Pettman, Tahna and Thoms, Aileen and Thow, Anne Marie T and Timperio, Anna and Williams, Carmel and Wright, Annemarie and Zapata-Diomedi, Belen and Demaio, Sandro",Australia in 2030: what is our path to health for all?,2021,https://doi.org/10.5694/mja2.51020,https://onlinelibrary.wiley.com/doi/abs/10.5694/mja2.51020,Journal,Medical Journal of Australia,"Summary Chapter 1: How Australia improved health equity through action on the social determinants of health Do not think that the social determinants of health equity are old hat. In reality, Australia is very far away from addressing the societal level drivers of health inequity. There is little progressive policy that touches on the conditions of daily life that matter for health, and action to redress inequities in power, money and resources is almost non-existent. In this chapter we ask you to pause this reality and come on a fantastic journey where we envisage how COVID-19 was a great disruptor and accelerator of positive progressive action. We offer glimmers of what life could be like if there was committed and real policy action on the social determinants of health equity. It is vital that the health sector assists in convening the multisectoral stakeholders necessary to turn this fantasy into reality. Chapter 2: Aboriginal and Torres Strait Islander connection to culture: building stronger individual and collective wellbeing Aboriginal and Torres Strait Islander peoples have long maintained that culture (ie, practising, maintaining and reclaiming it) is vital to good health and wellbeing. However, this knowledge and understanding has been dismissed or described as anecdotal or intangible by Western research methods and science. As a result, Aboriginal and Torres Strait Islander culture is a poorly acknowledged determinant of health and wellbeing, despite its significant role in shaping individuals, communities and societies. By extension, the cultural determinants of health have been poorly defined until recently. However, an increasing amount of scientific evidence supports what Aboriginal and Torres Strait Islander people have always said ¡ª that strong culture plays a significant and positive role in improved health and wellbeing. Owing to known gaps in knowledge, we aim to define the cultural determinants of health and describe their relationship with the social determinants of health, to provide a full understanding of Aboriginal and Torres Strait Islander wellbeing. We provide examples of evidence on cultural determinants of health and links to improved Aboriginal and Torres Strait Islander health and wellbeing. We also discuss future research directions that will enable a deeper understanding of the cultural determinants of health for Aboriginal and Torres Strait Islander people. Chapter 3: Physical determinants of health: healthy, liveable and sustainable communities Good city planning is essential for protecting and improving human and planetary health. Until recently, however, collaboration between city planners and the public health sector has languished. We review the evidence on the health benefits of good city planning and propose an agenda for public health advocacy relating to health-promoting city planning for all by 2030. Over the next 10 years, there is an urgent need for public health leaders to collaborate with city planners ¡ª to advocate for evidence-informed policy, and to evaluate the health effects of city planning efforts. Importantly, we need integrated planning across and between all levels of government and sectors, to create healthy, liveable and sustainable cities for all. Chapter 4: Health promotion in the Anthropocene: the ecological determinants of health Human health is inextricably linked to the health of the natural environment. In this chapter, we focus on ecological determinants of health, including the urgent and critical threats to the natural environment, and opportunities for health promotion arising from the human health co-benefits of actions to protect the health of the planet. We characterise ecological determinants in the Anthropocene and provide a sobering snapshot of planetary health science, particularly the momentous climate change health impacts in Australia. We highlight Australia¡¯s position as a major fossil fuel producer and exporter, and a country lacking cohesive and timely emissions reduction policy. We offer a roadmap for action, with four priority directions, and point to a scaffold of guiding approaches ¡ª planetary health, Indigenous people¡¯s knowledge systems, ecological economics, health co-benefits and climate-resilient development. Our situation requires a paradigm shift, and this demands a recalibration of health promotion education, research and practice in Australia over the coming decade. Chapter 5: Disrupting the commercial determinants of health Our vision for 2030 is an Australian economy that promotes optimal human and planetary health for current and future generations. To achieve this, current patterns of corporate practice and consumption of harmful commodities and services need to change. In this chapter, we suggest ways forward for Australia, focusing on pragmatic actions that can be taken now to redress the power imbalances between corporations and Australian governments and citizens. We begin by exploring how the terms of health policy making must change to protect it from conflicted commercial interests. We also examine how marketing unhealthy products and services can be more effectively regulated, and how healthier business practices can be incentivised. Finally, we make recommendations on how various public health stakeholders can hold corporations to account, to ensure that people come before profits in a healthy and prosperous future Australia. Chapter 6: Digital determinants of health: the digital transformation We live in an age of rapid and exponential technological change. Extraordinary digital advancements and the fusion of technologies, such as artificial intelligence, robotics, the Internet of Things and quantum computing constitute what is often referred to as the digital revolution or the Fourth Industrial Revolution (Industry 4.0). Reflections on the future of public health and health promotion require thorough consideration of the role of digital technologies and the systems they influence. Just how the digital revolution will unfold is unknown, but it is clear that advancements and integrations of technologies will fundamentally influence our health and wellbeing in the future. The public health response must be proactive, involving many stakeholders, and thoughtfully considered to ensure equitable and ethical applications and use. Chapter 7: Governance for health and equity: a vision for our future Coronavirus disease 2019 has caused many people and communities to take stock on Australia¡¯s direction in relation to health, community, jobs, environmental sustainability, income and wealth. A desire for change is in the air. This chapter imagines how changes in the way we govern our lives and what we value as a society could solve many of the issues Australia is facing ¡ª most pressingly, the climate crisis and growing economic and health inequities. We present an imagined future for 2030 where governance structures are designed to ensure transparent and fair behaviour from those in power and to increase the involvement of citizens in these decisions, including a constitutional voice for Indigenous peoples. We imagine that these changes were made by measuring social progress in new ways, ensuring taxation for public good, enshrining human rights (including to health) in legislation, and protecting and encouraging an independent media. Measures to overcome the climate crisis were adopted and democratic processes introduced in the provision of housing, education and community development.",Wiley
"Procel, Paul and Ingenito, Andrea and De Rose, Raffaele and Pierro, Silvio and Crupi, Felice and Lanuzza, Marco and Cocorullo, Giuseppe and Isabella, Olindo and Zeman, Miro",Opto-electrical modelling and optimization study of a novel IBC c-Si solar cell,2017,https://doi.org/10.1002/pip.2874,https://onlinelibrary.wiley.com/doi/abs/10.1002/pip.2874,Journal,Progress in Photovoltaics: Research and Applications,"Interdigitated back contact (IBC) crystalline silicon (c-Si) solar cells are attracting a lot of attention because of their capability to reach world record conversion efficiency. Because of the relatively complex contact pattern, their design and optimization typically require advanced numerical simulation tools. In this work, a TCAD-based simulation platform has been developed to account accurately and in detail the optical and passivation mechanisms of front texturization. Its validation has been carried out with respect to a novel homo-junction IBC c-Si solar cell based on ion implantation and epitaxial growth, comparing measured and simulated reflectance, transmittance, internal quantum efficiency, external quantum efficiency spectra, and current density¨Cvoltage characteristics. As a result of the calibration process, the opto-electrical losses of the investigated device have been identified quantitatively and qualitatively. Then, an optimization study about the optimal front surface field (FSF) doping, front-side texturing morphology, and rear side geometry has been performed. The proposed simulation platform can be potentially deployed to model other solar cell architectures than homo-junction IBC devices (e.g., passivated emitter rear cell, passivated emitter rear locally diffused cell, hetero-IBC cell). Simulation results show that a not-smoothed pyramid-textured front interface and an optimal FSF doping are mandatory to minimize both the optical and the recombination losses in the considered IBC cell and, consequently, to maximize the conversion efficiency. Similarly, it has been showed that recombination losses are affected more by the doping profile rather than the surface smoothing. Moreover, the performed investigation reveals that the optimal FSF doping is almost independent from the front texturing morphology and FSF passivation quality. According to this result, it has been demonstrated that an IBC cell featuring an optimal FSF doping does not exhibit a significant efficiency improvement when the FSF passivation quality strongly improves, proving that IBC cell designs based on low-doped FSF require a very outstanding passivation quality to be competitive. Deploying an optimization algorithm, the adoption of an optimized rear side geometry can potentially lead to an efficiency improvement of about 1\%abs as compared with the reference IBC solar cell. Further, by improving both emitter and c-Si bulk quality, a 22.84\% efficient solar cell for 280-¦Ìm thick c-Si bulk was simulated. Copyright ? 2017 John Wiley \& Sons, Ltd.",Wiley
"Wang, Hairong and Lu, Rong and Yu, Duo",Machine Vision Nondestructive Inspection System Assisted by Industrial IoT Supervision Mechanism,2022,https://doi.org/10.1155/2022/8449518,https://onlinelibrary.wiley.com/doi/abs/10.1155/2022/8449518,Journal,Mathematical Problems in Engineering,"This paper introduces the development status of machine vision nondestructive testing technology and industrial IoT supervision mechanism. The study designs and implements a machine vision nondestructive testing system from two aspects: construction of industrial IoT supervision and detection model, and optimization of machine vision nondestructive testing algorithm. In this paper, the random deployment of dynamic and static nodes is adopted. The coverage rate after random deployment and the moving distance of dynamic nodes are two necessary research parameters. To improve the initial coverage and optimize the mobile path of dynamic nodes, this paper proposes a mobile deployment optimization scheme based on the supervisory mechanism model of industrial IoT, which improves the traversal of the quantum genetic algorithm by improving the genetic variation rules, thus improving the initial deployment of the network. The optimized machine vision nondestructive detection algorithm is used for mobile path optimization from dynamic nodes to target locations. Simulation results show that a random deployment of 100 static nodes and 20 dynamic nodes in a 400?m ¡Á 400?m factory area works best with a coverage rate of 6.719\% and an average movement distance of 23.47?m, and the movement path avoids the obstacle area. The average accuracy of the modified machine vision nondestructive testing system is 1.59\% higher than that before the modification, and the average detection accuracy of the final experiment reaches 95.46\%. Not only is the coverage rate better than that of the cellular structure-based dynamic node optimization scheme, but also the monitoring range of the plant tends to be more comprehensive in the actual deployment environment. Through the analysis of test results, the system achieves the monitoring and display of data on the one hand and provides a natural information access and interaction experience for IoT managers on the other hand, which meets the requirements of real time, accuracy, and stability of industrial IoT information data to a certain extent.",Wiley
"Nishimura, Yoshifumi and Nakai, Hiromi",Dcdftbmd: Divide-and-Conquer Density Functional Tight-Binding Program for Huge-System Quantum Mechanical Molecular Dynamics Simulations,2019,https://doi.org/10.1002/jcc.25804,https://onlinelibrary.wiley.com/doi/abs/10.1002/jcc.25804,Journal,Journal of Computational Chemistry,"Dcdftbmd is a Fortran 90/95 program that enables efficient quantum mechanical molecular dynamics (MD) simulations using divide-and-conquer density functional tight-binding (DC-DFTB) method. Based on the remarkable performance of previous massively parallel DC-DFTB energy and gradient calculations for huge systems, the code has been specialized to MD simulations. Recent implementations and modifications including DFTB extensions, improved computational speed in the DC-DFTB computational steps, algorithms for efficient initial guess charge prediction, and free energy calculations via metadynamics technique have enhanced the capability to obtain atomistic insights in novel applications to nanomaterials and biomolecules. The energy, structure, and other molecular properties are also accessible through the single-point calculation, geometry optimization, and vibrational frequency analysis. The available functionalities are outlined together with efficiency tests and simulation examples. ? 2019 Wiley Periodicals, Inc.",Wiley
"R, Mahaveerakannan and C, Suresh Gnana Dhas",Big data analytics for large-scale UAV-MBN in quantum networks using efficient hybrid GKM,2022,https://doi.org/10.1002/cpe.5559,https://onlinelibrary.wiley.com/doi/abs/10.1002/cpe.5559,Journal,Concurrency and Computation: Practice and Experience,"Summary A primary important aspect of wireless network domain is known to be secured communication as the signals are emphatically available and broadcasted through the air. Quantum wireless networks are a hot topic of research in recent years that made researchers to avail new techniques in this field. Big data is one of the major aspects that support large-scale quantum network applications. As sensor nodes have resource constraints, it is more complex when using the traditional techniques of key establishment that only used for stable communication networks. Group-related applications are also one of the important aspects in wireless network for sending and receiving messages from multiple users. Unfortunately, maintenance of security for the group-oriented protocols is major issue due to the frequent changes in membership. In this paper, a hybrid GKM with re-keying procedure is proposed to obtain a secure communication for the remote system of unmanned autonomous vehicle (UAV) with mobile backbone network (MBN). Here, the group controller is selected based on the simplified hybrid energy efficient distributed (HEED) protocol and honey key encryption algorithm is used by the key management center (KMC) for generating and distribution of key for the group's controller. The secure communication is explored using the key exchange mechanism between the nodes. The joining and leaving of a node from the group are initiated by the re-keying process. The simulation results explain the improved performance of the proposed hybrid method when compared with other existing techniques in terms of privacy level, energy, memory, and time consumption.",Wiley
"Weder, Benjamin and Barzen, Johanna and Leymann, Frank and Salm, Marie and Wild, Karoline",QProv: A provenance system for quantum computing,2021,https://doi.org/10.1049/qtc2.12012,https://onlinelibrary.wiley.com/doi/abs/10.1049/qtc2.12012,Journal,IET Quantum Communication,"Quantum computing promises breakthroughs in various application areas, such as machine learning, chemistry, or simulations. However, today¡¯s quantum computers are error-prone and have limited capabilities. This leads to various challenges when developing and executing quantum algorithms, for example, the mitigation of occurring errors or the selection of a suitable quantum computer to execute a certain quantum circuit. To address these challenges, detailed information about the quantum circuit to be executed as well as past executions, and the up-to-date information about the available quantum computers are required. Thus, this data must be continuously collected and stored in the long-term, which is currently not supported. To overcome this problem, a provenance approach is introduced for quantum computing. Therefore, relevant provenance attributes that should be gathered in the area of quantum computing are identified. Furthermore, QProv, a provenance system that automatically collects the identified provenance attributes and provides them in a uniform manner to the user is introduced. Finally, a case study with the collected provenance data and corresponding use cases that can benefit from this provenance data are presented here.",Wiley
"Chatterjee, Turbasu and Das, Arnav and Bala, Subhayu Kumar and Saha, Amit and Chattopadhyay, Anupam and Chakrabarti, Amlan",QuDiet: A classical simulation platform for qubit-qudit hybrid quantum systems,2023,https://doi.org/10.1049/qtc2.12058,https://onlinelibrary.wiley.com/doi/abs/10.1049/qtc2.12058,Journal,IET Quantum Communication,"In recent years, numerous research advancements have extended the limit of classical simulation of quantum algorithms. Although, most of the state-of-the-art classical simulators are only limited to binary quantum systems, which restrict the classical simulation of higher-dimensional quantum computing systems. Through recent developments in higher-dimensional quantum computing systems, it is realised that implementing qudits improves the overall performance of a quantum algorithm by increasing memory space and reducing the asymptotic complexity of a quantum circuit. Hence, in this article, QuDiet, a state-of-the-art user-friendly python-based higher-dimensional quantum computing simulator is introduced. QuDiet offers multi-valued logic operations by utilising generalised quantum gates with an abstraction so that any naive user can simulate qudit systems with ease as compared to the existing ones. Various benchmark quantum circuits is simulated in QuDiet and show the considerable speedup in simulation time as compared to the other simulators without loss in precision. Finally, QuDiet provides a full qubit-qudit hybrid quantum simulator package with quantum circuit templates of well-known quantum algorithms for fast prototyping and simulation. Comprehensive simulation up to 20 qutrits circuit on depth 80 on QuDiet was successfully achieved. The complete code and packages of QuDiet is available at https://github.com/LegacYFTw/QuDiet.",Wiley
"Zheng, Min and Moriarty, Nigel W. and Xu, Yanting and Reimers, Jeffrey R. and Afonine, Pavel V. and Waller, Mark P.",Solving the scalability issue in quantum-based refinement: Q|R\#1,2017,https://doi.org/10.1107/S2059798317016746,https://onlinelibrary.wiley.com/doi/abs/10.1107/S2059798317016746,Journal,Acta Crystallographica Section D,"Accurately refining biomacromolecules using a quantum-chemical method is challenging because the cost of a quantum-chemical calculation scales approximately as nm, where n is the number of atoms and m (¡Ý3) is based on the quantum method of choice. This fundamental problem means that quantum-chemical calculations become intractable when the size of the system requires more computational resources than are available. In the development of the software package called Q|R, this issue is referred to as Q|R\#1. A divide-and-conquer approach has been developed that fragments the atomic model into small manageable pieces in order to solve Q|R\#1. Firstly, the atomic model of a crystal structure is analyzed to detect noncovalent interactions between residues, and the results of the analysis are represented as an interaction graph. Secondly, a graph-clustering algorithm is used to partition the interaction graph into a set of clusters in such a way as to minimize disruption to the noncovalent interaction network. Thirdly, the environment surrounding each individual cluster is analyzed and any residue that is interacting with a particular cluster is assigned to the buffer region of that particular cluster. A fragment is defined as a cluster plus its buffer region. The gradients for all atoms from each of the fragments are computed, and only the gradients from each cluster are combined to create the total gradients. A quantum-based refinement is carried out using the total gradients as chemical restraints. In order to validate this interaction graph-based fragmentation approach in Q|R, the entire atomic model of an amyloid cross-¦Â spine crystal structure (PDB entry 2oNA) was refined.",Wiley
"Zhao, Wenju and Guo, Shuanglin and Zhou, Yun and Zhang, Jian",A Quantum-Inspired Genetic Algorithm-Based Optimization Method for Mobile Impact Test Data Integration,2018,https://doi.org/10.1111/mice.12352,https://onlinelibrary.wiley.com/doi/abs/10.1111/mice.12352,Journal,Computer-Aided Civil and Infrastructure Engineering,"The traditional impact test method needs a large number of sensors deployed on the entire structure, which cannot meet the requirements of rapid bridge testing. A new mobile impact test method is proposed by sequentially testing the substructures then integrating the test data of all substructures for flexibility identification of the entire structure. The novelty of the proposed method is that the quantum-inspired genetic algorithm (QIGA) is proposed to improve computational efficiency by transforming the scaling factor sign determination problem to an optimization problem. Experimental example of a steel¨Cconcrete composite slab and numerical example of a three-span continuous rigid-frame bridge are studied which successfully verify the effectiveness of the proposed method.",Wiley
"Kim, Sun Hong and Baek, Geun Woo and Yoon, Jiyong and Seo, Seunghwan and Park, Jinhong and Hahm, Donghyo and Chang, Jun Hyuk and Seong, Duhwan and Seo, Hyunseon and Oh, Seyong and Kim, Kyunghwan and Jung, Heeyoung and Oh, Youngsu and Baac, Hyoung Won and Alimkhanuly, Batyrbek and Bae, Wan Ki and Lee, Seunghyun and Lee, Minbaek and Kwak, Jeonghun and Park, Jin-Hong and Son, Donghee",A Bioinspired Stretchable Sensory-Neuromorphic System,2021,https://doi.org/10.1002/adma.202104690,https://onlinelibrary.wiley.com/doi/abs/10.1002/adma.202104690,Journal,Advanced Materials,"Conventional stretchable electronics that adopt a wavy design, a neutral mechanical plane, and conformal contact between abiotic and biotic interfaces have exhibited diverse skin-interfaced applications. Despite such remarkable progress, the evolution of intelligent skin prosthetics is challenged by the absence of the monolithic integration of neuromorphic constituents into individual sensing and actuating components. Herein, a bioinspired stretchable sensory-neuromorphic system, comprising an artificial mechanoreceptor, artificial synapse, and epidermal photonic actuator is demonstrated; these three biomimetic functionalities correspond to a stretchable capacitive pressure sensor, a resistive random-access memory, and a quantum dot light-emitting diode, respectively. This system features a rigid-island structure interconnected with a sinter-free printable conductor, which is optimized by controlling the evaporation rate of solvent (¡Ö160\% stretchability and ¡Ö18 550 S cm?1 conductivity). Devised design improves both areal density and structural reliability while avoiding the thermal degradation of heat-sensitive stretchable electronic components. Moreover, even in the skin deformation range, the system accurately recognizes various patterned stimuli via an artificial neural network with training/inferencing functions. Therefore, the new bioinspired system is expected to be an important step toward implementing intelligent wearable electronics.",Wiley
"Hasan, Tayyabah and Ahmad, Fahad and Rizwan, Muhammad and Alshammari, Nasser and Alanazi, Saad Awadh and Hussain, Iftikhar and Naseem, Shahid",Edge Caching in Fog-Based Sensor Networks through Deep Learning-Associated Quantum Computing Framework,2022,https://doi.org/10.1155/2022/6138434,https://onlinelibrary.wiley.com/doi/abs/10.1155/2022/6138434,Journal,Computational Intelligence and Neuroscience,"Fog computing (FC) based sensor networks have emerged as a propitious archetype for next-generation wireless communication technology with caching, communication, and storage capacity services in the edge. Mobile edge computing (MEC) is a new era of digital communication and has a rising demand for intelligent devices and applications. It faces performance deterioration and quality of service (QoS) degradation problems, especially in the Internet of Things (IoT) based scenarios. Therefore, existing caching strategies need to be enhanced to augment the cache hit ratio and manage the limited storage to accelerate content deliveries. Alternatively, quantum computing (QC) appears to be a prospect of more or less every typical computing problem. The framework is basically a merger of a deep learning (DL) agent deployed at the network edge with a quantum memory module (QMM). Firstly, the DL agent prioritizes caching contents via self organizing maps (SOMs) algorithm, and secondly, the prioritized contents are stored in QMM using a Two-Level Spin Quantum Phenomenon (TLSQP). After selecting the most appropriate lattice map (32?¡Á?32) in 750,000 iterations using SOMs, the data points below the dark blue region are mapped onto the data frame to get the videos. These videos are considered a high priority for trending according to the input parameters provided in the dataset. Similarly, the light-blue color region is also mapped to get medium-prioritized content. After the SOMs algorithm¡¯s training, the topographic error (TE) value together with quantization error (QE) value (i.e., 0.0000235) plotted the most appropriate map after 750,000 iterations. In addition, the power of QC is due to the inherent quantum parallelism (QP) associated with the superposition and entanglement principles. A quantum computer taking ¡°n¡± qubits that can be stored and execute 2n presumable combinations of qubits simultaneously reduces the utilization of resources compared to conventional computing. It can be analyzed that the cache hit ratio will be improved by ranking the content, removing redundant and least important content, storing the content having high and medium prioritization using QP efficiently, and delivering precise results. The experiments for content prioritization are conducted using Google Colab, and IBM¡¯s Quantum Experience is considered to simulate the quantum phenomena.",Wiley
"Nuvvula, Ramakrishna S S and Devaraj, Elangovan and Teegala, Srinivasa Kishore",A hybrid multiobjective optimization technique for optimal sizing of BESS-WtE supported multi-MW HRES to overcome ramp rate limitations on thermal stations,2021,https://doi.org/10.1002/2050-7038.13241,https://onlinelibrary.wiley.com/doi/abs/10.1002/2050-7038.13241,Journal,International Transactions on Electrical Energy Systems,"In India, favorable renewable energy policies have resulted in a higher proportion of renewable energy in the system. However, this led to the lower capacity utilization factor of thermal power stations. Any additional burden on thermal stations by enforcing higher ramp rates during peak hours would seriously affect technically as well as economically. In this regard, further renewable additions must be supported by energy storage systems to meet the ramping requirements. Waste-to-energy (WtE) plants play a crucial role in improving grid resilience in a high-renewable energy scenario to support expensive battery energy storage systems. In this article, the potential of WtE is assessed for a smart city in India, selected based on the possible urban and industrial growth, along with three other renewable energy technologies such as floating solar, bifacial rooftops solar, and wind energy conversion systems. The selected location has a total renewable energy potential of 439?MW. To achieve the municipality's techno-economic objectives, a multiobjective-enabled adaptive local attractor¨Cbased quantum-behaved particle swarm optimization (ALA-mQPSO) is proposed with mutation. With the proposed ALA-mQPSO, Pareto optimal sets of the hybrid renewable energy sources aided by the combination of battery energy storage system and WtE plant is achieved. The Pareto fronts are then compared with the benchmark techniques such as differential evolution along with the recently proposed multiobjective golden eagle optimizer algorithm. The results show that with the addition of the WtE plant, the grid can provide greater reliability for an optimal set of BESS and HRES. The obtained optimal configuration resulted in a levelized cost of \$0.0539 along with just 0.049\% of loss of power supply probability and 0.048?cycle loss of BESS, and when compared with similar works from the literature, the results proved to be superior and realistic.",Wiley
"Barone, Vincenzo",From Perception to Prediction and Interpretation: Enlightening the Gray Zone of Molecular Bricks of Life With the Help of Machine Learning and Quantum Chemistry,2025,https://doi.org/10.1002/wcms.70000,https://onlinelibrary.wiley.com/doi/abs/10.1002/wcms.70000,Journal,WIREs Computational Molecular Science,"ABSTRACT The latest developments of a general exploration/exploitation strategy for the computational study of molecular bricks of life in the gas-phase are presented and illustrated by means of prototypical semi-rigid and flexible systems. In the first step, generalized natural internal coordinates are employed to obtain a clear-cut separation between different degrees of freedom, and machine-learning algorithms based on chemical descriptors (synthons) drive fast quantum chemical methods in the exploration of rugged potential energy surfaces ruled by soft degrees of freedom. Then, different quantum chemical models are carefully selected for exploiting energies, geometries, and vibrational frequencies with the aim of maximizing the accuracy of the overall description while retaining a reasonable cost for all the steps. In particular, a composite wave-function method is used for energies, whereas a double-hybrid functional is employed for geometries and harmonic frequencies and a cheaper global hybrid functional for anharmonic contributions. A panel of molecular bricks of life containing up to 50 atoms is employed to show that the proposed strategy draws closer to the accuracy of state-of-the-art composite wave-function methods for small semi-rigid molecules, but is applicable to much larger systems. The implementation of the whole computational workflow in terms of preprocessing and postprocessing of data provided by standard electronic structure codes paves the way toward the accurate yet not prohibitively expensive study of medium- to large-sized molecules by a user-friendly black-box tool exploitable also by experiment-oriented researchers.",Wiley
"Vedavyasa, Kurudi V and Kumar, Ashok",Classification Analysis of Transition Metal Compounds Using Quantum Machine Learning,,https://doi.org/10.1002/qute.202400081,https://onlinelibrary.wiley.com/doi/abs/10.1002/qute.202400081,Journal,Advanced Quantum Technologies,,Wiley
"Dong, Lina and Li, Yulin and Liu, Dandan and Ji, Ye and Hu, Bo and Shi, Shuai and Zhang, Fangyan and Hu, Junjie and Qian, Kun and Jin, Xianmin and Wang, Binju",Prediction of Protein-Ligand Binding Affinity by a Hybrid Quantum-Classical Deep Learning Algorithm,2023,https://doi.org/10.1002/qute.202300107,https://onlinelibrary.wiley.com/doi/abs/10.1002/qute.202300107,Journal,Advanced Quantum Technologies,"Rapid and accurate prediction of protein-ligand binding affinity plays a vital role in high-throughput drug screening. With the development of deep learning, increasingly accurate prediction models have been established. Deep learning may have ushered in an era of quantization, but the practical use of this theory for protein-ligand binding affinity is still infrequent. Here, the introduction of the quantum algorithm into classical deep learning is described, which enables it to reliably predict protein-ligand binding affinity using simple sequence information. Based on different deep learning models, including graph neural networks (GNN) and convolutional neural networks (CNN), corresponding quantum hybrid deep learning models have been constructed and compared to the classical models. This study has shown that the quantum algorithm can achieve considerable accuracy and good generalization, and show potential to balance between accuracy and generalization, although the parameters used in the model have been remarkably reduced. These models based on quantum hybrid deep learning (QDL) show robust predictions on four benchmark datasets, and exhibit the practical application power in drug screening for targets related to human liver cirrhosis. This work highlights the potential of the hybrid quantum deep learning algorithm in solving complex problems in bioinformatics.",Wiley
"Szymku?, Sara and Gajewska, Ewa P. and Klucznik, Tomasz and Molga, Karol and Dittwald, Piotr and Startek, Micha? and Bajczyk, Micha? and Grzybowski, Bartosz A.",Computer-Assisted Synthetic Planning: The End of the Beginning,2016,https://doi.org/10.1002/anie.201506101,https://onlinelibrary.wiley.com/doi/abs/10.1002/anie.201506101,Journal,Angewandte Chemie International Edition,"Exactly half a century has passed since the launch of the first documented research project (1965 Dendral) on computer-assisted organic synthesis. Many more programs were created in the 1970s and 1980s but the enthusiasm of these pioneering days had largely dissipated by the 2000s, and the challenge of teaching the computer how to plan organic syntheses earned itself the reputation of a ¡°mission impossible¡±. This is quite curious given that, in the meantime, computers have ¡°learned¡± many other skills that had been considered exclusive domains of human intellect and creativity¡ªfor example, machines can nowadays play chess better than human world champions and they can compose classical music pleasant to the human ear. Although there have been no similar feats in organic synthesis, this Review argues that to concede defeat would be premature. Indeed, bringing together the combination of modern computational power and algorithms from graph/network theory, chemical rules (with full stereo- and regiochemistry) coded in appropriate formats, and the elements of quantum mechanics, the machine can finally be ¡°taught¡± how to plan syntheses of non-trivial organic molecules in a matter of seconds to minutes. The Review begins with an overview of some basic theoretical concepts essential for the big-data analysis of chemical syntheses. It progresses to the problem of optimizing pathways involving known reactions. It culminates with discussion of algorithms that allow for a completely de novo and fully automated design of syntheses leading to relatively complex targets, including those that have not been made before. Of course, there are still things to be improved, but computers are finally becoming relevant and helpful to the practice of organic-synthetic planning. Paraphrasing Churchill's famous words after the Allies¡¯ first major victory over the Axis forces in Africa, it is not the end, it is not even the beginning of the end, but it is the end of the beginning for the computer-assisted synthesis planning. The machine is here to stay.",Wiley
"Qasim, Mohammed N. and Mohammed, Tareq Abed and Bayat, Oguz",Breast Sentinel Lymph Node Cancer Detection from Mammographic Images Based on Quantum Wavelet Transform and an Atrous Pyramid Convolutional Neural Network,2022,https://doi.org/10.1155/2022/1887613,https://onlinelibrary.wiley.com/doi/abs/10.1155/2022/1887613,Journal,Scientific Programming,"This study proposes an optimal approach to reduce noise in mammographic images and to identify salt-and-pepper, Gaussian, Poisson, and impact noises to determine the exact mass detection operation after these noise reductions. It therefore offers a method for noise reduction operations called quantum wavelet transform filtering and a method for precision mass segmentation called the image morphological operations in mammographic images based on the classification with an atrous pyramid convolutional neural network (APCNN) as a deep learning model. The hybrid approach called a QWT-APCNN is evaluated in terms of criteria compared with previous methods such as peak signal-to-noise ratio (PSNR) and mean-squared error (MSE) in noise reduction and accuracy of detection for mass area recognition. The proposed method presents more performance of noise reduction and segmentation in comparison with state-of-the-art methods. In this paper, we used the APCNN based on the convolutional neural network (CNN) as a new deep learning method, which is able to extract features and perform classification simultaneously, but it is intended as far as possible, empirically for the purpose of this research to be able to determine breast cancer and then identify the exact area of the masses and then classify them according to benign, malignant, and suspicious classes. The obtained results presented that the proposed approach has better performance than others based on some evaluation criteria such as accuracy with 98.57\%, sensitivity with 90\%, specificity with 85\%, and also ROC and AUC with a rate of 86.77.",Wiley
"Du, Yanan and Gao, Hongyuan and Liu, Yapeng and Sun, Rongchen",Computationally efficient angle estimation of bistatic MIMO radar based on multimodal optimization,2023,https://doi.org/10.1049/ell2.12966,https://onlinelibrary.wiley.com/doi/abs/10.1049/ell2.12966,Journal,Electronics Letters,"In this letter, a computationally efficient multiple signal classification (MUSIC)-based evolutionary algorithm for angle estimation of bistatic multiple-input multiple-output (MIMO) radar is proposed. The existing MUSIC algorithms require a computationally cumbersome two-dimensional (2D) peak searching and the performance is highly related to the grid that set, which leads to a conflict between the computational efficiency and estimation performance. To address this difficulty, a multimodal quantum-inspired salp swarm algorithm, integrating kmeans clustering technique, is proposed to substitute the 2D peak searching to obtain multiple maxima of the MUSIC algorithm. The resulting computationally efficient algorithm obviously reduces the computational complexity of the MUSIC algorithm, avoids grid errors, and further exploits the potential of the MUSIC algorithm. Numerical simulations in various scenarios are carried out to verify the superiority of the method.",Wiley
"Zhang, Degan and Wang, Jiaxu and Fan, Hongrui and Zhang, Ting and Gao, Jinxin and Yang, Peng",New method of traffic flow forecasting based on quantum particle swarm optimization strategy for intelligent transportation system,2021,https://doi.org/10.1002/dac.4647,https://onlinelibrary.wiley.com/doi/abs/10.1002/dac.4647,Journal,International Journal of Communication Systems,"Summary Traffic flow forecasting is one of the essential means to realize smart cities and smart transportation. The accurate and effective prediction will provide an important basis for decision-making in smart transportation systems. This paper proposes a new method of traffic flow forecasting based on quantum particle swarm optimization (QPSO) strategy for intelligent transportation system (ITS). We establish a corresponding model based on the characteristics of the traffic flow data. The genetic simulated annealing algorithm is applied to the quantum particle swarm algorithm to obtain the optimized initial cluster center, and is applied to the parameter optimization of the radial basis neural network prediction model. The function approximation of radial basis neural network is used to obtain the required data. In addition, in order to compare the performance of the algorithms, a comparison study with other related algorithms such as QPSO radial basis function (QPSO-RBF) is also performed. Simulation results show that compared with other algorithms, the proposed algorithm can reduce prediction errors and get better and more stable prediction results.",Wiley
"Yang, Yu and Dai, Hongwei and Gao, Shangce and Wang, Yirui and Jia, Dongbao and Tang, Zheng",Complete receptor editing operation based on quantum clonal selection algorithm for optimization problems,2019,https://doi.org/10.1002/tee.22822,https://onlinelibrary.wiley.com/doi/abs/10.1002/tee.22822,Journal,IEEJ Transactions on Electrical and Electronic Engineering,"Clonal selection mechanism, which is the theoretical foundation of clonal selection algorithm (CSA) and its variants, was proposed for explaining the essential features of adaptive immune responses: adequate diversity, discrimination of self and nonself, and sustaining immunologic memory. On the basis of the clonal selection theory, only the high-affinity immune cells are chosen to proliferate. Those cells with low affinity must be efficiently eliminated. However, the ability of receptor editing to salvage low-affinity immune cells from deletion by changing their receptor specificity realized the clonal selection process anew. By combining clonal selection theory and receptor editing, a quantum clonal selection algorithm based on complete receptor editing operation is proposed for the traveling salesman problem (TSP) and the holes-machining-path-planning (HMPP) problem. Two receptor editing operators (inversion and deletion) work together to improve the performance of CSA. Furthermore, in order to overcome the drawback of asexual proliferation during the immune maturation process, a quantum interference crossover based on complete receptor editing operation is used. The effectiveness of the improved algorithm is evaluated on optimization problems including TSP and HMPP problems. The experimental results are also compared with those of other methods based on clonal selection theory. ? 2018 Institute of Electrical Engineers of Japan. Published by John Wiley \& Sons, Inc.",Wiley
"Xing, Longyue and Wang, Zhaoshun and Ding, Zhezhao and Chu, Genshen and Dong, Lingyu and Xiao, Nan",An efficient sparse stiffness matrix vector multiplication using compressed sparse row storage format on AMD GPU,2022,https://doi.org/10.1002/cpe.7186,https://onlinelibrary.wiley.com/doi/abs/10.1002/cpe.7186,Journal,Concurrency and Computation: Practice and Experience,"Summary The performance of sparse stiffness matrix-vector multiplication is essential for large-scale structural mechanics numerical simulation. Compressed sparse row (CSR) is the most common format for storing sparse stiffness matrices. However, the high sparsity of the sparse stiffness matrix makes the number of nonzero elements per row very small. Therefore, the CSR-scalar algorithm, light algorithm, and HOLA algorithm in the calculation will cause some threads in the GPU to be in idle state, which will not only affect the computing performance but also waste computing resources. In this article, a new algorithm, CSR-vector row, is proposed for fine-grained computing optimization based on the AMD GPU architecture on heterogeneous supercomputers. This algorithm can set a vector to calculate a row based on the number of nonzero elements of the stiffness matrix. CSR-vector row has efficient reduce operations, deep memory access optimization, better memory access, and calculation overlapping kernel function configuration scheme. The access bandwidth of the algorithm on AMD GPU is more than 700?GB/s. Compared with CSR-scalar algorithm, the parallel efficiency of CSR-vector row is improved by 7.2 times. And floating-point computing performance is 41\%¨C95\% higher than that of light algorithm and HOLA algorithm. In addition, CSR-vector row is used to calculate the examples from CFD, electromagnetics, quantum chemistry, power network, and semiconductor process, the memory access bandwidth and double floating-point performance are also improved compared with rocSPARSE-CSR-vector.",Wiley
"Wang, Bao and Wang, Chengzhang and Wu, Kedi and Wei, Guo-Wei",Breaking the polar-nonpolar division in solvation free energy prediction,2018,https://doi.org/10.1002/jcc.25107,https://onlinelibrary.wiley.com/doi/abs/10.1002/jcc.25107,Journal,Journal of Computational Chemistry,"Implicit solvent models divide solvation free energies into polar and nonpolar additive contributions, whereas polar and nonpolar interactions are inseparable and nonadditive. We present a feature functional theory (FFT) framework to break this ad hoc division. The essential ideas of FFT are as follows: (i) representability assumption: there exists a microscopic feature vector that can uniquely characterize and distinguish one molecule from another; (ii) feature-function relationship assumption: the macroscopic features, including solvation free energy, of a molecule is a functional of microscopic feature vectors; and (iii) similarity assumption: molecules with similar microscopic features have similar macroscopic properties, such as solvation free energies. Based on these assumptions, solvation free energy prediction is carried out in the following protocol. First, we construct a molecular microscopic feature vector that is efficient in characterizing the solvation process using quantum mechanics and Poisson¨CBoltzmann theory. Microscopic feature vectors are combined with macroscopic features, that is, physical observable, to form extended feature vectors. Additionally, we partition a solvation dataset into queries according to molecular compositions. Moreover, for each target molecule, we adopt a machine learning algorithm for its nearest neighbor search, based on the selected microscopic feature vectors. Finally, from the extended feature vectors of obtained nearest neighbors, we construct a functional of solvation free energy, which is employed to predict the solvation free energy of the target molecule. The proposed FFT model has been extensively validated via a large dataset of 668 molecules. The leave-one-out test gives an optimal root-mean-square error (RMSE) of 1.05 kcal/mol. FFT predictions of SAMPL0, SAMPL1, SAMPL2, SAMPL3, and SAMPL4 challenge sets deliver the RMSEs of 0.61, 1.86, 1.64, 0.86, and 1.14 kcal/mol, respectively. Using a test set of 94 molecules and its associated training set, the present approach was carefully compared with a classic solvation model based on weighted solvent accessible surface area. ? 2017 Wiley Periodicals, Inc.",Wiley
"Vijayarajan, S. M. and Manoj Kumar, D. and Sudha, G. and Reddy, A. Basi",Infrared thermal images using PCSAN-Net-DBOA: An approach of breast cancer classification,2024,https://doi.org/10.1002/jemt.24550,https://onlinelibrary.wiley.com/doi/abs/10.1002/jemt.24550,Journal,Microscopy Research and Technique,"This manuscript proposes thermal images using PCSAN-Net-DBOA Initially, the input images are engaged from the database for mastology research with infrared image (DMR-IR) dataset for breast cancer classification. The adaptive distorted Gaussian matched-filter (ADGMF) was used in removing noise and increasing the quality of infrared thermal images. Next, these preprocessed images are given into one-dimensional quantum integer wavelet S-transform (OQIWST) for extracting Grayscale statistic features like standard deviation, mean, variance, entropy, kurtosis, and skewness. The extracted features are given into the pyramidal convolution shuffle attention neural network (PCSANN) for categorization. In general, PCSANN does not show any adaption optimization techniques to determine the optimal parameter to offer precise breast cancer categorization. This research proposes the dung beetle optimization algorithm (DBOA) to optimize the PCSANN classifier that accurately diagnoses breast cancer. The BCD-PCSANN-DBO method is implemented using Python. To classify breast cancer, performance metrics including accuracy, precision, recall, F1 score, error rate, RoC, and computational time are considered. Performance of the BCD-PCSANN-DBO approach attains 29.87\%, 28.95\%, and 27.92\% lower computation time and 13.29\%, 14.35\%, and 20.54\% greater RoC compared with existing methods like breast cancer diagnosis utilizing thermal infrared imaging and machine learning approaches(BCD-CNN), breast cancer classification from thermal images utilizing Grunwald-Letnikov assisted dragonfly algorithm-based deep feature selection (BCD-VGG16) and Breast cancer detection in thermograms using deep selection based on genetic algorithm and Gray Wolf Optimizer (BCD-SqueezeNet), respectively. Research Highlights The input images are engaged from the breast cancer dataset for breast cancer classification. The ADQMF was used in removing noise and increasing the quality of infrared thermal images. The extracted features are given into the PCSANN for categorization. DBOA is proposed to optimize PCSANN classifier that classifies breast cancer precisely. The proposed BCD-PCSANN-DBO method is implemented using Python.",Wiley
"Deverajan, Ganesh Gopal and Muthukumaran, V. and Hsu, Ching-Hsien and Karuppiah, Marimuthu and Chung, Yeh-Ching and Chen, Ying-Huei",Public key encryption with equality test for Industrial Internet of Things system in cloud computing,2022,https://doi.org/10.1002/ett.4202,https://onlinelibrary.wiley.com/doi/abs/10.1002/ett.4202,Journal,Transactions on Emerging Telecommunications Technologies,"Present day world have evolved from traditional environment to smart industries using IoT scheme which in turn forms Industrial Internet of Things (IIoT), which significantly elaborated by providing enhance integration using smart communication through IoT based sensors. IIoT has been providing cost reduction and enhancement in technology by bringing availability, flexibility and data sharing through real time scenario. Despite being unsecure environment of cloud, the privacy of data transfer and information confidentiality is guaranteed. In this context, this work presents a Public Key Encryption with Equality Test based on DLP with double decomposition problems over near-ring. Computation Diffie-Hellman is utilized in algebraic structure which involves DLP with Double Decomposition problem for proposing a Public Key Encryption with Equality Test which provides more security to the scheme. The proposed method is highly secure and it solves the problem of quantum algorithm attacks in IIoT systems. Further, the suggested system is significantly secure and it prevents the chosen-ciphertext attack in type-I rival and it is indistinguishable against the random oracle model for the type-II rival. The recommended scheme is highly secure and the security analysis measures are comparatively stronger than existing techniques. Search time of the proposed scheme is 150 milliseconds for which the number of attributes is 50 and when comparing to the decryption time of the proposed model which is lower when compared to other existing scheme for 50 attributes.",Wiley
"Kumar, Yogesh and Koul, Apeksha and Sisodia, Pushpendra Singh and Shafi, Jana and Verma, Kavita and Gheisari, Mehdi and Davoodi, Mohamad Bagher",Heart Failure Detection Using Quantum-Enhanced Machine Learning and Traditional Machine Learning Techniques for Internet of Artificially Intelligent Medical Things,2021,https://doi.org/10.1155/2021/1616725,https://onlinelibrary.wiley.com/doi/abs/10.1155/2021/1616725,Journal,Wireless Communications and Mobile Computing,"Quantum-enhanced machine learning plays a vital role in healthcare because of its robust application concerning current research scenarios, the growth of novel medical trials, patient information and record management, procurement of chronic disease detection, and many more. Due to this reason, the healthcare industry is applying quantum computing to sustain patient-oriented attention to healthcare patrons. The present work summarized the recent research progress in quantum-enhanced machine learning and its significance in heart failure detection on a dataset of 14 attributes. In this paper, the number of qubits in terms of the features of heart failure data is normalized by using min-max, PCA, and standard scalar, and further, has been optimized using the pipelining technique. The current work verifies that quantum-enhanced machine learning algorithms such as quantum random forest (QRF), quantum K nearest neighbour (QKNN), quantum decision tree (QDT), and quantum Gaussian Na?ve Bayes (QGNB) are better than traditional machine learning algorithms in heart failure detection. The best accuracy rate is (0.89), which the quantum random forest classifier attained. In addition to this, the quantum random forest classifier also incurred the best results in F1 score, recall and, precision by (0.88), (0.93), and (0.89), respectively. The computation time taken by traditional and quantum-enhanced machine learning algorithms has also been compared where the quantum random forest has the least execution time by 150 microseconds. Hence, the work provides a way to quantify the differences between standard and quantum-enhanced machine learning algorithms to select the optimal method for detecting heart failure.",Wiley
"Ren, Ting and Wang, Ruikun and Zhang, Yang and Nie, Shengqiang and Guo, Shaoyun and Zhang, Xianlong",Hollow glass microsphere/polybutadiene composites with low dielectric constant and ultralow dielectric loss in high-frequency,2025,https://doi.org/10.1002/app.56351,https://onlinelibrary.wiley.com/doi/abs/10.1002/app.56351,Journal,Journal of Applied Polymer Science,"High-frequency dielectric materials have been widely and rapidly applied in areas such as automotive radar, Internet of Things, artificial intelligence, and quantum computing. Currently, the challenge in high-frequency dielectric materials lies in reducing the dielectric constant (Dk) and dielectric loss (Df) without sacrificing its mechanical properties. This study addresses this challenge by introducing air, as the most common ¡°low dielectric factor,¡± into the polymer matrix in the form of hollow glass microspheres. Meanwhile, the reactive vinyl groups were also introduced onto the surface of the hollow glass microspheres, enabling an interfacial chemical reaction between the side vinyl groups of polybutadiene and its surface so that the organic¨Cinorganic interface compatibility and interface peel strength are simultaneously improved. Consequently, the minimum Dk of 1.29 and Df of 0.0012 in 3¨C18?GHz are achieved, and the interface peel strength also reaches 0.65?N/mm. Molecular dynamics simulations, analysis of dielectric properties, and interface peel strength reveal the influence of hollow glass microspheres' morphology and chemical structure on their high-frequency dielectric performance and adhesive strength. This paper provides effective strategies for the structural design and preparation of high-frequency, low-dielectric composites, contributing to the further development of next-generation microwave communication devices towards higher frequencies and faster information transmission.",Wiley
"Kundu, Neel Kanth and Babu, Prabhu and Stoica, Petre",Majorisation-minimisation algorithm for optimal state discrimination in quantum communications,2024,https://doi.org/10.1049/qtc2.12107,https://onlinelibrary.wiley.com/doi/abs/10.1049/qtc2.12107,Journal,IET Quantum Communication,"Designing optimal measurement operators for quantum state discrimination (QSD) is an important problem in quantum communications and cryptography applications. Prior works have demonstrated that optimal quantum measurement operators can be obtained by solving a convex semidefinite program (SDP). However, solving the SDP can represent a high computational burden for many real-time quantum communication systems. To address this issue, a majorisation-minimisation (MM)-based algorithm, called Quantum Majorisation-Minimisation (QMM) is proposed for solving the QSD problem. In QMM, the authors reparametrise the original objective, then tightly upper-bound it at any given iterate, and obtain the next iterate as a closed-form solution to the upper-bound minimisation problem. Our numerical simulations demonstrate that the proposed QMM algorithm significantly outperforms the state-of-the-art SDP algorithm in terms of speed, while maintaining comparable performance for solving QSD problems in quantum communication applications.",Wiley
"Li, Desheng",Cooperative Quantum-Behaved Particle Swarm Optimization with Dynamic Varying Search Areas and L¨¦vy Flight Disturbance,2014,https://doi.org/10.1155/2014/370691,https://onlinelibrary.wiley.com/doi/abs/10.1155/2014/370691,Journal,The Scientific World Journal,"This paper proposes a novel variant of cooperative quantum-behaved particle swarm optimization (CQPSO) algorithm with two mechanisms to reduce the search space and avoid the stagnation, called CQPSO-DVSA-LFD. One mechanism is called Dynamic Varying Search Area (DVSA), which takes charge of limiting the ranges of particles¡¯ activity into a reduced area. On the other hand, in order to escape the local optima, L¨¦vy flights are used to generate the stochastic disturbance in the movement of particles. To test the performance of CQPSO-DVSA-LFD, numerical experiments are conducted to compare the proposed algorithm with different variants of PSO. According to the experimental results, the proposed method performs better than other variants of PSO on both benchmark test functions and the combinatorial optimization issue, that is, the job-shop scheduling problem.",Wiley
"Pan, Wen-Tsao and Liu, Yi and Jiang, Huan and Chen, Ya-Ting and Liu, Ting and Qing, Yan and Huang, Guo-Hui and Li, Rong",Model Construction of Enterprise Financial Early Warning Based on Quantum FOA-SVR,2021,https://doi.org/10.1155/2021/5018917,https://onlinelibrary.wiley.com/doi/abs/10.1155/2021/5018917,Journal,Scientific Programming,"The sudden outbreak of COVID-19 has a great impact on human life security and global economic development. To deal with the rampant pandemic, many countries have taken strict control measures, including restricting gathering in public places and stopping the production of enterprises; as a result, many enterprises suffered great challenges in survival and development during the pandemic. In order to help enterprises monitor their own financial situation and realize their healthy development under the pandemic, this paper constructs an Enterprise Financial Early Warning Model, in which Quantum Rotation Gate is used to optimize four algorithms, namely, Fruit Fly Optimization Algorithm (QFOA), Bee Colony Optimization Algorithm (QABC), Particle Swarm Optimization (QPSO), and Ant Colony Optimization (QACO). The results show that the ability of the prediction model can be greatly improved by using the Quantum Rotation Gate to optimize these four algorithms.",Wiley
"Kaveh, Ali and Dadras Eslamlou, Armin",An efficient two-stage method for optimal sensor placement using graph-theoretical partitioning and evolutionary algorithms,2019,https://doi.org/10.1002/stc.2325,https://onlinelibrary.wiley.com/doi/abs/10.1002/stc.2325,Journal,Structural Control and Health Monitoring,"Summary This paper presents a two-stage optimal sensor placement method for modal identification of structures. At the first stage, using a graph theoretical technique, the structure is partitioned into equal substructures. At the second stage, a preset number of triaxial sensors are proportionately allocated to the substructures. The location of sensors is determined using an evolutionary optimization algorithm, which optimizes the triaxial modal assurance criterion of the structure. The first stage leads to the even distribution of the sensors. This stage not only improves the mode shape visualization as the secondary criterion but also accelerates the optimization process by space reduction. Here, various graph-theoretical methods including k-means, k-means++, and spectral partitioning are examined as the partitioning techniques. In addition, a dynamic version for quantum-inspired evolutionary optimization algorithm (DQEA) is proposed and applied to find the placement of triaxial sensors, along with the standard version of quantum-inspired evolutionary algorithm and genetic algorithm. In order to examine the efficiency of the methods, the bridge model of the University of Central Florida, USA, is considered as the benchmark structure. The results show that the proposed method efficiently satisfies both criteria. Moreover, the introduced optimization algorithm (DQEA) outperforms other algorithms.",Wiley
"Gu, Juntao and Su, Zhongbin and Gao, Rui and Wang, Yue and Meng, Ying and Kong, Qingming",Improving QGA-ELM Inversion Model of Rice Leaf Area Index Based on UAV Remote Sensing Image,2022,https://doi.org/10.1155/2022/9658966,https://onlinelibrary.wiley.com/doi/abs/10.1155/2022/9658966,Journal,Mobile Information Systems,"The leaf area index (LAI) is an important physiological parameter that characterizes the growth of crops. Traditional measurement could not meet the demands of large-scale accurate monitoring. QGA-ELM and LS-SVM algorithm combined with UAV remote sensing images was used to achieve the goal of building large-scale fast inversion modeling of LAI in this paper. Linear and nonlinear models were constructed for comparing the correlation between six spectral indices and LAI by categorizing the nitrogen level. The LS-SVM model was constructed to replace traditional linear model, the determination coefficient of correction set and prediction set (R2C and R2P) were 0.6496 and 0.6814; and the root mean square error of correction set and prediction set (RMSEC and RMSEP) were 0.5702 and 0.6842, respectively. The results showed that the inversion of edge objects in noncrop areas was not so stable. In order to address the problem, an improvement based on the extreme learning machine (ELM) and quantum genetic algorithm (QGA) with probabilistic evolution were used to combine with LS-SVM for overcoming the problem which the hidden layer connection weight and threshold randomly generated and solve the problems of slow regression of nonlinear data and insufficient model generalization ability. Compared with traditional linear and nonlinear regression, the QGA-ELM combined with LS-SVM showed the following: (1) improving the optimization ability greatly and avoid the prematurity of GA (genetic algorithm) effectively. The generalization performance has also been enhanced. (2) R2P of prediction set was 0.6686, and RMSEP was 0.8952 which could reflect the growth and distribution trend of rice in the regional scale. (3) Adapting different fertilization gradients (deficiency to excess) could provide basis for LAI inversion in different varieties and accumulated temperature zone of rice. The results above showed that QGA-ELM combined with LS-SVM could improve the stability of the model greatly and provide reference significance for rice growth inversion.",Wiley
"Curtis, Kevin and King, Corban and Odoh, Samuel O.",Novel Triangulenes: Computational Investigations of Energy Thresholds for Photocatalytic Water Splitting,2023,https://doi.org/10.1002/cphc.202300556,https://onlinelibrary.wiley.com/doi/abs/10.1002/cphc.202300556,Journal,ChemPhysChem,"Organic materials with Inverted Singlet-Triplet (INVEST) gaps are interesting for their potential use in photocatalytic small molecule transformations such as the entirely solar-driven water splitting reaction. However, only a few INVEST emitters are thermodynamically able to split water requiring a first singlet excited dark state, S1, above 1.27 or 1.76?eV, and absorption near solar the maximum, 2.57?eV. These requirements and the INVEST character are key for achieving a long-lived photocatalyst for water splitting. The only known INVEST emitters that conform to these criteria are large triangular boron carbon nitrides with unknown synthesis pathways. Using ADC(2), a quantum-mechanical method, we describe three triangulenes. 3?a is a cyano azacyclopenta[cd]phenalene derivative while 3?b and 3?c are cycl[3.3.3]azine derivatives. 3?b has a previously undescribed disulfide bridge. Overall, 3?a fulfills requirements for photocatalytic four-electron reduction of water while the S1 states of 3?b and 3?c are likely slightly low for the two-electron reduction process. By analyzing impacts of ligands, we find that there are guidelines describing how S1-S5 energies and oscillator strengths, T1 energies, and ¦¤ES1T1 gaps are affected, requiring deep-learning algorithms for which studies will be presented by us in due time. The impact of ground-state geometries, solvation effects, as well as reduced-cost ADC(2) algorithms on our findings are also discussed.",Wiley
"Rahmani, Arsalan and Hosseini, Meysam and Sahami, Amir","A Competitive Bilevel Programming Model for Green, CLSCs in Light of Government Incentives",2024,https://doi.org/10.1155/2024/4866890,https://onlinelibrary.wiley.com/doi/abs/10.1155/2024/4866890,Journal,Journal of Mathematics,"The growth of world population has fueled environmental, legal, and social concerns, making governments and companies attempt to mitigate the environmental and social implications stemming from supply chain operations. The state-run Environmental Protection Agency has initially offered financial incentives (subsidies) meant to encourage supply chain managers to use cleaner technologies in order to minimize pollution. In today¡¯s competitive markets, using green technologies remains vital. In the present project, we have examined a class of closed-loop supply chain competitive facility location-routing problems. According to the framework of the competition, one of the players, called the Leader, opens its facilities first. The second player, called the Follower, makes its decision when Leader¡¯s location is known. Afterwards, each customer chooses an open facility based on some preference huff rules before returning the benefits to one of the two companies. The follower, under the influence of the leader¡¯s decisions, performs the best reaction in order to obtain the maximum capture of the market. So, a bilevel mixed-integer linear programming model is formulated. The objective function at both levels includes market capture profit, fixed and operating costs, and financial incentives. A metaheuristic quantum binary particle swarm optimization (PSO) is developed via Benders decomposition algorithm to solve the proposed model. To evaluate the convergence rate and solution quality, the method is applied to some random test instances generated in the literature. The computational results indicate that the proposed method is capable of efficiently solving the model.",Wiley
"Wang, Peng and Cheng, Kun and Huang, Yan and Li, Bo and Ye, Xinggui and Chen, Xiuhong",Multiscale Quantum Harmonic Oscillator Algorithm for Multimodal Optimization,2018,https://doi.org/10.1155/2018/8430175,https://onlinelibrary.wiley.com/doi/abs/10.1155/2018/8430175,Journal,Computational Intelligence and Neuroscience,"This paper presents a variant of multiscale quantum harmonic oscillator algorithm for multimodal optimization named MQHOA-MMO. MQHOA-MMO has only two main iterative processes: quantum harmonic oscillator process and multiscale process. In the two iterations, MQHOA-MMO only does one thing: sampling according to the wave function at different scales. A set of benchmark test functions including some challenging functions are used to test the performance of MQHOA-MMO. Experimental results demonstrate good performance of MQHOA-MMO in solving multimodal function optimization problems. For the 12 test functions, all of the global peaks can be found without being trapped in a local optimum, and MQHOA-MMO converges within 10 iterations.",Wiley
"Lv, Yong and Luo, Jie and Yi, Cancan",Enhanced Orthogonal Matching Pursuit Algorithm and Its Application in Mechanical Equipment Fault Diagnosis,2017,https://doi.org/10.1155/2017/4896056,https://onlinelibrary.wiley.com/doi/abs/10.1155/2017/4896056,Journal,Shock and Vibration,"The vibration signal measured from the mechanical equipment is associated with the operation of key structure, such as the rolling bearing and gear. The effective signal processing method for early weak fault has attracted much attention and it is of vital importance in mechanical fault monitoring and diagnosis. The recently proposed atomic sparse decomposition algorithm is performed around overcomplete dictionary instead of the traditional signal analysis method using orthogonal basis operator. This algorithm has been proved to be effective in extracting useful components from complex signal by reducing influence of background noises. In this paper, an improved linear frequency-modulated (Ilfm) function as an atom is employed in the proposed enhanced orthogonal matching pursuit (EOMP) algorithm. Then, quantum genetic algorithm (QGA) with the OMP algorithm is integrated since the QGA can quickly obtain the global optimal solution of multiple parameters for rapidly and accurately extracting fault characteristic information from the vibration signal. The proposed method in this paper is superior to the traditional OMP algorithm in terms of accuracy and reducing the computation time through analyzing the simulation data and real world data. The experimental results based on the application of gear and bearing fault diagnosis indicate that it is more effective than traditional method in extracting fault characteristic information.",Wiley
"Hellstern, Gerhard and Dehn, Vanessa and Zaefferer, Martin",Quantum computer based feature selection in machine learning,2024,https://doi.org/10.1049/qtc2.12086,https://onlinelibrary.wiley.com/doi/abs/10.1049/qtc2.12086,Journal,IET Quantum Communication,"The problem of selecting an appropriate number of features in supervised learning problems is investigated. Starting with common methods in machine learning, the feature selection task is treated as a quadratic unconstrained optimisation problem (QUBO), which can be tackled with classical numerical methods as well as within a quantum computing framework. The different results in small problem instances are compared. According to the results of the authors¡¯ study, whether the QUBO method outperforms other feature selection methods depends on the data set. In an extension to a larger data set with 27 features, the authors compare the convergence behaviour of the QUBO methods via quantum computing with classical stochastic optimisation methods. Due to persisting error rates, the classical stochastic optimisation methods are still superior.",Wiley
"Bopp, Julian M. and Plock, Matthias and Turan, Tim and Pieplow, Gregor and Burger, Sven and Schr?der, Tim",¡®Sawfish¡¯ Photonic Crystal Cavity for Near-Unity Emitter-to-Fiber Interfacing in Quantum Network Applications,2024,https://doi.org/10.1002/adom.202301286,https://onlinelibrary.wiley.com/doi/abs/10.1002/adom.202301286,Journal,Advanced Optical Materials,"Photon loss is one of the key challenges to overcome in complex photonic quantum applications. Photon collection efficiencies directly impact the amount of resources required for measurement-based quantum computation and communication networks. Promising resources include solid-state quantum light sources. However, efficiently coupling light from a single quantum emitter to a guided mode remains demanding. In this work, photon losses are eliminated by maximizing coupling efficiencies in an emitter-to-fiber interface. A waveguide-integrated ¡®Sawfish¡¯ photonic crystal cavity is developed and finite element (FEM) simulations are employed to demonstrate that such an emitter-to-fiber interface transfers, with 97.4?\% efficiency, the zero-phonon line (ZPL) emission of a negatively-charged tin vacancy center in diamond (SnV?) adiabatically to a single-mode fiber. A surrogate model trained by machine learning provides quantitative estimates of sensitivities to fabrication tolerances. The corrugation-based Sawfish design proves robust under state-of-the-art nanofabrication parameters, maintaining an emitter-to-fiber coupling efficiency of 88.6?\%. Applying the Sawfish cavity to a recent one-way quantum repeater protocol substantiates its potential in reducing resource requirements in quantum communication.",Wiley
"Huang, Wenkang and Geng, Lv and Deng, Rong and Lu, Shaoyong and Ma, Guangli and Yu, Jianxiu and Zhang, Jian and Liu, Wei and Hou, Tingjun and Lu, Xuefeng",Prediction of Human Clearance Based on Animal Data and Molecular Properties,2015,https://doi.org/10.1111/cbdd.12567,https://onlinelibrary.wiley.com/doi/abs/10.1111/cbdd.12567,Journal,Chemical Biology \& Drug Design,"Human clearance is often predicted prior to clinical study from in vivo preclinical data by virtue of interspecies allometric scaling methods. The aims of this study were to determine the important molecular descriptors for the extrapolation of animal data to human clearance and further to build a model to predict human clearance by combination of animal data and the selected molecular descriptors. These important molecular descriptors selected by genetic algorithm (GA) were from five classes: quantum mechanical, shadow indices, E-state keys, molecular properties, and molecular property counts. Although the data set contained many outliers determined by the conventional Mahmood method, the variation of most outliers was reduced significantly by our final support vector machine (SVM) model. The values of cross-validated correlation coefficient and root-mean-squared error (RMSE) for leave-one-out cross-validation (LOOCV) of the final SVM model were 0.783 and 0.305, respectively. Meanwhile, the reliability and consistency of the final model were also validated by an external test set. In conclusion, the SVM model based on the molecular descriptors selected by GA and animal data achieved better prediction performance than the Mahmood method. This approach can be applied as an improved interspecies allometric scaling method in drug research and development.",Wiley
"Zeng, Han and Meng, Fanxu and Luan, Tian and Yu, Xutao and Zhang, Zaichen",Improved Quantum Approximate Optimization Algorithm for Low-Density Parity-Check Channel Decoding,2024,https://doi.org/10.1002/qute.202300262,https://onlinelibrary.wiley.com/doi/abs/10.1002/qute.202300262,Journal,Advanced Quantum Technologies,"Quantum computing shows promise for 6G networks due to its parallel computing capabilities. In the context of the Noisy Intermediate-Scale Quantum era, the introduction of hybrid quantum-classical algorithms like Quantum Approximate Optimization Algorithm (QAOA) offer powerful solutions to many combinatorial optimization problems in 6G. This paper focuses on Low-Density Parity-Check (LDPC) channel decoding and proposes an improved QAOA algorithm assisted by the learning-to-learn strategy. We also investigate the parameter concentration phenomenon in QAOA-based LDPC decoding to assess the rationality. To evaluate effectiveness, a comprehensive numerical expression for the energy expectation of single-layer QAOA and propose indicators for transfer performance evaluation is provided. Based on simulation results, the similarity in parameter distribution across specific LDPC configurations is investigated. This similarity facilitates the transfer of training outcomes from smaller to larger-scale problems for optimization initialization, thereby avoiding the need for retraining. This approach offers insights and potential solutions for rapid, large-scale channel decoding in 6G networks, despite the current limitations of quantum hardware.",Wiley
"Zhu, Yantao and Niu, Xinqiang and Wang, Jimin and Gu, Chongshi and Zhao, Erfeng and Huang, Lixian",Inverse Analysis of the Partitioning Deformation Modulusof High-Arch Dams Based on Quantum Genetic Algorithm,2020,https://doi.org/10.1155/2020/9842140,https://onlinelibrary.wiley.com/doi/abs/10.1155/2020/9842140,Journal,Advances in Civil Engineering,"The physical and mechanical parameters of hydraulic structures in complicated operating conditions often change over time. Updating these parameters in a timely manner is important to comprehend the operating behaviors and monitor the safety of hydraulic structures. Conventional inverse analysis methods can only generate inversions on the comprehensive deformation modulus of concrete dam structures, which contradict practical conditions. Based on the researches on conventional reversion methods of the deformation modulus of the dam body, foundation, and reservoir basin, the objective fitness function is established in this paper according to engineering-measured data and finite element simulation results. The quantum genetic algorithm has high global search efficiency and population diversity. A mechanical parameter inversion of high-arch dams is built from the intelligent optimization of an established algorithm by applying the quantum genetic algorithm. The proposed algorithm is tested to be feasible and valid for practical engineering projects and therefore shows scientific and practical application values.",Wiley
"San Mart¨ªn, Gabriel and L¨®pez Droguett, Enrique",Quantum-Based Combinatorial Optimization for Optimal Sensor Placement in Civil Structures,2024,https://doi.org/10.1155/2024/6681342,https://onlinelibrary.wiley.com/doi/abs/10.1155/2024/6681342,Journal,Structural Control and Health Monitoring,"Over the last decade, concepts such as industry 4.0 and the Internet of Things (IoT) have contributed to the increase in the availability and affordability of sensing technology. In this context, structural health monitoring (SHM) arises as an especially interesting field to integrate and develop these new sensing capabilities, given the criticality of structural application for human life and the elevated costs of manual monitoring. Due to the scale of structural systems, one of the main challenges when designing a modern monitoring system is the optimal sensor placement (OSP) problem. The OSP problem is combinatorial in nature, making its exact solution infeasible in most practical cases, usually requiring the use of metaheuristic optimization techniques. While approaches such as genetic algorithms (GAs) have been able to produce significant results in many practical case studies, their ability to scale up to more complex structures is still an area of open research. This study proposes a novel quantum-based combinatorial optimization approach to solve the OSP problem approximately, within the context of SHM. For this purpose, a quadratic unconstrained binary optimization (QUBO) model formulation is developed, taking as a starting point of the modal strain energy (MSE) of the structure. The framework is tested using numerical simulations of Warren truss bridges of varying scales. The results obtained using the proposed framework are compared against exhaustive search approaches to verify their performance. More importantly, a detailed discussion of the current limitations of the technology and the future paths of research in the area is presented to the reader.",Wiley
"Gianani, Ilaria and Mastroserio, Ivana and Buffoni, Lorenzo and Bruno, Natalia and Donati, Ludovica and Cimini, Valeria and Barbieri, Marco and Cataliotti, Francesco S. and Caruso, Filippo",Experimental Quantum Embedding for Machine Learning,2022,https://doi.org/10.1002/qute.202100140,https://onlinelibrary.wiley.com/doi/abs/10.1002/qute.202100140,Journal,Advanced Quantum Technologies,"The classification of big data usually requires a mapping onto new data clusters which can then be processed by machine learning algorithms by means of more efficient and feasible linear separators. Recently, Lloyd et al. have advanced the proposal to embed classical data into quantum ones: these live in the more complex Hilbert space where they can get split into linearly separable clusters. Here, these ideas are implemented by engineering two different experimental platforms, based on quantum optics and ultra-cold atoms, respectively, where we adapt and numerically optimize the quantum embedding protocol by deep learning methods, and test it for some trial classical data. A similar analysis is also performed on the Rigetti superconducting quantum computer. Therefore, it is found that the quantum embedding approach successfully works also at the experimental level and, in particular, we show how different platforms could work in a complementary fashion to achieve this task. These studies might pave the way for future investigations on quantum machine learning techniques especially based on hybrid quantum technologies.",Wiley
"Dawson, William and Degomme, Augustin and Stella, Martina and Nakajima, Takahito and Ratcliff, Laura E. and Genovese, Luigi","Density functional theory calculations of large systems: Interplay between fragments, observables, and computational complexity",2022,https://doi.org/10.1002/wcms.1574,https://onlinelibrary.wiley.com/doi/abs/10.1002/wcms.1574,Journal,WIREs Computational Molecular Science,"In the past decade, developments of computational technology around density functional theory (DFT) calculations have considerably increased the system sizes which can be practically simulated. The advent of robust high performance computing algorithms which scale linearly with system size has unlocked numerous opportunities for researchers. This fact enables computational physicists and chemists to investigate systems of sizes which are comparable to systems routinely considered by experimentalists, leading to collaborations with a wide range of techniques and communities. This has important consequences for the investigation paradigms which should be applied to reduce the intrinsic complexity of quantum mechanical calculations of many thousand atoms. It becomes important to consider portions of the full system in the analysis, which have to be identified, analyzed, and employed as building-blocks from which decomposed physico-chemical observables can be derived. After introducing the state-of-the-art in the large scale DFT community, we will illustrate the emerging research practices in this rapidly expanding field, and the knowledge gaps which need to be bridged to face the stimulating challenge of the simulation of increasingly realistic systems. This article is categorized under: Electronic Structure Theory > Density Functional Theory Software > Simulation Methods Structure and Mechanism > Computational Materials Science",Wiley
"Peelam, Mritunjay Shall and Rout, Anjaney Asreet and Chamola, Vinay",Quantum computing applications for Internet of Things,2024,https://doi.org/10.1049/qtc2.12079,https://onlinelibrary.wiley.com/doi/abs/10.1049/qtc2.12079,Journal,IET Quantum Communication,"The rapidly developing discipline of quantum computing (QC) employs ideas from quantum physics to improve the performance of traditional computers and other devices. Because of the dramatically improved speed at which it processes data, it can be applied to various issues. QC has many potential applications, but three of the most exciting applications are unstructured search, quantum simulation, and network optimisation. Several existing technologies, such as machine learning, may benefit from its increased speed and precision. In this study, the authors will explore how the principles of QC might be applied to the Internet of Things (IoT) to improve its accuracy, speed, and security. Several approaches exist for achieving this goal, such as network optimisation in IoT using QC, faster computation at IoT endpoints, securing IoT using QC, a quantum sensor for IoT, quantum digital marketing, quantum-secured smart lock etc.",Wiley
"Pichi, Federico and Ballarin, Francesco and Rozza, Gianluigi and Hesthaven, Jan S.",Artificial neural network for bifurcating phenomena modelled by nonlinear parametrized PDEs,2021,https://doi.org/10.1002/pamm.202000350,https://onlinelibrary.wiley.com/doi/abs/10.1002/pamm.202000350,Journal,PAMM,"The aim of this work [1] is to show the applicability of the Reduced Basis (RB) model reduction and Artificial Neural Network (ANN) dealing with parametrized Partial Differential Equations (PDEs) in nonlinear systems undergoing bifurcations. Bifurcation analysis, i.e., following the different bifurcating branches due to the non-uniqueness of the solution, as well as determining the bifurcation points themselves, are complex computational tasks. Reduced Order Models (ROM) and Machine Learning (ML) techniques can potentially reduce the computational burden by several orders of magnitude. Models describing bifurcating phenomena arising in several fields with interesting applications, from continuum to quantum mechanics passing through fluid dynamics [2¨C4]. Following the approach in [5], we analyzed different bifurcating test cases where both physical and geometrical parameters were considered. In particular, we studied the Navier-Stokes equations for a viscous, steady and incompressible flow in a planar straight channel with a narrow inlet. We reconstructed the branching solutions and explored a new empirical strategy in order to employ the RB and ANN for an efficient detection of the critical points. All the simulations were performed within the open source software FEniCS and RBniCS for the ROM, while we chose PyTorch to construct the neural network.",Wiley
"Piccardo, Matteo and Soncini, Alessandro",A full-pivoting algorithm for the Cholesky decomposition of two-electron repulsion and spin-orbit coupling integrals,2017,https://doi.org/10.1002/jcc.25062,https://onlinelibrary.wiley.com/doi/abs/10.1002/jcc.25062,Journal,Journal of Computational Chemistry,"A significant reduction in the computational effort for the evaluation of the electronic repulsion integrals (ERI) in ab initio quantum chemistry calculations is obtained by using Cholesky decomposition (CD), a numerical procedure that can remove the zero or small eigenvalues of the ERI positive (semi)definite matrix, while avoiding the calculation of the entire matrix. Conversely, due to its antisymmetric character, CD cannot be directly applied to the matrix representation of the spatial part of the two-electron spin-orbit coupling (2e-SOC) integrals. Here, we present a computational strategy to achieve a Cholesky representation of the spatial part of the 2e-SOC integrals, and propose a new efficient CD algorithm for both ERI and 2e-SOC integrals. The proposed algorithm differs from previous CD implementations by the extensive use of a full-pivoting design, which allows a univocal definition of the Cholesky basis, once the CD ¦Ä threshold is made explicit. We show that is the upper limit for the errors affecting the reconstructed 2e-SOC integrals. The proposed strategy was implemented in the ab initio program Computational Emulator of Rare Earth Systems (CERES), and tested for computational performance on both the ERI and 2e-SOC integrals evaluation. ? 2017 Wiley Periodicals, Inc.",Wiley
"Liu, Hongdan and Sun, Rong and Liu, Qi",The tactics of ship collision avoidance based on Quantum-behaved Wolf Pack Algorithm,2020,https://doi.org/10.1002/cpe.5196,https://onlinelibrary.wiley.com/doi/abs/10.1002/cpe.5196,Journal,Concurrency and Computation: Practice and Experience,"Summary To ensure the navigational safety of ships in the sea and reduce human errors, a set of navigational information systems with decision support function is developed. Fast and stable collision avoidance actions are also adopted according to the ship risk level and encounter situation. Therefore, the ship automation collision avoidance tactics based on Quantum-behaved Wolf Pack Algorithm (QWPA) is proposed complied to COLREG in this paper, and then feasibility and effectiveness of which have been positively verified in laboratory conditions based on the three-degree-of-freedom ship mathematical model; compared with existing collision avoidance scheme, the quality and generating speed of the collision avoidance strategy are enhanced greatly under different ship encounter situation.",Wiley
"Miller, Evan D. and Jones, Matthew L. and Henry, Mike M. and Stanfill, Bryan and Jankowski, Eric",Machine learning predictions of electronic couplings for charge transport calculations of P3HT,2019,https://doi.org/10.1002/aic.16760,https://onlinelibrary.wiley.com/doi/abs/10.1002/aic.16760,Journal,AIChE Journal,"The purpose of this work is to lower the computational cost of predicting charge mobilities in organic semiconductors, which will benefit the screening of candidates for inexpensive solar power generation. We characterize efforts to minimize the number of expensive quantum chemical calculations we perform by training machines to predict electronic couplings between monomers of poly-(3-hexylthiophene). We test five machine learning techniques and identify random forests as the most accurate, information-dense, and easy-to-implement approach for this problem, achieving mean-absolute-error of 0.02 [¡Á 1.6?¡Á?10?19 J], R2 = 0.986, predicting electronic couplings 390 times faster than quantum chemical calculations, and informing zero-field hole mobilities within 5\% of prior work. We discuss strategies for identifying small effective training sets. In sum, we demonstrate an example problem where machine learning techniques provide an effective reduction in computational costs while helping to understand underlying structure¨Cproperty relationships in a materials system with broad applicability.",Wiley
"Shekhawat, Hema and Gupta, Daya Sagar",A survey on lattice-based security and authentication schemes for smart-grid networks in the post-quantum era,2024,https://doi.org/10.1002/cpe.8080,https://onlinelibrary.wiley.com/doi/abs/10.1002/cpe.8080,Journal,Concurrency and Computation: Practice and Experience,"Summary The present scenario witnesses ¡°the second quantum revolution,¡± which has enabled the development of revolutionary novel quantum tools. Quantum computing endeavors to establish higher computing standards that can potentially solve complex structures. Post-quantum cryptography (PQC) has emerged as one of the new domains of cryptography, which is resilient to quantum attacks owing to the revolution in quantum computing. To ensure quantum security, the lattice-based cryptosystem (LB-cryptosystem) is one of the promising tools of PQC to address quantum-based threats. The traditional security algorithms, such as RSA and Diffie¨CHellman (DH), are strong enough to resist present security threats. However, it has been predicted that quantum technologies have the capability to break the security of most traditional algorithms whose security is based on prime factorization and DH-type hard problems. Therefore, research is currently focused on addressing the security and privacy threats by using LB-cryptosystems to secure various applications, organizations' data, and information infrastructure in the quantum era. The purpose of this article is to investigate recent advances in LB-cryptosystems that may allow the design of secure models for smart-grid networks (SGNs) against existing and future quantum attacks. SGNs have been explored as the bi-directional assimilation of communication in terms of electricity generation, transmission, allocation, and utilization. This survey provides a comprehensive overview of LB-cryptosystems, as well as their potential applications in securing SGNs. Lastly, the article summarizes the various PQC primitives, NIST selected algorithms, open-source tools along with their packages, and various PQC industrial initiatives, and also compares traditional cryptographic schemes with other PQC.",Wiley
"Hasija, Taniya and Ramkumar, K. R. and Singh, Bhupendra",Development of Quantum Safe Polynomial-Based Cryptography in Classical and Quantum Framework,,https://doi.org/10.1002/itl2.601,https://onlinelibrary.wiley.com/doi/abs/10.1002/itl2.601,Journal,Internet Technology Letters,,Wiley
"Wang, Yong and Sun, Dongye",Powertrain Matching and Optimization of Dual-Motor Hybrid Driving System for Electric Vehicle Based on Quantum Genetic Intelligent Algorithm,2014,https://doi.org/10.1155/2014/956521,https://onlinelibrary.wiley.com/doi/abs/10.1155/2014/956521,Journal,Discrete Dynamics in Nature and Society,"In order to increase the driving range and improve the overall performance of all-electric vehicles, a new dual-motor hybrid driving system with two power sources was proposed. This system achieved torque-speed coupling between the two power sources and greatly improved the high performance working range of the motors; at the same time, continuously variable transmission (CVT) was achieved to efficiently increase the driving range. The power system parameters were determined using the ¡°global optimization method¡±; thus, the vehicle¡¯s dynamics and economy were used as the optimization indexes. Based on preliminary matches, quantum genetic algorithm was introduced to optimize the matching in the dual-motor hybrid power system. Backward simulation was performed on the combined simulation platform of Matlab/Simulink and AVL-Cruise to optimize, simulate, and verify the system parameters of the transmission system. Results showed that quantum genetic algorithms exhibited good global optimization capability and convergence in dealing with multiobjective and multiparameter optimization. The dual-motor hybrid-driving system for electric cars satisfied the dynamic performance and economy requirements of design, efficiently increasing the driving range of the car, having high performance, and reducing energy consumption of 15.6\% compared with the conventional electric vehicle with single-speed reducers.",Wiley
"Duster, Adam W. and Wang, Chun-Hung and Garza, Christina M. and Miller, Danielle E. and Lin, Hai","Adaptive quantum/molecular mechanics: what have we learned, where are we, and where do we go from here?",2017,https://doi.org/10.1002/wcms.1310,https://onlinelibrary.wiley.com/doi/abs/10.1002/wcms.1310,Journal,WIREs Computational Molecular Science,"Adaptive quantum-mechanics/molecular-mechanics (QM/MM) methods feature on-the-fly reclassification of atoms as QM or MM during a molecular dynamics (MD) simulation, allowing the location and contents of the QM subsystem to be dynamically updated as needed. Such flexibility is a distinct advantage over conventional QM/MM, where a ¡®static¡¯ boundary is retained between the QM and MM subsystems. The ¡®dynamic¡¯ boundary in adaptive QM/MM allows a finite-size QM to sustain simulations with an arbitrary length of time. To ensure smooth transitions between QM and MM, the energy or forces are interpolated. Special treatments are applied so that artifacts are eliminated or minimized. Recent developments have shed light on the relationship between the adaptive algorithms that describe Hamiltonian and non-Hamiltonian systems. Originally developed to model an ion solvated in bulk solvent, adaptive QM/MM has been enhanced in many aspects, including the treatment of molecular fragments in macromolecules, monitoring molecules entering/leaving binding sites, and tracking proton transfer via the Grotthuss mechanism. Because the size of the QM region can be set as small as possible in adaptive QM/MM, the computational costs can be kept low. Small QM subsystems also facilitate the utilization of high-level QM theory and long simulation time, which can potentially lead to new insights. WIREs Comput Mol Sci 2017, 7:e1310. doi: 10.1002/wcms.1310 This article is categorized under: Electronic Structure Theory > Combined QM/MM Methods Molecular and Statistical Mechanics > Molecular Dynamics and Monte-Carlo Methods Software > Molecular Modeling",Wiley
"Shieh, Chun-Chien and Gonzalez, Yesenia and Li, Bin and Jia, Xun and Rit, Simon and Mory, Cyril and Riblett, Matthew and Hugo, Geoffrey and Zhang, Yawei and Jiang, Zhuoran and Liu, Xiaoning and Ren, Lei and Keall, Paul",SPARE: Sparse-view reconstruction challenge for 4D cone-beam CT from a 1-min scan,2019,https://doi.org/10.1002/mp.13687,https://onlinelibrary.wiley.com/doi/abs/10.1002/mp.13687,Journal,Medical Physics,"Purpose Currently, four-dimensional (4D) cone-beam computed tomography (CBCT) requires a 3¨C4 min full-fan scan to ensure usable image quality. Recent advancements in sparse-view 4D-CBCT reconstruction have opened the possibility to reduce scan time and dose. The aim of this study is to provide a common framework for systematically evaluating algorithms for 4D-CBCT reconstruction from a 1-min scan. Using this framework, the AAPM-sponsored SPARE Challenge was conducted in 2018 to identify and compare state-of-the-art algorithms. Methods A clinically realistic CBCT dataset was simulated using patient CT volumes from the 4D-Lung database. The selected patients had multiple 4D-CT sessions, where the first 4D-CT was used as the prior CT, and the rest were used as the ground truth volumes for simulating CBCT projections. A GPU-based Monte Carlo tool was used to simulate the primary, scatter, and quantum noise signals. A total of 32 CBCT scans of nine patients were generated. Additional qualitative analysis was performed on a clinical Varian and clinical Elekta dataset to validate the simulation study. Participants were blinded from the ground truth, and were given 3 months to apply their reconstruction algorithms to the projection data. The submitted reconstructions were analyzed in terms of root-mean-squared-error (RMSE) and structural similarity index (SSIM) with the ground truth within four different region-of-interests (ROI) ¡ª patient body, lungs, planning target volume (PTV), and bony anatomy. Geometric accuracy was quantified as the alignment error of the PTV. Results Twenty teams participated in the challenge, with five teams completing the challenge. Techniques involved in the five methods included iterative optimization, motion-compensation, and deformation of the prior 4D-CT. All five methods rendered significant reduction in noise and streaking artifacts when compared to the conventional Feldkamp¨CDavis¨CKress (FDK) algorithm. The RMS of the three-dimensional (3D) target registration error of the five methods ranged from 1.79 to 3.00 mm. Qualitative observations from the Varian and Elekta datasets mostly concur with those from the simulation dataset. Each of the methods was found to have its own strengths and weaknesses. Overall, the MA-ROOSTER method, which utilizes a 4D-CT motion model for temporal regularization, had the best and most consistent image quality and accuracy. Conclusion The SPARE Challenge represents the first framework for systematically evaluating state-of-the-art algorithms for 4D-CBCT reconstruction from a 1-min scan. Results suggest the potential for reducing scan time and dose for 4D-CBCT. The challenge dataset and analysis framework are publicly available for benchmarking future reconstruction algorithms.",Wiley
"Lederer, Jonas and Kaiser, Waldemar and Mattoni, Alessandro and Gagliardi, Alessio",Machine Learning¨CBased Charge Transport Computation for Pentacene,2019,https://doi.org/10.1002/adts.201800136,https://onlinelibrary.wiley.com/doi/abs/10.1002/adts.201800136,Journal,Advanced Theory and Simulations,"Insight into the relation between morphology and transport properties of organic semiconductors can be gained using multiscale simulations. Since computing electronic properties, such as the intermolecular transfer integral, using quantum chemical (QC) methods requires a high computational cost, existing models assume several approximations. A machine learning (ML)¨Cbased multiscale approach is presented that allows to simulate charge transport in organic semiconductors considering the static disorder within disordered crystals. By mapping fingerprints of dimers to their respective transfer integral, a kernel ridge regression ML algorithm for the prediction of charge transfer integrals is trained and evaluated. Since QC calculations of the electronic structure must be performed only once, the use of ML reduces the computation time radically, while maintaining the prediction error small. Transfer integrals predicted by ML are utilized for the computation of charge carrier mobilities using off-lattice kinetic Monte Carlo (kMC) simulations. Benefiting from the rapid performance of ML, microscopic processes can be described accurately without the need for phenomenological approximations. The multiscale system is tested with the well-known molecular semiconductor pentacene. The presented methodology allows reproducing the experimentally observed anisotropy of the mobility and enables a fast estimation of the impact of disorder.",Wiley
"Mahdi, Fahad Parvez and Vasant, Pandian and Abdullah-Al-Wadud, Mohammad and Watada, Junzo and Kallimani, Vish",A quantum-inspired particle swarm optimization approach for environmental/economic power dispatch problem using cubic criterion function,2018,https://doi.org/10.1002/etep.2497,https://onlinelibrary.wiley.com/doi/abs/10.1002/etep.2497,Journal,International Transactions on Electrical Energy Systems,"Summary In electrical power dispatch problem, economic dispatch (ED) and environmental dispatch problems play a crucial part. Economic dispatch problem refers to the minimization of generation cost, where environmental dispatch problem refers to the minimization of emission of pollutants like CO2, SO2, and NOx from the power generation system. A quantum-inspired particle swarm optimization (QPSO) technique is presented in this paper to solve many-objective environmental economic dispatch (EED) problems. Emissions of CO2, SO2, and NOx are considered 3 different objectives, thus making it a 4-objective problem considering ED. Many-objective EED problems are defined by using a cubic criterion function, and a max/max price penalty factor is considered to convert all the objectives into a single objective to compare the final results with other well-known methods found in the literature like Lagrangian relaxation, particle swarm optimization, simulated annealing, and quantum-behaved bat algorithm. Quantum-inspired particle swarm optimization is implemented on a 6-unit system to solve many-objective EED problems, and at the same time, to show the effectiveness of QPSO in large systems, it is also implemented in a 26-unit power generation system for ED problem. The obtained results demonstrate and verify the effectiveness and robustness of QPSO to solve many-objective EED problems. This also shows that QPSO can effectively be implemented in such power dispatch problems.",Wiley
"Esseissah, Mohamed S. and Bhery, Ashraf and Daoud, Sameh S. and Bahig, Hatem M.",Three Strategies for Improving Shortest Vector Enumeration Using GPUs,2021,https://doi.org/10.1155/2021/8852497,https://onlinelibrary.wiley.com/doi/abs/10.1155/2021/8852497,Journal,Scientific Programming,"Hard Lattice problems are assumed to be one of the most promising problems for generating cryptosystems that are secure in quantum computing. The shortest vector problem (SVP) is one of the most famous lattice problems. In this paper, we present three improvements on GPU-based parallel algorithms for solving SVP using the classical enumeration and pruned enumeration. There are two improvements for preprocessing: we use a combination of randomization and the Gaussian heuristic to expect a better basis that leads rapidly to a shortest vector and we expect the level on which the exchanging data between CPU and GPU is optimized. In the third improvement, we improve GPU-based implementation by generating some points in GPU rather than in CPU. We used NVIDIA GeForce GPUs of type GTX 1060 6G. We achieved a significant improvement upon Hermans¡¯s improvement. The improvements speed up the pruned enumeration by a factor of almost 2.5 using a single GPU. Additionally, we provided an implementation for multi-GPUs by using two GPUs. The results showed that our algorithm of enumeration is scalable since the speedups achieved using two GPUs are almost faster than Hermans¡¯s improvement by a factor of almost 5. The improvements also provided a high speedup for the classical enumeration. The speedup achieved using our improvements and two GPUs on a challenge of dimension 60 is almost faster by factor 2 than Correia¡¯s parallel implementation using a dual-socket machine with 16 physical cores and simultaneous multithreading technology.",Wiley
"Kumar, Anmol and Yoluk, Ozge and MacKerell Jr., Alexander D.",FFParam: Standalone package for CHARMM additive and Drude polarizable force field parametrization of small molecules,2020,https://doi.org/10.1002/jcc.26138,https://onlinelibrary.wiley.com/doi/abs/10.1002/jcc.26138,Journal,Journal of Computational Chemistry,"Accurate force-field (FF) parameters are key to reliable prediction of properties obtained from molecular modeling (MM) and molecular dynamics (MD) simulations. With ever-widening applicability of MD simulations, robust parameters need to be generated for a wider range of chemical species. The CHARMM General Force Field program (CGenFF, https://cgenff.umaryland.edu/) is a tool for obtaining initial parameters for a given small molecule based on analogy with the available CGenFF parameters. However, improvement of these parameters is often required and performing their optimization remains tedious and time consuming. In addition, tools for optimization of small molecule parameters in the context of the Drude polarizable FF are not yet available. To overcome these issues, the FFParam package has been designed to facilitate the parametrization process. The package includes a graphical user interface (GUI) created using Qt libraries. FFParam supports Gaussian and Psi4 for performing quantum mechanical calculations and CHARMM and OpenMM for MM calculations. A Monte Carlo simulated annealing (MCSA) algorithm has been implemented for automated fitting of partial atomic charge, atomic polarizabilities and Thole scale parameters. The LSFITPAR program is called for automated fitting of bonded parameters. Accordingly, FFParam provides all the features required for generation and analysis of CHARMM and Drude FF parameters for small molecules. FFParam-GUI includes a text editor, graph plotter, molecular visualization, and text to table converter to meet various requirements of the parametrization process. It is anticipated that FFParam will facilitate wider use of CGenFF as well as promote future use of the Drude polarizable FF.",Wiley
"Fernandes, Kyle D. and Renison, C. Alicia and Naidoo, Kevin J.",Quantum supercharger library: Hyper-parallelism of the Hartree¨CFock method,2015,https://doi.org/10.1002/jcc.23936,https://onlinelibrary.wiley.com/doi/abs/10.1002/jcc.23936,Journal,Journal of Computational Chemistry,"We present here a set of algorithms that completely rewrites the Hartree¨CFock (HF) computations common to many legacy electronic structure packages (such as GAMESS-US, GAMESS-UK, and NWChem) into a massively parallel compute scheme that takes advantage of hardware accelerators such as Graphical Processing Units (GPUs). The HF compute algorithm is core to a library of routines that we name the Quantum Supercharger Library (QSL). We briefly evaluate the QSL's performance and report that it accelerates a HF 6-31G Self-Consistent Field (SCF) computation by up to 20 times for medium sized molecules (such as a buckyball) when compared with mature Central Processing Unit algorithms available in the legacy codes in regular use by researchers. It achieves this acceleration by massive parallelization of the one- and two-electron integrals and optimization of the SCF and Direct Inversion in the Iterative Subspace routines through the use of GPU linear algebra libraries. ? 2015 Wiley Periodicals, Inc.",Wiley
"Escribano Pablos, Jos¨¦ Ignacio and Gonz¨¢lez Vasco, Mar¨ªa Isabel",Secure post-quantum group key exchange: Implementing a solution based on Kyber,2023,https://doi.org/10.1049/cmu2.12561,https://onlinelibrary.wiley.com/doi/abs/10.1049/cmu2.12561,Journal,IET Communications,"Quantum computing poses fascinating challenges for current cryptography, threatening the security of many schemes and protocols widely used today. To adapt to this reality, the U.S. National Institute for Standards and Technology (NIST) is currently running a standardization process in search of post-quantum (classical, yet resistant to quantum attacks) cryptographic tools, focusing on signature schemes and key encapsulation mechanisms. Many of the competing proposals also include designs for two-party key exchange, which can be combined in different ways to fit scenarios involving n¡Ý2\$n \ge 2\$ parties, that is, yielding group key exchange protocols. However, very few implementations of such group protocols are available to practitioners, which face a non-trivial challenge when deciding how to implement a protocol for establishing secure group sessions in this new post-quantum scenario. With this in mind, the authors report on the implementation of a secure post-quantum group key exchange protocol in the so-called Quantum Random Oracle Model. The protocol decided to implement is based on a KEM called Kyber, which is one of the finalists of the NIST competition. Not only this group construction is the only one available in the literature using a NIST finalist, but also, among all post-quantum designs the authors are aware of, it uses this strongest security model (as, e.g. in other proposals, the adversarial interaction with the hash functions of the system is assumed to be exclusively classical). Furthermore, experimental evidence is provided supporting this choice in terms of performance, even if the number of involved entities is large (up to 2000). All data and code are publicly available.",Wiley
"Lei, Weidong and Manier, Herv¨¦ and Manier, Mari¨¦-Ange and Wang, Xinping",A Hybrid Quantum Evolutionary Algorithm with Improved Decoding Scheme for a Robotic Flow Shop Scheduling Problem,2017,https://doi.org/10.1155/2017/3064724,https://onlinelibrary.wiley.com/doi/abs/10.1155/2017/3064724,Journal,Mathematical Problems in Engineering,"We aim at solving the cyclic scheduling problem with a single robot and flexible processing times in a robotic flow shop, which is a well-known optimization problem in advanced manufacturing systems. The objective of the problem is to find an optimal robot move sequence such that the throughput rate is maximized. We propose a hybrid algorithm based on the Quantum-Inspired Evolutionary Algorithm (QEA) and genetic operators for solving the problem. The algorithm integrates three different decoding strategies to convert quantum individuals into robot move sequences. The Q-gate is applied to update the states of Q-bits in each individual. Besides, crossover and mutation operators with adaptive probabilities are used to increase the population diversity. A repairing procedure is proposed to deal with infeasible individuals. Comparison results on both benchmark and randomly generated instances demonstrate that the proposed algorithm is more effective in solving the studied problem in terms of solution quality and computational time.",Wiley
"Chang, En-Chih",Applying Robust Intelligent Algorithm and Internet of Things to Global Maximum Power Point Tracking of Solar Photovoltaic Systems,2020,https://doi.org/10.1155/2020/8882482,https://onlinelibrary.wiley.com/doi/abs/10.1155/2020/8882482,Journal,Wireless Communications and Mobile Computing,"The important dare in the solar photovoltaic (PV) system is to investigate the performance under partial shading conditions. A robust intelligent algorithm (RIA) connected with internet of things (IoT) is developed to offer the real-time monitoring of solar PV systems, thus ensuring global maximum power point tracking (MPPT). The RIA comprises a limited-time terminal sliding-mode control (LTTSMC) and a quantum particle swarm optimization- (QPSO-) radial basis function (RBF) neural network. The LTTSMC creates a quick limited-system-state convergence time and allows for singularity avoidance. However, if the system ambiguity is overrated or underrated, the tremble phenomenon or steady-state error probably occurs around the LTTSMC. The QPSO-RBF neural network is integrated into LTTSMC to handle plant parameter variations and external load perturbations, thus reducing tremble and steady-state errors. With the aggregation of the RIA and the IoT, the remote monitoring in the solar PV system yields faster convergence to nonsingular points, and it also introduces neural network method to achieve more accurate ambiguity estimation. Experimental results show the mathematical analysis and performance enhancement of a prototype algorithm-controlled solar PV system based on digital signal processing under transient and steady-state loading conditions. Because the proposed solar PV system has notable advantages over the classical terminal-sliding solar PV system in terms of tracking accuracy and robust adaptation, this paper is worthy of reference to designers of relative robust control and neural network learning algorithm.",Wiley
"Zhang, Hanxu and Chen, Tian and Pan, Naiqiao and Zhang, Xiangdong",Electric-Circuit Simulation of Quantum Fast Hitting with Exponential Speedup,2022,https://doi.org/10.1002/qute.202100143,https://onlinelibrary.wiley.com/doi/abs/10.1002/qute.202100143,Journal,Advanced Quantum Technologies,"The ultimate goal of developing quantum algorithms and constructing quantum computers is to achieve faster information processing than using current classical computers. Quantum walks are powerful kernels in quantum computing protocols and possess strong capabilities in speeding up various simulation and optimization tasks. One striking example is provided by quantum walkers evolving on unbalanced trees, which demonstrate faster hitting performances than classical random walk. However, direct experimental construction of unbalanced trees to prove quantum advantage with exponential speedup remains a great challenge due to the highly complex arrangements of the structure. This study attempts to simulate quantum algorithm by classical circuit. Inspired by the quantum algorithm, the classical circuit networks are designed and fabricated with unbalanced tree structures. It is then demonstrated, both theoretically and experimentally, that the quantum algorithm for the fast hitting problem can be simulated in the structure. It is shown that the hitting efficiency of electric signals in the circuit networks with unbalanced tree structures is exponentially faster than the corresponding cases of classical random walks. Because classical circuit networks possess good scalability and stability, the results open up a scalable new path toward quantum speedup in complex problems.",Wiley
"Manzoor, Habib Ullah and Manzoor, Tareq and Hussain, Sajjad and Manzoor, Muhammad Nasir and Zoha, Ahmed",Swarm-Optimized ZnO/CdS/CIGS/GaAs Solar Cell for Enhanced Efficiency and Thermal Resilience,,https://doi.org/10.1002/aesr.202400203,https://onlinelibrary.wiley.com/doi/abs/10.1002/aesr.202400203,Journal,Advanced Energy and Sustainability Research,,Wiley
"Talatahari, Siamak and Azizi, Mahdi",Optimal design of real-size building structures using quantum-behaved developed swarm optimizer,2020,https://doi.org/10.1002/tal.1747,https://onlinelibrary.wiley.com/doi/abs/10.1002/tal.1747,Journal,The Structural Design of Tall and Special Buildings,"Summary In this paper, the quantum-behaved developed swarm optimizer is proposed for optimal design of real-size building structures in which the quantum computing is introduced into the standard developed swarm optimizer. In this method, the position-updating process for the search agents is conducted by simultaneous utilization of the so far best position of all particles, center of mass of all particles, so far best position of each particle, and the mean best position of all particles in which the first two of these aspects satisfy the exploration phase of the algorithm, whereas the other two are utilized for improving the exploitation phase of the proposed method. In order to evaluate the capability of the proposed method in dealing with difficult optimization problems, three real-size building structures are considered, namely, a 10-story building with 1,026 structural members, a 20-story building with 3,860 members, and a 60-story building with 8,272 members. The overall performance of the proposed quantum-behaved developed swarm optimizer is compared with that of the standard developed swarm optimizer and other approaches. The obtained results proved that the proposed method is capable of providing better results for the considered examples than are the other algorithms.",Wiley
"Jiang, Zhuoying and Jiang, Ying and Chen, Mengyu and Li, Jinchai and Li, Penggang and Chen, Binghuan and Zhao, Shanshan and Wang, Jie and Jiang, Sijie and Cai, Miaomin and Li, Lin and Li, Cheng and Huang, Kai and Lu, Weifang and Kang, Junyong and Zhang, Rong",Advanced Design of a III-Nitride Light-Emitting Diode via Machine Learning,2023,https://doi.org/10.1002/lpor.202300113,https://onlinelibrary.wiley.com/doi/abs/10.1002/lpor.202300113,Journal,Laser \& Photonics Reviews,"Gallium nitride (GaN)-based light-emitting diodes (LEDs) have obtained great market success in the past 20 years. However, the traditional research paradigm, i.e., experimental trial-and-error method, no longer adapts to the industry development. In this work, an efficient approach is demonstrated to design and optimize GaN-based LED structures via machine learning (ML). By using the dataset of GaN-based LED structures over the past decade to train four typical ML models, it is found that the convolutional neural network (CNN) provides the most accurate prediction, with a root mean square error (RMSE) of 1.03\% for internal quantum efficiency (IQE) and 11.98 W cm?2 for light output power density (LOPD). Based on the CNN model, 1) the feature importance analysis is adopted to reveal the critical features for LED performance; 2) the predicted trends of IQE and LOPD match well with the physical mechanism, being consistent with the experimental and simulation results; and 3) a high-throughput screening is demonstrated to predict the properties of over 20 000 structures within seconds to obtain high efficiency LED structures. This ML-based LED design method enables direct guiding of the LED structure optimization in terms of key parameter selection during manufacturing and greatly accelerates the development cycle of GaN-based LEDs.",Wiley
"Paglierani, Pietro and Fahim Raouf, Amir Hossein and Pelekanakis, Konstantinos and Petroccia, Roberto and Alves, Jo?o and Uysal, Murat",A Primer on Underwater Quantum Key Distribution,2023,https://doi.org/10.1155/2023/7185329,https://onlinelibrary.wiley.com/doi/abs/10.1155/2023/7185329,Journal,Quantum Engineering,"The growing importance of underwater networks (UNs) in mission-critical activities at sea enforces the need for secure underwater communications (UCs). Classical encryption techniques can be used to achieve secure data exchange in UNs. However, the advent of quantum computing will pose threats to classical cryptography, thus challenging UCs. Currently, underwater cryptosystems mostly adopt symmetric ciphers, which are considered computationally quantum robust but pose the challenge of distributing the secret key upfront. Post-quantum public-key (PQPK) protocols promise to overcome the key distribution problem. The security of PQPK protocols, however, only relies on the assumed computational complexity of some underlying mathematical problems. Moreover, the use of resource-hungry PQPK algorithms in resource-constrained environments such as UNs can require nontrivial hardware/software optimization efforts. An alternative approach is underwater quantum key distribution (QKD), which promises unconditional security built upon the physical principles of quantum mechanics (QM). This tutorial provides a basic introduction to free-space underwater QKD (UQKD). At first, the basic concepts of QKD are presented, based on a fully worked out QKD example. A thorough state-of-the-art analysis of UQKD is carried out. The paper subsequently provides a theoretical analysis of the QKD performance through free-space underwater channels and its dependence on the key optical parameters of the system and seawater. Finally, open challenges, points of strength, and perspectives of UQKD are identified and discussed.",Wiley
"Sihare, Shyam R.",Dimensionality Reduction for Data Analysis With Quantum Feature Learning,2025,https://doi.org/10.1002/widm.1568,https://onlinelibrary.wiley.com/doi/abs/10.1002/widm.1568,Journal,WIREs Data Mining and Knowledge Discovery,"ABSTRACT To improve data analysis and feature learning, this study compares the effectiveness of quantum dimensionality reduction (qDR) techniques to classical ones. In this study, we investigate several qDR techniques on a variety of datasets such as quantum Gaussian distribution adaptation (qGDA), quantum principal component analysis (qPCA), quantum linear discriminant analysis (qLDA), and quantum t-SNE (qt-SNE). The Olivetti Faces, Wine, Breast Cancer, Digits, and Iris are among the datasets used in this investigation. Through comparison evaluations against well-established classical approaches, such as classical PCA (cPCA), classical LDA (cLDA), and classical GDA (cGDA), and using well-established metrics like loss, fidelity, and processing time, the effectiveness of these techniques is assessed. The findings show that cPCA produced positive results with the lowest loss and highest fidelity when used on the Iris dataset. On the other hand, quantum uniform manifold approximation and projection (qUMAP) performs well and shows strong fidelity when tested against the Wine dataset, but ct-SNE shows mediocre performance against the Digits dataset. Isomap and locally linear embedding (LLE) function differently depending on the dataset. Notably, LLE showed the largest loss and lowest fidelity on the Olivetti Faces dataset. The hypothesis testing findings showed that the qDR strategies did not significantly outperform the classical techniques in terms of maintaining pertinent information from quantum datasets. More specifically, the outcomes of paired t-tests show that when it comes to the ability to capture complex patterns, there are no statistically significant differences between the cPCA and qPCA, the cLDA and qLDA, and the cGDA and qGDA. According to the findings of the assessments of mutual information (MI) and clustering accuracy, qPCA may be able to recognize patterns more clearly than standardized cPCA. Nevertheless, there is no discernible improvement between the qLDA and qGDA approaches and their classical counterparts.",Wiley
"Xu, Jiaqi and Luo, Yafei and Wang, Chuanbing and Chen, Haiyan and Tang, Yuxia and Xu, Ziqing and Li, Yang and Ni, Hao and Shi, Xianbiao and Hu, Yongzhi and Wu, Feiyun and Zhang, Jiulou and Wang, Shouju",A High-Resolution Prediction Network for Predicting Intratumoral Distribution of Nanoprobes by Tumor Vascular and Nuclear Feature,2024,https://doi.org/10.1002/aisy.202300592,https://onlinelibrary.wiley.com/doi/abs/10.1002/aisy.202300592,Journal,Advanced Intelligent Systems,"In this study, the critical need for precise and accurate prediction of intra-tumor heterogeneity related to the enhanced permeability and retention effect and spatial distribution of nanoprobes is addressed for the development of effective nanodrug delivery strategies. Current predictive models are limited in terms of resolution and accuracy, prompting the construction of a high-resolution prediction network (HRPN) that estimates the microdistribution of quantum dots, factoring in tumor vascular and nuclear features. The HRPN algorithm is trained using 27?780 patches and validated on 4920 patches derived from 4T1 breast cancer whole-slide images, demonstrating its reliability. The HRPN model exhibits minimal error (mean square error?=?1.434, root mean square error?=?1.198), satisfactory goodness of fit (R2?=?0.891), and superior image quality (peak signal-to-noise ratio?=?44.548) when compared to a generative-adversarial-network-structured model. Furthermore, the HRPN model offers improved prediction accuracy, broader prediction intervals, and reduced computational resource requirements. Consequently, the proposed model yields high-resolution predictions that more closely resemble actual tumor microdistributions, potentially serving as a powerful analytical tool for investigating the spatial relationship between the tumor microenvironment and nanoprobes.",Wiley
"Mahmud, Naveed and El-Araby, Esam",Dimension Reduction Using Quantum Wavelet Transform on a High-Performance Reconfigurable Computer,2019,https://doi.org/10.1155/2019/1949121,https://onlinelibrary.wiley.com/doi/abs/10.1155/2019/1949121,Journal,International Journal of Reconfigurable Computing,"The high resolution of multidimensional space-time measurements and enormity of data readout counts in applications such as particle tracking in high-energy physics (HEP) is becoming nowadays a major challenge. In this work, we propose combining dimension reduction techniques with quantum information processing for application in domains that generate large volumes of data such as HEP. More specifically, we propose using quantum wavelet transform (QWT) to reduce the dimensionality of high spatial resolution data. The quantum wavelet transform takes advantage of the principles of quantum mechanics to achieve reductions in computation time while processing exponentially larger amount of information. We develop simpler and optimized emulation architectures than what has been previously reported, to perform quantum wavelet transform on high-resolution data. We also implement the inverse quantum wavelet transform (IQWT) to accurately reconstruct the data without any losses. The algorithms are prototyped on an FPGA-based quantum emulator that supports double-precision floating-point computations. Experimental work has been performed using high-resolution image data on a state-of-the-art multinode high-performance reconfigurable computer. The experimental results show that the proposed concepts represent a feasible approach to reducing dimensionality of high spatial resolution data generated by applications such as particle tracking in high-energy physics.",Wiley
"Katirci, Ramazan and Adem, Kemal and Tatar, Muhammed and ?lmez, Fatih",Comparison of the performance of classical and quantum machine-learning methods on the detection of sugar beet Cercospora leaf disease,,https://doi.org/10.1111/ppa.14036,https://onlinelibrary.wiley.com/doi/abs/10.1111/ppa.14036,Journal,Plant Pathology,,Wiley
"Wang, Kaidong and Margolis, Samuel and Cho, Jae Min and Wang, Shaolei and Arianpour, Brian and Jabalera, Alejandro and Yin, Junyi and Hong, Wen and Zhang, Yaran and Zhao, Peng and Zhu, Enbo and Reddy, Srinivasa and Hsiai, Tzung K.",Non-Invasive Detection of Early-Stage Fatty Liver Disease via an On-Skin Impedance Sensor and Attention-Based Deep Learning,2024,https://doi.org/10.1002/advs.202400596,https://onlinelibrary.wiley.com/doi/abs/10.1002/advs.202400596,Journal,Advanced Science,"Early-stage nonalcoholic fatty liver disease (NAFLD) is a silent condition, with most cases going undiagnosed, potentially progressing to liver cirrhosis and cancer. A non-invasive and cost-effective detection method for early-stage NAFLD detection is a public health priority but challenging. In this study, an adhesive, soft on-skin sensor with low electrode-skin contact impedance for early-stage NAFLD detection is fabricated. A method is developed to synthesize platinum nanoparticles and reduced graphene quantum dots onto the on-skin sensor to reduce electrode-skin contact impedance by increasing double-layer capacitance, thereby enhancing detection accuracy. Furthermore, an attention-based deep learning algorithm is introduced to differentiate impedance signals associated with early-stage NAFLD in high-fat-diet-fed low-density lipoprotein receptor knockout (Ldlr?/?) mice compared to healthy controls. The integration of an adhesive, soft on-skin sensor with low electrode-skin contact impedance and the attention-based deep learning algorithm significantly enhances the detection accuracy for early-stage NAFLD, achieving a rate above 97.5\% with an area under the receiver operating characteristic curve (AUC) of 1.0. The findings present a non-invasive approach for early-stage NAFLD detection and display a strategy for improved early detection through on-skin electronics and deep learning.",Wiley
"Cheng, Rong and Zhang, Fangguo",Lattice-based obfuscation for re-encryption functions,2015,https://doi.org/10.1002/sec.1112,https://onlinelibrary.wiley.com/doi/abs/10.1002/sec.1112,Journal,Security and Communication Networks,"AbstractProgram obfuscation is a compiler that transfers a program into an unintelligible form while preserving the original functionality. Secure obfuscation for several particular function families has been raised out despite the general impossibility result presented by Barak et al. Re-encryption function is a useful primitive, which transforms ciphertexts for one party into ciphertexts under another party's public key. Hohenberger et al. constructed a special re-encryption function and securely obfuscated it in TCC'07, and the security is based on classical hardness assumption. In this paper, we construct a new re-encryption function and securely obfuscate it based on the standard learning with error (LWE) assumption. LWE is proved to be reducible to standard lattice problems, which are conjectured immune to quantum cryptanalysis or ¡®post-quantum¡¯. Besides, we discuss about the relations between these two cryptographic primitives in detail: proxy re-encryption and obfuscation for re-encryption functions. Copyright ? 2014 John Wiley \& Sons, Ltd.",Wiley
"Bai, Ti and Wang, Biling and Nguyen, Dan and Jiang, Steve",Probabilistic self-learning framework for low-dose CT denoising,2021,https://doi.org/10.1002/mp.14796,https://onlinelibrary.wiley.com/doi/abs/10.1002/mp.14796,Journal,Medical Physics,"Purpose Despite the indispensable role of x-ray computed tomography (CT) in diagnostic medicine, the associated harmful ionizing radiation dose is a major concern, as it may cause genetic diseases and cancer. Decreasing patients¡¯ exposure can reduce the radiation dose and hence the related risks, but it would inevitably induce higher quantum noise. Supervised deep learning techniques have been used to train deep neural networks for denoising low-dose CT (LDCT) images, but the success of such strategies requires massive sets of pixel-level paired LDCT and normal-dose CT (NDCT) images, which are rarely available in real clinical practice. Our purpose is to mitigate the data scarcity problem for deep learning-based LDCT denoising. Methods To solve this problem, we devised a shift-invariant property-based neural network that uses only the LDCT images to characterize both the inherent pixel correlations and the noise distribution, shaping into our probabilistic self-learning (PSL) framework. The AAPM Low-dose CT Challenge dataset was used to train the network. Both simulated datasets and real dataset were employed to test the denoising performance as well as the model generalizability. The performance was compared to a conventional method (total variation (TV)-based), a popular self-learning method (noise2void (N2V)), and a well-known unsupervised learning method (CycleGAN) by using both qualitative visual inspection and quantitative metrics including peak signal-noise-ratio (PSNR), structural similarity index (SSIM) and contrast-to-noise-ratio (CNR). The standard deviations (STD) of selected flat regions were also calculated for comparison. Results The PSL method can improve the averaged PSNR/SSIM values from 27.61/0.5939 (LDCT) to 30.50/0.6797. By contrast, the averaged PSNR/SSIM values were 31.49/0.7284 (TV), 29.43/0.6699 (N2V), and 29.79/0.6992 (CycleGAN). The averaged STDs of selected flat regions were calculated to be 132.3 HU (LDCT), 25.77 HU (TV), 19.95 HU (N2V), 75.06 HU (CycleGAN), 60.62 HU (PSL) and 57.28 HU (NDCT). As for the low-contrast lesion detectability quantification, the CNR were calculated to be 0.202 (LDCT), 0.356 (TV), 0.372 (N2V), 0.383 (CycleGAN), 0.399 (PSL), and 0.359 (NDCT). By visual inspection, we observed that the proposed PSL method can deliver a noise-suppressed and detail-preserved image, while the TV-based method would lead to the blocky artifact, the N2V method would produce over-smoothed structures and CT value biased effect, and the CycleGAN method would generate slightly noisy results with inaccurate CT values. We also verified the generalizability of the PSL method, which exhibited superior denoising performance among various testing datasets with different data distribution shifts. Conclusions A deep learning-based convolutional neural network can be trained without paired datasets. Qualitatively visual inspection showed the proposed PSL method can achieve superior denoising performance than all the competitors, despite that the employed quantitative metrics in terms of PSNR, SSIM and CNR did not always show consistently better values.",Wiley
"Yu, Xiaohuan and Cai, Ailong and Wang, Linyuan and Zheng, Zhizhong and Wang, Yizhong and Wang, Zhe and Li, Lei and Yan, Bin",Framelet tensor sparsity with block matching for spectral CT reconstruction,2022,https://doi.org/10.1002/mp.15529,https://onlinelibrary.wiley.com/doi/abs/10.1002/mp.15529,Journal,Medical Physics,"Purpose Spectral computed tomography (CT) based on the photon-counting detection system has the capability to produce energy-discriminative attenuation maps of objects with a single scan. However, the insufficiency of photons collected into the narrow energy bins results in high quantum noise levels causing low image quality. This work aims to improve spectral CT image quality by developing a novel regularization based on framelet tensor prior. Methods First, similar patches are extracted from highly correlated interchannel images in spectral and spatial domains, and stacked to form a third-order tensor after vectorization along the energy channels. Second, the framelet tensor nuclear norm (FTNN) is introduced and applied to construct the regularization to exploit the sparsity embedded in nonlocal similarity of spectral images, and thus the reconstruction problem is modeled as a constrained optimization. Third, an iterative algorithm is proposed by utilizing the alternating direction method of multipliers framework in which efficient solvers are developed for each subproblem. Results Both numerical simulations and real data verifications were performed to evaluate and validate the proposed FTNN-based method. Compared to the analytic, TV-based, and the state-of-the-art tensor-based methods, the proposed method achieves higher numerical accuracy on both reconstructed CT images and decomposed material maps in the mouse data indicating the capability in noise suppression and detail preservation of the proposed method. Conclusions A framelet tensor sparsity¨Cbased iterative algorithm is proposed for spectral reconstruction. The qualitative and quantitative comparisons show a promising improvement of image quality, indicating its promising potential in spectral CT imaging.",Wiley
"Xie, Qing-Xing and Zhang, Wen-gang and Xu, Xu-Sheng and Liu, Sheng and Zhao, Yan",Qubit unitary coupled cluster with generalized single and paired double excitations ansatz for variational quantum eigensolver,2022,https://doi.org/10.1002/qua.27001,https://onlinelibrary.wiley.com/doi/abs/10.1002/qua.27001,Journal,International Journal of Quantum Chemistry,"Variational quantum eigensolver (VQE) with a unitary coupled cluster (UCC) ansatz has been suggested as a promising method for electronic structure calculations on future quantum computers. However, the complexity of the excitation terms for UCC with the single and double excitations (UCCSD) ansatz is up-bounded to OM?N2N2, where N is the number of electrons and M is the number of spin orbitals. The gate complexity of quantum circuit for the UCCSD ansatz is up-bounded to OMM?N2N2 using the Jordan¨CWigner transformation. These complexities significantly limit the implementation of UCCSD on current Noisy Intermediate-Scale Quantum (NISQ) devices. Herein, we developed a k-QUpCCGSD ansatz which is based on the generalized paired double excitation operators and the particle preserving exchange gate. The former reduces the number of the excitation operators, the latter reduces the number of qubit gates for transforming excitation operators to quantum circuit. The gate complexity of the proposed k-QUpCCGSD ansatz is up-bounded to O(kM2), which significantly reduce the complexity of the VQE algorithm on NISQ devices. The performance of the proposed ansatz on VQE is demonstrated by calculating ground-state dissociation energy curves of the H6, LiH, H2O, and BeH2 molecules with the STO-3G minimal basis set, and the accuracy is evaluated by comparing to the full configuration interaction (FCI) benchmarks. Moreover, we compare the number of quantum gates, especially the CNOT gates, and accuracies of various ansatzes. The assessments have shown that the accuracy of qubit unitary coupled cluster (QUCC) ansatzes is slightly worse than that of the UCC ones, but the circuit complexity of QUCC is much less than that of UCC. Among the tested QUCC ansatzes, k-QUpCCGSD achieves higher accuracy with fewer quantum gates than QUCCSD, and k-QUpCCGSD is a promising ansatz for VQE calculation on NISQ devices.",Wiley
"Li, Xiang and Guo, Chong and Li, Chengjun and Xu, Tianyuan and Wu, Songyu",Power Grid Low Carbon Collaborative Planning Method Using Improved Cat Swarm Optimization Algorithm in Edge Cloud Computing Environment,2022,https://doi.org/10.1155/2022/5213270,https://onlinelibrary.wiley.com/doi/abs/10.1155/2022/5213270,Journal,Wireless Communications and Mobile Computing,"The current power grid planning mostly realizes the calculation and analysis based on the factors of operation reliability or operation economy, but low-carbon green operation has become the main melody of power system development. Aiming to support the green and reliable operation of the power grid, this paper proposes a power grid low-carbon collaborative planning method based on improved cat swarm optimization algorithm. First, the carbon emission characteristics of the whole cycle of power grid construction are analyzed on the edge side, and a power grid planning model including environmental, economic, and reliability is constructed; on the cloud side, the cat swarm optimization algorithm is improved based on quantum mechanics and chaotic algorithm to achieve efficient solution to the power grid low-carbon planning model, which can support the stable and sustainable operation. Finally, the simulation experiment is realized based on IEEE 39 bus system. In this experiment, the construction cost and carbon emission of the proposed collaborative planning method are 23 million yuan and 2.28?t/MWh, respectively, which can reduce carbon emission while optimizing the construction cost and maintaining the low-carbon and stable operation.",Wiley
"Xu, Yin-Song and Cai, Bin-Bin and Yuan, Zheng and Qin, Su-Juan and Gao, Fei and Wen, Qiao-Yan",Quantum Differential Meet-In-The-Middle Attack and Some Applications to Lightweight Ciphers,2024,https://doi.org/10.1002/qute.202400157,https://onlinelibrary.wiley.com/doi/abs/10.1002/qute.202400157,Journal,Advanced Quantum Technologies,"At CRYPTO 2023, Boura et al. proposed a new cryptanalysis technique, differential meet-in-the-middle (MITM) attack. They used MITM technique to make the key recovery step of a differential attack more efficient. In this study, a quantum differential meet-in-the-middle attack is proposed by using nested quantum search algorithm, which can achieve up to a quadratic speed-up compared to the classical version. Besides, the time complexity of the attack can be reduced by at least a factor of 2(kin¡Èkout?n)/2\${2^{({\left| {{k\_{in}} \cup {k\_{out}}} \right| } - n)/2}}\$ (kin¡Èkout\${{\left| {{k\_{in}} \cup {k\_{out}}} \right| }}\$ is the guessed key length and n\$n\$ is the block size) compared to the first quantum differential attack proposed by Kaplan et al. at ToSC 2016. Finally, to demonstrate the efficiency of our attack, it is applied to two reduced-round lightweight block ciphers, PIPO and SIMON, to evaluate their post-quantum security. When attacking the same number of rounds, the time complexity of our attack is significantly lower than that of classical attacks. For the 8-round PIPO-128, the attack significantly improves efficiency, reducing the time complexity from 264+260.94\$2^{64} + 2^{60.94}\$ to 260.48\$2^{60.48}\$, cutting down the required qRAM size by a factor of 214\$2^{14}\$ and obtaining the data complexity 257\$2^{57}\$ instead of 264\$2^{64}\$ compared to the best quantum attack proposed by Schrottenloher at CRYPTO 2023. For the 19-round SIMON-32-64, the time complexity here will be 231.68\$2^{31.68}\$ instead of 233.39\$2^{33.39}\$ compared to the other quantum attack, and the attack can target more rounds than using Grover-meets-Simon technique.",Wiley
"Jafari, Mahdi and Momeni Isfahani, Tahereh and Shafiei, Fatemeh and Senejani, Masumeh Abdoli","QSPR study to predict some of quantum chemical properties of anticancer imidazo[4,5-b]pyridine derivatives using genetic algorithm multiple linear regression and molecular descriptors",2024,https://doi.org/10.1002/qua.27259,https://onlinelibrary.wiley.com/doi/abs/10.1002/qua.27259,Journal,International Journal of Quantum Chemistry,"Pyridine and its derivatives have been applied clinically for the treatment of a wide range of diseases and in the synthesis of novel drugs. In the present work, imidazo[4,5-b]pyridine derivatives as anticancer drugs were exhibited to select the important descriptor for quantum chemical properties. Two of the fundamental thermodynamic properties are heat capacity (Cv) and entropy (S), which are important in the field of chemical kinetics and are key in the understanding and design of chemical processes involving chemical reactions. A Quantitative Structure¨CProperty Relationship (QSPR) study was used to predict the quantum chemical properties like Cv and S of 105 imidazole derivatives using molecular descriptors and the genetic algorithm¨Cmultiple linear regression (GA¨CMLR). The best QSPR models were selected using criteria coefficients such as R2, R2adj, RMSE and Fisher ratio. Different internal and external validation metrics were adopted to evaluate the stability, fit and predictive power of the QSPR models. The validation results and statistical analysis show that the models possess good prediction power and robustness, and the total size (TS) and Sanderson electronegativity(RDF060e) and total information content index(TIC1) of imidazo[4,5-b]pyridine derivatives are increasingly related to the studied properties.",Wiley
"Zhu, Kai and Gu, Chongshi and Qiu, Jianchun and Liu, Wanxin and Fang, Chunhui and Li, Bo",Determining the Optimal Placement of Sensors on a Concrete Arch Dam Using a Quantum Genetic Algorithm,2016,https://doi.org/10.1155/2016/2567305,https://onlinelibrary.wiley.com/doi/abs/10.1155/2016/2567305,Journal,Journal of Sensors,"Structural modal identification has become increasingly important in health monitoring, fault diagnosis, vibration control, and dynamic analysis of engineering structures in recent years. Based on an analysis of traditional optimization algorithms, this paper proposes a novel sensor optimization criterion that combines the effective independence (EFI) method with the modal strain energy (MSE) method. Considering the complex structure and enormous degrees of freedom (DOFs) of modern concrete arch dam, a quantum genetic algorithm (QGA) is used to optimize the corresponding sensor network on the upstream surface of a dam. Finally, this study uses a specific concrete arch dam as an example and determines the optimal sensor placement using the proposed method. By comparing the results with the traditional optimization methods, the proposed method is shown to maximize the spatial intersection angle among the modal vectors of sensor network and can effectively resist ambient perturbations, which will make the identified modal parameters more precise.",Wiley
"Mahmud, Naveed and El-Araby, Esam and Caliga, David",Scaling reconfigurable emulation of quantum algorithms at high precision and high throughput,2019,https://doi.org/10.1002/que2.19,https://onlinelibrary.wiley.com/doi/abs/10.1002/que2.19,Journal,Quantum Engineering,"Summary The general approach for emulating quantum algorithms on classical platforms has been through representing them as gate-based quantum circuits. However, direct implementation of quantum circuits significantly increases the hardware resource utilization and system latency of classical emulators. In this paper, we investigate multiple implementation models alternative to conventional emulation approaches, as feasible solutions to the scalability problem in classical emulation of quantum circuits. In the first model, the quantum circuit functionality is reduced to equivalent, arithmetic (multiply-and-accumulate) operations and combined with two computation methods, based on lookup and dynamic generation. In the second model, a kernel operation is extracted from the quantum circuit based on its functionality, and the kernel is iterated through all input quantum states. The proposed emulation models provide space and time optimizations, significantly reducing resource utilizations and latencies and improving scalability. We use these models to develop a highly scalable hardware emulator that is based on reconfigurable technology for efficient simulations of full quantum algorithms and circuits. Our hardware implementations support single precision floating point arithmetic for improved accuracy, and contain fully pipelined designs for high throughput. We investigate quantum algorithms such as quantum Fourier transform and quantum wavelet transform and explore different hardware architectures and optimizations. Experimental results and analysis are provided for the architectures in terms of resource consumption and emulation time. The experiments are carried out on a high-performance reconfigurable computing system and the obtained results show that the proposed emulator is feasible for running and testing a variety of quantum algorithms.",Wiley
"Sharma, Purva and Gupta, Shubham and Bhatia, Vimal and Prakash, Shashi",Deep reinforcement learning-based routing and resource assignment in quantum key distribution-secured optical networks,2023,https://doi.org/10.1049/qtc2.12063,https://onlinelibrary.wiley.com/doi/abs/10.1049/qtc2.12063,Journal,IET Quantum Communication,"In quantum key distribution-secured optical networks (QKD-ONs), constrained network resources limit the success probability of QKD lightpath requests (QLRs). Thus, the selection of an appropriate route and the efficient utilisation of network resources for establishment of QLRs are the essential and challenging problems. This work addresses the routing and resource assignment (RRA) problem in the quantum signal channel of QKD-ONs. The RRA problem of QKD-ONs is a complex decision making problem, where appropriate solutions depend on understanding the networking environment. Motivated by the recent advances in deep reinforcement learning (DRL) for complex problems and also because of its capability to learn directly from experiences, DRL is exploited to solve the RRA problem and a DRL-based RRA scheme is proposed. The proposed scheme learns the optimal policy to select an appropriate route and assigns suitable network resources for establishment of QLRs by using deep neural networks. The performance of the proposed scheme is compared with the deep-Q network (DQN) method and two baseline schemes, namely, first-fit (FF) and random-fit (RF) for two different networks, namely The National Science Foundation Network (NSFNET) and UBN24. Simulation results indicate that the proposed scheme reduces blocking by 7.19\%, 10.11\%, and 33.50\% for NSFNET and 2.47\%, 3.20\%, and 19.60\% for UBN24 and improves resource utilisation up to 3.40\%, 4.33\%, and 7.18\% for NSFNET and 1.34\%, 1.96\%, and 6.44\% for UBN24 as compared with DQN, FF, and RF, respectively.",Wiley
"Silva, Tha¨ªs Boulhosa Barros da and Monteiro, Marta Chagas and Borges, Rosivaldo dos Santos and Barros, Tain¨¢ Guimar?es and Carneiro, Agnaldo da Silva and Barros, Carlos Augusto Lima",Theoretical and practical study of the cefoxitin-Escherichia coli PBP5 complex interaction by molecular dynamics to obtain computational prototype of antimicrobial susceptibility to Gram negative bacteria,2020,https://doi.org/10.1111/cbdd.13358,https://onlinelibrary.wiley.com/doi/abs/10.1111/cbdd.13358,Journal,Chemical Biology \& Drug Design,"The penicillin-binding proteins (PBPs) are important biological target for new antibacterial drugs development. This study focused on molecular interaction between cefoxitin and the Escherichia coli PBP5 by molecular dynamics (MD) using hybrid quantum mechanics/molecular mechanics (QM/MM) simulations approach, searching to develop a computational simulations prototype method on antimicrobial susceptibility of gram-negative bacteria against antibiotics. Escherichia coliATCC 8739 strain susceptibility for the drugs used in the antimicrobial susceptibility testing and selection of bioactive molecules against resistant strain. The protonation revealed a deprotonate state for His146, His151, His216, and His320 residues. The complex was stabilized after 0.6 ns of MD simulation. The global interaction means for inhibition zone diameters of E. coliATCC8739 strain and cefoxitin were 24.33 mm no showing significant difference between computational and experimental methods. Our computational simulation method can reliably be performed as a molecular modeling prototype for gram-negative antimicrobial susceptibility testing bacteria.",Wiley
"Liu, Lanjun and Liu, Denghui and Wu, Han and Wang, Xinyu",The Prediction of Metro Shield Construction Cost Based on a Backpropagation Neural Network Improved by Quantum Particle Swarm Optimization,2020,https://doi.org/10.1155/2020/6692130,https://onlinelibrary.wiley.com/doi/abs/10.1155/2020/6692130,Journal,Advances in Civil Engineering,"The prediction of construction cost of metro shield engineering is of great significance to project management. In this study, we used the rough set theory, a backpropagation (BP) neural network, and quantum particle swarm optimization (QPSO) to establish a prediction model for predicting the metro shield construction costs. The model accounts for the complexity of metro shield construction and the nonlinear relationship between the construction cost factors. First, the factors affecting the construction cost were determined by referring to the Chinese National Standards and analysing the engineering practice of typical metro shield projects. The rough set theory was used to simplify the system of influencing factors to extract the dominant influencing factors and reduce the number of input variables in the BP neural network. Since the BP neural network easily falls into a local minimum and has a slow convergence speed, QPSO was used to optimize the weights and thresholds of the BP neural network. This method combined the strong nonlinear analysis capabilities of the BP and the global search capabilities of the QPSO. Finally, we selected 50 projects in China for a case analysis. The results showed the dominant factors affecting the construction cost of these projects included ten indicators, such as the type of tunnelling machine and the geological characteristics. The determination coefficient, mean absolute percentage error, root mean square error, and mean absolute error, which are frequently used error analysis tools, were used to analyse the calculation errors of different models (the proposed model, a multiple regression method, a traditional BP model, a BP model optimized by the genetic algorithm, and the BP model optimized by the particle swarm optimization). The results showed that the proposed method had the highest prediction accuracy and stability, demonstrating the effectiveness and excellent performance of this proposed method.",Wiley
"Yan, Jianhua and Wang, Licheng and Li, Jing and Li, Muzi and Yang, Yixan and Yao, Wenbin",Pre-image sample algorithm with irregular Gaussian distribution and construction of identity-based signature,2017,https://doi.org/10.1002/cpe.3925,https://onlinelibrary.wiley.com/doi/abs/10.1002/cpe.3925,Journal,Concurrency and Computation: Practice and Experience,"Summary Lattice has become an attractive cryptographic tool due to its potential resistance to quantum attacks, worst-case hardness, simple computation kind, and flexibility. The pre-image sample algorithm is the most fundamental algorithm in lattice-based cryptography for its comprehensive applications in various primitives. Currently, due to Micciancio and Peikert (MP) sample algorithm is the most efficient pre-image sample algorithm. However, this algorithm also needs massive computations. On the one hand, it expenses the cube of the lattice dimension multiplications over reals to set matrices as Gaussian parameters. On the other hand, it needs complex discrete convolution computations. First, this paper proposes an efficient pre-image sample algorithm with outputs obeying irregular Gaussian distribution. Two measures are adopted to prevent the leakage of the geometrical property of trapdoor caused by irregular Gaussian outputs. A variant of MP trapdoor is proposed, and a new trapdoor is randomly assembled from a big enough space in each sample. Although still using a matrix as the Guassian parameter, in the proposed algorithm, the computational cost to set Gaussian parameters is zero. Meanwhile, the computational overhead for every sample is far less than that of MP sample algorithm. Second, to demonstrate the security and efficiency of the proposed sample algorithm, a hierarchical identity-based signature scheme is put forward. This scheme is proved existentially unforgeable against selective identity adaptively chosen-message attacks. Furthermore, the theoretical analysis shows that the proposed identity-based signature is more efficient than the existing schemes. Copyright ? 2016 John Wiley \& Sons, Ltd.",Wiley
"Xiao, Hang and Zhang, Zhengfeng and Kang, Huimin and Yang, Jun",Solid-State NMR Double-Quantum Dipolar Recoupling Enhanced by Additional Phase Modulation,2023,https://doi.org/10.1002/cphc.202300141,https://onlinelibrary.wiley.com/doi/abs/10.1002/cphc.202300141,Journal,ChemPhysChem,"Additional phase modulation (APM) is proposed to generally enhance the theoretical efficiency of homonuclear double-quantum (DQ) recoupling in solid-state NMR. APM applies an additional phase list to DQ recoupling in steps of an entire block. The sine-based phase list can enhance the theoretical efficiency by 15¨C30?\%, from 0.52 to 0.68 (non-¦Ã-encoded recoupling) or from 0.73 to 0.84 (¦Ã-encoded recoupling), with doubled recoupling time. The genetic-algorithm (GA) optimized APM can adiabatically enhance the efficiency to ?1.0 at longer times. The concept of APM has been tested on SPR-51, BaBa, and SPR-31, which represent ¦Ã-encoded recoupling, non-¦Ã-encoded recoupling, and another kind beyond the former two, respectively. Simulations reveal that enhancements from APM are due to the activation of more crystallites in the powder. Experiments on 2,3-13C labeled alanine are used to validate the APM recoupling. This new concept shall shed light on developing more efficient homonuclear recoupling methods.",Wiley
"Xu, Jie and Qian, Dingjun and Hu, Gensheng",Analysis on Simplified Method of IoT-based HHL Algorithm Corresponding Quantum Circuit for Quantum Computer Application,2023,https://doi.org/10.1155/2023/1063505,https://onlinelibrary.wiley.com/doi/abs/10.1155/2023/1063505,Journal,Mobile Information Systems,"Whether it is a traditional industry or a Frontier field, it has unveiled the trend of industrial IoT construction and application, which plays a vital role in building a strong manufacturing country and promoting high-quality economic development in China. HHL algorithm has become one of the important quantum algorithms, but there are few researches on the construction of quantum circuits and the application of quantum sequencing. In this paper, a model based on the quantum circuit corresponding to the HHL algorithm to deal with the quantum application problem is proposed. A quantum circuit based on HHL algorithm is used to solve the linear system, and the numerical solution of the target partial differential equation is obtained. Finally, the experimental analysis shows that, in the process of processing quantum computer application problems based on quantum circuit, it can reduce the computation amount of quantum circuit corresponding to HHL algorithm, improve the simulation efficiency of quantum circuit, and reduce the occupation of hardware resources, which has a certain effectiveness and superiority. This discussion brings new ideas for intelligent IoT technology and provides implications for the study of simplified methods of HHL algorithms corresponding to quantum circuits to deal with computer application problems.",Wiley
"Temel, Mehmet H¨¹seyin and ?kori?, Boris and Monroy, Idelfonso Tafur",Implementation of entropically secure encryption: Securing personal health data,2024,https://doi.org/10.1049/ell2.70065,https://onlinelibrary.wiley.com/doi/abs/10.1049/ell2.70065,Journal,Electronics Letters,"Entropically secure encryption (ESE) offers unconditional security with shorter keys compared to the One-Time Pad. Here, the first implementation of ESE for bulk encryption is presented. The main computational bottleneck for bulk ESE is a multiplication in a very large finite field. This involves multiplication of polynomials followed by modular reduction. A polynomial multiplication is implemented based on the gf2x library, with modifications that avoid inputs of vastly different length, thus improving speed. Additionally, a recently proposed efficient reduction algorithm that works for any polynomial degree is implemented. Two use cases are investigated: x-ray images of patients and human genome data. Entropy estimation is conducted using compression methods whose results determine the key lengths required for ESE. The running times for all steps of the encryption are reported. The potential of ESE to be used in conjunction with quantum key distribution (QKD), in order to achieve full information-theoretic security of QKD-protected links for these use cases is discussed.",Wiley
"Dogra, Ayush and Ahuja, Chirag Kamal and Kumar, Sanjeev",A multi-modality paradigm for CT and MRI fusion with applications of quantum image processing,2022,https://doi.org/10.1002/cpe.6610,https://onlinelibrary.wiley.com/doi/abs/10.1002/cpe.6610,Journal,Concurrency and Computation: Practice and Experience,"As pixel resolution continues to increase in images acquired from different sensors, the measurement of the correlation between pixels and their properties requires numerous processing steps over multiple iterations. Quantum image processing (QIP) is a technology capable of processing exponentially large volumes of data within polynomial time. One such application is image fusion. In the field of radiography, computerized tomography (CT) images provide the structural information of bone tissues, and magnetic resonance MR images can provide the visualization of gray-scale anatomical structures of soft tissues. With the help of CT and MR fusion, a composite image can be obtained containing information on both hard and soft tissues. Clinicians often have to switch between these modalities to trace various patterns for effective staging and diagnosis of various oncological diseases. In this study, a multilevel filtering-based image fusion algorithm that efficiently fuses information from CT and MR images into a single image has been proposed. First, source images are processed with a rolling guidance filter, and the detail layer is calculated. The base layer is then computed using guided filtering to ensure a high level of edge preservation. Furthermore, to minimize noise and artifacts, the detail layers are fused using the Karhunen¨CLoeve transform, and the base layers are combined using the weighted superimposition principle. Experimental results demonstrate that the proposed methodology is subjectively more efficient than the existing state-of-the-art methods.",Wiley
"Mortazavi, Bohayra",Recent Advances in Machine Learning-Assisted Multiscale Design of Energy Materials,,https://doi.org/10.1002/aenm.202403876,https://onlinelibrary.wiley.com/doi/abs/10.1002/aenm.202403876,Journal,Advanced Energy Materials,,Wiley
"Davydov, Denis and Young, Toby D. and Steinmann, Paul","On the adaptive finite element analysis of the Kohn¨CSham equations: methods, algorithms, and implementation",2016,https://doi.org/10.1002/nme.5140,https://onlinelibrary.wiley.com/doi/abs/10.1002/nme.5140,Journal,International Journal for Numerical Methods in Engineering,"Summary In this paper, details of an implementation of a numerical code for computing the Kohn¨CSham equations are presented and discussed. A fully self-consistent method of solving the quantum many-body problem within the context of density functional theory using a real-space method based on finite element discretisation of realspace is considered. Various numerical issues are explored such as (i) initial mesh motion aimed at co-aligning ions and vertices; (ii) a priori and a posteriori optimization of the mesh based on Kelly's error estimate; (iii) the influence of the quadrature rule and variation of the polynomial degree of interpolation in the finite element discretisation on the resulting total energy. Additionally, (iv) explicit, implicit and Gaussian approaches to treat the ionic potential are compared. A quadrupole expansion is employed to provide boundary conditions for the Poisson problem. To exemplify the soundness of our method, accurate computations are performed for hydrogen, helium, lithium, carbon, oxygen, neon, the hydrogen molecule ion and the carbon-monoxide molecule. Our methods, algorithms and implementation are shown to be stable with respect to convergence of the total energy in a parallel computational environment. Copyright ? 2015 John Wiley \& Sons, Ltd.",Wiley
"Sadeghi Pour, Ehsan and Esmaeili, Mahdi and Romoozi, Morteza",Employing Atrous Pyramid Convolutional Deep Learning Approach for Detection to Diagnose Breast Cancer Tumors,2023,https://doi.org/10.1155/2023/7201479,https://onlinelibrary.wiley.com/doi/abs/10.1155/2023/7201479,Journal,Computational Intelligence and Neuroscience,"Breast cancer is among the most common diseases and one of the most common causes of death in the female population worldwide. Early identification of breast cancer improves survival. Therefore, radiologists will be able to make more accurate diagnoses if a computerized system is developed to detect breast cancer. Computer-aided design techniques have the potential to help medical professionals to determine the specific location of breast tumors and better manage this disease more rapidly and accurately. MIAS datasets were used in this study. The aim of this study is to evaluate a noise reduction for mammographic pictures and to identify salt and pepper, Gaussian, and Poisson so that precise mass detection operations can be estimated. As a result, it provides a method for noise reduction known as quantum wavelet transform (QWT) filtering and an image morphology operator for precise mass segmentation in mammographic images by utilizing an Atrous pyramid convolutional neural network as the deep learning model for classification of mammographic images. The hybrid methodology dubbed QWT-APCNN is compared to earlier methods in terms of peak signal-to-noise ratio (PSNR) and mean square error (MSE) in noise reduction and detection accuracy for mass area recognition. Compared to state-of-the-art approaches, the proposed method performed better at noise reduction and segmentation according to different evaluation criteria such as an accuracy rate of 98.57\%, 92\% sensitivity, 88\% specificity, 90\% DSS, and ROC and AUC rate of 88.77.",Wiley
"Pereira, Florbela",Machine Learning for the Prediction of Ionization Potential and Electron Affinity Energies Obtained by Density Functional Theory,2023,https://doi.org/10.1002/slct.202300036,https://onlinelibrary.wiley.com/doi/abs/10.1002/slct.202300036,Journal,ChemistrySelect,"Quantum chemical (QC) calculations based on density functional theory (DFT) provide increasingly accurate estimates of various properties, but with a relatively high computational cost. Machine learning (ML) techniques can be envisaged to extract new knowledge from these large volumes of data, creating empirical models to fast predict QC calculations in new situations. Here, ML algorithms were explored for the fast estimation of ionization potential (IP) and electron affinity (EA) energies calculated by DFT using the B3LYP and PBE0 with 6¨C31G** basic set on molecular descriptors generated from DFT-optimized geometries. A database of 9,410 and 9,627 small organic structures for IP and EA energies modelling were used, respectively. Several ML algorithms such as random forest, support vector machines, deep learning multilayer perceptron networks, and light gradient-boosting machine were screened. The best performance was achieved with a consensus regression model predicted an external test set of 972 and 963 small organic molecules achieving a mean absolute error up to 0.23?eV and 0.32?eV for modelling IP and EA energies, respectively.",Wiley
"Siddi Moreau, Giuliana and Pisani, Lorenzo and Mameli, Andrea and Podda, Carlo and Cao, Giacomo and Prati, Enrico",Gravity Data Inversion by Adiabatic Quantum Computing,2024,https://doi.org/10.1002/qute.202300152,https://onlinelibrary.wiley.com/doi/abs/10.1002/qute.202300152,Journal,Advanced Quantum Technologies,"A quantum-enhanced implementation of the binary inversion method for gravity data acquisition is discussed. The subsurface structure of a single density anomaly with an assigned density contrast is calculated by using a D-Wave adiabatic quantum computer. In particular, an iterative heuristic based on quantum annealing that recovers a sharp shape of the subsurface anomaly is developed. Such a task is accomplished by collecting partial images obtained by quantum annealing processes for optimal Lagrange penalty coefficients. The results are compared with those obtained according to the same cost function minimized via genetic algorithms by conventional hardware on a realistic 2D dataset. The outcomes of this work are promising as the reconstructed model is obtained in tenths of iterations instead of the hundreds required in conventional methods. Moreover, for the part of the computation that resides in the quantum processing unit, the computational cost of the single quantum annealing descent is constant with respect to the number of degrees of freedom of the subsurface grid. The implemented method is likely to reveal its full potential on forthcoming quantum annealing devices, outperforming existing techniques.",Wiley
"Lu, Wang and Zhiyang, Li and Shuyao, Liu and Zhipeng, Wang and Entao, Sun and Song, Liu and Wenzheng, Gao",5-3: Predicting External Quantum Efficiency of Red Phosphorescent Organic Light-Emitting Devices by Machine Learning,2024,https://doi.org/10.1002/sdtp.16993,https://onlinelibrary.wiley.com/doi/abs/10.1002/sdtp.16993,Journal,SID Symposium Digest of Technical Papers,"As the core material that affects the performance of OLED devices, the demand for performance improvement of OLED materials is urgent. However, due to the molecular diversity of organic compounds, traditional methods of development are inefficient and expensive. Recently, the machine learning (ML) approach has attracted increasing attention in the field of organic luminescent materials, which can learn from the existing results and provide the relation between the input features to the output performance. By constructing the relationship between molecular structure and device performance of OLED, the efficiency of material development is higher and guidance for material design is better provided through the identification of molecular key factors. In this work, we attempt to use the ML approach to explore the quantificational relation between the external quantum efficiency (EQE) of red phosphorescent organic light-emitting devices (OLEDs) and their material and device structural factors, aiming to screen out the key factors governing the EQE and predict EQE values directly by molecular structure. We established the dataset based on over 1000 device data from experiment, and reduced the number of molecular descriptors to below 35. Currently, the root mean squared error (RMSE) of test set has been lowered to 3.21\%. These results provide essential guidance for material screening and experimental device optimization. On this basis, we further designed new red host materials, which have higher EQE, up to 27.56\%. It has reached the first-class level of commercial materials.",Wiley
"Spyroglou, Ioannis and Rybka, Krystyna and Czembor, Pawe? and Piaskowska, Dominika and Pernisov¨¢, Mark¨¦ta and Matysik, Przemys?aw",Higher alterations in leaf fluorescence parameters of wheat cultivars predict more extensive necrosis in response to Zymoseptoria tritici,2022,https://doi.org/10.1111/ppa.13569,https://onlinelibrary.wiley.com/doi/abs/10.1111/ppa.13569,Journal,Plant Pathology,"Septoria tritici blotch (STB) is one of the main causes of wheat yield loss in the world. Apart from good agrotechnical practice, disease-resistant cultivars are required to prevent yield losses. Breeding of such cultivars is time-consuming and laborious, mainly due to the quantitative character of such resistance, but can be shortened using precise phenotyping. We show that fluorescence parameters, collected in a high-throughput system, can be used for estimating wheat STB resistance. Using machine learning methods (deep learning network, random forest), we demonstrate that disease resistance based on the percentage of necrotic leaf area can be estimated by alterations in fluorescence parameters 8 days after inoculation, and before disease symptoms become visible. Moreover, we applied a random forest classifier to assess the significance of fluorescence parameters in an informative way (classification accuracy = 64.84\%, p value [Accuracy >No information rate] <0.001). Based on this, we observed extensive alterations in parameters of sensitive cultivars, reflecting worse photosynthetic performance. The most highly altered parameters were fluorescence intensity measurements and descriptors of energy flux through photosystem II (PSII) reaction centres towards PSI such as F2, F3 and F4 fluorescence intensities at 0.1, 0.270 and 2 ms; initial to maximal fluorescence ratio (F0/Fm); the time derivative of relative variable fluorescence (dV/dT0); maximum quantum yield of PSII in the dark-adapted state (Fv/Fm); maximum electron transport flux at PSII (ET0/RC); maximum trapped excitonic energy flux per excited PSII cross section (CS) at time T0 (TR0/CS0); and quantum efficiency of the reduction of end acceptors dR0 [dR0/(1 ? dR0)].",Wiley
"Jamasb, Ali and Motavalli-Anbaran, Seyed-Hani and Zeyen, Hermann","Non-linear stochastic inversion of gravity data via quantum-behaved particle swarm optimisation: application to Eurasia¨CArabia collision zone (Zagros, Iran)",2017,https://doi.org/10.1111/1365-2478.12558,https://onlinelibrary.wiley.com/doi/abs/10.1111/1365-2478.12558,Journal,Geophysical Prospecting,"ABSTRACT Potential field data such as geoid and gravity anomalies are globally available and offer valuable information about the Earth's lithosphere especially in areas where seismic data coverage is sparse. For instance, non-linear inversion of Bouguer anomalies could be used to estimate the crustal structures including variations of the crustal density and of the depth of the crust¨Cmantle boundary, that is, Moho. However, due to non-linearity of this inverse problem, classical inversion methods would fail whenever there is no reliable initial model. Swarm intelligence algorithms, such as particle swarm optimisation, are a promising alternative to classical inversion methods because the quality of their solutions does not depend on the initial model; they do not use the derivatives of the objective function, hence allowing the use of L1 norm; and finally, they are global search methods, meaning, the problem could be non-convex. In this paper, quantum-behaved particle swarm, a probabilistic swarm intelligence-like algorithm, is used to solve the non-linear gravity inverse problem. The method is first successfully tested on a realistic synthetic crustal model with a linear vertical density gradient and lateral density and depth variations at the base of crust in the presence of white Gaussian noise. Then, it is applied to the EIGEN 6c4, a combined global gravity model, to estimate the depth to the base of the crust and the mean density contrast between the crust and the upper-mantle lithosphere in the Eurasia¨CArabia continental collision zone along a 400 km profile crossing the Zagros Mountains (Iran). The results agree well with previously published works including both seismic and potential field studies.",Wiley
"CAO, W. and SUN, T. and FARDELL, G. and PRICE, B. and DEWULF, W.",Comparative performance assessment of beam hardening correction algorithms applied on simulated data sets,2018,https://doi.org/10.1111/jmi.12746,https://onlinelibrary.wiley.com/doi/abs/10.1111/jmi.12746,Journal,Journal of Microscopy,"Summary Beam hardening artefacts deteriorate the reconstructed image quality in industrial computed tomography. The appearances of beam hardening artefacts can be cupping effects or streaks. They impair the image fidelity to the object being scanned. This work aims at comparing a variety of commonly used beam hardening correction algorithms in the context of industrial computed tomography metrology. We choose four beam hardening correction algorithms of different types for the comparison. They are a single-material linearization algorithm, a multimaterial linearization algorithm, a dual-energy algorithm and an iterative reconstruction algorithm. Each beam hardening correction algorithm is applied to simulated data sets of a dual-material phantom consisting of multiple rods. The comparison is performed on data sets simulated both under ideal conditions and with the addition of quantum noise. The performance of each algorithm is assessed with respect to its effect on the final image quality (contrast-to-noise ratio, spatial resolution), artefact reduction (streaks, cupping effects) and dimensional measurement deviations. The metrics have been carefully designed in order to achieve a robust and quantifiable assessment. The results suggest that the single-material linearization algorithm can reduce beam hardening artefacts in the vicinity of one material. The multimaterial linearization algorithm can further reduce beam hardening artefacts induced by the other material and improve the dimensional measurement accuracy. The dual-energy method can eliminate beam hardening artefacts, and improve the low contrast visibility and dimensional measurement accuracy. The iterative algorithm is able to eliminate beam hardening streaks. However, it induces aliasing patterns around the object edge, and its performance depends critically upon computational power. The contrast-to-noise ratio and spatial resolution are declined by noise. Noise also increases the difficulty of image segmentation and quantitative analysis. Lay Description X-ray computed tomography (CT) is a major breakthrough in digital imaging technology in the late 20th century. First used as an important tool in medical imaging, CT has gradually introduced to the nonmedical areas (e.g. industrial nondestructive testing). Inherently CT is more prone to artefacts comparing to the conventional real-time X-ray image. Beam hardening artefacts caused by the polychromatic nature of X-ray spectra are known to deteriorate the reconstructed image quality in industrial CT. A number of beam hardening correction algorithms exist and are used across medical CT. However, there is a lack of research on their effectiveness on industrial CT. This study presents an in-depth beam hardening correction algorithm comparison in industrial CT. Since this study takes various factors of the algorithm performance into account, it provides insights of the advantages and disadvantages of each algorithm and assists the choice of algorithm to meet specific needs of industry. Existing beam hardening correction algorithms are divided into the following four categories: linearization, segmentation based linearization, dual-energy and iterative methods. Since the linearization method can only correct single-material objects, we did not include it in the comparative study. Among the remaining categories, we chose one from each category for comparison, for methods in one peer category share similar physical and mathematical principles. The methods are polynomial fit, Joseph segmentation, dual energy and IMPACT iterative method. This study uses a simulated polychromatic data set of a multimaterial phantom. The central slice of the corrected reconstructions is then assessed and the results are presented. In this study, we will compare beam hardening correction methods with respect to their performance on image quality, the removal of image artefacts and the influence on dimensional accuracy.",Wiley
"Ortega, Sergio A. and Martin-Delgado, Miguel A.",SQUWALS: A Szegedy QUantum WALks Simulator,2024,https://doi.org/10.1002/qute.202400022,https://onlinelibrary.wiley.com/doi/abs/10.1002/qute.202400022,Journal,Advanced Quantum Technologies,"Szegedy's quantum walk is an algorithm for quantizing a general Markov chain. It has plenty of applications, such as many variants of optimizations. In order to check its properties in an error-free environment, it is important to have a classical simulator. However, the current simulation algorithms require a great deal of memory due to the particular formulation of this quantum walk. In this paper, a memory-saving algorithm is proposed that scales as O(N2)\$\mathcal {O}(N^2)\$ with the size N\$N\$ of the graph. Additional procedures are provided for simulating Szegedy's quantum walk over mixed states and also the Semiclassical Szegedy walk. With these techniques, a classical simulator in Python called SQUWALS (Szegedy QUantum WALks Simulator) has been built. It is shown that the simulator scales as O(N2)\$\mathcal {O}(N^2)\$ in both time and memory resources. This package provides some high-level applications for algorithms based on Szegedy's quantum walk, as for example the quantum PageRank.",Wiley
"Lee, Hoon Jeong and Chiu, Arlene and Lin, Yida and Chintapalli, Sreyas and Kamal, Serene and Ji, Eric and Thon, Susanna M.",Predicting PbS Colloidal Quantum Dot Solar Cell Parameters Using Neural Networks Trained on Experimental Data,,https://doi.org/10.1002/aisy.202400310,https://onlinelibrary.wiley.com/doi/abs/10.1002/aisy.202400310,Journal,Advanced Intelligent Systems,,Wiley
"Han, Kehang and Jamal, Adeel and Grambow, Colin A. and Buras, Zachary J. and Green, William H.",An Extended Group Additivity Method for Polycyclic Thermochemistry Estimation,2018,https://doi.org/10.1002/kin.21158,https://onlinelibrary.wiley.com/doi/abs/10.1002/kin.21158,Journal,International Journal of Chemical Kinetics,"ABSTRACT Automatic kinetic mechanism generation, virtual high-throughput screening, and automatic transition state search are currently trending applications requiring exploration of a large molecule space. Large-scale search requires fast and accurate estimation of molecules' properties of interest, such as thermochemistry. Existing approaches are not satisfactory for large polycyclic molecules: considering the number of molecules being screened, quantum chemistry (even cheap density functional theory methods) can be computationally expensive, and group additivity, though fast, is not sufficiently accurate. This paper provides a fast and moderately accurate alternative by proposing a polycyclic thermochemistry estimation method that extends the group additivity method with two additional algorithms: similarity match and bicyclic decomposition. It significantly reduces Hf(298 K) estimation error from over 60 kcal/mol (group additivity method) to around 5 kcal/mol, Cp(298 K) error from 9 to 1 cal/mol/K, and S(298 K) error from 70 to 7 cal/mol/K. This method also works well for heteroatomic polycyclics. A web application for estimating thermochemistry by this method is made available at http://rmg.mit.edu/molecule\_search.",Wiley
"Li, Yangyang and Chen, Zhenghan and Wang, Yang and Jiao, Licheng and Xue, Yu",A Novel Distributed Quantum-Behaved Particle Swarm Optimization,2017,https://doi.org/10.1155/2017/4685923,https://onlinelibrary.wiley.com/doi/abs/10.1155/2017/4685923,Journal,Journal of Optimization,"Quantum-behaved particle swarm optimization (QPSO) is an improved version of particle swarm optimization (PSO) and has shown superior performance on many optimization problems. But for now, it may not always satisfy the situations. Nowadays, problems become larger and more complex, and most serial optimization algorithms cannot deal with the problem or need plenty of computing cost. Fortunately, as an effective model in dealing with problems with big data which need huge computation, MapReduce has been widely used in many areas. In this paper, we implement QPSO on MapReduce model and propose MapReduce quantum-behaved particle swarm optimization (MRQPSO) which achieves parallel and distributed QPSO. Comparisons are made between MRQPSO and QPSO on some test problems and nonlinear equation systems. The results show that MRQPSO could complete computing task with less time. Meanwhile, from the view of optimization performance, MRQPSO outperforms QPSO in many cases.",Wiley
"Telford, William",Deep ultraviolet 266?nm laser excitation for flow cytometry,2024,https://doi.org/10.1002/cyto.a.24813,https://onlinelibrary.wiley.com/doi/abs/10.1002/cyto.a.24813,Journal,Cytometry Part A,"High dimensional flow cytometry relies on multiple laser sources to excite the wide variety of fluorochromes now available for immunophenotyping. Ultraviolet lasers (usually solid state 355?nm) are a critical part of this as they excite the BD Horizon? Brilliant Ultraviolet (BUV) series of polymer fluorochromes. The BUV dyes have increased the number of simultaneous fluorochromes available for practical high-dimensional analysis to greater than 40 for spectral cytometry. Immunologists are now seeking to increase this number, requiring both novel fluorochromes and additional laser wavelengths. A laser in the deep ultraviolet (DUV) range (from ca. 260 to 320?nm) has been proposed as an additional excitation source, driven by the on-going development of additional polymer dyes with DUV excitation. DUV lasers emitting at 280 and 320?nm have been previously validated for flow cytometry but have encountered practical difficulties both in probe excitation behavior and in availability. In this article, we validate an even shorter DUV 266?nm laser source for flow cytometry. This DUV laser provided minimal excitation of the BUV dyes (a desirable characteristic for high-dimensional analysis) while demonstrating excellent excitation of quantum nanoparticles (Qdots) serving as surrogate fluorochromes for as yet undeveloped DUV excited dyes. DUV 266?nm excitation may therefore be a viable candidate for expanding high-dimensional flow cytometry into the DUV range and providing an additional incidental excitation wavelength for spectral cytometry. Excitation in a spectral region with strong absorption by nucleic acids and proteins (260¨C280?nm) did result in strong autofluorescence requiring care in fluorochrome selection. DUV excitation of endogenous molecules may nevertheless have additional utility for label-free analysis applications.",Wiley
"Li, Chaojie and Zhong, Jiyou",Efficient and Thermally Robust Broadband Near-Infrared Emission in a Garnet Ca3MgHfGe3O12:Cr3+ Phosphor,2023,https://doi.org/10.1002/adom.202202323,https://onlinelibrary.wiley.com/doi/abs/10.1002/adom.202202323,Journal,Advanced Optical Materials,"Near-infrared (NIR) spectroscopy based on phosphor-converted light-emitting-diode (pc-LED) has promising applications in food quality analysis, security monitoring, medical diagnosis, and bioimaging fields, stimulating the demand of developing NIR phosphors with high-performance. Herein, a highly efficient and thermally robust Ca3MgHfGe3O12:Cr3+ NIR phosphor is discovered, which exhibits a broadband NIR emission (¦Ëem = 800 nm) covering 700 to 1100 nm region with an internal quantum efficiency as high as 90.7\% when excited by 460 nm blue light. Moreover, the emission intensity at 423 K retains 84.5\% of that at room temperature. The highly efficient and thermally robust luminescence of this material is mainly ascribed to the ultrawide bandgap of host, extremely weak electron¨Cphoton coupling effect, defect-free, and highly structural rigidity. The NIR pc-LED device fabricated by using the optimized Ca3Mg0.97Hf0.97Ge3O12:0.06Cr3+ phosphor combined with blue (¦Ëem = 455 nm) LED chip produces an excellent NIR output power of 49.5 mW @ 11.5\% under a driving current of 150 mA, which indicates a superiority to the device fabricated by using the well-known efficient ScBO3:Cr3+ phosphor under the same condition. Therefore, this work not only provides a promising broadband NIR material, but also highlights the design rules for searching high-performance NIR materials toward spectroscopy applications.",Wiley
"C, Selvan and Govinda Rajulu, G. and Padmanaban, K. and Aghalya, S.",A Distributed Mobile Edge Computing Based Dynamic Resource Allocation in 5G Network Using Green Anaconda Optimization Based Deep Learning Network,,https://doi.org/10.1002/dac.6050,https://onlinelibrary.wiley.com/doi/abs/10.1002/dac.6050,Journal,International Journal of Communication Systems,,Wiley
"Ertl, Peter and Gerebtzoff, Gr¨¦gori and Lewis, Richard and Muenkler, Hagen and Schneider, Nadine and Sirockin, Finton and Stiefl, Nikolaus and Tosco, Paolo",Chemical Reactivity Prediction: Current Methods and Different Application Areas,2022,https://doi.org/10.1002/minf.202100277,https://onlinelibrary.wiley.com/doi/abs/10.1002/minf.202100277,Journal,Molecular Informatics,"The ability to predict chemical reactivity of a molecule is highly desirable in drug discovery, both ex vivo (synthetic route planning, formulation, stability) and in?vivo: metabolic reactions determine pharmacodynamics, pharmacokinetics and potential toxic effects, and early assessment of liabilities is vital to reduce attrition rates in later stages of development. Quantum mechanics offer a precise description of the interactions between electrons and orbitals in the breaking and forming of new bonds. Modern algorithms and faster computers have allowed the study of more complex systems in a punctual and accurate fashion, and answers for chemical questions around stability and reactivity can now be provided. Through machine learning, predictive models can be built out of descriptors derived from quantum mechanics and cheminformatics, even in the absence of experimental data to train on. In this article, current progress on computational reactivity prediction is reviewed: applications to problems in drug design, such as modelling of metabolism and covalent inhibition, are highlighted and unmet challenges are posed.",Wiley
"Singh, Ajay Vikram and Varma, Mansi and Rai, Mansi and Pratap Singh, Shubham and Bansod, Girija and Laux, Peter and Luch, Andreas","Advancing Predictive Risk Assessment of Chemicals via Integrating Machine Learning, Computational Modeling, and Chemical/Nano-Quantitative Structure-Activity Relationship Approaches",2024,https://doi.org/10.1002/aisy.202300366,https://onlinelibrary.wiley.com/doi/abs/10.1002/aisy.202300366,Journal,Advanced Intelligent Systems,"The escalating use of novel chemicals and nanomaterials (NMs) across diverse sectors underscores the need for advanced risk assessment methods to safeguard human health and the environment. Traditional labor-intensive approaches have given way to computational methods. This review integrates recent developments in chemical and nano-quantitative structure-activity relationship (QSAR) with machine learning and computational modeling, offering a comprehensive predictive assessment of NMs and chemicals. It explores nanodescriptors, their role in predicting toxicity, and the amalgamation of machine learning algorithms with chemical and nano-QSAR for improved risk assessment accuracy. The article also investigates computational modeling techniques like molecular dynamics simulations, molecular docking, and molecular mechanics/quantum mechanics for predicting physical and chemical properties. By consolidating these approaches, the review advocates for a more accurate and efficient means of assessing risks associated with NMs/chemicals, promoting their safe utilization and minimizing adverse effects on human health and the environment. A valuable resource for researchers and practitioners, informed decision-making, advancing our understanding of potential risks, is facilitated. Beyond studying systems at various scales, computational modeling integrates data from diverse sources, enhancing risk assessment accuracy and fostering the safe use of NMs/chemicals while minimizing their impact on human health and the environment.",Wiley
"Malhotra, Atul and Kaur, Sanmeet",A quality of service-aware routing protocol for FANETs,2024,https://doi.org/10.1002/dac.5723,https://onlinelibrary.wiley.com/doi/abs/10.1002/dac.5723,Journal,International Journal of Communication Systems,"Summary Flying ad hoc networks (FANETs) are a class of highly dynamic mobile ad hoc networks in which flying UAVs coordinate among themselves for delivering the data to the applications. Data routing in FANETs has been a challenge due to the inherent mobile and unpredictable movement of UAV nodes. This paper proposes a quality of service-aware routing protocol (QARP) for FANETs which incorporates hybrid nature-inspired heuristics to identify optimized routes to the destination UAVs. The routing mechanism operates in two phases. In the first phase, the neighbour discovery initializes the adapted firefly algorithm to identify nodes with least packet delivery delay to the destination. In the second phase, the Gaussian quantum-behaved particle swarm optimization meta-heuristic algorithm is utilized to identify the most optimal nodes to create a route for data delivery to destination. The proposed protocol has been tested to perform better in terms of delay, routing overhead, throughput and packet delivery ratio in comparison to MA-DP-AODV, MDA-AODV and MDRMA routing protocols.",Wiley
"Feng, Yan-Y. and Zhou, Jian and Zhang, Dan-B. and Shi, Jin-J.",Parameterized Quantum Circuits for Learning Cooperative Quantum Teleportation,2022,https://doi.org/10.1002/qute.202200040,https://onlinelibrary.wiley.com/doi/abs/10.1002/qute.202200040,Journal,Advanced Quantum Technologies,"Quantum teleportation is an elemental process in quantum communication and many variants have been widely investigated theoretically and experimentally. Motivated by cooperation in classical communications, cooperative quantum teleportation (CQT) are developed with features of the cooperation referring to allocation of resources and operations among participants. Parameterized quantum circuit (PQC) are employed to learn the CQT protocols on account of different training scenarios with controls of gate parameters among shared entangled states, measurement, and recovery operations. Numerical results show the CQT protocols can be discovered with unit fidelity regardless of ideal or nonideal channels by training the PQCs with hybrid quantum-classical (HQC) optimization under full cooperations of the participants. Further, the influence of quantum channel noise on the teleportation performance is explored by parameterizing the entangled states with noise and entanglement parameters under adjustable recovery operations. Simulation results indicate the trained PQC can improve the system performance, which implies the potential denoising capability of the HQC algorithms. The suggested CQT protocols satisfy the underlying properties of universality, randomness, locality and cooperation, and discussions indicate the designed quantum circuits can be optimized in view of quantum and circuit costs by appropriate optimization algorithms for achieving higher state fidelity in the future work.",Wiley
"Li, Yifan and Hu, Jiaqi and Zhang, Xiao-Ming and Song, Zhigang and Yung, Man-Hong",Variational Quantum Simulation for Quantum Chemistry,2019,https://doi.org/10.1002/adts.201800182,https://onlinelibrary.wiley.com/doi/abs/10.1002/adts.201800182,Journal,Advanced Theory and Simulations,"Variational quantum-classical hybrid algorithms are emerging as important tools for simulating quantum chemistry with quantum devices. These algorithms can be applied to evaluate various molecular properties, including potential energy surfaces. Here in, recent progresses on the development of the so-called variational quantum eigensolver (VQE) are surveyed. The eigensolver aims at reducing the consumption of quantum resources as much as possible. The key feature of VQE is that variation quantum states are optimized by a feedback process, where the measurement of the Hamiltonian is implemented term by term. This approach avoids the need of encoding all of the information about the molecular Hamiltonian in a quantum circuit. The VQE method is also compatible with classical methods in quantum chemistry, such as unitary coupled-cluster ansatz. Furthermore, basic elements of VQE are covered, such as qubit encoding, mapping rules of the fermionic operators, ansatz preparation, together with several techniques for improving the performance, including constraining, and error mitigation.",Wiley
"Bai, Yunpeng and Wang, Guangwen and Lan, Jinhua and Wu, Ping and Liang, Guowu and Huang, Jinhui and Wu, Zheng and Wang, Yirong and Chen, Chunbo",Mass Spectrometric Behavior and Molecular Mechanisms of Fermented Deoxyanthocyanidins to Alleviate Ulcerative Colitis Based on Network Pharmacology,2022,https://doi.org/10.1155/2022/9293208,https://onlinelibrary.wiley.com/doi/abs/10.1155/2022/9293208,Journal,International Journal of Analytical Chemistry,"Aims. Ulcerative colitis (UC) is a type of chronic idiopathic inflammatory bowel disease with a multifactorial pathogenesis and limited treatment options. The aim of the present study is to investigate the hydrogen deuterium exchange mass spectrometry (HDX-MS) behaviors of fermented deoxyanthocyanidins and their molecular mechanisms to alleviate UC by using quantum chemistry and network pharmacology. Methods. Tandem MS indicated at least two fragmentation pathways through which deuterated vinylphenol-deoxyanthocyanidins could generate different product ions. Quantum calculations were conducted to determine the transition states of the relevant molecules and analyze their optimized configuration, vibrational characteristics, intrinsic reaction coordinates, and corresponding energies. The potential targets of deoxyanthocyanidins in UC were screened from a public database. The R package was used for Gene Ontology (GO) and KEGG pathway analyses, and the protein¨Cprotein interactions (PPIs) of the targets were assessed using Search Tool for the Retrieval of Interacting Genes (STRING). Finally, molecular docking was implemented to analyze the binding energies and action modes of the target compounds through the online tool CB-Dock. Results. Quantum calculations indicated two potential fragmentation pathways involving the six-membered ring and dihydrogen cooperative transfer reactions of the vinylphenol-deoxyanthocyanidins. A total of 146 and 57 intersecting targets of natural and fermented deoxyanthocyanidins were separately screened out from the UC database and significant overlaps in GO terms and KEGG pathways were noted. Three shared hub targets (i.e., PTGS2, ESR1, and EGFR) were selected from the two PPI networks by STRING. Molecular docking results showed that all deoxyanthocyanidins have a good binding potential with the hub target proteins and that fermented deoxyanthocyanidins have lower binding energies and more stable conformations compared with natural ones. Conclusions. Deoxyanthocyanidins may provide anti-inflammatory, antioxidative, and immune system regulatory effects to suppress UC progression. It is proposed for the first time that fermentation of deoxyanthocyanidins can help adjust the structure of the intestinal microbiota and increase the biological activity of the natural compounds against UC. Furthermore, HDX-MS is a helpful strategy to analyze deoxyanthocyanidin metabolites with unknown structures.",Wiley
"Zhu, Hongxia and Fan, Liqiang",Application of Improved Deep Belief Network Based on Intelligent Algorithm in Stock Price Prediction,2022,https://doi.org/10.1155/2022/9362283,https://onlinelibrary.wiley.com/doi/abs/10.1155/2022/9362283,Journal,Mathematical Problems in Engineering,"In order to improve the prediction accuracy of stock price, an improved model QPSO-DBN-GABP using quantum particle swarm optimization algorithm to optimize deep belief network is proposed. In this model, the quantum particle swarm optimization algorithm is used to find the optimal combination of the number of neurons in each layer of RBM, and the genetic algorithm is used to optimize the initial weight and threshold of BP neural network, so as to obtain the optimized combination prediction model. The prediction results are compared with those of DBN, PSO-DBN, and QPSO-DBN models. Through the comparison of experimental results, it is found that compared with the above three prediction models, the prediction error index RMSE of the model is reduced by about 10.1\%, 9.1\%, 1.3\%, and MAE is reduced by 8.1\%, 5.7\%, and 0.67\%. The prediction accuracy of the model is improved to 96.435\%.",Wiley
"van der Burgt, Julia S. and Scalerandi, Francesca and de Boer, Jeroen J. and Rigter, Susan A. and Garnett, Erik C.",Perovskite Plasticity: Exploiting Instability for Self-Optimized Performance,2022,https://doi.org/10.1002/adfm.202203771,https://onlinelibrary.wiley.com/doi/abs/10.1002/adfm.202203771,Journal,Advanced Functional Materials,"Halide perovskites display outstanding photoluminescence quantum yield, tunable emission, and simple deposition, which make them attractive for optoelectronics. At the same time, their facile ion migration and transformation under optical, electrical, and chemical stress are seen as a major limitation. Mixed halide perovskites are particularly problematic since optical excitation can cause changes in the bandgap that are detrimental for solar cell and light-emitting diode efficiency and stability. In this work, instead of preventing such changes, photo-induced halide segregation in perovskites is exploited to enable responsive, reconfigurable, and self-optimizing materials. The mixed halide perovskite film is trained to give directional light emission using a nanophotonic microlens; through a self-optimized process of halide photosegregation, the system mimics the training stimulus. Longer training leads to more highly directional emission, while different halide migration kinetics in the light (fast training) and dark (slow forgetting) allows for material memory. This self-optimized material performs significantly better than lithographically aligned quantum dots because it eliminates lens-emitter misalignment and automatically corrects for lens aberrations. The system shows a combination of mimicking, improving over time, and memory, which comprise the basic requirements for learning, and allow for the intriguing prospect of intelligent optoelectronic materials.",Wiley
"Luo, Hao and Wang, Hanqing and Yang, Lijun and Wu, Han and Kang, Shenglin and Yong, Shun and Liao, Ruijin and Wang, Jiyu and Wang, Zhong Lin",In Situ Nanofluid Dispersion Monitoring by Liquid¨CSolid Triboelectric Nanogenerator Based on Tuning the Structure of the Electric Double Layer,2022,https://doi.org/10.1002/adfm.202200862,https://onlinelibrary.wiley.com/doi/abs/10.1002/adfm.202200862,Journal,Advanced Functional Materials,"An agglomeration phenomenon characterized by nanoparticle dispersion is a decisive factor that reflects the degree of the maintained overall performance of nanofluids and other nanocomposites. However, the quantitative characterization and non-destructive measurement for nanofluid dispersion (NFD) still remain challenged. Herein, an in situ NFD measurement system based on a variable frequency liquid¨Csolid triboelectric nanogenerator (VFLS-TENG) is developed. This work utilizes VFLS-TENG as a passive probe and proposes an equivalent capacitance circuit model for detecting NFD based on the electric double layer model at liquid¨Csolid interfaces. In the circuit model, a quantitative calculation process for both particle size and spacing is introduced through parameter identification using the Quantum Genetic and Levenberg¨CMarquardt hybrid algorithm, and parameter separation using the Runge¨CKutta algorithm. The results demonstrates a good agreement with the traditional methods, among which the measured particle size is more accurate than the hydrodynamic diameter of dynamic light scattering by 28.6\% with a high sensitivity of 1667 nm nF?1. The proposed method is capable of measuring the effective charge on the nanoparticle surface in situ, and simultaneously obtaining the particle size and spacing for the online monitoring NFD, thus further facilitating the controllable preparation during the nano-composites modification, and quantitative optimization of nanofluid design performance.",Wiley
"Xu, Baoyu and Zhang, Hongjun and Wang, Zhiteng and Wang, Huaixiao and Zhang, Youliang",Model and Algorithm of BP Neural Network Based on Expanded Multichain Quantum Optimization,2015,https://doi.org/10.1155/2015/362150,https://onlinelibrary.wiley.com/doi/abs/10.1155/2015/362150,Journal,Mathematical Problems in Engineering,"The model and algorithm of BP neural network optimized by expanded multichain quantum optimization algorithm with super parallel and ultra-high speed are proposed based on the analysis of the research status quo and defects of BP neural network to overcome the defects of overfitting, the random initial weights, and the oscillation of the fitting and generalization ability along with subtle changes of the network parameters. The method optimizes the structure of the neural network effectively and can overcome a series of problems existing in the BP neural network optimized by basic genetic algorithm such as slow convergence speed, premature convergence, and bad computational stability. The performance of the BP neural network controller is further improved. The simulation experimental results show that the model is with good stability, high precision of the extracted parameters, and good real-time performance and adaptability in the actual parameter extraction.",Wiley
"Irfan, Ahmad and Hussien, Mohamed and Mehboob, Muhammad Yasir and Ahmad, Aziz and Janjua, Muhammad Ramzan Saeed Ashraf",Learning from Fullerenes and Predicting for Y6: Machine Learning and High-Throughput Screening of Small Molecule Donors for Organic Solar Cells,2022,https://doi.org/10.1002/ente.202101096,https://onlinelibrary.wiley.com/doi/abs/10.1002/ente.202101096,Journal,Energy Technology,"In recent years, research on the development of organic solar cells has increased significantly. For the last few years, machine learning (ML) has been gaining the attention of the scientific community working on organic solar cells. Herein, ML is used to screen small molecule donors for organic solar cells. ML models are fed by molecular descriptors. Various ML models are employed. The predictive capability of a support vector machine is found to be higher (Pearson's coefficient?=?0.75). The best small donors with fullerene acceptors are selected to pair with Y6. New small molecule donors are also designed taking into account quantum chemistry principles, using building units that are searched through similarity analysis. Their energy levels and power conversion efficiencies (PCEs) are predicted. Efficient small molecule donors with PCE?>?13\% are selected. This design and discovery pipeline provides an easy and fast way to select potential candidates for experimental work.",Wiley
"Mathavan, Nagaraj and Siva Ranjani, Seenivasan and Suresh, Seetharaman and Bhuvanesh, Ananthan",Application of optimization algorithm for virtual reference tag assisted localization and tracking of RFID,2024,https://doi.org/10.1002/dac.5807,https://onlinelibrary.wiley.com/doi/abs/10.1002/dac.5807,Journal,International Journal of Communication Systems,"Summary In an indoor setting, the radio frequency communication is utilized to locate and track mobile objects utilizing Radio Frequency Identification (RFID) technology. Measurements from the Received Signal Strength Indicator (RSSI) are typically the foundation of the localization technique. In an RFID-based interior setting, lowering tracking mistakes and increasing the precision of tracking remain difficult tasks. In order to address these issues, we developed the VIRALTRACK (Virtual Reference Tag Localization and Tracking) framework that consists of four procedures: deep reinforced learning-based tracking, quantum-based localization, optimization-based virtual reference tag allocation, and signal enhancement. In order to increase the signal's effectiveness, we initially suggested using the Extended Gradient Filter (EGF) technique to eliminate RSSI oscillations. In the second step, we suggested using the Emperor Penguin Colony (EPC) optimization technique to allocate the virtual reference tag while taking the number of tags, SNR, and temperature and humidity of the surroundings into account. In the third phase, we use a quantum neural network (QNN) for localization in order to estimate the position of the moving target. We introduced the SignRank approach to select the best virtual reference tag for localization, which lowers tracking mistakes. In conclusion, we presented the Twin Delayed Deep Deterministic Policy Gradient (TD3) method that boosts the tracking precision by tracking the moving target tag efficiently and taking into account stage, the orientation, distance, and valuable coordinates. The NS3.26 network simulator is used to run the simulation, and tracking precision, tracking error, and accumulated probabilities are used to assess effectiveness.",Wiley
"Wang, Huan and Liu, Ruigang and Wang, Peng and Liu, Guanghua and Wang, Hao and Yan, Liping",Intelligent optimization of dynamic traffic light control via diverse optimization priorities,2021,https://doi.org/10.1002/int.22567,https://onlinelibrary.wiley.com/doi/abs/10.1002/int.22567,Journal,International Journal of Intelligent Systems,"Given the distribution difference of the vehicle flow in different urban areas, coordinating the optimization priorities of crossroads in the dynamic control of traffic lights is vital. To reduce traffic congestion at crossroads, in this study, an intelligent diverse optimization priority method (IDOPM) was developed for dynamic traffic light control at crossroads, where diverse optimization priorities can be flexibly and efficiently assigned to different crossroads. The IDOPM mainly consists of a dynamic state constructor and an optimization priority assigner. The dynamic state constructor controls the transformation of the signal combinations of traffic lights. The signal combinations of traffic lights at crossroads are abstracted as cells to be controlled by formulated rules. By designing duration particles and enhancing particles, the optimization priority assigner reconstructs the quantum particle swarm algorithm to assign crossroads with different optimization priorities. The results obtained by comparison with state-of-the-art methods via extensive experiments confirmed the outstanding optimization performance of the proposed IDOPM in dynamic traffic light control.",Wiley
"Lin, Liyun and Liu, Jiaxin and Pan, Zhengyuan and Pang, Wen and Jiang, Xinyan and Lei, Man and Gao, Jucai and Xiao, Yujie and Li, Bo and Hu, Fang and Bao, Zhouzhou and Wei, Xunbin and Wu, Wenbo and Gu, Bobo",General Post-Regulation Strategy of AIEgens¡¯ Photophysical Properties for Intravital Two-Photon Fluorescence Imaging,2024,https://doi.org/10.1002/advs.202404792,https://onlinelibrary.wiley.com/doi/abs/10.1002/advs.202404792,Journal,Advanced Science,"Fluorogens with aggregation-induced emission (AIEgens) are promising agents for two-photon fluorescence (TPF) imaging. However, AIEgens¡¯ photophysical properties are fixed and unoptimizable once synthesized. Therefore, it is urgent and meaningful to explore an efficient post-regulation strategy to optimize AIEgens¡¯ photophysical properties. Herein, a general and efficient post-regulation strategy is reported. By simply tuning the ratio of inert AIEgens within binary nanoparticles (BNPs), the fluorescence quantum yield and two-photon absorption cross-section of functional AIEgens are enhanced by 8.7 and 5.4 times respectively, which are not achievable by conventional strategies, and the notorious phototoxicity is almost eliminated. The experimental results, theoretical simulation, and mechanism analysis demonstrated its feasibility and generality. The BNPs enabled deep cerebrovascular network imaging with ¡Ö1.10 mm depth and metastatic cancer cell detection with single-cell resolution. Furthermore, the TPF imaging quality is improved by the self-supervised denoising algorithm. The proposed binary molecular post-regulation strategy opened a new avenue to efficiently boost the AIEgens¡¯ photophysical properties and consequently TPF imaging quality.",Wiley
"Sun, Shiqi and Liu, Shubin and Chen, Yanjun and Li, Lei and Bai, Qiang and Tian, Zhen and Huang, Que and Wang, Yanzhong and Wang, Xiaomin and Guo, Li","Quantum Physics and Deep Learning to Reveal Multiple Dimensional Modified Regulation by Ternary Substitution of Iron, Manganese, and Cobalt on Na3V2(PO4)3 for Superior Sodium Storage",2023,https://doi.org/10.1002/adfm.202213711,https://onlinelibrary.wiley.com/doi/abs/10.1002/adfm.202213711,Journal,Advanced Functional Materials,"Na3V2(PO4)3 is regarded as a promising candidate for sodium ion batteries. Nevertheless, the poor electronic conductivity, low capacities, and unstable structure limit its further investigations. Herein, a new type of Fe/Mn/Co co-substituted Na3V2(PO4)3 with nitrogen-doped carbon coating (NFMC) by a facile sol-gel route is synthesized. The introduced elements feature in both crystal bulk and carbon coating layer. Suitable heteroatom substitution activates more effective Na+ to participate in electrochemical process and reinforce the structure. An extra high voltage platform at 3.8 V resulting from the multi-element synergy (Mn2+/Mn3+/Mn4+; Co2+/Co3+; V4+/V5+) is stably and reversibly existed in NFMC to supply added capacities, which is investigated by quantum physics calculations. The high flux paths for Na+ migration and spin quantum state distribution in NFMC are demonstrated by molar magneton calculation. Significantly, the generated polyatomic coordination environment of M?N?C (M = Fe/Co/Mn) in carbon layer is first proposed. The most optimized combination structures are obtained from 69 possible structures and demonstrated by X-ray absorption spectroscopy. The superior electrochemical performance is precisely forecasted by innovative deep learning. Predicted values with high precision are obtained based on a small number of operating data, extremely short development period, and provide real-time status references for safer use.",Wiley
"Bentrcia, Toufik and Djeffal, Fay?al and Chebaki, Elasaad",Approach for designing and modelling of nanoscale DG MOSFET devices using Kriging metamodelling technique,2017,https://doi.org/10.1049/iet-cds.2017.0204,https://onlinelibrary.wiley.com/doi/abs/10.1049/iet-cds.2017.0204,Journal,"IET Circuits, Devices \& Systems","In this study, the authors focus mainly on the investigation of Kriging interpolation method to elaborate surrogate models of the nanoscale double-gate metal oxide silicon field effect transistors (DG MOSFET) analogue/RF performance under critical operational conditions. The elaboration of such models is made possible through the generation of computer experiments using ATLAS-2D simulator, where the numerical simulations or experimental measurements, account for the accurate behaviour of the device including the ageing phenomena, short channel and quantum confinement effects. The validity of the obtained Kriging models is tested by comparing the predicted responses of the device with their numerical counterpart in terms of some statistical criteria namely the sum of relative errors, the mean percentage of absolute errors and the correlation coefficient. It is also shown that the obtained Kriging interpolation models are precise enough to be used as objective functions in the context of a genetic algorithm optimisation with the aim of improving the device analogue/RF performance in terms of transconductance and cut-off frequency parameters. Therefore, this study may provide more insights regarding the investigation of surrogate modelling tools in the field of deep nanoscale devices especially with the intractable mission of developing physical based models at this scale for nanoelectronic simulators.",Wiley
"Song, Zilin and Ding, Ye and Huang, Jing",Constant advance replicas method for locating minimum energy paths and transition states,2023,https://doi.org/10.1002/jcc.27178,https://onlinelibrary.wiley.com/doi/abs/10.1002/jcc.27178,Journal,Journal of Computational Chemistry,"The chain-of-states (CoS) constant advance replicas (CAR) method and its climbing image variant (CI-CAR) for locating minimum energy paths (MEPs) and transition states are reported. The CAR algorithm applies the Lagrange multiplier method for imposing holonomic constraints on a chain-of-replicas, aiming to maintain equal mass-weighted/scaled root-mean-square (RMS) distances between the adjacent replicas by removing the sliding-down displacements contributed by the potential gradients during path optimization. Two contextual regularization schemes with clear geometrical interpretations are implemented to jointly promote high convergence and numerical robustness of the CAR algorithm. We show that the constrained reaction path can be solved normally within 5 steps of Lagrange multiplier updates with remarkably high numerical precision via the CAR approach. The efficacy of the CAR methods is demonstrated by testing on multiple analytical, classical, and quantum mechanical transition paths: the M¨¹ller potential, the alanine dipeptide isomerization, the helix unwinding of the VIVITLVMLKKK 12-mer peptide, and the Baker set of reactions. We also explore the potential of applying adaptive momentum (AdaM) optimizers for locating optimal transition paths under complex conformational changes. Most importantly, we discuss extensively the differences and connections between our newly proposed CAR methods and several related methods, with focuses on the reaction path with holonomic constraints (RPCons) approach of Brokaw et al. [J. Chem. Theory Comput. 2009, 5 (8), 2050¨C2061] and the state-of-the-art string method (SM) of E et al. [J. Chem. Phys. 2007, 126 (16), 164103]. The CAR approach represents a latest update to the general theoretical framework of reaction path finding algorithms in the two-ended CoS regime.",Wiley
"Thayananthan, Vijey and Alzahrani, Ahmed and Qureshi, Muhammad Shuaib",Efficient techniques of key management and quantum cryptography in RFID networks,2015,https://doi.org/10.1002/sec.1005,https://onlinelibrary.wiley.com/doi/abs/10.1002/sec.1005,Journal,Security and Communication Networks,"An efficient way of handling security keys using quantum cryptography (QC) for increasing security in radio frequency identification (RFID) networks is being investigated by network security industries. To establish secure RFID network, communication between any two nodes that hold RFID tags and/or readers merged with existing networks should be protected. In order to maximize the data security and secure transmission around RFID network, theoretical model of the quantum key management (KM) system based on RFID is introduced as a proposed research. This model not only manages the secure keys but also it defends passive eavesdropping attacks and other potential attacks. Novelties in this research are security keys of which QC is being utilized in RFID network with continuous key updates. To establish future security around RFID networks, efficient KM protocol and QC, which deal with quantum mathematical procedures and quantum physics, should be analyzed without affecting the legacy. Computational complexities in KM are increasing with the large key sizes, which are manageable through QC. To maximize the security and minimize the complexity in KM, QC with Grover's algorithm is introduced as a method in RFID network environments. So, we have proved that a number of operations with key sizes obtained in KM are reduced. In this proposal, QC will help to reduce the complexity of algorithms used in KM protocols and maximize the security. Copyright ? 2014 John Wiley \& Sons, Ltd.",Wiley
"Bosia, Francesco and Weymuth, Thomas and Reiher, Markus",Ultra-fast spectroscopy for high-throughput and interactive quantum chemistry,2022,https://doi.org/10.1002/qua.26966,https://onlinelibrary.wiley.com/doi/abs/10.1002/qua.26966,Journal,International Journal of Quantum Chemistry,"We present ultra-fast quantum chemical methods for the calculation of infrared and ultraviolet¨Cvisible spectra designed to provide fingerprint information during autonomous and interactive explorations of molecular structures. Characteristic spectral signals can serve as diagnostic probes for the identification and characterization of molecular structures. These features often do not require ultimate accuracy with respect to peak position and intensity, which alleviates the accuracy¨Ctime dilemma in ultra-fast electronic structure methods. If approximate ultra-fast algorithms are supplemented with an uncertainty quantification scheme for the detection of potentially large prediction errors in signal position and intensity, an offline refinement will always be possible to confirm or discard the predictions of the ultra-fast approach. Here, we present ultra-fast electronic structure methods for such a protocol in order to obtain ground- and excited-state electronic energies, dipole moments, and their derivatives for real-time applications in vibrational spectroscopy and photophysics. As part of this endeavor, we devise an information-inheritance partial Hessian approach for vibrational spectroscopy, a tailored subspace diagonalization approach and a determinant-selection scheme for excited-state calculations.",Wiley
"Hoggan, Philip E. and Boufergu¨¨ne, Ahmed",Quantum Monte Carlo for activated reactions at solid surfaces: Time well spent on stretched bonds,2014,https://doi.org/10.1002/qua.24676,https://onlinelibrary.wiley.com/doi/abs/10.1002/qua.24676,Journal,International Journal of Quantum Chemistry,"Many chemical reactions involve bond-dissociation. This is also true for reactions at solid surfaces, in which the dissociation step is often limiting but facilitated in comparison to gas-phase reaction channels. This work considers N2 dissociation. The molecule is strongly bound and stretched geometries are chosen. Heterogeneous catalysis by copper is simulated. It was investigated in our previous work as it is in many ways a prototype metal presenting a close-packed surface here. These nitrogen molecules are adsorbed on copper and fixed geometries on the dissociation reaction pathway for stretched N2 are given using density functional theory (DFT) calculations in a plane-wave basis. This dissociating molecule appears to be underbound using the ab initio Perdew, Burke, Ernzerhof (PBE) DFT functional but while this phenomenon accounts for a few percent at 5 ?, at 6 ?, PBE gives less than 30\% of the binding energy. This indicates the onset of dissociation. The PBE wave-functions at these bond-lengths serve as trial input for Quantum Monte Carlo (QMC) simulations of the ground states to obtain highly accurate correlated results for the associated activation barriers indicating the catalytic effect on this dissociation. The geometries from this bond-stretching study mimic the transition state (TS). This procedure requires no search for the actual TS geometry. Finite-size effects and fixed-node error are possible limitations to accuracy of this type of QMC study. We are able to limit fixed-node error, using certain trial wave-functions. The finite-size effect is considerable, although comparing two adsorbed geometries cancels about 90\% with respect to clean surfaces. Unfolding the cell to simulate a 9 k-point grid (rather than a single k-point) reduces the remainder by at least a factor 130 but relations for calibrating the remaining (2 mHa) error on converged grids are also used. The pseudopotential used to represent the atomic core of copper must also be determined carefully: we leave 11 active electrons but include the 3d shell in the pseudopotential. ? 2014 Wiley Periodicals, Inc.",Wiley
"Gassoumi, Ismail and Touil, Lamjed and Ouni, Bouraoui and Mtibaa, Abdellatif",An Efficient Design of DCT Approximation Based on Quantum Dot Cellular Automata (QCA) Technology,2019,https://doi.org/10.1155/2019/9029526,https://onlinelibrary.wiley.com/doi/abs/10.1155/2019/9029526,Journal,Journal of Electrical and Computer Engineering,"Optimization for power is one of the most important design objectives in modern digital image processing applications. The DCT is considered to be one of the most essential techniques in image and video compression systems, and consequently a number of extensive works had been carried out by researchers on the power optimization. On the other hand, quantum-dot cellular automata (QCA) can present a novel opportunity for the design of highly parallel architectures and algorithms for improving the performance of image and video processing systems. Furthermore, it has considerable advantages in comparison with CMOS technology, such as extremely low power dissipation, high operating frequency, and a small size. Therefore, in this study, the authors propose a multiplier-less DCT architecture in QCA technology. The proposed design provides high circuit performance, very low power consumption, and very low dimension outperform to the existing conventional structures. The QCADesigner tool has been utilized for QCA circuit design and functional verification of all designs in this work. QCAPro, a very widespread power estimator tool, is applied to estimate the power dissipation of the proposed circuit. The suggested design has 53\% improvement in terms of power over the conventional solution. The outcome of this work can clearly open up a new window of opportunity for low power image processing systems.",Wiley
"Szarejko, Dariusz and Kami¨½ski, Rados?aw and ?aski, Piotr and Jarzembska, Katarzyna N.",Seed-skewness algorithm for X-ray diffraction signal detection in time-resolved synchrotron Laue photocrystallography,2020,https://doi.org/10.1107/S1600577520000077,https://onlinelibrary.wiley.com/doi/abs/10.1107/S1600577520000077,Journal,Journal of Synchrotron Radiation,"A one-dimensional seed-skewness algorithm adapted for X-ray diffraction signal detection is presented and discussed. The method, primarily designed for photocrystallographic time-resolved Laue data processing, was shown to work well for the type of data collected at the Advanced Photon Source and European Synchrotron Radiation Facility. Nevertheless, it is also applicable in the case of standard single-crystal X-ray diffraction data. The reported algorithm enables reasonable separation of signal from the background in single one-dimensional data vectors as well as the capability to determine small changes of reflection shapes and intensities resulting from exposure of the sample to laser light. Otherwise, the procedure is objective, and relies only on skewness computation and its subsequent minimization. The new algorithm was proved to yield comparable results to the Kruskal¨CWallis test method [Kalinowski, J. A. et al. (2012). J. Synchrotron Rad.19, 637], while the processing takes a similar amount of time. Importantly, in contrast to the Kruskal¨CWallis test, the reported seed-skewness approach does not need redundant input data, which allows for faster data collections and wider applications. Furthermore, as far as the structure refinement is concerned, the reported algorithm leads to the excited-state geometry closest to the one modelled using the quantum-mechanics/molecular-mechanics approach reported previously [Jarzembska, K. N. et al. (2014). Inorg. Chem.53, 10594], when the t and s algorithm parameters are set to the recommended values of 0.2 and 3.0, respectively.",Wiley
"Aquilante, Francesco and Autschbach, Jochen and Carlson, Rebecca K. and Chibotaru, Liviu F. and Delcey, Micka?l G. and De Vico, Luca and Fdez. Galv¨¢n, Ignacio and Ferr¨¦, Nicolas and Frutos, Luis Manuel and Gagliardi, Laura and Garavelli, Marco and Giussani, Angelo and Hoyer, Chad E. and Li Manni, Giovanni and Lischka, Hans and Ma, Dongxia and Malmqvist, Per ?ke and M¨¹ller, Thomas and Nenov, Artur and Olivucci, Massimo and Pedersen, Thomas Bondo and Peng, Daoling and Plasser, Felix and Pritchard, Ben and Reiher, Markus and Rivalta, Ivan and Schapiro, Igor and Segarra-Mart¨ª, Javier and Stenrup, Michael and Truhlar, Donald G. and Ungur, Liviu and Valentini, Alessio and Vancoillie, Steven and Veryazov, Valera and Vysotskiy, Victor P. and Weingart, Oliver and Zapata, Felipe and Lindh, Roland",Molcas 8: New capabilities for multiconfigurational quantum chemical calculations across the periodic table,2016,https://doi.org/10.1002/jcc.24221,https://onlinelibrary.wiley.com/doi/abs/10.1002/jcc.24221,Journal,Journal of Computational Chemistry,"In this report, we summarize and describe the recent unique updates and additions to the Molcas quantum chemistry program suite as contained in release version 8. These updates include natural and spin orbitals for studies of magnetic properties, local and linear scaling methods for the Douglas¨CKroll¨CHess transformation, the generalized active space concept in MCSCF methods, a combination of multiconfigurational wave functions with density functional theory in the MC-PDFT method, additional methods for computation of magnetic properties, methods for diabatization, analytical gradients of state average complete active space SCF in association with density fitting, methods for constrained fragment optimization, large-scale parallel multireference configuration interaction including analytic gradients via the interface to the Columbus package, and approximations of the CASPT2 method to be used for computations of large systems. In addition, the report includes the description of a computational machinery for nonlinear optical spectroscopy through an interface to the QM/MM package Cobramm. Further, a module to run molecular dynamics simulations is added, two surface hopping algorithms are included to enable nonadiabatic calculations, and the DQ method for diabatization is added. Finally, we report on the subject of improvements with respects to alternative file options and parallelization. ? 2015 Wiley Periodicals, Inc.",Wiley
"Bourmaud, Claire L. and Bertella, Stefania and Bosch Rico, Anna and Karlen, Steven D. and Ralph, John and Luterbacher, Jeremy S.",Quantification of Native Lignin Structural Features with Gel-Phase 2D-HSQC0 Reveals Lignin Structural Changes During Extraction,2024,https://doi.org/10.1002/ange.202404442,https://onlinelibrary.wiley.com/doi/abs/10.1002/ange.202404442,Journal,Angewandte Chemie,"Our ability to study and valorize the lignin fraction of biomass is hampered by the fundamental and still unmet challenge of precisely quantifying native lignin's structural features. Here, we developed a rapid elevated-temperature 1H?13C Heteronuclear Single-Quantum Coherence Zero (HSQC0) NMR method that enables this precise quantification of native lignin structural characteristics even with whole plant cell wall (WPCW) NMR spectroscopy, overcoming fast spin relaxation in the gel phase. We also formulated a Gaussian fitting algorithm to perform automatic and reliable spectral integration. By combining HSQC0 measurements with yield measurements following depolymerisation, we can confirm the combinatorial nature of radical coupling reactions during biosynthesis leading to a random sequential organization of linkages within a largely linear lignin chain. Such analyses illustrate how this analytical method can greatly facilitate the study of native lignin structure, which can then be used for fundamental studies or to understand lignin depolymerization methods like reductive catalytic fractionation or aldehyde-assisted fractionation.",Wiley
"Aucique-P¨¦rez, Carlos Eduardo and Rios, Vinicius Souza and Neto, Lara Beatriz Cruz and Rios, Jonas Alberto and Martins, Samuel Cordeiro Vitor and Rodrigues, Fabr¨ªcio ?vila",Photosynthetic changes in wheat cultivars with contrasting levels of resistance to blast,2020,https://doi.org/10.1111/jph.12952,https://onlinelibrary.wiley.com/doi/abs/10.1111/jph.12952,Journal,Journal of Phytopathology,"Wheat blast, caused by Pyricularia oryzae, is currently the main disease that threat to food security and wheat production in the world. This study investigated the photosynthetic responses of wheat plants from cultivars BR-18 (moderately resistant) and BRS-Guamirim (susceptible), differing in their levels of resistance to blast, by using leaf gas exchange and rapid light curves analysis focusing primarily on the asymptomatic (AS) and symptomatic (S) phases of disease development. The photosynthetic capacity of plants from cultivar BRS-Guamirim was compromised by diffusional CO2 limitations and inefficient photoprotection mechanism at the AS phase of blast due to reductions in CO2 assimilation, stomatal conductance, transpiration rate and fluorescent quantum efficiency (Fv/Fm). For cultivar BR-18, the loss in photosynthesis was minimized due to an efficient control in the regulated energy dissipation [Y(NPQ)] avoiding losses by latent heat [Y(NO)]. Additionally, Fv/Fm was a promissory physiological indicator of blast during its AS phase while Y(NPQ) and Y(NO) were more sensitive at the S phase of the disease. In conclusion, the physiological parameters Fv/Fm, Y(NQP) and Y(NO) can be used as physiological markers in wheat breeding programs seeking in the development of cultivars resistant to blast.",Wiley
"Chagneau, Anthony and Nathoo, La?ticia and Alloul, J¨¦r¨¦my and Gabriel, Bertrand",Quantum finite difference solvers for physics simulation,2023,https://doi.org/10.1049/qtc2.12054,https://onlinelibrary.wiley.com/doi/abs/10.1049/qtc2.12054,Journal,IET Quantum Communication,"Physics systems are becoming increasingly complex and require more and more computing time. Quantum computing, which has shown its efficiency on some problems, such as the factorisation of a number with Shor's algorithm, may be the solution to reduce these computation times. Here, the authors propose two quantum numerical schemes for the simulation of physics phenomena, based on the finite difference method. The aim is to see if quantum versions of standard numerical schemes offer an advantage over their classical counterparts, either in accuracy, stability or computation time. First, the authors will present the different phenomena studied as well as the classical solution methods chosen. The authors will then describe the implementation of the quantum numerical schemes and present some results obtained on the different physics phenomena beforehand and then compare both approaches, classical and quantum.",Wiley
"Chen, Yong and Zhao, Yisheng and He, Ximei and Xu, Zhihong",Resource allocation method for Mobility-Aware and Multi-UAV-Assisted mobile edge computing systems with energy harvesting,2023,https://doi.org/10.1049/cmu2.12596,https://onlinelibrary.wiley.com/doi/abs/10.1049/cmu2.12596,Journal,IET Communications,"Due to the limited coverage of base station (BS) and battery capacity of mobile users, the resource allocation strategy in multiple unmanned aerial vehicles (UAVs)-assisted edge computing system with nonlinear energy harvesting is investigated in this paper. The cooperation between BS and multi-UAV is considered, which can provide extensive coverage for users with mobility. Mobile users can simultaneously offload computation bits to the BS and the UAV, and mobile users harvest energy from BS and UAV. Meanwhile, the mobility of users is taken into account. Moreover, an echo state network (ESN)-based prediction algorithm is utilized for predicting the future positions of mobile users. Therefore, the UAV can reach the predicted users' positions in advance to ensure the continuity of communication. The objective of the resource allocation strategy is to maximize the energy efficiency by jointly optimizing bandwidth allocation, computation resources, the trajectory of UAV, and transmitting power of mobile users. Then, the resource allocation problem is formulated as a mixed-integer nonlinear programming problem. The quantum-behaved particle swarm optimization (QPSO) algorithm is used to solve the problem. Simulation results demonstrate that the proposed strategy can achieve higher energy efficiency than other benchmark strategies. In addition, QPSO algorithm outperforms the standard particle swarm optimization algorithm and genetic algorithm in terms of energy efficiency.",Wiley
"?ak?r, Bekir and Yakar, Yusuf and ?zmen, Ayhan",Investigation of the Electronic Structure in GaAs/AlxGa1-xAs Quantum Dots with Four Electrons,2025,https://doi.org/10.1002/adts.202400910,https://onlinelibrary.wiley.com/doi/abs/10.1002/adts.202400910,Journal,Advanced Theory and Simulations,"In this paper, a detailed analysis of the electronic structure of four-electron quantum dots is performed with finite confinement potential by a modified variational optimization approach based mainly on the quantum genetic algorithm and the Hartree-Fock-Roothaan method. For the ground and higher excited configurations, our analysis covers a range of parameters like the average energies of ground and excited states, singlet and triplet state energies, orbital energies, and two-electron Coulomb and exchange interaction energies. One-electron kinetic energy, the Coulomb potential energy between electrons and impurity, the confinement potential energy for the electrons, and the probability of finding an electron inside or outside the quantum well are also studied. The results demonstrate that both spatial confinement and the height of the potential barrier have a pronounced effect on all energies in the strong and intermediate confinement regions, but this influence weakens significantly in large dot radii. The most substantial difference between singlet and triplet energies occurs in the 1s22s2p configurations, with this difference decreasing in higher configurations. Significant increases in the 1s and 2s orbital energies are observed at the dot radii where the 2p, 3d, and 4f electrons from the outermost orbit begin to penetrate the well.",Wiley
"Zhang, Jinfeng and Zhang, Dongdong",Internet of things network intrusion detection model based on quantum artificial fish group and fuzzy kernel clustering algorithm,2023,https://doi.org/10.1002/spy2.220,https://onlinelibrary.wiley.com/doi/abs/10.1002/spy2.220,Journal,SECURITY AND PRIVACY,"The application of internet of things (IoT) devices in 5G/B5G has benefited many industries, such as automated production, smart agriculture and autopilot, and has provided access to billions of smart devices. However, the rapid growth of IoT devices has also brought network security issues. The purpose of this paper is to study the network intrusion detection model based on quantum artificial fish population and fuzzy kernel clustering algorithm. In this paper, the network intrusion detection model based on traditional fuzzy C-means (FCM) clustering has poor classification effect and is prone to local extremum. A semi-supervised fuzzy kernel¨Cclustering algorithm based on quantum artificial fish group is proposed. The algorithm adopts a small amount of tag data and many unknown tag data to generate the classification of network intrusion detection and constructs a new objective function of FCM algorithm by means of kernel distance. In the simulation experiment of KDD Cup 99 network intrusion detection data, compared with the intrusion detection model based on FCM, particle swarm optimization-FCM, the detection rate of the proposed algorithm in the known attack and unknown attack is 92.5\% and 84.9\%, respectively. The results show that the proposed intrusion detection algorithm has better detection rate.",Wiley
"Meena, Uma and Sharma, Promila",An improved blockchain based encryption scheme for secure routing in wireless sensor network using machine learning technique,2023,https://doi.org/10.1002/ett.4713,https://onlinelibrary.wiley.com/doi/abs/10.1002/ett.4713,Journal,Transactions on Emerging Telecommunications Technologies,"A secure routing scheme plays an integral role in ensuring the secure routing and efficiency of wireless sensor networks (WSNs). Recently, many studies have been undertaken to improve the data aggregation process, data security, and routing security. However, these approaches are highly suffered due to major limitations like time complexity, malicious attacks, and data insecurity. This research aims to develop an improved blockchain based encryption scheme for secure routing in wireless sensor networks using machine learning techniques. An improved artificial quantum beetle swarm neural network approach is proposed to perform the data aggregation among the sensor nodes. The cosine equivalent function and packet density correlation degree approach is emphasized to perform clustering in sensor nodes. The cluster head (CH) is selected based on the similarity of each sensor node. The Kalman filtering technique is introduced to filter out the data from unwanted malicious. This technique helps to filter the data before it is sent to the CH. Blockchain-based encryption scheme is emphasized for data security by preventing malicious attacks during data transmission. The enhanced differential evaluation based firefly routing protocol is presented to maintain secure routing by choosing the optimal routing for the protected data transmission. Performance metrics such as latency, throughput, routing performance, energy consumption, FPR, blockchain (BC) computational performance, dead sensor count and average hop count are analyzed and compared with existing techniques. In an experimental scenario, the proposed approach achieves a maximum packet delay of 500 slots, throughput of 581 times/s, a latency of 0.31?ms, a computation complexity of 0.6, and a routing complexity of 2081?ms with a BC computation time of 95?ms. The performance of the proposed approach shows a better result than other existing approaches.",Wiley
"Hu, Min and Cai, Wei",Simulation and Optimization for the Staircase Evacuation of a Cruise Ship Based on a Multigrid Model,2021,https://doi.org/10.1155/2021/9961536,https://onlinelibrary.wiley.com/doi/abs/10.1155/2021/9961536,Journal,Mathematical Problems in Engineering,"A cruise ship is a large public place, and it is very important to ensure the safety of passengers during the evacuation process in case of an emergency. This paper proposes a method to improve evacuation efficiency on cruise ships by controlling passengers¡¯ density. According to the construction of the staircase, the space of the staircase is divided into the step and landing areas. On the basis of considering the influence of passengers¡¯ view field and moving characteristics of passengers, the moving rules of passengers in two areas are established. Taking staircases of the cruise ship as the evacuation scenario, the evacuation process is simulated by using the established model. From simulation results, it is found that numbers of evacuated passengers between staircases are very unbalanced and too many passengers gather in one staircase, which lead to serious congestion. By controlling passengers¡¯ density in stairs areas, the minimum evacuation time is the optimization objective and the optimization model is established by using the quantum-inspired evolutionary algorithm and genetic algorithm. The optimization results show that the evacuation time is significantly shortened when the passenger¡¯s density on the staircase is kept within an appropriate range, which proves that the evacuation efficiency can be effectively improved by controlling the passengers¡¯ density.",Wiley
"Cardamone, Salvatore and Popelier, Paul L. A.",Prediction of conformationally dependent atomic multipole moments in carbohydrates,2015,https://doi.org/10.1002/jcc.24215,https://onlinelibrary.wiley.com/doi/abs/10.1002/jcc.24215,Journal,Journal of Computational Chemistry,"The conformational flexibility of carbohydrates is challenging within the field of computational chemistry. This flexibility causes the electron density to change, which leads to fluctuating atomic multipole moments. Quantum Chemical Topology (QCT) allows for the partitioning of an ¡°atom in a molecule,¡± thus localizing electron density to finite atomic domains, which permits the unambiguous evaluation of atomic multipole moments. By selecting an ensemble of physically realistic conformers of a chemical system, one evaluates the various multipole moments at defined points in configuration space. The subsequent implementation of the machine learning method kriging delivers the evaluation of an analytical function, which smoothly interpolates between these points. This allows for the prediction of atomic multipole moments at new points in conformational space, not trained for but within prediction range. In this work, we demonstrate that the carbohydrates erythrose and threose are amenable to the above methodology. We investigate how kriging models respond when the training ensemble incorporating multiple energy minima and their environment in conformational space. Additionally, we evaluate the gains in predictive capacity of our models as the size of the training ensemble increases. We believe this approach to be entirely novel within the field of carbohydrates. For a modest training set size of 600, more than 90\% of the external test configurations have an error in the total (predicted) electrostatic energy (relative to ab initio) of maximum 1 kJ mol?1 for open chains and just over 90\% an error of maximum 4 kJ mol?1 for rings. ? 2015 Wiley Periodicals, Inc.",Wiley
"Ren, Peixin and Gu, Xiaozhuo and Wang, Ziliang",Efficient module learning with errors-based post-quantum password-authenticated key exchange,2023,https://doi.org/10.1049/ise2.12094,https://onlinelibrary.wiley.com/doi/abs/10.1049/ise2.12094,Journal,IET Information Security,"Password-authenticated key exchange (PAKE) is a cryptographic primitive that can establish secure remote communications between the client and the server, especially with the advantage of amplifying memorable passwords into strong session keys. However, the arrival of the quantum computing era has brought new challenges to traditional PAKE protocols. Thus, designing an efficient post-quantum PAKE scheme becomes an open research question. In this paper, the authors construct a quantum-safe PAKE protocol, which is a horizontal extension of the password-authenticated key (PAK) protocol in the field of module lattices. Subsequently, the authors accompany the proposed protocol with a rigorous security proof in the random oracle model with two adaptions: applying the CDF-Zipf model to characterise the ability of the adversary and using the pairing with errors assumption to simplify the proof. Taking the flexibility of the module learning with errors (MLWE) problem, the authors elaborately select three parameter sets to meet different application scenarios. Specifically, the authors¡¯ Recommended-PAKE implementation achieves 177-bit post-quantum security with a generous margin to cope with later improvement in cryptanalysis. The performance results indicate that the authors¡¯ MLWE-PAKE is quite practical: compared with the latest Yang-PAK, the authors¡¯ Recommended-PAK reduces the communication cost and the running time by 36.8\% and 13.8\%, respectively.",Wiley
"Gholami, Mohammad and Amirzadeh, Zaman",Novel Low-Latency T-Latch with Minimum Number of Cells in QCA Technology,2023,https://doi.org/10.1002/adts.202200686,https://onlinelibrary.wiley.com/doi/abs/10.1002/adts.202200686,Journal,Advanced Theory and Simulations,"As an alternative to nanoelectronic devices, the quantum-dot cellular automata (QCA) offer new opportunities to design high-level algorithms and architectures. Using parallel processing, high speed, and low energy consumption, this emerging technology is very suitable and efficient for operational needs that require a large amount of computing and are often time consuming. In this paper, a new and optimal T-latch design is introduced. The proposed latch structure has less occupied area and energy consumption than the existing implementation methods. In the proposed T-latch the cell, area and energy consumption are reduced by 9.52\%, 6.45\%, and 19.67\% compared to the best previous designs, respectively. Also, in this article, the T-latch with reset and T-latch with set/reset terminals are designed. Then, using the proposed T-latch, various other latches are designed to ensure the correct operation of the designed T-latch. Finally, to show that the proposed latch works properly in more complex circuits, they are used in the design of 1-bit, 4-bit, and n-bit counters and the results of the simulations show the proper operation of the circuit. The proposed methods are simulated using the QCADesigner software and compared with other designs in terms of cell number, area, and energy consumption.",Wiley
"Nguyen, Thi Thuy Huong and Bui, Hoang Khang and Im, Ju Yeon and Seo, Tae Seok",Cognitively Driven Autonomous Flow Chemistry for Producing On-Demand Perovskite Quantum Dots Via Advanced Closed-Loop Feedback Control,,https://doi.org/10.1002/smtd.202400094,https://onlinelibrary.wiley.com/doi/abs/10.1002/smtd.202400094,Journal,Small Methods,,Wiley
"Pellegrini, Pedro and Cossani, C. Mariano and Bella, Carlos M. Di and Pi?eiro, Gervasio and Sadras, V¨ªctor O. and Oesterheld, Mart¨ªn",Simple regression models to estimate light interception in wheat crops with Sentinel-2 and a handheld sensor,2020,https://doi.org/10.1002/csc2.20129,https://onlinelibrary.wiley.com/doi/abs/10.1002/csc2.20129,Journal,Crop Science,"Capture of radiation by crop canopies drives growth rate, grain set, and yield. Since the fraction of photosynthetically active radiation absorbed by green area (fAPARg) correlates with normalized difference vegetation index (NDVI), remote sensors have been used to monitor vegetation. With a 10-m spatial resolution and 5-d revisiting time, the recently launched Sentinel-2 satellite is a promising tool for fAPARg monitoring. However, the available algorithm to estimate fAPARg is based on simulations of canopy interception of several vegetation types and was never tested in field crops. Handheld sensors, such as GreenSeeker, are another alternative to estimate fAPARg. Our objectives were (a) to test the ability of indices derived from Sentinel-2 and GreenSeeker NDVI to capture fAPARg of wheat (Triticum aestivum L.) crops, (b) to compare these sensors¡¯ performance against the moderate resolution imaging spectroradiometer (MODIS), and (c) to compare our Sentinel-2 model estimations with the available algorithm. In wheat fields in the southwest Argentinean Pampas, on several sampling dates, we measured fAPARg with a quantum light sensor and NDVI with a GreenSeeker. We regressed fAPARg measurements with vegetation indices from the different sources and selected the best models. Sentinel-2 and GreenSeeker NDVI precisely estimated fAPARg, with a performance similar to MODIS (p < .05; RMSD = 0.09, 0.11, and 0.08; R2 = .89, .88, and .95, respectively). The available algorithm to estimate fAPARg with Sentinel-2 yielded biased estimations, mainly in the lower range of fAPARg. These results suggest that simple models may provide fAPARg estimations with Sentinel-2 and GreenSeeker in wheat crops with an accuracy suitable for agricultural applications.",Wiley
"Mohammadi, Asra and Rahmandoust, Moones and Mirzajani, Fateme and Azadkhah Shalmani, Armin and Raoufi, Mohammad",Optimization of the interaction of graphene quantum dots with lipase for biological applications,2020,https://doi.org/10.1002/jbm.b.34579,https://onlinelibrary.wiley.com/doi/abs/10.1002/jbm.b.34579,Journal,Journal of Biomedical Materials Research Part B: Applied Biomaterials,"Graphene quantum dots (GQDs) are known as emerging sub-10 nm nanoparticles (NPs), which are in fact few-layered pieces of graphene, capable of emitting blue fluorescence, when exposed to 360?nm UV light. Understanding the details of the interaction between GQDs and lipase can serve as a critical step for improving the biological outcome of GQD-derived drug-delivery and diagnosis systems. The interaction occurs in the form of surface adsorption, which can subsequently influence the physicochemical properties of both the NP and the protein. Hence, a systematic approach was taken here to optimize the GQDs' synthesis conditions in order to achieve the highest possible quantum yield (QY). Furthermore, to understands the influence of the interaction of GQDs and lipase, on both the activity of lipase and the emission intensity of GQDs, various incubation conditions were tested to achieve optimized conditions over central composite design algorithm by Design-Expert?, using response surface methodology. The results show that the GQDs fabricated by thermal decomposition of citric acid at 160¡ãC, with a heating duration of 55?min, obtain almost three times higher QY than the highest values reported previously. The best enzymatic activity after the formation of the hard corona, as well as the highest fluorescent emission, were achieved at GQD-to-enzyme ratios within the rage of 23¨C25\%, at temperatures between 41 and 42¡ãC, for 6¨C8 min. In the aforementioned condition, the enzyme retains 91¨C95\% of its activity and the NP preserves about 80¨C82\% of its fluorescence intensity after incubation.",Wiley
"Billett, Stephen and Noble, Christy and Sturman, Nancy and O'Shannessy, Megan and Brumpton, Kay and Le, Anh Hai",Reimagining rural clinical education from lessons learnt during COVID,2024,https://doi.org/10.1111/tct.13732,https://onlinelibrary.wiley.com/doi/abs/10.1111/tct.13732,Journal,The Clinical Teacher,"Background Securing access to sufficient and focussed learning experiences is a perennial challenge for medical trainees. This challenge was accentuated during the COVID-19 pandemic lockdowns and with physical isolation processes that decreased in-person patient presentations and a shift to telehealth consultations. This situation has prompted the need to optimise the available experiences and educational responses to overcome the limitations in the number, quantum and range of available clinical learning experiences. Methods Semi-structured interviews were conducted with medical practice teams in four rural general practices to understand how medical trainees' education in rural general practices can be sustained in such circumstances. Findings Key considerations included optimising the available experiences to assist medical trainees to generate the kinds of mental models needed by trainees to conduct medical work, and particularly, when it became even more restricted through remote or physically distanced consultations. It also identified lessons learnt during COVID-19 pandemic lockdowns to inform and improve the provision of trainees' experiences in such practices. Discussion Providing experiences for trainees to participate fully in clinical activities is imperative. A sequenced set of experiences was proposed to incrementally prepare trainees to engage in and conduct clinical consultations remotely using digital technologies. Conclusion Such an approach may not always be easy or possible to enact but offers a pathway of experiences most likely to lead to positive outcomes for the trainees whilst maintaining patient care and safety considerations.",Wiley
"Brochard-Garnier, Stanislas and Paris, Michael and G¨¦nois, Romain and Han, Quanxiang and Liu, Yang and Massuyeau, Florian and Gautier, Romain",Screening Approach for the Discovery of New Hybrid Perovskites with Efficient Photoemission,2019,https://doi.org/10.1002/adfm.201806728,https://onlinelibrary.wiley.com/doi/abs/10.1002/adfm.201806728,Journal,Advanced Functional Materials,"Owing to quantum confinement, low-dimensional hybrid perovskite materials have recently shown a great potential for applications in optoelectronics. Such compounds can exhibit broad- or narrow-band light emission, low-temperature solution processability, high thermal stability, and relatively high photoluminescence quantum yields (PLQY). However, the search for efficient phosphors with a specific set of characteristics remains difficult because the family of hybrid perovskites consists in an extremely large chemical system (i.e., different halides, metals, and organic molecules), and optical properties are not predictable prior to material synthesis and characterization. Here, is proposed a simple approach to screen a significant amount of new hybrid lead halide perovskites. The synthetic method by fast crystallization at low temperature enables the rapid identification of the materials exhibiting the targeted photoluminescence properties. This approach is tested for the discovery of hybrid lead halide perovskites with efficient white-light emission. Among 100 newly synthesized compounds, 5 exhibit intense white emission, and the in-depth characterization of a selected candidate shows high color rendering index (CRI) = 78 and a PLQY of 9\%, which is equivalent to the record reported for hybrid perovskites. This compound exhibits a new structure type for warm white-light emitting hybrid perovskites with chains of corner-sharing PbX6.",Wiley
"Fan-Yuan, Guan-Jie and Wang, Ze-Hao and Wang, Shuang and Yin, Zhen-Qiang and Chen, Wei and He, De-Yong and Guo, Guang-Can and Han, Zheng-Fu",Optimizing Decoy-State Protocols for Practical Quantum Key Distribution Systems,2021,https://doi.org/10.1002/qute.202000131,https://onlinelibrary.wiley.com/doi/abs/10.1002/qute.202000131,Journal,Advanced Quantum Technologies,"The decoy-state protocol enables quantum key distribution (QKD) systems to achieve high performance without using the single-photon source. In the dozen years since the decoy-state protocol has been proposed, a series of advances in scheme design, finite-size analysis, system modelling, and parameter estimation has developed. Unfortunately, most advances are based on different starting points and lack a synthesis to figure out the optimal protocol of decoy-state method. Here, the advances in decoy-state method are reviewed and they are synthesized to compare the key-rate performance of 38 decoy-state protocols using the particle swarm optimization (PSO) algorithm. To form a guideline for practical QKD systems, the optimal decoy-state protocols are found with the change of five system parameters (the transmission loss, the block size of postprocessing, the misalignment-error probability, the dark-count probability, and the afterpulse rate). It is expected that this work can answer the questions of what the actual performance is for different decoy-state protocol in various scenarios and which decoy-state protocol is the optimal choice for various QKD systems.",Wiley
"Hartnagel, Paula and Ravishankar, Sandheep and Klingebiel, Benjamin and Thimm, Oliver and Kirchartz, Thomas",Comparing Methods of Characterizing Energetic Disorder in Organic Solar Cells,2023,https://doi.org/10.1002/aenm.202300329,https://onlinelibrary.wiley.com/doi/abs/10.1002/aenm.202300329,Journal,Advanced Energy Materials,"The energetic disorder has been known for decades to limit the performance of structurally disordered semiconductors such as amorphous silicon and organic semiconductors. However, in the past years, high-performance organic solar cells have emerged showing a continuously reduced amount of energetic disorder. While searching for future high-efficiency material systems, it is therefore important to correctly characterize this energetic disorder. While there are several techniques in the literature, the most common approaches to probe the density of defect states are using optical excitation as in external quantum efficiency measurements, or sequential filling of the tail states by applying an external voltage as in admittance spectroscopy. A metanalysis of available literature, as well as the experiments using four characterization techniques on two material systems, reveal that electrical, voltage-dependent measurements frequently yield higher values of energetic disorder than optical measurements. With drift-diffusion simulations, it is demonstrated that the approaches probe different energy ranges of the subband-gap density of states. The limitations of the techniques are further explored and it is found that extraction of information from a capacitance-voltage curve can be inhibited by internal series resistance. Thereby, the discrepancies between measurement techniques with sensitivity to different energy ranges and electronic parameters are explained.",Wiley
"Hasan Babu, Hafiz Md. and Saleheen, Nazir and Jamal, Lafifa and Sarwar, Sheikh Muhammad and Sasao, Tsutomu",Approach to design a compact reversible low power binary comparator,2014,https://doi.org/10.1049/iet-cdt.2013.0066,https://onlinelibrary.wiley.com/doi/abs/10.1049/iet-cdt.2013.0066,Journal,IET Computers \& Digital Techniques,"Reversible logic has captured significant attention in recent time as reducing power consumption is the main concern of digital logic design. It consumes less power by recovering bit loss from its unique input¨Coutput mapping. In this study, the authors propose a reversible low power n-bit binary comparator. An algorithm is presented for constructing a compact reversible n-bit binary comparator circuit. The authors also propose two new reversible gates, namely, Babu-Jamal-Saleheen (BJS) and Hasan-Lafifa-Nazir (HLN) gates, to optimise the comparator. In addition, several theorems on the numbers of gates, garbage outputs, quantum cost, ancilla input, power, delay and area of the reversible n-bit comparator have been presented. The simulation results of the proposed comparator show that the circuit works correctly and gives significantly better performance than the existing ones. The comparative study shows that, as an example, for a 64-bit comparator, the proposed design achieves the improvement of 24.4\% in terms of number of gates, 19.9\% in terms of garbage outputs, 7.7\% in terms of quantum cost, 25.77\% in terms of area and 3.43\% in terms of power over the existing best one. Area and power analysis also show that the proposed design is the most compact as well as a low power circuit.",Wiley
"Gon?alves, Yan M. H. and Kashefolgheta, Sadra and Oliveira, Marina P. and H¨¹nenberger, Philippe H. and Horta, Bruno A. C.",Simultaneous parametrization of torsional and third-neighbor interaction terms in force-field development: The LLS-SC algorithm,2022,https://doi.org/10.1002/jcc.26819,https://onlinelibrary.wiley.com/doi/abs/10.1002/jcc.26819,Journal,Journal of Computational Chemistry,"The calibration of torsional interaction terms by fitting relative gas-phase conformational energies against their quantum-mechanical values is a common procedure in force-field development. However, much less attention has been paid to the optimization of third-neighbor nonbonded interaction parameters, despite their strong coupling with the torsions. This article introduces an algorithm termed LLS-SC, aimed at simultaneously parametrizing torsional and third-neighbor interaction terms based on relative conformational energies. It relies on a self-consistent (SC) procedure where each iteration involves a linear least-squares (LLS) regression followed by a geometry optimization of the reference structures. As a proof-of-principle, this method is applied to obtain torsional and third-neighbor interaction parameters for aliphatic chains in the context of the GROMOS 53A6 united-atom force field. The optimized parameter set is compared to the original one, which has been fitted manually against thermodynamic properties for small linear alkanes. The LLS-SC implementation is freely available under http://github.com/mssm-labmmol/profiler.",Wiley
"Tu, Hongwei and Han, Yanqiang and Wang, Zhilong and Chen, An and Tao, Kehao and Ye, Simin and Wang, Shiwei and Wei, Zhiyun and Li, Jinjin",RotNet: A Rotationally Invariant Graph Neural Network for Quantum Mechanical Calculations,2024,https://doi.org/10.1002/smtd.202300534,https://onlinelibrary.wiley.com/doi/abs/10.1002/smtd.202300534,Journal,Small Methods,"Deep learning has proven promising in biological and chemical applications, aiding in accurate predictions of properties such as atomic forces, energies, and material band gaps. Traditional methods with rotational invariance, one of the most crucial physical laws for predictions made by machine learning, have relied on Fourier transforms or specialized convolution filters, leading to complex model design and reduced accuracy and efficiency. However, models without rotational invariance exhibit poor generalization ability across datasets. Addressing this contradiction, this work proposes a rotationally invariant graph neural network, named RotNet, for accurate and accelerated quantum mechanical calculations that can overcome the generalization deficiency caused by rotations of molecules. RotNet ensures rotational invariance through an effective transformation and learns distance and angular information from atomic coordinates. Benchmark experiments on three datasets (protein fragments, electronic materials, and QM9) demonstrate that the proposed RotNet framework outperforms popular baselines and generalizes well to spatial data with varying rotations. The high accuracy, efficiency, and fast convergence of RotNet suggest that it has tremendous potential to significantly facilitate studies of protein dynamics simulation and materials engineering while maintaining physical plausibility.",Wiley
"Li, Dewang and Chen, Jianbao and Qiu, Meilan",Research on Population Development Trend in Huizhou of China Forecast Based on Optimal Weighted Combination Method and Fractional Grey Model,2021,https://doi.org/10.1155/2021/3320910,https://onlinelibrary.wiley.com/doi/abs/10.1155/2021/3320910,Journal,Journal of Mathematics,"In this paper, the optimal weighted combination model and fractional grey model are constructed. The coefficients of the optimal weighted combination model are determined by minimizing the sum of squares of resists of each model. On the other hand, the optimal conformable fractional order and dynamic background value coefficient are determined by the quantum inspired evolutionary algorithm (QIEA). Taking the resident population from 2008 to 2018 as the research object, the optimal weighted combination model and fractional grey model were used to study the estimated and predicted values. The results are compared and analyzed. The results show that the fractional grey model is better than the optimal weighted combination model in the estimation of the values. The optimal weighted combination model is better than the fractional grey model in predicting. Meanwhile, the fractional grey model is found to be very suitable for the data values that are large, and the changes between the data are relatively small. The research results expand the application of the fractional grey model and have important implications for the policy implementation activities of Huizhou government according to the population growth trend in Huizhou.",Wiley
"Stroev, Nikita and Berloff, Natalia G.","Analog Photonics Computing for Information Processing, Inference, and Optimization",2023,https://doi.org/10.1002/qute.202300055,https://onlinelibrary.wiley.com/doi/abs/10.1002/qute.202300055,Journal,Advanced Quantum Technologies,"This review presents an overview of the current state-of-the-art in photonics computing, which leverages photons, photons coupled with matter, and optics-related technologies for effective and efficient computational purposes. It covers the history and development of photonics computing and modern analogue computing platforms and architectures, focusing on optimization tasks and neural network implementations. The authors examine special-purpose optimizers, mathematical descriptions of photonics optimizers, and their various interconnections. Disparate applications are discussed, including direct encoding, logistics, finance, phase retrieval, machine learning, neural networks, probabilistic graphical models, and image processing, among many others. The main directions of technological advancement and associated challenges in photonics computing are explored, along with an assessment of its efficiency. Finally, the paper discusses prospects and the field of optical quantum computing, providing insights into the potential applications of this technology.",Wiley
"Johnson, Matthew S. and McGill, Charles J. and Green, William H.",Transitory sensitivity in automatic chemical kinetic mechanism analysis,2025,https://doi.org/10.1002/kin.21766,https://onlinelibrary.wiley.com/doi/abs/10.1002/kin.21766,Journal,International Journal of Chemical Kinetics,"Detailed chemical kinetic mechanisms are necessary for resolving many important chemical processes. As the chemistry of smaller molecules has become better grounded and quantum chemistry calculations have become cheaper, kineticists have become interested in constructing progressively larger kinetic mechanisms to model increasingly complex chemical processes. These large kinetic mechanisms prove incredibly difficult to refine and time-consuming to interpret. Traditional sensitivity analysis on a large mechanism can range from inconvenient to practically impossible without special techniques to reduce the computational cost. We first present a new time-local sensitivity analysis we term transitory sensitivity analysis. Transitory sensitivity analysis is demonstrated in an example to accurately identify traditionally sensitive reactions at an 18,000x speed up over traditional sensitivities. By fusing transitory sensitivity analysis with more traditional time-local branching, pathway, and cluster analyses, we develop an algorithm for efficient automatic mechanism analysis. This automatic mechanism analysis at a time point is able to identify the reactions a target is most sensitive to using transitory sensitivity analysis and then propose hypotheses why the reaction might be sensitive using branching, pathway, and cluster analyses. We implement these algorithms within the reaction mechanism simulator (RMS) package, which enables us to report the automatic mechanism analysis results in highly readable text formats and in molecular flux diagrams.",Wiley
"Avdonin, Sergei A. and Khmelnytskaya, Kira V. and Kravchenko, Vladislav V.",Reconstruction techniques for quantum trees,2024,https://doi.org/10.1002/mma.9963,https://onlinelibrary.wiley.com/doi/abs/10.1002/mma.9963,Journal,Mathematical Methods in the Applied Sciences,"The inverse problem of recovery of a potential on a quantum tree graph from the Weyl matrix given at a number of points is considered. A method for its numerical solution is proposed. The overall approach is based on the leaf peeling method combined with Neumann series of Bessel functions (NSBF) representations for solutions of Sturm¨CLiouville equations. In each step, the solution of the arising inverse problems reduces to dealing with the NSBF coefficients. The leaf peeling method allows one to localize the general inverse problem to local problems on sheaves, while the approach based on the NSBF representations leads to splitting the local problems into two-spectrum inverse problems on separate edges and reduces them to systems of linear algebraic equations for the NSBF coefficients. Moreover, the potential on each edge is recovered from the very first NSBF coefficient. The proposed method leads to an efficient numerical algorithm that is illustrated by numerical tests.",Wiley
"Jahangir, Mohammed and Griffiths, Darren and White, Daniel and Donlan, Gwynfor and Ren, Xiaofei and Kannanthara, Jithin and Singh, Yeshpal and Wayman, Joseph P. and Baker, Chris J. and Sadler, Jon P. and Reynolds, S. James and Antoniou, Michail",Development of a networked photonic-enabled staring radar testbed for urban surveillance,2024,https://doi.org/10.1049/rsn2.12524,https://onlinelibrary.wiley.com/doi/abs/10.1049/rsn2.12524,Journal,"IET Radar, Sonar \& Navigation","Urban surveillance of slow-moving small targets such as drones and birds in low to medium airspace using radar presents significant challenges. Detecting, locating and identifying such low observable targets in strong clutter requires both innovation in radar hardware design and optimisation of processing algorithms. To this end, the University of Birmingham (UoB) has set-up a testbed of two L-band staring radars to support performance benchmarking using datasets of target and clutter from realistic urban environment. This testbed is also providing the vehicle to understand how novel radar architectures can enhance radar capabilities. Some of the challenges in installing the radar at the UoB campus are highligted. Detailed benchmarking results are provided from urban monostatic and bistatic field trials that form the basis for performance comparison against future hardware modification. The solution to the challenge of interfacing the radar to the external oscillators is described and stand-alone bench tests with the candidate oscillators are reported. The testbed provides a valuable capability to undertake detailed analysis of performance of Quantum photonic-enabled radar and allows for its comparison with conventional oscillator technology for surveillance of low observable targets in the presence of urban clutter.",Wiley
"Dyson, Matthew J. and Verhage, Michael and Ma, Xiao and Simone, Giulio and Tordera, Daniel and Janssen, Ren¨¦ A. J. and Gelinck, Gerwin H.",Color Determination from a Single Broadband Organic Photodiode,2020,https://doi.org/10.1002/adom.201901722,https://onlinelibrary.wiley.com/doi/abs/10.1002/adom.201901722,Journal,Advanced Optical Materials,"Establishing the color of incident light is essential for many applications, such as machine vision, but generally requires either a dispersive component or multiple spectrally selective photodetectors. In contrast, here an incident spectrum is parametrized using a single broadband organic photodiode (OPD). This is achieved by exploiting the incident wavelength dependence of charge extraction caused by optically induced trap states in a metal oxide electron extraction layer, which results in an atypical spectral dependence of the reverse bias photocurrent density vs voltage (J¨CV) characteristics. Such dependence is augmented by confining the active layer within an optical microcavity to influence the light absorption profile and thus metal oxide trap state density. The average wavelength of an (approximately normally distributed) incident spectrum is then calculated to within ¡Ö5 nm by algorithmically minimizing the difference between a measured J¨CV curve and one determined from the overlap integral of a trial spectrum with previously acquired voltage bias dependent external quantum efficiency (EQE) spectra.",Wiley
"Hughes, Timothy J. and Cardamone, Salvatore and Popelier, Paul L. A.",Realistic sampling of amino acid geometries for a multipolar polarizable force field,2015,https://doi.org/10.1002/jcc.24006,https://onlinelibrary.wiley.com/doi/abs/10.1002/jcc.24006,Journal,Journal of Computational Chemistry,"The Quantum Chemical Topological Force Field (QCTFF) uses the machine learning method kriging to map atomic multipole moments to the coordinates of all atoms in the molecular system. It is important that kriging operates on relevant and realistic training sets of molecular geometries. Therefore, we sampled single amino acid geometries directly from protein crystal structures stored in the Protein Databank (PDB). This sampling enhances the conformational realism (in terms of dihedral angles) of the training geometries. However, these geometries can be fraught with inaccurate bond lengths and valence angles due to artefacts of the refinement process of the X-ray diffraction patterns, combined with experimentally invisible hydrogen atoms. This is why we developed a hybrid PDB/nonstationary normal modes (NM) sampling approach called PDB/NM. This method is superior over standard NM sampling, which captures only geometries optimized from the stationary points of single amino acids in the gas phase. Indeed, PDB/NM combines the sampling of relevant dihedral angles with chemically correct local geometries. Geometries sampled using PDB/NM were used to build kriging models for alanine and lysine, and their prediction accuracy was compared to models built from geometries sampled from three other sampling approaches. Bond length variation, as opposed to variation in dihedral angles, puts pressure on prediction accuracy, potentially lowering it. Hence, the larger coverage of dihedral angles of the PDB/NM method does not deteriorate the predictive accuracy of kriging models, compared to the NM sampling around local energetic minima used so far in the development of QCTFF. ? 2015 The Authors. Journal of Computational Chemistry Published by Wiley Periodicals, Inc.",Wiley
"Halder, Dipanjali and Prasannaa, V. Srinivasa and Agarawal, Valay and Maitra, Rahul",Iterative quantum phase estimation with variationally prepared reference state,2023,https://doi.org/10.1002/qua.27021,https://onlinelibrary.wiley.com/doi/abs/10.1002/qua.27021,Journal,International Journal of Quantum Chemistry,"The iterative quantum phase estimation algorithm (IQPE) is theoretically appealing in its wide scope of being able to handle electronic correlation. However, the quality of the initial input state strongly enhances the probability of landing on the desired eigenstate. In this work, we systematically study two different parametrization schemes of the unitary coupled cluster (UCC) ans?tz in the variational quantum eigensolver (VQE) framework toward the reference state preparation for IQPE. The efficacy of the UCC variants toward an appropriate state preparation is studied with prototypical H4 molecule on a circle. While the conventional UCC ans?tz can lead to high success probability across various degrees of electronic complexity, a resource efficient minimally parametrized UCC ans?tz consisting of active space excitations is shown to incorporate the essential static correlation in the reference state description. We demonstrate that such a carefully prepared initial state can significantly reduce the effects of noise due to sampling in the estimation of the desired eigenphase.",Wiley
"He, Zhijun and Yang, Qiqi and Li, Xiaoqian and Wang, Zi and Wen, Shengwu and Dong, Ming-Jie and Zhang, Weiyun and Gong, Youcong and Zhou, Zijia and Liu, Qiong and Dong, Haifeng",Vanadium Carbide Quantum Dots Exert Efficient Anti-Inflammatory Effects in Lipopolysaccharide-Induced BV2 Microglia and Mice,2024,https://doi.org/10.1002/smsc.202300334,https://onlinelibrary.wiley.com/doi/abs/10.1002/smsc.202300334,Journal,Small Science,"The regulation of glial cell activation is a critical step for the treatment or prevention of neuroinflammation-based brain diseases. However, the development of therapeutic drugs that pass the blood¨Cbrain barrier (BBB) and inhibit the glia cell activation remains a significant challenge. Herein, an ultrasmall 2D vanadium carbide quantum dots (V2C QDs) that are capable of crossing the BBB are prepared, and the admirable anti-neuroinflammatory effects are presented. The prepared 2D V2C QDs with an average size of 2.54?nm show good hydrophilicity, physiological stability, and effective BBB-crossing ability. The biological effect of V2C QDs on inflammatory reactions demonstrates fascinating results in preventing the impairment of learning and memory in BALB/c mice stimulated by lipopolysaccharide. Investigation of molecular mechanism reveals that V2C QDs not only inhibit the toll-like receptor 4/myeloid differentiation factor 88-mediated nuclear factor kappa B and mitogen-activated protein kinase pathways, but also prevent eukaryotic translation initiation factor 2¦Á/activating transcription factor 4/C/EBP homologous protein-signaling pathway and reduce oxidative stress via activating the NF-E2-related factor-2/heme oxygenase-1-signaling pathway, leading to greatly inhibited activation of microglia and astrocytes and weakened production of inflammatory cytokines. In summary, V2C QDs exert potent anti-inflammatory effects through multiple pathways, thus offer great potential for the treatment of neurodegenerative diseases.",Wiley
"Jin, Zihan and Wei, Zihao","Molecular simulation for food protein¨Cligand interactions: A comprehensive review on principles, current applications, and emerging trends",2024,https://doi.org/10.1111/1541-4337.13280,https://onlinelibrary.wiley.com/doi/abs/10.1111/1541-4337.13280,Journal,Comprehensive Reviews in Food Science and Food Safety,"In recent years, investigations on molecular interaction mechanisms between food proteins and ligands have attracted much interest. The interaction mechanisms can supply much useful information for many fields in the food industry, including nutrient delivery, food processing, auxiliary detection, and others. Molecular simulation has offered extraordinary insights into the interaction mechanisms. It can reflect binding conformation, interaction forces, binding affinity, key residues, and other information that physicochemical experiments cannot reveal in a fast and detailed manner. The simulation results have proven to be consistent with the results of physicochemical experiments. Molecular simulation holds great potential for future applications in the field of food protein¨Cligand interactions. This review elaborates on the principles of molecular docking and molecular dynamics simulation. Besides, their applications in food protein¨Cligand interactions are summarized. Furthermore, challenges, perspectives, and trends in molecular simulation of food protein¨Cligand interactions are proposed. Based on the results of molecular simulation, the mechanisms of interfacial behavior, enzyme-substrate binding, and structural changes during food processing can be reflected, and strategies for hazardous substance detection and food flavor adjustment can be generated. Moreover, molecular simulation can accelerate food development and reduce animal experiments. However, there are still several challenges to applying molecular simulation to food protein¨Cligand interaction research. The future trends will be a combination of international cooperation and data sharing, quantum mechanics/molecular mechanics, advanced computational techniques, and machine learning, which contribute to promoting food protein¨Cligand interaction simulation. Overall, the use of molecular simulation to study food protein¨Cligand interactions has a promising prospect.",Wiley
"Li, Yingnan and Fu, Yuzhuang and Chen, Xiling and Fan, Shilong and Cao, Zexing and Xu, Fei",A Dual-Focus Workflow for Simultaneously Engineering High Activity and Thermal Stability in Methyl Parathion Hydrolase,2024,https://doi.org/10.1002/anie.202410881,https://onlinelibrary.wiley.com/doi/abs/10.1002/anie.202410881,Journal,Angewandte Chemie International Edition,"Industrial fermentation applications typically require enzymes that exhibit high stability and activity at high temperatures. However, efforts to simultaneously improve these properties are usually limited by a trade-off between stability and activity. This report describes a computational strategy to enhance both activity and thermal stability of the mesophilic organophosphate-degrading enzyme, methyl parathion hydrolase (MPH). To predict hotspot mutation sites, we assembled a library of features associated with the target properties for each residue and then prioritized candidate sites by hierarchical clustering. Subsequent in silico screening with multiple algorithms to simulate selective pressures yielded a subset of 23?candidate mutations. Iterative parallel screening of mutations that improved thermal stability and activity yielded, MPHase-m5b, which exhibited 13.3?¡ãC higher Tm and 4.2?times higher catalytic activity than wild-type (WT) MPH over a wide temperature range. Systematic analysis of crystal structures, molecular dynamics (MD) simulations, and quantum mechanics/molecular mechanics (QM/MM) calculations revealed a wider entrance to the active site that increased substrate access with an extensive network of interactions outside the active site that reinforced ¦Á¦Â/¦Â¦Á sandwich architecture to improve thermal stability. This study thus provides an advanced, rational design framework to improve efficiency in engineering highly active, thermostable biocatalysts for industrial applications.",Wiley
"Park, Young Ran and Wang, Gunuk",Learning-Effective Mixed-Dimensional Halide Perovskite QD Synaptic Array for Self-Rectifying and Luminous Artificial Neural Networks,2024,https://doi.org/10.1002/adfm.202307971,https://onlinelibrary.wiley.com/doi/abs/10.1002/adfm.202307971,Journal,Advanced Functional Materials,"A mixed-dimensional heterostructure comprising nanomaterials with varying dimensions provides a promising structure for an artificial synapse for reconfigurable neuromorphic functions. In this study, an 8 ¡Á 8 memristor crossbar array based on a mixed-dimensional heterostructure comprising Cs1?xFAxPbBr3 (0.00 ¡Ü x ¡Ü 0.15) quantum dots (QDs) and different dimensional interfacial nanomaterial layers between the Al and ITO electrodes is designed and fabricated. This array device exhibits a high yield and reliable self-rectifying analog switching characteristics with low synaptic-coupling (SC, up to 5.19 ¡Á 10?5) and light emission, facilitating stimuli response visualization and preventing undesired pathways in the network array. Furthermore, because the formamidinium (FA) concentration alters the QD size, thereby engineering interfacial band alignment in the heterostructure, the essential synaptic properties such as dynamic range, SC, and nonlinearity can be improved. Especially, as x increases from 0 to 0.11, the recognition accuracy for the MNIST patterns increases significantly, from 68.97\% to 89.08\%, even for single-layer ANNs. The energy consumption required for a specific accuracy level is reduced by a factor of 25.15. The utilization of mixed-dimensional perovskite QD-based heterostructures in neural networks may provide desirable neuromorphic electronic functions with enhanced learning capability and energy efficiency, while preventing unwanted neural signals.",Wiley
"Gottschalk, Michael and Tropr¨¨s, Ir¨¨ne and Lamalle, Laurent and Grand, Sylvie and Le Bas, Jean-Fran?ois and Segebarth, Christoph","Refined modelling of the short-T2 signal component and ensuing detection of glutamate and glutamine in short-TE, localised, 1H MR spectra of human glioma measured at 3?T",2016,https://doi.org/10.1002/nbm.3548,https://onlinelibrary.wiley.com/doi/abs/10.1002/nbm.3548,Journal,NMR in Biomedicine,"Short-TE 1H MRS has great potential for brain cancer diagnostics. A major difficulty in the analysis of the spectra is the contribution from short-T2 signal components, mainly coming from mobile lipids. This complicates the accurate estimation of the spectral parameters of the resonance lines from metabolites, so that a qualitative to semi-quantitative interpretation of the spectra dominates in practice. One solution to overcome this difficulty is to measure and estimate the short-T2 signal component and to subtract it from the total signal, thus leaving only the metabolite signals. The technique works well when applied to spectra obtained from healthy individuals, but requires some optimisation during data acquisition. In the clinical setting, time constraints hardly allow this. Here, we propose an iterative estimation of the short-T2 signal component, acquired in a single acquisition after measurement of the full spectrum. The method is based on QUEST (quantitation based on quantum estimation) and allows the refinement of the estimate of the short-T2 signal component after measurement. Thus, acquisition protocols used on healthy volunteers can also be used on patients without further optimisation. The aim is to improve metabolite detection and, ultimately, to enable the estimation of the glutamine and glutamate signals distinctly. These two metabolites are of great interest in the characterisation of brain cancer, gliomas in particular. When applied to spectra from healthy volunteers, the new algorithm yields similar results to QUEST and direct subtraction of the short-T2 signal component. With patients, up to 12 metabolites and, at least, seven can be quantified in each individual brain tumour spectrum, depending on the metabolic state of the tumour. The refinement of the short-T2 signal component significantly improves the fitting procedure and produces a separate short-T2 signal component that can be used for the analysis of mobile lipid resonances. Thus, in brain tumour spectra, distinct estimates of signals from glutamate and glutamine are possible. Copyright ? 2016 John Wiley \& Sons, Ltd.",Wiley
"Ugalde, Hernan and Morris, William and Madriz, Yuleika and Kirsch, Moritz and Gloaguen, Richard and Schneider, Michael and Schiffler, Markus and Siemon, Bernhard and Fr¨¦ville, Tristan and Munschy, Marc","Locating skarns with magnetic survey data, Geyer, Erzgebirge: optimizing data acquisition procedures",2022,https://doi.org/10.1111/1365-2478.13231,https://onlinelibrary.wiley.com/doi/abs/10.1111/1365-2478.13231,Journal,Geophysical Prospecting,"ABSTRACT Magnetic data can be acquired from a number of different platforms (e.g., ground, drone, helicopter) using a variety of sensors (e.g., caesium vapour-type optically pumped magnetometers, fluxgate, superconducting quantum interference devices) with different flight line configurations. To detect a magnetic anomaly associated with a mineral commodity that is not exposed but is thought to be associated with the anomalous magnetic mineral content, it is necessary to optimize the survey parameters through a complete data integration process. Prior petrophysical measurements provide insight into the physical contrast that might be expected between adjacent lithologic units and between the ore zone and the encompassing lithology. Oriented rock samples provide access to magnetic remanence data through palaeomagnetic laboratory measurements. Knowing the typical morphology of the ore zone one can compute a forward model of the expected anomalous response and determine which combination of survey parameters provides the highest probability of detecting the commodity being sought. In this study, we analyse magnetic patterns associated with thin dipping skarn bodies from the Geyer mining district in Erzgebirge, Germany. Petrophysical measurements indicate that the skarns are more magnetic than the surrounding host rock. Partially oriented samples from a bore core record a Variscan age metamorphic remanence. Forward modelling indicates that clusters of skarn bodies are required to produce a reliably detectable magnetic signal. Ground, or low elevation drone surveys are needed to detect these anomalies with standard scalar-type optically pumped magnetometer or fluxgate magnetic surveys. The enhanced spatial resolution and long-wavelength rejection of a superconducting quantum interference device based full-tensor magnetic gradiometer provide an improvement over optically pumped magnetometers for an aircraft-based survey platform.",Wiley
"Kalam, Abdul and Kumar, Shubham and Kumar, Ashok and Panigrahi, Prasanta K.",Quantum Computation of Hydride Ion using Variational Quantum Algorithm,2024,https://doi.org/10.1002/slct.202402699,https://onlinelibrary.wiley.com/doi/abs/10.1002/slct.202402699,Journal,ChemistrySelect,"Because of remarkable reactivity and strong electron-electron correlation effects, the precise prediction of ground state energy and chemical reactivity of hydride ion is an essential objective in quantum chemistry. Leveraging variational quantum algorithms offers a promising avenue for studying molecular properties using current noisy intermediate-scale quantum devices. This work utilises the variational approach to anticipate the ground state, reactivity, and single-electron detachment energy of the three-body hydride ion. We investigated both Hardware-Efficient Ansatz (HEA) and Chemistry-inspired ansatz based on a Unitary Coupled Cluster (UCC) on both noiseless and noisy IBM simulators. Modern error-mitigating techniques, such as Zero-Noise Extrapolation (ZNE) with unitary folding and measurement error mitigation, have been implemented to significantly reduce errors in noisy environments. This study contributes to our understanding of the quantum computational nuances of the hydride ion and addresses the question of whether quantum computers can retain the correlation energies for these correlated ions.",Wiley
"Kutskaya, Anastasia M. and Serkov, Semyon A. and Voronin, Vladimir V. and Ledovskaya, Maria S. and Polynski, Mikhail V.",Negligible Substituent Effect as Key to Synthetic Versatility: a Computational-Experimental Study of Vinyl Ethers Addition to Nitrile Oxides,2022,https://doi.org/10.1002/slct.202200174,https://onlinelibrary.wiley.com/doi/abs/10.1002/slct.202200174,Journal,ChemistrySelect,"A tangible substituent effect may be perceived as a good feature in developing an organic reaction. This work demonstrates that, on the contrary, a zero-slope Hammet plot should be sought. The synthesis of isoxazoles by consecutive cycloaddition of nitrile oxides to vinyl ethers and alcohols elimination was studied computationally and experimentally. We performed a Hammett study in silico to demonstrate a negligible substituent effect (i.?e., broad substrate scope) in the addition of benzyl vinyl ether to nitrile oxides. The modeling was performed at the ¦ØB97X-V/def2-TZVP//PBE0-D4/def2-TZVP+SMD(benzene) level of theory within the RIJCOSX approximation. The experimental evaluation validated the computational model. A versatile methodology for synthesizing substituted isoxazolines and isoxazoles was proposed as the main result. We present this work as a successful example of how quantum chemical modeling can re-boost the classic Hammett approach to the optimization and design of organic synthetic methodologies. We anticipate further Hammett studies in silico, considering the current trend for data-driven chemical research.",Wiley
"Xu, Xiaowei and Wang, Rongna and Zhang, Dachao and Feng, Yingge",[Retracted] Clinical Application of Graphene Composite in Internal Fixation of Ankle Fracture in Sports,2022,https://doi.org/10.1155/2022/2504511,https://onlinelibrary.wiley.com/doi/abs/10.1155/2022/2504511,Journal,Advances in Materials Science and Engineering,"The ankle joint consists of the tibia, the fibrous lower end, and the talus. Osteoporotic fractures and deboning are common injuries in orthopaedic surgery, often due to abnormal disorders following an ankle fracture. Various fractures can occur depending on the shape, size, and position of the foot at the time of the injury. With the continuous development of science and the continuous improvement of modern sports level, scientists and sports workers worldwide recognize the importance of applying new materials in sports equipment. Composite material is a combination of multiphase combination material. In short, two or more components with different properties and different forms are used in a multimaterial combination of composite means. The organic combination of related scientific equipment and composite materials promotes the development of sports equipment and the probability of reducing sports injury. The function of the existing graphene composite is analyzed and applied, and the combination of graphene composite and sports is realized theoretically. The clinical application of graphene composite in sports is studied to promote sports development. This article mainly studies the clinical application of graphene composite in ankle fracture internal fixation in sports. It is found that with the increasingly mature application of graphene rubber composite, graphene fiber composite, and other graphene composite materials, it can be widely used in all aspects of sports equipment. Graphene composite materials can be used more easily in sports equipment. In this article, the thermal material conversion algorithm, Schrodinger equation in quantum mechanics, and the use method of graphene composite materials are used to study the clinical application of graphene composite in the internal fixation of ankle joint fracture in sports. The frequent injury and instability of ankle and knee joints are signs of ankle and knee joint injury. The main factors that affect the instability of ankle and knee function are the comprehensive effects of motion range, muscle force valgus, and body feeling, and graphene composite materials are widely used in the internal fixation of ankle joint fracture in sports. The results show that graphene composite can be used in sports equipment and has a great space and high feasibility through the analysis of four groups of sports equipment. It shows that advanced materials play a very important role in the research of sports equipment.",Wiley
"Su¨¢rez, Dimas and D¨ªaz, Natalia",Molecular Modeling of Bioorganometallic Compounds: Thermodynamic Properties of Molybdocene¨CGlutathione Complexes and Mechanism of Peptide Hydrolysis,2015,https://doi.org/10.1002/cphc.201500169,https://onlinelibrary.wiley.com/doi/abs/10.1002/cphc.201500169,Journal,ChemPhysChem,"The computational study of bioinorganic complexes between transition metals and flexible ligands is still challenging, given that, besides requiring extensive conformational searches, the treatment of metal¨Cligand bonds demands the application of quantum chemical methods. Herein, the adducts formed between molybdocene, which exhibits antitumor activity and reacts with thiol groups to give stable water-soluble complexes, and the tripeptide glutathione, which is a major source of biological thiols, are studied. Conformational searches are performed using the semiempirical PM6 method followed by geometry optimizations and single-point calculations using density functional theory methods. In addition, molecular dynamics simulations of the molybdocene¨Cglutathione complex involved in the regioselective hydrolysis of the Cys¨CGly linkage are performed in explicit solvent. The reactive process is also studied theoretically on cluster models of both the molybdocene-bound and the free peptide.",Wiley
"Lan, Jun and Li, Zhixiong and Chen, Zhenjie and Zhu, Quanzhou and Wang, Wenhui and Zaheer, Muhammad and Lu, Jiqing and Liang, Jinxuan and Shen, Mei and Chen, Peng and Chen, Kai and Zhang, Guobiao and Wang, Zhongrui and Zhou, Feichi and Lin, Longyang and Li, Yida",Improved Performance of HfxZnyO-Based RRAM and its Switching Characteristics down to 4 K Temperature,2023,https://doi.org/10.1002/aelm.202201250,https://onlinelibrary.wiley.com/doi/abs/10.1002/aelm.202201250,Journal,Advanced Electronic Materials,"The search for high-performance resistive random-access memory (RRAM) devices is essential to pave the way for highly efficient non-Von Neumann computing architecture. Here, it is reported on an alloying approach using atomic layer deposition for a Zn-doped HfOx-based resistive random-access memory (HfZnO RRAM), with improved performance. As compared with HfOx RRAM, the HfZnO RRAM exhibits reduced switching voltages (>20\%) and switching energy (>3¡Á), as well as better uniformity both in voltages and resistance states. Furthermore, the HfZnO RRAM exhibits stable retention exceeding 10 years, as well as write/erase endurance exceeding 105 cycles. In addition, excellent linearity and repeatability of conductance tuning can be achieved using the constant voltage pulse scheme, achieving ¡Ö90\% accuracy in a simulated multi-layer perceptron network for the recognition of modified national institute of standards and technology database handwriting. The HfZnO RRAM is also characterized down to the temperature of 4 K, showing functionality and the elucidation of its carrier conduction mechanism. Hence, a potential pathway for doped-RRAM to be used in a wide range of temperatures including quantum computing and deep-space exploration is shown.",Wiley
"Spackman, Peter R. and Bohman, Bj?rn and Karton, Amir and Jayatilaka, Dylan",Quantum chemical electron impact mass spectrum prediction for de novo structure elucidation: Assessment against experimental reference data and comparison to competitive fragmentation modeling,2018,https://doi.org/10.1002/qua.25460,https://onlinelibrary.wiley.com/doi/abs/10.1002/qua.25460,Journal,International Journal of Quantum Chemistry,"We investigate the success of the quantum chemical electron impact mass spectrum (QCEIMS) method in predicting the electron impact mass spectra of a diverse test set of 61 small molecules selected to be representative of common fragmentations and reactions in electron impact mass spectra. Comparison with experimental spectra is performed using the standard matching algorithms, and the relative ranking position of the actual molecule matching the spectra within the NIST-11 library is examined. We find that the correct spectrum is ranked in the top two matches from structural isomers in more than 50\% of the cases. QCEIMS, thus, reproduces the distribution of peaks sufficiently well to identify the compounds, with the RMSD and mean absolute difference between appropriately normalized predicted and experimental spectra being at most 9\% and 3\% respectively, even though the most intense peaks are often qualitatively poorly reproduced. We also compare the QCEIMS method to competitive fragmentation modeling for electron ionization, a training-based mass spectrum prediction method, and remarkably we find the QCEIMS performs equivalently or better. We conclude that QCEIMS will be very useful for those who wish to identify new compounds which are not well represented in the mass spectral databases.",Wiley
"Abelha, Thais F. and Morris, Graeme and Lima, Sandro M. and Andrade, Luis H. C. and McLean, Andrew J. and Alexander, Cameron and Calvo-Castro, Jesus and McHugh, Callum J.",Development of a Neutral Diketopyrrolopyrrole Phosphine Oxide for the Selective Bioimaging of Mitochondria at the Nanomolar Level,2020,https://doi.org/10.1002/chem.201905634,https://onlinelibrary.wiley.com/doi/abs/10.1002/chem.201905634,Journal,Chemistry ¨C A European Journal,"Development of novel bioimaging materials that exhibit organelle specific accumulation continues to be at the forefront of research interests and efforts. Among the various subcellular organelles, mitochondria, which are found in the cytoplasm of eukaryotic cells, are of particular interest in relation to their vital function. To date, most molecular probes that target mitochondria utilise delocalised lipophilic cations such as triphenylphosphonium and pyridinium. However, the use of such charged motifs is known to be detrimental to the working function of the mitochondrial transmembrane potential and there remains a strong case for development of neutral mitochondrial fluorescent probes. Herein, we demonstrate for the first time the exploitation of diketopyrrolopyrrole-based chemistries for the realisation of a neutral fluorescent probe that exhibits organelle specific accumulation within the mitochondria at the nanomolar level. The synthesised probe, which bears a neutral triphenylphosphine oxide moiety, exhibits a large Stokes shift and high fluorescence quantum yield in water, both highly sought-after properties in the development of bioimaging agents. In vitro studies reveal no interference with cell metabolism when tested for the human MCF7 breast cancer cell and nanomolar subcellular organelle colocalisation with commercially available mitochondrial staining agent Mitotracker Red. In light of its novelty, neutral structure and the preferential accumulation at nanomolar concentrations we anticipate this work to be of significant interest for the increasingly larger community devoted to the realisation of neutral mitochondrial selective systems and more widely to those engaged in the rational development of superior organic architectures in the biological field.",Wiley
"Xia, Xiao-Jian and Fang, Ping-Ping and Guo, Xie and Qian, Xiang-Jie and Zhou, Jie and Shi, Kai and Zhou, Yan-Hong and Yu, Jing-Quan",Brassinosteroid-mediated apoplastic HO-glutaredoxin 12/14 cascade regulates antioxidant capacity in response to chilling in tomato,2018,https://doi.org/10.1111/pce.13052,https://onlinelibrary.wiley.com/doi/abs/10.1111/pce.13052,Journal,"Plant, Cell \& Environment","Brassinosteroids (BRs) regulate plant development and stress response. Although much has been learned about their roles in plant development, the mechanisms by which BRs regulate plant stress tolerance remain unclear. Chilling is a major stress that adversely affects plant growth. Here, we report that BR positively regulates chilling tolerance in tomato. BR partial deficiency aggravated chilling-induced oxidized protein accumulation, membrane lipid peroxidation, and decrease of maximum quantum efficiency of photosystem II (Fv/Fm). By contrast, overexpression of BR biosynthetic gene Dwarf or treatment with 24-epibrassinolide (EBR) attenuated chilling-induced oxidative damages and resulted in an increase of Fv/Fm. BR increased transcripts of RESPIRATORY BURST OXIDASE HOMOLOG1 (RBOH1) and GLUTAREDOXIN (GRX) genes, and BR-induced chilling tolerance was associated with an increase in the ratio of reduced/oxidized 2-cysteine peroxiredoxin (2-Cys Prx) and activation of antioxidant enzymes. However, RBOH1-RNAi plants failed to respond to EBR as regards to the induction of GRX genes, activation of antioxidant capacity, and attenuation of chilling-induced oxidative damages. Furthermore, silencing of GRXS12 and S14 compromised EBR-induced increases in the ratio of reduced/oxidized 2-Cys Prx and activities of antioxidant enzymes. Our study suggests that BR enhances chilling tolerance through a signalling cascade involving RBOH1, GRXs, and 2-Cys Prx in tomato.",Wiley
"Bossavit, Erwan and Yeromina, Oleksandra and Mastrippolito, Dario and Cavallo, Mariarosa and Zhang, Huichen and Gemo, Tommaso and Colle, Albin and Khalili, Adrien and Shcherbakov, Andrei and Nguyen, Lam Do and Abadie, Claire and Dandeu, Erwan and Silly, Mathieu G. and Gallas, Bruno and Pierucci, Debora and Degiron, Aloyse and Reiss, Peter and Lhuillier, Emmanuel",Advancing the Coupling of III¨CV Quantum Dots to Photonic Structures to Shape Their Emission Diagram,2024,https://doi.org/10.1002/adom.202401601,https://onlinelibrary.wiley.com/doi/abs/10.1002/adom.202401601,Journal,Advanced Optical Materials,"The development of optoelectronic devices based on III¨CV semiconductor colloidal quantum dots (CQDs) is highly sought after due to their reduced toxicity. While devices based on conventional CQDs (II¨CVI semiconductors, halide perovskites) have achieved impressive technological leaps since their discovery, the most mature of these compounds contain toxic heavy metal elements (Cd, Hg, or Pb), which are highly undesirable for safe industrial scale applications. The strong covalent bonds of III¨CV compounds like InP, InAs, or InSb prevent the release of their toxic atoms, making them safer. However, these same bonds create severe material constraints. Namely, their harsher reaction conditions and increased sensitivity to oxidation have kept most of the research focused on material development. Meanwhile, their integration into devices and their coupling to photonic structures lag behind. Here, the integration of InAs/ZnSe core-shell CQDs is advanced. First, the material parameters necessary to design plasmonic gratings coupled to the CQDs are elucidated and those gratings are fabricated. Angle-resolved spectroscopy shows that the plasmon modes successfully couple to the CQD layer's emission leading to a tunable directivity with a 15¡ã linewidth. A 3-fold increase of the PL signal is achieved at normal incidence, thus advancing toward the goal of efficient outcoupling in LEDs.",Wiley
"Myronov, Maksym and Kycia, Jan and Waldron, Philip and Jiang, Weihong and Barrios, Pedro and Bogan, Alex and Coleridge, Peter and Studenikin, Sergei",Holes Outperform Electrons in Group IV Semiconductor Materials,2023,https://doi.org/10.1002/smsc.202200094,https://onlinelibrary.wiley.com/doi/abs/10.1002/smsc.202200094,Journal,Small Science,"A record-high mobility of holes, reaching 4.3?¡Á?106?cm2?V?1?s?1 at 300?mK in an epitaxial strained germanium (s-Ge) semiconductor, grown on a standard silicon wafer, is reported. This major breakthrough is achieved due to the development of state-of-the-art epitaxial growth technology culminating in superior monocrystalline quality of the s-Ge material platform with a very low density of background impurities and other imperfections. As a consequence, the hole mobility in s-Ge appears to be ¡Ö2 times higher than the highest electron mobility in strained silicon. In addition to the record mobility, this material platform reveals a unique combination of properties, which are a very large and tuneable effective g*-factor (>18), a very low percolation density (5?¡Á?109?cm?2) and a small effective mass (0.054?m 0). This long-sought combination of parameters in one material system is important for the research and development of low-temperature electronics with reduced Joule heating and for quantum-electronics circuits based on spin qubits.",Wiley
"Xiong, Yingfei and Teng, Sasa and Zheng, Lianghong and Sun, Suhua and Li, Jie and Guo, Ning and Li, Mingli and Wang, Li and Zhu, Feipeng and Wang, Changhe and Rao, Zhiren and Zhou, Zhuan",Stretch-induced Ca2+ independent ATP release in hippocampal astrocytes,2018,https://doi.org/10.1113/JP275805,https://onlinelibrary.wiley.com/doi/abs/10.1113/JP275805,Journal,The Journal of Physiology,"Key points Similar to neurons, astrocytes actively participate in synaptic transmission via releasing gliotransmitters. The Ca2+-dependent release of gliotransmitters includes glutamate and ATP. Following an ¡®on-cell-like¡¯ mechanical stimulus to a single astrocyte, Ca2+ independent single, large, non-quantal, ATP release occurs. Astrocytic ATP release is inhibited by either selective antagonist treatment or genetic knockdown of P2X7 receptor channels. Our work suggests that ATP can be released from astrocytes via two independent pathways in hippocampal astrocytes; in addition to the known Ca2+-dependent vesicular release, larger non-quantal ATP release depends on P2X7 channels following mechanical stretch. Astrocytic ATP release is essential for brain functions such as synaptic long-term potentiation for learning and memory. However, whether and how ATP is released via exocytosis remains hotly debated. All previous studies of non-vesicular ATP release have used indirect assays. By contrast, two recent studies report vesicular ATP release using more direct assays. In the present study, using patch clamped ¡®ATP-sniffer cells¡¯, we re-investigated astrocytic ATP release at single-vesicle resolution in hippocampal astrocytes. Following an ¡®on-cell-like¡¯ mechanical stimulus of a single astrocyte, a Ca2+ independent single large non-quantal ATP release occurred, in contrast to the Ca2+-dependent multiple small quantal ATP release in a chromaffin cell. The mechanical stimulation-induced ATP release from an astrocyte was inhibited by either exposure to a selective antagonist or genetic knockdown of P2X7 receptor channels. Functional P2X7 channels were expressed in astrocytes in hippocampal brain slices. Thus, in addition to small quantal ATP release, larger non-quantal ATP release depends on P2X7 channels in astrocytes.",Wiley
"El Hage, Krystel and Piquemal, Jean-Philip and Hobaika, Zeina and Maroun, Richard G. and Gresh, Nohad","Could the ¡°Janus-like¡± properties of the halobenzene CX bond (X?Cl, Br) be leveraged to enhance molecular recognition?",2015,https://doi.org/10.1002/jcc.23786,https://onlinelibrary.wiley.com/doi/abs/10.1002/jcc.23786,Journal,Journal of Computational Chemistry,"The CX bond in halobenzenes (X?Cl, Br) exhibits a dual character, being electron-deficient along the CX direction, and electron-rich on its flanks. We sought to amplify both features by resorting to electron-withdrawing and electron-donating substituents, respectively. This was done by quantum chemistry (QC) computations in the recognition sites of three protein targets: farnesyl transferase, coagulation factor Xa, and the HIV-1 integrase. In this context, some substituents, notably fluorine, CF3, and NHCH3, afforded significant overall gains in the binding energies as compared to the parent halobenzene, in the 2¨C5 kcal/mol range. In fact, we found that some di- and up to tetra-substitutions enabled even larger gains than those they contribute separately owing to many-body effects. Moreover, desolvation was also found to be a key contributor to the energy balances. As a consequence, some particular substituents, contributing to reduce the halobenzene dipole moment, accordingly reduced solvation: this factor acted in synergy with their enhancement of the intermolecular interaction energies along and around the CX bond. We could thus leverage the ¡°Janus-like¡± properties of such a bond and the fact that it can be tuned and possibly amplified by well-chosen substituents. We propose a simple yet rigorous computational strategy resorting to QC to prescreen novel substituted halobenzenes. The QC results on the recognition sites then set benchmarks to validate polarizable molecular mechanics/dynamics approaches used to handle the entirety of the inhibitor-protein complex. ? 2014 Wiley Periodicals, Inc.",Wiley
"Penfold, T. J. and Eng, J.",Tailoring Donor-Acceptor Emitters to Minimise Localisation Induced Quenching of Thermally Activated Delayed Fluorescence,2023,https://doi.org/10.1002/cptc.202200243,https://onlinelibrary.wiley.com/doi/abs/10.1002/cptc.202200243,Journal,ChemPhotoChem,"By inverting the common structural motif of thermally activated delayed fluorescence (TADF) materials to a rigid donor core and multiple peripheral acceptors, it has been shown possible to achieve both a reverse intersystem crossing (rISC) rate 1¡Á107?s?1 and a unity photoluminescence quantum yield [Dos Santos et?al. Adv. Sci. 5 (2018) 1700989]. However, the rISC rate in this motif is quenched by localisation of the excited state electronic structure which causes in-equivalence between the peripheral acceptors. In this paper, we explore a series of related molecular targets which seek to reduce the effect of localisation on the rISC rates. This includes structures that contain donors exhibiting three-fold or four-fold symmetry and different degrees of steric hindrance around the donor-acceptor bond with the objective of using steric hindrance to exert finer conformational control of the excited state dynamics to enhance functional properties. We demonstrate that a triazatruxene central donor is most effective for TADF owing to the energetic position of the locally excited state, while cyano-benzonitriles are the most effective acceptors for reducing the effect of localisation on the electronic structure. These also push the emission into the blue region of the spectrum, opening the possibilities for this to be a pathway to develop efficient blue TADF emitters.",Wiley
"Mart¨ªnez-Ram¨ªrez, Carmen and Baraibar, Andr¨¦s M. and Nanclares, Carmen and M¨¦ndez-L¨®pez, Iago and G¨®mez, Ana and Mu?oz, M? Paz and de Diego, Antonio M. G. and Gand¨ªa, Luis and Casarejos, Mar¨ªa Jos¨¦ and Garc¨ªa, Antonio G.",Altered excitability and exocytosis in chromaffin cells from the R6/1 mouse model of Huntington's disease is linked to over-expression of mutated huntingtin,2018,https://doi.org/10.1111/jnc.14585,https://onlinelibrary.wiley.com/doi/abs/10.1111/jnc.14585,Journal,Journal of Neurochemistry,"As the peripheral sympathoadrenal axis is tightly controlled by the cortex via hypothalamus and brain stem, the central pathological features of Hunting's disease, (HD) that is, deposition of mutated huntingtin and synaptic dysfunctions, could also be expressed in adrenal chromaffin cells. To test this hypothesis we here present a thorough investigation on the pathological and functional changes undergone by chromaffin cells (CCs) from 2-month (2 m) to 7-month (7 m) aged wild-type (WT) and R6/1 mouse model of Huntington's disease (HD), stimulated with acetylcholine (ACh) or high [K+] (K+). In order to do this, we used different techniques such as inmunohistochemistry, patch-clamp, and amperometric recording. With respect to WT cells, some of the changes next summarized were already observed in HD mice at a pre-disease stage (2 m); however, they were more pronounced at 7 m when motor deficits were clearly established, as follows: (i) huntingtin over-expression as nuclear aggregates in CCs; (ii) smaller CC size with decreased dopamine ¦Â-hydroxylase expression, indicating lesser number of chromaffin secretory vesicles; (iii) reduced adrenal tissue catecholamine content; (iv) reduced Na+ currents with (v) membrane hyperpolarization and reduced ACh-evoked action potentials; (v) reduced [Ca2+]c transients with faster Ca2+ clearance; (vi) diminished quantal secretion with smaller vesicle quantal size; (vii) faster kinetics of the exocytotic fusion pore, pore expansion, and closure. On the basis of these data, the hypothesis is here raised in the sense that nuclear deposition of mutated huntingtin in adrenal CCs of R6/1 mice could be primarily responsible for poorer Na+ channel expression and function, giving rise to profound depression of cell excitability, altered Ca2+ handling and exocytosis. Open Practices This article has received a badge for *Open Materials* because it provided all relevant information to reproduce the study in the manuscript. The complete Open Science Disclosure form for this article can be found at the end of the article. More information about the Open Practices badges can be found at https://cos.io/our-services/open-science-badges/. Cover Image for this issue: doi: 10.1111/jnc.14201.",Wiley
"Ho, Wen-Jeng and Liu, Jheng-Jie and Chen, Xing-Yu and Xiao, Hung-Pin",Light-trapping and spectral modulation to increase the conversion efficiency of triple-junction GaAs solar cells using antireflective coating comprising a periodic array of cone-shaped TiO structures,2022,https://doi.org/10.1002/er.7240,https://onlinelibrary.wiley.com/doi/abs/10.1002/er.7240,Journal,International Journal of Energy Research,"Summary This study sought to increase the conversion efficiency of triple-junction GaAs solar cells via spectral light trapping through the application of a uniform TiO2 layer with an antireflective coating (ARC) comprising a periodic array of cone-shaped TiO2 structures. The cone-shaped TiO2 ARC structures were fabricated using a mask of polystyrene spheres (PS) of various diameters (600, 700, and 800?nm). This surface modification was meant to match external quantum efficiency (EQE) response and reflectance spectra in order to modulate the light-trapping effects. In experiments, forward light scattering and reduced reflectivity were shown to improve the EQE response of the cells to beyond that of the cell with a uniform layer of TiO2. The average weighted EQE (EQEW) values of the cell with the proposed ARC (PS: 600?nm) exceeded that of cells with larger surface structure (PS: 700 or 800?nm). These modifications were also shown to increase short-circuit current-density (JSC) and conversion efficiency (¦Ç), as confirmed by photovoltaic current-voltage measurements under AM 1.5G illumination. The cone-shaped ARC structures also increased the acceptance angle and electrical output under solar illumination of a given duration. Compared to the reference cell, the cell with 600-nm structures enhanced the EQEW by an impressive 40.26\% (from 48.88\% to 68.56\%), JSC by 20.55\% (from 9.73 to 11.73?mA/cm2), and ¦Ç by 20.59\% (from 20.98\% to 25.30\%).",Wiley
"Mishra, Poonam and Narayanan, Rishikesh",Ion-channel degeneracy: Multiple ion channels heterogeneously regulate intrinsic physiology of rat hippocampal granule cells,2021,https://doi.org/10.14814/phy2.14963,https://onlinelibrary.wiley.com/doi/abs/10.14814/phy2.14963,Journal,Physiological Reports,"Degeneracy, the ability of multiple structural components to elicit the same characteristic functional properties, constitutes an elegant mechanism for achieving biological robustness. In this study, we sought electrophysiological signatures for the expression of ion-channel degeneracy in the emergence of intrinsic properties of rat hippocampal granule cells. We measured the impact of four different ion-channel subtypes¡ªhyperpolarization-activated cyclic-nucleotide-gated (HCN), barium-sensitive inward rectifier potassium (Kir), tertiapin-Q-sensitive inward rectifier potassium, and persistent sodium (NaP) channels¡ªon 21 functional measurements employing pharmacological agents, and report electrophysiological data on two characteristic signatures for the expression of ion-channel degeneracy in granule cells. First, the blockade of a specific ion-channel subtype altered several, but not all, functional measurements. Furthermore, any given functional measurement was altered by the blockade of many, but not all, ion-channel subtypes. Second, the impact of blocking each ion-channel subtype manifested neuron-to-neuron variability in the quantum of changes in the electrophysiological measurements. Specifically, we found that blocking HCN or Ba-sensitive Kir channels enhanced action potential firing rate, but blockade of NaP channels reduced firing rate of granule cells. Subthreshold measures of granule cell intrinsic excitability (input resistance, temporal summation, and impedance amplitude) were enhanced by blockade of HCN or Ba-sensitive Kir channels, but were not significantly altered by NaP channel blockade. We confirmed that the HCN and Ba-sensitive Kir channels independently altered sub- and suprathreshold properties of granule cells through sequential application of pharmacological agents that blocked these channels. Finally, we found that none of the sub- or suprathreshold measurements of granule cells were significantly altered upon treatment with tertiapin-Q. Together, the heterogeneous many-to-many mapping between ion channels and single-neuron intrinsic properties emphasizes the need to account for ion-channel degeneracy in cellular- and network-scale physiology.",Wiley
